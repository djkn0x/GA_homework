Action-Gap Phenomenon 
in Reinforcement Learning

Amir-massoud Farahmand
academic.SoloGen.net

Easy choice! Even if we 
don’t know the exact 
quality (value) of each 
choice (action)

r
e
t
t
e
B

vs.

r
e
t
t
e
B

vs.

Not a big deal if we choose the wrong one!

Cheesecake and Bara Brith by zingyyellow@Flicker. Broccoli by Daniel Eizans@Flicker.

The Fixed Points of Off-Policy TD 
J. Zico Kolter 
Computer Science and Artificial Intelligence Laboratory 
Massachusetts Institute of Technology 

Poster T6 

• Given sequence of experience: 
Action 

State 

Reward 

• For an arbitrary policy, determine value (expected sum 
of discounted rewards) for acting under that policy 

• Can be solved, in principle, by Temporal Difference learning: 

Repeat: 

• Works when values are represented explicitly, but might 
not work with value function approximation 

On-Policy 

Off-Policy 

TD converges  
[Tsitsiklis and Van Roy, 1997] 

TD solution close to true value function   
[Tsitsiklis and Van Roy, 1997] 

TD can fail to converge [Boyan, 1994] 
(cid:857) (cid:296)(cid:349)(cid:454)(cid:286)(cid:282)(cid:842) (cid:896)S(cid:437)(cid:410)(cid:410)(cid:381)(cid:374) et al., 2008] 
TD solution can be arbitrarily poor  
[example in paper] 

J. Zico Kolter | The Fixed Points of Off-Policy TD | Poster T6 

• This work is about fixing off-policy TD 
Basic idea: reweight samples so that TD solution has 
quality guarantees (and so that TD converges) 

• Technical idea 
Off-policy 
sampling 

"TD operator" not 
a contraction 

"filtered" states 

stationary distribution of policy 

Key contribution: we can find set of all 
distributions for which TD operator is 
a contraction (represented efficiently 
via a linear matrix inequality) 

Algorithm: Project empirical 
distribution on to this set 

J. Zico Kolter | The Fixed Points of Off-Policy TD | Poster T6 

• Guarantees on resulting solution quality 

Modified off-policy solution 

Best possible approximation 
in function class 

• Efficient projection via low-rank optimization of dual problem 

• Provides much better solutions in practice 

J. Zico Kolter | The Fixed Points of Off-Policy TD | Poster T6 

Inductive reasoning about chimeric creatures 

Charles Kemp 
Carnegie Mellon University 

Inductive reasoning 

Animal X has no legs. 
Animal X can fly. 
 
Animal X has wings. 

(Osherson, Rips, Heit, …) 
 

Modeling inductive reasoning 

Structure combination 
model 

Observed entries taken from  
the Leuven Natural Concept  
Database (DeDeyne et al) 
 

An undirected graphical model 
 

Experimental results 

1)   Chimeras 

Exemplar model 
(case-based) 
 
 

Structure combination 
model 
 
 

Animal X has no legs. 
Animal X can fly. 
 
Animal X has wings. 

 
n
a
m
u
h

2)  Non-chimeras 

Animal X has no legs. 
 
Animal X has wings. 

model 

!"#$%#&’()*+,)-’",./,)0,1-/-2’34#5-’()
#66.2#1+)*2)6.,7,.,’1,)$,#.’-’()

8$#’)9,.’)

:+.-/*26+,.);<)=%1#/)

:+#.$,/)>,46)

>’2?)8$-1,@/)6.,7,.,’1,/)

H’7,.)8$-1,@/)6.,7,.,’1,/)

G)

G)

G)

G)

G)

G)

A6&2’)B)

A6&2’)C)

A6&2’)D)

A6&2’)B)

A6&2’)C)

A6&2’)D)

E.,0-1*)8$-1,@/)1+2-1,)F,+#"-2.)

AF/,.",)8$-1,@/)1+2-1,)F,+#"-2.)

H’7,..-’()8$-1,@/)6.,7,.,’1,/)

8$-1,@/)6.,7,.,’1,/)
I%&$-&,/T)

8$-1,@/)26&2’/)

u

p(c = o j | u, f ) =

f

T u)
j

exp(f
n
!
k=1

T u)
exp(f
k

c

8$-1,@/)1+2-1,)

•! ;,’,.#&",)#66.2#1+)
–! H’",./,)0,1-/-2’34#5-’()
IJ1K#00,’L)BMNDO)=%1#/L),*)#$<L)CPPMO)
Q,.(,’L)!"#’/L)R)S,’,’F#%4L)CPBPO)
9,.’)R)>,46L)CPBBT)

•! U-/1.-4-’#&",)#66.2#1+)
–! K,#*%.,3F#/,0)4#66-’()7.24)
0,1-/-2’)V7,#*%.,/W)*2)
6.,7,.,’1,/)

!X#46$,)0,1-/-2’)

:#’0Y)

)
/
(
’
-
5
’
#
.
)
$
,
0
2
J

:#’0Y)"/<)!$,1*.-1)[+215/)

Z%4#’).#’5-’(/)

)
/
(
’
-
5
’
#
.
)
’
#
4
%
Z

)
T
/
5
1
2
+
[
)
1
-
.
*
1
,
$
!
I

!$,1*.-1)[+215/)

Z%4#’).#’5-’(/)
I:#’0YT)

)
/
(
’
-
5
’
#
.
)
$
,
0
2
J

K,#*%.,3F#/,0)420,$/)1#’)2’$Y)4#*1+)
6,.72.4#’1,)27)-’",./,)0,1-/-2’34#5-’()
#66.2#1+)?+,’)6.2"-0,0)?-*+)4#’Y)7,#*%.,/<)

Z%4#’).#’5-’(/)

Identifying Alzheimer’s Disease Brain 
Regions from Multi-Modality 
Neuroimaging Data Using Sparse 
Composite Linear Discrimination 
Analysis (SCLDA) 

Shuai Huang, Jing Li, Jieping Ye, Teresa Wu, 
Kewei Chen, Adam Fleisher, Eric Reiman  

1 

Shuai Huang 

T016  

Combine MRI and PET for AD Study 

A tree structure which links the AD pathology, brain regions, PET and MRI  

MRI and PET measure the 
same AD pathology, and 
supplement each other 

A joint analysis of MRI and 
PET imaging data will 
increase the statistical 
power to detect AD-related 
brain regions 

(cid:303)1 

(cid:303)3 

(cid:303)2 

(cid:537)1P 

(cid:537)1M 

Region 2 

(cid:537)2P  (cid:537)2M 

(cid:537)3P 

(cid:537)3M 

PET 
MRI 
 (cid:303)1 : the relatedness of brain region 1 with the AD pathology 
 (cid:537)1P: the signal strength of (cid:537)1 reflected on PET (i.e., enhanced or reduced ) 
 (cid:537)2M: the signal strength of (cid:537)1 reflected on MRI (i.e., enhanced or reduced)  
Shuai Huang 

2 

Formulation of SCLDA 

Original formulation – impose penalty on both (cid:537) and (cid:534)   

Reduced formulation – a non-convex sparse learning model  

Superiority over L1/L2 penalty 

Less shrinkage effect – less irrelevant 
features been selected  

DC (difference of convex 
functions) programming is 
used to solve the optimization 
task 

No more “all-in-all-out” solution for the 
parameters under the same square root  

Has a linkage with adaptive 
LASSO 

3 

Shuai Huang 

Result – Identified AD-related Brain Regions 

Locations of AD-related brain regions  

PET  

MRI 

Most of the AD-related regions are consistent with existing knowledge  

4 

Shuai Huang 

Anatomically Constrained Decoding of 
Finger Flexion from Electrocorticographic
Signals
Zuoguan Wang1, Gerwin Schalk2, Qiang Ji1

1. Rensselaer Polytechnic Institute  2. Wadsworth Center
y

Goal: Decoding finger flexion from ECoG signals

Motivations
(cid:149) Motivations
(cid:149) Existing decoding methods are mainly 
data-driven, ignoring anatomical and 
kinematic constraints on finger motion.

(cid:149) Bayesian Decoding
y
g

Anatomical and Kinematic 
Constraints

1. Three states: extension (S1), flexion (S2) and rest (S3)

For each state there are predominant movement patterns
2. For each state, there are predominant movement patterns
2

3. For S1 and S2, move faster at middle and slower at two ends

4. Finger movement is limited to certain ranges
Finger mo ement is limited to certain ranges

5. The transition among states is  limited

6. The probability of transitions depends on finger positions
i i
fi
d
d
i i
f
b bili
Th

Prior Model (SNDS)
(
)

States

Finger 

position
position

Measurement

F
D
P

− =
1

(
P Y
t

−
1

|

S
t

=

flexion S
,
t

extension
)

Results

Pace 
regression
regression

Our model

Predicted 
States

26% improvement over pace regression used
26% improvement over pace regression used 

in the previous work in terms of MSE

Active learning of 
neural response functions 
with Gaussian processes

Mijung Park, 
Greg Horwitz, 
& Jonathan Pillow 

poster T020

“cascade” neural  encoding model

linear

nonlinear

stochastic spiking

*.0%$1/.)
1,%4*#"%

!"#$$"%
$&#’#%()

./$&"%$/

$*#+,-,$

2#$*".3)1#-*/.

GP prior

Question: how to eﬃciently learn neural response nonlinearities?

Adaptive stimulus selection
• “closed-loop” experiment
• select     for which             has highest uncertainty 

!"#"$%&!%’()#)!

"2*".’("3%

)*+,%"&*-!%".’-.

)*+,%"&/0*".1*,.,(!

Poisson likelihood

GP prior

