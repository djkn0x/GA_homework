A Two-Stage Weighting Framework for Multi-Source
Domain Adaptation

Qian Sun∗ , Rita Chattopadhyay∗, Sethuraman Panchanathan, Jieping Ye
Computer Science and Engineering, Arizona State University, AZ 85287
{Qian Sun, rchattop, panch, Jieping.Ye}@asu.edu

Abstract

Discriminative learning when training and test data belong to different distribu-
tions is a challenging and complex task. Often times we have very few or no
labeled data from the test or target distribution but may have plenty of labeled
data from multiple related sources with different distributions. The difference in
distributions may be both in marginal and conditional probabilities. Most of the
existing domain adaptation work focuses on the marginal probability distribution
difference between the domains, assuming that the conditional probabilities are
similar. However in many real world applications, conditional probability dis-
tribution differences are as commonplace as marginal probability differences. In
this paper we propose a two-stage domain adaptation methodology which com-
bines weighted data from multiple sources based on marginal probability differ-
ences (ﬁrst stage) as well as conditional probability differences (second stage),
with the target domain data. The weights for minimizing the marginal probability
differences are estimated independently, while the weights for minimizing condi-
tional probability differences are computed simultaneously by exploiting the po-
tential interaction among multiple sources. We also provide a theoretical analysis
on the generalization performance of the proposed multi-source domain adapta-
tion formulation using the weighted Rademacher complexity measure. Empirical
comparisons with existing state-of-the-art domain adaptation methods using three
real-world datasets demonstrate the effectiveness of the proposed approach.

1

Introduction

We consider the domain adaptation scenarios where we have very few or no labeled data from target
domain but a large amount of labeled data from multiple related source domains with different data
distributions. Under such situations, learning a single or multiple hypotheses on the source domains
using traditional machine learning methodologies and applying them on target domain data may lead
to poor prediction performance. This is because traditional machine learning algorithms assume that
both the source and target domain data are drawn i.i.d. from the same distribution. Figure 1 shows
two such source distributions, along with their hypotheses obtained based on traditional machine
learning methodologies and a target data distribution. It is evident that the hypotheses learned by
the two source distributions D1 and D2 would perform poorly on the target domain data.
One effective approach under such situations is domain adaptation, which enables transfer of knowl-
edge between the source and target domains with dissimilar distributions [1]. It has been applied
successfully in various applications including text classiﬁcation (parts of speech tagging, webpage
tagging, etc) [2], video concept detection across different TV channels [3], sentiment analysis (iden-
tifying positive and negative reviews across domains) [4] and WiFi Localization (locating device
location depending upon the signal strengths from various access points) [5].
∗Authors contributed equally.

1

Figure 1: Two source domains D1 and D2 and target domain data with different marginal and
conditional probability differences, along with conﬂicting conditional probabilities (the red squares
and blue triangles refer to the positive and negative classes).
Many existing methods re-weight source domain data in order to minimize the marginal probability
differences between the source and target domains and learn a hypothesis on the re-weighted source
data [6, 7, 8, 9]. However they assume that the distributions differ only in marginal probabilities but
the conditional probabilities remain the same. There are other methods that learn model parameters
to reduce marginal probability differences [10, 11]. Similarly, several algorithms have been devel-
oped in the past to combine knowledge from multiple sources [12, 13, 14]. Most of these methods
measure the distribution difference between each source and target domain data, independently,
based on marginal or conditional probability differences and combine the hypotheses generated by
each of them on the basis of the respective similarity factors. However the example in Figure 1
demonstrates the importance of considering both marginal and conditional probability differences
in multi-source domain adaptation.
In this paper we propose a two-stage multi-source domain adaptation framework which computes
weights for the data samples from multiple sources to reduce both marginal and conditional prob-
ability differences between the source and target domains. In the ﬁrst stage, we compute weights
of the source domain data samples to reduce the marginal probability differences, using Maximum
Mean Discrepancy (MMD) [15, 6] as the measure. The second stage computes the weights of
multiple sources to reduce the conditional probability differences; the computation is based on the
smoothness assumption on the conditional probability distribution of the target domain data [16].
Finally, a target classiﬁer is learned on the re-weighted source domain data. A novel feature of our
weighting methodologies is that no labeled data is needed from the target domain, thus widening the
scope of their applicability. The proposed framework is readily extendable to the case where a few
labeled data may be available from the target domain.
In addition, we present a detailed theoretical analysis on the generalization performance of our
proposed framework. The error bound of the proposed target classiﬁer is based on the weighted
Rademacher complexity measure of a class of functions or hypotheses, deﬁned over a weighted
sample space [17, 18]. The Rademacher complexity measures the ability of a class of functions to
ﬁt noise. The empirical Rademacher complexity is data-dependent and can be measured from ﬁnite
samples. It can lead to tighter bounds than those based on other complexity measures such as the
VC-dimension. Theoretical analysis of domain adaptation has been studied in [19, 20]. In [19], the
authors provided the generalization bound based on the VC dimension for both single-source and
multi-source domain adaptation. The results were extended in [20] to a broader range of prediction
problems based on the Rademacher complexity; however only the single-source case was analyzed
in [20]. We extend the analysis in [19, 20] to provide the generalization bound for our proposed
two-stage framework based on the weighted Rademacher complexity; our generalization bound is
tighter than the previous ones in the multi-source case. Our theoretical analysis also reveals the
key properties of our generalization bound in terms of a differential weight µ between the weighted
source and target samples.
We have performed extensive experiments using three real-world datasets including 20 Newsgroups,
Sentiment Analysis data and one dataset of multi-dimensional feature vectors extracted from Surface
Electromyigram (SEMG) signals from eight subjects. SEMG signals are recorded using surface
electrodes, from the muscle of a subject, during a submaximal repetitive gripping activity, to detect
stages of fatigue. Our empirical results demonstrate superior performance of the proposed approach
over the existing state-of-the-art domain adaptation methods; our results also reveal the effect of the
differential weight µ on the target classiﬁer performance.

2

−2024681012024681012D1: Source Domain 1(a)−2024681012024681012D2: Source Domain 2(b)−2024681012024681012Target Domain(c)A5A6A4A3A2A12 Proposed Approach
We consider the following multi-source domain adaptation setting. There are k auxiliary source
i=1 , s = 1, 2, · · · k ,
i )|ns
domains. Each source domain is associated with a sample set Ds = (xs
i , ys
where xs
i is the i-th feature vector, ys
i is the corresponding class label, ns is the sample size of the
(cid:83) DT
s-th source domain, and k is the total number of source domains. The target domain consists of
i )|nl
i |nu
i=1 . Here
i=1 and optionally a few labeled data DT
plenty of unlabeled data DT
l = (xT
i , yT
u = xT
nu and nl are the numbers of unlabeled and labeled data, respectively. Denote DT = DT
u and
l
nT = nl + nu . The goal is to build a classiﬁer for the target domain data using the source domain
data and a few labeled target domain data, if available.
The proposed approach consists of two stages. In the ﬁrst stage, we compute the weights of source
domain data based on the marginal probability difference; in the second stage, we compute the
weights of source domains based on the conditional probability difference. A target domain classiﬁer
is learned on these re-weighted data.

2.1 Re-weighting data samples based on marginal probability differences

The difference between the means of two distributions after mapping onto a reproducing kernel
Hilbert space, called Maximum Mean Discrepancy, has been shown to be an effective measure of
the differences in their marginal probability distributions [15]. We use this measure to compute the
(cid:13)(cid:13)(cid:13)(cid:13)(cid:13) 1
(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)2
ns(cid:88)
nT(cid:88)
weights αs
i ’s of the s-th source domain data by solving the following optimization problem [6]:
Φ(xT
i )
ns
i=1
i=1
H
i ≥ 0
s.t. αs
where Φ(x) is a feature map onto a reproducing kernel Hilbert space H [21], ns is the number of
samples in the s-th source domain, nT is the number of samples in the target domain, and αs is the
ns dimensional weight vector. The minimization problem is a standard quadratic problem and can
be solved by applying many existing solvers.

i ) − 1
i Φ(xs
αs
nT

min
αs

(1)

2.2 Re-weighting Sources based on Conditional probability differences

In the second stage the proposed framework modulates the αs weights of a source domain s obtained
on the basis of marginal probability differences in the ﬁrst stage, with another weighting factor given
by β s . The weight β s reﬂects the similarity of a particular source domain s to the target domain
with respect to conditional probability distributions.
Next, we show how to estimate the weights β s . For each of the k source domains, a hypothesis
hs : X → Y is learned on the αs re-weighted source data samples. This ensures that the hypothesis
is learned on source data samples with similar marginal probability distributions. These k source
i |nu
domain hypotheses are used to predict the unlabeled target domain data DT
i=1 . Let H S
u = xT
i =
i · · · hk
i ] be the 1 × k vector of predicted labels of k source domain hypotheses for the i-th sample
[h1
of target domain data. Let β = [β 1 · · · β k ](cid:48) be the k × 1 weight vector, where β s is the weight
corresponding to the s-th source hypothesis. The estimation of the weight for each source domain
hypothesis hs is based on the smoothness assumption on the conditional probability distribution
of the target domain data [16]; speciﬁcally we aim to ﬁnd the optimal weights by minimizing the
nu(cid:88)
difference in predicted labels between two nearby points in the target domain as follows.
i β − H S
(H S
j β )2Wij
min
e=1,β≥0
β :β
i,j=1
where H S is an n × k matrix with each row of H S given by H S
i β and H S
i as deﬁned above, H S
j β
are the predicted labels for the i-th and j -th samples of target domain data obtained by following
a β weighted ensemble methodology over all k sources, and Wij is the similarity between the two
target domain data samples. We can rewrite the minimization problem as follows:
(cid:48)
H S (cid:48)

(2)

β

(3)

LuH S β

(cid:48)

(cid:48)

min
e=1,β≥0

β :β

3

is the diagonal matrix given by Dii = (cid:80)n
u , given by Lu = D − W ,
where Lu is the graph Laplacian associated with the target domain data DT
where W is the similarity matrix deﬁning edge weights between the data samples in DT
u , and D
j=1 Wij . The minimization problem in (3) is a standard
quadratic problem (QP) and can be solved efﬁciently by applying many existing solvers.
To illustrate the proposed two-stage framework, we demonstrate the effect of re-weighting data
samples in source domains D1 and D2 of the toy dataset (shown in Figure 1), based on the computed
weights, in the supplemental material.

2.3 Learning the Target Classiﬁer

The target classiﬁer is learned based on the re-weighted source data and a few labeled target domain
data (if available). We also incorporate an additional weighting factor µ to provide a differential
weight to the source domain data with respect to the labeled target domain data. Mathematically,
k(cid:88)
ns(cid:88)
nl(cid:88)
the target classiﬁer ˆh is learnt by solving the following optimization problem:
s=1
j=1
i=1

i L(h(xs
i ), ys
αs
i ) +

L(h(xT
j ), yT
j )

ˆh = argmin
h

β s
ns

1
nl

(4)

µ

where nl is the number of labeled data from the target domain.
We refer to the proposed framework as 2-Stage Weighting framework for Multi-Source Domain
Adaptation (2SW-MDA). Algorithm 1 below summarizes the main steps involved in 2SW-MDA.

Algorithm 1 2SW-MDA
1: for s = 1, . . . ,k do
Compute αs by solving (1)
2:
Learn a hypothesis hs on the αs weighted source data
3:
4: end for
5: Form the nu × k prediction matrix H S as in Section 2.2
6: Compute matrices W , D and L using the unlabeled target data DT
u
7: Compute β s by solving (3)
8: Learn the target classiﬁer ˆh by solving (4)

β s
ns

i L(h(xs
i ), fs (xs
αs
i )) +

ˆE S
α,β (h) = µˆα,β (h) + ˆT (h) = µ

3 Theoretical Analysis
For convenience of presentation, we rewrite the empirical joint error function on (α, β )-weighted
nl(cid:88)
ns(cid:88)
k(cid:88)
source domain and the target domain deﬁned in (4) as follows:
s=1
i=1
i=1
i ) and fs is the labeling function for source s, µ > 0, (x0
where ys
i ) are samples from the
i = fs (xs
i ) and f0 is the labeling function for the target domain, and S = (xs
target, y t
i ) include all
i = f0 (x0
samples from the target and source domains. The true (α, β )-weighted error α,β (h) on weighted
m = (cid:80)k
source domain samples is deﬁned analogously. Similarly, we deﬁne E S
α,β (h) as the true joint error
function. For notational simplicity, denote n0 = nl as the number of labeled samples from the target,
s=0 ns as the total number of samples from both source and target, and γ i
i /ns for
s = µβ sαs
s ≥ 1 and γ i
k(cid:88)
ns(cid:88)
s = 1/n for s = 0. Then we can re-write the empirical joint error function in (5) as:
s=0
i=1

L(h(x0
i )) (5)
i ), f0 (x0

i L(h(xs
i ), fs (xs
γ s
i )).

ˆE S
α,β (h) =

1
nl

Next, we bound the difference between the true joint error function E S
α,β (h) and its empirical esti-
mate ˆE S
α,β (h) using the weighted Rademacher complexity measure [17, 18] deﬁned as follows:

4

Deﬁnition 1. (Weighted Rademacher Complexity) Let H be a set of real-valued functions deﬁned
over a set X . Given a sample S ∈ X m , the empirical weighted Rademacher complexity of H is
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) S = (xs
(cid:34)
(cid:35)
| k(cid:88)
ns(cid:88)
deﬁned as follows:
ˆ(cid:60)S (H ) = Eσ
i )|
i σs
i h(xs
γ s
i )
sup
.
h∈H
s=0
i=1
i } are independent uniform random variables
i } where {σs
The expectation is taken over σ = {σs
taking values in {−1, +1}. The weighted Rademacher complexity of a hypothesis set H is deﬁned
(cid:12)(cid:12)(cid:12) |S | = m
(cid:105)
(cid:104) ˆ(cid:60)S (H )
as the expectation of ˆ(cid:60)S (H ) over all samples of size m:
(cid:60)m (H ) = ES
Our main result is summarized in the following lemma, which involves the estimation of the
Rademacher complexity of the following class of functions:
G = {x (cid:55)→ L(h(cid:48) (x), h(x)) : h, h(cid:48) ∈ H}.
Lemma 1. Let H be a family of functions taking values in {−1, +1}. Then, for any δ > 0, with
(cid:118)(cid:117)(cid:117)(cid:116) (cid:16)(cid:80)k
(cid:17)
probability at least 1 − δ , the following holds for h ∈ H:
(cid:80)ns
(cid:12)(cid:12)(cid:12)E S
(cid:12)(cid:12)(cid:12) ≤ IRS (H) +
i=1 (γ s
i )2
α,β (h) − ˆE S
s=0
α,β (h)
.
(cid:118)(cid:117)(cid:117)(cid:116) (cid:16)(cid:80)k
2
(cid:17)
Furthermore, if H has a VC dimension of d, then the following holds with probability at least 1 − δ :
(cid:80)ns
(cid:18)(cid:114)
(cid:19)
(cid:12)(cid:12)(cid:12)E S
(cid:12)(cid:12)(cid:12) ≤
i=1 (γ s
i )2
α,β (h) − ˆE S
s=0
α,β (h)
2
where e is the natural number.

log(2/δ)

log(2/δ)

em
d

2d log

.

+ 1

,

The proof is provided in Section A of the supplemental material.

3.1 Error bound on target domain data

In the previous section we presented an upper bound on the difference between the true joint error
function and its empirical estimate and established its relation to the weighting factors γ s
i . Next we
present our main theoretical result, i.e., an upper bound of the error function on target domain data,
i.e., an upper bound of T (ˆh). We need the following deﬁnition of divergence for our main result:
Deﬁnition 2. For a hypothesis space H, the symmetric difference hypothesis space dH∆H is the set
of hypotheses
g ∈ H∆H ⇔ g(x) = h(x) ⊕ h
(cid:48) ∈ H,
(cid:48)
(x) f or some h, h
where ⊕ is the XOR function. In other words, every hypothesis g ∈ H∆H is the set of disagreements
between two hypotheses in H.
The H∆H-divergence between any two distributions DS and DT is deﬁned as
|P rx(cid:118)DS [h(x) (cid:54)= h(cid:48) (x)] − P rx(cid:118)DT [h(x) (cid:54)= h(cid:48) (x)]| .
dH∆H (DS , DT )) = 2 sup
h,h(cid:48)∈H
Theorem 1. Let ˆh ∈ H be an empirical minimizer of the joint error function on similarity weighted
source domain and the target domain:
ˆEα,β (h) ≡ µˆα,β (h) + ˆT (h)
ˆh = arg min
h∈H
for ﬁxed weights µ, α, and β and let h∗
(cid:118)(cid:117)(cid:117)(cid:116) (cid:16)(cid:80)k
T = minh∈H T (h) be a target error minimizer. Then for any
(cid:17)
δ ∈ (0, 1), the following holds with probability at least 1 − δ :
(cid:80)ns
2(cid:60)S (H )
i=1 (γ s
i )2
T (ˆh) ≤ T (h∗
2
s=0
T ) +
1 + µ
1 + µ
2
µ
(2λα,β + dH∆H (Dα,β , DT )) ,
1 + µ

log(2/δ)

(6)

+

+

5

T (ˆh) ≤ T (h∗
T ) +


(cid:118)(cid:117)(cid:117)(cid:116) (cid:16)(cid:80)k
(cid:17)
if H has a VC dimension of d, then the following holds with probability at least 1 − δ :
(cid:80)ns
(cid:18)(cid:114)
i=1 (γ s
i )2
s=0
2d log
2
µ
(2λα,β + dH∆H (Dα,β , DT )) ,
(7)
+
1 + µ
where λα,β = minh∈H{T (h) + α,β (h)}, and dH∆H (Dα,β , DT )) is the symmetric difference hy-
pothesis space for (α, β )-weighted source and target domain data.

(cid:19)

2
1 + µ

log(2/δ)

em
d

+ 1

The proof as well as a comparison with the result in [19] is provided in the supplemental material.
We observe that µ and the divergence between the weighted source and target data play signiﬁcant
roles in the generalization bound. Our proposed two-stage weighting scheme aims to reduce the
divergence. Next, we analyze the effect of µ. When µ = 0, the bound reduces to the generalization
bound using the nl training samples in the target domain only. As µ increases, the effect of the source
domain data increases. Speciﬁcally, when µ is larger than a certain value, for the bound in (7), as µ
increases, the second term will reduce, while the last term capturing the divergence will increase. In
the extreme case when µ = ∞, the second term in (7) can be shown to be the generalization bound
using the weighted samples in the source domain only (the target data will not be effective in this
case), and the last term equals to 2λα,β + dH∆H (Dα,β , DT ). Thus, effective transfer is possible in
this case only if the divergence is small. We also observed in our experiments that the target domain
error of the learned joint hypothesis follows a bell shaped curve; it has a different optimal point for
each dataset under certain similarity and divergence measures.

4 Empirical evaluations

Datasets. We evaluate the proposed 2SW-MDA method on three real-world datasets and the
toy data shown in Figure 1. The toy dataset is generated using a mixture of Gaussian distribu-
tions. It has two classes and three domains, as shown in Figure 1. The two source domains D1
and D2 were created to have both conditional and marginal probability differences with the target
domain data so as to provide an ideal testbed for the proposed domain adaptation methodology.
The three real-world datasets used are 20 Newsgroups1 , Sentiment Analysis2 and another dataset
of multi-dimensional feature vectors extracted from SEMG (Surface electromyogram) signals. The
20 Newsgroups dataset is a collection of approximately 20,000 newsgroup documents, partitioned
(nearly) evenly across 20 different categories. We represented each document as a binary vector
of the 100 most discriminating words determined by Weka’s info-gain ﬁlter [22]. Out of the 20
categories, we used 13 categories, to form the source and target domains. For each of these cat-
egories the negative class was formed by a random mixture of the rest of the seven categories, as
suggested in [23]. The details of the 13 categories used can be found in the supplemental material.
The Sentiment Analysis dataset contains positive and negative reviews on four categories (or do-
mains) including kitchen, book, dvd, and electronics. We processed the Sentiment Analysis dataset
to reduce the feature dimension to 200 using a cutoff document frequency of 50.
The SEMG dataset is 12-dimensional time and frequency domain features derieved from Surface
Electromyogram (SEMG) physiological signals. SEMG are biosignals recorded from the muscle
of a subject using surface electrodes to study the muscoskeletal activities of the subject under test.
SEMG signals used in our experiments, are recorded from extensor carpi radialis muscle during a
submaximal repetitive gripping activity, to study different stages of fatigue. Data is collected from
8 subjects. Each subject data forms a domain. There are 4 classes deﬁning various stages of fatigue.
Data from a target subject is classiﬁed using the data from the remaining 7 subjects, which form the
multiple source domains.
Competing Methods. To evaluate the effectiveness of our approach we compare 2SW-MDA with a
baseline method SVM-C as well as with ﬁve state-of-the-art domain adaptation methods. In SVM-C,
1Available at http://www.ai.mit.edu/(cid:118)jrennie/20Newsgroups/
2Available at http://www.cs.jhu.edu/(cid:118)mdredze/

6

the training data comprises of data from all source domains (12 for 20 Newsgroups data) and the test
data is from the remaining one domain as indicated in the ﬁrst column of the results in Table 1. The
recently proposed multi-source domain adaptation methods used for comparison include Locally
Weighted Ensemble (LWE) [14] and Domain Adaptation Machine (DAM) [13]. To evaluate the
effectiveness of multi-source domain adaption, we also compared with three other state-of-the-art
single-source domain adaptation methods, including Kernel Mean Matching (KMM) [6], Transfer
Component Analysis (TCA) [11] and Kernel Ensemble (KE) [24].
Experimental Setup. Recall that one of the appealing features of the proposed method is that
it requires very few or no labeled target domain data. In our experiments, we used only 1 labeled
sample per class from the target domain. The results of the proposed 2SW-MDA method are based
on µ = 1 (see Figure 2 for results on varying µ). Each experiment was repeated 10 times with
random selections of the labeled data. For each experiment, the category shown in ﬁrst column of
Table 1 was used as the target domain and the rest of the categories as the source domains. Different
instances of the 20 Newsgroups categories are different random samples of 100 data samples se-
lected from the total 500 data samples in the dataset. Different instances of SEMG dataset are data
belonging to different subjects used as target data. Details about the parameter settings are included
in the supplemental material.

Dataset

talk.politics.mideast

talk.politics.misc

comp.sys.ibm.pc.hardware

rec.sport.baseball

kitchen
electronics
book
dvd

SEMG- 8 subjects

Toy data

DAM 2SW-MDA
SVM-C
TCA
KMM
KE
LWE
73.49%
46.00% 50.66% 49.01% 45.78% 58.66% 52.03%
65.06%
49.33% 49.39% 53.48% 39.75% 56.00% 52.00%
62.65%
49.33% 50.27% 54.67% 43.37% 52.04% 51.81%
63.67%
48.83% 53.62% 46.77% 62.32% 55.90% 53.22%
48.22% 51.12% 48.39% 59.42% 53.23% 54.12%
60.87%
68.12%
48.31% 50.72% 55.01% 59.07% 54.83% 54.12%
62.92%
48.42% 51.25% 49.50% 50.56% 61.25% 52.50%
60.67%
47.44% 51.44% 49.44% 59.55% 57.50% 52.50%
64.04%
45.93% 49.88% 48.00% 58.43% 59.75% 57.80%
56.25% 61.51% 47.50% 61.79% 61.75% 61.25%
79.78%
60.22%
58.75% 50.09% 51.25% 64.04% 57.75% 53.75%
61.24%
56.35% 59.26% 56.25% 58.43% 57.83% 55.05%
70.55%
35.55% 40.12% 49.38% 64.04% 64.10% 58.61%
59.44%
35.95% 42.66% 48.38% 65.55% 54.20% 52.61%
59.47%
37.77% 40.12% 49.38% 58.88% 55.01% 54.10%
36.01% 49.44% 48.77% 50.00% 50.00% 50.61%
51.11%
83.03%
70.76% 67.44% 63.55% 64.94% 66.35% 74.83%
87.96%
43.69% 77.54% 74.62% 63.63% 59.94% 81.36%
88.96%
50.11% 75.55% 62.50% 64.06% 56.78% 74.77%
88.49%
59.65% 81.22% 69.35% 52.68% 73.38% 80.63%
86.14%
40.37% 52.48% 65.61% 49.77% 57.48% 76.74%
59.21% 65.77% 83.92% 70.62% 76.92% 59.21%
87.10%
87.08%
47.13% 60.32% 77.97% 51.13% 55.64% 74.27%
93.01%
69.85% 72.81% 79.48% 67.24% 42.79% 84.55%
60.05% 75.63% 81.40% 68.01% 64.97% 84.27%
98.54%

Table 1: Comparison of different methods on three real-world and one toy datasets in terms of
classiﬁcation accuracies (%).

Comparative Studies. Table 1 shows the classiﬁcation accuracies of different methods on the real-
world and the toy datasets. We observe that SVM-C performs poorly for all cases. This may be
attributed to the distribution difference among the multiple source and target domains. We observe
that 20 Newsgroups and Sentiment Analysis datasets have predominantly marginal probability dif-
ferences. In other words, the frequency of a particular word varies from one category of documents
to another. In contrary physiological signals, such as SEMG are predominantly different in con-
ditional probability distributions due to the high subject based variability in the power spectrum
of these signals and their variations as fatigue sets in [25, 26]. We also observe that the proposed
2SW-MDA method outperforms other domain adaptation methods and achieves higher classiﬁcation
accuracies in most cases, specially for the SEMG dataset. The accuracies of an SVM classiﬁer, on
the toy dataset, when learned only on the source domains D1, D2 individually and on the combined
source domains, are 64.08% and 71.84% and 60.05% respectively, while 2SW-MDA achieves an
accuracy of 98.54%. More results are provided in the supplemental material.
It is interesting to note that instance re-weighting method KMM and feature mapping based method
TCA, which address marginal probability differences between the source and target domains per-

7

form better than LWE and KE for both 20 Newsgroups and Sentiment Analysis data. They also
perform better than DAM, a multi-source domain adaptation method, based on marginal probability
based weighted hypotheses combination. It is worthwhile to note that LWE is based on conditional
probability differences and KE tries to address both differences. Thus, it is not surprising that LWE
and KE perform better than KMM and TCA for the SEMG dataset, which is predominantly differ-
ent in conditional probability distributions. DAM too performs better for SEMG signals. However
the proposed 2SW-MDA method, which addresses both marginal and conditional probability differ-
ences outperforms all the other methods in most cases. Our experiments verify the effectiveness of
the proposed two-stage framework.
Parameter Sensitivity Studies. In this exper-
iment, we study the effect of µ on the classiﬁca-
tion performance. Figure 2 shows the variation
in classiﬁcation accuracies for some cases pre-
sented in Table 1, with varying µ over a range
[0 0.001 0.01 0.1 0.3 0.5 1 100 1000]. The x-
axis of the ﬁgures are in logarithmic scale. The
results for the toy data are included in supple-
mental material. We can observe from the ﬁg-
ure that in most cases, the accuracy values in-
crease as µ increases from 0 to an optimal value
and decreases when µ further increases. When
µ = 0 the target classiﬁer is learned only on the
few labeled data from the target domain. As µ
increases the transfer of knowledge due to the
presence of additional weighted source data has
a positive impact leading to increase in classiﬁ-
cation accuracies in the target domain. We also
observe that after a certain value of µ the classiﬁer accuracies drop, due to the distribution differ-
ences between the source and target domains. These experimental results are consistent with the
theoretical results established in this paper.

Figure 2: Performance of the proposed 2SW-
MDA method on 20 Newsgroups dataset and Sen-
timent Analysis dataset with varying µ.

5 Conclusion
Domain adaptation is an important problem that arises in a variety of modern applications where
limited or no labeled data is available for a target application. We presented here a novel multi-
source domain adaptation framework. The proposed framework computes the weights for the source
domain data using a two-step procedure in order to reduce both marginal and conditional probability
distribution differences between the source and target domain. We also presented a theoretical error
bound on the target classiﬁer learned on re-weighted data samples from multiple sources. Empirical
comparisons with existing state-of-the-art domain adaptation methods demonstrate the effectiveness
of the proposed approach. As a part of the future work we plan to extend the proposed multi-source
framework to applications involving other types of physiological signals for developing generalized
models across subjects for emotion and health monitoring [27, 28]. We would also like to extend
our framework to video and speech based applications, which are commonly affected by distribution
differences [3].

Acknowledgements

This research is sponsored by NSF IIS-0953662, CCF-1025177, and ONR N00014-11-1-0108.

References
[1] S.J. Pan and Q. Yang. A survey on transfer learning. IEEE Transactions on Knowledge and Data Engi-
neering, 2009.
[2] H. Daum III. Frustratingly easy domain adaptation. In ACL, 2007.
[3] L. Duan, I.W. Tsang, D. Xu, and S.J. Maybank. Domain transfer svm for video concept detection. In
CVPR, 2009.

8

−8−6−4−20246845505560657075log uaccuracy(%)  talk.politics.misccomp.sys.ibm.pc.hardwaretalk.politics.mideastdvdbookelectronics[4] J. Blitzer, M. Dredze, and F. Pereira. Biographies, bollywood, boom-boxes and blenders: Domain adap-
tation for sentiment classiﬁcation. In ACL, 2007.
[5] S.J. Pan, J.T. Kwok, and Q. Yang. Transfer learning via dimensionality reduction. In AAAI 08.
[6] J. Huang, A.J. Smola, A. Gretton, K.M. Borgwardt, and B. Scholkopf. Correcting sample selection bias
by unlabeled data. In NIPS, volume 19, page 601, 2007.
[7] H. Shimodaira.
Improving predictive inference under covariate shift by weighting the log-likelihood
function. In JSPI, 2000.
[8] S. Bickel, M. Br ¨uckner, and T. Scheffer. Discriminative learning under covariate shift. In JMLR, 2009.
[9] C. Cortes, Y. Mansour, and M. Mohri. Learning bounds for importance weighing. In NIPS, 2010.
[10] M. Sugiyama, S. Nakajima, H. Kashima, P.V. Buenau, and M. Kawanabe. Direct importance estimation
with model selection and its application to covariate shift adaptation. In NIPS, 2008.
[11] S.J. Pan, I.W. Tsang, J.T. Kwok, and Q. Yang. Domain adaptation via transfer component analysis. In
IJCAI, 2009.
[12] Y. Mansour, M. Mohri, and A. Rostamizadeh. Domain adaptation with multiple sources. In NIPS, 2009.
[13] L. Duan, I.W. Tsang, D. Xu, and T. Chua. Domain adaptation from multiple sources via auxiliary classi-
ﬁers. In ICML, pages 289–296, 2009.
[14] J. Gao, W. Fan, J. Jiang, and J. Han. Knowledge transfer via multiple model local structure mapping. In
KDD, pages 283–291, 2008.
[15] K.M. Borgwardt, A. Gretton, M.J. Rasch, H.P. Kriegel, B. Scholkopf, and A.J. Smola. Integrating struc-
tured biological data by kernel maximum mean discrepancy. In Bioinformatics, volume 22, pages 49–57,
2006.
[16] R. Chattopadhyay, J. Ye, S. Panchanathan, W. Fan, and I. Davidson. Multi-source domain adaptation and
its application to early detection of fatigue. In KDD, 2011.
[17] P.L. Bartlett and S. Mendelson. Rademacher and gaussian complexities: Risk bounds and structural
results. JMLR, 3:463–482, 2002.
[18] V. Koltchinskii. Rademacher penalties and structural risk minimization. IEEE Transactions on Informa-
tion Theory, 47(5):1902–1914, 2001.
[19] S. Ben-David, J. Blitzer, K. Crammer, A. Kulesza, F. Pereira, and J.W. Vaughan. A theory of learning
from different domains. Journal of Mach Learn, 79:151–175, 2010.
[20] Y. Mansour, M. Mohri, and A. Rostamizadeh. Domain adaptation: Learning bounds and algorithms.
Computing Research Repository, abs/0902.3430, 2009.
[21] I. Steinwart. On the inﬂuence of the kernel on the consistency of support vector machines. In JMLR,
volume 2, page 93, 2002.
[22] I.H. Witten and E. Frank. In Data Mining: Practical Machine Learning Tools with Java Implementations,
San Francisco, CA, 2000. Morgan Kaufmann.
[23] E. Eaton and M. desJardins. Set-based boosting for instance-level transfer. In IEEE International Con-
ference on Data Mining Workshops, 2009.
[24] E. Zhong, W. Fan, J. Peng, K. Zhang, J. Ren, D. Turaga, and O. Verscheure. Cross domain distribution
adaptation via kernel mapping. In KDD, Paris, France, 2009. ACM.
[25] P. Contessa, A. Adam, and C.J. De Luca. Motor unit control and force ﬂuctuation during fatigue. Journal
of Applied Physiology, April 2009.
[26] B. Gerdle, B. Larsson, and S. Karlsson. Criterion validation of surface EMG variables as fatigue indicators
using peak torque: a study of repetitive maximum isokinetic knee extensions. Journal of Electromyogra-
phy and Kinesiology, 10(4):225–232, August 2000.
[27] E. leon, G. Clarke, V. Callaghan, and F. Sepulveda. A user independent real time emotion recognition
system for software agents in domestic environment. In Engineering Application of Artiﬁcial Intelligence,
April 2007.
[28] J. Kim and E. Andre. Emotion recognition based on physiological changes in music listening. In Pattern
Analysis and Machine Intelligence, December 2008.
[29] C. McDiarmid. On the method of bounded differences., volume 5. Cambridge University Press, Cam-
bridge, 1989.
[30] S. Kakade and A. Tewari. Lecture notes of CMSC 35900: Learning theory, Toyota Technological Institute
at Chicago. Spring 2008.
[31] P. Massart. Some applications of concentration inequalities to statistics. Annales de la Faculte des sciences
de ToulouseSciences de Toulouse, IX(2):245–303, 2000.

9

