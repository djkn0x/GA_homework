P ICOD E S: Learning a Compact Code for
Novel-Category Recognition

Alessandro Bergamo, Lorenzo Torresani
Dartmouth College
Hanover, NH, U.S.A.
{aleb, lorenzo}@cs.dartmouth.edu

Andrew Fitzgibbon
Microsoft Research
Cambridge, United Kingdom
awf@microsoft.com

Abstract

We introduce P ICOD E S: a very compact image descriptor which nevertheless al-
lows high performance on object category recognition. In particular, we address
novel-category recognition: the task of deﬁning indexing structures and image
representations which enable a large collection of images to be searched for an
object category that was not known when the index was built. Instead, the train-
ing images deﬁning the category are supplied at query time. We explicitly learn
descriptors of a given length (from as small as 16 bytes per image) which have
good object-recognition performance. In contrast to previous work in the domain
of object recognition, we do not choose an arbitrary intermediate representation,
but explicitly learn short codes. In contrast to previous approaches to learn com-
pact codes, we optimize explicitly for (an upper bound on) classiﬁcation perfor-
mance. Optimization directly for binary features is difﬁcult and nonconvex, but
we present an alternation scheme and convex upper bound which demonstrate ex-
cellent performance in practice. P ICOD E S of 256 bytes match the accuracy of the
current best known classiﬁer for the Caltech256 benchmark, but they decrease the
database storage size by a factor of 100 and speed-up the training and testing of
novel classes by orders of magnitude.

1 Introduction

In this work we consider the problem of efﬁcient object-class recognition in large image collections.
We are speciﬁcally interested in scenarios where the classes to be recognized are not known in
advance. The motivating application is “object-class search by example” where a user provides
at query time a small set of training images deﬁning an arbitrary novel category and the system
must retrieve from a large database images belonging to this class. This application scenario poses
challenging requirements on the system design: the object classiﬁer must be learned efﬁciently at
query time from few examples; recognition must have low computational cost with respect to the
database size; ﬁnally, compact image descriptors must be used to allow storage of large collections
in memory rather than on disk for additional efﬁciency.

Traditional object categorization methods do not meet these requirements as they typically use non-
linear kernels on high-dimensional descriptors, which renders them computationally expensive to
train and test, and causes them to occupy large amounts of storage. For example, the LP-β multiple
kernel combiner [11] achieves state-of-the-art accuracy on several categorization benchmarks but it
requires over 23 Kbytes to represent each image and it uses 39 feature-speciﬁc nonlinear kernels.
This recognition model is impractical for our application because it would require costly query-time
kernel evaluations for each image in the database since the training set varies with every new query
and thus pre-calculation of kernel distances is not possible.

We propose to address these storage and efﬁciency requirements by learning a compact binary im-
age representation, called P ICOD E S1 , optimized to yield good categorization accuracy with linear

1Which we think of as “Picture Codes” or “Pico-Descriptors”, or (with Greek pronunciation) π -codes

1

Figure 1: Visualization of P ICOD E S. The 128-bit P ICOD E (whose accuracy on Caltech256 is displayed in
ﬁgure 3) is applied to the test data of ILSVRC2010. Six of the 128 bits are illustrated as follows: for bit c,
all images are sorted by non-binarized classiﬁer outputs a⊤
c x and the 10 smallest and largest are presented on
each row. Note that ac is deﬁned only up to sign, so the patterns to which the bits are specialized may appear
in either the “positive” or “negative” columns.

(i.e., efﬁcient) classiﬁers. The binary entries in our image descriptor are thresholded nonlinear pro-
jections of low-level visual features extracted from the image, such as descriptors encoding texture
or the appearance of local image patches. Each non-linear projection can be viewed as implementing
a nonlinear classiﬁer using multiple kernels. The intuition is that we can then use these pre-learned
multiple kernel combiners as a classiﬁcation basis to deﬁne recognition models for arbitrary novel
categories: the ﬁnal classiﬁer for a novel class is obtained by linearly combining the binary outputs
of the basis classiﬁers, which we can pre-compute for every image in the database, thus enabling
efﬁcient novel object-class recognition even in large datasets.

The search for compact codes for images has been the subject of much recent work, which we
loosely divide into “designed” and “learned” codes. In the former category we include min-hash [6],
VLAD [14], and attributes [10, 18, 17] which are fully-supervised classiﬁers trained to recognize
certain visual properties in the image. A related idea is the representation of images in terms of
distances to basis classes. This has been previously investigated as a way to deﬁne image similar-
ities [30], to perform video search [12], or to enable natural scene recognition and retrieval [29].
Torresani et al. [27] deﬁne a compact image code as a bitvector, the entries of which are the out-
puts of a large set of weakly-trained basis classiﬁers (“classemes”) evaluated on the image. Simple
linear classiﬁers trained on classeme vectors produce near state-of-the-art categorization accuracy.
Li et al. [19] use the localized outputs of object detectors as an image representation. The advan-
tage of this representation is that it encodes spatial information; furthermore, object detectors are
more robust to clutter and uninformative background than classiﬁers evaluated on the entire image.
These prior methods work under the assumption that an “overcomplete” representation for classiﬁ-
cation can be obtained by pre-learning classiﬁers for a large number of basis classes, some of which
will be related to those encountered at test-time. Such high-dimensional representations are then
compressed down using quantization, dimensionality reduction or feature selection methods.

The second strand of related work is the learning of compact codes for images [31, 26, 24, 15,
22, 8] where binary image codes are learned such that the Hamming distance between codewords
approximates a kernelized distance between image descriptors, most typically GIST. Autoencoder
learning [23], on the other hand, produces a compact code which has good image reconstruction
properties, but again is not specialized for category recognition.

All the above descriptors can produce very compact codes, but few (excepting [27, 19]) have been
shown to be effective at category-level recognition beyond simpliﬁed problems such as Caltech-
20 [2] or Caltech-101 [14, 16]. In contrast, we consider Caltech-256 a baseline competence, and
also test compact codes on a large-scale class retrieval task using ImageNet [7].

The goal of this paper then is to learn a compact binary code (as short as 128 bits) which has
good object-category recognition accuracy. In contrast to previous learning approaches, our training
objective is a direct approximation to this goal; while in contrast to previous “designed” descriptors,
we learn abstract categories (see ﬁgure 1) aimed at optimizing classiﬁcation rather than an arbitrary
predeﬁned set of attributes or classemes, and thus achieve increased accuracy for a given code length.

2

