Estimating time-varying input signals and ion
channel states from a single voltage trace of a neuron

Ryota Kobayashi∗
Department of Human and Computer Intelligence, Ritsumeikan University
Siga 525-8577, Japan
kobayashi@cns.ci.ritsumei.ac.jp

Yasuhiro Tsubo
Laboratory for Neural Circuit Theory, Brain Science Institute, RIKEN
2-1 Hirosawa Wako, Saitama 351-0198, Japan
yasuhirotsubo@riken.jp

Petr Lansky
Institute of Physiology, Academy of Sciences of the Czech Republic
Videnska 1083, 142 20 Prague 4, Czech Republic
lansky@biomed.cas.cz

Shigeru Shinomoto
Department of Physics, Kyoto University
Kyoto 606-8502, Japan
shinomoto@scphys.kyoto-u.ac.jp

Abstract

State-of-the-art statistical methods in neuroscience have enabled us to ﬁt math-
ematical models to experimental data and subsequently to infer the dynamics of
hidden parameters underlying the observable phenomena. Here, we develop a
Bayesian method for inferring the time-varying mean and variance of the synaptic
input, along with the dynamics of each ion channel from a single voltage trace of a
neuron. An estimation problem may be formulated on the basis of the state-space
model with prior distributions that penalize large ﬂuctuations in these parameters.
After optimizing the hyperparameters by maximizing the marginal likelihood, the
state-space model provides the time-varying parameters of the input signals and
the ion channel states. The proposed method is tested not only on the simulated
data from the Hodgkin−Huxley type models but also on experimental data ob-
tained from a cortical slice in vitro.

1 Introduction

Owing to the great advancements in measurement technology, a huge amount of data is generated
in the ﬁeld of science, engineering, and medicine, and accordingly, there is an increasing demand
for estimating the hidden states underlying the observed signals. Neurons transmit information by
transforming synaptic inputs into action potentials; therefore, it is essential to investigate the dynam-
ics of the synaptic inputs to understand the mechanism of the information processing in neuronal
systems. Here we propose a method to deduce the dynamics from experimental data.
Webpage: http://www.ritsumei.ac.jp/∼r-koba84/index.html
∗

1

Cortical neurons in vivo receive synaptic bombardments from thousands of neurons, which cause the
membrane voltage to ﬂuctuate irregularly. As each synaptic input is small and the synaptic input rate
is high, the total input can be characterized only with its mean and variance, as in the mathematical
description of Brownian motion of a small particle suspended in a ﬂuid. Given the information of
the mean and variance of the synaptic input, it is possible to estimate the underlying excitatory and
inhibitory ﬁring rates from respective populations of neurons.
The membrane voltage ﬂuctuations in a neuron are caused not only by the synaptic input but also
by the hidden dynamics of ionic channels. These dynamics can be described by conductance-based
models, including the Hodgkin−Huxley model. Many studies have been reported on the dynamics
of ionic channels and their impact on neural coding properties [1].
There have been attempts to decode a voltage trace in terms of input parameters; the maximum like-
lihood estimator for current inputs was derived under an assumption of linear leaky integration [2, 3].
Empirical attempts were made to infer conductance inputs by ﬁtting an approximate distribution of
the membrane voltage to the experimental data [4, 5]. A linear regression method was proposed to
infer the maximal ionic conductances and single synaptic inputs in the dendrites [6]. In all studies,
these input parameters were assumed to be constant in time. In practice, however, such assumption
of the constancy of input parameters is too strong simpliﬁcation for the neuronal ﬁring [7, 8].
In this paper, we propose a method for the simultaneous identiﬁcation of the time-varying input
parameters and of the ion-channels dynamics from a single voltage trajectory. The problem is ill-
posed, in the sense that the set of parameters giving rise to a particular voltage trace cannot be
uniquely determined. However, the problem may be formulated as a statistical problem of estimating
the hidden state using a state-space model and then it is solvable. We verify the proposed method
by applying it not only to numerical data obtained from the Hodgkin−Huxley type models but also
to the biological data obtained in in vitro experiment.

2 Model

2.1 Conductance-based model

∑
We start from the conductance-based neuron model [1]:
= −¯gleak (V − Eleak ) −
dV
Jion (V , ⃗w) + Jsyn (t),
dt
ion
where, ¯gleak =: gleak /Cm , Jion =: Iion /Cm , Jsyn (t) := Isyn (t)/Cm ,
V is the membrane voltage, ¯gleak is the normalized leak conductance, Eleak is the reversal potential,
Jion are the voltage-dependent ionic inputs, ⃗w := (w1 , w2 , · · · , wd ) are the gating variables that
characterize the states of ion channels, Jsyn is a synaptic input, Cm is the membrane capacitance,
Iion are the voltage-dependent ionic currents and Isyn (t) is a synaptic input current. The ionic
inputs Jion are a nonlinear function of V and ⃗w . Each gating variable wi (i = 1, · · · , d) follows the
Langevin equation [9]:

(1)

= αi (V )(1 − wi ) − βi (V )wi + si ξi (t),
dwi
(2)
dt
where αi (V ), βi (V ) are nonlinear functions of the voltage, si is the standard deviation of the channel
noise, and ξi (t) is an independent Gaussian white noise with zero mean and unit variance. The
synaptic input Jsyn (t) is the sum of the synaptic inputs from a large number of presynaptic neurons.
If each synaptic input is weak and the synaptic time constants are small, we can adopt a diffusion
approximation [10],

Jsyn (t) = µ(t) + σ(t)χ(t),
(3)
where µ(t), σ(t) are the instantaneous mean and standard deviation of the synaptic input, and χ(t)
is Gaussian white noise with zero mean and unit variance. The components µ(t) and σ2 (t) are
considered to be the input signals to a neuron.

2.2 Estimation Problem
The problem is to ﬁnd the parameters of model (1-3) from a single voltage trace {V (t)}. There are
three kinds of parameters in the model. The ﬁrst kind is the input signals {µ(t), σ2 (t)}. The second

2

kind is the gating variables { ⃗w(t)} that characterize the activity of the ionic channels. The remaining
parameters are the intrinsic parameters of a neuron, such as the standard deviation of the channel
noise, the functional form of voltage-dependent ionic inputs, and that of the rate constants. Some
of these parameters, i.e., Jion (V , ⃗w), αi (V ), βi (V ), ¯gleak and Eleak are measurable by additional
experiments. After determining such intrinsic parameters of the third group by separate experiments,
we estimate parameters of the ﬁrst and second group from a single voltage trace.

3 Method

Because of the ill-posedness of the estimation problem, we cannot determine the input signals from
a voltage trace alone. To overcome this, we introduce random-walk-type priors for the input signals.
Then, we determine hyperparameters using the EM algorithm. Finally, we evaluate the Bayesian
estimate for the input signals and the ion channel states with the Kalman ﬁlter and smoothing algo-
rithm. Figure 1 is a schematic of the estimation method.

3.1 Priors for Estimating Input Parameters
Let us assume, for the sake of simplicity, that the voltage is sampled at N equidistant steps δ t,
{
}
∑
denoting by Vj the observed voltage at time j δ t. To apply the Bayesian approach, the conductance
√
based model (1, 3) is modiﬁed into the discretized form:
−¯gleak (Vj − Eleak ) −
Vj+1 = Vj +
Jion (Vj , ⃗wj ) + Mj
δ t +
(4)
Sj δ tηj ,
ion
where {Mj , Sj } are random functions of time, ηj is a standard Gaussian random variable. It is
not possible to infer a large set of parameters {Mj , Sj } from a single voltage trace {Vj } alone,
because the number of parameters overwhelms the number of data points. To resolve it, we introduce
random-walk-type priors, i.e. we assume that the random functions are sufﬁciently smooth to satisfy
the following conditions [11]:
P [Mj+1 |Mj = m] ∼ N (m, γ 2
M δ t),
(5)
P [Sj+1 |Sj = s] ∼ N (s, γ 2
S δ t),
(6)
where γM and γS are hyperparameters that regulate the smoothness of M (t) and S (t), respectively,
and N (µ, σ2 ) represents the Gaussian distribution with mean µ and variance σ2 .

3.2 Formulation as a State Space model

√

√

√

δ t, γS

δ t, s1

δ t, s2

The model described in the previous sections could be represented as the state-space model, in which
⃗xj ≡ (Mj , Sj , ⃗wj ) are the (d + 2)-dimensional states, and Zj ≡ Vj+1 − Vj (j = 1, · · · , N − 1) are
the observations. The kinetic equations (2) and the prior distributions (5, 6) can be rewritten as
⃗xj+1 = Fj ⃗xj + ⃗uj + G⃗ηj ,
√

where
Fj = diag(1, 1, a1;j , a2;j , · · · , ad;j ), G = diag(γM
⃗uj = (0, 0, b1;j , b2;j , · · · , bd;j )T ,
Fj and G are (d + 2) × (d + 2) diagonal matrices, ⃗uj is (d + 2)-dimensional vector, and ⃗ηj is a
(d + 2)-dimensional independent Gaussian random vector with zero mean and unit variance.
ai,j and bi,j is given by
ai,j = 1 − {αi (Vj ) + βi (Vj )}δ t, bi,j = αi (Vj )δ t,
∑
√
The observation equation is obtained from Eq. (4):
Zj = −¯gleak (Vj − Eleak )δ t −
Jion (Vj , ⃗wj )δ t + Mj δ t +
Sj δ tξj ,
ion
where ξj is an independent Gaussian random variable with zero mean and unit variance. In the
estimation problem, only {Vj }N
j=1 are observable. {⃗xj }N
j=1 are the hidden variables because it
cannot be observed in a experiment.

δ t, · · · , sd

δ t),

√

(7)

(8)

3

Figure 1: A schema of the estimation procedure: A conductance-based model neuron [12] is driven
by a ﬂuctuating input of the mean µ(t) and variance σ2 (t) varying in time. The µ(t) (black line) and
the µ(t) ± σ(t) (black dotted lines) are depicted in the second panel from the top. We estimate the
input signals {µ(t), σ2 (t)} and the gating variables {m(t), h(t), n(t), p(t)} from a single voltage
trace (blue line). The estimated results are shown in the bottom panels. The input signals are in the
two panels and the ion channel states are in the right shaded box. Gray dashed lines are the true
values and red lines are their estimates.

3.3 Hyperparameter Optimization

1 , · · · , s2
We determine d + 2 hyperparameters ⃗q := (γ 2
d ) by maximizing the marginal like-
S , s2
M , γ 2
lihood via the EM algorithm [13]. We maximize the likelihood integrated over hidden variables
∫
{⃗xt}N −1
t=1 ,

⃗qML = argmax
⃗q

p(Z1:N −1 |⃗q) = argmax
⃗q

p(Z1:N −1 , ⃗x1:N −1 |⃗q)d⃗x1:N −1 ,

(9)

4

where Z1:N −1 := {Zj }N −1
j=1 , ⃗x1:N −1 := {⃗xj }N −1
j=1 , and d⃗x1:N −1 := ΠN −1
j=1 d⃗xj . The maximization
can be achieved by iteratively maximizing the Q function, the conditional expectation of the log
likelihood:
Q(⃗q |⃗qk ),
⃗qk+1 = argmax
⃗q
where Q(⃗q |⃗qk ) := E [log(P [Z1:N −1 , ⃗x1:N −1 |⃗q ])|Z1:N −1 , ⃗qk ],
⃗qk is the k th iterated estimate of ⃗q , E [X |Y ] is the conditional expectation of X given the value of
Y , and P [X |Y ] is the conditional probability distribution of X given the value of Y .
N −2∑
N −1∑
The Q function can be written as
Q(⃗q |⃗qk ) =
E [log(P [Zj |⃗xj ]) |Z1:N −1 , ⃗qk ] +
j=1
j=1
N −2∑
The (k + 1) th iterated estimate of ⃗q is determined by the conditions for ∂Q/∂ qi = 0:
E [(xi,j+1 − fi,j xi,j − ui,j )2 |Z1:N −1 , ⃗qk ],
j=1

E [log(P [⃗xj+1 |⃗xj , ⃗q ]) |Z1:N −1 , ⃗qk ]. (11)

(12)

(10)

qi,k+1 =

1
(N − 2)δ t

where qi,k+1 is the ith component of the ⃗qk+1 , xi,j is the ith component of ⃗xj , fi,j is the ith diagonal
component of Fj , and ui,j is the ith component of ⃗uj . As the EM algorithm increases the marginal
likelihood at each iteration, the estimate converges to a local maximum. We calculate the conditional
expectations in Eq.(12) using Kalman ﬁlter and smoothing algorithm [11, 14, 15, 16, 17].

3.4 Bayesian estimator for the input signal

After ﬁtting the hyperparameters, we evaluate the Bayesian estimator for the input signals and the
gating variables:
j = E [⃗xj |Z1:N −1 , ⃗q ],
∗
(13)
⃗x
∗
j is the Bayesian estimator for ⃗xj . Using this estimator, we can estimate not only the
where ⃗x
(smoothly) time-varying mean and variance of the synaptic input {µ(t), σ2 (t)}, but also the time
evolution of the gating variables ⃗w(t). We evaluate the estimator (13) using a Kalman ﬁlter and
smoothing algorithm [11, 14, 15, 16, 17].

4 Applications

4.1 Estimating time-varying input signals and ion channel states in a conductance-based
model

To test the accuracy and robustness of our method, we applied the proposed method to simulated
voltage traces. We adopted a Hodgkin−Huxley model with microscopic description of ionic chan-
nels [18], which consists of two ionic inputs Jion (ion ∈ {Na, Kd}): JNa = γNa [m3h1 ](V − ENa )
and JKd = γK [n4 ](V − EK ), where γNa(K) is the conductance of a single sodium (potassium)
ion channel in the open state, [m3h1 ] ([n4 ]) is the number of sodium (potassium) channels that are
open and ENa(K) is the sodium (potassium) reversal potential. There are 8 (5) states in a sodium
(potassium) channel and the state transitions are described by a Markov chain model. Details of this
model can be found in [18].
First, we apply the proposed method to sinusoidally modulated input signals. Figure 2B compares
the time-varying input signals {µ(t), σ2 (t)} with their estimate and Figure 2C compares the open
probability of each ion channel with its estimate. It is observed in this case that the method provides
∑
the accurate estimate. Second, we examine whether the method can also work in the presence
of discontinuity in the input signals. Though discontinuous inputs do not satisfy the smoothness
∑
assumption (5, 6), the method gives accurate estimates (Figure 3A). Third, the estimation method is
j,k δ(t − tk
E ,j )(VE − V (t)) +
applied to conductance input model, which is given by Jsyn (t) = ¯gE
j,k δ(t − tk
I ,j )(VI − V (t)), where the subscript E (I ) means the excitatory (inhibitory) synapse,
¯gI

5

¯gE (I ) is the normalized postsynaptic conductance, VE (I ) is the reversal potential and tk
E (I ),j is the
k th spike time of the j th presynaptic neuron, and δ(t) is the Dirac delta function. It can be seen
from Figure 3B that the method can provide accurate estimate except during action potentials when
the input undergoes a rapid modulation. Fourth, the effect of observation noise on the estimation
accuracy is investigated. We introduce an observation noise in the following manner: Zobs,j =
Zj + σobsηj , where Zobs,j =: Vobs,j+1 − Vobs,j is the observed value, Vobs,j is the recorded voltage
at time step j , σobs is the standard deviation of the observation noise and ηj is an independent
Gaussian random variable with zero mean and unit variance. Mathematically, it is equivalent to
assume the observation noise as an additive Gaussian white noise on the voltage. In such a case, the
estimation method reckons the input variance at the sum of the original input variance σ2 (t) and the
observation noise variance σ2
obs (Figure 3C).
Furthermore, we also tested the present framework in its potential applicability to more compli-
cated conductance-based models, which have slow ionic currents. To observe this, we adopted a
conductance-based model proposed by Pospischil et al. [12] that has three ionic inputs Jion (ion ∈
{Na, Kd, M}): JNa = ¯gNam3h(V − ENa ), JKd = ¯gKdn4 (V − EK ) and JM = ¯gMp(V − EK ),
where {m, h, n, p} are the gating variables, ¯gion represents the normalized ionic conductances and
Eion are the reversal potentials. (See [12] for details.) An example of the estimation result is shown
in Figure 1.

Figure 2: Estimation of input signals and ion channel states from the simulated data: A. Voltage
Trace. B. Estimate of the mean µ and variance σ2 input signals. C. Estimate of the ion channel
states. The time evolution of the open probabilities of sodium (Na) and potassium (K) channels are
shown. The gray dashed lines and red lines represent the true and the estimates, respectively.

4.2 Estimating time-varying input signals and ion channel states in experimental data

We applied the proposed method to experimental data. Randomly ﬂuctuating current, generated by
the sum of the ﬁltered time-dependent Poisson process, was injected to a neuron in the rat motor
cortex and the membrane voltage was recorded intracellularly in vitro. Details of the experimental
procedure can be found in [19, 20]. We adopted the neuron model proposed by Pospischil et
al. [12] for the membrane voltage. After tuning the ionic conductances and kinetic parameters, six
hyperparameters γM ,S and sm,h,n,p were optimized using Eq. (12). For avoiding over-ﬁtting, we set
the upper limit smax = 0.002 for the hyperparameters of the gating variables. The observation noise
obs = 0.66 [(mV)2 /ms].
variance was estimated from data recorded in absence of stimulation: σ2
The variance of the input signal was estimated by subtracting the observation noise variance from
the estimated variance. In this way, the mean and standard deviation (SD) of the input as well as

6

Figure 3: Robustness of the estimation method: A. Constant input with a jump. B. Conductance
input. C. Sinusoidal input with observation noise. Voltage traces used for the estimation and es-
timates of the input signals {µ(t), σ2 (t)} are shown. In A and B, the gray dashed and red lines
represents the true and the estimated input signals, respectively. In C, the blue dotted line repre-
sents the true input variance σ2 (t), the gray dotted line represents the sum of the true input variance
obs = 1.6 [(mV)2 /ms], and the red line represents the
and the true observation noise variance σ2
estimated variance.

the gating variables were estimated. The time-varying mean and SD of the input are compared with
their estimates in Figure 4B. The results suggest that the proposed method is applicable for these
experimental data.

5 Discussion

We have developed a method for estimating not only the time-varying mean and variance of the
synaptic input but also the ion channel states from a single voltage trace of a neuron. It was con-
ﬁrmed that the proposed method is capable of providing accurate estimate by applying it to simu-
lated data. We also tested the general applicability of this method by applying it to experimental
data obtained with current injection to a neuron in cortical slice preparation.
Until now, several attempts have been made to estimate synaptic input from experimental data [2,
4, 5, 8, 21, 22]. The new aspects introduced in this paper are the implementation of the state space
model that allows to estimate the input signals to ﬂuctuate in time and the gating variables that
varies according to the voltage. However, the present method can be implemented under several
simplifying assumptions, whose validity should be veriﬁed.
First, we approximated the synaptic inputs by white (uncorrelated) noise. In practice, the synaptic
inputs are conductance-based and inevitably have the correlation of a few milliseconds. We have
conﬁrmed the applicability of the model to the numerical data generated with conductance input,
and also the experimental data in which temporally correlated current is injected to a neuron. These
results indicate that the white noise assumption in our method robustly applies to the reality.
Second, we constructed the state space method by assuming the smooth ﬂuctuation of the input
signals, or equivalently, by penalizing the rapid ﬂuctuation in the prior distribution. By applying the
present method to the case of stepwise change in the input signals, we realized that the method is
rather robust against an abrupt change.
Third, we also approximated the channel noise by the white noise. We tested our method by applying
it to a more realistic Hodgkin−Huxley type model in which the individual channels are modeled by
a Markov chain [18]. It was conﬁrmed that the present white noise approximation is acceptable for
such realistic models.

7

Figure 4: Estimation of input signals and ion channel states from experimental data. A. Voltage trace
recorded intracellularly in vitro. Fluctuating current, sinusoidally modulated mean and standard
deviation (SD), was injected to the neuron. B. Estimation of the time-varying mean and SD of the
input. The gray dashed and red lines represent the true and the estimates, respectively. C. Estimation
of the ion channels state. The red lines represent the estimates of the gating variables.

Fourth, we ignored the possible nonlinear effects in dendritic conduction such as dendritic spike
and backpropagating action potential. It would be worthwhile to consider augmenting the model by
dividing into multiple compartments as has been done in Huys et al. [6].
Fifth, in analyzing experimental data, we employed ﬁxed functions for the ionic currents and the
rate constants and assumed that some of the intrinsic parameters are known. It may be possible
to infer the maximal ionic conductances using the particle ﬁlter method developed by Huys and
Paninski [23], but their method is not able to identify the ionic currents and the rate constants. In
our examination of biological data, we have explored parameters empirically from current-voltage
data. It would be an important direction of this study to develop the method such that models are
selected solely from the voltage trace.

Acknowledgments

This study was supported by Support Center for Advanced Telecommunications Technology Re-
search, Foundation; Yazaki Memorial Foundation for Science and Technology; and Ritsumeikan
University Research Funding Research Promoting Program “Young Scientists (Start-up) (cid:673), “Gen-
eral Research” to R.K., Grant-in-Aid for Young Scientists (B) from the MEXT Japan (22700323) to
Y.T., Grants-in-Aid for Scientiﬁc Research from the MEXT Japan (20300083, 23115510) to S.S.,
and the Center for Neurosciences LC554, Grant No. AV0Z50110509 and the Grant Agency of the
Czech Republic, project P103/11/0282 to P.L.

References

[1] Koch, C. (1999) Biophysics of Computation: Information Processing in Single Neurons. Ox-
ford University Press.
[2] Lansky, P. (1983) Math. Biosci. 67: 247-260.
[3] Lansky, P. & Ditlevsen S. (2008) Biol. Cybern. 99: 253-262.

8

[4] Rudolph, M., Piwkowska, Z., Badoual, M., Bal, T. & Destexhe, A. (2004) J. Neurophysiol.
91: 2884-2896.
[5] Pospischil, M., Piwkowska, Z., Bal, T. & Destexhe, A. (2009) Neurosci. 158: 545-552.
[6] Huys, Q.J.M., Ahrens, M.B. & Paninski, L. (2006) J. Neurophysiol. 96: 872-890.
[7] Shinomoto, S., Sakai, S. & Funahashi, S. (1999) Neural Comput. 11: 935-951.
[8] DeWeese, M.R. & Zador, A.M. (2006) J. Neurosci. 26: 12206-12218.
[9] Fox, R.F. (1997) Biophys. J. 72: 2068-2074.
[10] Burkitt, A.N. (2006) Biol. Cybern. 95: 1-19.
[11] Kitagawa, G. & Gersh, W. (1996) Smoothness priors analysis of time series. New York:
Springer-Verlag.
[12] Pospischil, M., Toledo-Rodriguez, M., Monier, C., Piwkowska, Z., Bal, T., Fregnac, Y.,
Markram, H. & Destexhe, A. (2008) Biol. Cybern. 99: 427-441.
[13] Dempster, A.P., Laird, N.M. & Rubin, D.B. (1977) J. R. Stat. Soc. 39: 1-38.
[14] Smith, A.C. & Brown, E.N. (2003) Neural Comput. 15: 965-991.
[15] Eden, U.T., Frank, L.M., Barbieri, R., Solo, V. & Brown, E.N., (2004) Neural Comput. 16:
971-998.
[16] Paninski, L., Ahmadian, Y., Ferreira, D.G., Koyama, S., Rad, K.R., Vidne, M., Vogelstein, J.
& Wu, W. (2010) J. Comput. Neurosci. 29: 107-126.
[17] Koyama, S., P ´erez-Bolde, L.C., Shalizi, C.R. & Kass, R.E. (2010) J. Am. Stat. Assoc. 105:
170-180.
[18] Schneidman, E., Freedman, B. & Segev, I. (1998) Neural Comput. 10: 1679-1703.
[19] Tsubo, Y., Takada, M., Reyes, A. D. & Fukai, T. (2007) Eur. J. Neurosci. 25: 3429-3441.
[20] Kobayashi, R., Tsubo, Y. & Shinomoto, S. (2009) Front. Comput. Neurosci. 3: 9.
[21] Lansky, P., Sanda, P. & He, J. (2006) J. Comput. Neurosci. 21: 211-223.
[22] Kobayashi, R., Shinomoto, S. & Lansky, P. (2011) Neural Comput. 23: 3070-3093.
[23] Huys, Q.J.M. & Paninski, L. (2009) PLoS Comput. Biol. 5: e1000379.

9

