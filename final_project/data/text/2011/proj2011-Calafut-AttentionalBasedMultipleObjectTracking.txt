 

 

 

Attentional Based Multiple -Object Tracking 

Mark Ca la fut  
 
Stanford Unive rs ity 
mcalafu t@sta nford .edu  
 
 

Abs trac t  
 
Th is  paper  invest iga tes  the  a t ten t ional   based   track ing 
framework   o f  Bazzan i  et  a l .  ( 2011)   and  the  genera l 
performance  o f  a t ten t ional   based   track ing   systems  using 
d i fferen t   classi fica t ion ,  pred iction ,  and   gaze  s elect ion 
techn iques.  Three  ob ject   classi fiers  were   imp lemen ted 
using   the  KNN  techn ique,  support  vector  mach ines,  and 
ADA Boost ing  to  recogn ize d igi ts from the MN IST da taset . 
The  performance  o f   the   classi fiers  was  considered   using 
fovea ted   and  una l tered   images  as  input .  The  d i fferen t  
classi fiers,  k nown   col lect ively  as  the  ‘wha t’  module   were 
then   in tegra ted  wi th   a   ‘w here’  pred iction   modu le   to 
determine  gaze  loca tion .  This  modu le  est ima tes  ob ject 
sta te  based   on   previous  state  h istory ,  using   a   trad i tiona l 
Ka lman   fi l ter. Gaze  select ion   is then  performed   start ing  a t 
the  expected  ob ject  posit ion   and   moving   ou tward   using  a 
randomized   diamond  shaped   search   pa ttern .  The  opt ima l 
gaze  loca t ion   is  selected   and   used   to  est ima te  track   ob ject 
posi t ion .  Fol lowing  comp letion  o f  the  track ing   system,  i ts 
performance   wa s  eva lua ted   using   dynamic  d igi t   videos 
genera ted   from  the  MNIST   da taset .  Test   videos  included 
four  classes  o f  randomly  generated   mo t ion   pro fi les  and 
varying  degrees  o f  in -scene  clu t ter.  In   genera l ,  the 
performance  o f  the  a lgorithm  was  robust   to   changes  in 
mo t ion  pro fi le and  degree o f clu t ter. 

1. Introduc tio n 

Ob ject   track in g   is   an   impo rtan t   app licat ion   in   the  fie lds  
o f  mach ine  learn ing   and   compu t er  v is ion .  However  
desp ite  the  focus   it   has   received ,  in   p ract ice  au to mated  
tracking  s ys tems  can  rarely  meet  the  perfo rmance  levels  o f  
their  hu man   coun terparts . Res earch   in to   the  human   v is ual  
s ys tem  has  made  it   clear  that   humans   effect ively   us e 
foveat ion   and   s elect ive  at ten t ion   in   the  p rocess   o f  ob ject 
tracking   (Rens ink,  2000).  Thes e  techn iques   in   con junct ion 
with   the  human   ab ility   to   unders tand   con text   in   the 
ongo ing  s cenes  may  d rive the d iffe rence in  perfo rmance.   
Th is   paper  at temp ts   to   rep licate  (w ith   mod if icat ion )  the  
general  fra mewo r k  o f  Ba zzan i,   et   a l .  ( 2011)   to   bu ild   a  
mu lt ip le  ob ject   track ing  model  that   inco rpo rates   foveat ion 
and   s elect ive  at ten t ion .  Specifica lly   the  Bazzan i,  et   a l.  
(2011 )  model   cons is ts   o f  a  general  clas s ificat ion   modu le  
(known   as   the  ventral  pathway )  and   a n   atten t ional  o r  gaze 
s elect ion  modu le  (known   as   the  do rs al  pathway ).  Ba zzan i  

et   a l .  (2011)  imp le men t   a  part icle  fi lter  in   the  do rs al 
pathway   fo r  state  es t imat ion   bu t   s uggest   a  variety   o f 
alternat ive  app roaches   fo r  p red ict ion .  Ga ze  s elect ion   is  
learned   us ing  the  on line  hedg ing   algo rithm  o f  Auer  et  a l . 
(1998 ).  The  co rres pond ing   ven tral  pathway   perfo rms  
clas s ificat ion   us ing   the  d is tance  bas ed   appearance  model  
s ugges ted   by   Larrochelle  and   H in ton  
(2010).  The  
appearance  model  us ed   is   mo re  e xp res s ive  o f  shape  than 
convent ional  appearance models . Overall  the  s imu ltaneous 
us e  o f  mo re  advanced   appearance  models   in   the  ven tral 
pathway   comb ined   with   learn ing   o f  gaze  p lann ing   in   the 
do rs al  pathway  wa s   expected   to   bet ter mimic   the  track ing  
o f human  obs ervers  and  to  lead  to  imp roved  accu racy . 
Th is   wo rk  ad jus ts   the  general  fra mewo r k  men t ioned  
above  (us ing   a  variety   o f  d ifferen t   techn iques )  and  tes ts 
the  perfo rmance  o f  the  developed  techn iques   us ing   the 
MNIST  dataset   (LeCun   and  Co rtes ).  Clas s ificat ion   models  
are  trained   us ing   s amp les   fro m  the  60, 000  M NIST  s tat ic 
d ig it   train ing   cas es .  Tes t ing   is   perfo rmed   us ing   s amp les  
fro m  the  10, 000  M NIST  s tat ic  d ig it   tes t   cas es .  The  gaze 
s elect ion   modu le  is   tes ted   by   generat ing   dynamic  v ideos 
fro m the MN IST tra in ing  s et . D ig its  are s amp led  rando mly  
fro m  the  tes t   s et   and   p laced   as   backg rou nd   clu t ter  in   a 
s tat ic  frame .  Dyna mical ly   a  s elected   number  o f  track  
ob jects  are  moved   th roughou t   the  s cene.  Fou r  mo t ion  
p ro fi les   o f  the  track  ob jects   are  availab le  fo r  tes t ing   o f 
comb in ing  clas s ificat ion  and  track ing  s ys tem.  

2. Clas s ificat ion M o de l 

is  
The  clas s ificat ion   model  o r  do rs al  pathway  
imp le men ted   us ing   th ree  alternat ive  methods .  The  firs t  
two   methods   are  imp le men ted   as   bas eline  techn iques   and 
the  th ird   techn ique  inco rpo rated   a  mo re  fle xib le  ob ject  
rep res en tat ion  in  an  at temp t  to  imp rove per fo rmance . Each  
techn ique  is  tes ted  us ing   unaltered   and   foveated  d ig it  
rep res en tat ions .  A ll  s tat ic  clas s ificat ion  
res u lts   are 
p res en ted  in  the fo llo wing  s ect ion . 

2 .1 . B aseline  Classification 

Dig it   clas s ificat ion   is   perfo rmed   us ing   a  K  Neares t  
Neighbo r  model .  The  K  Neares t   Ne ighbo r  model  was  
tes ted   with   d ifferen t   numbers   o f  s amp le  MNIST  d ig it  
rep res en tat ions   (100 ,  1000,  and   10, 000 ),  with   d iffe ren t  
numbers   o f  neighbo rs  cons idered  us ing  majo r ity   ru le  (1,  5,  

 

 

10 ),  and   us ing   foveated   test   images   and   unaltered   images .  
Bo th   fovea ted  images   and   unaltered   images   are s to red   and 
tes ted   as   a  featu re  vecto r.  24  tes t   runs   were  perfo rmed  
with   randomly   s elected   s amp les   over  the  tes t  cond it ions 
men t ioned   above  and   the  resu lts   were  averaged .   The 
res u lts   o f  the  tes t ing   are  s ummar ized   in   Tab le s   1  and   2.  
Overal l  us ing  K Neares t  Neighbo rs   the  best   resu lts with   o r 
10, 000  
occu r  when  
foveat ion  
withou t  
us ing  
neighbo r. 
s ing le 
and 
rep res en tat ions 
a 
nearest  
Clas s ificat ion  
accu racy  
in  
th is   bes t  
cas e  was 
app roximately   92%.    
In   an   attemp t   to  min imize  the  e ffects  o f  changes   in   d ig it  
locat ion   with in   inpu t   images ,  a  cen tro id   ad jus ted   KNN  
clas s ifier  was   imp le men ted   (als o   us ing   foveated   inpu ts ). 
Th is   alterat ion   d id   no t   lead   to   a  general   increas e  in  
clas s ifier  accu racy . The  lac k  o f  imp rove men t   is   l ike ly   due 
to   the  small   20x20  s ized   p ixe l  patches   us ed   to   rep res en t 
each   d ig it . Ad jus tmen t   o f  a d ig it   to  p lace  the  d ig it   centro id  
at   the  cen ter  o f  the  patch  wou ld   o ften   y ield   ro llover  o f  the 
d ig it  
the  patch ,  creat ing 
top   o r  bot tom  o f 
the 
to  
d is connected   patches   on   the  ima ge.  Th is   techn ique  was 
d is carded  and  its  tes t  res u lts  are summa rized   in  Tab le  3 .  
 
1  Neigh bor  
W.O Fovea t.  
69 .9%  
100  Repre.  
87 .3%  
1000  Repre.  
10000  Re pre.   92%  
 
Tab le 1 : KNN Resu l ts over 24  runs wi th  200  Samp les 
( una l tered  inputs) 

10  Neighbor  
64 .4%  
86 .7%  
91 .3%  

5  Neigh bor  
64 .6%  
85 .6%  
91 .4%  

1  Neigh bor  
W. Fove a t.  
68 .0%  
100  Repre.  
85 .5%  
1000  Repre.  
10000  Re pre.   92 .1%  
 
Tab le 2 : KNN Resu l ts over 24  runs wi th  200  Samp les 
(Foveated  inpu ts)   

5  Neigh bor  
64 .5%  
83 .2%  
92 .0%  

10  Neighbor  
63 .7%  
84 .5%  
92 .8%  

1  Neigh bor  
W. Fove a t.  
65 .5%  
100  Repre.  
84 .5%  
1000  Repre.  
10000  Re pre.   90 .0%  

5  Neigh bor  
59 .0%  
81 .5%  
88 .0%  

10  Neighbor  
56 .0%  
79 .5%  
88 .5%  

Tab le 3 : KNN Resu l ts over 24  runs wi th  200  Samp les 
(Foveated  inpu ts and  cen troid  ad justmen t)   

 
A ls o ,  a  two   clas s  SVM   rep res en tat ion was   imp le men ted  
to   d ifferen t iate  between   a  s elected   tes t   d ig it   (‘8 ’)  and   al l  
o ther  d ig its   in   the  datas et .  The  SVM   was   trained   us ing 
2, 000  t rain ing   s amp les . The  c las s ificat ion   accu racy   o f   the 
SVM   was   app roximate ly   the  s ame  us ing   foveated   inpu ts 
and  unaltered  inpu ts  and  was  g reater than  90%.   
The  res u lts   o f  LeCu n   et   al.  ( 1998)  s uggest   that   the se 
bas eline  techn iques   cou ld   be   fu rther  imp roved   to   98%  
accu racy   with   mod ificat ion   to   include  des kewing   and  
train ing  w ith  mo re  s amp les .   

 

2 .2 . Finalize d Object Re presentation 

Rather  than   main tain ing   comp lete   raw  p ixe l  l is ts   fo r 
each   patch ,  alternat ive  ob ject  
rep res en tat ions   were 
cons idered .  Fo llo wing   in it ia l  inves t igat ion ,  an  ADA  Boos t 
fra me wo r k   was   s elected   and   imp le men ted   fo r  comparis on  
with   the KNN  and   SVM   bas eline  perfo rmances .  A   variety  
o f  image  p ropert ies  were  e xtracted   f ro m  the  train ing   d ig it  
images   and   s to red   in   a  featu re  vecto r  includ ing   the  Eu ler  
Nu mber,  Or ien tat ion ,  Exten t ,  Per imeter,  A rea ,  Conve x 
A rea,  So lid ity ,  M ino r  A xis   Leng th ,  Eccen tric ity ,  Majo r  
Axis   Leng th ,  Equ iv   Dia meter,  M in   In tens ity ,  W eighted 
Cen tro id ,  Mean  
In tens ity ,  and   Fil led   A rea.  Thes e 
p ropert ies   were  chos en   experimen tal ly   and   us ed   to 
rep res en t  train ing   and  tes t  ob jects .  A fter  train ing   they 
funct ioned   as   d is crimin ato rs   fo r  the  ADA   Boos t   weak  
clas s ifiers .   
The  ADA   Boos t  algo rithm  was   trained   us ing  the  16  
featu re  ob ject   vecto rs   des cribed   above  with   50, 000  d ig it  
train ing   cas es .  The  clas s ifier  was   then  tes ted   us ing   the 
re main ing   10, 000  d ig it   cas es   in   the MNIST  databas e  with  
a  two -clas s   class ificat ion   ( 8  o r  no t -8 )  accu racy   o f  95. 9%  
withou t   foveat ion   after  algo r ith m  convergence  (requ ir ing  
app roximately   200  boos t ing   itera t ions ).  The  accu racy   o f 
the  clas s ifier  us ing   foveated   images   was   96 .3%.  The  
clas s ificat ion   accu racy   o f  the  ADA   Boost   techn ique 
e xceeded  
the  accu racy   o f 
the  bas eline  methods 
inves t igated   in   Sect ion   2 .1 ,  and   the  algo rith m  was  
u lt imately  s elected  due to  its  s ign ifican t ly  s uperio r  run t ime  
in   co mparis on   to   KNN.  A lthough   the  tra in ing   period   fo r  
ADA   Boos t  was   s ign ifican t   (487. 7  s econds   on  average 
over  the  50, 000  cas e  train ing   databas e),  the  evaluat ion   o f 
new  tes t   cases   after  the  comp let ion   o f  tra in ing   was   very  
rap id  
(~ 0. 0098 
s econds   on  
average).  Th is   was 
s ign ifican t ly   s ho rter  than   the  (~0.17)  s econd   average 
evaluat ion   t ime  fo r  tes t   cas es   us ing   KNN  w ith   10, 000  
rep res en tat ions .  Th is   s peed   increas e  in   con junct ion   with  
the  s ligh t   imp rovemen t   in   clas s ificat ion   accu racy   lead   to  
the  s elect ion   o f  the  ADA   Boos t  techn ique   as   the  p rimary  
clas s ifier.  
Other 
techn iques   were 
co ns idered  
fo r  ob ject  
clas s ificat ion   and   fo r  reducing   requ ired   da ta  s to rage  fo r 
ob ject   rep res en tat ions .  Several  o f  thes e  techn iques  cou ld 
be e xp lo red   in   fu tu re wo r k to  e xpand  upon  th is  p ro ject  and  
to   po ten t ially   imp rove  perfo rmance.  Fo r  e xa mp le ,  an  
in fo rmat ion  
be 
cou ld  
techn ique 
accumu lat ion  
imp le men ted   us ing   PCA   o r  ICA   (Kos ter  and   Hyvarinen ,  
2007)  and   PCA   techn iques   (in   con junct ion  w ith   quad rat ic 
clas s ifiers )  have  p rev ious ly   ach ieved   accu racy   in  exces s   o f 
97% .    Ano ther  poten t ial  method   fo r  fu tu re  e xp lo rat ion   is  
the  us e  o f  shape  con text   matched   K-NN  as   imp le men ted  
by   Belong ie  et   a l .  (2002)  w ith   repo rted   clas s ificat ion  
accu racy  in  e xces s  o f 99% .   

 

3. Ga ze  Se le ction 

Two   s teps   are  ess ent ial  to   the  gaze  s elect ion   p rocess . 
In it ia l ly   the  cu rren t   s tate  o f  the  track  ob jec t   mus t  be 
rep res en ted   us ing   des crip to rs  such   as   locat ion ,  o rien tat ion , 
s peed ,  scale,  and   appearance .  Second ,  fo llow ing   the 
es t imat ion   o f  the  ob ject   p ropert ies   at   the  next   t ime  
incre men t , an  op t ima l ga ze locat ion  mus t  be s elected . 
 Du r ing   the  exper imen tal  e valuat ion   o f  th is  p ro ject  
s amp le  d ig its   fro m  the  l is t   o f  ‘8 ’s   in   the  MNIST  datas et 
were  s elected   and   us ed   as   track  ob jects   (mo re   details   on  
th is   are  p rov ided   in   Sect ion   4).    The  appearance  o f  track 
ob jects   was   als o   main tained   us ing   a  comb inat ion   o f 
techn iques .  Firs t ,  the  clas s if icat ion   algo r ith m  des cribed   in  
Sect ion   2. 2  (ADA   Boos t   trained   with   50 ,000  s a mp le  
d ig its )  was   us ed   to   determine  wh ether  o r  no t   foveated 
gazes  were  s imila r  in   appearance  to   typ ical  ‘ 8’s . Th is   s tep 
in   the  algo rith m  was   es s en t ially   a   ‘s an ity   check’,  as   any  
s pecific  ‘8  ‘s hou ld   generally   res emb le  the  clas s   o f  all  ‘8’s .  
In  add it ion  to  compa ring  ga ze  locat ions  to  generalized   ‘8 ’s  
us ing   ADA   Boos t ,  foveated   gaze  locat ions   were  als o  
compared   to   the  s pecific  ‘8 ’  track  ob ject   in   the  part icu lar  
track  v ideo .  In   the  firs t   frame  o f  each   tracking   exper imen t ,  
the  foveated   temp late  rep res en t ing  the  specific  trac k  ‘ 8’  
was   reco rded .  Th is   temp late  was   then  compared   to 
analyzed   gaze   locat ions   us ing   metrics   s uch  as   co rrelat ion  
(in   con junct ion   with   the  we igh ted   res u lts   o f  the  ADA 
Boos t   class ifier )  and   an   op t ima l  gaze 
locat ion   wa s  
s elected .  In   general,  it   was   expected   that  the  comb inat ion  
o f  the ADA   Boos t   framewo rk  and   a  generalized   temp late  
tracker  wou ld   p rov ide  a  h igh   deg ree  o f  con fidence  that 
iden t if ied  gaze  locat ions  dep icted  the true track ob ject .   

3 .1 . State Re presentation 

A   Kalman   f i lter  wa s   imp le men ted   to   es t imate  the 
pos it ion   and   speed  o f  the  track  ob ject   in   s ubs equent   v ideo 
fra mes .  The  accele rat ion   o f  the  ob ject   was   imp lic it ly  
ass umed   to   be  ze ro   and   the  velocity  was   us ed   to   est imate  
the  change  in   pos it ion   o f  the  track  ob ject .  The  fo l low ing  
s tate equat ions  were us ed  in  the Kalman   fi lter :     
 

 

 

 

 
The  x  var iab le   re fers   to   the  p red icted   s tate,  the  z  var iab le  
refers   to   the  obs erved  s tate,  the A  matrix  re flects   the  state 
trans it ion   matrix  fo r 
the  dynamic  s ys tem,  and  
the 
observat ion   and   p rocess   no is e  were  modeled   us ing   the  Q 
and  R matr ices . 

 

In   each   t ime  s tep ,  the  Kalman   f ilter  was   p rov ided   an  
 
updated   ob ject   locat ion   and   es t imated   velocit y   bas ed   on 
the s elected   op t ima l  gaze  locat ion . Thes e  inpu ts  were  then 
us ed   to   co rrect  the p rev ious s tate  p red ict ion   o f  the Kalman  
fi lter,  and   fo llo wing   the  fi lter  update  a  new  pos it ion   and 
velocity  p red ict ion  was  made fo r the ne xt  t ime s tep . 

3 .2 . Gaze  Se lection 

the 
to  
The  gaze  s elect ion   p rocess   was   crit ical 
perfo rmance  o f  the  tracking   algo r ith m.  The  cen ter  o f  the 
gaze  s earch   at   each   t ime  s tep   was   the  p red icted   ob ject  
locat ion   p rov ided   by   the Kalman   fi lter. A   d ia mond   s haped 
s earch   pat tern  was   fo llowed ,  rad iat ing   ou tward   from  the 
Kalman  s elected  midpo in t .   
The  gaze  search   and   s elect ion   p rocess  occu rred   in   a 
s eries   o f  iterat ions .  A t   each   iterat ion ,  the   s earch   pat tern 
wou ld  be fo llo wed  w ith  18  to tal gaze  locat ions  analyzed .  8  
o f  thes e  gaze  locat ions   were  at   the  edges  o f  the  d iamond  
(3   at   each   edge) w ith   the  9t h   locat ion  was   at   the  cen ter  o f  
the d iamond . T wo  s ets  o f random values  were  added  to  the 
9 te mp late s earch   locat ions , y ield ing  a to t al o f  18  d is parate 
gaze  s earch   po in ts   at   each   iterat ion .  The  s ize  o f  the 
d ia mond   s earch   pattern  was   in it ial ized   as   3  p ixe ls   (with   a  
to tal wid th  o f  6 p ixe ls  fro m on e edge o f the d ia mond  to  the 
o ther  in   its   wides t   d imens ion ).  The  added   p ixel  s h ift  
facto rs   at   each   locat ion   were  d rawn   randomly   fro m  the 
range  o f  -2   to   2.   An   e xa mp le  o f  the  d ia mond   s earch  
pat tern  with  randomizat ion   is  s hown  in  Figu re  1 belo w:  
    

 

 

Figure  1 :Th is  image  sequence  dep icts  the  spread   o f  gaze 
loca tions ( shown   as  yel low  x’s)  according  to  the 
d iamond  
temp la te  plus  randomiza t ion .   The 
loca tions  spread   as  a   cloud   and   a ttemp t   to 
iden ti fy  an  op t ima l  fovea ted  gaze. The last  frame  
shows  the  true ob ject   loca t ion   (mark ed  by  a   red 
square)   and  the  est ima ted  loca t ion   determined 
by  the  a lgori thm  a fter  search ing   (mark ed   by  a 
green  square under the red  square) .   

,~ N(0,Q), ~ N(0,R)xAxBuwwzHxvv100010A = ,,000100001ttHIB 

A t   each  gaze  locat ion   the  ADA   Boos t   clas s ifier  fro m  
Sect ion   2. 2  p rov ided   an   es t imate  o f  how  clos e  the  ob ject 
was   to  a  typ ical  ‘8 ’  ob ject .  Add it ionally ,  the  co rrelat ion  
between   the  extracted   foveated   ob ject   te mp late  and   the 
foveated   gaze  was   determined .  Thes e  metrics   were  
weigh ted   bas ed   on  perfo rmance  and   comb ined   to   est imate  
the  op t ima lity   o f   each   gaze  locat ion .  The  op t ima l   gaze  
locat ion   is   u lt imately   the  locat ion   y ie ld ing   the   h ighes t 
value o f th is  comb ined  metric .   
Fo l low ing   the  comp let ion   o f  an   iterat ion   o f  the  ga ze  
s earch ,  the  d iamond   s haped   s earch   pat tern   was   expanded 
by   a  cons tant   facto r  o f  1.2 x. Add it ionally   the  random  s h ift  
facto r was   increas ed   in   p ropo rt ion  with   the  inc reas e  in   the 
s earch   pat tern   s ize.   Du r ing   each   s earch   iterat ion ,   the 
algo rith m  main tains   the  locat ion   o f   the  op t ima l   gaze  
locat ion   found   up   to  that   po in t . The s earch  con t inues   fo r  a 
min imu m  o f   f ive   d ia mond   s tep   s izes ,  bu t   wi l l  con t inue 
un t il  a  reas onab le  s t eady   s tate  is  ach ieved  in   the  value  o f 
the est imated  ma ximu m metr ic at  that  t ime s tep .   
A t   the  comp let ion   o f  the  gaze  s elect ion   p rocess ,  the 
ob ject   locat ion   is  reco rded   as  an  obs ervat ion  and  pass ed  to 
the  Kalman   fi lter  s tate  es t imato r.  The  gaze  s earch   pat t ern 
and   other  parameters  
lis ted   above  were  op t imized  
e xperimen tally  th rough  tes t ing  in  Sect ion  4.  

4. Ex pe rime ntal Re sults  

The  tracking   a lgo rith m  was   tes ted   by   generat ing   v ideos  
fro m  the  MN IST  datas et .  Clu t ter  s ou rces   were   rando mly  
d rawn   fro m  the  tes t   s et   and   in terspers ed   at   random 
locat ion s   in   the  s cene.  A   tes t   d ig it   (fro m  the  l is t   o f  ‘8’s )  
was   s elected   and   moved   th roughou t   the  s cene  us ing   a 
linear  p ro f i le  w ith   vary ing   s tep   s ize ,  a  l inear  p ro f ile  w ith  
added   no ise,  a  s inus o idal  p ro fi le  w ith   no is e,  a nd   a 
inco rpo rat ing   no ise  and   d ifferen t  
comp le x  p ro f ile 
move men t  
types   vary ing   over 
t ime.  Stat ic  d ig it  
rep res en tat ions   were   us ed   fo r  in it ia l  c las s ifier   (ADA  
Boos t)  train ing   and  all  train ing   and   tes ted   was  perfo rmed  
with   unclu t tered   images   p rio r  to   dynamic  tes t ing .  Videos 
withou t   clu t ter  were   us ed   fo r  in it ia l  s tate  rep res entat ion 
tes t ing  and  to  help  s elect  a gaze s earch  pat tern .  
The  tracking   algo r ith m  was   tes ted   us ing   randomly  
generated   dynamic  v ideos   (with   vary ing   deg rees   o f 
clu t ter) o f the types  men t ioned  above.  
Tes t ing   was   perfo rmed   w ith   0,   10,   20,   and   30  rando mly  
s elected   clu t ter  d ig its   (p laced   at   random  locat ions )  w ith  
each   o f  the  fou r  mo t ion   p ro files .  The  tracking   erro r  
(Eucl idean   d is tance  between   the  es t imated   cen tro id   and  
the  true  centro id   at   each   t ime  s tep )  was   reco rded  over  10 
random  v ideo   s equences  in   each s et t ing  and  averaged . The 
res u lts  (in   average  p ixe l  erro r )  are  s hown   in   Tab le  4.  Fo r 
con text ,  d ig it   s izes   in   the  image  were  on   the  o rder  o f  20  
p ixe ls   in   heigh t   and  w id th . Therefo re   an   abs o lu te  erro r  o f  
abou t  10 p ixe ls  in  heigh t  and  10 p ixe ls  in  w id th  wou ld  s t il l  
in   general  p lace  a  trac k  po in t   on   body   o f  the  des ired  

ob ject .  Fo r  th is   reas on ,  average  tracking   erro rs   exceed ing  
20  were  ind icat ive  o f  qualitat ively   poo r  perfo rmance  and   a 
reas onab le   l ike l ihood   that   the  track  po in t   wou ld   be  fu lly  
s eparated  fro m the track  ob ject  fo r a  period  o f  the v ideo .  
 

Mo tion  Pr.  

0  Clut ter 
O bjec ts  

10  Cl . 
O bjec ts  

20  Cl . 
O bjec ts  

30  Cl . 
O bjec ts  

Line ar  

0. 557       

0. 989      

13 .6      

12 .8  

Lin.  +  Nois e  

.716     

6. 0      

16 .4      

18 .2  

S in. + Nois e 

0. 550       

0. 705      

18 .4      

22 .5  

Complex  

0. 490      

5. 2      

10 .6  

8. 6  

 Tab le 4 : Pixel  error wi th  each  mo t ion  pro fi le/clu t ter 
ob ject  comb ina tion  ( 10  test  average va lue for 
each  en try) .  

5. Dis cus s ion 

Regard les s   o f  the  mo t ion   p ro fi le  being   tes ted ,  the 
algo rith m  was   qualitat ively   and   quan t itat ively   effect ive  in  
tracking   in   al l  cas es   withou t   backg round   clu t ter.  The 
average  percen tage  tracking   erro r  acros s  all  tes ts   with   no 
clu t ter  was   0. 58% .  Th roughou t   tes t   runs   the  algo rithm 
appeared   to   retain   track  almos t   perfect ly   at  all  t imes .  In  
general,  the  s uccess   in   th is   bas e  cas e p rov ided   con fidence 
that  the algo rithm  funct ioned  co rrect ly .  
A s   the  level  o f  c lu t ter  increas ed ,  the  algo rith m  was  
fu rther  s tress ed   to   class ify   ob jects   s een   at   each   gaze 
locat ion . W ith   10  clu t ter  ob jects  p res ent ,  effect ive  tracking  
was   st ill  s een   with   all  mo t ion   p ro fi les .  The  average 
percen tage  tracking   erro r  in   thes e  s ituat ions   was   3.22%.  
Qual itat ively   a lthough   the  percen tage  erro r  was   s ligh t ly  
h igher  fo r  the  linear  p lus   no is e  mo t ion   p ro file  and   the 
comp le x  mo t ion   p ro fi le,  th is   was   like ly   at tribu tab le  to  
randomnes s   in   the  type  and   locat ion   o f  clu t ter  p res en t   in 
the s cene. The p res ence  o f many   ‘8’s   as  clu t ter s ou rces  fo r 
e xa mp le  tended   to   be  mo re  challeng ing   fo r  the  ADA 
Boos t   typ ical  ‘8 ’  clas s ifie r  and   wou ld   occas ional  y ield  
smal l  increas es  in  uncertain ty  in  the 10  clu t ter ob ject  cas e.  

 

 

 

Figure  2 :  Th is  image  sequence  dep icts  the  successfu l  
track ing   o f  an   ob ject   fo l lowing   a   sinuso ida l 
mo t ion   pro fi le  through   dense  clu t ter  ( 30   ob jects) . 
(Track  Box –  Green , True Loca t ion  –  Red) 

 

 

helped   allev iate  th is   uncertain ty  fo r  sho rt   periods   by 
gu id ing   the  algo rith m  to   mos t   like ly   ob ject   locat ions .  The 
mos t   s tress ing   s ituat ions   invo lved   occlus ion   fo r  very   long  
periods   (o r  alternat ively   occlus ion   s imu ltaneous   with   a 
large  and   unp red ictab le  change  in   d irect ion   o f  the  track 
ob ject).     

 

 

 

6. Future  Wo rk  

Figure  3 :  Th is  image  sequence  dep icts  the  cha llenge  o f 
track ing   through   dense  clu tter  ( 30   ob jects) .  After 
severa l   frames  o f   the  track   ob ject   moving   beh ind 
dense  clut ter,  the  sta te  est ima tor  beg ins  to   yield 
inaccura te  pred ict ions.  (Track   Box  –  Green ,  True 
Loca t ion  –  Red , Linear + No ise Mo t ion  Pro fi le) 

The  20  and   30  c lu t ter  ob ject   tests   were  mo re  s tres s ing 
fo r  the  algo rithm  and   demons trated   in teres t ing  aspects   o f 
its   perfo rmance.  Specif ica lly   the  average  percen tage  
tracking   er ro r  in   the  20  c lu t ter  ob jects   test  was   14. 8%  and  
the  average  percen tage  tracking   erro r  in   the  30  c lu t ter 
ob jects   tes t   was   15.5%.  In   the  vas t   majo rity   o f  tes t   cas es 
the  qualitat ive  track ing   perfo rmance  o f  the  a lgo rith m  was  
very   good  (s hown   in   Figu re  2).  In   compar is on   to  the  lower 
clu t ter  cas es ,  the  track  algo rith m  wou ld   o ften   co rrect ly  
iden t ify  the target  bu t  have s ome sma l l er ro r  (~ 10  p ixels  o r  
around   half  o f  an   ob ject  wid th )  about   its   exact   locat ion .  In  
a  smal ler  percen tage  o f  track  cases , the  track  ob ject  wou ld 
be comp lete ly  los t  due to  long  term occlus ion  o f the target . 
Thes e  cas es  wou ld   occu r  irregu lar ly   bas ed  on   the  inheren t 
randomnes s  o f  the  clu t ter  pos it ion   and   the  mo t ion   p ro file  
o f  the  track  ob ject .  In   s ome  o f  thes e  cas es ,  the  clu t ter was 
s o   dense  that   it  was   imposs ib le  fo r  the  hu man   obs erver  to 
iden t ify   where 
located   fo r  a 
track  ob ject  was  
the 
s ign ifican t   po rt ion   o f  the  v ideo . Du ring   thes e  long  periods 
o f  uncertain ty ,  erro r  accumu lated   in   the  Kalman   s tate 
es t imate  and   even tually   led   to   loss   o f  track.  In   thes e  cases , 
the  on ly   way   fo r  a  hu man   obs erver  to   regain   the  track 
po in t  was  to  s can  the en t ire s cene repeated ly  fo r any  ob ject  
move men t . A   fra me  to   fra me  d ifferenc ing   techn ique  cou ld 
be  bu ilt   in to   later  vers ions   o f  the  algo rith m  to   s pecifica lly  
deal  w ith   these  stress ing   cas es .  Figu re  3   below  dep icts   a 
s ituat ion  where  the  track  ob ject   was   even tually   los t  wh i le  
mov ing  th rough  a 30 clu t ter ob ject  s cene.  
In   general,  the  trac king   a lgo rith m  was   ab le  to   track  
   
all  mo t ion   p ro fi les   effect ively . Th is   ind icates  that  although 
the  cons tan t   velocity   ass ump t ion   in   the Ka lman   f i lter  was  
v io lated   (part icu lar ly   by   the  comp le x  and   s inus o idal 
mo t ion   p ro f iles )  the  us e  randomizat ion   in   the  d iagonal 
s earch   pat tern   p rov ided  enough  variety   o f  s earch   po in ts  to 
effect ively   iden t ify   the  target .  In   add it ion ,  the  comb ined  
appearance  metric   was   s uccess fu lly   ab le  to   iden t ify   the 
target   even  with  h igh   levels  o f  clu t ter.  Frequen t ly  the  track 
ob ject   wou ld   be  occluded   fo r  s ign ifican t   periods   o f  t ime,  
y ield ing   low  con fidence ma tches   in   the  appearance metric.  
In   thes e  s cenarios ,  the  us e  o f  the  Kalman   s tate  es t imato r  

The  general  fra me wo r k  o f  at ten t ional  bas ed   tracking  
p rov ides   fo r  a  w ide  variety   o f  var iat ion .  Ba zzan i  et   a l .  
e xp lo red   d iffe ren t   learn ing   mechan isms   fo r   clas s ificat ion  
and   gaze 
s elect ion .  As ide 
fro m 
the 
algo rith ms  
imp le men ted   in   th is   paper,  there  are  a  tremendous   number 
o f  alternat ive  op t ions  that  cou ld   be tested  and  compared   in  
perfo rmance  us ing   the  MNIST  databa s e  fo r  tes t ing .  A 
focus   cou ld   be  p laced   on   iden t ify ing   o ther  effect ive 
algo rith ms   that  can  funct ion  in   real-t ime.  Add it ionally  
limited   tes t ing   was   perfo rmed   us ing   mu lt ip le -tes t   ob jects 
in   th is   paper  (due  to   t ime  cons train ts ).  Fu tu re wo r k  cou ld  
s pecifical ly   at temp t   to   iden t ify   a lgo rith ms   w ith   s uperio r 
perfo rmance  in   mu lt ip le -ob ject   track ing   s cenarios   us ing 
the s ame fra me wo r k p res en ted  above .  

7. Re fe rence s   

Auer P., Ces a-Bianch i  N .,  Freund  Y. , and  
Schap ire, Robert  E.  Ga mb l ing  in  a  rigged  casino : the 
adversaria l  mu l ti -armed  band it  problem. Techn ical  Repo rt  
NC2 -T R- 1998- 025 ,  1998.  
 
Ba zzan i L.,  Fre itas  N. , Larochel le H. , Mu r ino  V. , and  T ing  
J..  Learn ing   At tent iona l   Po licies 
for  Track ing   and 
Recogn it ion   in  Video  wi th  Deep  Network s .  Proceed ings   o f 
the  28t h   In ternat ion al  Con ference  on   Mach ine  Learn ing ,  
2011.  
 
Be long ie S. , J itend ra M .,  Puzicha J.  Shape Mach ing  and   
Ob ject   Recogn i t ion   Using   Shape  Con texts.  
IEEE 
Trans act ions   on   Pattern   Analys is 
and  Mach ine 
In tell igence, Vo l.  24. No .  24.  2002  
 
Freund   Y.  and   Schap ire  R.  A  Short   In troduction   to 
Boost ing .  Jou rnal  o f  Japanes e  Society   fo r  A rt if icia l  
In tell igence, 14( 5 ).  1999  
 
Kos ter U. and  Hyv ar inen  A . A two -layer ICA -l ik e 
model  est ima ted  by score ma tch ing . In  In ternat ional 
Con ference o f A rt if ic ial Neu ra l Netwo r ks , pp . 798- 807,  
2007.  
 
La rochelle  H .  and   Hin ton   G.  Learn ing   to  comb ine  fovea l 
g l impses wi th   a  third -order Bo ltzmann  machine.  In  Neu ral 
In fo rmat ion  P roces s ing  Sys tems , 2010.  
 
Le Cun  Y., Co rtes  C. The MN IST Da taset .  
 
Rens ink,  Ronald  A .  The dynamic  represen tat ion   o f  scenes. 
Vis ual Cogn it ion , pp .  17- 42 ,  2000.  

 

