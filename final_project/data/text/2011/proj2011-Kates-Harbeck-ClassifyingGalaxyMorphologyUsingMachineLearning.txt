Julian Kates-Harbeck 

 

CS229 Final Report 

Julian Kates-Harbeck, CS229 Final Report 
 

Classifying Galaxy Morphology using Machine  Learning 

 
Introduction: 
 
The  goal  of  th is  project  is  to  c lassify  galaxy  morphologies.  Generally,  galaxy  morphologies  fall 
into  one  of  two  categories:  "early  types"  (elliptical  ga laxies)  and  spiral  ga laxies,  like  the  Milky 
Way.  Additionally,  a  celestial  object  of  interest  may  be  categorized  as  neither,  wh ich  usually 
corresponds  to  an  image  of  a  point  source  (e.g.  a  star)  or  to  an  artifact  of  the  data.  Alth ough 
humans are  generally  successful  at  classifying  astronomical  images,  the  sheer  amount  of  data 
that is currently produced is far too  immense to be interpreted by humans. The Sloan Digital Sky 
Survey  (SDSS)  for  example  –  the  number  one  source  for  public ly  available  astronomical 
imaging  data  –  has  a  growing  catalog  of  over  230  million  celestia l  objects.  Successful 
classification  of  all  of  these  objects  could  represent  a  major  step  forward  in  the  fie ld  of 
observational  astronomy,  ultimately  bringing  us  closer  to  the  goal  of  better  understanding  the 
composition  and  origins  of  our  universe.  Several  attempts  have  been  made  to  classify  the 
images from SDSS. One interesting project is the Galaxy Zoo Pro ject (C. Lintott et al.): The idea 
of  the project was  to have humans – more specifica lly volunteers with some prior knowledge of 
the  subject  (e.g.  science  teachers)  –  interactively  classify  images  of  celestia l  objects  online. 
Every given  image was classified by several  people,  in order  to produce a measure of reliab ility 
of  the  classification.  Using  these  statistics,  as  well  as  several  data  reduction  and  cleansing 
methods,  a  data  set  of  about  700,000  reliably  c lassified  galaxies  was  produced.  A  common 
object  ID  identifies  the  objects used  in Galaxy  Zoo with  the  images  from SDSS.  In  this  project, 
we  use  the  classifications  from Galaxy  Zoo  together with  the  corresponding  observational  data 
from SDSS as our data set. 
 
This project consists of 2 separa te approaches. In the first, we hand pick pre -computed features 
from  SDSS  for  every  galaxy  and  run  classification  using  those  features.  In  the  second  and  far 
more  challenging  approach,  we  aim  to  classify  galaxies  using  only  the  raw  image  data.   As  a 
train ing  set, we  use  the  clean  images  from Galaxy  Zoo  –  those galaxies where at  least  80%  of 
observers agree on  the morphology. We evaluate 
all c lassifiers using 10 fold cross validation. 
 
I.  Classification using Pre-computed Features 
 

Meaning 

Data Selection: 

 
The  SDSS  catalog,  in  addition  to  the  raw  image 
data,  offers  a  set  of  preprocessed  features  for 
every object. The  total number of such  features  is 
very  large  and  many  of  them  are  not  useful  for 
the  Weka 
morphological  classification.  Us ing 
package 
(M.  Hall  et  a l.),  we  analyze 
the 
classification  power  of  different  features.  Using 
several  attribute  selection  methods,  we  find  that 
the  feature  set  with  the  strongest  classification 
power  is  very  similar  to  the  feature  set  used  by 
Banerji  et  al.  The  features  are  described  and  the 
classification power is presented in table 1. 
 

fit 

(log 

Information 
Gain  
0.362  

g-r color 

deVAB_i 

expAB_i 

0.304  

fit  parameter 

0.285  

Evaluator vs.  
Feature 
Concentration  petroR90/petroR50  (ratio  of  radii 
containing  90%  and  50%  of  the 
Petrosian flux 
Green  minus  red  color  (redshift 
removed) 
DeVaucouleurs 
(infrared) 
Exponential 
(infrared) 
Adaptive second moment 
Adaptive shape measure 
Adaptive shape measure 
Exponential 
disk 
fit 
likelihood) 
DeVaucouleurs fit (log likelihood)  0.136  
0.107  
Adaptive fourth moment 
Red minus infrared color (redshift 
0.101  
removed) 
Log 
likelihood  of  being  well 
modeled as a star 
Texture parameter (infrared) 

mRrCc_i 
mE2_i 
mE1_i 
lnLexp_i 

0.279  
0.229  
0.197  
0.161  

lnLdeV_i 
mCr4_i 
r-i color 

parameter 

0.284  

0.021  

0.01   

lnLstar_i 

texture_i 

Table 1:  Description of the different features and relative classification power 
(arb. scaling) . 

Julian Kates-Harbeck 

 

CS229 Final Report 

Classification Results: 

 
Using  the  optimized  features,  we  employ  several  machine  learning  techniques  on  our  data. 
Specifically,  we  use  a  simple  Naïve  Bayes  classifier,  a  log istic  regression  classifier,  a n 
alternating  decision  tree,  a  random  forest  (using  10  trees  and  4  random  features per  tree)  and 
an  SVM  with  a  linear  kernel.  The  results  are  presented  in  table  2 .  We  can  see  that  the 
classification performance reaches a maximum of 95.21% with a logistic regression classifier. 
For  most  classification  techniques,  the  performance  lies  between  93%  and  95%.  The  only 
outlier  is  the  Naïve  Bayes  classifier.  Th is  is  an  indication  that  the  Naïve  Bayes  independence 
assumption  is  not well-justified.  Indeed,  for  the SDSS  feature set,  several  features  often aim  to 
describe  the  same  characteristic:  For  example,  both  “Concentration”  and  “mE2_i”/”mE1_i” 
describe the width of the brightness distribution in the image.  
 
II. Direct Image Classification 
 
While  we  were  able  to  achieve  good  results  using  the  pre -compiled  features  from  SDSS,  a  far 
more interesting problem is to classify the galaxies using only the raw image data. The goal is to 
train  a  classifier  that  can  –  just  like  a  human  –  take  a  raw  image  of  a  galaxy  and  classify  it  as 
either spira l or e lliptical. 
 
 
 
Image Processing: 
 
The  imaging  data  retrieved  from  SDSS  consists  of  200  x  200  pixel  RGB 
images.  A  typical  co llection  of  SDSS  imaging  data  is  shown  in  fig .  1.  It 
quickly  becomes  obv ious  that  before  the  raw  image  data  can  be  used  for 
classification,  several  issues  need  to  be  overcome.  First,  the  image  data 
contains a strong background noise  level.  The  regions  that  appear  “black” 
in  the  images  actually  have  a  consistent  magnitude  of  about  ¼  of  the 
maximum  magnitude  of  the  image.  Second,  the  imaging  data,  apart  from 
the  actual  galaxies,  contains  many  other  bright  secondary  objects.  These 
secondary  objects may be artifacts of  the camera, stars, quasars, or other 
galaxies.  Th ird,  the  images  are  subject  to  random  rotations.  In  our  final 
classifier  we  do  not  want  the  rotation  of  the  image  to  affect  the 
classification  of  the  galaxies.  One  of  the  most  challenging  aspects  of  this 
project was the development of a reliab le image processing procedure that 
would remove the three issues listed above. The following is a summary of the  developed image 
processing pipeline. 
 
First,  the RGB-image  is converted  to a grayscale  image (“flattened”),  i.e. a sing le 200 by 
200 matrix.  In  order  to  subtract  the  constant  background, we  find  the minimum pixel  value  and 
subtract it  from the matrix. We further zero all p ixe l values bellow a certa in magnitude cutoff (we 
found that half the mean of the matrix was ideal). This further reduces random fluctuations  in the 
ideally “black” regions of the image. 
The  second  step  –  the  removal  of  bright  secondary  objects  –  proved  to  be  the  most 
challenging.  Due  to  their  brightness,  secondary  objects  are  usually  not  removed  by  the  above 
described procedure. The two key ins ights that lead to an effic ient solution were the following: 1) 
The  images  queried  from  SDSS  are  almost  exactly  (within  1  p ixel)  centered  on  the  objects  of 
interest  2)  Galaxies  generally  are  almost  perfectly  invariant  under  180°  rotation.  Thus,  we  can 
compare each pixel of our image matrix to the corresponding pixel rotated 180° about the center 
of  the  image.  Taking  advantage  of  2),  a  “strong  enough”  difference  in  magnitude  of  these  two 
pixe ls  means  that  they  are  very  like ly  part  of  secondary  objects  and  can  thus  be  set  to  zero. 
There  are  however  a  few  subtleties  involved  in  this  algorithm.  First,  spira l  galaxies  sometimes 

Figure 1. Typical Imaging data from 
SDSS: Spiral (top) and Elliptical (bottom) 
galaxies. Single Objects (left) and 
images with Secondary Objects (right).  

Julian Kates-Harbeck 

 

CS229 Final Report 

have structural e lements (such as  indications of galaxy arms) that are not 
exactly symmetric under 180° rotations. Second,  the condition  for “strong 
enough”  must  be  optimized,  since  a  too  high  threshold  would  miss 
objects,  while  a  too  low  threshold  might  cause  obstruction  of  the  galaxy 
itself. We found that the optimal condition for “strong enough” is a relative 
difference  in  magnitude  of  over  0.5.  Further,  in  order  to  guarantee  that  
the main  structure of  the  galaxy  itself  is  unaffected, we  run  the  algorithm 
only  on  pixe ls  that  are  further  than  30%  of  the   total  image  radius  away 
from the image center. 
 
Finally,  we  wish  to  process  the  images  such  that  rotation  of  the 
orig inal  image will not affect the classification. The key insight here is that 
galaxies  share  a  common  ellipsoid  structure  in  the  images,  i.e.  they  a ll 
have  two  orthogonal  axes  of  symmetry.  By  ca lculating  the  second 
moments  in x and y of  the  image as well as  the correlation of  x and y, we 
can  construct  the  covariance  matrix  of  the  galaxy  image.  This  allows  us 
to  deduce  the  major  variance  carrying  axis  (Teague).  We  can  now  use 
the angle of this axis and rotate every image onto its major axis. 
In  summary,  we  now  have  a  clean,  centered  image  with 
consistent defin itions of  the x and y axes, without secondary objects and 
with a ll p ixe ls other  than  those of  the main object set  to zero. A summary 
of the image processing pipeline is g iven in figure 2.  
 

Image Analysis: 
 
Using  the  clean  image  data,  we  tra in  both  a  “blind”  classifier  that 
processes  the  image  without  any  insight  into  the  data  as  well  as  a more 
inte lligent  classifier  that  uses   scientific  knowledge  of  galaxies  in  order  to 
extract features that might be especially indicative of morphology. 
In  our  blind  approach,  we  compute  the  2D  Fourier  Transform  of 
the  image,  discarding  the  high  frequency  terms  (which  carry  mostly 
noise).  Specifically,  taking  the  central  10  by  10  Fourier  components 
showed  the  best  performance.  When  performing  classification  using 
these  100  Fourier  coefficients  direct ly,  we  achieve  a  classification 
accuracy  of  88.23%  with  an  ROC  area  of  0.931   using  an SVM  with  a 
linear  kernel.  After  further  dimensionality  reduction  using  ICA  and 
retain ing  only  the  coefficients  of  the  20  most  prevalent  independent 
components  (20  yielded  the  best  results)  as  features,  we  achieved 
91.52% classification accuracy with an ROC area of 0.878 using an 
SVM with a Gaussian kernel, 
three  main  distinguishing 
takes  advantage  of 
Our  knowledge  based  classifier 
characteristics between elliptica l and spiral galaxies.  F irst,  the  typ ical color spectrum of elliptical 
galaxies  is  different  from  that  of spiral  galaxies,  since  most  elliptica l  galaxies  are very  old  (they 
are  often  also  called  “early  type”  galaxies)  and  thus  are  subject  to  a  stronger  redshift  than  the 
usually “ younger” spiral ga laxies. We use  the  three RGB matrices of  the raw unflattened  image 
– corresponding  to  the  intensities  from  the green, red and  infrared color channels of  the  origina l 
photometric  SDSS  image,  together  with  a  bitmask  obtained  in  the  image  processing  step 
separating  the  galaxy  from  the  background,  to  extract  the  color  composition   of  the  galaxy. We 
then compute the fractions of the R, G and B pixe ls of the total  image magnitude, thus obtaining 
the fractions of green, red and infrared light of the total brightness of the galaxy, respectively. 
Second,  we  take  advantage  of  the  fact  that  spiral  galaxies,  unless  they  are  v iewed 
directly  from  their  axis  of  rotation,  appear  as  very  eccentric  ellipsoids,  while  elliptica l  galaxies 

Figure 2. Image Processing Pipeline as 
illustrated with an example galaxy 
(greyscale images as heat maps): Raw 
image (top), flattened image (upper 
center), background and secondary 
objects removed (lower center), 
rotation normalization (bottom). 

Julian Kates-Harbeck 

 

CS229 Final Report 

0.986 
0.982 
0.926 
0.979 
0.977 

Classifier 
Accuracy  ROC Area 
Pre-computed features 
95.21% 
Logistic Regression (PCF) 
94.86% 
Random Forrest 
SVM (SMO, linear kernel) 
94.12% 
93.76% 
Decision Tree  
Naïve Bayes  
91.43% 
Blind image classification 
Image Analysis + ICA + SVM 
91.52% 
0.878 
Knowledge-based image classification 
Image  Analysis 
+ 
feature  
95.89% 
0.943 
selection + SVM (poly. Kernel 3) 
Image Analysis +  feature selection 
+ Random Forest (60 trees) 
Image Analysis +  feature selection 
+ Logistic Regression 

show  very  uniform  circular  symmetry  with  low  eccentric ity.  We  use  up  to  4th  order  normalized 
central moments in x and y as well as generalized TSR (translation, rotation, scaling) invariant   
moments (Hu; Flusser) of the images to capture this information. Since our images are centered 
and  rotated  onto  their  major  axis,  the  x  and  y  moments  won’t  be  affected  by  rotation  of  the  
galaxies. 
Third,  we  make  use  of  the 
difference 
in 
radia l 
intensity 
distributions  between  elliptica l  and 
spiral  ga laxies.  Generally,  e lliptica l 
galaxies  experience  an  exponentia lly 
decreasing  intensity  profile  with  radius, 
wh ile 
spira l  galaxies  are  better 
modeled  using  a  deVacouleurs  profile: 
 
                               
                     
(for 
some  constant  k)  (Sérsic).  By  taking 
advantage  of  the  symmetry  of  the 
galaxies 
rotational 
their 
and 
normalization  onto  the  major  axis,  we 
can  capture most  of  the  information  by 
using  the  1D  density  profiles  along  the 
major  and  minor  axes  of  the  image 
instead  of  the  full  2D  radia l  profile,  thus 
simplifying  the  computation  substantia lly.  Specifica lly,  we  compute  the  distances  in  x  and  in  y 
from  the  center  that  capture  50%  and  90%  of  the  total  magnitude  of  the  1D  intensity  profile 
along  the major  and minor  axes,  respectively. We  then  take  ratios  of  these  4  values,  including 
cross terms. These features capture information about the radial density d istribution well.  
The  combined  features  from  the  color  study,  the  distribution  moments  an d  the  density 
profiles  are  then  fed  to  several  different  classifiers,  as  summarized  in  table  2.  The  best 
performance  is  achieved  using  an  SVM  with  a  3rd  degree  polynomial  kerne l:  we  achieve  a 
maximum  classification  accuracy  of  95.89%  with  an  ROC  area  of  0.986,  exceeding  the 
benchmark performance in section I using the  pre-computed features. 
 

95.18% 

0.989 

95.69% 

0.968 

Table 2: This table summarizes classification performance from the different parts of 
the project. The best performing classifiers are printed in bold face. 

Pre-Computed 
Features 

Useful 
Feature 
Extraction 

SVM 

SDSS 
imaging 
data 

Raw Images 

Background 
removal 

Artefact 
Removal 

Rotational 
Normalization 

Knowledge 
based 
Classification 

Color  

+ 

 Moments and 
Eccentricity  

+ 

Radial density 
Profille 

SVM 

"Blind" 
Classification 

2D 
Fourier 
Analysis 

ICA 

SVM 

Figure 3. Summary of the learning systems used in this project. Classification is performed using pre-computed features as well as raw image 
data. For the raw image data, we use both knowledge-based and "blind" features. 

 

Julian Kates-Harbeck 

 

CS229 Final Report 

Conclusion and Future Work 
 
We have presented a system consisting of an  image  processing algorithm  in conjunction with a 
knowledge  based  classifier  that  can  with  high  accuracy  classify  ga laxies  using  only  the  same 
raw  image data that was available to humans in the Galaxy Zoo study.  Comparing the blind and 
ins ightful c lassifiers, we have also shown that using physical ins ight into the details of a problem 
can  lead  to significant  improvement of classification performance. The summary of our  learning 
systems is given in figure 3, and the summary of classification performance is g iven in tab le 2  
There  are  two  major  areas  for  possible  improvement  of  our  system .  First,  due  to  the 
computational  complexity  of  the  problem  of  image  cleansing  and  feature  extraction  and 
limitations of our computational processing and memory resources, we were only able  to create 
a  train ing set of 1000 galaxies  for  testing and  training ; a  larger  tra in ing set will very  likely  result 
in even better classification performance. Second, one physical difference between elliptica l and 
spiral ga laxies that we have found difficult to capture in our feature set  is the very fine spiral arm 
structure:  In  some  cases,  a  spira l  ga laxy  v iewed  from  above  (close  to  or  along  the  axis  of 
rotation)  can  show  (usually  very  slight)  ind ications  of  spiral  arm  structure,  while  an  elliptica l 
galaxy  is  a lways  azimuthally  homogeneous.  A  more  advanced  feature  set  including  this 
information would most like ly increase the classification accuracy even further. 
 
Acknowledgements: 
 
I  would  like  to  thank  Dr.  Mark  Allen  from  the Stanford  Physics  Department  for  his  helpful  input 
and suggestions for this project.  
 
References: 
 
M. Banerji et al. "Galaxy Zoo: reproducing galaxy morphologies via machine learning." Monthly Notices 
of the Royal  Astronomical Society. Vol. 406 2010: pp. 342-353. 

Flusser, Jan. "On the independence of rotation moment invariants." Pattern Recognition 2000: 1405-
1410. 

M. Hall et al. "The WEKA Data Mining Software: An Update." SIGKDD Explorations, Volume 11, Issue 1 
2009. 

Hu, M. "Visual pattern recognition by moment invariants." IRE Transactions on Information Theory, 8 2 
Feb. 1962. 

C. Lintott et al. "Galaxy Zoo 1: Data Release of Morphological Classifications for nearly 900,000 galaxies." 
Monthly notices of the Royal Astronomical Society  2010. 
 
—. "Galaxy Zoo: morphologies derived from visual inspection of galaxies from the Sloan Digital Sky 
Survey." Monthly Notices of the Royal Astronomical Society  2008. 

Sérsic, J. L. "Influence of the atmospheric and instrumental dispersion on the brightness distribution in a 
galaxy." Boletin de la Asociacion Argentina de Astronomia 1963: p. 41. 

Teague, M. R. "Image analysis via the general theory of moments." Journal of the Optical Society of 
America August 1980: 920-930. 
 

