Movies’ Genres Classi ﬁcation by Synopsis

Ka-Wing Ho

Abstract

This paper investigated four different approaches for
automated movies’ genres classiﬁcation based on their
synopsis.

1 Introduction

Public movies’ database such as IMDB provides genre
information to assist searching. The tagging of movies’
genres is still a manual process which involves the col-
lection of users’ suggestions sent to known email ad-
dresses of IMDB. Movies are often registered with in-
accurate genres. Automatic genres classiﬁcation of a
movie based on its synopsis not only speeds up the clas-
siﬁcation process by providing a list of suggestion but
the result may potentially be more accurate than an un-
trained human.

2 Data set

The data used in this project is a set of text ﬁles from
IMDB [1]. They contain 158,840 synopsis [4] and
746,883 pieces of genre information [3] of movies and
TV shows. For this project, 16,000 unique titles at
which both the synopsis and genre information were
available were chosen and randomly split into 80% and
20% sets. The former was used for training while the
latter for testing. Note that a movie can be (and of-
ten so) associated with more than one genres. There
are 20 listed genres in the IMDB data set and only the
10 (denoted as L) most common genres were used in
this project. The genres’ names and percentages of
movies in them are: action(13.2%), adventure(9.1%),
comedy(30.0%), crime(13.1%), documentary(16.3%),
drama(49.1%), family(11.0%), romance(15.65%), short
ﬁlms( 33.4%) and thriller(13.6%) respectively.
The synopsis text ﬁle was processed to generate the
bag-of-words (BoW) representation. The NLTK stop-
words list [2] was ﬁrst used to remove all stopwords
from the synopsis. All numerical words were also

mapped to the same index in the dictionary as they usu-
ally don’t provide much genre related information. The
remaining words were ﬁltered through a Python stem-
mer library [5] so words with the same base but differ-
ent forms mapped to the same index in the dictionary.
For the 16,000 titles used in this project, a dictionary
with 63,840 words was generated. Out of the 63,840
words, only those which have occurred more than 15
times in all the training samples were used in BoW rep-
resentation so only 10,656 (denoted as V ) words were
left. The term frequency inverse document frequency
(tﬁdf ) of the words were then computed:

tf idf (wk , di ) = wki ∗ log

m
Pm
d=1 1{wkd > 0}
where wki is the frequncy of the k-th word in the i-th
movie’s synopsis (di ), and m is the number of train-
ing/test sets.
After the preprocessing above, each movie’s synopsis
vector x ∈ R10,656 . The
was represented by its tﬁdf
vector was also normalized to make it a unit vector. This
was done to account for the variation in length between
the synopsis of different movies. Similar treatment of
and normalization were also done for the test set
tﬁdf
using the same 10,656 words. There is also a bit-vector
y ∈ R10 associated with each movie where yl = {0, 1}
to indicate whether it belongs to genre l.

3 Classiﬁcation Methods

A movie can be associated with multiple genres so the
task in this project is a mult-label classiﬁcation problem.
We evaluated four different approaches, some of which
were published in previous literature:

• One-Vs-All approach with SVM

• Multi-label K-nearest neighbor (KNN) [7]

• Parametric mixture model (PMM) [8, 9]

• Neural network

1

3.1 SVM

While a movie can belong to mutliple genres, whether
tagging it wih a paritcular genre is just a binary classiﬁ-
cation problem. Speciﬁcally, one can group all movies
of a particular genre together as the positive samples and
the rest as negative samples and train a binary classi-
ﬁer with these two disjoint sets. This approach is gener-
ally known as One-Vs-All. However, if the sizes of the
two classes differ a lot, the classiﬁer resulted is likely to
bias towards the more populous class. While the preci-
sion may be good, it would result in a rather low recall
for less common genres (e.g. adventure). So, we also
tried two different approaches: (1) increase the weight
(option -w in libsvm [6]) of the penalty for misclassify-
ing the smaller class. One simple way to determine the
weight is based on the ratio between the sizes of the two
classes; (2) reduce the training set of the more populous
class to match the size of the less populous class. We
used libsvm [6] in this project. The input is the normal-
ized tﬁdf matrix and the corresponding output labels for
each genres. We tried different solvers and misclassi-
ﬁcation penalty and found that the combination of L2-
regularized L1-loss support vector classiﬁcation (dual)
with default penalty of 1 yielded the best result.

3.2 Multi-label K-nearest neighbor

Intuitively, movies belonging to the same genre should
share more common keywords in their synopsis. If one
were to consider a movie synopsis x as a point in the
hyperspace, movies with similar genres combination of
x should be close to it. This is similar to the idea behind
multi-label KNN alogrithm in [7] which utitlizes the
statisical information of a document’s k-nearest neigh-
bor to infer its genres.
For a training sample (x(i) , y (i) ), its k-nearest neigh-
:= Pa∈N (i) y (a)
bors are denoted as N (i) . Let C (i)
de-
l
l
note the number of its k-nearest neighbors which belong
l be the event that C (i)
to the genre l. Let E j
l = j ∈
{0, 1, ..., k} (i.e. j out of k neighbors are in genre l) and
l be the event that y (i)
H p
l = p ∈ {0, 1}. The task of clas-
sifying whether a test sample t belongs to genre l is by
computing the maximum a posteriori(MAP) estimate:
(t)
C
y (t)
:= arg maxp∈{0,1} P (H p
l |E
l
l
l
P (H p
l )P (E
C

= arg maxp∈{0,1}

)
(t)
l

|H p
l )

C

l
(t)
l

P (E
= arg maxp∈{0,1} P (H p
l )P (E

l

)

(t)
l

C
l

|H p
l )

2

l |H p
P (E j
l ) is estimated from the training set by
l [j ] and d1
updating counters d0
l [j ] as follows:

l [j ] := 0; d1
d0
l [j ] := 0; ∀ j ∈ {0, ..., k}
for i ∈ {1, ..., m}
for l ∈ {drama, comedy , thriller, ...}
if (y (i)
l == 1)
l [C (i)
d1
]++;
l
else
l [C (i)
d0
l
end

]++;

end

end

With Laplace smoothing,

l |H p
P (E j
l ) =

dp
l [j ] + 1
j ′=0 dp
Pk
l [j ′ ] + k + 1
No smoothing is needed for the prior as there is at least
a movie in each genre:

, ∀ l, j, p

i=1 1{y (i)
l ) = Pm
l = p}
P (H p
m

, ∀ l, p

Alternately, one can also assume that
the prior
follows a uniform distribution. In this case, it’s the same
as computing the maximum likelihood estimate(MLE):

y (t)
l

:= arg maxp∈{0,1} P (E

(t)
l

C
l

|H p
l )

3.3 Parametric Mixture Model

In [8, 9], the authors argued that the binary classi ﬁca-
tion approach taken in section 3.1 doesn’t represent the
the multi-faceted negative samples well. They proposed
a generative model which conjectured that a document
belonging to muliple categories can be regarded as a
mixture of words related to those categories. Specif-
ically, for a word w , suppose its probability of show-
ing up in the synopsis of a movie in genre l is the pa-
rameter θl,w = P (w |l) where PV
w=1 θl,w = 1. For
a given movie belonging to multiple genres, the prob-
ability of the word w showing up in its synopsis is a
weighted sum of the word distribution over each gen-
l=1 λ(i)
l=1 λ(i)
res: P (w |y (i) ) = PL
l ∗ θl,w where PL
l = 1
and λ(i)
l = 0 if y (i)
l = 0. We implemented the
PMM1 model in [9] which made a simplifying assump-
tion that λ(i)
has a uniform distribution over all the
l

genres to which a movie belongs.
In other words,
λ(i)
:= y (i)
l=1 y (i)
l / PL
. For example, if a movie is an
l
l
action drama, its y (i) = [1, 0, 0, 0, 0, 1, 0, 0, 0, 0], then
P (w |y (i) ) = 0.5 ∗ θ1,w + 0.5 ∗ θ6,w .
With the naive Bayes assumption, the probability of a
synopsis x(i) given genres y (i) is:

P (x(i) |y (i) , Θ) =

V
Y
i=1

( PL
l=1 yl θl,w
PL
l′=1 yl′

(i)
w

)n

where n(i)
w is the frequency of word w in x(i) and Θ is
the set of all θl,w . Θ is estimated by maximizing the
posterior P (Θ|Ω) where Ω = {(x(i) , y (i) )}m
i=1 . As-
sume y is independent of Θ. Taking log on both sides
gives Θmap := arg maxΘ Pm
i=1{logP (x(i) |y (i) , Θ) +
logP (Θ)} where the prior over the parameters is as-
sumed to be P (Θ) ∝ QL
l=1 QV
w=1 θl,w in [9]. So, the
objective function to maximize is:

J (Θ) =

m
X
i=1

V
X
w=1

n(i)
w log

L
X
l=1

λ(i)
l θl,w +

L
X
l=1

V
X
w=1

logθl,w

The authors in [9] proved that the objective function can
be maximized by iteratively updating the followings un-
til convergence:

g (i)
l,w (Θ) :=

λ(i)
l θl,w
l=1 λ(i)
PL
l θl,w
w g (i)
i=1 n(i)
:= Pm
l,w (Θ(t) ) + 1
i=1 n(i)
w g (i)
PV
w=1 Pm
l,w (Θ(t) ) + V
For a given test sample t, prediction of its genres y (t) is:

θ(t+1)
l,w

, ∀l, w

y (t) := arg maxy ′ P (x(t) |y ′ ; Θmap )P (y ′ )

where prior P (y ′ ) can be estimated from the training
set. This is essentially computing the maximum a pos-
teriori (MAP) estimate. Note there are 210 − 1 possible
values which y ′ can take on, each corresponding to
different combination of the 10 genres. Alternately, one
can once again assume a uniform class prior as in [9].
This is essentially the MLE. We experimented with
both in this project.

3.4 Neural network

Lastly, we also trained a neural network using error
backpropagation. The neural net consisted of one hid-
den layer, an input layer of size V (10,656) and output

layer size of L(10). 2 different hidden layer sizes (S )
were tried: 100 and 300. The activation function was
the sigmoid function and the cost function with regular-
ization was:

J (θ) =

1
m

m
X
i=1

L
[−y (i)
X
l
l=1

log(hθ (x(i) )l )−(1−y (i)
l )log(1−hθ (x(i) )l )]

+

λ
2m

[

S
X
j=1

V
X
k=1

(Θ(1)
j,k )2 +

L
X
j=1

S
X
k=1

(Θ(2)
j,k )2 ]

where hθ (x(i) )l is the output of l-th output unit, Θ(1) ∈
RSxV and Θ(2) ∈ RLxS are the weights for the two con-
necting layers.
We also attempted to utilize PCA to reduce the dimen-
sion of the input data. We used the princomp command
in Matlab to generate the principal components and the
mappings of the tﬁdf vectors to the space of the principal
components and trained neural networks with different
number of principal components. The test set was also
mapped into the space of the principal components be-
fore being fed into the trained neural network to make
prediction.

4 Results

SVM(Default)
SVM(weighted)
SVM(1:1)
KNN(k=97)(MLE)
KNN(k=88)(MAP)
PMM(MLE)
PMM(MAP)
NN(λ = 1, P C = 1000)
NN(λ = 1, P C = 4000)
NN(λ = 1, P C = 8000)
NN(λ = 1, No PCA)
NN(λ = 0, No PCA)

Precision
0.66141
0.47689
0.51205
0.40987
0.64093
0.46371
0.53624
0.67630
0.65444
0.62493
0.64453
0.66886

Recall
0.39572
0.62533
0.61631
0.73400
0.33261
0.54234
0.45876
0.41513
0.43225
0.45708
0.43666
0.41655

F Measure
0.47151
0.53785
0.54999
0.51580
0.40060
0.48550
0.47375
0.49896
0.50849
0.52044
0.50938
0.49786

Table 1: Average precision, average recall and average
F-Measures over all genres.

The evaluation is based on the following metrics:

P recision =

T P
T P + F P

Recall =

T P
T P + F N

3

0.75

0.7

0.65

0.6

0.55

0.5

0.45

0.4

0.35

 
0

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

 
0

 

Avg Precision
Avg Recall
Avg F−Measure

10

20

30

60
50
40
Number of neighbors(K)

70

80

90

100

Figure 1: KNN(MLE) over different K

 

Avg Precision
Avg Recall
Avg F−Measure

10

20

30

60
50
40
Number of neighbors(K)

70

80

90

100

Figure 2: KNN(MAP) over different K

F M easure =

2 ∗ P recision ∗ Recall
P recision + Recall
where T P , F P and F N are the numbers of true posi-
tive, false positive and false negative results respectively.
Table 1 shows the average precision, average recall and
average F-Measures over all genres by different algo-
rithms. Table 2 shows the precision and recall informa-
tion for each genres.
SVM(Default) and SVM(weighted) were SVM clas-
siﬁers trained with the entire training set but the latter
assigned more weight to the misclassiﬁcation penalty
of the smaller class; SVM(1:1) was a SVM classi-
ﬁer trained with a subset of the training set so that
sizes of both classes were similar. KNN(MLE/MAP)
and PMM(MLE/MAP) were the K-nearest neighbor and
parametric mixture model respectively; NN(*) stand for

4

various conﬁgurations of a neural network with 100 hid-
den units: λ is the weight of the regularization term and
P C is the number of principal components used if PCA
was applied to the inputs.
As shown in table 2, SVM(Default) had a low recall
rate for the less common genres in the data set as the
imbalance in class sizes resulted in a decision boundary
which favored the negative class. There is also a notable
difference in the recall between MLE and MAP for the
KNN model and, to a lesser extent, the PMM model.
For less common genres, its prior P (H 1
l ) is much less
(t)
C
than P (H 0
l ) so the posterior probability P (H 1
)
l |E
l
l
was dragged down by it, resulting in lower recall (but
higher precision) than KNN(MLE). Similar effect was
observed in the PMM(MAP) model but the difference
with PMM(MLE) was not as much. There were 210 − 1
possible priors to consider so the skewness among them
was more evenly “spread out”.
We experimented with values of K from 5 to 99 for
the KNN models. Figure 1 and Figure 2 show the aver-
age precision, recall and F measure over different num-
bers of K. Interestingly, for KNN(MLE), both the preci-
sion and recall kept rising as the number of neighbors
increased. This may suggest that movies with the same
genres weren’t as closely clustered as initially thought.
It may also be the case that different genres perform best
at different values of K.
As mentioned in section 3.4, we tried neural networks
with hidden layer sizes of 100 and 300 respectively.
The latter actually had a slightly inferior performance to
the former. The high dimensionality of the input layer
(V > 10, 000) led to huge number of parameters in the
weight matrix Θ(1) relative to the number of training
samples(12, 000+). A neural network with fewer num-
bers of hidden units has fewer parameters and it may
be less prone to over ﬁtting in this case. We attempted
to reduce the the input dimension with PCA but it ap-
pears that PCA may not be as effective on this data set as
one would have desired: the maximum amount of vari-
ance captured by a single principal component was only
0.38%. The ﬁrst 1000, 2000, 4000 and 8,000 princi-
pal components accounted for about 46%, 66%, 86%
and 98% of the variance respectively. It’s interesting to
note a neural network trained with only the ﬁrst 1000
principal components (i.e. 10% of the size of the origi-
nal input layer) still managed to achieve similar level of
precision and recall as one trained with all components
(albeit without regularization).

SVM(Default)
SVM(weighted)
SVM(1:1)
KNN(k=97)(MLE)
KNN(k=88)(MAP)
PMM(MLE)
PMM(MAP)
NN(λ = 1, P C = 1000)
NN(λ = 1, P C = 4000)
NN(λ = 1, P C = 8000)
NN(λ = 1, No PCA)
NN(λ = 0, No PCA)

SVM(Default)
SVM(weighted)
SVM(1:1)
KNN(k=97)(MLE)
KNN(k=88)(MAP)
PMM(MLE)
PMM(MAP)
NN(λ = 1, P C = 1000)
NN(λ = 1, P C = 4000)
NN(λ = 1, P C = 8000)
NN(λ = 1, No PCA)
NN(λ = 0, No PCA)

action

r
p
0.27945
0.67978
0.61201
0.39970
0.75751
0.31752
0.71824
0.34289
0.21709
0.68116
0.31640
0.47079
0.22402
0.59146
0.31409
0.65700
0.34411
0.62869
0.38106
0.60886
0.35335
0.62705
0.31409
0.65385
drama

p
0.69486
0.69444
0.69337
0.65719
0.66292
0.68331
0.68304
0.71704
0.68118
0.69135
0.69212
0.70633

r
0.73624
0.73624
0.73688
0.76953
0.75416
0.58707
0.63188
0.73816
0.71127
0.71127
0.70807
0.70679

adventure
r
p
0.12903
0.64516
0.47097
0.32088
0.72258
0.23455
0.61613
0.24741
0.10000
0.62000
0.48387
0.34642
0.36452
0.46311
0.18065
0.69136
0.21613
0.63810
0.23548
0.57031
0.20968
0.59091
0.18710
0.64444
family

p
0.61607
0.31707
0.22743
0.25000
0.70968
0.33191
0.49785
0.62416
0.61875
0.56784
0.59756
0.62774

r
0.19828
0.52299
0.73851
0.64943
0.12644
0.44828
0.33333
0.26724
0.28448
0.32471
0.28161
0.24713

comedy

r
p
0.48638
0.68563
0.63471
0.56616
0.69425
0.55261
0.68113
0.52611
0.38547
0.62623
0.52573
0.61950
0.42785
0.63568
0.48234
0.68188
0.51564
0.64520
0.50757
0.61341
0.51463
0.64885
0.52472
0.65409
romance

p
0.60465
0.40112
0.34342
0.32866
0.62838
0.41344
0.44231
0.62025
0.61134
0.57333
0.57664
0.60956

r
0.26971
0.59336
0.75311
0.73029
0.19295
0.33195
0.19087
0.30498
0.31328
0.35685
0.32780
0.31743

crime

r
p
0.48984
0.65165
0.68623
0.46769
0.81264
0.41002
0.81490
0.40883
0.36795
0.66803
0.73363
0.49094
0.63657
0.57787
0.47178
0.73592
0.47630
0.71525
0.50113
0.69159
0.47856
0.71380
0.44470
0.74060
short ﬁlms
p
0.70474
0.61793
0.60235
0.56079
0.66917
0.48695
0.49341
0.70631
0.66027
0.65396
0.67822
0.71377

r
0.54460
0.66667
0.72113
0.74930
0.50141
0.66573
0.63286
0.54648
0.54930
0.59624
0.58779
0.55962

documentary
p
r
0.64591
0.77209
0.80350
0.63636
0.88327
0.54177
0.49607
0.85992
0.62062
0.70110
0.87743
0.40304
0.80350
0.48876
0.80446
0.63230
0.64981
0.80676
0.66537
0.79350
0.66732
0.80328
0.80332
0.65953
thriller

p
0.55944
0.34751
0.31082
0.28073
0.44262
0.39080
0.48889
0.52459
0.53881
0.48519
0.51691
0.53488

r
0.17778
0.52667
0.74667
0.75111
0.06000
0.45333
0.34222
0.21333
0.26222
0.29111
0.23778
0.20444

Table 2: Precision (p) and recall (r) of each genres by different algorithms.

[7] M. ling Zhang and Z. hua Zhou. Ml-knn: A lazy
learning approach to multi-label learning. Pattern
Recognition, 40:2038–3048, 2007.

[8] A. K. McCallum. Multi-label text classiﬁcation with
a mixture model trained by em. In AAAI 99 Work-
shop on Text Learning, 1999.

[9] N. Ueda and K. Saito. Parametric mixture models
for multi-labeled text. In In Advances in Neural In-
formation Processing Systems 15, pages 721–728.
MIT Press, 2003.

References

[1] Imdb alternative interfaces. URL http://www.
imdb.com/interfaces.

[2] Natural language toolkit. URL http://www.
nltk.org.

[3] Imdb
URL
2011.
database,
genres
ftp://ftp.fu-berlin.de/pub/misc/
movies/database/genres.list.gz.

[4] Imdb plots database,
URL ftp:
2011.
//ftp.fu-berlin.de/pub/misc/
movies/database/plot.list.gz.

[5] R. Boulton.
Pystemmer 1.0.1.
http://pypi.python.org/pypi/
PyStemmer/1.0.1.

URL

[6] C.-C. Chang and C.-J. Lin. Libsvm: a library for
support vector machines, 2001.

5

