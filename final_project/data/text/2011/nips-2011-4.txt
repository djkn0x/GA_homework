Minimax Localization of Structural 
Information in Large Noisy Matrices 
Poster: W055 

M. Kolar 

S. Balakrishnan  

A. Rinaldo 

A. Singh 

Identifying biclusters 
n1 

n2 

k2 

Goal:  De-noise and re-order rows/columns of the matrix to infer biclusters 
that are activated. 
 

Observation model 
 A = (cid:533)uvT + R 
    u – k1 sparse unit vector 
    v – k2 sparse unit vector 
 
 
 
 
    u,v    {-1,0,1} 
R ~ i.i.d. zero-mean subgaussian((cid:305)2) perturbation  

 
 

 

 

Identifying biclusters 

Information Theoretic minimax limit: If 

 

 

 

SNR 

 

then, for any biclustering procedure, the probability of failure 
remains bounded away from zero by a constant. 

 
Note:    
 
 
 
Optimal performance achieved by scanning over all 
submatrices of size k1 x k2. 
 
 

 

Computationally efficient procedures 

SNR 

 

Elementwise thresholding 
 

Sparse Singular Value Decomposition 
 

Row/Column Averaging 

   (large clusters only                         ) 

 

Note:    
 
These procedures do not achieve information theoretic lower 
bound. 

NIPS 2011

!"#$%&’"(")#*(+,’%-%#.’&/0(,&1#234%1+#5+(")#.’%%46#2%-034+

!"#$%&"&"#’$()*#+,-.)/*$(0$%-)1+-1$&12$3*&2//.$4&5#678&*$

!"#$%&’#()*+,*-%./’*/(*01’(#"*

• Two Contributions ::

• Statistical estimation with sparse parameters :: analysis of forward-backward 
greedy algorithm; better than ell_1!

• Application to Discrete Graphical Model Selection

Statistical Model ::

X (i)

∼ P (X ; θ∗ )

Neg. Log-Likelihood ::

L(θ ; D) =

1
n

n
￿
i=1

− log P (X (i) ; θ)

ell_1? 

Sparsity Constrained MLE ::

min
θ:￿θ￿0≤k

L(θ ; D)

Non-Convex?

Bias; Restrictive Model 
Conditions

Learning Discrete Graphical Models 

• Problem :: Estimate underlying graph G 

• Discrete Random Variables 

• Discrete Graphical Model :: 

X = (X1 , X2 , . . . , Xp )
P (X ; θ , G) ∝ exp 

D := (X (1) , . . . , X (n) )
• Given :: n samples                                    where

￿
(s,t)∈E (G)

X (i)

θstφst (xs , xt )


∼ P (X ; θ∗ , G)

?

Forward-Backward Greedy Algorithm

• Generalization of [T. Zhang, 2008] greedy algorithm for linear regression to general sparse statistical 
estimation

• Algorithm (Stopping Threshold \epsilon) ::

! Forward: Find best co-ordinate to add ; add if improvement greater than \epsilon; set \delta = 
amount of improvement

! Backward: Prune co-ordinates with loss-increase smaller than \delta

Theorem [Sparsistency]: Recovers support 
of true parameter, given restricted strong 
convexity, sufﬁcient stopping threshold 

Comparison: Learning Discrete Graphical Models

ell_1

greedy

Model 
Assumptions

Irrepresentable
/ Incoherence

Restricted Strong 
Convexity

Sample 
Complexity

Comp.
Complexity

n = Ω(d3 log p)

n = Ω(d2 log p)

O(p4 )

O(d3 p2 )

Better in all respects!

i.e. don’t use ell_1 regularization; 
use greedy!

Oh, and 
Information-theoretically Optimal 
(Santhanam, Wainwright 08)

Visit us at Poster

!"#$%&%’()*(!"#$%(+&),(
-*./*0%1(23(4*1"56(

7066(8#5#9,0)1&%*:(

B*6,0#(A"%"%C#0.(

3"/#$)."%)(*;(8)#<6<=6>(
?%&:"$6&)@(*;(A*$*%)*(

D$#&%(#%1(-*’%&<:"(8=&"%="6(
4EA(

F%)*%&*(A*$$#5C#(

-8FE!>(4EA(

2&"$#$=,&=#5G3""/(4*1"56(
M%"G8,*)(!"#$%&%’(

!"#$%&’()*#E%)"’$#)"(
,&"$#$=,&=#5(D#@"6&#%(.*1"56(
+&),(1""/(%")+*$96H(

80/"$G=#)"’*$@(

!2’/3/41243(#>3?’)*#
(

•!(!"#$%(12’/3/412’)#%5#43-’;%/2’)#;*$(6,#$&%’(
#C6)$#=)(9%*+5"1’"H#
•!(KL/5&=&)5@()13/’#+3/3@’-’/)#),#)(#$"($"5":#%)(
)*(5"#$%&%’(%"+(=*%="/)H(

"’’+#,’-.%/0)*#
(

•!(!"#$%#12’/3/412’)#%5#5’3-6/’)7#
•!#89)6+’/:2)’&#5’3-6/’#(’3/929;#I(%*(%""1(
)*($"5@(*%(,0.#%G=$#J"1(&%/0)(;"#)0$"6H(
•!#"2)-/2<6-’&#/’+/’)’9-3=%9)7##

8,#$"1(,&’,"$G5":"5(;"#)0$"6(

8,#$"1(5*+G5":"5(;"#)0$"6(

2&"$#$=,&=#5(Q"%"$#<:"(4*1"5(

A$""(,&"$#$=,@(*;((
=5#66"6(&6(5"#$%"1(

A392@3(B#

A:’124(’B#

(
(N,’)-’&#C129’)’#D’)-36/39-#E/%4’))F#
/$&*$O(#(%*%/#$#.")$&=(/$&*$(*:"$()$""(
6)$0=)0$"6(

(
(N!2’/3/41243(#"2/241(’-#E/%4’))F#/$&*$O(
#(%*%/#$#.")$&=(/$&*$(#55*+&%’(=#)"’*$&"6()*(
6,#$"(,&’,"$G5":"5(;"#)0$"6>(*$(/#$)6H(

(,*$6"(

(=*+(

(=#$(

(:#%(

()$0=9(

"’’+#>%(-G@399#$34129’#

K%;*$="(N#//$*L&.#)"P(’5*C#5(=*%6&6)"%=@((
),$*0’,(.#%@(5*=#5(=*%6)$#&%)6H((

E.#’"6>(2#%1+$&R"%(=,#$#=)"$6>(
4*<*%(=#/)0$"(1#)#6")6H(

!"#$%&%’()*(!"#$%(;$*.(U"+(KL#./5"6(
A$#&%&%’(KL#./5"6(NC@($*+P(
-*%1&<*%#5(8#./5"6(

!"#$%&%’(;$*.(
T("L#./5"6(

Q"%"$#<%’(
S*:"5(
-,#$#=)"$6(

!"#$%"1(80/"$G-5#66"6(NC@($*+P( 8#./5"1(S*:"5(-,#$#=)"$6(

Probabilistic Joint 
Image Segmentation and Labeling 

Adrian Ion1,2, Joao Carreira1, Cristian Sminchisescu1 

1Faculty of Mathematics and Natural Sciences 
University of Bonn 

2PRIP, TU Wien & IST Austria 

How to segment and how to label images? 

•

Image segmentation and labeling are inter-dependent 
− At pixel level recognition is poorly defined for many 
semantic categories, e.g. people, chairs… 
− Given regions with sufficiently large spatial support, 
reliable recognition is possible 

•

Low-level segmentation can produce useful spatial 
support hypotheses, but these are rarely accurate in 
any single segmentation 
• A recognition model should allow segment 
recombination and produce semantic label 
distributions rather than point estimates 

Model and Computational Principle 

We explore figure/ground methods to generate large segment pools, then 
recombine and recognize subsets, within a sound statistical framework 
 

θ
((
tlp

θ
IZ
)(

Joint Segmentation and Labeling Model 
=
 
),),
It
∑∑
=
=
t
tl
)(
α
l
),),
It
((
tlF
category dependent 

β
t
),(
ItF
category independent 

1
θ
)(
IZ
θ
((
tlF

θ
((
tlF

θ
tlF
((

),),
It
+

),

I

)

exp

),),
It

•
Learn parameters using Maximum Likelihood 
• Novel incremental partition function estimation 
− Sum over subset of configurations (multiple cliques, labeled) 
− Include incorrect configurations the model rates probable 
 

Qualitative Scene Geometry 
(Stanford class + geometry) 

Image       Ours-S          GT-S         Ours-G       GT-G 

Semantic 

Ours 

Gould et al. 

75.6 

76.4 

Geometry 

Ours 

Gould et al. 

88.8 

91.0 

Pascal VOC 2010 
Segmentation and object class recognition  

Poster W016 

Ours 

CVC-HARMONY-DET 

Average 
score 

41.7 

40.1 

UOCTTI_LSVM_MDPM 

31.8 

BROOKES_AHCRF 

STANFORD_REGLABEL 

30.3 

29.1 

Object detection with grammar models
Ross Girshick
David McAllester
Pedro Felzenszwalb
University of Chicago
TTI Chicago
Brown University

helmet,
occluded left side

ski cap, no face
truncated

pirate hat, dresses,
long hair

truncation, holding glass,
heavy occlusion

Objects from rich categories have 
diverse structural variation

 

Object detection with grammar models
Ross Girshick
David McAllester
Pedro Felzenszwalb
University of Chicago
TTI Chicago
Brown University

Dalal & Triggs 
CVPR 2005
AP 0.12

(f)

Felzenszwalb, McAllester & Ramanan
CVPR 2008
AP 0.27

More mixture components?

Felzenszwalb, Girshick, 
McAllester & Ramanan
PAMI 2010
AP 0.36

Felzenszwalb, Girshick & McAllester
voc-release4
AP 0.42

There are too many combinations!
Instead...

... compositional models deﬁned by grammars  

Object detection with grammar models
Ross Girshick
David McAllester
Pedro Felzenszwalb
University of Chicago
TTI Chicago
Brown University

Localizing people with an object detection grammar
Subtype 1 Subtype 2
Example detections and derived ﬁlters

Part 1

Part 2

Part 3

Part 4

Part 5

Part 6

Occluder

AP 0.47

Parts 1-6 (no occlusion)

Parts 1-4 & occluder

Parts 1-2 & occluder

! Fine-grained occlusion   ! Part sharing 
! Non-trivial model of the stuff that causes occlusion  
! Part subtypes   ! Subparts at multiple resolutions

Object detection with grammar models
Ross Girshick
David McAllester
Pedro Felzenszwalb
University of Chicago
TTI Chicago
Brown University

Discriminative training when the label space != output space

person

per son

face

trunk

arms

lower-par t

mouth

eyes

nose

shoe

legs

shoe

output

pants

label

Weak-label structural SVM
Generalizes latent structural SVM  

Top performance on PASCAL VOC 2010 ‘person’

Rapid Deformable Object Detection using Dual-Tree Branch and Bound

Iasonas Kokkinos

Center for Visual Computing
Ecole Centrale Paris 

Galen Team
INRIA-Saclay

Deformable Part Model score:

Felzenszwalb, Girshick, McAllester, Ramanan, PAMI 2010

Max-Product/Dynamic Programming

Generalized Distance Transforms

Approximate solutions:
Y. Chen et al. Rapid inference on a novel and/or graph for object detection, NIPS 2007
P F Felzenszwalb R B Girshick and D A McAllester Cascade object detection with DPMs CVPR 2010
P. F. Felzenszwalb, R. B. Girshick, and D. A. McAllester. Cascade object detection with DPMs CVPR 2010
I. Kokkinos and A. Yuille. HOP: Hierarchical Object Parsing, CVPR, 2009
M.Pedersoli, A.Vedaldi, and J.Gonzalez. A coarse-to-fine approach for object detection, CVPR 2011
B. Sapp, A. Toshev, and B. Taskar. Cascaded models for articulated pose estimation, ECCV, 2010

Rapid Deformable Object Detection using Dual-Tree Branch and Bound

Branch and Bound: exact solution
Branch and Bound: exact solution

Best-case:
Best case:

Iasonas Kokkinos, Ecole Centrale Paris/INRIA Saclay

Rapid Deformable Object Detection using Dual-Tree Branch and Bound

Dual Tree Branch and Bound:  Dual Trees [1] + ESS [2] for DPMs
Dual Tree Branch and Bound: Dual Trees [1] + ESS [2] for DPMs

Dual Trees: bound

Upper and lower bounds

High:  objects in A  & parts in 1
Low:   objects in A & parts in 6

[1] A.G. Gray and A.W. Moore. Nonparametric density estimation: Toward
computational tractability. ICDM 2003
[2] C Lampert M Blaschko and T Hofmann Beyond sliding windows- efficient
[2] C. Lampert, M. Blaschko, and T. Hofmann. Beyond sliding windows efficient
subwindow search. CVPR 2008

Iasonas Kokkinos, Ecole Centrale Paris/INRIA Saclay

Rapid Deformable Object Detection using Dual-Tree Branch and Bound

Comparisons with GDT on 3000 images (precomputed unary terms)
Comparisons with GDT on 3000 images (precomputed unary terms)

Single object: speedup increases with threshold

Multiple-objects, 1-best: 100-fold speedup for > 50% of images

Current bottleneck: unary term computation – amenable to bounding

Code available from 
http://vision mas ecp fr/Personnel/iasonas/
http://vision.mas.ecp.fr/Personnel/iasonas/

Iasonas Kokkinos, Ecole Centrale Paris/INRIA Saclay

Im2Text: Describing Images Using  
1 Million Captioned Photographs 
  Vicente Ordonez (presenter), Girish Kulkarni, Tamara L. Berg 
Stony Brook University 

sky 
trees 
water 
building 
bridge 

Computer Vision 

Our Goal 

An old bridge over dirty green water. 

One of the many stone bridges in town  
that carry the gravel carriage roads. 

A stone bridge over a peaceful river. 

Harness the Web! 

SBU Captioned Photo Dataset 
1 million captioned images! 

Matching using Global  
Image Features 
(GIST + Color) 

Smallest house in paris 
between red (on right) 
and beige (on left). 

Bridge to temple in 
Hoan Kiem lake. 

A walk around the 
lake near our house 
with Abby. 

Transfer Caption(s) 
(cid:286)(cid:856)(cid:336)(cid:856) (cid:862)T(cid:346)(cid:286) water is clear 
enough to see fish 
swimming around in it(cid:856)(cid:863) 

The water is clear 
enough to see 
fish swimming 
around in it. 

Hangzhou bridge in 
West lake. 
. . . 

The daintree river by 
boat. 

Use High Level Content to Rerank  
(Objects, Stuff, People, Scenes, Captions) 

The bridge over the 
lake on Suzhou Street. 

Iron bridge over the Duck 
river. 

Transfer Caption(s) 

(cid:286)(cid:856)(cid:336)(cid:856) (cid:862)T(cid:346)(cid:286) bridge over the 
lake on Suzhou Street(cid:856)(cid:863) 

The Daintree river by boat.  Bridge over Cacapon river. 
. . . 

Results 

Good 

Bad 

A female Mallard duck in 
the lake at Luukki Espoo. 

The cat in the window. 

Amazing colours in the sky at 
sunset with the orange of 
the cloud and the blue of the 
sky behind. 

Cat in sink. 

Fresh fruit and 
vegetables at the market 
in Port Louis Mauritius. 

The boat ended up a kilometre 
from the water in the middle of 
the airstrip. 

