Improved Algorithms for Linear Stochastic
Bandits

Yasin Abbasi-Yadkori, D ´avid P ´al, Csaba Szepesv ´ari

Department of Computing Science, University of Alberta
&
Google, New York
abbasiya@ualberta.ca, dpal@google.com, szepesva@ualberta.ca

December 14, 2011

Linear Bandits

In round t = 1, 2, . . .
◮ Choose an action Xt from a set Dt ⊂ ❘d .
◮ Receive a reward Yt = hXt , θ∗ i + ηt
◮ Goal: Maximize total reward.
◮ Web advertisement, online shortest path, ...

◮ Weights θ∗ are unknown but ﬁxed. kθ∗k2 ≤ S.
◮ Noise is conditionally R-sub-Gaussian i.e.
E[eγηt | X1:t , η1:t−1 ] ≤ exp (cid:18) γ2R2
2 (cid:19) .

∀γ ∈ ❘

Regret of the Bandit Algorithm

◮ Optimism in the Face of Uncertainty.

◮ Build a conﬁdence set. With probability ≥ 1 − δ,
kbθt − θ∗kVt ≤ Rr2 ln (cid:16) det(Vt )1/2
δ det(λI)1/2 (cid:17) + S√λ
A tight data dependent conﬁdence set.
(Vt = Pt
t , bθt : ridge-regression solution, λ: regularizer.)
XtX⊤
s=1

◮ Improvements over previous results (Dani et al., 2008):
Worst-case regret:
O(d log(n)pn log(n/δ)) → O(d log(n)√n + pdn log(n/δ))
Problem-dependent regret with “gap” ∆ :
O( d2
∆ log(n/δ) log2 (n)) → O( log 1/δ
∆ (log2 (n) + d2 + d log n))

New bound
Old bound
New bound with rare switching

 

2000

4000

Time

6000

8000

10000

t
e
r
g
e
R

3000

2500

2000

1500

1000

500

0
 
0

0.2

0.15

0.1

0.05

t
e
r
g
e
r
 
e
g
a
r
e
v
A

Vast improvements
compared to Dani et al. (2008)

Computational Improvements

0

0

0.2

0.4

0.6

0.8

1

C

See our poster W082!

From Bandits to Experts:                   
On the Value of Side-Observations 

Shie Mannor 

The Technion 

Ohad Shamir* 

Microsoft Research  
New England 

 

NIPS 

December 2011 

Shie Mannor and Ohad Shamir 

From Bandits to Experts 

What We Do 
• Sequential decision making: repeatedly choose among (cid:1863)  actions 
•
(cid:862)E(cid:454)(cid:393)(cid:286)(cid:396)(cid:410)(cid:400)(cid:863) “(cid:286)(cid:410)(cid:410)(cid:349)(cid:374)(cid:336)(cid:855) Learner sees rewards of all actions 
•
(cid:862)B(cid:258)(cid:374)(cid:282)(cid:349)(cid:410)(cid:400)(cid:863) “(cid:286)(cid:410)(cid:410)(cid:349)(cid:374)(cid:336)(cid:855) Learner sees only its own reward 
  
Click to edit Master title style 
Our (More General) Model 
 
By picking an action, Learner gets side-information on 
some subset of other actions. Captures: 
(cid:857)(cid:271)(cid:258)(cid:374)(cid:282)(cid:349)(cid:410)(cid:400)(cid:857) 
E(cid:454)(cid:393)(cid:286)(cid:396)(cid:410)(cid:400)(cid:857) 
(cid:857)(cid:258)(cid:374)(cid:282) (cid:349)(cid:374) (cid:271)(cid:286)(cid:410)(cid:449)(cid:286)(cid:286)(cid:374)(cid:842) 

1 

3 

2 

4 

1 

3 

2 

4 

1 

3 

2 

4 

Shie Mannor and Ohad Shamir 

From Bandits to Experts 

Why 

• Captures structure between the actions 
– Web Advertising 
 
 
 
Click to edit Master title style 
 
 
 
 
– Sensor and  communication networks 

 
 
• Related work: Focus on affinity (Bandits in 
Metric Spaces) or stochastic correlations, 
while we make no such assumptions 
 

Shie Mannor and Ohad Shamir 

From Bandits to Experts 

Results 

• New Efficient Algorithms 
• Regret upper and lower bounds 
– Non-trivial dependence on 
information feedback structure 
Click to edit Master title style 
• Experiments 
• Many open questions! 
 
 

Come see our poster!  
 

Shie Mannor and Ohad Shamir 

From Bandits to Experts 

Lower Bounds for 
Passive and Active 
Learning

Maxim Raginsky
Duke / UIUC

Alexander Rakhlin
UPenn

Presenter: Maxim Raginsky

Two Learning Paradigms

Passive Learning

Active Learning

What governs the learning rate?
VC dimension Disagreement Coefﬁcient

Wanted: 
A Uniﬁed Lower 
Bound Analysis

(X1,Y1),...,(Xn,Yn)X1Y1...XnYn! Vapnik-Chervonenkis Class

VC-dim(F ) = d

! Hard Margin Parameter

!
!

E[Y |X = x] − 1
2

!
!

> h
2

Not all VC classes are created equal: 

F

Alexander's Capacity Function

⌧ (✏)

measure of X ’s on which functions in F✏ disagree.

F✏

f ∗

Supremum of this function is the disagreement 
coefﬁcient

Passive Learning

Active Learning

h 6= 1

h = 1

n = Ω ⇣ (1−δ)d log τ (ε)
εh2
n = Ω ⇣ (1−δ)d
ε ⌘

+

log 1
εh2 ⌘
δ

n = Ω ⇣ (1−δ)d log τ (ε)
h2

+

τ (ε) log 1
δ
h2

⌘

Tools from Information Theory

Can phrase the problem in terms of information gain on 
ever y round

φ
Data Processing Inequality for    -Divergences

Dφ (PZ kQZ )  Dφ (PkQ)

Classical Fano inequality is a consequence, but not enough for 
our purposes.

Freedom to choose  φ is key

A new packing lemma allows to consider any active learning 
method

Active Classification 
based on Value of Classifier 
Tianshi Gao     Daphne Koller 
 

Motivation:

Classification 
accuracy

our goal

•! Multiple features/kernels 
•! Ensemble of classifiers 
•! Good statistical power 
•! Expensive computational cost

Test time

Can we enjoy the statistical gain of using multiple 
features/kernels/classifiers at a small computational 
cost?

TexPoint fonts used in EMF.  



Active Classification

Given an ensemble of classifiers (built on multiple features):

classifier

feature

Classifier 
cost

Feat. 
cost

(        ,          , 0.01s, 
0.3s)

(        ,          , 0.01s, 
0.3s)

Test 
instance 

(        ,          , 0.5s, 
1.0s)

(        ,          , 0.1s, 2.0s)

Active classification process: 
!! classification as a sensing problem: each classifier is viewed as a 
potential observation that might inform our classification process 

!! a dynamic process: observations are selected sequentially based on 
previous observations 

!! selection based on value of classifier 
!! A value-theoretic computation that balances an estimate of the expected 
classification gain and its computational cost 

Active Classification

! " # $

! " # $% &

! " # $% &

High info. gain+ Low comp. cost
(     ,       , 0.01s,
0.3s)
(     ,       , 0.1s, 
2.0s)

(     ,       , 0.1s,
2.0s)

Feat. 
cost

Classifier 
feature
classifier
cost
(     ,       , 0.01s,
0.3s)
(     ,       , 0.5s, 
1.0s)
Good info. gain+ Very low comp. cost
(     ,       , 0.01s, 
0s)
(     ,       , 0.5s,
1.0s)

Better info. gain + Comparable comp. cost
(     ,       , 0.1s,
(     ,       , 0.5s,
2.0s)
1.0s)

! " # $% &

! " # $% &

! " # $% &

Model/Algorithm Highlights: instance-specific, dynamic, robust, joint consideration 
of statistical and computational properties

Results (multiple features)

26.4x speedup

Highest accuracy

Individual  
features

Budgeted Optimization with Concurrent 
Stochastic-Duration Experiments 

Javad Azimi, Alan Fern, Xiaoli Fern  
Oregon State University  
 
NIPS 2011 
 
Poster #W052   
 

 

1 

Bayesian Optimization (BO) 

Goals: maximize an unknown function  f  by requesting a small 
set of function evaluations 
•Assume a prior on  f  is available (e.g. Gaussian Process) 

 

Current Experiments 

Posterior Model 

Select Experiment(s) 

 

Poster #W052   

Run Experiment(s) 

2 

Extended BO Model 
Time Horizon h 

We consider the following: 
• Concurrent experiments 
(up to l exp. at any time)  
 
• Stochastic exp. durations 
(known distribution p)  
 
• Experiment budget 
(total of n experiments) 

 
• Experimental time 
horizon h 

 

 

Lab 1 

Lab 2 

Lab 3 

Lab l 

x1 

x2 

x4 

xn-1 

x5 

x8 

x3 

x7 

xn 

x6 

Stochastic Experiment 
Durations 

Problem: 
Schedule when to start new experiments and which ones to start.   
 
3 

Poster #W052   

Challenges 

Objective 2: maximize info. used 
in selecting each experiment 
(favors minimizing concurrency) 

x1 

x2 

xn 

Lab 1 

Lab 2 

Lab 3 

Lab 4 

x4 

x5 

x6 

x1 

x2 

x3 

x4 

x7 

We present online and offline approaches that effectively 
trade off these two conflicting objectives 

 

Poster #W052   

4 

Projection onto A Nonnegative 
Max-Heap  

Jun Liu, Liang Sun, Jieping Ye 

Arizona State University 

W039 

Heredity Principle induced by 
Nonnegative Max-Heap 

Key Contributions: 
• Develop an analytical top-
down algorithm for the 
projection onto P 
 
• Develop an efficient 
bottom-up algorithm with 
empirically  linear time 
complexity 

Drosophila Gene Expression Images 

1. cellular blastoderm;   
2. segmentally repeated;   
3. yolk;  
4. ectoderm anlage in statu nascendi;   
5. pair rule;   
6. segment polarity;   
7. gap;  
8. yolk nuclei;   
9. procephalic  ectoderm anlage in statu nascendi;   
10. foregut anlage in statu nascendi 
11. clypeolabrum  anlage in statu nascendi 

A Bottom-Up Algorithm 

Empirical Evaluation 

Phase transition in the family of p-resistances

Mor teza Alamgir Ulrike von Luxburg

Max Planck Institute for Intelligent Systems
Tübingen, Germany

Resistance distance R (s , t )

Consider the electrical network corresponding to a graph.
R(s,t): The effective resistance between s and t .
R(s, t) = mini Pe∈E re i 2
i = (ie )e∈E is a unit s-t ﬂow.
e
Pro: In small graphs, it captures the cluster structure!

Small resistance distance

Large resistance distance

Con: (von Luxburg et al. 2010) In large geometric graphs, it
converges to the trivial limit

R (s , t ) ≈

1
ds

+

1
dt

p-Resistance

How we can cure this problem?

p-Resistance : For p ≥ 1, deﬁne

30

25

20

15

10

5

0

0

5

25

30

10
15
20
p = 2

Rp (s , t ) := min
i

re |ie | p

X
e edge

Theorem (Special cases of Rp (s , t ))
p = 1: Shor test path distance

p = 2: Standard resistance distance

p → ∞: Related to s-t -mincut

30

25

20

15

10

5

0

0

30

25

20

15

10

5

25

30

5

10
15
20
p = 1.33

0

0

5

25

30

10
15
20
p = 1.1

Phase transition in the family of p-resistances

Main Theorem:

For large random geometric graphs in R d :

1 If p < 1 + 1/(d − 1), then the “global” contribution dominates
the “local” one.
; meaningful distance

,

2 If p > 1 + 1/(d − 2), then all “global” information vanishes.
; useless distance

/

