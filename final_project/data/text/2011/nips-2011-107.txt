Anatomically Constrained Decoding of Finger
Flexion from Electrocorticographic Signals

Zuoguan Wang
Department of ECSE
Rensselaer Polytechnic Inst.
Troy, NY 12180
wangz6@rpi.edu

Gerwin Schalk
Wadsworth Center
NYS Dept of Health
Albany, NY, 12201
schalk@wadsworth.org

Qiang Ji
Department of ECSE
Rensselaer Polytechnic Inst.
Troy, NY 12180
jiq@rpi.edu

Abstract

Brain-computer interfaces (BCIs) use brain signals to convey a user’s intent. Some
BCI approaches begin by decoding kinematic parameters of movements from
brain signals, and then proceed to using these signals, in absence of movements,
to allow a user to control an output. Recent results have shown that electrocor-
ticographic (ECoG) recordings from the surface of the brain in humans can give
information about kinematic parameters (e.g., hand velocity or ﬁnger ﬂexion). The
decoding approaches in these demonstrations usually employed classical classiﬁ-
cation/regression algorithms that derive a linear mapping between brain signals
and outputs. However, they typically only incorporate little prior information
about the target kinematic parameter. In this paper, we show that different types of
anatomical constraints that govern ﬁnger ﬂexion can be exploited in this context.
Speciﬁcally, we incorporate these constraints in the construction, structure, and
the probabilistic functions of a switched non-parametric dynamic system (SNDS)
model. We then apply the resulting SNDS decoder to infer the ﬂexion of individ-
ual ﬁngers from the same ECoG dataset used in a recent study. Our results show
that the application of the proposed model, which incorporates anatomical con-
straints, improves decoding performance compared to the results in the previous
work. Thus, the results presented in this paper may ultimately lead to neurally
controlled hand prostheses with full ﬁne-grained ﬁnger articulation.

1

Introduction

Brain computer interfaces (BCIs) allow people to control devices directly using brain signals [19].
Because BCI systems directly convert brain signals into commands to control output devices, they
can be used by people with severe paralysis. Core components of any BCI system are the fea-
ture extraction algorithm that extracts those brain signal features that represent the subject’s intent,
and the decoding algorithm that translates those features into output commands to control artiﬁcial
actuators.
Substantial efforts in signal processing and machine learning have been devoted to decoding algo-
rithms. Many of these efforts focused on classifying discrete brain states. The linear and non-linear
classiﬁcation algorithms used in these efforts are reviewed in [12, 1, 10]. The simplest translation
algorithms use linear models to model the relationship between brain signals and limb movements.
This linear relationship can be deﬁned using different algorithms, including multiple linear regres-
sion, pace regression [8], or ridge regression [13]. Other studies have explored the use of non-linear
methods, including neural networks [15], multilinear perceptrons [7], and support vector machines
[7]. Despite substantial efforts, it is still unclear whether non-linear methods can provide consistent
beneﬁts over linear methods in the BCI context.
What is common to current linear and non-linear methods is that they are often used to model the
instantaneous relationship between brain signals and particular behavioral parameters. Thus, they

1

Figure 1: (a) Examples of two ﬂexion traces. (b) A diagram of possible state transitions for ﬁnger
movements.

do not account for the temporal evolution of movement parameters, and can also not directly pro-
vide uncertainty in their predictions. Furthermore, existing methods do not offer opportunities to
incorporate prior knowledge about the target model system. In the example of ﬁnger ﬂexion, ex-
isting methods cannot readily account for the physiological, physical, and mechanical constraints
that affect the ﬂexion of different ﬁngers. The main question we sought to answer with this study
is whether mathematical decoding algorithms that can make use of the temporal evolution of move-
ment parameters, that can incorporate uncertainty, and that can also incorporate prior knowledge,
would provide improved decoding results compared to an existing algorithm that utilized only the
instantaneous relationship.
Some previous studies evaluated models that can utilize temporal evolutions. These include the
Kalman ﬁlter (KF) that explicitly characterizes the temporal evolution of movement parameters [20].
One important beneﬁt offered by Kalman ﬁlters (KFs) is that as a probabilistic method, it can provide
conﬁdence estimates for its results. Hidden Markov Models (HMMs) represent another dynamic
model that can allow to model the latent space both spatially and temporally. As a generalization
of HMMs and KFs, switching linear dynamic systems (SLDSs) provide more expressive power for
sequential data. Standard SLDS has also been used in BCI research, where it was used for inference
of hand motion from motor cortical neurons [21]. Apart from its expressive power, as a probabilistic
graphical model, SLDS has a ﬂexible structural framework that facilitates the incorporation of prior
knowledge by specifying parameters or structures. Nevertheless, no previous study has evaluated a
method that can utilize temporal evolutions, incorporate uncertainty, and make use of different types
of constraints.
The proposed SNDS addresses several limitations of SLDS in terms of modeling the anatomical
constraints of the ﬁnger ﬂexion. We applied the SNDS technique to a dataset used in previous stud-
ies ([8]) to decode from ECoG signals the ﬂexion of individual ﬁngers, and we compared decoding
results when we did and did not use anatomical constraints (i.e., for SNDS/regression and regres-
sion). Our results show that incorporation of anatomical constraints substantially improved decoding
results compared to when we did not incorporate this information. We attribute this improvement to
the following technical advances. First, and most importantly, we introduce a prior model based on
SNDS, which takes advantage of anatomical constraints about ﬁnger ﬂexion. Second, to effectively
model the duration of movement patterns, our model solves the “Markov assumption” problem more
efﬁciently by modeling the dependence of state transition on the continuous state variable. Third,
because estimation of continuous transition is crucial to accurate prediction, we applied kernel den-
sity estimation to model the continuous state transition. Finally, we developed effective learning and
inference methods for the SNDS model.

2 Modeling of Finger Flexion

Figure 1 (a) shows two examples for typical ﬂexion traces. From this ﬁgure, we can make the
following observations:

2

TIMENORMALIZED AMPLITUDE1sS1S2S3ExtensionFlexionRest(a)(b)Figure 2: SNDS model in which St , Yt , Zt represent the moving states, real ﬁnger position and the
measurement of ﬁnger position at time t respectively.

1. The movement of ﬁngers can be categorized into three states: extension (state S1 ), ﬂexion
(state S2 ) and rest (rest state S3 ).
2. For each state, there are particular predominant movement patterns. In the extension state
S1 , the ﬁnger keeps moving away from the rest position. In the ﬂexion state S2 , the ﬁnger
moves back to the rest position. In the rest state S3 , there are only very small movements.
3. For either state S1 or state S2 , the movement speed is relatively low toward full ﬂexion or
full extension, but faster in between. For the rest state, the speed stays close to zero.
4. The natural ﬂexion or extension of ﬁngers are limited to certain ranges due to the physical
constraints of our hand.
5. The transition between different states is not random. Figure 1 (b) shows the four possible
transitions between three states. The extension state and ﬂexion state can transfer to each
other, while the rest state can only follow the ﬂexion state and can only precede the ex-
tension state. This is also easy to understand from our common sense about natural ﬁnger
ﬂexion. When the ﬁnger is extended, it is impossible for it to directly transition into the
rest state without experiencing ﬂexion ﬁrst. Similarly, ﬁngers can not transition from rest
state to ﬂexion state without ﬁrst going through the extension state.
6. Figure 1 (b) discusses four possible ways of state transitions. The probability of these
transitions depends on the ﬁnger position. For example, in the situation at hand, it is
unlikely that the extension state transfers to the ﬂexion state right after the extension state
begins. At the same time, it is more likely to occur when the ﬁnger has extended enough
and is near the end. Similar situations occur at other state transitions.
In summary, the observations described above provide constraints that govern ﬁnger ﬂexion patterns.
Using the methods described below, we will build a computational model that incorporates these
constraints and that can systematically learn the movement patterns from data.

3 Model Construction

In this section, we show how the constraints summarized above are incorporated into the construc-
tion of the ﬁnger ﬂexion model. The overall structure of our model is shown in Figure 2. The top
layer S represents moving states that include the extension state (S1 ), ﬂexion state (S2 ), and rest
state (S3 ). The middle layer (continuous state variable) represents the real ﬁnger position, and the
bottom layer (observation) Z the measurements of ﬁnger positions. We discuss each layer in detail
below.

3.1 State Transitions

In the standard SLDS, the probability of duration τ of state i is, according to the Markov assumption,
deﬁned as follows:
ii (1 − qii )
(1)
P (τ ) = qτ
where qii denotes the transition probability of state i when it makes a self transition. Equation 1
states that the probability of staying in a given state decreases exponentially with time. This behavior
can not provide an adequate representation for many natural temporal phenomena. The natural ﬁnger

3

KDE1tY−tY1tS−tS1tZ−tZFigure 3: (a) Probabilistic density function (PDF) of Yt−1 given St−1 = extension and St =
f lexion; (b) Probabilistic density function of Yt−1 given St−1 = f lexion and St = extension.

ﬂexion is an example. It usually takes a certain amount of time for ﬁngers to ﬁnish extension or
ﬂexion. Thus, the duration of certain movement patterns will deviate from the distribution described
by Equation 1.
This limitation of the state duration model has been investigated by [2, 14]. In fact, in many cases, the
temporal variance is dependent on spacial variance, i.e., state transition is dependent on continuous
state variables. In the context of ﬁnger ﬂexion, as discussed in Section 2, the transition of moving
states is dependent on ﬁnger position. In the model shown in Figure 2, the variable St not only has
an incoming arrow from St−1 but also from Yt−1 :
P (St |Yt−1 , St−1 ) =

1
P (Yt−1 , St−1 )
P (St−1 )
P (Yt−1 |St−1 , St )P (St |St−1 )
P (Yt−1 , St−1 )
P (Yt−1 |St−1 , St )P (St |St−1 )
1
P (Yt−1 |St−1 )
=
where P (Yt−1 |St−1 ) is a normalization term with no relation to St . P (St |St−1 ) is the state tran-
sition, which is same with that in HMM and standard SLDS. P (Yt−1 |St−1 , St ) is the posterior
probability of Yt−1 given state transition from St−1 to St . P (Yt−1 |St−1 , St ) plays a central role in
controlling state transition. It directly relates state transition to ﬁnger position. We take the transition
between extension state and ﬂexion state as an example to give an intuitive explanation. Figure 3(a)
shows that the transition from extension state to ﬂexion state most probably happens at the ﬁnger
position between 1.5 and 2.5, which is near the extension end of movement. Similarly, Figure 3(b)
implies that when the ﬁnger position is between -0.6 and -0.3, which is the ﬂexion end of the ﬁnger
movement, the transition from ﬂexion state to extension state has a high probability.

P (Yt−1 , St−1 , St )

(2)

=

3.2 Continuous State Transition

In SLDSs, the Y transition is linearly modeled. However, in our model, the continuous state transi-
tion is still highly nonlinear during the extension and ﬂexion states. This is mainly because the ﬁnger
movement speed is uneven (fast in the middle but slow at the beginning and end). Modeling the con-
tinuous state transition properly is important for accurate decoding of ﬁnger movement. Here we
propose a nonparametric method with which continuous state transitions are modeled using kernel
density estimation [3]. A Gaussian kernel is the most common choice because of its effectiveness
and tractability. With a Gaussian kernel, the joint estimated joint distribution ˆp(Yt−1 , Yt ) under each
(cid:18) yt−1 − yj−1
(cid:19)
(cid:18) yt − yj
(cid:19)
N(cid:88)
state can be obtained by:
1
hYt
hYt−1
N hYt−1 hYt
j=1
where K (·) is a given kernel function; hYt−1 and hYt are numeric bandwidth for Yt−1 and Yt .
N is the total number of training examples. Our choice for K (·) is a Gaussian kernel K (t) =
(2π)−1/2 e−t2 /2 . Bandwidths hYt−1 and hYt are estimated via a leave-one-out likelihood criterion

ˆp(Yt−1 = yt−1 , Yt = yt ) =

(3)

K

K

.

4

024600.20.40.60.8-1-0.500.5100.511.52(A)(B)NORMALIZED AMPLITUDEPDFLC V (hYt−1 ,hYt

) =

(4)

[9], which maximizes:

ˆp{hYt−1 ,hYt ,−i} (yi−1 , yi )

Figure 4:
(a) kernel locations for ˆp(Yt−1 , Yt ) under extension state; (b) kernel locations for
ˆp(Yt−1 , Yt ) under ﬂexion state; kernel locations for ˆp(Yt−1 , Yt ) under rest state. Numbers on the
axis are the normalized amplitude of the ﬁngers’ ﬂexion.
N(cid:89)
i=1
where ˆp{hYt−1 ,hYt ,−i} (yi−1 , yi ) denotes the density estimated with (yi−1 , yi ) deleted. ˆp(Yt−1 , Yt )
provides a much more accurate representation of continuous state transition than does a linear model.
Figure 4 gives an example of the kernel locations for ˆp(Yt−1 , Yt ) under each of the three states
(trained with part of the data from thumb ﬂexion of subject A). Even though kernel locations do not
represent the joint distribution ˆp(Yt−1 , Yt ), they do help to gain some insight into the relationship
between Yt−1 and Yt . Each graph in Figure 4 describes a temporal transition pattern for each move-
ment pattern. For the extension state, all kernel locations are above the diagonal, which means that
statistically Yt is greater than Yt−1 , i.e., ﬁngers are moving up. Also the farther the kernel locations
are from the diagonal, the larger the value of Yt − Yt−1 , which implies greater moving speed at
time t. In the extension state, the moving speed around average ﬂexion is statistically greater that
around the two extremes (full ﬂexion and extension). Similar arguments can be applied to the ﬂexion
state in Figure 4(b). For the rest state, kernel locations are almost along the diagonal, which means
Yt = Yt−1 , i.e., ﬁngers are not moving. The capability of being able to model the non-linear de-
pendence of speed on position under each state is critical to make a precise prediction of the ﬂexion
trace.

3.3 Observation Model

Z is the observation which is the ﬁnger ﬂexion trace directly mapped from ECoG signals through
other regression algorithms. In this paper, we employ the pace regression for this mapping. Here we
make an assumption that under each movement pattern, Zt depends linearly on Yt , and corrupted by
Gaussian noise. Speciﬁcally, this relationship can be represented by a linear Gaussian [4]:
w(s) ∼ N (µ, σ (s) 2
(5)
Zt = α(s)Yt + w(s) ,
)
Parameters α(s) , µ(s) and σ (s) 2 can be estimated from the training data via: α(s) = E [Z Y ]−E [Z ]E [Y ]
,
E [Y 2 ]−E 2 [Y ]
= E [Z 2 ] − E 2 [Z ] − (E [Z Y ]−E [Z ]E [Y ])2
µ(s) = E [Z ] − αE [Y ] and σ (s) 2
, where E represents the
E [Y 2 ]−E 2 [Y ]
statistical expectation and it is approximated by the sample mean.

3.4 Learning and Inference

3.4.1 Learning

All variables of the SNDS model are incorporated during learning. Finger ﬂexion states are esti-
mated from the behavioral ﬂexion traces (e.g., Figure 1 (a)). Speciﬁcally, samples on the extension
parts of the traces are labeled with state “extension,” samples on the ﬂexion parts of the traces are
labeled with state “ﬂexion,” and samples during rest are labeled with state “rest.” Y is the true ﬂex-
ion trace, which we approximate with the data glove measurements. Z is the observation for which
we use the output of pace regression.

5

024-1012345-0.8-0.6-0.4-0.2-0.8-0.7-0.6-0.5-0.4-0.3-0.2-101234-101234(A)(B)(C)tYtYtY1tY−1tY−1tY−All parameters ¯Φ in our model (Figure 2) consist of three components: the state transition parameter
¯ΦS , continuous state transition parameter ¯ΦY , and observation parameter ¯ΦO . For state transition
parameter ¯ΦS , as discussed in Equation 2, P (St |St−1 ) and P (Yt−1 |St−1 , St ) are learned from
the training data. P (St |St−1 ) can be simply obtained by counting. However, here we need to
enforce the constraints described in section 2(5). The elements in the conditional probability table
of P (St |St−1 ) corresponding to the impossible state transitions are set to zero. P (Yt−1 |St−1 , St ) is
estimated by kernel density estimation using the one-dimensional form of Equation 1. Y transition
parameter ¯ΦY includes the joint distribution ˆp(Yt−1 , Yt ), which can be estimated using Equation 3
in which bandwidths were selected using the criteria in Equation 4. ¯ΦO includes α(s) , µ(s) and σ (s) 2
and they can be estimated using Equations in section 3.3.

3.4.2 Inference

Given the time course of ECoG signals, our goal is to infer the time course of ﬁnger ﬂexion. This
is a typical ﬁltering problem, that is, recursively estimating the posterior distribution of St and Yt
given the observation from the beginning to time t, i.e.,Z1:t :
(cid:88)

(cid:90)
P (St , Yt |Z1:t ) ∝ P (Zt |St , Yt , Z1:t−1 )P (St , Yt |Z1:t−1 )
= P (Zt |St , Yt )
P (St , Yt |St−1 , Yt−1 )P (St−1 , Yt−1 |Z1:t−1 )
(cid:88)

(cid:90)
Yt−1
St−1
P (St |St−1 , Yt−1 )P (Yt |St , Yt−1 )P (St−1 , Yt−1 |Z1:t−1 )
Yt−1
St−1
where P (St−1 , Yt−1 |Z1:t−1 ) is the ﬁltering result of the former step. However we note that not
all the continuous variables in our model follow Gaussian distribution, because kernel density esti-
mation was used to model the dynamics of the continuous state variable. Hence, it is infeasible to
update the posterior distribution P (St , Yt |Z1:t ) analytically in each step. To cope with this issue,
we adopted a numerical sampling method based on particle ﬁltering [6] to propagate and update the
discretely approximated distribution over time.

= P (Zt |St , Yt )

(6)

4 Experiments

4.1 Data Collection

The section gives a brief overview of data collection and feature extraction. A more comprehensive
description is given in [8]. The study included ﬁve subjects – three women (subjects A, C and E)
and two men (subject B and D). Each subject had a 48- or 64-electrode grid placed over the fronto-
parietal-temporal region including parts of sensorimotor cortex. During the experiment, the subjects
were asked to repeatedly ﬂex and extend speciﬁc individual ﬁngers according to visual cues that
were given on a video screen. Typically, the subjects ﬂexed the indicated ﬁnger 3-5 times over a
period of 1.5-3 s and then rested for 2 s. The data collection for each subject lasted 10 min, which
yielded an average of 30 trials for each ﬁnger. The ﬂexion of each ﬁnger was measured by a data
glove (5DT Data Glove 5 Ultra, Fifth Dimension Technologies), which digitized the ﬂexion of each
ﬁnger at 12 bit resolution.
The ECoG signals from the electrode grid were recorded using the general-purpose BCI2000 system
[17, 16] connected to a Neuroscan Synamps2 system. All electrodes were referenced to an inactive
electrode. The signals were further ampliﬁed, bandpass ﬁltered between 0.15 and 200 Hz, and
digitized at 1000 Hz. Each dataset was visually inspected and those channels that did not clearly
contain ECoG activity were removed, which resulted in 48, 63, 47, 64 and 61 channels (for subjects
A-E respectively) for subsequent analyses.

4.2 Feature Extraction

(cid:80)H
Feature extraction was identical to that in [8]. In short, we ﬁrst re-referenced the signals using a
common average reference (CAR), which subtracted 1
q=1 sq from each channel, where H is
H
the total number of channels and sq is the collected signal at the qth channel and at the particular

6

time. For each 100-ms time slice (overlapped by 50 ms) and each channel, we converted these time-
series ECoG data into the frequency domain using an autogressive model of order 20 [11]. Using
this model, we derived frequency amplitudes between 0 to 500 Hz in 1 Hz bins. ECoG features were
extracted by averaging these frequency amplitudes across ﬁve frequency ranges, i.e., 8-12 Hz, 18-24
Hz, 75-115 Hz, 125-159 Hz, and 159-175 Hz. In addition to the frequency features described above,
we obtained the Local Motor Potential (LMP) [18] by averaging the raw time-domain signal at each
channel over 100-ms time window. This resulted in 6 features for each of the ECoG channels, e.g.,
a total of 288 features from 48 channels.

4.3 Evaluation

We deﬁned a movement period as the time between 1000 ms prior to movement onset and 1000
ms after movement offset. Movement onset was deﬁned as the time when the ﬁnger’s ﬂexion value
exceeded an empirically deﬁned threshold. Conversely, movement offset was deﬁned as the time
when the ﬁnger’s ﬂexion value fell below that threshold and no movement onset was detected within
the next 1200 ms [8]. To achieve a dataset with relatively balanced movement and rest periods, we
discarded all data outside the movement period. For each ﬁnger, we used 5-fold cross validation to
evaluate the performance of our modeling and inference algorithms that are described in more detail
in the following sections, i.e., 4/5th of data was used for training and 1/5th of data was used for
testing. Finally, we compared the performance with that achieved using pace regression (which had
been used in [8]). To do this, we used the PaceRegression algorithm implemented in the Java-based
Weka package [5].

4.4 Results

To give an impression of the qualitative improvement of our modeling algorithms described above
compared to pace regression, we ﬁrst provide a qualitative example of the results achieved with each
method on the index ﬁnger of subject A. These results are shown in Figure 5. In this ﬁgure, the top
panel shows results achieved using pace regression and the middle ﬁgure shows results achieved
using SNDS. In each of these two panels, the thin dotted line shows the actual ﬂexion of the index
ﬁnger (concatenated for ﬁve movement periods), and the thick solid line shows the ﬂexion decoded
using pace regression/SNDS. This ﬁgure demonstrates qualitatively that the decoding of ﬁnger ﬂex-
ion achieved using SNDS much better approximates the actual ﬁnger ﬂexion than does pace regres-
sion. We also observe that SNDS produces much smoother predictions, which is mainly due to
the consideration of temporal evolution of movement parameters in SNDS. The bottom panel again
shows the actual ﬂexion pattern (thin dotted line) as well as the ﬁnger ﬂexion state (1=ﬂexion, 2=ex-
tension, 3=rest; thick solid line). These results demonstrate that the state of ﬁnger ﬂexion (which
cannot be directly inferred using a method that does not incorporate a state machine (such as pace
regression)) can be accurately inferred using SNDS. In addition to the qualitative comparison pro-
vided above, Table 1 gives a quantitative comparison between the results achieved using SNDS and
pace regression. The results presented in this table give mean square errors (MSE) (min/max/mean
computed across the cross validation folds). They show that for all ﬁngers and all subjects, the
results achieved using SNDS are superior to those achieved using pace regression. The overall av-
erage of mean square error reduces from 0.86 (pace regression) to 0.64 (SNDS). This improvement
of SNDS compared to pace regression was highly statistically signiﬁcant: when computed a paired
t-test on the mean square errors for all ﬁngers and subjects and between pace regression and SNDS,
the resulting p-value was << 0.001.

5 Discussion

This paper demonstrates that anatomical constraints can be successfully captured to build switched
non-parametric dynamic systems to decode ﬁnger ﬂexion from ECoG signals. We also showed
that the resulting computational models are more accurately able to infer the ﬂexion of individual
ﬁngers than does pace regression, an established technique that has recently been used on the same
dataset. This improvement is possible by dividing the ﬂexion activity into several moving states
(St ), considering the state transition over time, establishing speciﬁc state transition by considering
its dependence on the ﬁnger position (continuous state variable Yt ) and modeling the individual
transition pattern of continuous state variables under each moving state accurately by using kernel
density estimation.

7

Figure 5: (a) Actual ﬁnger ﬂexion (dotted trace) and decoded ﬁnger ﬂexion (solid trace) using pace
regression (mean square error 0.68); (b) Actual ﬁnger ﬂexion (dotted trace) and decoded ﬁnger
ﬂexion (solid trace) using SNDS (mean square error 0.40); (c) Actual ﬁnger ﬂexion (dotted trace)
and state prediction (solid trace).

Table 1: Comparison of decoding performance between pace regression and SNDS. Results
are given, for a particular ﬁnger and subject, as mean square errors between actual and decoded
movement (minimum, maximum and mean across all cross validation folds).
Ring Finger
Index Finger Middle Finger
Thumb
Alg.
Subject
0.77/0.93/0.86
0.74/0.84/0.77
0.61/0.68/0.64
0.49/0.64/0.58
pace
A
0.64/0.86/0.73
0.57/0.76/0.63
0.40/0.51/0.44
0.27/0.45/0.35
SNDS
A
0.43/0.62/0.52
0.47/0.87/0.68
0.46/0.99/0.63
0.56/0.81/0.65
pace
B
B
SNDS
0.31/0.62/0.46
0.32/0.80/0.44
0.32/0.67/0.49
0.25/0.50/0.39
0.79/1.01/0.89
0.79/1.07/0.87
0.73/0.79/0.78
0.69/1.03/0.83
pace
C
0.44/0.76/0.61
0.48/0.60/0.54
0.35/0.54/0.46
0.33/0.85/0.53
SNDS
C
0.98/1.17/1.09
0.90/1.05/0.99
0.82/1.21/1.07
1.18/1.42/1.29
pace
D
0.92/1.04/0.96
0.82/0.90/0.87
0.75/1.08/0.94
0.97/1.28/1.15
SNDS
D
0.85/1.04/0.94
0.56/0.98/0.80
0.76/1.15/0.96
0.94/1.09/1.03
pace
E
E
SNDS
0.75/1.01/0.84
0.57/1.00/0.75
0.44/0.77/0.63
0.63/0.82/0.73

Little Finger Avg.
0.73
0.74/0.85/0.81
0.54
0.52/0.68/0.59
0.62
0.46/0.85/0.60
0.23/0.64/0.40
0.43
0.87
0.81/1.12/0.97
0.56
0.60/0.95/0.73
1.14
1.17/1.43/1.27
0.98
0.94/1.19/1.0
0.93
0.71/1.05/0.90
0.43/0.90/0.68
0.71

Generally, this improvement in decoding performance is possible, because the computational model
puts different types of constraints on the possible ﬂexion predictions. In other words, the model may
not be able to produce all possible ﬁnger ﬂexion patterns. However, the constraints that we put on
these ﬁnger ﬂexions are based on the actual natural ﬁnger ﬂexions, and thus should not be limiting
for other natural ﬂexions of individual ﬁngers. However, to what extent these constraints used here
may generalize to those of simultaneous movements of multiple ﬁngers remains to be explored.
There are some directions in which this work could be further improved. First, to reduce the com-
putational complexity caused by kernel density estimation, non-linear transition functions can be
used to model the continuous state transitions. Second, more efﬁcient inference methods could be
developed to replace standard particle sampling. Finally, the methods presented in this paper could
be extended to allow for simultaneous decoding of all ﬁve ﬁngers instead of one at a time.

References
[1] Bashashati, Ali, Fatourechi, Mehrdad, Ward, Rabab K., and Birch, Gary E. A survey of signal
processing algorithms in brain-computer interfaces based on electrical brain signals. J. Neural

8

02.557.51012.51517.520(B)02.557.51012.51517.520(A)TIME (s)NORMALIZED AMPLITUDE02.557.51012.51517.520(C)Eng., 4(2):R32+, June 2007. ISSN 1741-2552. doi: 10.1088/1741-2560/4/2/R03.
[2] Ferguson, J. Variable duration models for speech. In Proc. Symp. on the Application of Hidden
Markov Models to Text and Speech, pp. 143–79, 1980.
[3] Frank, Eibe, Trigg, Leonard, Holmes, Geoffrey, and Witten, Ian H. Naive Bayes for Regres-
sion. In Machine Learning, pp. 5–26, 1998.
[4] Friedman, Nir, Goldszmidt, Moises, and Lee, Thomas J. Bayesian network classiﬁcation with
continuous attributes: Getting the best of both discretization and parametric ﬁtting. In ICML,
pp. 179–187. Morgan Kaufmann, 1998.
[5] Hall, Mark, Frank, Eibe, Holmes, Geoffrey, Pfahringer, Bernhard, Reutemann, Peter, and Wit-
ten, Ian H. The weka data mining software: an update. SIGKDD Explor. Newsl., 11:10–18,
November 2009. ISSN 1931-0145.
[6] Isard, Michael and Blake, Andrew. Condensation - conditional density propagation for visual
tracking. International Journal of Computer Vision, 29:5–28, 1998.
[7] Kim, Kyung Hwan, Kim, Sung Shin, and Kim, Sung June. Superiority of nonlinear map-
ping in decoding multiple single-unit neuronal spike trains: A simulation study. Journal of
Neuroscience Methods, 150(2):202 – 211, 2006. ISSN 0165-0270.
[8] Kub ´anek, J, Miller, K J, Ojemann, J G, Wolpaw, J R, and Schalk, G. Decoding ﬂexion of
individual ﬁngers using electrocorticographic signals in humans. J Neural Eng, 6(6):066001–
066001, Dec 2009.
[9] Loader, Clive R. Bandwidth Selection: Classical or Plug-In? The Annals of Statistics, 27(2):
415–438, 1999. ISSN 00905364. URL http://www.jstor.org/stable/120098.
[10] Lotte, F, Congedo, M, L ´ecuyer, A, Lamarche, F, and Arnaldi, B. A review of classiﬁcation
algorithms for EEG-based brain-computer interfaces. J Neural Eng, 4(2):1–1, Jun 2007.
[11] Marple, S. L. Digital spectral analysis: with applications. Prentice-Hall, Inc., Upper Saddle
River, NJ, USA, 1986. ISBN 0-132-14149-3.
[12] Muller, K.-R., Anderson, C.W., and Birch, G.E. Linear and nonlinear methods for brain-
computer interfaces. Neural Systems and Rehabilitation Engineering, IEEE Transactions on,
11(2):165 –169, june 2003. ISSN 1534-4320. doi: 10.1109/TNSRE.2003.814484.
[13] Mulliken, Grant H., Musallam, Sam, and Andersen, Richard A. Decoding Trajectories from
Posterior Parietal Cortex Ensembles. J. Neurosci., 28(48):12913–12926, 2008.
[14] Russell, M. and Moore, R. Explicit modelling of state occupancy in hidden Markov models
for automatic speech recognition. In ICASSP, volume 10, pp. 5–8, Apr 1985.
[15] Sanchez, Justin C., Erdogmus, Deniz, and Principe, Jose C. Comparison between nonlinear
mappings and linear state estimation to model the relation from motor cortical neuronal ﬁring
to hand movements. In Proceedings of SAB Workshop, pp. 59–65, 2002.
[16] Schalk, G and Mellinger, J. A Practical Guide to Brain-Computer Interfacing with BCI2000.
Springer, 2010.
[17] Schalk, G., McFarland, D. J., Hinterberger, T., Birbaumer, N., and Wolpaw, J. R. BCI2000: a
general-purpose brain-computer interface (BCI) system. Biomedical Engineering, IEEE Trans-
actions on, 51(6):1034–1043, June 2004.
[18] Schalk, G, Kub ´anek, J, Miller, K J, Anderson, N R, Leuthardt, E C, Ojemann, J G, Limbrick, D,
Moran, D, Gerhardt, L A, and Wolpaw, J R. Decoding two-dimensional movement trajectories
using electrocorticographic signals in humans. J Neural Eng, 4(3):264–75, Sep 2007.
[19] Wolpaw, Jonathan R. Brain-computer interfaces (BCIs) for communication and control. In
ACM SIGACCESS, Assets ’07, pp. 1–2. ACM, 2007.
[20] Wu, Wei, Black, Michael J., Gao, Yun, Bienenstock, Elie, Serruya, Mijail, Shaikhouni, Ali,
and Donoghue, John P. Neural decoding of cursor motion using a Kalman ﬁlter, 2003.
[21] Wu, Wei, Black, M.J., Mumford, D., Gao, Yun, Bienenstock, E., and Donoghue, J.P. A switch-
ing Kalman ﬁlter model for the motor cortical coding of hand motion. In IEMBS, volume 3,
pp. 2083 – 2086 Vol.3, sept. 2003. doi: 10.1109/IEMBS.2003.1280147.

9

