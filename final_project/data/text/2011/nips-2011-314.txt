NEWTRON: an Efﬁcient Bandit algorithm for Online
Multiclass Prediction

Elad Hazan
Department of Industrial Engineering
Technion - Israel Institute of Technology
Haifa 32000 Israel
ehazan@ie.technion.ac.il

Satyen Kale
Yahoo! Research
4301 Great America Parkway
Santa Clara, CA 95054
skale@yahoo-inc.com

Abstract

We present an efﬁcient algorithm for the problem of online multiclass prediction
with bandit feedback in the fully adversarial setting. We measure its regret with
respect to the log-loss deﬁned in [AR09], which is parameterized by a scalar α.
We prove that the regret of N EW TRON is O(log T ) when α is a constant that does
√
not vary with horizon T , and at most O(T 2/3 ) if α is allowed to increase to inﬁnity
with T . For α = O(log T ), the regret is bounded by O(
T ), thus solving the open
problem of [KSST08, AR09]. Our algorithm is based on a novel application of the
online Newton method [HAK07]. We test our algorithm and show it to perform
well in experiments, even when α is a small constant.

1

Introduction

Classiﬁcation is a fundamental task of machine learning, and is by now well understood in its basic
variants. Unlike the well-studied supervised learning setting, in many recent applications (such as
recommender systems, ad selection algorithms, etc.) we only obtain limited feedback about the true
label of the input (e.g., in recommender systems, we only get feedback on the recommended items).
Several such problems can be cast as online, bandit versions of multiclass prediction problems1 . The
general framework, called the “contextual bandits” problem [LZ07], is as follows. In each round,
the learner receives an input x in some high dimensional feature space (the “context”), and produces
an action in response, and obtains an associated reward. The goal is to minimize regret with respect
to a reference class of policies specifying actions for each context.
In this paper, we consider the special case of multiclass prediction, which is a fundamental problem
in this area introduced by Kakade et al [KSST08]. Here, a learner obtains a feature vector, which
is associated with an unknown label y which can take one of k values. Then the learner produces
a prediction of the label, ˆy . In response, only 1 bit of information is given, whether the label is
correct or incorrect. The goal is to design an efﬁcient algorithm that minimizes regret with respect
to a natural reference class of policies: linear predictors. Kakade et al [KSST08] gave an efﬁcient
algorithm, dubbed BAND I TRON. Their algorithm attains regret of O(T 2/3 ) for a natural multiclass
√
hinge loss, and they ask the question whether a better regret bound is possible. While the EXP4
T log T ) regret bound, it is highly inefﬁ-
algorithm [ACBFS03], applied to this setting, has an O(
√
cient, requiring O(T n/2 ) time per iteration, where n is the dimension of the feature space. Ideally,
one would like to match or improve the O(
T log T ) regret bound of the EXP4 algorithm with an
efﬁcient algorithm (for a suitable loss function).
This question has received considerable attention. In COLT 2009, Abernethy and Rakhlin [AR09]
formulated the open question precisely as minimizing regret for a suitable loss function in the fully

1For the basic bandit classiﬁcation problem see [DHK07, RTB07, DH06, FKM05, AK08, MB04, AHR08].

1

√
adversarial setting (and even offered a monetary reward for a resolution of the problem). Some
special cases have been successfully resolved:
the original paper of [KSST08], gives a O(
T )
√
bound in the noiseless large-margin case. More recently, Crammer and Gentile [CG11] gave a
T log T ) regret bound via an efﬁcient algorithm based on the upper conﬁdence bound method
O(
under a semi-adversarial assumption on the labels: they are generated stochastically via a speciﬁc
linear model (with unknown parameters which change over time). Yet the general (fully adversarial)
case has been unresolved as of now.
In this paper we address this question and design a novel algorithm for the fully adversarial setting
with its expected regret measured with respect to log-loss function deﬁned in [AR09], which is
parameterized by a scalar α. When α is a constant independent of T , we get a much stronger
√
guarantee than required by the open problem: the regret is bounded by O(log T ). In fact, the regret
is bounded by O(
T ) even for α = Θ(log T ). Our regret bound for larger values of α increases
smoothly to a maximum of O(T 2/3 ), matching that of BAND I TRON in the worst case.
The algorithm is efﬁcient to implement, and it is based on the online Newton method introduced
in [HAK07]; hence we call the new algorithm N EW TRON. We implement the algorithm (and a
faster variant, PN EW TRON) and test it on the same data sets used by Kakade et al [KSST08]. The
experiments show improved performance over the BAND I TRON algorithm, even for α as small as 10.

2 Preliminaries

2.1 Notation
Let [k ] denote the set of integers {1, 2, . . . , k}, and ∆k ⊆ Rk the set of distributions on [k ].
product, i.e. v · w = (cid:80)n
For any Rn , let 1, 0 denote the all 1s and all 0s vectors respectively, and let I denote the identity
matrix in Rn×n . For two (row or column) vectors v, w ∈ Rn , we denote by v · w their usual inner
i=1 viwi . We denote by (cid:107)v(cid:107) the (cid:96)2 norm of v. For a vector v ∈ Rn , denote
by diag(v) the diagonal matrix in Rn×n where the ith diagonal entry equals vi .
For a matrix W ∈ Rk×n , denote by W1 , W2 , . . . , Wk its rows, which are (row) vectors in Rn .
To avoid deﬁning unnecessary notation, we will interchangeably use W to denote both a matrix in
Rk×n or a (column) vector in Rkn . The vector form of the matrix W is formed by arranging its
rows one after the other, and then taking the transpose (i.e., the vector [W1 |W2 | · · · |Wk ](cid:62) ). Thus,
for two matrices V and W, V · W denotes their inner product in their vector form. For i ∈ [n] and
l ∈ [k ], denote by Eil the matrix which has 1 in its (i, l)th entry, and 0 everywhere else.
For a matrix W, we denote by (cid:107)W(cid:107) the Frobenius norm of W, which is also the usual (cid:96)2 norm
of the vector form of W, and so the notation is consistent. Also, we denote by (cid:107)W(cid:107)2 the spectral
norm of W, i.e. the largest singular value of W.
For two matrices W and V denote by W ⊗ V their Kronecker product [HJ91]. For two square sym-
metric matrices W, V of like order, denote by W (cid:23) V the fact that W − V is positive semideﬁnite,
i.e. all its eigenvalues are non-negative. A useful fact of the Kronecker product is the following:
if W, V are symmetric matrices such that W (cid:23) V, and if U is a positive semideﬁnite symmetric
matrix, then W ⊗ U (cid:23) V ⊗ U. This follows from the fact that if W, U are both symmetric, positive
semideﬁnite matrices, then so is their Kronecker product W ⊗ U.

2.2 Problem setup

Learning proceeds in rounds. In each round t, for t = 1, 2, . . . , T , we are presented a feature vector
xt ∈ X , where X ⊆ Rn , and (cid:107)x(cid:107) ≤ R for all x ∈ X . Here R is some speciﬁed constant. Associated
with xt is an unknown label yt ∈ [k ]. We are required to produce a prediction, ˆyt ∈ [k ], as the label
of xt . In response, we obtain only 1 bit of information: whether ˆyt = yt or not. In particular, when
ˆyt (cid:54)= yt , the identity of yt remains unknown (although one label, ˆyt , is ruled out).
The learner’s hypothesis class is parameterized by matrices W ∈ Rk×n with (cid:107)W(cid:107) ≤ D , for some
speciﬁed constant D . Denote the set of such matrices by K. Given a matrix W ∈ K with the rows

2

W1 , W2 , . . . , Wk , the prediction associated with W for xt is
Wi · xt .
ˆyt = arg max
i∈[k]
While ideally we would like to minimize the 0 − 1 loss suffered by the learner, for computational
reasons it is preferable to consider convex loss functions. A natural choice used in Kakade et
al [KSST08] is the multi-class hinge loss:

[1 − Wyt · xt + Wi · xt ]+ .
(cid:96)(W, (xt , yt )) = max
i∈[k]\yt
Other suitable loss functions (cid:96)(·, ·) may also be used. The ultimate goal of the learner is to minimize
T(cid:88)
T(cid:88)
regret, i.e.
t=1
t=1

(cid:96)(Wt , (xt , yt )) − min
W(cid:63)∈K

(cid:96)(W(cid:63) , (xt , yt )).

Regret :=

.

P(W, x)i =

A different loss function was proposed in an open problem by Abernethy and Rakhlin in COLT
2009 [AR09]. We use this loss function in this paper and deﬁne it now.
We choose a constant α which parameterizes the loss function. Given a matrix W ∈ K and an
example (x, y) ∈ X × [k ], deﬁne the function P : K × X → ∆k as
(cid:80)
exp(αWi · x)
j exp(αWj · x)
Now let p = P(W, x). Suppose we make our prediction ˆyt by sampling from p.
(cid:32)
(cid:33)
A natural loss function for this scheme is log-loss deﬁned as follows:
(cid:80)
exp(αWy · x)
log(py ) = − 1
(cid:96)(W, (x, y)) = − 1
(cid:17)
(cid:16)(cid:80)
j exp(αWk · x)
log
α
α
j exp(αWj · x)
= −Wy · x +
1
α
The log-loss is always positive. As α becomes large, this log-loss function has the property that
when the prediction given by W for x is correct, it is very close to zero, and when the prediction is
incorrect, it is roughly proportional to the margin of the incorrect prediction over the correct one.
The algorithm and its analysis depend upon the the gradient and Hessian of the loss function w.r.t.
W. The following lemma derives these quantities (proof in full version). Note that in the following,
W is to be interpreted as a vector W ∈ Rkn .
Lemma 1. Fix a matrix W ∈ K and an example (x, y) ∈ X × [k ], and let p = P(W, x). Then we
have

log

.

∇(cid:96)(W, (x, y)) = (p − ey ) ⊗ x and ∇2 (cid:96)(W, (x, y)) = α(diag(p) − pp(cid:62) ) ⊗ xx(cid:62) .
In the analysis, we need bounds on the smallest non-zero eigenvalue of the (diag(p) − pp(cid:62) ) factor
of the Hessian. Such bounds are given in the full version2 For the sake of the analysis, however, the
matrix inequality given in Lemma 2 below sufﬁces. It is given in terms of a parameter δ , which is
the minimum probability of a label in any distribution P(W, x).
Deﬁnition 1. Deﬁne δ := minW∈K,x∈X mini P(W, x)i .
We have the following (loose) bound on δ , which follows easily using the fact that |Wi · x| ≤ RD:
δ ≥ exp(−2αRD)/k .
(1)
Lemma 2. Let W ∈ K be any weight matrix, and let H ∈ Rk×k be any symmetric matrix such that
H1 = 0. Then we have
H ⊗ xx(cid:62) .
∇2 (cid:96)(W, (x, y)) (cid:23) αδ
(cid:107)H(cid:107)2
2Our earlier proof used Cheeger’s inequality. We thank an anonymous referee for a simpliﬁed proof.

3

Algorithm 1 N EW TRON. Parameters: β , γ
1: Initialize W(cid:48)
1 = 0.
2: for t = 1 to T do
Obtain the example xt .
3:
t = (1 − γ ) · pt + γ
t , xt ), and set p(cid:48)
Let pt = P(W(cid:48)
k 1.
4:
Output the label ˆyt by sampling from p(cid:48)
t . This is equivalent to playing Wt = W(cid:48)
t with
5:
probability (1 − γ ), and Wt = 0 with probability γ .
· (cid:0) 1
(cid:1) ⊗ xt and κt := p(cid:48)
Obtain feedback, i.e. whether ˆyt = yt or not.
if ˆyt = yt then
Deﬁne ˜∇t := 1−pt (yt )
k 1 − eyt
t ( ˆyt ) · (cid:0)e ˆyt − 1
k 1(cid:1) ⊗ xt and κt := 1.
t (yt ).
p(cid:48)
t (yt )
else
Deﬁne ˜∇t := pt ( ˆyt )
p(cid:48)
end if
Deﬁne the cost function
ft (W) := ˜∇t · (W − W(cid:48)
t ) +
t(cid:88)
τ =1

κtβ ( ˜∇t · (W − W(cid:48)
t ))2 .

W(cid:48)
t+1 := arg min
W∈K

6:
7:
8:
9:
10:
11:
12:

13:

Compute

(cid:107)W(cid:107)2 .

1
2D

(2)

(3)

1
2

ft (W) +

14: end for

2.3 The FTAL Lemma

Our algorithm is based on the FTAL algorithm [HAK07]. This algorithm is an online version of
the Newton step algorithm in ofﬂine optimization. The following lemma speciﬁes the algorithm,
specialized to our setting, and gives its regret bound. The proof is in the full version.
Lemma 3. Consider an online convex optimization problem over some convex, compact domain
2 βt (vt · w − αt )2 , where the
K ⊆ Rn of diameter D with cost functions ft (w) = (vt · w − αt ) + 1
vector vt ∈ Rn and scalars αt , βt are chosen by the adversary such that for some known parameters
r, a, b, we have (cid:107)vt(cid:107) ≤ r , βt ≥ a, and |βt (vt · w − αt )| ≤ b, for all w ∈ K. Then the algorithm
t−1(cid:88)
that, in round t, plays
τ =1

wt := arg min
w∈K

ft (w)

has regret bounded by O( nb2
a log( DraT
b

)).

3 The NEWTRON algorithm

Our algorithm for bandit multiclass learning algorithm, dubbed N EW TRON, is shown as Algorithm 1
above. In each iteration, we randomly choose a label from the distribution speciﬁed by the current
weight matrix on the current example mixed with the uniform distribution over labels speciﬁed by
an exploration parameter γ . The parameter γ (which is similar to the exploration parameter used
in the EXP3 algorithm of [ACBFS03]) is eventually tuned based on the value of the parameter α
in the loss function (see Corollary 5). We then use the observed feedback to construct a quadratic
loss function (which is strongly convex) that lower bounds the true loss function in expectation (see
Lemma 7) and thus allows us to bound the regret. To do this we construct a randomized estimator
˜∇t for the gradient of the loss function at the current weight matrix. Furthermore, we also choose a
parameter κt , which is an adjustment factor for the strongly convexity of the quadratic loss function
ensuring that its expectation lower bounds the true loss function. Finally, we compute the new loss
matrix using a Follow-The-Regularized-Leader strategy, by minimizing the sum of all quadratic loss
functions so far with (cid:96)2 regularization. As described in [HAK07], this convex program can be solved
in quadratic time, plus a projection on K in the norm induced by the Hessian.

4

Statement and discussion of main theorem. To simplify notation, deﬁne the function (cid:96)t : K → R
as (cid:96)t (W) = (cid:96)(W, (xt , yt )). Let Et [·] denote the conditional expectation with respect to the σ -ﬁeld
Ft , where Ft is the smallest σ -ﬁeld with respect to which the predictions ˆyk , for k = 1, 2, . . . , t − 1,
are measurable.
With this notation, we can state our main theorem giving the regret bound:
Theorem 4. Given α, δ and γ ≤ 1
2 , suppose we set β ≤ min{ αδ
4RD } in the N EW TRON
1
10 + η ,
k }. The N EW TRON algorithm has the following
20αR2D2 . Let ν = max{ δ
algorithm, for η = γ log(k)
2 , γ
(cid:17)
(cid:16) kn
T(cid:88)
bound on the expected regret:
ν β log T + γ log(k)
α
t=1

E[(cid:96)t (Wt )] − (cid:96)t (W(cid:63) ) = O

T

Before giving the proof theorem 4, we ﬁrst state a corollary (a simple optimization of parameters,
proved in the full version) which shows how γ in Theorem 4 can be set appropriately to get a smooth
interpolation between O(log(T )) and O(T 2/3 ) regret based on the value of α.
(cid:26)
(cid:27)
Corollary 5. Given α, there is a setting of γ so that the regret of N EW TRON is bounded by

min

c

exp(4αRD)
α

log(T ),

6cRDT 2/3

,

where the constant c = O(k3n) is independent of α.

Discussion of the bound. The parameter α is inherent to the log-loss function as deﬁned in
[AR09]. Our main result as given in Corollary 5 which entails logarithmic regret for constant α,
contains a constant which depends exponentially on α. Empirically, it seems that α can be set to a
small constant, say 10 (see Section 4), and still have good performance.
Note that even when α grows with T , as long as α ≤ 1
√
8RD log(T ), the regret can be bounded as
T ), thus solving the open problem of [KSST08, AR09] for log-loss functions with this
O(cRD
range of α.
We can say something even stronger - our results provide a “safety net” - no matter what the value
of α is, the regret of our algorithm is never worse than O(T 2/3 ), matching the bound of the BAN -
D I TRON algorithm (although the latter holds for the multiclass hinge loss).

Analysis.

Proof. (Theorem 4.) The optimization (3) is essentially running the algorithm from Lemma 3 on
2D (Eil · W)2
K with the cost functions ft (W), with additional nk initial ﬁctitious cost functions 1
for i ∈ [n] and l ∈ [k ]. These ﬁctitious cost functions can be thought of as regularization. While
technically these ﬁctitious cost functions are not necessary to prove our regret bound, we include
them since this seems to give better experimental performance and only adds a constant to the regret.
We now apply the regret bound of Lemma 3 by estimating the parameters r, a, b. This is a simple
technical calculation and done in Lemma 6 below, which yields the values r = R
ν , a = β ν , b = 1.
Hence, the regret bound of Lemma 3 implies that for any W(cid:63) ∈ K,
(cid:17)
(cid:16) kn
T(cid:88)
ν β log T
t=1
Note that the bound above excludes the ﬁctitious cost functions since they only add a constant addi-
tive term to the regret, which is absorbed by the O(log T ) term. Similarly, we have also suppressed
additive constants arising from the log( DraT
) term in the regret bound of Lemma 3.
b
(cid:20)
(cid:21)
Taking expectation on both sides of the above bound with respect to the randomness in the algorithm,
(cid:16) kn
(cid:17)
and using the speciﬁcation (2) of ft (W) we get
κtβ ( ˜∇t · (W(cid:48)
˜∇t · (W(cid:48)
t − W(cid:63) ) − 1
t − W(cid:63) ))2
ν β log T
2

t ) − ft (W(cid:63) ) = O
ft (W(cid:48)

= O

(4)

E

.

.

5

(cid:20)
By Lemma 7 below, we get that
˜∇t · (W(cid:48)
t − W(cid:63) ) − 1
t ) − (cid:96)t (W(cid:63) ) ≤ E
(cid:96)t (W(cid:48)
2
t
Furthermore, we have

κtβ ( ˜∇t · (W(cid:48)
t − W(cid:63) ))2

(cid:21)

+ 20ηR2D2 .

(5)

t ) ≤ γ log(k)
[(cid:96)t (Wt )] − (cid:96)(W(cid:48)
E
(6)
,
α
t
t with probability (1 − γ ) and Wt = 0 with probability γ , and (cid:96)t (0) = log(k)
since Wt = W(cid:48)
α .
(cid:17)
(cid:16) kn
T(cid:88)
Plugging (5) and (6) in (4), and using η = γ log(k)
20αR2D2 ,
E[(cid:96)(Wt )] − (cid:96)(W(cid:63) ) = O
ν β log T + γ log(k)
α
t=1

T

.

+ 20ηR2D2 .

κtβ ( ˜∇t · (W(cid:48)
t − W(cid:63) ))2

We now state two lemmas that were used in the proof of Theorem 4. The ﬁrst one (proof in the full
version) obtains parameter settings to use Lemma 3 in Theorem 4.
Lemma 6. Assume β ≤ 1
4RD and γ ≤ 1
2 . Let ν = max{ δ
k }. Then the following are valid
2 , γ
settings for the parameters r, a, b: r = R
ν , a = β ν and b = 1.
The next lemma shows that in each round, the expected regret of the inner FTAL algorithm with ft
cost functions is larger than the regret of N EW TRON.
(cid:20)
(cid:21)
10 + η and γ ≤ 1
Lemma 7. For β = αδ
2 , we have
˜∇t · (W(cid:48)
t − W(cid:63) ) − 1
t ) − (cid:96)t (W(cid:63) ) ≤ E
(cid:96)t (W(cid:48)
2
t
Proof. The intuition behind the proof is the following. We show that Et [ ˜∇t ] = (p − eyt ) ⊗ xt ,
t ). Next, we show that Et [κt ˜∇t ˜∇(cid:62)
t ] = Ht ⊗ xtx(cid:62)
which by Lemma 1 equals ∇(cid:96)t (W(cid:48)
for some
matrix Ht s.t. Ht1 = 0. By upper bounding (cid:107)Ht(cid:107), we then show (using Lemma 2) that for any
t
Ψ ∈ K we have
∇2 (cid:96)t (Ψ) (cid:23) βHt ⊗ xtx(cid:62)
t .
The stated bound then follows by an application of Taylor’s theorem.
The technical details for the proof are as follows. First, note that
[ ˜∇t ] · (W(cid:48)
[ ˜∇t · (W(cid:48)
t − W(cid:63) )] = E
t − W(cid:63) ).
E
p(cid:48)
t
t
(cid:18) 1
(cid:19)
We now compute Et [ ˜∇t ].
(cid:88)
t (yt ) · 1 − pt (yt )
[ ˜∇t ] =
E
p(cid:48)
k
t (yt )
y (cid:54)=yt
t
= (pt − eyt ) ⊗ xt .
Next, we have
[κt ˜∇t ˜∇(cid:62)
[κt ( ˜∇t · (W(cid:48)
t − W(cid:63) )(cid:62) E
t − W(cid:63) ))2 ] = (W(cid:48)
t − W(cid:63) ).
t ](W(cid:48)
E
t
t
(cid:34)
(cid:19)(cid:62)
(cid:19) (cid:18) 1
(cid:18) 1
(cid:19)2 ·
(cid:18) 1 − pt (yt )
We now compute Et [κt ˜∇t ˜∇(cid:62)
t ].
[κt ˜∇t ˜∇(cid:62)
t (yt ) · κt
1 − eyt
p(cid:48)
(cid:19)(cid:62) ⊗ xtx(cid:62)
E
(cid:19)2 ·
(cid:18) pt (y)
(cid:18)
t ] =
p(cid:48)
(cid:88)
t (yt )
k
k
t
ey − 1
t (y) ·
p(cid:48)
1
p(cid:48)
t
t (y)
k
y (cid:54)=yt
=: Ht ⊗ xtx(cid:62)
t ,

1 − eyt
(cid:19) (cid:18)
ey − 1
k

(cid:19) ⊗ xt

e ˆyt − 1
k

t (y) · pt (y)
p(cid:48)
p(cid:48)
t (y)

·

(8)

(9)

·

1 − eyt

+

+

1

(cid:18)

1

(7)

(10)

6

where Ht is the matrix in the brackets above. We note a few facts about Ht . First, note that
(ey − 1
k 1) · 1 = 0, and so Ht1 = 0. Next, the spectral norm (i.e.
(cid:88)
(cid:107)Ht(cid:107)2 ≤ (cid:13)(cid:13) 1
(cid:13)(cid:13)ey − 1
k 1(cid:13)(cid:13)2 ≤ 10,
(cid:13)(cid:13)2
largest eigenvalue) of Ht is
bounded as:
k 1 − eyt
p(cid:48)
1
(1 − γ )2
t (y)
+
y (cid:54)=yt
2 . Now, for any Ψ ∈ K, by Lemma 2, for the speciﬁed value of β we have
for γ ≤ 1
∇2 (cid:96)t (Ψ) (cid:23) αδ
Ht ⊗ xtx(cid:62)
t .
10
Now, by Taylor’s theorem, for some Ψ on the line segment connecting W(cid:48)
t to W(cid:63) , we have
t ) · (W(cid:63) − W(cid:48)
(cid:96)t (W(cid:63) )−(cid:96)t (W(cid:48)
t ) = ∇(cid:96)t (W(cid:48)
t )(cid:62) [∇2 (cid:96)t (Ψ)](W(cid:63) − W(cid:48)
(W(cid:63) − W(cid:48)
1
t ) +
t ),
2
t ](W(cid:63) − W(cid:48)
Ht ⊗ xtx(cid:62)
(W(cid:63) − W(cid:48)
≥ ((pt − eyt ) ⊗ xt ) · (W(cid:63) − W(cid:48)
t )(cid:62) [
αδ
1
t ) +
t ),
2
10
(12)

(11)

where the last inequality follows from (11). Finally, we have
t )(cid:62) [ηHt ⊗ xtx(cid:62)
t (cid:107)2(cid:107)W(cid:63) − W(cid:48)
η(cid:107)Ht ⊗ xtx(cid:62)
t ) ≤ 1
t ](W(cid:63) − W(cid:48)
(W(cid:63) − W(cid:48)
t(cid:107)2 ≤ 20ηR2D2 , (13)
1
2
2
since (cid:107)W(cid:63) − W(cid:48)
t(cid:107) ≤ 2D . Adding inequalities (12) and (13), rearranging the result and using (7),
(8), (9), and (10) gives the stated bound.
4 Experiments

While the theoretical regret bound for N EW TRON is O(log T ) when α = O(1), the provable constant
in O(·) notation is quite large, leading one to question the practical performance of the algorithm.
The main reason for the large constant is that the analysis requires the β parameter to be set ex-
tremely small to get the required bounds. In practice, however, one can keep β a tunable parameter
and try using larger values. In this section, we give experimental evidence (replicating the exper-
iments of [KSST08]) that shows that the practical performance of the algorithm is quite good for
small values of α (like 10), and not too small values of β (like 0.01, 0.0001).

Data sets. We used three data sets from [KSST08]: SYNS E P, SYNNONS E P, and R EUT ER S4. The
ﬁrst two, SYNS E P and SYNNONS E P, are synthetic data sets, generated according to the description
given in [KSST08]. These data sets have the same 106 feature vectors with 400 features. There are
9 possible labels. The data set SYNS E P is linearly separable, whereas the data set SYNNONS E P is
made inseparable by artiﬁcially adding 5% label noise. The R EU T ER S4 data set is generated from
the Reuters RCV1 corpus. There are 673, 768 documents in the data set with 4 possible labels, and
346, 810 features. Our results are reported by averaging over 10 runs of the algorithm involved.

Algorithms. We implemented the BAND I TRON and N EW TRON algorithms3 . The N EW TRON al-
gorithm is signiﬁcantly slower than BAND I TRON due to its quadratic running time. This makes it
infeasible for really large data sets like R EUT ER S4. To surmount this problem, we implemented
an approximate version of N EW TRON, called PN EW TRON4 , which runs in linear time per iteration
and thus has comparable speed to BAND I TRON. PN EW TRON does not have the same regret guaran-
tees of N EW TRON however. To derive PN EW TRON, we can restate N EW TRON equivalently as (see
[HAK07]):
τ and bt = (cid:80)t−1
D I +(cid:80)t−1
t )(cid:62)At (W − W(cid:48)(cid:48)
W∈K(W − W(cid:48)(cid:48)
W(cid:48)
t = arg min
t )
τ =1 κτ β ˜∇τ ˜∇(cid:62)
τ =1 (1 − κτ β ˜∇τ ·Wτ ) ˜∇τ .
t = −A−1
where W(cid:48)(cid:48)
t bt , for At = 1
PN EW TRON makes the following change, using the diagonal approximation for the Hessian, and
usual Euclidean projections:
t )(cid:62) (W − W(cid:48)(cid:48)
W∈K(W − W(cid:48)(cid:48)
W(cid:48)
t = arg min
t )
3We did not implement the Conﬁdit algorithm of [CG11] since our aim was to consider algorithms in the
fully adversarial setting.
4Short for pseudo-N EW TRON. The “P” may be left silent so that it’s almost N EW TRON, but not quite.

7

D I + (cid:80)t−1
bt = (cid:80)t−1
τ =1 diag(κτ β ˜∇τ ˜∇(cid:62)
t = −A−1
where W(cid:48)(cid:48)
τ ) and bt is the same as before,
t bt , for At = 1
τ =1 (1 − κτ β ˜∇τ · Wτ ) ˜∇τ .
In our experiments, we chose K to be the unit (cid:96)2 ball in Rkn , so D = 1. We
Parameter settings.
also choose α = 10 for all experiments in the log-loss. For BAND I TRON, we chose the value of
γ speciﬁed in [KSST08]: γ = 0.014, 0.006 and 0.05 for SYNS E P, SYNNONS E P and R EUT ER S4
respectively. For N EW TRON and PN EW TRON, we chose γ = 0.01, 0.006 and 0.05 respectively. The
other parameter for N EW TRON and PN EW TRON, β , was set to the values β = 0.01, 0.01, and 0.0001
respectively. We did not tune any of the parameters α, β and γ for N EW TRON or PN EW TRON.

Evaluation. We evaluated the algorithms in terms of their error
rate, i.e.
the fraction of prediction mistakes made as a function
of time. Experimentally, PN EW TRON has quite similar perfor-
mance to N EW TRON, but is signiﬁcantly faster. Figure 4 shows
how BAND I TRON, N EW TRON and PN EW TRON compare on the
SYNNONS E P data set for 104 examples5 .
It can be seen that
PN EW TRON has similar behavior to N EW TRON, and is not much
worse.
The rest of the experiments were conducted using only BAN -
D I TRON and PN EW TRON. The results are shown in ﬁgure 4. It
can be clearly seen that PN EW TRON decreases the error rate much
faster than BAND I TRON. For the SYNS E P data set, PN EW TRON
very rapidly converges to the lowest possible error rate due to
setting the exploration parameter γ = 0.01, viz. 0.01 × 8/9 =
0.89%. In comparison, the ﬁnal error for BAND I TRON is 1.91%.
For the SYNNONS E P data set, PN EW TRON converges rapidly to
its ﬁnal value of 11.94%. BAND I TRON remains at a high error
level until about 104 examples, and at the very end catches up
with and does slightly better than PN EW TRON, ending at 11.47%.
For the R EU T ER S4 data set, both BAND I TRON and PN EW TRON
decrease the error rate at roughly same pace; however PN EW TRON still obtains better performance
consistently by a few percentage points. In our experiments, the ﬁnal error rate for PN EW TRON is
13.08%, while that for BAND I TRON is 18.10%.

Figure 1: Log-log plots of error
rates vs. number of examples
for BAND I TRON, N EW TRON
and PN EW TRON on SYNNON -
S E P with 104 examples.

Figure 2: Log-log plots of error rates vs. number of examples for BAND I TRON and PN EW TRON on
different data sets. Left: SYNS E P. Middle: SYNNONS E P. Right: R EU T ER S4.

5 Future Work

Some interesting questions remain open. Our theoretical guarantee applies only to the quadratic-
time N EW TRON algorithm. Is it possible to obtain similar regret guarantees for a linear time algo-
rithm? Our regret bound has an exponentially large constant, which depends on the loss functions
parameters. Does there exist an algorithm with similar regret guarantees but better constants?

5 In the interest of reducing running time for N EW TRON, we used a smaller data set.

8

10210310410−0.810−0.710−0.610−0.510−0.410−0.310−0.2SynNonSep: number of exampleserror rate  BanditronNewtronPNewtron10210310410510610−310−210−1100SynSep: number of exampleserror rate  BanditronPNewtron10210310410510610−0.910−0.810−0.710−0.610−0.510−0.410−0.310−0.2SynNonSep: number of exampleserror rate  BanditronPNewtron10210310410510610−0.810−0.710−0.610−0.510−0.410−0.310−0.2Reuters4: number of examplesError rate  BanditronPNewtronT -regret

[AHR08]

[AK08]

[AR09]

[CG11]

[DH06]

[DHK07]

References
[ACBFS03] Peter Auer, Nicol `o Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. The non-
stochastic multiarmed bandit problem. SIAM J. Comput., 32:48–77, January 2003.
Jacob Abernethy, Elad Hazan, and Alexander Rakhlin. Competing in the dark: An
efﬁcient algorithm for bandit linear optimization. In COLT, pages 263–274, 2008.
Baruch Awerbuch and Robert Kleinberg. Online linear optimization and adaptive rout-
ing. J. Comput. Syst. Sci., 74(1):97–114, 2008.
√
Jacob Abernethy and Alexander Rakhlin. An efﬁcient bandit algorithm for
in online multiclass prediction? In COLT, 2009.
Koby Crammer and Claudio Gentile. Multiclass classiﬁcation with bandit feedback
using adaptive regularization. In ICML, 2011.
Varsha Dani and Thomas P. Hayes. Robbing the bandit: less regret in online geometric
optimization against an adaptive adversary. In SODA, pages 937–943, 2006.
Varsha Dani, Thomas Hayes, and Sham Kakade. The price of bandit information for
online optimization. In NIPS. 2007.
Abraham D. Flaxman, Adam Tauman Kalai, and H. Brendan McMahan. Online convex
optimization in the bandit setting: gradient descent without a gradient. In SODA, pages
385–394, 2005.
Elad Hazan, Amit Agarwal, and Satyen Kale. Logarithmic regret algorithms for online
convex optimization. Machine Learning, 69(2-3):169–192, 2007.
R.A. Horn and C.R. Johnson. Topics in Matrix Analysis. Cambridge University Press,
Cambridge, 1991.
Sham M. Kakade, Shai Shalev-Shwartz, and Ambuj Tewari. Efﬁcient bandit algorithms
for online multiclass prediction. In ICML’08, pages 440–447, 2008.
John Langford and Tong Zhang. The epoch-greedy algorithm for multi-armed bandits
with side information. In NIPS, 2007.
H. Brendan McMahan and Avrim Blum. Online geometric optimization in the bandit
setting against an adaptive adversary. In COLT, pages 109–123, 2004.
Alexander Rakhlin, Ambuj Tewari, and Peter Bartlett. Closing the gap between bandit
and full-information online optimization: High-probability regret bound. Technical
Report UCB/EECS-2007-109, EECS Department, University of California, Berkeley,
Aug 2007.

[KSST08]

[FKM05]

[HAK07]

[HJ91]

[LZ07]

[MB04]

[RTB07]

9

