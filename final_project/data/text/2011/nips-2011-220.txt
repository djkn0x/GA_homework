An Exact Algorithm for F-Measure Maximization

Krzysztof Dembczy ´nski
Institute of Computing Science
Pozna ´n University of Technology
Pozna ´n, 60-695 Poland
kdembczynski@cs.put.poznan.pl

Willem Waegeman
Mathematical Modelling, Statistics
and Bioinformatics, Ghent University
Ghent, 9000 Belgium
willem.waegeman@ugent.be

Weiwei Cheng
Mathematics and Computer Science
Philipps-Universit ¨at Marburg
Marburg, 35032 Germany
cheng@mathematik.uni-marburg.de

Eyke H ¨ullermeier
Mathematics and Computer Science
Philipps-Universit ¨at Marburg
Marburg, 35032 Germany
eyke@mathematik.uni-marburg.de

Abstract

The F-measure, originally introduced in information retrieval, is nowadays rou-
tinely used as a performance metric for problems such as binary classiﬁcation,
multi-label classiﬁcation, and structured output prediction. Optimizing this mea-
sure remains a statistically and computationally challenging problem, since no
closed-form maximizer exists. Current algorithms are approximate and typically
rely on additional assumptions regarding the statistical distribution of the binary
response variables. In this paper, we present an algorithm which is not only com-
putationally efﬁcient but also exact, regardless of the underlying distribution. The
algorithm requires only a quadratic number of parameters of the joint distribu-
tion (with respect to the number of binary responses). We illustrate its practical
performance by means of experimental results for multi-label classiﬁcation.

1

Introduction

While being rooted in information retrieval [1], the so-called F-measure is nowadays routinely used
as a performance metric for different types of prediction problems, including binary classiﬁcation,
multi-label classiﬁcation (MLC), and certain applications of structured output prediction, like text
chunking and named entity recognition. Compared to measures like error rate in binary classiﬁcation
and Hamming loss in MLC, it enforces a better balance between performance on the minority and the
majority class, respectively, and, therefore, it is more suitable in the case of imbalanced data. Given a
prediction h = (h1 , . . . , hm ) ∈ {0, 1}m of an m-dimensional binary label vector y = (y1 , . . . , ym )
2 (cid:80)m
(e.g., the class labels of a test set of size m in binary classiﬁcation or the label vector associated with
i=1 yi + (cid:80)m
(cid:80)m
a single instance in MLC), the F-measure is deﬁned as follows:
∈ [0, 1] ,
i=1 yihi
F (y , h) =
i=1 hi
(cid:80)m
(cid:80)m
where 0/0 = 1 by deﬁnition. This measure essentially corresponds to the harmonic mean of preci-
(cid:80)m
(cid:80)m
sion prec and recall rec:
i=1 yihi
i=1 yihi
i=1 yi
i=1 hi
One can generalize the F-measure to a weighted harmonic average of these two values, but for the
sake of simplicity, we stick to the unweighted mean, which is often referred to as the F1-score or the
F1-measure.

prec(y , h) =

(1)

,

rec(y , h) =

.

1

Despite its popularity in experimental settings, only a few methods for training classiﬁers that di-
rectly optimize the F-measure have been proposed so far. In binary classiﬁcation, the existing al-
gorithms are extensions of support vector machines [2, 3] or logistic regression [4]. However, the
most popular methods, including [5], rely on explicit threshold adjustment. Some algorithms have
also been proposed for structured output prediction [6, 7, 8] and MLC [9, 10, 11]. In these two
application domains, three different aggregation schemes of the F-measure can be distinguished,
namely the instance-wise, the micro-, and the macro-averaging. One should carefully distinguish
these versions, as algorithms optimized with a given objective are usually performing suboptimally
for other (target) evaluation measures.
All the above algorithms intend to optimize the F-measure during the training phase. Conversely,
in this article we rather investigate an orthogonal problem of inference from a probabilistic model.
Modeling the ground-truth as a random variable Y , i.e., assuming an underlying probability distri-
(cid:88)
bution p(Y ) on {0, 1}m , the prediction h
∗
F that maximizes the expected F-measure is given by
∗
Ey∼p(Y ) [F (y , h)] = arg max
p(Y = y) F (y , h).
F = arg max
h
h∈{0,1}m
h∈{0,1}m
y∈{0,1}m
independence of the Yi , i.e., p(Y = y) = (cid:81)m
As discussed in Section 2, this setting was mainly examined before by [12], under the assumption of
i (1 − pi )1−yi with pi = p(Yi =1). Indeed, ﬁnding
i=1 pyi
the maximizer (2) is in general a difﬁcult problem. Apparently, there is no closed-form expression,
and a brute-force search is infeasible (it would require checking all 2m combinations of prediction
vector h). At ﬁrst sight, it also seems that information about the entire joint distribution p(Y ) is
needed to maximize the F-measure. Yet, as will be shown in this paper, the problem can be solved
more efﬁciently. In Section 3, we present a general algorithm for maximizing the F-measure that
requires only m2 + 1 parameters of the joint distribution. If these parameters are given, the exact
solution can be obtained in time o(m3 ). This result holds regardless of the underlying distribution.
In particular, unlike algorithms such as [12], we do not require independence of the binary response
variables (labels). While being natural for problems like binary classiﬁcation, this assumption is
indeed not tenable in domains like MLC and structured output prediction. A discussion of existing
methods for F-measure maximization, along with results indicating their shortcomings, is provided
in Section 2. An experimental comparison in the context of MLC is presented in Section 4.

(2)

2 Existing Algorithms for F-Measure Maximization

Current algorithms for solving (2) make different assumptions to simplify the problem. First of
all, the algorithms operate on a constrained hypothesis space, sometimes justiﬁed by theoretical
arguments. Secondly, they guarantee optimality only for speciﬁc distributions p(Y ).

2.1 Algorithms Based on Label Independence

By assuming independence of the random variables Y1 , ..., Ym , the optimization problem (2) can be
substantially simpliﬁed. It has been shown independently in [13] and [12] that the optimal solution
always contains the labels with the highest marginal probabilities pi , or no labels at all. As a conse-
quence, only a few hypotheses h (m + 1 instead of 2m ) need to be examined, and the computation
of the expected F-measure can be performed in an efﬁcient way.
(cid:40) (cid:81)m
Lewis [13] showed that the expected F-measure can be approximated by the following expression
under the assumption of independence:1
2 (cid:80)m
i=1 (1 − pi ),
if h = 0
(cid:80)m
i=1 pi+(cid:80)m
Ey∼p(Y ) [F (y , h)] (cid:39)
if h (cid:54)= 0
i=1 pi hi
,
i=1 hi
This approximation is exact for h = 0, while for h (cid:54)= 0, an upper bound of the error can easily be
determined [13].
Jansche [12], however, has proposed an exact procedure, called maximum expected utility frame-
work (MEUF), that takes marginal probabilities p1 , p2 , . . . , pm as inputs and solves (2) in time
1 In the following, we denote 0 and 1 as vectors containing all zeros and ones, respectively.

2

(3)

(4)

O(m4 ). He noticed that (2) can be solved via outer and inner maximization. Namely, (2) can be
transformed into an inner maximization
h(k)∗
Ey∼p(Y ) [F (y , h)] ,
where Hk = {h ∈ {0, 1}m | (cid:80)m
= arg max
h∈Hk
i=1 hi = k}, followed by an outer maximization
∗
Ey∼p(Y ) [F (y , h)] .
arg max
F =
h
h∈{h(0)∗
,...,h(m)∗ }
The outer maximization (4) can be done by simply checking all m + 1 possibilities. The main effort
is then devoted for solving the inner maximization (3). According to Theorem 2.1, to solve (3)
for a given k , we need to check only one vector h in which hi = 1 for the k labels with highest
marginal probabilities pi . The remaining problem is the computation of the expected F-measure in
(3). This expectation cannot be computed naively, as the sum is over exponentially many terms.
But the F-measure is a function of integer counts that are bounded, so it can normally only assume
a much smaller number of distinct values. The cardinality of its domain is indeed exponential
in m, but the cardinality of its range is polynomial in m, so the expectation can be computed in
polynomial time. As a result, Jansche [12] obtains a procedure that is cubic in m for computing (3).
He also presents approximate variants of this procedure, reducing its complexity from cubic to
quadratic or even to linear. The results of the quadratic-time approximation, according to [12], are
almost indistinguishable in practice from the exact algorithm; but still the overall complexity of the
approach is O(m3 ).
If the independence assumption is violated, the above methods may produce predictions being far
away from the optimal one. The following result shows this concretely for the method of Jansche.2
Proposition 2.1. Let hJ be a vector of predictions obtained by MEUF, then the worst-case regret
(cid:2)F (Y , h
F ) − F (Y , hJ )(cid:3)) = 1,
converges to one in the limit of m, i.e.,
∗
(EY
m→∞ sup
lim
p
where the supremum is taken over all possible distributions p(Y ).

Additionally, one can easily construct families of probability distributions that obtain a relatively
fast convergence rate as a function of m.
2.2 Algorithms Based on the Multinomial Distribution
ity mass is distributed over vectors y containing only a single positive label, i.e., (cid:80)m
Solving (2) becomes straightforward in the case of a speciﬁc distribution in which the probabil-
i=1 yi = 1,
corresponding to the multinomial distribution. This was studied in [14] in the setting of so-called
non-deterministic classiﬁcation.
Theorem 2.2 (Del Coz et al. [14]). Denote by y(i) a vector for which yi = 1 and all the other
entries are zeros. Assume that p(Y ) is a joint distribution such that p(Y = y(i)) = pi . The
∗
maximizer h
F of (2) consists of the k labels with the highest marginal probabilities, where k is the
k(cid:88)
ﬁrst integer for which
j=1

pj ≥ (1 + k)pk+1 ;

if there is no such integer, then h = 1.

2.3 Algorithms Based on Thresholding on Ordered Marginal Probabilities

Since all the methods so far rely on the fact that the optimal solution contains ones for the labels with
the highest marginal probabilities (or consists of a vector of zeros), one may expect that thresholding
on the marginal probabilities (hi = 1 for pi ≥ θ , and hi = 0 otherwise) will provide a solution to
2Some of the proofs have been attached to the paper as supplementary material and will also be provided
later with the extended version of the paper.

3

(2) in general. Obviously, to ﬁnd an optimal threshold θ , access to the entire joint distribution is
needed. However, this is not the main problem here, since in the next section, we will show that
only a polynomial number of parameters of the joint distribution is needed. What is more interesting
is the observation that the F-maximizer is in general not consistent with the order of marginal label
probabilities. In fact, the regret can be substantial, as shown by the following result.
Proposition 2.3. Let hT be a vector of predictions obtained by putting a threshold on sorted
(cid:2)F (Y , h
F ) − F (Y , hT )(cid:3)) ≥ max(0,
marginal probabilities in the optimal way, then the worst-case regret is lower bounded by
1
− 2
∗
(EY
m + 4
6
where the supremum is taken over all possible distributions p(Y ).3

sup
p

),

This is a rather surprising result in light of the existence of many algorithms that rely on ﬁnding a
threshold for maximizing the F-measure [5, 9, 10]. While being justiﬁed by Theorems 2.1 and 2.3
for speciﬁc applications, this approach does not yield optimal predictions in general.

3 An Exact Algorithm for F-Measure Maximization

= arg max
h∈Hk

We now introduce an exact and efﬁcient algorithm for computing the F-maximizer without using any
additional assumption on the probability distribution p(Y ). While adopting the idea of decomposing
the problem into an outer and an inner maximization, our algorithm differs from Jansche’s in the way
the inner maximization is solved. As a key element, we consider equivalence classes for the labels
in terms of the number of ones in the vectors h and y . The optimization of the F-measure can
be substantially simpliﬁed by using these equivalence classes, since h and y then only appear in
Theorem 3.1. Let sy = (cid:80)m
the numerator of the objective function. First, we show that only m2 + 1 parameters of the joint
distribution p(Y ) are needed to compute the F-maximizer.
i=1 yi . The solution of (2) can be computed by solely using p(Y = 0)
and the values of
i, s ∈ {1, . . . , m} ,
pis = p(Yi = 1 , sy = s),
which constitute an m × m matrix P.
2 (cid:80)m
i=1 yihi
sy + k

(cid:88)
Proof. The inner optimization problem (3) can be formulated as follows:
h(k)∗
Ey∼p(Y ) [F (y , h)] = arg max
h∈Hk
y∈{0,1}m
(cid:88)
m(cid:88)
= arg max
2
h∈Hk
y∈{0,1}m
i=1
pis = (cid:88)
Furthermore, one can sum up the probabilities p(y) for all ys with an equal value of sy . By using
yip(y) ,
y∈{0,1}m :sy =s
m(cid:88)
m(cid:88)
one can transform (5) into the following expression:
s=1
i=1
As a result, one does not need the whole distribution to solve (3), but only the values of pis , which
can be given in the form of an m × m matrix P with entries pis . For the special case of k = 0, we
have h(k)∗
= 0 and Ey∼p(Y ) [F (y , 0)] = p(Y = 0).
3Finding the exact value of the supremum is an interesting open question.

The sums can be swapped, resulting in

p(y)yi
sy + k

.

pis
s + k

h(k)∗

h(k)∗

= arg max
h∈Hk

2

hi

p(y)

.

(5)

(6)

hi

4

Algorithm 1 General F-measure Maximizer
INPUT: matrix P and probability p(Y = 0)
deﬁne matrix W with elements given by Eq. 7;
compute F = PW
for k = 1 to m do
m(cid:88)
solve the inner optimization problem (3) that can be reformulated as:
h(k)∗
= arg max
hi fik
h∈Hk
i=1
(cid:105)
(cid:104)
by setting hi= 1 for top k elements in the k-th column of matrix F, and hi= 0 for the rest;
m(cid:88)
store a value of
F (y , h(k)∗
)
i=1

Ey∼p(Y )

h(k)∗
i

= 2

fik ;

2

end for
for k = 0 take h(k)∗
= 0, and Ey∼p(Y ) [F (y , 0)] = p(Y = 0);
solve the outer optimization problem (4):
∗
arg max
F =
h
h∈{h(0)∗
,...,h(m)∗ }
∗
∗
F and Ey∼p(Y ) [F (y , h
return h
F )];

Ey∼p(Y ) [F (y , h)] ;

If the matrix P is given, the solution of (2) is straight-forward. To simplify the notation, let us
introduce an m × m matrix W with elements
1
wsk =
s + k
The resulting algorithm, referred to as General F-measure Maximizer (GFM), is summarized in
Algorithm 1 and its time complexity is analyzed in the following theorem.
Theorem 3.2. Algorithm 1 solves problem (2) in time o(m3 ) assuming that the matrix P of m2
parameters and p(Y = 0) are given.

s, k ∈ {1, . . . , m} ,

(7)

,

Proof. We can notice in (6) that the sum s + k assumes at most m + 1 values (it varies from s to
m(cid:88)
s + m). By introducing the matrix W with elements (7), we can simplify (6) to
h(k)∗
= arg max
h∈Hk
i=1
where fik are elements of a matrix F = PW. To solve (8), it is enough to ﬁnd the top k elements
(i.e., the elements with the highest values) in the k-th column of matrix F, which can be carried
out in linear time [15]. The solution of the outer optimization problem (4) is then straight-forward.
Consequently, the complexity of the algorithm is dominated by a matrix multiplication that is solved
naively in O(m3 ), but faster algorithms working in O(m2.376 ) are known [16].4

hi fik ,

(8)

2

Let us brieﬂy discuss the properties of our algorithm in comparison to the other algorithms discussed
in Section 2. First of all, MEUF is characterized by a much higher time complexity being O(m4 )
for the exact version. The recommended approximate variant reduces this complexity to O(m3 ).
In turn, the GFM algorithm has a complexity of o(m3 ). In addition, let us also remark that this
complexity can be further decreased if the number of distinct values of sy with non-zero probability
mass is smaller than m.
Moreover, the MEUF framework will not deliver an exact F-maximizer if the assumption of inde-
pendence is violated. On the other hand, MEUF relies on a smaller number of parameters (m values

4The complexity of the Coppersmith-Winograd algorithm [16] is more of theoretical signiﬁcance, since
practically this algorithm outperforms the na¨ıve method only for huge matrices.

5

representing marginal probabilities). Our approach needs m2 + 1 parameters, but then computes the
maximizer exactly. Since estimating a larger number of parameters is statistically more difﬁcult, it
is a priori unclear which method performs better in practice.
it is enough to rely on the order of the marginal probabilities pi = (cid:80)m
Our algorithm can also be tailored for ﬁnding an optimal threshold. It is then simpliﬁed due to
constraining the number of hypotheses. Instead of ﬁnding the top k elements in the k-th column,
s=1 pis . As a result, there is
no need to compute the entire matrix F; instead, only the elements that correspond to the k highest
marginal probabilities for each column k are needed. Of course, the thresholding can be further
simpliﬁed by verifying only a small number t < m of thresholds.

4 Application of the Algorithm

p(Y = y | x) =

(9)

p(Yk = yk | x, y1 , . . . , yk−1 )

The GFM algorithm can be used whenever an estimation of the distribution p(Y ) or, alternatively,
estimates of the matrix P and probability p(Y = 0) are available. In this section, we focus on the
application of GFM in the multi-label setting. Thus, we consider the task of predicting a vector y =
(y1 , y2 , . . . , ym ) ∈ {0, 1}m given another vector x = (x1 , x2 , . . . , xn ) ∈ Rn as input attributes. To
this end, we train a classiﬁer h(x) on a training set {(xi , y i )}N
i=1 and perform inference for a given
test vector x so as to deliver an optimal prediction under the F-measure (1). Thus, we optimize
the performance for each instance individually (instance-wise F-measure), in contrast to macro- and
micro-averaging of the F-measure.
We follow an approach similar to Conditional Random Fields (CRFs) [17, 18], which estimates
the joint conditional distribution p(Y | x). This approach has the additional advantage that one can
easily sample from the estimated distribution. The underlying idea is to repeatedly apply the product
m(cid:89)
rule of probability to the joint distribution of the labels Y = (Y1 , . . . , Ym ):
k=1
This approach, referred to as Probabilistic Classiﬁer Chains (PCC), has proved to yield state-of-
the-art performance in MLC [19]. Learning in this framework can be considered as a procedure
that relies on constructing probabilistic classiﬁers for estimating p(Yk = yk |x, y1 , . . . , yk−1 ), inde-
pendently for each k = 1, . . . , m. To sample from the conditional joint distribution p(Y | x), one
follows the chain and picks the value of label yk by tossing a biased coin with probabilities given by
the k-th classiﬁer. Based on a sample of observations generated in this way, our GFM algorithm can
be used to perform the optimal inference under F-measure.
In the experiments, we train PCC by using linear regularized logistic regression. By plugging the
log-linear model into (9), it can be shown that pairwise dependencies between labels yi and yj can be
modeled. We tune the regularization parameter using 3-fold cross-validation. To perform inference,
we draw for each test example a sample of 200 observations from the estimated conditional distri-
bution. We then apply ﬁve inference methods. The ﬁrst one (H) estimates marginal probabilities
pi (x) and predicts 1 for labels with ˆpi (x) ≥ 0.5; this is an optimal strategy for the Hamming loss.
The second method (MEUF) uses the estimates ˆpi (x) for computing the F-measure by applying the
MEUF method. If the labels are independent, this method computes the F-maximizer exactly. As a
third method, we use the approximate cubic-time variant of MEUF with the parameters suggested
in the original paper [12]. Finally, we use GFM and its variant that ﬁnds the optimal threshold
(GFM-T).
Before showing the results of PCC on benchmark datasets, let us discuss results for two synthetic
models, one with independent and another one with dependent labels. Plots and a description of the
models are given in Fig. 1. As can be observed, MEUF performs the best for independent labels,
while GFM approaches its performance if the sample size increases. This is coherent with our the-
oretical analysis, since GFM needs to estimate more parameters. However, in the case of dependent
labels, MEUF performs poorly, even for a larger sample size, since the underlying assumption is not
satisﬁed. Interestingly, both approximate variants perform very similarly to the original algorithms.
We also see that GFM has a huge advantage over MEUF regarding the time complexity.5

5All the computations are performed on a typical desktop machine.

6

Figure 1: The plots show the performance under the F-measure of the inference methods: GFM, its threshold-
ing variant GFM-T, MEUF, and its approximate version MEUF Approx. Left: the performance as a function
2 (i − 1) +(cid:80)i−1
of sample size generated from independent distribution with pi = 0.12 and m = 25 labels. Center: similarly
as above, but the distribution is deﬁned according to (9), where all p(Yi = yi | y1 , . . . , yi−1 ) are deﬁned by
logistic models with a linear part − 1
j=1 yj . Right: running times as a function of the number of
labels with a sample size of 200. All the results are averaged over 50 trials.
Table 1: Experimental results on four benchmark datasets. For each dataset, we give the number of labels (m)
and the size of training and test sets (in parentheses: training/test set). A “-” symbol indicates that an algorithm
did not complete the computations in a reasonable amount of time (several days). In bold: the best results for a
given dataset and performance measure.

M ETHOD

HAMM ING MACRO -F M ICRO -F
LO S S

F

IN FERENCE
T IM E [ S ]

HAMM ING MACRO -F M ICRO -F
LO S S

F

IN FERENCE
T IM E [ S ]

SC EN E : m = 6 (1211 /11 69 )

Y EA S T: m = 14 (1 50 0 / 9 17 )

PCC H
PCC GFM
PCC GFM -T
PCC MEUF A P PROX .
PCC MEUF
BR
BR MEUF A P PROX .
BR MEUF

0 .1 0 30
0 .1 3 41
0 .1 3 43
0 .1323
0 .1 3 23
0 .102 3
0 .1 140
0 .1 1 40

0 . 667 3
0 .7159
0 . 715 4
0 .7131
0 . 713 1
0 .6591
0 .7 04 8
0 . 704 8

0 .6 675 0 .5 7 79
0 .6 91 5 0 .7 10 1
0 .6 908 0 .7 0 94
0 .69 1 0 0 .6 9 77
0 .6 910 0 .6 9 77
0 .66 02 0 . 55 4 2
0 .6 94 8 0 .6 46 8
0 .6 948 0 .6 4 68

0 . 969
0 .9 85
1 . 031
1 .4 06
1 . 297
1 . 1 25
1 .5 79
2 . 094

0 . 20 4 6
0 . 23 22
0 . 23 2 4
0 . 229 5
0 . 22 9 2
0 .1 98 7
0 .2 2 4 8
0 . 22 6 3

0 .3633
0 .4 0 3 4
0 .4039
0 .4 0 30
0 .4034
0 .3 34 9
0 .4 09 8
0 .4096

0 .6391 0 .6160
0 .6 5 54 0 .6 4 79
0 .6553 0 .6476
0 .6 5 51 0 .64 69
0 .6557 0 .6477
0 . 62 99 0 . 6 03 9
0 . 66 01 0 . 6 52 7
0 .6591 0 .6523

3 .704
3 . 796
3 .907
10 .00 0
11 .453
0 . 6 40
7 .1 10
10 .031

ENRON : m = 53 (1123 / 5 79 )

PCC H
PCC GFM
PCC GFM -T
PCC MEUF A P PROX .
PCC MEUF
BR
BR MEUF A P PROX .
BR MEUF

0 .0 4 71
0 .0 5 21
0 .0 5 21
0 .0523
0 .0 5 23
0 .046 8
0 .0 513
0 .0 5 13

0 . 114 1
0 . 161 8
0 .1619
0 .1612
0 . 161 2
0 .1049
0 .1 55 4
0 . 155 4

0 .5 185 0 .4 8 92
0 .5 943 0 .6 0 06
0 .5 94 8 0 .6 01 1
0 .59 3 2 0 .6 0 07
0 .5 932 0 .6 0 07
0 .52 23 0 . 48 2 1
0 .5 96 9 0 .5 94 7
0 .5 969 0 .5 9 47

1 9 5 . 061
1 9 4 . 889
1 96 .0 30
1 08 1 .8 37
6 6 76 . 14 5
8 . 5 94
8 50 .4 94
7 0 14 . 45 3

M ED IAM I L L : m = 101 (3 09 99 / 12 91 4 )
0 .0 30 4
0 . 03 4 8
0 . 03 4 8
0 . 035 0
-
0 .0 30 4
0 .3 5 0 8
-

1 4 05 . 77 2
0 . 55 77 0 . 5 42 9
1420 .663
0 .5849 0 .5734
0 . 5 85 4 0 .5 7 37
1 4 64 . 14 7
0 .5 8 71 0 .57 40 3 08 58 2 .0 19
-
-
-
0 . 56 23 0 . 5 46 2
2 07 . 65 5
0 . 58 89 0 . 5 74 4 2 58 43 1 . 12 5
-
-
-

0 .0 93 1
0 .1491
0 . 14 9 9
0 .1 5 04
-
0 .1 42 9
0 .1 91 7
-

The results on four commonly used benchmark datasets6 with known training and test sets are pre-
sented in Table 1, which also includes some basic statistics of these datasets. We additionally present
results of the binary relevance (BR) approach which trains an independent classiﬁer for each label
(we used the same base learner as in PCC). We also apply the MEUF method on marginals delivered
by BR. This is the best we can do if only marginals are known. From the results of the F-measure, we
can clearly state that all approaches tailored for this measure obtain better results. However, there is
no clear winner among them. It seems that in practical applications, the theoretical results concern-
ing the worst-case scenario do not directly apply. Also, the number of parameters to be estimated
does not play an important role. However, GFM drastically outperforms MEUF in terms of com-
putational complexity. For the Mediamill dataset, the MEUF algorithm in its exact version did not
complete the computations in a reasonable amount of time. The running times for the approximate
version are already unacceptably high for this dataset.
We also report results for the Hamming loss, macro- and micro-averaging F-measure. We can see,
for example, that approaches appropriate for Hamming loss obtain the best results regarding this
measure. The macro and micro F-measure are presented mainly as a reference. The former is
computed by averaging the F-measure label-wise, while the latter concatenates all test examples and
computes a single value over all predictions. These two variants of the F-measure are not directly
optimized by the algorithms used in the experiment.

6These datasets are taken from the MULAN (http://mulan.sourceforge.net/datasets.html) and LibSVM
(http://www.csie.ntu.edu.tw/∼cjlin/libsvmtools/datasets/multilabel.html) repositories.

7

204060801000.140.160.18sample sizeF1llllllllllllGFMGFM−TMEUFMEUF Approx204060801000.20.30.40.50.6sample sizeF1lllllllllll1020304050050100150# of labelstime [s]lllllllll5 Discussion

The GFM algorithm can be considered for maximizing the macro F-measure, for example, in a
similar setting as in [10], where a speciﬁc Bayesian on-line model is used. In order to maximize the
macro F-measure, the authors sample from the graphical model to ﬁnd an optimal threshold. The
GFM algorithm may solve this problem optimally, since, as stated by the authors, the independence
of labels is lost after integrating out the model parameters. Theoretically, one may also consider a
direct maximization of the micro F-measure with GFM, but the computational burden is rather high
in this case.
Interestingly, there are no other MLC algorithms that maximize the F-measure in an instance-wise
manner. We also cannot refer to other results already published in the literature, since usually only
the micro- and macro-averaged F-measures are reported [20, 11]. This is rather surprising, especially
since some closely related measures are often computed in the instance-wise manner in empirical
studies. For example, the Jaccard distance (sometimes referred to as accuracy [21]), which differs
from the F-measure in an additional term in the denominator, is commonly used in such a way.
The situation is slightly different in structured output prediction, where algorithms for instance-wise
maximization of the F-measure do exist. These include, for example, struct SVM [6], SEARN [8],
and a speciﬁc variant of CRFs [7]. Usually, these algorithms are based on additional assumptions,
like label independence in struct SVM. The GFM algorithm can also be easily tailored for maxi-
mizing the instance-wise F-measure in structured output prediction, in a similar way as presented
above. If the structured output classiﬁer is able to model the joint distribution from which we can
easily sample observations, then the use of the algorithm is straight-forward. An application of this
kind is planned as future work.
Surprisingly, in both papers [8] and [6], experimental results are reported in terms of micro F-
measure, although the algorithms maximize the instance-wise F-measure on the training set. Need-
speciﬁc case where (cid:80)m
less to say, one should not expect such an approach to result in optimal performance for the micro-
averaged F-measure. Despite being related to each other, these two measures coincide only in the
(cid:80)m
i=1 (yi + hi ) is constant for all test examples. The discrepancy between these
measures strongly depends on the nature of the data and the classiﬁer used. For high variability in
i=1 (yi + hi ), a signiﬁcant difference between the values of these two measures is to be expected.
The use of the GFM algorithm in binary classiﬁcation seems to be superﬂuous, since in this case,
the assumption of label independence is rather reasonable. MEUF seems to be the right choice
for probabilistic classiﬁers, unless its application is prevented due to its computational complexity.
Thresholding methods [5] or learning algorithms optimizing the F-measure directly [2, 3, 4] are
probably the most appropriate solutions here.

6 Conclusions

In contrast to other performance measures commonly used in experimental studies, such as misclas-
siﬁcation error rate, squared loss, and AUC, the F-measure has been investigated less thoroughly
from a theoretical point of view so far. In this paper, we analyzed the problem of optimal predic-
tive inference from the joint distribution under the F-measure. While partial results were already
known from the literature, we completed the picture by presenting the solution for the general case
without any distributional assumptions. Our GFM algorithm requires only a polynomial number
of parameters of the joint distribution and delivers the exact solution in polynomial time. From a
theoretical perspective, GFM should be preferred to existing approaches, which typically perform
threshold maximization on marginal probabilities, often relying on the assumption of (conditional)
independence of labels.

Acknowledgments. Krzysztof Dembczy ´nski has started this work during his post-doctoral stay
at Philipps-Universit ¨at Marburg supported by German Research Foundation (DFG) and ﬁnalized it
at Pozna ´n University of Technology under the grant 91-515/DS of the Polish Ministry of Science
and Higher Education. Willem Waegeman is supported as a postdoc by the Research Foundation
of Flanders (FWO-Vlaanderen). The part of this work has been done during his visit at Philipps-
Universit ¨at Marburg. Weiwei Cheng and Eyke H ¨ullermeier are supported by DFG. We also thank
the anonymous reviewers for their valuable comments.

8

In

References
[1] C. J. van Rijsbergen. Foundation of evaluation. Journal of Documentation, 30(4):365–373,
1974.
[2] David R. Musicant, Vipin Kumar, and Aysel Ozgur. Optimizing F-measure with support vector
machines. In FLAIRS-16, 2003, pages 356–360, 2003.
[3] Thorsten Joachims. A support vector method for multivariate performance measures. In ICML
2005, pages 377–384, 2005.
[4] Martin Jansche. Maximum expected F-measure training of logistic regression models.
HLT/EMNLP 2005, pages 736–743, 2005.
[5] Sathiya Keerthi, Vikas Sindhwani, and Olivier Chapelle. An efﬁcient method for gradient-
In Advances in Neural Information
based adaptation of hyperparameters in SVM models.
Processing Systems 19, 2007.
[6] Ioannis Tsochantaridis, Thorsten Joachims, Thomas Hofmann, and Yasemin Altun. Large
margin methods for structured and interdependent output variables. J. Mach. Learn. Res.,
6:1453–1484, 2005.
[7] Jun Suzuki, Erik McDermott, and Hideki Isozaki. Training conditional random ﬁelds with
multivariate evaluation measures. In ACL, pages 217–224, 2006.
[8] Hal Daum ´e III, John Langford, and Daniel Marcu. Search-based structured prediction. Ma-
chine Learning, 75:297–325, 2009.
[9] Rong-En Fan and Chih-Jen Lin. A study on threshold selection for multi-label classiﬁcation.
Technical report, Department of Computer Science, National Taiwan University, 2007.
[10] Xinhua Zhang, Thore Graepel, and Ralf Herbrich. Bayesian online learning for multi-label
and multi-variate performance measures. In AISTATS 2010, pages 956–963, 2010.
[11] James Petterson and Tiberio Caetano. Reverse multi-label learning. In Advances in Neural
Information Processing Systems 23, pages 1912–1920, 2010.
[12] Martin Jansche. A maximum expected utility framework for binary sequence labeling. In ACL
2007, pages 736–743, 2007.
[13] David Lewis. Evaluating and optimizing autonomous text classiﬁcation systems. In SIGIR
1995, pages 246–254, 1995.
[14] Juan Jose del Coz, Jorge Diez, and Antonio Bahamonde. Learning nondeterministic classiﬁers.
J. Mach. Learn. Res., 10:2273–2293, 2009.
[15] Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein. Introduction
to Algorithms, 2nd edition. MIT Press, 2001.
[16] Don Coppersmith and Shmuel Winograd. Matrix multiplication via arithmetic progressions.
Journal of Symbolic Computation, 3(9):251–280, 1990.
[17] John Lafferty, Andrew McCallum, and Fernando Pereira. Conditional random ﬁelds: Prob-
abilistic models for segmenting and labeling sequence data. In ICML 2001, pages 282–289,
2001.
[18] Nadia Ghamrawi and Andrew McCallum. Collective multi-label classiﬁcation. In CIKM 2005,
pages 195–200, 2005.
[19] Krzysztof Dembczy ´nski, Weiwei Cheng, and Eyke H ¨ullermeier. Bayes optimal multilabel
classiﬁcation via probabilistic classiﬁer chains. In ICML 2010, pages 279–286, 2010.
[20] Piyush Rai and Hal Daum ´e III. Multi-label prediction via sparse inﬁnite CCA. In Advances in
Neural Information Processing Systems 22, pages 1518–1526, 2009.
[21] Matthew R. Boutell, Jiebo Luo, Xipeng Shen, and Christopher M. Brown. Learning multi-label
scene classiﬁcation. Pattern Recognition, 37(9):1757–1771, 2004.

9

