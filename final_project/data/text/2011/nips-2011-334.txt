Advice Re ﬁnement in Knowledge-Based SVMs

Gautam Kunapuli
Univ. of Wisconsin-Madison
1300 University Avenue
Madison, WI 53705
kunapuli@wisc.edu

Richard Maclin
Univ. of Minnesota, Duluth
1114 Kirby Drive
Duluth, MN 55812
rmaclin@d.umn.edu

Jude W. Shavlik
Univ. of Wisconsin-Madison
1300 University Avenue
Madison, WI 53705
shavlik@cs.wisc.edu

Abstract
Knowledge-based support vector machines (KBSVMs) incorporate advice from
domain experts, which can improve generalization signiﬁca ntly. A major limita-
tion that has not been fully addressed occurs when the expert advice is imperfect,
which can lead to poorer models. We propose a model that extends KBSVMs
and is able to not only learn from data and advice, but also simultaneously im-
proves the advice. The proposed approach is particularly effective for knowledge
discovery in domains with few labeled examples. The proposed model contains
bilinear constraints, and is solved using two iterative approaches: successive linear
programming and a constrained concave-convex approach. Experimental results
demonstrate that these algorithms yield useful re ﬁnements
to expert advice, as
well as improve the performance of the learning algorithm overall.

1 Introduction
We are primarily interested in learning in domains where there is only a small amount of labeled data
but advice can be provided by a domain expert. The goal is to re ﬁne this advice, which is usually
only approximately correct, during learning, in such scenarios, to produce interpretable models that
generalize better and aid knowledge discovery. For learning in complex environments, a number
of researchers have shown that incorporating prior knowledge from experts can greatly improve the
generalization of the model learned, often with many fewer labeled examples. Such approaches
have been shown in rule-learning methods [16], artiﬁcial ne ural networks (ANNs) [21] and support
vector machines (SVMs) [10, 17]. One limitation of these methods concerns how well they adapt
when the knowledge provided by the expert is inexact or partially correct. Many of the rule-learning
methods focus on rule re ﬁnement to learn better rules, while ANNs form the rules as portions of
the network which are re ﬁned by backpropagation. Further, A NN methods have been paired with
rule-extraction methods [3, 20] to try to understand the resulting learned network and provide rules
that are easily interpreted by domain experts.
We consider the framework of knowledge-based support vector machines (KBSVMs), in-
troduced by Fung et al.
[6]. KBSVMs have been extensively studied, and in addition to linear
classiﬁcation, they have been extended to incorporate kern els [5], nonlinear advice [14] and for ker-
nel approximation [13]. Recently, Kunapuli et al. derived an online version of KBSVMs [9], while
other approaches such as that of Le et al. [11] modify the hypothesis space rather than the optimiza-
tion problem. Extensive empirical results from this prior work establish that expert advice can be
effective, especially for biomedical applications such as breast-cancer diagnosis. KBSVMs are an
attractive methodology for knowledge discovery as they can produce good models that generalize
well with a small amount of labeled data.
Advice tends to be rule-of-thumb and is based on the expert’s accumulated experience in
the domain; it may not always be accurate. Rather than simply ignoring or heavily penalizing in-
accurate rules, the effectiveness of the advice can be improved through re ﬁnement. There are two
main reasons for this: ﬁrst, re ﬁned rules result in the impro
vement of the overall generalization,
and second, if the re ﬁnements to the advice are interpretabl e by the domain experts, it will help in
the understanding of the phenomena underlying the applications for the experts, and consequently

1

Figure 1: (left) Standard SVM, trades off complexity and loss wrt the data; (center) Knowledge-based SVM,
also trades off loss wrt advice. A piece of advice set 1 extends over the margin, and is penalized as the advice
error. No part of advice set 2 touches the margin, i.e., none of the rules in advice set 2 are useful as support
constraints. (right) SVM that reﬁnes advice in two ways: (1) advice set 1 is reﬁned
so that no part of is on the
wrong side of the optimal hyperplane, minimizing advice error, (2) advice set 2 is expanded until it touches the
optimal margin thus maximizing coverage of input space.

greatly facilitate the knowledge-discovery process. This is the motivation behind this work. KB-
SVMs already have several desirable properties that make them an ideal target for re ﬁnement. First,
advice is speciﬁed as polyhedral regions in input space, who se constraints on the features are easily
interpretable by non-experts. Second, it is well-known that KBSVMs can learn to generalize well
with small data sets [9], and can even learn from advice alone [6]. Finally, owing to the simplicity of
the formulation, advice-re ﬁnement terms for the rules can b e incorporated directly into the model.
We further motivate advice re ﬁnement in KBSVMs with the foll owing example. Figure 1
(left) shows an SVM, which trades off regularization with the data error. Figure 1 (center) illustrates
KBSVMs in their standard form as shown in [6]. As mentioned before, expert rules are speciﬁed
in the KBSVM framework as polyhedral advice regions in input space. They introduce a bias to
focus the learner on a model that also includes the advice of the form ∀x, (x ∈ advice region i) ⇒
class(x) = 1. Advice regarding the regions for which class(x) = −1 can be speciﬁed similarly.
In the KBSVM (Figure 1, center), each advice region contributes to the ﬁnal hypothesis in
a KBSVM via its advice vector, u1 and u2 (as introduced in [6]; also see Section 2). The individual
j components. As a piece of advice
constraints that touch or intersect the margin have non-zero ui
region 1 extends beyond the margin, u1 6= 0; furthermore, analogous to data error, this overlap is
penalized as the advice error. As no part of advice set 2 touches the margin, u2 = 0 and none of
its rules contribute anything to the ﬁnal classiﬁer. Again,
analogous to support vectors, rules with
non-zero ui
j components are called support constraints [6]. Consequently, in the ﬁnal classiﬁer the
advice sets are incorporated with advice error (advice set 1) or are completely ignored (advice set
2). Even though the rules are inaccurate, they are able to improve generalization compared to the
SVM. However, simply penalizing advice that introduces errors can make learning difﬁcult as the
user must carefully trade off between optimizing data or advice loss.
Now, consider an SVM that is capable of re ﬁning inaccurate ad vice (Figure 1, right). When
advice is inaccurate and intersects the hyperplane, it is truncated such that it minimizes the advice
error. Advice that was originally ignored is extended to cover as much of the input space as is
feasible. The optimal classiﬁer has now minimized the error with respect to the data and the re ﬁned
advice and is able to further improve upon the performance of not just the SVM but also the KBSVM.
Thus, the goal is to re ﬁne potentially inaccurate expert adv ice during learning so as to learn a model
with the best generalization.
Our approach generalizes the work of Maclin et al. [12], to produce a model that corrects
the polyhedral advice regions of KBSVMs. The resulting mathematical program is no longer a
linear or quadratic program owing to bilinear correction factors in the constraints. We propose
two algorithmic techniques to solve the resulting bilinear program, one based on successive linear
programming [12], and the other based on a concave-convex procedure [24]. Before we describe
advice re ﬁnement, we brie ﬂy introduce our notation and KBSV Ms.
We wish to learn a linear classiﬁer ( w′x = b) given ℓ labeled data (xj , yj )ℓ
j=1 with xj ∈ Rn
and labels yj ∈ {±1}. Data are collected row-wise in the matrix X ∈ Rℓ×n , while Y = diag(y) is
the diagonal matrix of the labels. We assume that m advice sets (Di , di , zi )m
i=1 are given in addition
to the data (see Section 2), and if the i-th advice set has ki constraints, we have Di ∈ Rki×n ,
di ∈ Rki and zi = {±1}. The absolute value of a scalar y is denoted |y |, the 1-norm of a vector x

2

is denoted kxk1 = Pn
i=1 |xi |, and the entrywise 1-norm of a m × n matrix A ∈ Rp×q is denoted
i=1 Pq
kAk1 = Pp
i=1 |Aij |. Finally, e is a vector of ones of appropriate dimension.
2 Knowledge-Based Support Vector Machines
In KBSVMs, advice can be speciﬁed about every potential data point in the input space that satisﬁes
certain advice constraints. For example, consider a task of learning to diagnose diabetes, based on
features such as age, blood pressure, body mass index (bmi), plasma glucose concentration (gluc),
etc. The National Institute for Health (NIH) provides the following guidelines to establish risk for
Type-2 Diabetes1 : a person who is obese (bmi ≥ 30) with gluc ≥ 126 is at strong risk for diabetes,
while a person who is at normal weight (bmi ≤ 25) with gluc ≤ 100 is unlikely to have diabetes.
This leads to two advice sets, one for each class:
(bmi ≤ 25) ∧ (gluc ≤ 100) ⇒ ¬diabetes;

(bmi ≥ 30) ∧ (gluc ≥ 126) ⇒ diabetes,

s.t. Y (X w − eb) + ξ ≥ e.

(1)
where ¬ is the negation operator. In general, rules such as the ones above de ﬁne a polyhedral region
of the input space and are expressed as the implication
Dix ≤ di ⇒ zi (w′x − b) ≥ 1,
(2)
where the advice label zi = +1 indicates that all points x that satisfy the constraints for the i-th
advice set, Dix ≤ di belong to class +1, while z = −1 indicates the same for the other class. The
standard linear SVM formulation (without incorporating advice) for binary classiﬁcation optimizes
model complexity + λ data loss:
kwk1 + λe′ξ ,
min
ξ≥0,w,b
The implications (2), for the i = 1, . . . , m, can be incorporated into (3) using the nonhomogeneous
Farkas theorem of the alternative [6] that introduces advice vectors ui . The advice vectors perform
the same role as the dual multipliers α in the classical SVM. Recall that points with non-zero α’s
are the support vectors which additively contribute to w. Similarly, the constraints of an advice set
which have non-zero ui s are called support constraints. The resulting formulation is the KBSVM,
which optimizes model complexity + λ data loss + µ advice loss:
kwk1 + λe′ ξ + µ Pm
i=1 (e′η i + ζi )
min
w,b,(ξ,ui ,ηi ,ζi )≥0
s.t.
Y (X w − be) + ξ ≥ e,
−η i ≤ D ′
iui + ziw ≤ η i ,
−di ′
ui − zib + ζi ≥ 1, i = 1, . . . , m.
In the case of inaccurate advice, the advice errors η i and ζi soften the advice constraints analogous
to the data errors ξ . Returning to Figure 1, for advice set 1, η1 , ζ1 and u1 are non-zero, while for
advice set 2, u2 = 0. The in ﬂuence of data and advice is determined by the choice o f the parameters
λ and µ which re ﬂect the user’s trust in the data and advice respecti vely.

(3)

(4)

3 Advice-Reﬁning Knowledge-based Support Vector Machines
Previously, Maclin et al. [12] formulated a model to re ﬁne ad vice in KBSVMs. However, their
model is limited as only the terms di are re ﬁned, which as we discuss below, greatly restricts the
types of re ﬁnements that are possible. They only consider re ﬁnement terms
f i for the right hand
side of the i-th advice set, and attempt to re ﬁne each rule such that
Dix ≤ (di − f i ) ⇒ zi (w′x − b) ≥ 1, i = 1, . . . , m.
(5)
The resulting formulation adds re ﬁnement terms into the KBS VM model (4) in the advice con-
straints, as well as in the objective. The latter allows for the overall extent of the re ﬁnement to be
controlled by the re ﬁnement parameter ν > 0. This formulation was called Re ﬁning-Rules Support
Vector Machine (RRSVM):
min
w,b,f i ,(ξ,ui ,ηi ,ζi )≥0
s.t.

kwk1 + λe′ ξ + µ Pm
i=1 (e′η i + ζi ) + ν Pm
i=1 kf ik1
Y (X w − be) + ξ ≥ e,
−η i ≤ D ′
iui + ziw ≤ η i ,
−(di − f i )′ui − zib + ζi ≥ 1, i = 1, . . . , m.

(6)

1http://diabetes.niddk.nih.gov/DM/pubs/∼riskfortype2

3

This problem is no longer an LP owing to the bilinear terms f i ′
ui which make the re ﬁnement con-
straints non-convex. Maclin et al. solve this problem using successive linear programming (SLP)
wherein linear programs arising from alternately ﬁxing eit her the advice terms di or the re ﬁnement
terms f i are solved iteratively.
We consider a full generalization of the RRSVM approach and develop a model where it is
possible to re ﬁne the entire advice region Dx ≤ d. This allows for much more ﬂexibility in re ﬁning
the advice based on the data, while still retaining interpretability of the resulting re ﬁned advice.
In addition to the terms f i , we propose the introduction of additional re ﬁnement terms Fi into the
model, so that we can re ﬁne the rules in as general a manner as p ossible:
(Di − Fi )x ≤ (di − f i ) ⇒ zi (w′x − b) ≥ 1, i = 1, . . . , m.
(7)
Recall that for each advice set we have Di ∈ Rki×n and di ∈ Rki , i.e., the i-th advice set contains
ki constraints. The corresponding re ﬁnement terms Fi and f i will have the same dimensions respec-
tively as Di and di . The formulation (6) now includes the additional re ﬁnement
terms Fi , and the
formulation optimizes:

min
w,b,Fi ,f i ,(ξ,ui ,ηi ,ζi )≥0
s.t.

kwk1 + λe′ξ + µ Pm
i=1 (e′η i + ζi ) + ν Pm
i=1 (cid:0)kFi k1 + kf i k1(cid:1)
Y (X w − be) + ξ ≥ e,
−η i ≤ (Di − Fi )′ui + ziw ≤ η i ,
−(di − f i )′ui − zib + ζi ≥ 1, i = 1, . . . , m.
The objective function of (8) trades-off the effect of re ﬁne ment in each of the advice sets via the
re ﬁnement parameter ν . This is the Advice-Re ﬁning K BSVM (arkSVM); it improves upon the work
of Maclin et al. in two important ways. First, re ﬁning d alone is highly restrictive as it allows only
for the translation of the boundaries of the polyhedral advice; the generalized re ﬁnement offered
by arkSVMs allows for much more ﬂexibility owing to the fact t hat the boundaries of the advice
can be translated and rotated (see Figure 2). Second, the newly added re ﬁnement terms, F ′
i ui , are
bilinear also, and do not make the overall problem more complex; in addition to the successive
linear programming approach of [12], we also propose a concave-convex procedure that leads to an
approach based on successive quadratic programming. We provide details of both approaches next.

(8)

3.1 arkSVMs via Successive Linear Programming
One approach to solving bilinear programming problems is to solve a sequence of linear programs
while alternately ﬁxing the bilinear variables. This appro ach is called successive linear program-
ming, and has been used to solve various machine learning formulations, for instance [1, 2]. In this
approach, which was also adopted by [12], we solve the LPs arising from alternatingly ﬁxing the
sources of bilinearity: (Fi , f i )m
i=1 and {ui}m
i=1 . Algorithm 1 describes the above approach. At the
t-th iteration, the algorithm alternates between the following steps:
i , ˆf i,t )m
( ˆF t
• (Estimation Step) When the re ﬁnement terms,
i=1 , are ﬁxed the resulting LP
becomes a standard KBSVM which attempts to ﬁnd a data-estima te of the advice vectors
j ) x ≤ (dj − ˆf j,t ).
(Dj − ˆF t
i=1 using the current re ﬁnement of the advice region:
{ui}m
• (Re ﬁnement Step ) When the advice-estimate terms { ˆui,t}m
i=1 are ﬁxed, the resulting LP
solves for (Fi , f i )m
i=1 and attempts to further re ﬁne the advice regions based on est imates
from data computed in the previous step.
Proposition 1 I. For ǫ = 0,
the sequence of objective values converges to the value
k ¯wk1 + λe′ ¯ξ + µ Pm
i=1 (e′ ¯η i + ¯ζi ) + ν Pm
i=1 (cid:0)k ¯Fi k1 + k¯f i k1(cid:1), where the data and advice
errors ( ¯ξ , ¯η i , ¯ζi ) are computed from any accumulation point ( ¯w, ¯b, ¯ui , ¯Fi , ¯f i ) of the sequence of
iterates ( ˆwt , ˆbt , ˆui,t , ˆF t
i , ˆf i,t )∞
t=1 generated by Algorithm 1.

II. Such an accumulation point satisﬁes the local minimum co ndition
( ¯w, ¯b) ∈
kwk1 + λe′ξ + µ Pm
i=1 (e′η i + ζi )
min
ui≥0
w,b,(ξ,ηi ζi≥0)
subject to Y (X w − be) + ξ ≥ e,
−η i ≤ (Di − ¯Fi )′ui + ziw ≤ η i ,
−(di − ¯f i )′ui − zib + ζi ≥ 1,

i = 1, . . . , m.

4

Algorithm 1 arkSVM via Successive Linear Programming (arkSVM-sla)
i = 0, ˆf i,1 = 0
1: initialize: t = 1, ˆF 1
2: while feasible do
i ) x ≤ (dj − ˆf i,t )
if x not feasible for (Di − ˆF t
3:
(estimation step) solve for { ˆui,t+1 }m
4:
i=1
kwk1 + λe′ξ + µ Pm
i=1 (e′η i + ζi )
Y (Xw − be) + ξ ≥ e,
−η i ≤ (Di − ˆF t
i )′ui + ziw ≤ η i ,
−(di − ˆf i,t )′ui − zi b + ζi ≥ 1, i = 1, . . . , m.

min
w,b,(ξ ,ui ,η i ,ζi )≥0
s.t.

return failure

5:

min
w,b,Fi ,f i ,(ξ ,η i ,ζi )≥0
s.t.

, ˆf i,t+1 )m
(reﬁnement step ) solve for ( ˆF t+1
i=1
i
kwk1 + λe′ξ + µ Pm
i=1 (e′η i + ζi ) + ν Pm
i=1 (cid:0)kFi k1 + kf i k1 (cid:1)
Y (Xw − be) + ξ ≥ e,
−η i ≤ (Di − Fi )′ ˆui,t+1 + ziw ≤ η i ,
−(di − f i )′ ˆui,t+1 − zi b + ζi ≥ 1, i = 1, . . . , m.
j − F t+1
(termination test) if Pj (cid:0)kF t
6:
j
(continue) t = t + 1
7:
8: end while

then return solution

j − f t+1
k + kf t
j

k(cid:1) ≤ ǫ

Algorithm 2 arkSVM via Successive Quadratic Programming (arkSVM-sqp)
i = 0, ˆf i,1 = 0
1: initialize: t = 1, ˆF 1
2: while feasible do
i ) x ≤ (dj − ˆf i,t )
if x not feasible for (Di − ˆF t
3:
solve for { ˆui,t+1 }m
4:
i=1

return failure

min
Fi ,f i ,(ui ≥0)
w,b,(ξ ,η i ζi ≥0)
s.t.

i=1 (e′η i + ζi ) + ν Pm
kwk1 + λe′ξ + µ Pm
i=1 (cid:0)kFi k1 + kf i k1 (cid:1)
Y (Xw − be) + ξ ≥ e,
eqns (10–12) , i = 1, . . . , m, j = 1, . . . , n
j − F t+1
(termination test) if Pj (cid:0)kF t
5:
j
(continue) t = t + 1
6:
7: end while

then return solution

j − f t+1
k + kf t
j

k(cid:1) ≤ ǫ

3.2 arkSVMs via Successive Quadratic Programming
In addition to the above approach, we introduce another algorithm (Algorithm 2) that is based on
successive quadratic programming. In the constraint (Di − Fi )′ui + ziw − η i ≤ 0, only the re-
i ui is bilinear, while the rest of the constraint is linear. Denote the j -th components
ﬁnement term F ′
j respectively. A general bilinear term r′ s, which is non-convex, can be
of w and η i to be wj and η i
written as the difference of two convex terms: 1
4 kr + sk2 − 1
4 kr − sk2 . Thus, we have the equivalent
constraint
1
1
kFij + uik2 ,
kFij − ui k2 ≤
ij ui + ziwj − η i
D ′
j +
4
4
and both sides of the constraint above are convex and quadratic. We can linearize the right-hand side
of (9) around some current estimate of the bilinear variables ( ˆF t
ij , ˆui,t ):
4 k ˆF t
4 kFij − ui k2 ≤ 1
j + 1
ij + ˆui,t k2
ij ui + ziwj − η i
D ′
ij + ˆui,t )′ (cid:16)(Fij − ˆF t
ij ) + (ui − ˆui,t )(cid:17) .
2 ( ˆF t
+ 1
Similarly, the constraint −(Di − Fi )′ui − ziw − η i ≤ 0, can be replaced by
4 k ˆF t
4 kFij + uik2 ≤ 1
j + 1
ij − ˆui,tk2
ij ui − ziwj − η i
−D ′
ij − ˆui,t )′ (cid:16)(Fij − ˆF t
ij ) − (ui − ˆui,t )(cid:17) ,
2 ( ˆF t
+ 1

(11)

(9)

(10)

5

(12)

Figure 2: Toy data set (Section 4.1) using (left) RRSVM (center) arkSVM-sla (right) arkSVM-sqp. Orange
and green unhatched regions show the original advice. The dashed lines show the margin, kwk∞ . For each
method, we show the reﬁned advice: vertically hatched for Cl ass +1, and diagonally hatched for Class −1.
ui + zi b + 1 − ζi − f i ′
while di ′
ui ≤ 0 is replaced by
di ′
4 kˆf i,t + ˆui,t k2
4 kf i − ui k2 ≤ 1
ui + zib + 1 − ζi + 1
2 (ˆf i,t + ˆui,t )′ (cid:16)(f i,t − ˆf i,t ) + (ui − ˆui,t )(cid:17) .
+ 1
The right-hand sides in (10 –12) are afﬁne and hence, the enti
re set of constraints are now convex.
Replacing the original bilinear non-convex constraints of (8) with the convexiﬁed relaxations results
in a quadratically-constrained linear program (QCLP). These quadratic constraints are more restric-
tive than their non-convex counterparts, which leads the feasible set of this problem to be a subset of
that of the original problem. Now, we can iteratively solve the resulting QCLP. At the t-th iteration,
the restricted problem uses the current estimate to construct a new feasible point and iterating this
procedure produces a sequence of feasible points with decreasing objective values. The approach
described here is essentially the constrained concave-convex procedure (CCCP) that has been dis-
covered and rediscovered several times. Most recently, the approach was described in the context
of machine learning approaches by Yuille and Rangarajan [24], and Smola and Vishwanathan [19],
who also derived conditions under which the algorithm converges to a local solution. The following
convergence theorem is due to [19].
Proposition 2 For Algorithm 2, the sequence of objective values converges to the value k ¯wk1 +
λe′ ¯ξ + µ Pm
i=1 (e′ ¯η i + ¯ζi ) + ν Pm
i=1 (cid:0)k ¯Fik1 + k¯f ik1 (cid:1), where ( ¯w, ¯b, ¯ui , ¯Fi , ¯f i , ¯ξ , ¯η i , ¯ζi ) is the
local minimum solution of (8) provided that the constraints (10 –12) in conjunction with the convex
constraints Y (X w − eb) + ξ ≥ e, ξ ≥ 0, ui ≥ 0, ζi ≥ 0 satisfy suitable constraint qualiﬁcations
at the point of convergence of the algorithm.
Both Algorithms 1 and 2 produce local minima solutions to the arkSVM formulation (8).
For either solution, the following proposition holds, which shows that either algorithm produces
a re ﬁnement of the original polyhedral advice regions. The p roof is a direct consequence of
[13][Proposition 2.1].
Proposition 3 Let ( ¯w, ¯b, ¯ui , ¯Fi , ¯f i , ¯ξ , ¯η i , ¯ζi ) be the local minimum solution produced by Algorithm
1 or Algorithm 2. Then, the following re ﬁnement to the advice sets holds:
(Di − ¯Fi ) ≤ (di − ¯f i ) ⇒ zi ( ¯w′x − ¯b) ≥ − ˆη i ′x − ¯ζi ,
where − ¯η i ≤ ˆη i ≤ ¯η i such that D ′
i ¯ui + ¯w + ˆη i = 0.

4 Experiments
We present the results of several experiments that compare the performance of three algorithms:
RRSVMs (which only re ﬁne the d term in Dx ≤ d), arkSVM-sla (successive linear programming)
and arkSVM-sqp (successive quadratic programming) with that of standard SVMs and KBSVMs.
The LPs were solved using QSOPT2 , while the QCLPs were solved using SDPT-3 [22].

4.1 Toy Example
We illustrate the behavior of advice re ﬁnement algorithms d iscussed previously geometrically using
a simple 2-dimensional example (Figure 2). This toy data set consists of 200 points separated by
x1 + x2 = 2. There are two advice sets: {S1 : (x1 , x2 ) ≥ 0 ⇒ z = +1}, {S2 : (x1 , x2 ) ≤ 0 ⇒

2http://www2.isye.gatech.edu/∼wcook/qsopt/

6

40

35

30

25

20

15

10

5

)
%
(
 
r
o
r
r
E
 
g
n
i
t
s
e
T

0
 
0

 

svm
kbsvm
rrsvm
arksvm−sla
arksvm−sqp

10

20

90 100

30
80
70
60
50
40
Number of Training Examples
Figure 3: Diabetes data set, Section 4.2; (left) Results averaged over 10 runs on a hold-out test set of 412
ion; (right) An approximate decision-tree represen-
points, with parameters selected by ﬁve-fold cross validat
tation of Diabetes Rule 6 before and after reﬁnement. The left branch is chosen if the q uery at a node is
true, and the right branch otherwise. The leaf nodes classify the data point according to ?diabetes.

z = −1}. Both arkSVMs are able to re ﬁne knowledge sets such that the n o part of S1 lies on the
wrong side of the ﬁnal hyperplane. In addition, the re ﬁnemen
t terms allow for sufﬁcient modiﬁcation
of the advice sets Dx ≤ d so that they ﬁll the input space as much as possible, without v iolating
the margin. Comparing to RRSVMs, we see that re ﬁnement is res trictive because corrections are
applied only to part of the advice sets, rather than fully correcting the advice.

4.2 Case Study 1: PIMA Indians Diabetes Diagnosis

The Pima Indians Diabetes data set [4] has been studied for several decades and is used as a standard
benchmark to test many machine learning algorithms. The goal is to predict the onset of diabetes in
768 Pima Indian women within the next 5 years based on current indicators (eight features): number
of times pregnant, plasma glucose concentration (gluc), diastolic blood pressure, triceps skin fold
test, 2-hour serum insulin, body mass index (bmi), diabetes pedigree function (pedf) and age.
Studies [15] show that diabetes incidence among the Pima Indians is signiﬁcantly higher among
subjects with bmi ≥ 30. In addition, a person with impaired glucose tolerance is at a signiﬁcant
risk for, or worse, has undiagnosed diabetes [8]. This leads to the following expert rules:

(Diabetes Rule 1)
(Diabetes Rule 2)
(Diabetes Rule 3)
(Diabetes Rule 4)

(gluc ≤ 126)
⇒¬diabetes,
(gluc ≥ 126) ∧ (gluc ≤ 140) ∧ (bmi ≤ 30) ⇒¬diabetes,
(gluc ≥ 126) ∧ (gluc ≤ 140) ∧ (bmi ≥ 30) ⇒ diabetes,
⇒ diabetes.
(gluc ≥ 140)

The diabetes pedigree function was developed by Smith et al. [18], and uses genetic information
from family relatives to provide a measure of the expected genetic in ﬂuence (heredity) on the sub-
ject’s diabetes risk. The function also takes into account the age of relatives who do have diabetes;
on average, Pima Indians are only 36 years old3 when diagnosed with diabetes. A subject with high
heredity who is at least 31 is at a signiﬁcantly increased risk for diabetes in the next ﬁ
ve years:

(Diabetes Rule 5)
(Diabetes Rule 6)

(pedf ≤ 0.5) ∧ (age ≤ 31) ⇒¬diabetes,
(pedf ≥ 0.5) ∧ (age ≥ 31) ⇒ diabetes.

Figure 3 (left) shows that unre ﬁned advice does help initial ly, especially with as few as 30 data
points. However, as more data points are available, the effect of the advice diminishes. In contrast,
the advice re ﬁning methods are able to generalize much bette r with few data points, and eventually
converge to a better solution. Finally, Figure 3 (right) shows an approximate tree representation of
Diabetes Rule 6 after re ﬁnement. This tree was constructed by sampling the s pace around
re ﬁned advice region uniformly, and then training a decisio n tree that covers as many of the sampled
points as possible. This naive approach to rule extraction from re ﬁned advice is shown here only to
illustrate that it is possible to produce very useful domain-expert-interpretable rules from re ﬁnement.
More efﬁcient and accurate rule extraction techniques insp ired by SVM-based rule extraction (for
example, [7]) are currently under investigation.

7

 

svm
kbsvm
rrsvm
arksvm−sla
arksvm−sqp

30

25

20

15

10

5

)
%
(
 
r
o
r
r
E
 
g
n
i
t
s
e
T

80
60
40
20
100
Number of Training Examples
Figure 4: Wargus data set, Section 4.3; (left) An example Wargus scenario; (right) Results using 5-fold cross
validation on a hold out test set of 1000 points.

0

 

4.3 Case Study 2: Re ﬁning GUI-Collected Human Advice in a War gus Task
Wargus4 is a real-time strategy game in which two or more players gather resources, build bases and
control units in order to conquer opposing players. It has been widely used to study and evaluate
various machine learning and planning algorithms. We evaluate our algorithms on a classiﬁcation
task in the Wargus domain developed by Walker et al. [23] called tower-defense (Figure 4,
left). Advice for this task was collected from humans via a graphical, human-computer interface
(HCI) as detailed in [23]. Each scenario (example) in tower-defense, consists of a single tower
being attacked by a group of enemy units, and the task is to predict whether the tower will survive
the attack and defeat the attackers given the size and composition of the latter, as well as other
factors such as the environment. The data set consists of 80 features including information about
units (eg., archers, ballista, peasants), unit properties (e.g., map location, health), group properties
(e.g., #archers, #footmen) and environmental factors (e.g., ?hasMoat).
Walker et al. [23] used this domain to study the feasibility of learning from human teachers.
To this end, human players were ﬁrst trained to identify whet her a tower would fall given a particular
scenario. Once the humans learned this task, they were asked to provide advice via a GUI-based
interface based on speciﬁc examples. This setting lends its elf very well to re ﬁnement as the advice
collected from human experts represents the sum of their experiences with the domain, but is by no
means perfect or exact. The following are some rules provided by human “domain experts”:

(Wargus Rule 1) (#footmen ≥ 3) ∧ (?hasMoat = 0)
⇒falls,
(Wargus Rule 2) (#archers ≥ 5)
⇒falls,
(Wargus Rule 3) (#ballistas ≥ 1)
⇒falls,
(Wargus Rule 4) (#ballistas = 0) ∧ (#archers = 0) ∧ (?hasMoat = 1) ⇒stands.

Figure 4 (right) shows the performance of the various algorithms on the Wargus data set. As with
the previous case study, the arkSVM methods are able to not only learn very effectively with a small
data set, they are also able to improve signiﬁcantly on the pe rformances of standard knowledge-
based SVMs (KBSVMs) and rule-re ﬁning SVMs (RRSVMs).

5 Conclusions and Future Work
We have presented two novel knowledge-discovery methods: arkSVM-sla and arkSVM-sqp, that
allow SVM methods to not only make use of advice provided by human experts but to re ﬁne that
advice using labeled data to improve the advice. These methods are an advance over previous
knowledge-based SVM methods which either did not re ﬁne advi ce [6] or could only re ﬁne simple
aspects of the advice [12]. Experimental results demonstrate that our arkSVM methods can make
use of inaccurate advice to revise them to better ﬁt the data. A signiﬁcant aspect of these learn-
ing methods is that the system not only produces a classiﬁer b ut also produces human-inspectable
changes to the user-provided advice, and can do so using small data sets. In terms of future work, we
plan to explore several avenues of research including extending this approach to the nonlinear case
for more complex models, better optimization algorithms for improved efﬁciency, and interpretation
of re ﬁned rules for non-AI experts.

3http://diabetes.niddk.nih.gov/dm/pubs/pima/kiddis/kiddis.htm
4http://wargus.sourceforge.net/index.shtml

8

Acknowledgements
The authors gratefully acknowledge support of the Defense Advanced Research Projects Agency under DARPA
grant FA8650-06-C-7606 and the National Institute of Health under NLM grant R01-LM008796. Views and
conclusions contained in this document are those of the authors and do not necessarily represent the ofﬁcial
opinion or policies, either expressed or implied of the US government or of DARPA.

In

References
[1] K. P. Bennett and E. J. Bredensteiner. A parametric optimization method for machine learning. INFORMS
Journal on Computing, 9(3):311–318, 1997.
[2] K. P. Bennett and O. L. Mangasarian. Bilinear separation of two sets in n-space. Computational Opti-
mization and Applications, 2:207–227, 1993.
[3] M. W. Craven and J. W. Shavlik. Extracting tree-structured representations of trained networks.
Advances in Neural Information Processing Systems, volume 8, pages 24–30, 1996.
[4] A. Frank and A. Asuncion. UCI machine learning repository, 2010.
[5] G. Fung, O. L. Mangasarian, and J. W. Shavlik. Knowledge-based nonlinear kernel classi ﬁers. In Sixteenth
Annual Conference on Learning Theory, pages 102–113, 2003.
[6] G. Fung, O. L. Mangasarian, and J. W. Shavlik. Knowledge-based support vector classi ﬁers. In Advances
in Neural Information Processing Systems, volume 15, pages 521–528, 2003.
[7] G. Fung, S. Sandilya, and R. B. Rao. Rule extraction from linear support vector machines.
In Proc.
Eleventh ACM SIGKDD Intl. Conference on Knowledge Discovery in Data Mining, pages 32–40, 2005.
[8] M. I. Harris, K. M. Flegal, C. C. Cowie, M. S. Eberhardt, D. E. Goldstein, R. R. Little, H. M. Wiedmeyer,
and D. D. Byrd-Holt. Prevalence of diabetes, impaired fasting glucose, and impaired glucose tolerance in
U.S. adults. Diabetes Care, 21(4):518–524, 1998.
[9] G. Kunapuli, K. P. Bennett, A. Shabbeer, R. Maclin, and J. W. Shavlik. Online knowledge-based support
vector machines. In Proc. of the European Conference on Machine Learning, pages 145–161, 2010.
[10] F. Lauer and G. Bloch. Incorporating prior knowledge in support vector machines for classi ﬁcation: A
review. Neurocomputing, 71(7–9):1578–1594, 2008.
[11] Q. V. Le, A. J. Smola, and T. G ¨artner. Simpler knowledge-based support vector machines. In Proceedings
of the Twenty-Third International Conference on Machine Learning, pages 521–528, 2006.
[12] R. Maclin, E. W. Wild, J. W. Shavlik, L. Torrey, and T. Walker. Reﬁning rules incorporated into
knowledge-based support vector learners via successive linear programming.
In AAAI Twenty-Second
Conference on Arti ﬁcial Intelligence , pages 584–589, 2007.
[13] O. L. Mangasarian, J. W. Shavlik, and E. W. Wild. Knowledge-based kernel approximation. Journal of
Machine Learning Research, 5:1127–1141, 2004.
[14] O. L. Mangasarian and E. W. Wild. Nonlinear knowledge-based classi ﬁcation.
Neural Networks, 19(10):1826–1832, 2008.
[15] M. E. Pavkov, R. L. Hanson, W. C. Knowler, P. H. Bennett, J. Krakoff, and R. G. Nelson. Changing
patterns of Type 2 diabetes incidence among Pima Indians. Diabetes Care, 30(7):1758–1763, 2007.
[16] M. Pazzani and D. Kibler. The utility of knowledge in inductive learning. Mach. Learn., 9:57–94, 1992.
[17] B. Sch ¨olkopf, P. Simard, A. Smola, and V. Vapnik. Priorknowledge in support vector kernels. In Advances
in Neural Information Processing Systems, volume 10, pages 640–646, 1998.
[18] J. W. Smith, J. E. Everhart, W. C. Dickson, W. C. Knowler, and R. S. Johannes. Using the ADAP learning
algorithm to forecast the onset of diabetes mellitus.
In Proc. of the Symposium on Comp. Apps. and
Medical Care, pages 261–265. IEEE Computer Society Press, 1988.
[19] A. J. Smola and S. V. N. Vishwanathan. Kernel methods for missing variables. In Proceedings of the
Tenth International Workshop on Arti ﬁcial Intelligence an d Statistics, pages 325–332, 2005.
[20] S. Thrun. Extracting rules from arti ﬁcial neural netwo rks with distributed representations. In Advances
in Neural Information Processing Systems, volume 8, 1995.
[21] G. G. Towell and J. W. Shavlik. Knowledge-based arti ﬁci al neural networks. Arti ﬁcial Intelligence ,
70(1–2):119–165, 1994.
[22] R. H. T ¨ut ¨unc ¨u, K. C. Toh, and M. J. Todd. Solving semideﬁnite-quadratic-linear programs using SDPT3.
Mathematical Programming, 95(2), 2003.
[23] T. Walker, G. Kunapuli, N. Larsen, D. Page, and J. W. Shavlik.
Integrating knowledge capture and
supervised learning through a human-computer interface. In Proc. Fifth Intl. Conf. Knowl. Capture, 2011.
[24] A. L. Yuille and A. Rangarajan. The concave-convex procedure (CCCP). In Advances in Neural Infor-
mation Processing Systems, volume 13, 2001.

IEEE Transactions on

9

