On U-processes and Clustering Performance

St´ephan Cl´emen¸con
LTCI UMR Telecom ParisTech/CNRS No. 5141 - Institut Telecom

Motivation

Pairwise dissimilarity-based clustering techniques are widely used to
segment a dataset into groups, such that data points in the same group
are more similar to each other than to those in other groups. The
empirical criteria these algorithms seek to optimize are of the form of
U -statistics of degree two. We propose to analyze their performance, using
recent advances in the theory of U-processes. The statistical framework
considered permits to establish learning rates for the excess of
clustering risk and to design model selection tools as well.

St´ephan Cl´emen¸con (LTCI)

On U-processes and Clustering Performance

December 2011

1 / 4

Statistical Framework
We observe an i.i.d. sample Dn = {(Xi )i ≤n } of n ≥ 1 observations in a
space X , drawn from a probability distribution µ(dx ). Here, we assume
that the space X is equipped with a dissimilarity measure D : X 2 → R+
that fulﬁlls the properties:
(Symmetry) D (x , x (cid:48) ) = D (x (cid:48) , x ),
(Separation) D (x , x (cid:48) ) = 0 ⇔ x = x (cid:48) .
The task is to partition the space X in a ﬁnite number of groups, K ≥ 1
K(cid:88)
(cid:88)
say, so as to minimize the quantity (i.e. the within cluster point scatter):
(cid:99)Wn (P ) =
k },
D (Xi , Xj ) · I{(Xi , Xj ) ∈ C 2
2
n(n − 1)
1≤i <j ≤n
k =1
over all possible partitions P = {C1 , . . . , CK }. The clustering risk is:
K(cid:88)
E (cid:2)D (X , X (cid:48) ) · I{(X , X (cid:48) ) ∈ C 2
k }(cid:3) .
W (P ) =
k =1
Optimal partitions are those that minimize W (P ).
On U-processes and Clustering Performance
St´ephan Cl´emen¸con (LTCI)

December 2011

2 / 4

Generalization Ability

Pairwise-based clustering can be cast in terms of minimization of a
(cid:111)
(cid:110)(cid:99)Wn (P ) − W (P ) : P ∈ Π
U -statistic over a class Π of partition candidates.
Analysis of the Empirical Clustering Risk Minimizers requires to study the
ﬂuctuations of the U-process
. Key
ingredients:
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:98)n/2(cid:99)(cid:88)
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ,
Complexity assumption
i =1
Projection techniques
U -process = Empirical Process + O (1/n)

i D (Xi , Xi +(cid:98)n/2(cid:99) ) · I{(Xi , Xi +(cid:98)n/2(cid:99) ) ∈ C 2}

1
(cid:98)n/2(cid:99)

sup
C , P

St´ephan Cl´emen¸con (LTCI)

On U-processes and Clustering Performance

December 2011

3 / 4

Results and Applications

Learning rates of the order O (1/

√

n)

Tight probability bounds for the excess of clustering risk

Fast rates

Model selection tools, computing additive complexity penalization
terms:

(cid:73) Automatic selection of the geometry of the cells
(cid:73) Choosing the number of cells

St´ephan Cl´emen¸con (LTCI)

On U-processes and Clustering Performance

December 2011

4 / 4

