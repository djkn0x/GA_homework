Correcting sample selection bias in maximum
entropy density estimation

Miroslav Dud´ık, Robert E. Schapire
Princeton University
Department of Computer Science
35 Olden St, Princeton, NJ 08544
{mdudik,schapire}@princeton.edu

Steven J. Phillips
AT&T Labs − Research
180 Park Ave, Florham Park, NJ 07932
phillips@research.att.com

Abstract

We study the problem of maximum entropy density estimation in the
presence of known sample selection bias. We propose three bias cor-
rection approaches. The ﬁrst one takes advantage of unbiase d sufﬁcient
statistics which can be obtained from biased samples. The second one es-
timates the biased distribution and then factors the bias out. The third one
approximates the second by only using samples from the sampling distri-
bution. We provide guarantees for the ﬁrst two approaches an d evaluate
the performance of all three approaches in synthetic experiments and on
real data from species habitat modeling, where maxent has been success-
fully applied and where sample selection bias is a signi ﬁcan t problem.

Introduction
1
We study the problem of estimating a probability distribution, particularly in the context of
species habitat modeling. It is very common in distribution modeling to assume access to
independent samples from the distribution being estimated. In practice, this assumption is
violated for various reasons. For example, habitat modeling is typically based on known
occurrence locations derived from collections in natural history museums and herbariums
as well as biological surveys [1, 2, 3]. Here, the goal is to predict the species’ distribution
as a function of climatic and other environmental variables. To achieve this in a statis-
tically sound manner using current methods, it is necessary to assume that the sampling
distribution and species distributions are not correlated. In fact, however, most sampling is
done in locations that are easier to access, such as areas close to towns, roads, airports or
waterways [4]. Furthermore, the independence assumption may not hold since roads and
waterways are often correlated with topography and vegetation which inﬂuence species dis-
tributions. New unbiased sampling may be expensive, so much can be gained by using the
extensive existing biased data, especially since it is becoming freely available online [5].
Although the available data may have been collected in a biased manner, we usually
have some information available about the nature of the bias. For instance, in the case of
habitat modeling, some factors inﬂuencing the sampling dis tribution are well known, such
as distance from roads, towns, etc. In addition, a list of visited sites may be available and
viewed as a sample of the sampling distribution itself. If such a list is not available, the
set of sites where any species from a large group has been observed may be a reasonable
approximation of all visited locations.
In this paper, we study probability density estimation under sample selection bias. We

assume that the sampling distribution (or an approximation) is known during training, but
we require that unbiased models not use any knowledge of sample selection bias during
testing. This requirement is vital for habitat modeling where models are often applied to
a different region or under different climatic conditions. To our knowledge this is the ﬁrst
work addressing sample selection bias in a statistically sound manner and in a setup suitable
for species habitat modeling from presence-only data.
We propose three approaches that incorporate sample selection bias in a common den-
sity estimation technique based on the principle of maximum entropy (maxent). Max-
ent with ℓ1 -regularization has been successfully used to model geographic distributions
of species under the assumption that samples are unbiased [3]. We review ℓ1 -regularized
maxent with unbiased data in Section 2, and give details of the new approaches in Section 3.
Our three approaches make simple modi ﬁcations to unbiased m axent and achieve anal-
ogous provable performance guarantees. The ﬁrst approach u ses a bias correction technique
similar to that of Zadrozny et al. [6, 7] to obtain unbiased conﬁdence intervals from biased
samples as required by our version of maxent. We prove that, as in the unbiased case, this
produces models whose log loss approaches that of the best possible Gibbs distribution
(with increasing sample size).
In contrast, the second approach we propose ﬁrst estimates t he biased distribution and
then factors the bias out. When the target distribution is a Gibbs distribution, the solution
again approaches the log loss of the target distribution. When the target distribution is not
Gibbs, we demonstrate that the second approach need not produce the optimal Gibbs dis-
tribution (with respect to log loss) even in the limit of inﬁn itely many samples. However,
we prove that it produces models that are almost as good as the best Gibbs distribution ac-
cording to a certain Bregman divergence that depends on the selection bias. In addition, we
observe good empirical performance for moderate sample sizes. The third approach is an
approximation of the second approach which uses samples from the sampling distribution
instead of the distribution itself.
One of the challenges in studying methods for correcting sample selection bias is that
unbiased data sets, though not required during training, are needed as test sets to evaluate
performance. Unbiased data sets are difﬁcult to obtain — thi
s is the very reason why
we study this problem! Thus, it is almost inevitable that synthetic data must be used. In
Section 4, we describe experiments evaluating performance of the three methods. We use
both fully synthetic data, as well as a biological dataset consisting of a biased training set
and an independently collected reasonably unbiased test set.
Related work. Sample selection bias also arises in econometrics where it stems from
factors such as attrition, nonresponse and self selection [8, 9, 10]. It has been extensively
studied in the context of linear regression after Heckman’s seminal paper [8] in which the
bias is ﬁrst estimated and then a transform of the estimate is used as an additional regressor.
In the machine learning community, sample selection bias has been recently considered
for classi ﬁcation problems by Zadrozny [6]. Here the goal is
to learn a decision rule from
a biased sample. The problem is closely related to cost-sensitive learning [11, 7] and the
same techniques such as resampling or differential weighting of samples apply.
However, the methods of the previous two approaches do not apply directly to density
estimation where the setup is “unconditional ”, i.e. there i
s no dependent variable, or, in the
classi ﬁcation terminology, we only have access to positive examples, and the cost function
(log loss) is unbounded. In addition, in the case of modeling species habitats, we face the
challenge of sample sizes that are very small (2– 100) by machine learning standards.

2 Maxent setup

In this section, we describe the setup for unbiased maximum entropy density estimation
and review performance guarantees. We use a relaxed formulation which will yield an
ℓ1 -regularization term in our objective function.

The goal is to estimate an unknown target distribution π over a known sample space X
based on samples x1 , . . . , xm ∈ X . We assume that samples are independently distributed
according to π and denote the empirical distribution by ˜π(x) = |{1 ≤ i ≤ m : xi =
x}|/m. The structure of the problem is speci ﬁed by real valued funct
ions fj : X → R,
j = 1, . . . , n, called features and by a distribution q0 representing a default estimate. We
assume that features capture all the relevant information available for the problem at hand
and q0 is the distribution we would choose if we were given no samples. The distribution
q0 is most often assumed uniform.
For a limited number of samples, we expect that ˜π will be a poor estimate of π under
any reasonable distance measure. However, empirical averages of features will not be too
different from their expectations with respect to π . Let p[f ] denote the expectation of a
function f (x) when x is chosen randomly according to distribution p. We would like to
ﬁnd a distribution p which satis ﬁes
(1)
|p[fj ] − ˜π [fj ]| ≤ βj for all 1 ≤ j ≤ n,
for some estimates βj of deviations of empirical averages from their expectations. Usually
there will be inﬁnitely many distributions satisfying thes e constraints. For the case when
the default distribution q0 is uniform, the maximum entropy principle tells us to choose
the distribution of maximum entropy satisfying these constraints. In general, we should
minimize the relative entropy from q0 . This corresponds to choosing the distribution that
satis ﬁes the constraints (1) but imposes as little addition al information as possible when
compared with q0 . Allowing for asymmetric constraints, we obtain the formulation
RE(p k q0 ) subject to ∀1 ≤ j ≤ n : aj ≤ p[fj ] ≤ bj .
min
p∈∆
Here, ∆ ⊆ RX is the simplex of probability distributions and RE(p k q) is the relative
entropy (or Kullback-Leibler divergence) from q to p, an information theoretic measure of
difference between the two distributions. It is non-negative, equal to zero only when the
two distributions are identical, and convex in its arguments.
Problem (2) is a convex program. Using Lagrange multipliers, we obtain that the solu-
tion takes the form
qλ (x) = q0 (x)eλ·f (x) /Zλ
(3)
where Zλ = Px q0 (x)eλ·f (x) is the normalization constant. Distributions qλ of the form
(3) will be referred to as q0 -Gibbs or just Gibbs when no ambiguity arises.
Instead of solving (2) directly, we solve its dual:
λ∈Rn(cid:16)log Zλ − 1
2 Pj (bj − aj )|λj |(cid:17).
2 Pj (bj + aj )λj + 1
min
We can choose from a range of general convex optimization techniques or use some of the
algorithms in [12]. For the symmetric case when
[aj , bj ] = (cid:2) ˜π [fj ] − βj , ˜π [fj ] + βj (cid:3),
λ∈Rn (cid:16)− ˜π [log qλ ] + Pj βj |λj |(cid:17).
min
The ﬁrst term is the empirical log loss (negative log likelihood), the second term is an ℓ1 -
regularization. Small values of log loss mean a good ﬁt to the data. This is bal anced by
regularization forcing simpler models and hence preventing over ﬁtting.
When all the primal constraints are satis ﬁed by the target dis tribution π then the solution
ˆq of the dual is guaranteed to be not much worse an approximation of π than the best Gibbs
distribution q∗ . More precisely:
Theorem 1 (Performance guarantees, Theorem 1 of [12]). Assume that the distribution
(2). Let ˆq be the solution of the dual (4). Then for an
π satis ﬁes the primal constraints
arbitrary Gibbs distribution q∗ = qλ∗
RE(π k ˆq) ≤ RE(π k q∗ ) + Pj (bj − aj )|λ∗
j |.

the dual becomes

(2)

(4)

(5)

(6)

Input: ﬁnite domain X
features f1 , . . . , fn where fj : X → [0, 1]
regularization parameter β > 0
default estimate q0
samples x1 , . . . , xm ∈ X
sampling distribution s
Output: q ˆλ approximating the target distribution
Let β0 = `β /√m´ · min {fσs[1/s], (max 1/s − min 1/s)/2}
[c0 , d0 ] = ˆfπs[1/s] − β0 , fπs[1/s] + β0 ˜ ∩ ˆmin 1/s, max 1/s]
For j = 1, . . . , n:
βj = `β /√m´ · min {fσs[fj /s], (max fj /s − min fj /s)/2}
[cj , dj ] = ˆfπs[fj /s] − βj , fπs[fj /s] + βj ˜ ∩ ˆmin fj /s, max fj /s]
[aj , bj ] = ˆcj /d0 , dj /c0 ˜ ∩ ˆmin fj , max fj ]
Solve the dual (4)

Algorithm 1: D EB IA SAV ERAG E S .

Table 1: Example 1.
Comparison
of distributions q∗ and q∗∗ minimizing
RE(π k qλ ) and RE(πs k qλ s).

x f (x) π(x) s(x) πs(x) q∗ (x) q∗∗ s(x) q∗∗ (x)
0.34
0.544
0.25
0.64
0.4
1 (0, 0) 0.4
0.16
0.256
0.25
0.16
0.4
2 (0, 1) 0.1
0.34
0.136
0.25
0.04
0.1
3 (1, 0) 0.1
4 (1, 1) 0.4
0.1
0.16
0.25
0.064
0.16

When features are bounded between 0 and 1, the symmetric box constraints (5) with
βj = O(p(log n)/m) are satis ﬁed with high probability by Hoeffding’s inequali
ty and
the union bound. Then the relative entropy from ˆq to π will not be worse than the relative
entropy from any Gibbs distribution q∗ to π by more than O(kλ∗ k1p(log n)/m).
In practice, we set
βj = (cid:0)β /√m(cid:1) · min { ˜σ [fj ], σmax [fj ]}
where β is a tuned constant, ˜σ [fj ] is the sample deviation of fj , and σmax [fj ] is an upper
bound on the standard deviation, such as (maxx fj (x) − minx fj (x))/2. We refer to this
algorithm for unbiased data as UNB IA S EDMAX EN T .

(7)

3 Maxent with sample selection bias
In the biased case, the goal is to estimate the target distribution π , but samples do not come
directly from π . For nonnegative functions p1 , p2 deﬁned on X , let p1p2 denote the distri-
bution obtained by multiplying weights p1 (x) and p2 (x) at every point and renormalizing:

.

p1p2 (x) =

p1 (x)p2 (x)
Px′ p1 (x′ )p2 (x′ )
Samples x1 , . . . , xm come from the biased distribution πs where s is the sampling distri-
bution. This setup corresponds to the situation when an event being observed occurs at the
point x with probability π(x) while we perform an independent observation with probabil-
ity s(x). The probability of observing an event at x given that we observe an event is then
equal to πs(x). The empirical distribution of m samples drawn from πs will be denoted
by fπs. We assume that s is known (principal assumption, see introduction) and strictly
positive (technical assumption).
Approach I: Debiasing Averages.
In our ﬁrst approach, we use the same algorithm as
for the unbiased case but employ a different method to obtain conﬁdence intervals
[aj , bj ].
Since we do not have direct access to samples from π , we use a version of the Bias Cor-
rection Theorem of Zadrozny [6] to convert expectations with respect to πs to expectations
with respect to π .
Theorem 2 (Bias Correction Theorem [6], Translation Theorem [7]).
πs[f /s](cid:14)πs[1/s] = π [f ].

πs[f /s] and πs[1/s] to obtain conﬁ-

Hence, it sufﬁces to give conﬁdence intervals for
dence intervals for π [f ].
Corollary 3. Assume that for some sample-derived bounds cj , dj , 0 ≤ j ≤ n, with high
probability 0 < c0 ≤ πs[1/s] ≤ d0 and 0 ≤ cj ≤ πs[fj /s] ≤ dj for all 1 ≤ j ≤ n. Then
with at least the same probability cj /d0 ≤ π [fj ] ≤ dj /c0 for all 1 ≤ j ≤ n.
If s is bounded away from 0 then Chernoff bounds may be used to determine cj , dj .
Corollary 3 and Theorem 1 then yield guarantees that this method’s performance converges,
with increasing sample sizes, to that of the “best ” Gibbs dis
tribution.
In practice, conﬁdence intervals
[cj , dj ] may be determined using expressions analo-
gous to (5) and (7) for random variables fj /s, 1/s and the empirical distribution fπs. After
ﬁrst restricting the conﬁdence intervals in a natural fashi
on, this yields Algorithm 1. Alter-
natively, we could use bootstrap or other types of estimates for the conﬁdence intervals.
Approach II: Factoring Bias Out. The second algorithm does not approximate π di-
rectly, but uses maxent to estimate the distribution πs and then converts this estimate into
an approximation of π . If the default estimate of π is q0 , then the default estimate of πs is
q0 s. Applying unbiased maxent to the empirical distribution fπs with the default q0 s, we
obtain a q0 s-Gibbs distribution q0 se ˆλ·f approximating πs. We factor out s to obtain q0 e ˆλ·f
as an estimate of π . This yields the algorithm FAC TORB IA SOU T .
This approach corresponds to ℓ1 -regularized maximum likelihood estimation of π by
q0 -Gibbs distributions. When π itself is q0 -Gibbs then the distribution πs is q0 s-Gibbs.
Performance guarantees for unbiased maxent imply that estimates of πs converge to πs as
the number of samples increases. Now, if inf x s(x) > 0 (which is the case for ﬁnite X )
then estimates of π obtained by factoring out s converge to π as well.
When π is not q0 -Gibbs then πs is not q0 s-Gibbs either. We approximate π by a
q0 -Gibbs distribution ˆq = q ˆλ which, with an increasing number of samples, minimizes
RE(πs k qλ s) rather than RE(π k qλ ). Our next example shows that these two minimiz-
ers may be different.
Example 1. Consider the space X = {1, 2, 3, 4} with two features f1 , f2 . Features f1 , f2 ,
target distribution π , sampling distribution s and the biased distribution πs are given in Ta-
ble 1. We use the uniform distribution as a default estimate. The minimizer of RE(π k qλ )
is the unique uniform-Gibbs distribution q∗ such that q∗ [f ] = π [f ]. Similarly, the mini-
mizer q∗∗ s of RE(πs k qλ s) is the unique s-Gibbs distribution for which q∗∗ s[f ] = πs[f ].
Solving for these exactly, we ﬁnd that q∗ and q∗∗ are as given in Table 1, and that these two
distributions differ.
Even though FAC TORB IA SOU T does not minimize RE(π k qλ ), we can show that it
minimizes a different Bregman divergence. More precisely, it minimizes a Bregman di-
vergence between certain projections of the two distributions. Bregman divergences gen-
eralize some common distance measures such as relative entropy or the squared Euclidean
distance, and enjoy many of the same favorable properties. The Bregman divergence asso-
ciated with a convex function F is deﬁned as DF (u k v) = F (u) − F (v) −∇F (v) · (u − v).
+ → R as F (u) = Px s(x)u(x) log u(x). Then F
Proposition 4. Deﬁne F : RX
is a convex function and for all p1 , p2 ∈ ∆, RE(p1 s k p2 s) = DF (p′
1 k p′
2 ), where
1 (x) = p1 (x)/Px′ s(x′ )p1 (x′ ) and p′
2 (x) = p2 (x)/Px′ s(x′ )p2 (x′ ) are projections of
p′
p1 , p2 along lines tp, t ∈ R onto the hyperplane Px s(x)p(x) = 1.
Approach III: Approximating FAC TORB IA SOU T . As mentioned in the introduction,
knowing the sampling distribution s exactly is unrealistic. However, we often have ac-
cess to samples from s.
In this approach we assume that s is unknown but that, in
addition to samples x1 , . . . , xm from πs, we are also given a separate set of samples
x(1) , x(2) , . . . , x(N ) from s. We use the algorithm FAC TORB IA SOU T with the sampling
distribution s replaced by the corresponding empirical distribution ˜s.
To simplify the algorithm, we note that instead of using q0 ˜s as a default estimate for
πs, it sufﬁces to replace the sample space X by X ′ = (cid:8)x(1) , x(2) , . . . , x(N )(cid:9) and use q0

2.5

2

target=π
1
RE(π
||u)=4.5
1

2

1.5

1

target=π
2
RE(π
||u)=5.0
2

2.2

2

1.8

target=π
3
RE(π
||u)=3.3
3

y
p
o
t
r
e
t
n
g
e
r
a
 
e
t
 
v
o
i
t
t
a
l
e
r

1.5
10

100

1000

10

1000

1000

number of training
samples (m)

100
10
100
unbiased maxent
approximate factor bias out
debias averages
1,000 samples
factor bias out
10,000 samples
Figure 1: Learning curves for synthetic experiments. We use u to denote the uniform distribution. For
the sampling distribution s, RE(s k u) = 0.8. Performance is measured in terms of relative entropy
to the target distribution as a function of an increasing number of training samples. The number of
samples is plotted on a log scale.
restricted to X ′ as a default. The last step of factoring out ˜s is equivalent to using ˆλ returned
for space X ′ on the entire space X .
When the sampling distribution s is correlated with feature values, X ′ might not cover
all feature ranges. In that case, reprojecting on X may yield poor estimates outside of these
ranges. We therefore do “clamping”, restricting values
fj (x) to their ranges over X ′ and
capping values of the exponent ˆλ · f (x) at its maximum over X ′ . The resulting algorithm
is called A P PROXFAC TORB IA SOU T .

4 Experiments

Conducting real data experiments to evaluate bias correction techniques is difﬁcult, be-
cause bias is typically unknown and samples from unbiased distributions are not available.
Therefore, synthetic experiments are often a necessity for precise evaluation. Neverthe-
less, in addition to synthetic experiments, we were also able to conduct experiments with
real-world data for habitat modeling.
Synthetic experiments.
In synthetic experiments, we generated three target uniform-
Gibbs distributions π1 , π2 , π3 over a domain X of size 10,000. These distributions were
derived from 65 features indexed as fi , 0 ≤ i ≤ 9 and fij , 0 ≤ i ≤ j ≤ 9. Values
fi (x) were chosen independently and uniformly in [0, 1], and we set fij (x) = fi (x)fj (x).
Fixing these features, we generated weights for each distribution. Weights λi and λii were
generated jointly to capture a range of different behaviors for values of fi in the range [0, 1].
Let US denote a random variable uniform over the set S . Each instance of US corre-
sponds to a new independent variable. We set λii = U{−1,0,1}U[1,5] and λi to be λiiU[−3,1]
if λii 6= 0, and U{−1,1}U[2,10] otherwise. Weights λij , i < j were chosen to create cor-
relations between fi ’s that would be observable, but not strong enough to dominate λi ’s
and λii ’s. We set λij = −0.5 or 0 or 0.5 with respective probabilities 0.05, 0.9 and 0.05.
In maxent, we used a subset of features specifying target distributions and some irrelevant
features. We used features f ′
i , 0 ≤ i ≤ 9 and their squares f ′
ii , where f ′
i (x) = fi (x) for
0 ≤ i ≤ 5 (relevant features) and f ′
i (x) = U[0,1] for 6 ≤ i ≤ 9 (irrelevant features). Once
generated, we used the same set of features in all experiments. We generated a sampling
distribution s correlated with target distributions. More speci ﬁcally, s was a Gibbs distrib-
ii , where f (s)
, 0 ≤ i ≤ 5 and their squares f (s)
ution generated from features f (s)
i (x) = U[0,1]
i
for 0 ≤ i ≤ 1 and f (s)
i = 0 and λ(s)
i = fi+2 for 2 ≤ i ≤ 5. We used weights λ(s)
ii = −1.
For every target distribution, we evaluated the performance of UNB IA S EDMAX EN T ,
D EB IA SAV ERAG E S, FAC TORB IA SOU T and A P PROXFAC TORB IA SOU T with 1,000 and
10,000 samples from the sampling distribution. The performance was evaluated in terms
of relative entropy to the target distribution. We used training sets of sizes 10 to 1000. We
considered ﬁve randomly generated training sets and took th e average performance over
these ﬁve sets for settings of β from the range [0.05, 4.64]. We report results for the best β ,
chosen separately for each average. The rationale behind this approach is that we want to

Table 2: Results of real data experiments. Average performance of unbiased maxent and three bias
correction approaches over all species in six regions. The uniform distribution would receive the
log loss of 14.2 and AUC of 0.5. Results of bias correction approaches are italicized if they are
signiﬁcantly worse and set in boldface if they are signiﬁcantly better than tho
se of the unbiased
maxent according to a paired t-test at the level of signiﬁcance 5%.
average AUC
average log loss
awt
swi
sa
can nsw nz
awt
swi
sa
nz
nsw
can
13.78 12.89 13.40 13.77 13.14 12.81 0.69 0.58 0.71 0.72 0.78 0.81
unbiased maxent
13.92 13.10 13.88 14.31 14.10 13.59 0.67 0.64 0.65 0.67 0.68 0.78
debias averages
13.90 13.13 14.06 14.20 13.66 13.46 0.71 0.69 0.72 0.72 0.78 0.83
factor bias out
apx. factor bias out 13.89 13.40 14.19 14.07 13.62 13.41 0.72 0.72 0.73 0.73 0.78 0.84

explore the potential performance of each method.
Figure 1 shows the results at the optimal β as a function of an increasing number of sam-
ples. FAC TORB IA SOU T is always better than UNB IA S EDMAX EN T . D EB IA SAV ERAG E S is
worse than UNB IA S EDMAX EN T for small sample sizes, but as the number of training sam-
ples increases, it soon outperforms UNB IA S EDMAX EN T and eventually also outperforms
FAC TORB IA SOU T . A P PROXFAC TORB IA SOU T improves as the number of samples from
the sampling distribution increases from 1,000 to 10,000, but both versions of A P PROX -
FAC TORB IA SOU T perform worse than UNB IA S EDMAX EN T for the distribution π2 .
Real data experiments.
In this set of experiments, we evaluated maxent in the task of
estimating species habitats. The sample space is a geographic region divided into a grid
of cells and samples are known occurrence localities — cells where a given species was
observed. Every cell is described by a set of environmental variables, which may be cat-
egorical, such as vegetation type, or continuous, such as altitude or annual precipitation.
Features are real-valued functions derived from environmental variables. We used binary
indicator features for different values of categorical variables and binary threshold features
for continuous variables. The latter are equal to one when the value of a variable is greater
than a ﬁxed threshold and zero otherwise.
Species sample locations and environmental variables were all produced and used as
part of the “Testing alternative methodologies for modelin g species’ ecological niches and
predicting geographic distributions ” Working Group at the National Center for Ecological
Analysis and Synthesis (NCEAS). The working group compared modeling methods across
a variety of species and regions. The training set contained presence-only data from un-
planned surveys or incidental records, including those from museums and herbariums. The
test set contained presence-absence data from rigorously planned independent surveys.
We compared performance of our bias correction approaches with that of the unbiased
maxent which was among the top methods in the NCEAS comparison [13]. We used the full
dataset consisting of 226 species in 6 regions with 2–5822 tr aining presences per species
(233 on average) and 102–19120 test presences/absences. Fo r more details see [13].
We treated training occurrence locations for all species in each region as sampling
distribution samples and used them directly in A P PROXFAC TORB IA SOU T .
In order to
apply D EB IA SAV ERAG E S and FAC TORB IA SOU T , we estimated the sampling distribution
using unbiased maxent. Sampling distribution estimation is also the ﬁrst step of [6]. In
contrast with that work, however, our experiments do not use the sampling distribution
estimate during evaluation and hence do not depend on its quality.
The resulting distributions were evaluated on test presences according to the log loss
and on test presences and absences according to the area under an ROC curve (AUC) [14].
AUC quanti ﬁes how well the predicted distribution ranks tes t presences above test ab-
sences. Its value is equal to the probability that a randomly chosen presence will be ranked
above a randomly chosen absence. The uniformly random prediction receives AUC of 0.5
while a perfect prediction receives AUC of 1.0.
In Table 2 we show performance of our three approaches compared with the unbiased
maxent. All three algorithms yield on average a worse log loss than the unbiased maxent.
This can perhaps be attributed to the imperfect estimate of the sampling distribution or to

the sampling distribution being zero over large portions of the sample space. In contrast,
when the performance is measured in terms of AUC, FAC TORB IA SOU T and A P PROX -
FAC TORB IA SOU T yield on average the same or better AUC as UNB IA S EDMAX EN T in all
six regions. Improvements in regions awt, can and swi are dramatic enough so that both of
these methods perform better than any method evaluated in [13].

5 Conclusions
We have proposed three approaches that incorporate information about sample selection
bias in maxent and demonstrated their utility in synthetic and real data experiments. Ex-
periments also raise several questions that merit further research: D EB IA SAV ERAG E S has
the strongest performance guarantees, but it performs the worst in real data experiments
and catches up with other methods only for large sample sizes in synthetic experiments.
This may be due to poor estimates of unbiased conﬁdence inter vals and could be possibly
improved using a different estimation method. FAC TORB IA SOU T and A P PROXFAC TOR -
B IA SOU T improve over UNB IA S EDMAX EN T in terms of AUC over real data, but are worse
in terms of log loss. This disagreement suggests that methods which aim to optimize AUC
directly could be more successful in species modeling, possibly incorporating some con-
cepts from FAC TORB IA SOU T and A P PROXFAC TORB IA SOU T . A P PROXFAC TORB IA S -
OU T performs the best on real world data, possibly due to the direct use of samples from the
sampling distribution rather than a sampling distribution estimate. However, this method
comes without performance guarantees and does not exploit the knowledge of the full sam-
ple space. Proving performance guarantees for A P PROXFAC TORB IA SOU T remains open
for future research.

Acknowledgments
This material is based upon work supported by NSF under grant 0325463. Any opinions, ﬁndings, and conclusions
or recommendations expressed in this material are those of the authors and do not necessarily reﬂect the views
of NSF. The NCEAS data was kindly shared with us by the members of the “Testing alternative methodologies
for modeling species’ ecological niches and predicting geographic distributions” Working Group, which was
supported by the National Center for Ecological Analysis and Synthesis, a Center funded by NSF (grant DEB-
0072909), the University of California and the Santa Barbara campus.

References
[1] Jane Elith. Quantitative methods for modeling species habitat: Comparative performance and an application
to Australian plants. In Scott Ferson and Mark Burgman, editors, Quantitative Methods for Conservation
Biology, pages 39 –58. Springer-Verlag, 2002.
[2] A. Guisan and N. E. Zimmerman. Predictive habitat distribution models in ecology. Ecological Modelling,
135:147 –186, 2000.
[3] Steven J. Phillips, Miroslav Dud´ık, and Robert E. Schapire. A maximum entropy approach to speci es distri-
bution modeling. In Proceedings of the Twenty-First International Conference on Machine Learning, 2004.
[4] S. Reddy and L. M. D ´avalos. Geographical sampling bias and its implications for conservation priorities in
Africa. Journal of Biogeography, 30:1719 –1727, 2003.
[5] Barbara R. Stein and John Wieczorek. Mammals of the world: MaNIS as an example of data integration in
a distributed network environment. Biodiversity Informatics, 1(1):14 –22, 2004.
[6] Bianca Zadrozny. Learning and evaluating classiﬁers un der sample selection bias. In Proceedings of the
Twenty-First International Conference on Machine Learning, 2004.
[7] Bianca Zadrozny, John Langford, and Naoki Abe. Cost-sensitive learning by cost-proportionate example
weighting. In Proceedings of the Third IEEE International Conference on Data Mining, 2003.
[8] James J. Heckman. Sample selection bias as a speciﬁcation er ror. Econometrica, 47(1):153 –161, 1979.
[9] Robert M. Groves. Survey Errors and Survey Costs. Wiley, 1989.
[10] Roderick J. Little and Donald B. Rubin. Statistical Analysis with Missing Data. Wiley, second edition, 2002.
[11] Charles Elkan. The foundations of cost-sensitive learning. In Proceedings of the Seventeenth International
Joint Conference on Artiﬁcial Intelligence , 2001.
[12] Miroslav Dud´ık, Steven J. Phillips, and Robert E. Schapire. Performance g uarantees for regularized maxi-
mum entropy density estimation. In 17th Annual Conference on Learning Theory, 2004.
[13] J. Elith, C. Graham, and NCEAS working group. Comparing methodologies for modeling species’ distribu-
tions from presence-only data. In preparation.
[14] J. A. Hanley and B. S. McNeil. The meaning and use of the area under a receiver operating characteristic
(ROC) curve. Radiology, 143:29 –36, 1982.

