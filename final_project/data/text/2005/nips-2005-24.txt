Improved Risk Tail Bounds
for On-Line Algorithms ∗

Nicol `o Cesa-Bianchi
DSI, Universit `a di Milano
via Comelico 39
20135 Milano, Italy
cesa-bianchi@dsi.unimi.it

Claudio Gentile
DICOM, Universit `a dell’Insubria
via Mazzini 5
21100 Varese, Italy
gentile@dsi.unimi.it

Abstract

We prove the strongest known bound for the risk of hypotheses selected
from the ensemble generated by running a learning algorithm incremen-
tally on the training data. Our result is based on proof techniques that are
remarkably different from the standard risk analysis based on uniform
convergence arguments.

1

Introduction

In this paper, we analyze the risk of hypotheses selected from the ensemble obtained by
running an arbitrary on-line learning algorithm on an i.i.d. sequence of training data. We
describe a procedure that selects from the ensemble a hypothesis whose risk is, with high
probability, at most
Mn + O   (ln n)2
ln n! ,
+ r Mn
n
n
where Mn is the average cumulative loss incurred by the on-line algorithm on a training
sequence of length n. Note that this bound exhibits the “fast ” rate
(ln n)2 /n whenever the
cumulative loss nMn is O(1).
This result is proven through a reﬁnement of techniques that we used in [2] to prove the
substantially weaker bound Mn + O(cid:0)p(ln n)/n(cid:1). As in the proof of the older result, we
analyze the empirical process associated with a run of the on-line learner using exponential
inequalities for martingales. However, this time we control the large deviations of the
on-line process using Bernstein’s maximal inequality rather than the Azuma-Hoeffding
inequality. This provides a much tighter bound on the average risk of the ensemble. Finally,
we relate the risk of a speci ﬁc hypothesis within the ensembl e to the average risk. As in [2],
we select this hypothesis using a deterministic sequential testing procedure, but the use of
Bernstein’s inequality makes the analysis of this procedure far more complicated.

The study of the statistical risk of hypotheses generated by on-line algorithms, initiated
by Littlestone [5], uses tools that are sharply different from those used for uniform con-
vergence analysis, a popular approach based on the manipulation of suprema of empirical

∗Part of the results contained in this paper have been presented in a talk given at the NIPS 2004
workshop on “(Ab)Use of Bounds ”.

processes (see, e.g., [3]). Unlike uniform convergence, which is tailored to empirical risk
minimization, our bounds hold for any learning algorithm. Indeed, disregarding efﬁciency
issues, any learner can be run incrementally on a data sequence to generate an ensemble of
hypotheses.

The consequences of this line of research to kernel and margin-based algorithms have been
presented in our previous work [2].

Notation. An example is a pair (x, y), where x ∈ X (which we call instance) is a data
element and y ∈ Y is the label associated with it. Instances x are tuples of numerical and/or
symbolic attributes. Labels y belong to a ﬁnite set of symbols (the class elements) or to
an interval of the real line, depending on whether the task is classi ﬁcation or regression.
We allow a learning algorithm to output hypotheses of the form h : X → D , where D
is a decision space not necessarily equal to Y . The goodness of hypothesis h on example
(x, y) is measured by the quantity ℓ(h(x), y), where ℓ : D × Y → R is a nonnegative and
bounded loss function.

2 A bound on the average risk

An on-line algorithm A works in a sequence of trials. In each trial t = 1, 2, . . . the algo-
rithm takes in input a hypothesis Ht−1 and an example Zt = (Xt , Yt ), and returns a new
hypothesis Ht to be used in the next trial. We follow the standard assumptions in statis-
tical learning: the sequence of examples Z n = (cid:0)(X1 , Y1 ), . . . , (Xn , Yn )(cid:1) is drawn i.i.d.
according to an unknown distribution over X × Y . We also assume that the loss function ℓ
satis ﬁes 0 ≤ ℓ ≤ 1. The success of a hypothesis h is measured by the risk of h, denoted by
risk(h). This is the expected loss of h on an example (X, Y ) drawn from the underlying
distribution, risk(h) = E ℓ(h(X ), Y ). Deﬁne also riskemp (h) to be the empirical risk
of h on a sample Z n ,
nXt=1
Given a sample Z n and an on-line algorithm A, we use H0 , H1 , . . . , Hn−1 to denote the
ensembleofhypothesesgeneratedby A. Note that the ensemble is a function of the random
training sample Z n . Our bounds hinge on the sample statistic
nXt=1
which can be easily computed as the on-line algorithm is run on Z n .
The following bound, a consequence of Bernstein’s maximal inequality for martingales due
to Freedman [4], is of primary importance for proving our results.

ℓ(Ht−1 (Xt ), Yt )

Mn = Mn (Z n ) =

1
n

1
n

riskemp (h) =

ℓ(h(Xt ), Yt ) .

Lemma 1 Let L1 , L2 , . . . be a sequence of random variables, 0 ≤ Lt ≤ 1. Deﬁne the
bounded martingale difference sequence Vt = E[Lt | L1 , . . . , Lt−1 ] − Lt and the asso-
ciated martingale Sn = V1 + . . . + Vn with conditional variance Kn = Pn
t=1 Var[Lt |
L1 , . . . , Lt−1 ]. Then, for all s, k ≥ 0,
P (Sn ≥ s, Kn ≤ k) ≤ exp (cid:18)−
2k + 2s/3 (cid:19) .
s2
The next proposition, derived from Lemma 1, establishes a bound on the average risk of
the ensemble of hypotheses.

Proposition 2 Let H0 , . . . , Hn−1 be the ensemble of hypotheses generated by an arbitrary
on-line algorithm A. Then, for any 0 < δ ≤ 1,
(cid:19) + 2 s Mn
(cid:19)!≤ δ .
P  1
ln (cid:18) n Mn + 3
ln (cid:18) n Mn + 3
nXt=1
36
risk(Ht−1 ) ≥ Mn +
n
n
δ
n
δ
The bound shown in Proposition 2 has the same rate as a bound recently proven by
Zhang [6, Theorem 5]. However, rather than deriving the bound from Bernstein inequality
as we do, Zhang uses an ad hoc argument.

Proof. Let
nXt=1
1
for t ≥ 1.
and Vt−1 = risk(Ht−1 ) − ℓ(Ht−1 (Xt ), Yt )
risk(Ht−1 )
µn =
n
Let κt be the conditional variance Var(cid:0)ℓ(Ht−1 (Xt ), Yt ) | Z1 , . . . , Zt−1 (cid:1). Also, set
for brevity Kn = Pn
t=1 κt , K ′n = ⌊Pn
t=1 κt ⌋, and introduce the function A(x) =
2 ln (x+1)(x+3)
for x ≥ 0. We ﬁnd upper and lower bounds on the probability
δ
Vt−1 ≥ A(Kn ) + pA(Kn ) Kn! .
P  nXt=1
The upper bound is determined through a simple strati ﬁcatio n argument over Lemma 1.
We can write
Vt−1 ≥ A(Kn ) + pA(Kn ) Kn(cid:17)
P(cid:16) nXt=1
Vt−1 ≥ A(K ′n ) + pA(K ′n ) K ′n(cid:17)
≤ P(cid:16) nXt=1
Vt−1 ≥ A(s) + pA(s) s, K ′n = s(cid:17)
P(cid:16) nXt=1
nXs=0
≤
Vt−1 ≥ A(s) + pA(s) s, Kn ≤ s + 1(cid:17)
P(cid:16) nXt=1
nXs=0
(A(s) + pA(s) s)2
3 (A(s) + pA(s) s) + 2(s + 1) (cid:17) (using Lemma 1).
exp(cid:16)−
nXs=0
≤
2
(A(s)+√A(s) s)2
3 “A(s)+√A(s) s”+2(s+1) ≥ A(s)/2 for all s ≥ 0, we obtain
2
nXs=0
nXs=0
δ
(1) ≤
(s + 1)(s + 3)
As far as the lower bound on (1) is concerned, we note that our assumption 0 ≤ ℓ ≤ 1
implies κt ≤ risk(Ht−1 ) for all t which, in turn, gives Kn ≤ nµn . Thus
(1) = P(cid:16)nµn − nMn ≥ A(Kn ) + pA(Kn ) Kn(cid:17)
≥ P(cid:16)nµn − nMn ≥ A(nµn ) + pA(nµn ) nµn(cid:17)
= P(cid:16)2nµn ≥ 2nMn + 3A(nµn ) + p4n Mn A(nµn ) + 5A(nµn )2(cid:17)
2 A(x) + qB A(x) + 5
= P(cid:16)x ≥ B + 3
4 A2 (x)(cid:17),

e−A(s)/2 =

Since

≤

(1)

< δ.

(2)

where we set for brevity x = nµn and B = n Mn . We would like to solve the inequality
2 A(x) + qB A(x) + 5
x ≥ B + 3
(3)
4 A2 (x)
w.r.t. x. More precisely, we would like to ﬁnd a suitable upper bound o n the (unique) x∗
such that the above is satis ﬁed as an equality.
A (tedious) derivative argument along with the upper bound A(x) ≤ 4 ln (cid:0) x+3
δ (cid:1) show that
x′ = B + 2 qB ln (cid:0) B+3
δ (cid:1) + 36 ln (cid:0) B+3
δ (cid:1)
makes the left-hand side of (3) larger than its right-hand side. Thus x′ is an upper bound
on x∗ , and we conclude that
(1) ≥ P(cid:16)x ≥ B + 2 qB ln (cid:0) B+3
δ (cid:1) (cid:17)
δ (cid:1) + 36 ln (cid:0) B+3
which, recalling the deﬁnitions of x and B , and combining with (2), proves the bound. (cid:3)
3 Selecting a good hypothesis from the ensemble
If the decision space D of A is a convex set and the loss function ℓ is convex in its ﬁrst
argument, then via Jensen’s inequality we can directly apply the bound of Proposition 2 to
n Pn
the risk of the averagehypothesis H = 1
t=1 Ht−1 . This yields
(cid:19) + 2 s Mn
(cid:19)! ≤ δ .
P  risk(H ) ≥ Mn +
ln (cid:18) n Mn + 3
ln (cid:18) n Mn + 3
36
δ
n
δ
n
Observe that this is a O(1/n) bound whenever the cumulative loss n Mn is O(1).
If the convexity hypotheses do not hold (as in the case of classi ﬁcation problems), then
the bound in (4) applies to a hypothesis randomly drawn from the ensemble (this was
investigated in [1] though with different goals).

(4)

and

In this section we show how to deterministically pick from the ensemble a hypothesis
whose risk is close to the average ensemble risk.
To see how this could be done, let us ﬁrst introduce the functi ons
, t! ,
cδ (r, t) = Eδ  r + r 2B r
+ r 2B r
8B
Eδ (r, t) =
3(n − t)
n − t
n − t
with B = ln n(n+2)
.
δ
Let riskemp (Ht , t + 1) + Eδ (cid:0)riskemp (Ht , t + 1), t(cid:1) be the penalized empirical risk of
hypothesis Ht , where
nXi=t+1
1
riskemp (Ht , t + 1) =
ℓ(Ht (Xi ), Yi )
n − t
is the empirical risk of Ht on the remaining sample Zt+1 , . . . , Zn . We now analyze the per-
formance of the learning algorithm that returns the hypothesis bH minimizing the penalized
risk estimate over all hypotheses in the ensemble, i.e., 1
0≤t<n (cid:16)riskemp (Ht , t + 1) + Eδ (cid:0)riskemp (Ht , t + 1), t(cid:1)(cid:17) .
bH = argmin
(5)
1Note that, from an algorithmic point of view, this hypothesis is fairly easy to compute. In par-
ticular, if the underlying on-line algorithm is a standard kernel-based algorithm, bH can be calculated
via a single sweep through the example sequence.

Lemma 3 Let H0 , . . . , Hn−1 be the ensemble of hypotheses generated by an arbitrary on-
line algorithm A working with a loss ℓ satisfying 0 ≤ ℓ ≤ 1. Then, for any 0 < δ ≤ 1, the
hypothesis bH satis ﬁes
0≤t<n(cid:0)risk(Ht ) + 2 cδ (risk(Ht ), t)(cid:1)(cid:19) ≤ δ .
P (cid:18)risk( bH ) > min
Proof. We introduce the following short-hand notation
bT = argmin
Rt = riskemp (Ht , t + 1),
(Rt + Eδ (Rt , t))
0≤t<n
T ∗ = argmin
(risk(Ht ) + 2cδ (risk(Ht ), t)) .
0≤t<n
Also, let H ∗ = HT ∗ and R∗ = riskemp (HT ∗ , T ∗ + 1) = RT ∗ . Note that bH deﬁned
in (5) coincides with H bT . Finally, let
Q(r, t) = p2B (2B + 9r(n − t)) − 2B
.
3(n − t)
With this notation we can write
P(cid:18)risk( bH ) > risk(H ∗ ) + 2cδ (risk(H ∗ ), T ∗ )(cid:19)
≤ P(cid:18)risk( bH ) > risk(H ∗ ) + 2cδ (cid:0)R∗ − Q(R∗ , T ∗ ), T ∗ (cid:1)(cid:19)
+ P(cid:18)risk(H ∗ ) < R∗ − Q(R∗ , T ∗ )(cid:19)
≤ P(cid:18)risk( bH ) > risk(H ∗ ) + 2cδ (R∗ − Q(R∗ , T ∗ ), T ∗ ) (cid:19)
P(cid:18)risk(Ht ) < Rt − Q(Rt , t)(cid:19) .
n−1Xt=0
+
Applying the standard Bernstein’s inequality (see, e.g., [3, Ch. 8]) to the random variables
Rt with |Rt | ≤ 1 and expected value risk(Ht ), and upper bounding the variance of Rt
with risk(Ht ), yields
B + pB (B + 18(n − t)risk(Ht ))
(cid:19)≤ e−B .
P(cid:18)risk(Ht ) < Rt −
3(n − t)
With a little algebra, it is easy to show that
B + pB (B + 18(n − t)risk(Ht ))
risk(Ht ) < Rt −
3(n − t)
is equivalent to risk(Ht ) < Rt − Q(Rt , t). Hence, we get
P(cid:18)risk( bH ) > risk(H ∗ ) + 2cδ (risk(H ∗ ), T ∗ )(cid:19)
≤ P(cid:18)risk( bH ) > risk(H ∗ ) + 2cδ (R∗ − Q(R∗ , T ∗ ), T ∗ ) (cid:19)+n e−B
≤ P(cid:18)risk( bH ) > risk(H ∗ ) + 2Eδ (R∗ , T ∗ )(cid:19)+n e−B

, t! = Eδ (r, t) .

cδ  r − r 2B r
n − t

where in the last step we used
Q(r, t) ≤ r 2B r
and
n − t
Set for brevity E = Eδ (R∗ , T ∗ ). We have
P(cid:18)risk( bH ) > risk(H ∗ ) + 2E (cid:19)
= P(cid:18)risk( bH ) > risk(H ∗ ) + 2E , R bT + Eδ (R bT , bT ) ≤ R∗ + E (cid:19)
(since R bT + Eδ (R bT , bT ) ≤ R∗ + E holds with certainty)
P(cid:18)Rt + Eδ (Rt , t) ≤ R∗ + E , risk(Ht ) > risk(H ∗ ) + 2E (cid:19) .
n−1Xt=0
≤
Now, if Rt + Eδ (Rt , t) ≤ R∗ + E holds, then at least one of the following three conditions
Rt ≤ risk(Ht ) − Eδ (Rt , t), R∗ > risk(H ∗ ) + E , risk(Ht ) − risk(H ∗ ) < 2E
must hold. Hence, for any ﬁxed t we can write
P(cid:18)Rt + Eδ (Rt , t) ≤ R∗ + E , risk(Ht ) > risk(H ∗ ) + 2E (cid:19)
≤ P(cid:18)Rt ≤ risk(Ht ) − Eδ (Rt , t), risk(Ht ) > risk(H ∗ ) + 2E (cid:19)
+ P(cid:18)R∗ > risk(H ∗ ) + E , risk(Ht ) > risk(H ∗ ) + 2E (cid:19)
+ P(cid:18)risk(Ht ) − risk(H ∗ ) < 2 E , risk(Ht ) > risk(H ∗ ) + 2E (cid:19)
≤ P(cid:18)Rt ≤ risk(Ht ) − Eδ (Rt , t)(cid:19)+P(cid:18)R∗ > risk(H ∗ ) + E (cid:19) .
Plugging (7) into (6) we have
P (cid:16)risk( bH ) > risk(H ∗ ) + 2E (cid:17)
P(cid:18)Rt ≤ risk(Ht ) − Eδ (Rt , t)(cid:19)+n P(cid:18)R∗ > risk(H ∗ ) + E (cid:19)
n−1Xt=0
≤
P(cid:18)Rt ≥ risk(Ht ) + Eδ (Rt , t)(cid:19) ≤ n e−B + n2 e−B ,
n−1Xt=0
≤ n e−B + n
where in the last two inequalities we applied again Bernstein’s inequality to the random
variables Rt with mean risk(Ht ). Putting together we obtain
P(cid:0)risk( bH ) > risk(H ∗ ) + 2cδ (risk(H ∗ ), T ∗ )(cid:1)≤ (2n + n2 )e−B
which, recalling that B = ln n(n+2)
, implies the thesis.
δ
Fix n ≥ 1 and δ ∈ (0, 1). For each t = 0, . . . , n − 1, introduce the function
+ 2r 2C x
11C
ln(n − t) + 1
ft (x) = x +
,
x ≥ 0,
n − t
3
n − t
where C = ln 2n(n+2)
. Note that each ft is monotonically increasing. We are now ready
δ
to state and prove the main result of this paper.

(6)

(7)

(cid:3)

ln

ln

(8)

Theorem 4 Fix any loss function ℓ satisfying 0 ≤ ℓ ≤ 1. Let H0 , . . . , Hn−1 be the ensem-
ble of hypotheses generated by an arbitrary on-line algorithm A and let bH be the hypoth-
esis minimizing the penalized empirical risk expression obtained by replacing cδ with cδ/2
in (5). Then, for any 0 < δ ≤ 1, bH satis ﬁes
+ 2 s Mt,n ln 2n(n+3)
!!≤ δ,
ft Mt,n +
P risk( bH ) ≥ min
2n(n + 3)
36
δ
n − t
δ
n − t
0≤t<n
n−t Pn
where Mt,n = 1
i=t+1 ℓ(Hi−1 (Xi ), Yi ). In particular, upper bounding the minimum
over t with t = 0 yields
+ 2 s Mn ln 2n(n+3)
!!≤ δ .
P risk( bH ) ≥ f0 Mn +
2n(n + 3)
36
δ
n
n
δ
For n → ∞, bound (8) shows that risk( bH ) is bounded with high probability by
n ! .
Mn + O   ln2 n
+ r Mn ln n
n
If the empirical cumulative loss n Mn is small (say, Mn ≤ c/n, where c is constant with n),
then our penalized empirical risk minimizer bH achieves a O(cid:0)(ln2 n)/n(cid:1) risk bound. Also,
recall that, in this case, under convexity assumptions the average hypothesis H achieves
the sharper bound O(1/n).
n−t Pn−1
Proof. Let µt,n = 1
i=t risk(Hi ). Applying Lemma 3 with cδ/2 we obtain
P(cid:16)risk( bH ) > min
0≤t<n (cid:0)risk(Ht ) + cδ/2 (risk(Ht ), t)(cid:1) (cid:17)≤
We then observe that
0≤t<n(cid:16)risk(Ht ) + cδ/2 (risk(Ht ), t)(cid:17)
min
t≤i<n(cid:16)risk(Hi ) + cδ/2 (risk(Hi ), i)(cid:17)
= min
min
0≤t<n
n−1Xi=t (cid:16)risk(Hi ) + cδ/2 (risk(Hi ), i)(cid:17)
1
≤ min
n − t
0≤t<n
n−1Xi=t  r 2C risk(Hi )
0≤t<n  µt,n +
n−1Xi=t
C
1
8
1
+
≤ min
n − t
n − i
3
n − t
n − i
(using the inequality √x + y ≤ √x + y
2√x )
!
0≤t<n  µt,n +
n−1Xi=t r 2C risk(Hi )
n−1Xi=t
C
1
1
11
+
= min
n − t
n − i
3
n − t
n − i
n − t !
0≤t<n  µt,n +
+ 2r 2C µt,n
ln(n − t) + 1
11C
≤ min
n − t
3
(using Pk
i=1 1/i ≤ 1 + ln k and the concavity of the square root)
= min
ft (µt,n ) .
0≤t<n

n − i !!
C

δ
2

.

(9)

+

(10)

Now, it is clear that Proposition 2 can be immediately generalized to imply the following
set of inequalities, one for each t = 0, . . . , n − 1,
n − t ! ≤
P  µt,n ≥ Mt,n +
+ 2 r Mt,n A
δ
36 A
n − t
2n
where A = ln 2n(n+3)
. Introduce the random variables K0 , . . . , Kn−1 to be deﬁned later.
δ
We can write
Kt!
P  min
0≤t<n(cid:16)risk(Ht ) + cδ/2 (risk(Ht ), t)(cid:17)≥ min
0≤t<n
Kt(cid:19) ≤
≤ P (cid:18) min
n−1Xt=0
P (ft (µt,n ) ≥ Kt ) .
ft (µt,n ) ≥ min
0≤t<n
0≤t<n
Now, for each t = 0, . . . , n− 1, deﬁne Kt = ft (cid:18)Mt,n + 36 A
n−t (cid:19) . Then (10)
n−t + 2 q Mt,n A
and the monotonicity of f0 , . . . , fn−1 allow us to obtain
Kt!
P  min
0≤t<n(cid:16)risk(Ht ) + cδ/2 (risk(Ht ), t)(cid:17)≥ min
0≤t<n
P  ft (µt,n ) ≥ ft  Mt,n +
n − t !!
+ 2 r Mt,n A
n−1Xt=0
36 A
≤
n − t
n − t ! ≤ δ/2 .
P  µt,n ≥ Mt,n +
+ 2 r Mt,n A
n−1Xt=0
36 A
n − t
Combining with (9) concludes the proof.
4 Conclusions and current research issues

=

(cid:3)

We have shown tail risk bounds for speci ﬁc hypotheses select ed from the ensemble gen-
erated by the run of an arbitrary on-line algorithm. Proposition 2, our simplest bound, is
proven via an easy application of Bernstein’s maximal inequality for martingales, a quite
basic result in probability theory. The analysis of Theorem 4 is also centered on the same
martingale inequality. An open problem is to simplify this analysis, possibly obtaining a
more readable bound. Also, the bound shown in Theorem 4 contains ln n terms. We do not
know whether these logarithmic terms can be improved to ln(Mnn), similarly to Propo-
sition 2. A further open problem is to prove lower bounds, even in the special case when
nMn is bounded by a constant.

References
[1] A. Blum, A. Kalai, and J. Langford. Beating the hold-out. In Proc. 12th COLT, 1999.
[2] N. Cesa-Bianchi, A. Conconi, and C. Gentile. On the generalization ability of on-line
learning algorithms. IEEE Trans. on Information Theory, 50(9):2050–2057, 2004.
[3] L. Devroye, L. Gy ˝or ﬁ, and G. Lugosi. A Probabilistic Theory of Pattern Recognition.
Springer Verlag, 1996.
[4] D. A. Freedman. On tail probabilities for martingales. The Annals of Probability,
3:100–118, 1975.
[5] N. Littlestone. From on-line to batch learning. In Proc. 2nd COLT, 1989.
[6] T. Zhang. Data dependent concentration bounds for sequential prediction algorithms.
In Proc. 18th COLT, 2005.

