Inference with Minimal Communication:
a Decision-Theoretic Variational Approach

O. Patrick Kreidl and Alan S. Willsky
Department of Electrical Engineering and Computer Science
MIT Laboratory for Information and Decision Systems
Cambridge, MA 02139
{opk,willsky}@mit.edu

Abstract

Given a directed graphical model with binary-valued hidden nodes and
real-valued noisy observations, consider deciding upon the maximum
a-posteriori (MAP) or the maximum posterior-marginal (MPM) assign-
ment under the restriction that each node broadcasts only to its children
exactly one single-bit message. We present a variational formulation,
viewing the processing rules local to all nodes as degrees-of-freedom,
that minimizes the loss in expected (MAP or MPM) performance subject
to such online communication constraints. The approach leads to a novel
message-passing algorithm to be executed ofﬂine , or before observations
are realized, which mitigates the performance loss by iteratively cou-
pling all rules in a manner implicitly driven by global statistics. We also
provide (i) illustrative examples, (ii) assumptions that guarantee conver-
gence and efﬁciency and (iii) connections to active researc h areas.

1

Introduction

Given a probabilistic model with discrete-valued hidden variables, Belief Propagation (BP)
and related graph-based algorithms are commonly employed to solve for the Maximum A-
Posteriori (MAP) assignment (i.e., the mode of the joint distribution of all hidden variables)
and Maximum-Posterior-Marginal (MPM) assignment (i.e., the modes of the marginal dis-
tributions of every hidden variable) [1]. The established “ message-passing” interpretation
of BP extends naturally to a distributed network setting: associating to each node and
edge in the graph a distinct processor and communication link, respectively, the algorithm
is equivalent to a sequence of purely-local computations interleaved with only nearest-
neighbor communications. Speci ﬁcally, each computation e vent corresponds to a node
evaluating its local processing rule, or a function by which all messages received in the
preceding communication event map to messages sent in the next communication event.

Practically, the viability of BP appears to rest upon an implicit assumption that network
communication resources are abundant. In a general network, because termination of the al-
gorithm is in question, the required communication resources are a-priori unbounded. Even
when termination can be guaranteed, transmission of exact messages presumes communi-
cation channels with inﬁnite capacity (in bits per observat
ion), or at least of sufﬁciently
high bandwidth such that the resulting ﬁnite message precis ion is essentially error-free. In

some distributed settings (e.g., energy-limited wireless sensor networks), it may be pro-
hibitively costly to justify such idealized online communications. While recent evidence
suggests substantial but “small-enough” message errors wi
ll not alter the behavior of BP
[2], [3], it also suggests BP may perform poorly when communication is very constrained.

Assuming communication constraints are severe, we examine the extent to which alterna-
tive processing rules can avoid a loss in (MAP or MPM) performance. Speci ﬁcally, given
a directed graphical model with binary-valued hidden variables and real-valued noisy ob-
servations, we assume each node may broadcast only to its children a single binary-valued
message. We cast the problem within a variational formulation [4], seeking to minimize a
decision-theoretic penalty function subject to such online communication constraints. The
formulation turns out to be an extension of the optimization problem underlying the decen-
tralized detection paradigm [5], [6], which advocates a team-theoretic [7] relaxation of the
original problem to both justify a particular ﬁnite paramet erization for all local processing
rules and obtain an iterative algorithm to be executed ofﬂine (i.e., before observations are
realized). To our knowledge, that this relaxation permits analytical progress given any di-
rected acyclic network is new. Moreover, for MPM assignment in a tree-structured network,
we discover an added convenience with respect to the envisioned distributed processor set-
ting: the ofﬂine computation itself admits an efﬁcient mess
age-passing interpretation.

This paper is organized as follows. Section 2 details the decision-theoretic variational for-
mulation for discrete-variable assignment. Section 3 summarizes the main results derived
from its connection to decentralized detection, culminating in the ofﬂine message-passing
algorithm and the assumptions that guarantee convergence and maximal efﬁciency. We
omit the mathematical proofs [8] here, focusing instead on intuition and illustrative exam-
ples. Closing remarks and relations to other active research areas appear in Section 4.

2 Variational Formulation

In abstraction, the basic ingredients are (i) a joint distribution p(x, y) for two length-N
random vectors X and Y , taking hidden and observable values in the sets {0, 1}N and
RN , respectively; (ii) a decision-theoretic penalty function J : Γ → R, where Γ denotes
the set of all candidate strategies γ : RN → {0, 1}N for posterior assignment; and (iii) the
set ΓG ⊂ Γ of strategies that also respect stipulated communication constraints in a given
N -node directed acyclic network G . The ensuing optimization problem is expressed by
J (γ ∗ ) = min
(1)
subject to γ ∈ ΓG ,
J (γ )
γ∈Γ
where γ ∗ then represents an optimal network-constrained strategy for discrete-variable as-
signment. The following subsections provide details unseen at this level of abstraction.

2.1 Decision-Theoretic Penalty Function

Let U = γ (Y ) denote the decision process induced from the observation process Y by
any candidate assignment strategy γ ∈ Γ. If we associate a numeric “cost ”
c(u, x) to every
possible joint realization of (U, X ), then the expected cost is a well-posed penalty function:
(2)
J (γ ) = E [c (γ (Y ), X )] = E [E [c(γ (Y ), X ) | Y ]] .
Expanding the inner expectation and recognizing p(x|y) to be proportional to p(x)p(y |x)
for every y such that p(y) > 0, it follows that ¯γ ∗ minimizes (2) over Γ if and only if
u∈{0,1}N Xx∈{0,1}N
¯γ ∗ (Y ) = arg min
(3)
p(x)c(u, x)p(Y |x) with probability one.
Of note are (i) the likelihood function p(Y |x) is a ﬁnite-dimensional sufﬁcient statistic
of Y , (ii) real-valued coefﬁcients ¯b(u, x) provide a ﬁnite parameterization of the function
space Γ and (iii) optimal coefﬁcient values ¯b∗ (u, x) = p(x)c(u, x) are computable ofﬂine.

Before introducing communication constraints, we illustrate by examples how the decision-
theoretic penalty function relates to familiar discrete-variable assignment problems.
Example 1: Let c(u, x) indicate whether u 6= x. Then (2) and (3) specialize to, respectively,
the word error rate (viewing each x as an N -bit word) and the MAP strategy:
¯γ ∗ (Y ) = arg max
p(x|Y ) with probability one.
x∈{0,1}N
Example 2: Let c(u, x) = PN
n=1 cn (un , xn ), where each cn indicates whether un 6= xn .
Then (2) and (3) specialize to, respectively, the bit error rate and the MPM strategy:
p(xN |Y )(cid:19) with probability one.
¯γ ∗ (Y ) = (cid:18)arg max
p(x1 |Y ), . . . , arg max
x1∈{0,1}
xN ∈{0,1}

2.2 Network Communication Constraints

Let G (V , E ) be any directed acyclic graph with vertex set V = {1, . . . , N } and edge set
E = {(i, j ) ∈ V × V | i ∈ π(j ) ⇔ j ∈ χ(i)},
where index sets π(n) ⊂ V and χ(n) ⊂ V indicate, respectively, the parents and children
of each node n ∈ V . Without loss-of-generality, we assume the node labels respect the
natural partial-order implied by the graph G ; speci ﬁcally, we assume every node n has
parent nodes π(n) ⊂ {1, . . . , n−1} and child nodes χ(n) ⊂ {n+1, . . . , N }. Local to each
node n ∈ V are the respective components Xn and Yn of the joint process (X, Y ). Under
best-case assumptions on p(x, y) and G , Belief Propagation methods (e.g., max-product
in Example 1, sum-product in Example 2) require at least 2|E | real-valued messages per
observation Y = y , one per direction along each edge in G . In contrast, we insist upon
a single forward-pass through G where each node n broadcasts to its children (if any) a
single binary-valued message. This yields communication overhead of only |E | bits per
observation Y = y , but also renders the minimizing strategy of (3) infeasible.
Accepting that performance-communication tradeoffs are inherent to distributed algo-
rithms, we proceed with the goal of minimizing the loss in performance relative to J (¯γ ∗ ).
Speci ﬁcally, we now translate the stipulated restrictions on communication into explicit
constraints on the function space Γ over which to minimize (2). The simplest such transla-
tion assumes the binary-valued message produced by node n also determines the respective
component un in decision vector u = γ (y). Recognizing that every node n receives the
messages uπ(n) from its parents (if any) as side information to yn , any function of the form
γn : R × {0, 1}|π(n)| → {0, 1} is a feasible processing rule; we denote the set of all such
rules by Γn . Then, every strategy in the set ΓG = Γ1 × · · · × ΓN respects the constraints.
3 Summary of Main Results

As stated in Section 1, the variational formulation presented in Section 2 can be viewed as
an extension of the optimization problem underlying decentralized Bayesian detection [5],
[6]. Even for specialized network structures (e.g., the N -node chain), it is known that exact
solution to (1) is NP-hard, stemming from the absence of a guarantee that γ ∗ ∈ ΓG pos-
sesses a ﬁnite parameterization. Also known is that analyti cal progress can be made for a
relaxation of (1), which is based on the following intuition: if strategy γ ∗ = (γ ∗
1 , . . . , γ ∗
N )
is optimal over ΓG , then for each n and assuming all components i ∈ V \n are ﬁxed at
rules γ ∗
i , the component rule γ ∗
n must be optimal over Γn . Decentralized detection has
roots in team decision theory [7], a subset of game theory, in which the relaxation is named
person-by-person (pbp) optimality. While global optimality always implies pbp-optimality,
the converse is false—in general, there can be multiple pbp-o ptimal solutions with varying

penalty. Nonetheless, pbp-optimality (along with a specialized observation process) jus-
ti ﬁes a particular ﬁnite parameterization for the function
space ΓG , leading to a nonlinear
ﬁxed-point equation and an iterative algorithm with favora ble convergence properties. Be-
fore presenting the general algorithm, we illustrate its application in two simple examples.

and

L1 (y1 )

Example 3: Consider the MPM assignment problem in Example 2, assuming N = 2 and
distribution p(x, y) is deﬁned by positive-valued parameters α, β1 and β2 as follows:
N
(yn − βnxn )2
(cid:21) .
p(x) ∝ (cid:26) 1
exp (cid:20)−
1
, x1 = x2
Yn=1
√2π
p(y |x) =
α , x1 6= x2
2
Note that X1 and X2 are marginally uniform and α captures their correlation (positive,
zero, or negative when α is less than, equal to, or greater than unity, respectively), while Y
captures the presence of additive white Gaussian noise with signal-to-noise ratio at node n
equal to βn . The (unconstrained) MPM strategy ¯γ ∗ simpli ﬁes to a pair of threshold rules
u1 = 1
u2 = 1
>
>
<
<
u1 = 0
u2 = 0
where Ln (yn ) = exp [βn (yn − βn/2)] denotes the likelihood-ratio local to node n. Let
E = {(1, 2)} and deﬁne two network-constrained strategies: myopic strategy γ 0 employs
thresholds η0
2 = 1, meaning each node n acts to minimize Pr[Un 6= Xn ] as if in isola-
1 = η0
2 = α2u1−1 , meaning
1 and ηh
tion, whereas heuristic strategy γ h employs thresholds ηh
1 = η0
node 2 adjusts its threshold as if X1 = u1 (i.e., as if the myopic decision by node 1 is always
correct). Figure 1 compares these strategies and a pbp-optimal strategy γ k —only
γ k is both
feasible and consistently “hedging” against all uncertain ty i.e., J (γ 0 ) ≥ J (γ k ) ≥ J (¯γ ∗ ).
L1
0.8
(1, 0)
α−1

1 + αL2 (y2 )
α + L2 (y2 )

1 + αL1 (y1 )
α + L1 (y1 )

and L2 (y2 )

¯η∗
1 =

¯η∗
2 =

,

0.6

)
γ
(
J

¯γ ∗
γ 0
γ h
γ k

(1, 1)

0.6

)
γ
(
J

1
α (0, 0)

(0, 1)
L2

α
α−1
0
1
(a) Shown for α < 1

0.4

0.5

0.4                   1 
β1
(b) With α = 0.1, β2 = 1

    2.5

   

   

.01

 1 
α
(c) With β1 = β2 = 1

100

Figure 1. Comparison of the four alternative strategies in Example 3: (a) sketch of the decision
regions in likelihood-ratio space, showing that network-constrained threshold rules cannot exactly
reproduce ¯γ ∗ (unless α = 1); (b) bit-error-rate versus β1 with α and β2 ﬁxed, showing γ h performs
comparably to γ k when Y1 is accurate relative to Y2 but otherwise performs worse than even γ 0
(which requires no communication); (c) bit-error-rate versus α with β1 and β2 ﬁxed, showing γ k
uses the allotted bit of communication such that roughly 35% of the loss J (γ 0 ) − J (¯γ ∗ ) is recovered.

Example 4: Extend Example 3 to N > 2 nodes, but assuming X is equally-likely to be
all zeros or all ones (i.e., the extreme case of positive correlation) and Y has identically-
accurate components with βn = 1 for all n. The MPM strategy employs thresholds
n = Qi∈V \n 1/Li (yi ) for all n, leading to U = ¯γ ∗ (Y ) also being all zeros or all ones;
¯η∗
thus, its cost distribution, or the probability mass function for c(¯γ ∗ (Y ), X ), has mass only
n = 1 for all n, leading to
on the values 0 and N . The myopic strategy employs thresholds η0
independent and identically-distributed (binary-valued) random variables cn (γ 0
n (Yn ), Xn );
thus, its cost distribution, approaching a normal shape as N gets large, has mass on all val-
ues 0, 1, . . . , N . Figure 2 considers a particular directed network G and, initializing to γ 0 ,
shows the sequence of cost distributions resulting from the iterative ofﬂine algorithm—note
the shape progression towards the cost distribution of the (infeasible) MPM strategy and
the successive reduction in bit-error-rate J (γ k ). Also noteworthy is the rapid convergence
and the successive reduction in word-error-rate Pr[c(γ k (Y ), X ) 6= 0].

γ k
1

u1

γ k
2

u2

γ k
3

u3

γ k
4

γ k
5

u4

u5

γ k
6

u6

γ k
7

u7

γ k
8

u8

γ k
9

u9

γ k
10

u10

γ k
11

u11

γ k
12

u12

y
t
i
l
i
b
a
b
o
r
p

n
o
i
t
c
n
u
f

s
s
a
m

0.4

0.3

0.2

0.1

0

Cost Distribution per Iteration k = 0, 1, . . .

J (γ 0 ) = 3.7 J (γ 1 ) = 2.9 J (γ 2 ) = 2.8 J (γ 3 ) = 2.8

0

4

8

12

0

4
8
4
0
12
8
number of bit errors

12

0

4

8

12

Figure 2.
Illustration of the iterative ofﬂine computation given p(x, y) as described in Example 4
and the directed network shown (N = 12). A Monte-Carlo analysis of ¯γ ∗ yields an estimate for its
bit-error-rate of J (¯γ ∗ ) ≈ 0.49 (with standard deviation of 0.05) —thus, with a total of just
|E | = 11
bits of communication, the pbp-optimal strategy γ 3 recovers roughly 28% of the loss J (γ 0 ) − J (¯γ ∗ ).

3.1 Necessary Optimality Conditions

We start by providing an explicit probabilistic interpretation of the general problem in (1).

p(u|y)p(y |x) dy

p(un |yn , uπ(n) ).

J (γ ∗ ) = min
p(u|y)

c(u, x) Zy∈RN

Lemma 1 The minimum penalty J (γ ∗ ) deﬁned in (1) is, ﬁrstly, achievable by a determin-
istic1 strategy and, secondly, equivalently deﬁned by
p(x) Xu∈{0,1}N
Xx∈{0,1}N
sub ject to p(u|y) = Yn∈V
Lemma 1 is primarily of conceptual value, establishing a correspondence between ﬁx-
ing a component rule γn ∈ Γn and inducing a decision process Un from the information
(Yn , Uπ(n) ) local to node n. The following assumption permits analytical progress towards
a ﬁnite parameterization for each function space Γn and the basis of an ofﬂine algorithm.
Assumption 1 The observation process Y satis ﬁes p(y |x) = Qn∈V p(yn |x).
Lemma 2 Let Assumption 1 hold. Upon ﬁxing a deterministic rule γn ∈ Γn local to node
n (in correspondence with p(un |yn , uπ(n) ) by virtue of Lemma 1), we have the identity
p(un |x, uπ(n) ) = Zyn∈R
p(un |yn , uπ(n) )p(yn |x) dyn .
Moreover, upon ﬁxing a deterministic strategy γ ∈ ΓG , we have the identity
p(u|x) = Yn∈V
p(un |x, uπ(n) ).
Lemma 2 implies ﬁxing component rule γn ∈ Γn is in correspondence with inducing the
conditional distribution p(un |x, uπ(n) ), now a probabilistic description that persists local
to node n no matter the rule γi at any other node i ∈ V \n. Lemma 2 also introduces further
structure in the constrained optimization expressed by Lemma 1: recognizing the integral
over RN to equal p(u|x), (4) and (5) together imply it can be expressed as a product of
1A randomized (or mixed) strategy, modeled as a probabilistic selection from a ﬁnite collection
of deterministic strategies, takes more inputs than just the observation process Y . That deterministic
strategies sufﬁce, however, justiﬁes “post-hoc” our initial abuse of no
tation for elements in the set Γ.

(4)

(5)

component integrals, each over R. We now argue that, despite these simpli ﬁcations, the
component rules of γ ∗ continue to be globally coupled.
Starting with any deterministic strategy γ ∈ ΓG , consider optimizing the nth component
rule γn over Γn assuming all other components stay ﬁxed. With γn a degree-of-freedom,
decision process Un is no longer well-deﬁned so each un ∈ {0, 1} merely represents a
candidate decision local to node n. Online, each local decision will be made only upon re-
ceiving both the local observation Yn = yn and all parents’ local decisions Uπ(n) = uπ(n) .
It follows that node n, upon deciding a particular un , may assert that random vector U is re-
stricted to values in the subset U [uπ(n) , un ] = {u′ ∈ {0, 1}N | u′
n = un}.
π(n) = uπ(n) , u′
Then, viewing (Yn , Uπ(n) ) as a composite local observation and proceeding in the manner
by which (3) is derived, the pbp-optimal relaxation of (1) reduces to the following form.

Proposition 1 Let Assumption 1 hold.
In an optimal network-constrained strategy
γ ∗ ∈ ΓG , for each n and assuming all components i ∈ V \n are ﬁxed at rules γ ∗
i (each
in correspondence with p∗ (ui |x, uπ(i) ) by virtue of Lemma 2), the rule γ ∗
n satis ﬁes
un∈{0,1} Xx∈{0,1}N
b∗
γ ∗
n (un , x; Uπ(n) )p(Yn |x) with probability one
n (Yn , Uπ(n) ) = arg min
(6)
where, for each uπ(n) ∈ {0, 1}|π(n)| ,
n (un , x; uπ(n) ) = p(x) Xu∈U [uπ(n) ,un ]
b∗

c(u, x) Yi∈V \n

p∗ (ui |x, uπ(i) ).

(7)

Of note are (i) the likelihood function p(Yn |x) is a ﬁnite-dimensional sufﬁcient statistic of
Yn , (ii) real-valued coefﬁcients
bn provide a ﬁnite parameterization of the function space
Γn and (iii) the pbp-optimal coefﬁcient values b∗
n , while still computable ofﬂine, also de-
i .
pend on the distributions p∗ (ui |x, uπ(i) ) in correspondence with all ﬁxed rules γ ∗
3.2 Of ﬂine Message-Passing Algorithm

Let fn map from coefﬁcients {bi ; i ∈ V \n} to coefﬁcients bn by the following operations:
1. for each i ∈ V \n, compute p(ui |x, uπ(i) ) via (4) and (6) given bi and p(yi |x);
2. compute bn via (7) given p(x), c(u, x) and {p(ui |x, uπ(i) ); i ∈ V \n}.
Then, the simultaneous satisfaction of Proposition 1 at all N nodes can be viewed as a
system of 2N +1 Pn∈V 2|π(n)| nonlinear equations in as many unknowns,
bn = fn (b1 , . . . , bn−1 , bn+1 , . . . , bN ), n = 1, . . . , N ,
or, more concisely, b = f (b). The connection between each fn and Proposition 1 affords
an equivalence between solving the ﬁxed-point equation f via a Gauss-Seidel iteration and
minimizing J (γ ) via a coordinate-descent iteration [9], implying an algorithm guaranteed
to terminate and achieve penalty no greater than that of an arbitrary initial strategy γ 0 ↔ b0 .
Proposition 2 Initialize to any coefﬁcients b0 = (b0
1 , . . . , b0
N ) and generate the sequence
{bk } using a component-wise iterative application of f in (8) i.e., for k = 1, 2, . . . ,
, . . . , bk−1
n := fn (bk−1
n−1 , bk
n+1 , . . . , bk
bk
(9)
N ), n = N , N − 1, . . . , 1.
1
If Assumption 1 holds, the associated sequence {J (γ k )} is non-increasing and converges:
J (γ 0 ) ≥ J (γ 1 ) ≥ · · · ≥ J (γ k ) → J ∗ ≥ J (γ ∗ ) ≥ J (¯γ ∗ ).

(8)

Direct implementation of (9) is clearly imprudent from a computational perspective, be-
cause the transformation from ﬁxed coefﬁcients
n to the corresponding distribution
bk
pk (un |x, uπ(n) ) need not be repeated within every component evaluation of f . In fact,
assuming every node n stores in memory its own likelihood function p(yn |x), this trans-
formation can be accomplished locally (cf. (4) and (6)) and, also assuming the resulting
distribution is broadcast to all other nodes before they proceed with their subsequent com-
ponent evaluation of f , the termination guarantee of Proposition 2 is retained. Requiring
every node to perform a network-wide broadcast within every iteration k makes (9) a decid-
edly global algorithm, not to mention that each node n must also store in memory p(x, yn )
and c(u, x) to carry forth the supporting local computations.
Assumption 2 The cost function satis ﬁes c(u, x) = Pn∈V cn (un , x) for some collection
of functions {cn : {0, 1}N +1 → R} and the directed graph G is tree-structured.
Proposition 3 Under Assumption 2, the following two-pass procedure is identical to (9):
• Forward-pass at node n: upon receiving messages from all parents i ∈ π(n), store them
for use in the next reverse-pass and send to each child j ∈ χ(n) the following messages:
pk−1 (cid:0)un |x, uπ(n) (cid:1) Yi∈π(n)
n→j (un |x) := Xuπ(n)∈{0,1}|π(n)|
P k
P k
(10)
i→n (ui |x).
• Reverse-pass at node n: upon receiving messages from all children j ∈ χ(n), update
i→n (ui |x) 
j→n (un , x)
n (cid:0)un , x; uπ(n) (cid:1) := p(x) Yi∈π(n)
cn (un , x) + Xj∈χ(n)
P k
C k
bk
(11)

and the corresponding distribution pk (un |x, uπ(n) ) via (4) and (6), store the distribution
for use in the next forward pass and send to each parent i ∈ π(n) the following messages:
p(un |x, ui ) 
j→n (un , x)
:= Xun∈{0,1}
cn (un , x) + Xj∈χ(n)
C k
C k
(12)
n→i (ui , x)
 ,
pk (cid:0)un |x, uπ(n) (cid:1) Yℓ∈π(n)\i
X
P k
ℓ→n (uℓ |x).
p(un |x, ui ) =
uπ(n)∈{u′∈{0,1}|π(n)| |u′
i=ui }
An intuitive interpretation of Proposition 3, from the perspective of node n, is as follows.
From (10) in the forward pass, the messages received from each parent deﬁne what, dur-
ing subsequent online operation, that parent’s local decision means (in a likelihood sense)
about its ancestors’ outputs and the hidden process. From (12) in the reverse pass, the mes-
sages received from each child deﬁne what the local decision will mean (in an expected
cost sense) to that child and its descendants. From (11), both types of incoming messages
impact the local rule update and, in turn, the outgoing messages to both types of neighbors.
While Proposition 3 alleviates the need for the iterative global broadcast of distributions
pk (un |x, uπ(n) ), the explicit dependence of (10)-(12) on the full vector x implies the mem-
ory and computation requirements local to each node can still be exponential in N .
Assumption 3 The hidden process X is Markov on G , or p(x) = Qn∈V p(xn |xπ(n) ), and
all component likelihoods/costs satisfy p(yn |x) = p(yn |xn ) and cn (un , x) = cn (un , xn ).
Proposition 4 Under Assumption 3, the iterates in Proposition 3 specialize to the form of
bk
n (un , xn ; uπ(n) ), P k
and C k
n→j (un |xn )
n→i (ui , xi ),
k = 0, 1, . . .
and each node n need only store in memory p(xπ(n) , xn , yn ) and cn (un , xn ) to carry forth
the supporting local computations. (The actual equations can be found in [8].)

Proposition 4 implies the convergence properties of Proposition 2 are upheld with maximal
efﬁciency (linear in N ) when G is tree-structured and the global distribution and costs sat-
isfy p(x, y) = Qn∈V p(xn |xπ(n) )p(yn |xn ) and c(u, x) = Pn∈V cn (un , xn ), respectively.
Note that these conditions hold for the MPM assignment problems in Examples 3 & 4.
4 Discussion

Our decision-theoretic variational approach reﬂects seve ral departures from existing meth-
ods for communication-constrained inference. Firstly, instead of imposing the constraints
on an algorithm derived from an ideal model, we explicitly model the constraints and de-
rive a different algorithm. Secondly, our penalty function drives the approximation by the
desired application of inference (e.g., posterior assignment) as opposed to a generic error
measure on the result of inference (e.g., divergence in true and approximate marginals).
Thirdly, the necessary ofﬂine computation gives rise to a do wnside, namely less ﬂexibility
against time-varying statistical environments, decision objectives or network conditions.

Our development also evokes principles in common with other research areas. Similar to
the sum-product version of Belief Propagation (BP), our message-passing algorithm origi-
nates assuming a tree structure, an additive cost and a synchronous message schedule. It is
thus enticing to claim that the maturation of BP (e.g., max-product, asynchronous sched-
ule, cyclic graphs) also applies, but unique aspects to our development (e.g., directed graph,
weak convergence, asymmetric messages) merit caution. That we solve for correlated equi-
libria and depend on probabilistic structure commensurate with cost structure for efﬁciency
is in common with graphical games [10], which distinctly are formulated on undirected
graphs and absent of hidden variables. Finally, our ofﬂine c omputation resembles learning
a conditional random ﬁeld [11], in the sense that factors of p(u|x) are iteratively modi ﬁed
to reduce penalty J (γ ); online computation via strategy u = γ (y), repeated per realization
Y = y , is then viewed as sampling from this distribution. Along the learning thread, a
special case of our formulation appears in [12], but assuming p(x, y) is unknown.

Acknowledgments

rch under contract FA9550-
This work supported by the Air Force Ofﬁce of Scienti ﬁc Resea
04-1 and by the Army Research Ofﬁce under contract DAAD19-00 -1-0466. We are grateful
to Professor John Tsitsiklis for taking time to discuss the correctness of Proposition 1.

References

[1] J. Pearl. Probabilistic Reasoning in Intelligent Systems. Morgan Kaufmann, 1988.
[2] L. Chen, et al. Data association based on optimization in graphical models with application to
sensor networks. Mathematical and Computer Modeling, 2005. To appear.
[3] A. T. Ihler, et al. Message errors in belief propagation. Advances in NIPS 17, MIT Press, 2005.
[4] M. I. Jordan, et al. An introduction to variational methods for graphical models. Learning in
Graphical Models, pp. 105–161, MIT Press, 1999.
[5] J. N. Tsitsiklis. Decentralized detection. Adv. in Stat. Sig. Proc., pp. 297–344, JAI Press, 1993.
[6] P. K. Varshney. Distributed Detection and Data Fusion. Springer-Verlag, 1997.
[7] J. Marschak and R. Radner. The Economic Theory of Teams. Yale University Press, 1972.
[8] O. P. Kreidl and A. S. Willsky. Posterior assignment in directed graphical models with minimal
online communication. Available: http://web.mit.edu/opk/www/res.html
[9] D. P. Bertsekas. Nonlinear Programming. Athena Scientiﬁc, 1995.
[10] S. Kakade, et al. Correlated equilibria in graphical games. ACM-CEC, pp. 42–47, 2003.
[11] J. Lafferty, et al. Conditional random ﬁelds: Probabilistic models f or segmenting and labeling
sequence data. ICML, 2001.
[12] X. Nguyen, et al. Decentralized detection and classiﬁcation using ke rnel methods. ICML,2004.

