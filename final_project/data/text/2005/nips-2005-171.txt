Afﬁne Structure From Sound

Sebastian Thrun
Stanford AI Lab
Stanford University, Stanford, CA 94305
Email: thrun@stanford.edu

Abstract

We consider the problem of localizing a set of microphones together
with a set of external acoustic events (e.g., hand claps), emitted at un-
known times and unknown locations. We propose a solution that ap-
proximates this problem under a far ﬁeld approximation deﬁned in the
calculus of afﬁne geometry, and that relies on singular value decompo-
sition (SVD) to recover the afﬁne
structure of the problem. We then
deﬁne low-dimensional optimization techniques for embedding the solu-
tion into Euclidean geometry, and further techniques for recovering the
locations and emission times of the acoustic events. The approach is use-
ful for the calibration of ad-hoc microphone arrays and sensor networks.

1 Introduction

Consider a set of acoustic sensors (microphones) for detecting acoustic events in the envi-
ronment (e.g., a hand clap). The structure from sound (SFS) problem addresses the prob-
lem of simultaneously localizing a set of N sensors and a set of M external acoustic events,
whose locations and emission times are unknown.
The SFS problem is relevant to the spatial calibration problem for microphone arrays.
Classically, microphone arrays are mounted on ﬁx ed brackets of known dimensions; hence
there is no spatial calibration problem. Ad-hoc microphone arrays, however, involve a per-
son placing microphones at arbitrary locations with limited knowledge as to where they
are. Today’s best practice requires a person to measure the distance between the micro-
phones by hand, and to apply algorithms such as multi-dimensional scaling (MDS) [1] for
recovering their locations. When sensor networks are deployed from the air [4], manual cal-
ibration may not be an option. Some techniques rely on GPS receivers [8]. Others require
a capability to emit and sense wireless radio signals [5] or sounds [9, 10], which are then
used to estimate relative distances between microphones (directly or indirectly, as in [9]).
Unfortunately, wireless signal strength is a poor estimator of range, and active acoustic
and GPS localization techniques are uneconomical in that they consume energy and re-
quire additional hardware. In contrast, SFS relies on environmental acoustic events such
as hand claps, which are not generated by the sensor network. The general SFS problem
was previously treated in [2] under the name passive localization. A related paper [3] de-
scribes a technique for incrementally localizing a microphone relative to a well-calibrated
microphone array through external sound events.
In this paper, the structure from sound (SFS) problem is deﬁned as the simultaneous lo-
calization problem of N sound sensors and M acoustic events in the environment detected
by these sensors. Each event occurs at an unknown time and an unknown location. The

sensors are able to measure the detection times of the event. We assume that the clocks
of the sensors are synchronized (see [6]); that events are spaced sufﬁciently far apart in
time to make the association between different sensors unambiguous; and we also assume
absence of sound reverberation. For the ease of representation, the paper assumes a 2D
world; although the technique is easily generalized to 3D.
Under the assumption of independent and identically distributed (iid) Gaussian noise,
the SFS problem can be formulated as a least squares problem in a space over three types of
variables: the locations of the microphones, the locations of the acoustic events, and their
emission times. However, this least squares problem is plagued by local minima, and the
number of constraints is quite large.
The gist of this paper transforms this optimization problem into a sequence of simpler
problems, some of which can be solved optimally, without the danger of getting stuck in
local minima. The key transformation involves a far ﬁeld approximation, which presup-
poses that the sound sources are relatively far away from the sensors. This approximation
reformulates the problem as one of recovering the incident angle of the acoustic signal,
which is the same for all sensors for any ﬁx ed acoustic event. The resulting optimization
problem is still non-linear; however, by relaxing the laws of Euclidean geometry into the
more general calculus of afﬁne geometry, the optimization problem can be solved by sin-
gular value decomposition (SVD). The resulting solution is mapped back into Euclidean
space by optimizing a matrix of size 2 (cid:2) 2, which is easily carried out using gradient de-
scent. A subsequent non-linear optimization step overcomes the far ﬁeld approximation
and enables the algorithm to recover locations and emission times of the deﬁning acoustic
events. Experimental results illustrate that our approach reliably solves hard SFS problems
where gradient-based techniques consistently fail.
Our approach is similar in spirit to the afﬁne
solution to the structure from motion
(SFM) problem proposed by a seminal paper by Tomasi&Kanade [11], which was later
extended to the non-orthographic case [7]. Like us, these authors expressed the structure
ﬁnding problem using afﬁne geometry, and applied SVD for solving it. SFM is of course
deﬁned for cameras, not for microphone arrays. Camera measure angles, whereas micro-
phones measure range. This paper establishes an afﬁne solution to the structure from sound
problem that tends to work well in practice.

X =

2 Problem Deﬁnition
2.1 Setup
We are given N sensors (microphones) located in a 2D plane. We shall denote the location
of the i-th sensor by (xi yi ), which deﬁned the following sensor location matrix of size
N (cid:2) 2:
1
0
y1
x1
y2
x2
CCA
BB@
...
...
xN yN
We assume that the sensor array detects M acoustic events. Each event has as unknown co-
ordinate and an unknown emission time. The coordinate of the j -th event shall be denoted
(aj bj ), providing us with the event location matrix A of size M (cid:2) 2. The emission time
of the j -th acoustic event is denoted tj , resulting in the vector T of length M :
1
1
0
0
b1
a1
t1
b2
a2
t2
CCA
CCA
BB@
BB@
...
...
...
aM bM
tM
X , A, and T , comprise the set of unknown variables. In problems such as sensor calibra-
tion, only X is of interest. In general SFS applications, A and T might also be of interest.

A =

(1)

(2)

T =

D =

(cid:22)X =

2.2 Measurement Data
In SFS, the variables X , A, and T are recovered from data. The data establishes the
detection times of the acoustic events by the individual sensors. Speciﬁcally , the data
matrix is of the form:
1
0
(cid:1) (cid:1) (cid:1)
d1;M
d1;2
d1;1
(cid:1) (cid:1) (cid:1)
d2;M
d2;2
d2;1
CCA
BB@
...
...
...
. . .
(cid:1) (cid:1) (cid:1)
dN ;M
dN ;2
dN ;1
Here each di;j denotes the detection time of acoustical event j by sensor i. Notice that we
assume that there is no data association problem. Even if all acoustic events sound alike,
the correspondence between different detections is easily established as long as there exists
sufﬁciently long time gaps between any two sound events.
The matrix D is a random ﬁeld induced by the laws of sound propagation (without re-
verberation). In the absence of measurement noise, each di;j is the sum of the correspond-
ing emission time tj , plus the time it takes for sound to travel from (aj bj ) to (xi yi ):
di;j = tj + c(cid:0)1 (cid:12)(cid:12)(cid:12)(cid:12)
bj (cid:19)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:18) xi
yi (cid:19) (cid:0) (cid:18) aj
Here j (cid:1) j denotes the L2 norm (Euclidean distance), and c denoted the speed of sound.
2.3 Relative Formulation
Obviously, we cannot recover the global coordinates of the sensors. Hence, without loss of
sensor’s location as x1 = y1 = 0. This gives us the relative
generality, we deﬁne the ﬁrst
location matrix for the sensors:
1
0
y2 (cid:0) y1
x2 (cid:0) x1
y3 (cid:0) y1
x3 (cid:0) x1
CCA
BB@
...
...
yN (cid:0) y1
xN (cid:0) x1
This relative sensor location matrix is of dimension (N (cid:0) 1) (cid:2) 2.
It shall prove convenient to subtract from the arrival time di;j the arrival time d1;j
measured by the ﬁrst
sensor i = 1. This relative arrival time is deﬁned as (cid:1) i;j := di;j (cid:0)
d1;j . In the relative arrival time, the absolute emission times tj cancel out:
bj (cid:19)(cid:12)(cid:12)(cid:12)(cid:12)
bj (cid:19)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:0) tj (cid:0) c(cid:0)1 (cid:12)(cid:12)(cid:12)(cid:12)
(cid:1)i;j = tj + c(cid:0)1 (cid:12)(cid:12)(cid:12)(cid:12)
(cid:18) aj
yi (cid:19) (cid:0) (cid:18) aj
(cid:18) xi
(cid:0) (cid:12)(cid:12)(cid:12)(cid:12)
bj (cid:19)(cid:12)(cid:12)(cid:12)(cid:12)
= c(cid:0)1 (cid:26)(cid:12)(cid:12)(cid:12)(cid:12)
bj (cid:19)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:18) aj
(cid:27)
yi (cid:19) (cid:0) (cid:18) aj
(cid:18) xi
We now deﬁne the matrix of relative arrival times:
0
d2;M (cid:0) d1;M
(cid:1) (cid:1) (cid:1)
d2;2 (cid:0) d1;2
d2;1 (cid:0) d1;1
d3;1 (cid:0) d1;1
d3;2 (cid:0) d1;2
(cid:1) (cid:1) (cid:1)
d3;M (cid:0) d1;M
BB@
...
...
...
. . .
dN ;M (cid:0) d1;M
dN ;1 (cid:0) d1;1
dN ;2 (cid:0) d1;2
(cid:1) (cid:1) (cid:1)
This matrix (cid:1) is of dimension (N (cid:0) 1) (cid:2) M .
2.4 Least Squares Formulation
The relative sensor locations X and the corresponding locations of the acoustic events
A can now be recovered through the following least squares problem. This optimization
seeks to identify X and A so as to minimize the quadratic difference between the predicted
relative measurements and the actual measurements.
bj (cid:19)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:0) (cid:12)(cid:12)(cid:12)(cid:12)
bj (cid:19)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:26)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:0) (cid:1)i;j (cid:27)2
(cid:18) aj
yi (cid:19) (cid:0) (cid:18) aj
(cid:18) xi
M
N
Xj=1
Xi=2

hA(cid:3) ; X (cid:3) i = argmin
X;A

1
CCA

(6)

(7)

(3)

(4)

(5)

(8)

(cid:1) =

1
N

T (cid:3) =

The minimum of this expression is a maximum likelihood solution for the SFS problem
under the assumption of iid Gaussian measurement noise.
If emission times are of interest, they are now easily recovered by the following
weighted mean:
di;j (cid:0) c (cid:12)(cid:12)(cid:12)(cid:12)
bj (cid:19)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:18) xi
yi (cid:19) (cid:0) (cid:18) aj
N
Xi=1
The minimum of Eq. 8 is not unique. This is because any solution can be rotated around
the origin of the coordinate system, and mirrored through any axis intersecting the origin.
This shall not concern us, as we shall be content with any solution of Eq. 8; others are then
easily generated.
What is of concern, however, is the fact that minimizing Eq. 8 is difﬁcult. A straw
man algorithm—which
tends to work poorly in practice—in volves starting with random
guesses for X and A and then adjusting them in the direction of the negative gradient until
convergence. As we shall show experimentally, such gradient algorithms work poorly in
practice because of the large number of local minima.

(9)

(10)

(cid:11)i;j = arctan2

3 The Far Field Approximation
The essence of our approximation pertains to the fact that for far range acoustic events—
i.e., events that are (inﬁnitely)
incoming sound wave
far away from the sensor array—the
hits each sensor at the same incident angle. Put differently, the rays connecting the location
of an acoustic event (aj bj ) with each of the perceiving sensors (xi yi ) are approximately
parallel for all i (but not for all j !). Under the far ﬁeld approximation, these incident angles
are entirely parallel. Thus, all that matters are the incident angle of the acoustic events.
To derive an equation for this case, it shall prove convenient to write the Euclidean
distance between a sensor and an acoustic event as a function of the incident angle (cid:11). This
angle is given by the four-quadrant extension of the arctan function:
bj (cid:0) yi
aj (cid:0) xi
The Euclidean distance between (aj bj ) and (xi yi ) can now be written as
(cid:12)(cid:12)(cid:12)(cid:12)
bj (cid:19)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:18) xi
yi (cid:19) (cid:0) (cid:18) aj
= (cos (cid:11)i;j sin (cid:11)i;j ) (cid:18) aj (cid:0) xi
bj (cid:0) yi (cid:19)
For far-away points (aj bj ), we can safely assume that all incident angles for the j -th
acoustic event are identical:
(12)
:= (cid:11)1;j = (cid:11)2;j = : : : = (cid:11)N ;j
(cid:11)j
Hence we substitute (cid:11)j for (cid:11)i;j in Eq. 11. Plugging this back into Eq. 6, this gives us the
following expression for (cid:1)i;j :
bj (cid:19)(cid:12)(cid:12)(cid:12)(cid:12)
bj (cid:19)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:0) (cid:12)(cid:12)(cid:12)(cid:12)
(cid:1)i;j = c(cid:0)1 (cid:26)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:27)
(cid:18) aj
yi (cid:19) (cid:0) (cid:18) aj
(cid:18) xi
bj (cid:19)(cid:21)(cid:27)
bj (cid:0) yi (cid:19) (cid:0) (cid:18) aj
(cid:25) c(cid:0)1 (cid:26)(cos (cid:11)j sin (cid:11)j ) (cid:20)(cid:18) aj (cid:0) xi
yi (cid:19)
= c(cid:0)1 (cos (cid:11)j sin (cid:11)j ) (cid:18) xi
This leads to the following non-linear least squares problem for the desired sensor loca-
tions:
sin (cid:11)M (cid:19) (cid:0) (cid:1)(cid:12)(cid:12)(cid:12)(cid:12)
X;(cid:11)1 ;:::;(cid:11)M (cid:12)(cid:12)(cid:12)(cid:12)
X (cid:18) cos (cid:11)1
cos (cid:11)M
cos (cid:11)2
argmin
sin (cid:11)1
sin (cid:11)2
The reader many notice that in this formulation of the SFS problem, the locations of the
sound events (aj ; bj ) have been replaced by (cid:11)j , the incident angles of the sound waves.

1 ; : : : ; (cid:11)(cid:3)
hX (cid:3) ; (cid:11)(cid:3)
M i =

(cid:1) (cid:1) (cid:1)
(cid:1) (cid:1) (cid:1)

(11)

(13)

2

(14)

One might think of this as the “ortho-acoustic” model of sound propagation (in analogy
to the orthographic camera model in computer vision). The ortho-acoustic projection re-
duces the number of variables in the optimization. However, the argument in the quadratic
expression is still non-linear, due to the non-linear trigonometric functions involved.

(cid:1) (cid:1) (cid:1)
(cid:1) (cid:1) (cid:1)

4 Afﬁne Solution for the Sensor Locations
Eq. 14 is trivially solvable in the space of afﬁne geometry. Following [11], in afﬁne ge-
ometry projections can be arbitrary linear functions, not just rotations and translations.
Speciﬁcally , let us replace the specialized matrix
sin (cid:11)M (cid:19)
(cid:18) cos (cid:11)1
cos (cid:11)M
cos (cid:11)2
sin (cid:11)1
sin (cid:11)2
by a general 2 (cid:2) M matrix of the form
(cid:13)2;M (cid:19)
(cid:0) = (cid:18) (cid:13)1;1
(cid:13)1;M
(cid:13)1;2
(cid:13)2;1
(cid:13)2;2
This leads to the least squares problem
jX (cid:0) (cid:0) (cid:1)j2

hX (cid:3) ; (cid:0)(cid:3) i = argmin
X;(cid:0)
In the noise free-case case, we know that there must exist a X and a (cid:0) for which X (cid:0) = (cid:1).
This suggests that the rank of (cid:1) should be 2, since it is the product of a matrix of size
(N (cid:0) 1) (cid:2) 2 and a matrix of size 2 (cid:2) M .
Further, we can recover both X and (cid:0) via singular value decomposition (SVD). Specif-
ically, we know that the matrix (cid:1) can be decomposed as into three other matrices, U , V ,
and W :

(cid:1) (cid:1) (cid:1)
(cid:1) (cid:1) (cid:1)

(16)

(15)

(17)

U V W T = svd((cid:1))
(18)
where U is a matrix of size (N (cid:0) 1) (cid:2) 2, V a diagonal matrix of eigenvalues of size 2 (cid:2) 2,
and W a matrix of size M (cid:2) 2. In practice, (cid:1) might be of higher rank because of noise or
because of violations of the far ﬁeld assumption, but it sufﬁces
to restrict the consideration
to the ﬁrst
two eigenvalues.
The decomposition in Eq. 18 leads to the optimal afﬁne solution of the SFS problem:
(cid:0) = W T
and
(19)
X = U V
However, this solution is not yet Euclidean, since (cid:0) might not be of the form of Eq. 15.
Speciﬁcally , Eq. 15 is a function of angles, and each row in Eq. 15 must be of the form
cos2 (cid:13)j + sin2 (cid:13)j = 1. Clearly, this constraint is not enforced in the SVD.
However, there is an easy “trick ”
for recovering a X and (cid:0) for which this constraint is
at least approximately met. The key insight is that for any invertible 2 (cid:2) 2 matrix C ,
X 0 = U V C (cid:0)1
(cid:0)0 = CW T
and
is equally a solution to the factorization problem in Eq.18. This is because
X 0(cid:0)0 = U V C (cid:0)1CW T = U V W T = X (cid:0)
(21)
The remaining search problem, thus, is the problem of ﬁnding an appropriate matrix C for
which (cid:0)0 is of the form of Eq. 15. This is a non-linear optimization problem, but it is much
lower-dimensional than the original SFS problem (it only involves 4 parameters!).
Speciﬁcally , we seek a C for which (cid:0)0 = CW T minimizes
(cid:12)(cid:12)(cid:12) (1 1) ((cid:0)0 (cid:1) (cid:0)0 )
(cid:0) (1 1 (cid:1) (cid:1) (cid:1) 1) (cid:12)(cid:12)(cid:12)
2
|
{z
}
((cid:3))
Here “ (cid:1)” denotes the dot product. The expression labeled ((cid:3)) evaluates to a vector of ex-
pressions of the form
1;M + (cid:13) 2
2;2 (cid:1) (cid:1) (cid:1) (cid:13) 2
1;2 + (cid:13) 2
2;1 (cid:13) 2
((cid:13) 2
1;1 + (cid:13) 2
2;M )

C (cid:3) = argmin
C

(20)

(23)

(22)

(a) Error

grad. desc.
@@R

SVD

3.5

3

2.5

2

1.5

1

0.5

)
s
l
a
v
r
e
t
n
i
 
e
c
n
e
d
i
f
n
o
c
 
%
5
9
(
 
r
o
r
r
e

2

1

0

−1

−2

−3

(b) Log-error

6
grad. desc.

SVD
?

)
s
l
a
v
r
e
t
n
i
 
e
c
n
e
d
i
f
n
o
c
 
%
5
9
(
 
r
o
r
r
e
−
g
o
l

SVD+grad. desc.
?

0
4

?

6
SVD+grad. desc.
8
14
12
10
8
10
N, M (here N=M)
N, M (here N=M)
Figure 1: (a) Error and (b) log error for three different algorithms: gradient descent (red), SVD
(blue), and SVD followed by gradient descent (green). Performance is shown for different values of
N and M , with N = M . The plot also shows 95% conﬁdence bars.

−4

−5

6

12

14

4

6

(a) ground truth

(b) gradient descent

(c) SVD

(d) SVD + grad. desc.

sensors

acoustic events

Figure 2: Typical SFS results for a simulated array of nine microphones spaced in a regular grid,
surrounded by 9 sounds arranged on a circle. (a) Ground truth; (b) Result of plain gradient descent
after convergence; the dashed lines visualize the residual error; (c) Result of the SVD with sound
directions as indicated; and (d) Result of gradient descent initialized with our SVD result.

The minimization in Eq. 22 is carried out through standard gradient descent. It involves
only 4 variables (C is of the size 2 (cid:2) 2), and each single iteration is linear in O(N + M )
(instead of the O(N M ) constraints that deﬁne Eq. 8). In (tens of thousands of) experiments
with synthetic noise-free data, we ﬁnd empirically that gradient descent reliably converges
to the globally optimal solution.

5 Recovering the Acoustic Event Locations and Emission Times
With regards to the acoustic events, the optimization for the far ﬁeld case only yields the
incident angles. In the near ﬁeld setting, in which the incident angles tend to differ for
different sensors, it may be desirable to recover the locations A of the acoustic event and
the corresponding emission times T .
To determine these variables, we use the vector X (cid:3) from the far ﬁeld case as mere
starting points in a subsequent gradient search. The event location matrix A is initialized
by selecting points sufﬁciently far away along the estimated incident angle for the far ﬁeld
approximation to be sound:
(24)
A = k (cid:0)0(cid:3)
Here (cid:0)0(cid:3) = C (cid:3)W T with C (cid:3) deﬁned in Eq. 22, and k is a multiple of the diameter of the
locations in X . With this initial guess for A, we apply gradient descent to optimize Eq. 8,
and ﬁnally use Eq. 9 to recover T .

6 Experimental Results
We ran a series of simulation experiments to characterize the quality of our algorithm,
especially in comparison with the obvious nonlinear least squares problem (Eq. 8) from
which it is derived. Fig. 1 graphs the residual error as a function of the number of sensors

(a) Error

grad. desc.
@@R

3.5

3

2.5

2

1.5

)
s
l
a
v
r
e
t
n
i
 
e
c
n
e
d
i
f
n
o
c
 
%
5
9
(
 
r
o
r
r
e

1

(b) Log-error

grad. desc.

2

1

0

−1

SVD

)
s
l
a
v
r
e
t
n
i
 
e
c
n
e
d
i
f
n
o
c
 
%
5
9
(
 
r
o
r
r
e
g
o
l

−2

−3

−4

0

0.5

0
0

SVD+grad. desc.

SVD
(cid:0)(cid:0)(cid:9)
(cid:8)(cid:8)(cid:8)(cid:25)
SVD+grad. desc.
4
8
6
2
4
2
8
6
diameter ratio of events vs sensor array
diameter ratio of events vs sensor array
Figure 3: (a) Error and (b) log-error for three different algorithms (gradient descent in red, SVD
in blue, and SVD followed by gradient descent in green), graphed here for varying distances of the
sound events to the sensor array. An error above 2 means the reconstruction has entirely failed. All
diagrams also show the 95% conﬁdence intervals, and we set N = M = 10.

10

10

(a) One of our motes
used to generate the data

(b) Optimal vs. hand-measured

(c) Result of gradient descent

(d) SVD and GD

m
o
t
e
s

sounds

motes
Figure 4: Results using our seven sensor motes as the sensor array, and a seventh mote to generate
sound events.
(a) A mote; (b) the globally optimal solution (big circles) compared to the hand-
measures locations (small circles); (c) a typical result of vanilla gradient descent; and (d) the result
of our approach, all compared to the optimal solution given the (noisy) data.

N and acoustic events M (here N = M ). Panel (a) plots the regular error along with
95% conﬁdence intervals, and panel (b) the corresponding log-error. Clearly, as N and M
increase, plain gradient descent tends to diverge, whereas our approach converges. Each
data point in these graphs was obtained by averaging 1,000 random con ﬁgurations,
in which
sensors were sampled uniformly within an interval of 1(cid:2)1m; sounds were placed at varying
ranges, from 2m to 10m. An example outcome (for a non-random con ﬁguration!)
is shown
in Fig. 2. This ﬁgure plots (a) a simulated sensor array consisting of 9 sensors with 9 sound
sources arranged in a circle; and (b)-(d) the resulting reconstructions of our three methods.
For the SVD result shown in (c), only the directions of the incoming sounds are shown.
An interesting question pertains to the effect of the far ﬁeld approximation in cases
where it is clearly violated. To examine the robustness of our approach, we ran a series of
experiments in which we varied the diameter of the acoustic events relative to the diameter
of the sensors. If this parameter is 1, the acoustic events are emitted in the same region as
the microphones; for values such as 10, the events are far away.
Fig. 3 graphs the residual errors and log-errors. The further away the acoustic events,
the better our results. However, even for nearby events, for which the far ﬁeld assumption
is clearly invalid, our approach generates results that are no worse than those of the plain
gradient descent technique.
We also implemented our approach using a physical sensor array. Fig. 4 plots empirical
results using a microphone array comprised of seven Crossbow sensor motes, one of which

−
is shown in Panel (a). Panels (b-d) compare the recovered structure with the one that
globally minimizes the LMS error, which we obtain by running gradient descent using the
hand-measured locations as starting point. Panel (a) in Fig. 4 shows the manually measured
locations; the relatively high deviation to the LMS optimum is the result of measurement
error, which is ampliﬁed by the fact that our motes are only spaced a few tens of centimeters
apart from each other (the standard deviation in the timing error corresponds to a distance
of 6.99cm, and the motes are placed between 14cm and 125cm apart). Panel (b) in Fig. 4
shows the solution of plain gradient descent applied to applied to Eq.8 and compares it
to the optimal reconstruction; and Panel (c) illustrates our solution. In all plots the lines
indicate residual error. This result shows that our method may work well on real-world
data that is noisy and that does not adhere to the far ﬁeld assumption.

7 Discussion
This paper considered the structure from sound problem and presented an algorithm for
solving it. Our approach makes is possible to simultaneously recover the location of a
collection of microphones, the locations of external acoustic events detected by these mi-
crophones, and the emission times for these events. By resorting to afﬁne geometry, our
approach overcomes the problem of local minima in the structure from sound problem.
There remain a number of open research issues. We believe the extension to 3-D is
mathematically straightforward but requires empirical validation. The current approach
also fails to address reverberation problems that are common in con ﬁned space. It shall
further be interesting to investigate data association problems in the SFS framework, and
to develop parallel algorithms that can be implemented on sensor networks with limited
communication resources. Finally, of great interest should be the incomplete data case in
which individual sensors may fail to detect acoustic events—a
problem studied in [2].

Acknowledgement
The motes data was made available by Rahul Biswas, which is gratefully acknowledged.
We also acknowledge invaluable suggestions by three anonymous reviewers.

References
[1] S.T. Birchﬁeld and A. Subramanya. Microphone array position calibration by basis-point clas-
sical multidimensional scaling. IEEE Trans. Speech and Audio Processing, forthcoming.
[2] R. Biswas and S. Thrun. A passive approach to sensor network localization. IROS-04.
[3] J.C. Chen, R.E. Hudson, and K. Yao. Maximum likelihod source localization and unknown sen-
sor location estimation for wideband signals in the near-ﬁeld. IEEE Trans. Signal Processing,
50, 2002.
[4] P. Corke, S. Hrabar, R. Peterson, D. Rus, S. Saripalli, and G. Sukhatme. Deployment and
connectivity repair of a sensor net with a ﬂying robot. ISER-04.
[5] E. Elnahrawy, X. Li, and R. Martin. The limits of localization using signal strength: A compar-
ative study. SECON-04.
[6] J. Elson and K. Romer. Wireless sensor networks: A new regime for time synchronization.
HotNets-02.
[7] S. Mahamud and M. Hebert. Iterative projective reconstruction from multiple views. CVPR-00.
[8] D. Niculescu and B. Nath. Ad hoc positioning system (APS). GLOBECOM-01.
[9] V.C. Raykar, I.V. Kozintsev, and R. Lienhart. Position calibration of microphones and loud-
speakers in distributed computing platforms. IEEE transaction on Speech and Audio Process-
ing, 13(1), 2005.
[10] J. Sallai, G. Balogh, M. Maroti, and A. Ledeczi. Acoustic ranging in resource-constrained
sensor networks. eCOTS-04.
[11] C. Tomasi and T. Kanade. Shape and motion from image streams under orthography: A factor-
ization method. IJCV, 9(2), 1992.
[12] T.L. Tung, K. Yao, D. Chen, R.E. Hudson, and C.W. Reed. Source localization and spatial ﬁl-
tering using wideband music and maxiumum power beam forming for multimedia applications.
In SIPS-99.

