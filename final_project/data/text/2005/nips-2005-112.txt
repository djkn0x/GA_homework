Consensus Propagation

Ciamac C. Moallemi
Stanford University
Stanford, CA 95014 USA
ciamac@stanford.edu

Benjamin Van Roy
Stanford University
Stanford, CA 95014 USA
bvr@stanford.edu

Abstract

We propose consensus propagation, an asynchronous distributed proto-
col for averaging numbers across a network. We establish convergence,
characterize the convergence rate for regular graphs, and demonstrate
that the protocol exhibits better scaling properties than pairwise averag-
ing, an alternative that has received much recent attention. Consensus
propagation can be viewed as a special case of belief propagation, and
our results contribute to the belief propagation literature. In particular,
beyond singly-connected graphs, there are very few classes of relevant
problems for which belief propagation is known to converge.

1 Introduction
aims to compute the average Pn
Consider a network of n nodes in which the ith node observes a number yi ∈ [0, 1] and
i=1 yi /n. The design of scalable distributed protocols for
this purpose has received much recent attention and is motivated by a variety of potential
needs. In both wireless sensor and peer-to-peer networks, for example, there is interest
in simple protocols for computing aggregate statistics (see, for example, the references
in [1]), and averaging enables computation of several important ones. Further, averaging
serves as a primitive in the design of more sophisticated distributed information processing
algorithms. For example, a maximum likelihood estimate can be produced by an averaging
protocol if each node’s observations are linear in variables of interest and noise is Gaussian
[2]. As another example, averaging protocols are central to policy-gradient-based methods
for distributed optimization of network performance [3].
In this paper we propose and analyze a new protocol – consensus propagation – for asyn-
chronous distributed averaging. As a baseline for comparison, we will also discuss another
asychronous distributed protocol – pairwise averaging – which has received much recent
attention. In pairwise averaging, each node maintains its current estimate of the average,
and each time a pair of nodes communicate, they revise their estimates to both take on the
mean of their previous estimates. Convergence of this protocol in a very general model of
asynchronous computation and communication was established in [4]. Recent work [5, 6]
has studied the convergence rate and its dependence on network topology and how pairs of
nodes are sampled. Here, sampling is governed by a certain doubly stochastic matrix, and
the convergence rate is characterized by its second-largest eigenvalue.
Consensus propagation is a simple algorithm with an intuitive interpretation. It can also be
viewed as an asynchronous distributed version of belief propagation as applied to approxi-

mation of conditional distributions in a Gaussian Markov random ﬁeld. When the network
of interest is singly-connected, prior results about belief propagation imply convergence
of consensus propagation. However, in most cases of interest, the network is not singly-
connected and prior results have little to say about convergence. In particular, Gaussian
belief propagation on a graph with cycles is not guaranteed to converge, as demonstrated
by examples in [7].
In fact, there are very few relevant cases where belief propagation on a graph with cy-
cles is known to converge. Some fairly general sufﬁcient conditions have been established
[8, 9, 10], but these conditions are abstract and it is difﬁcult to identify interesting classes
of problems that meet them. One simple case where belief propagation is guaranteed to
converge is when the graph has only a single cycle [11, 12, 13]. Recent work proposes the
use of belief propagation to solve maximum-weight matching problems and proves conver-
gence in that context [14]. [15] proves convergence in the application of belief propogation
to a classiﬁcation problem. In the Gaussian case, [7, 16] provide sufﬁcient conditions for
convergence, but these conditions are difﬁcult to interpret and do not capture situations that
correspond to consensus propagation.
With this background, let us discuss the primary contributions of this paper: (1) we pro-
pose consensus propagation, a new asynchronous distributed protocol for averaging; (2) we
prove that consensus propagation converges even when executed asynchronously. Since
there are so few classes of relevant problems for which belief propagation is known to
converge, even with synchronous execution, this is surprising; (3) We characterize the con-
vergence time in regular graphs of the synchronous version of consensus propagation in
terms of the the mixing time of a certain Markov chain over edges of the graph; (4) we
explain why the convergence time of consensus propagation scales more gracefully with
the number of nodes than does that of pairwise averaging, and for certain classes of graphs,
we quantify the improvement.

2 Algorithm
Consider a connected undirected graph (V , E ) with |V | = n nodes. For each node i ∈
P
V , let N (i) = {j :
(i, j ) ∈ E } be the set of neighbors of i. Each node i ∈ V is
assigned a number yi ∈ [0, 1]. The goal is for each node to obtain an estimate of ¯y =
i∈V yi /n through an asynchronous distributed protocol in which each node carries out
simple computations and communicates parsimonious messages to its neighbors.
We propose consensus propagation as an approach to the aforementioned problem. In this
protocol, if a node i communicates to a neighbor j at time t, it transmits a message consist-
ij ∈ R+ denote the values associated with
ij ∈ R and K t
ing of two numerical values. Let µt
the most recently transmitted message from i to j at or before time t. At each time t, node j
has stored in memory the most recent message from each neighbor: {µt
ij |i ∈ N (j )}.
ij , K t
The initial values in memory before receiving any messages are arbitrary.
Consensus propagation is parameterized by a scalar β > 0 and a non-negative matrix
+ with Qij > 0 if and only if i 6= j and (i, j ) ∈ E . Let ~E ⊆ V × V be a set
Q ∈ Rn×n
consisting of two directed edges (i, j ) and (j, i) per undirected edge (i, j ) ∈ E . For each
1 + P
(i, j ) ∈ ~E , it is useful to deﬁne the following three functions:
(cid:17) ,
(cid:16)
1 + P
u∈N (i)\j Kui
Fij (K ) =
yi + P
yi + P
1 + 1
u∈N (i)\j Kui
βQij
1 + P
1 + P
u∈N (i) Kuiµui
u∈N (i)\j Kuiµui
Xi (µ, K ) =
u∈N (i)\j Kui
u∈N (i) Kui

Gij (µ, K ) =

(1)

,

.

(2)

For each t, denote by Ut ⊆ ~E the set of directed edges along which messages are transmit-
ted at time t. Consensus propagation is presented below as Algorithm 1.

Algorithm 1 Consensus propagation.
1: for time t = 1 to ∞ do
for all (i, j ) ∈ Ut do
2:
ij ← Fij (K t−1 )
K t
3:
ij ← Gij (µt−1 , K t−1 )
µt
4:
end for
5:
for all (i, j ) /∈ Ut do
6:
ij ← K t−1
K t
7:
ij
ij ← µt−1
µt
8:
ij
end for
9:
xt ← X (µt , K t )
10:
11: end for

Consensus propagation is a distributed protocol because computations at each node re-
quire only information that is locally available. In particular, the messages Fij (K t−1 ) and
Gij (K t−1 ) transmitted from node i to node j depend only on {µt−1
|u ∈ N (i)},
, K t−1
ui
ui
i , which serves as an estimate of y , de-
which node i has stored in memory. Similarly, xt
pends only on {µt
ui |u ∈ N (i)}.
ui , K t
Consensus propagation is an asynchronous protocol because only a subset of the potential
messages are transmitted at each time. Our convergence analysis can also be extended to
accommodate more general models of asynchronism that involve communication delays,
as those presented in [17].
In our study of convergence time, we will focus on the synchronous version of consensus
propagation. This is where Ut = ~E for all t. Note that synchronous consensus propagation
is deﬁned by:
K t = F (K t−1 ), µt = G (µt−1 , K t−1 ),
xt = X (µt−1 , K t−1 ).

(3)

2.1 Intuitive Interpretation
Consider the special case of a singly connected graph. For any (i, j ) ∈ ~E , there is a set
Sij ⊂ V of nodes that can transmit information to Sj i = V \ Sij only through (i, j ). In
order for nodes in Sj i to compute y , they must at least be provided with the average µ∗
ij
ij = |Sij |. The messages µt
among observations at nodes in Sij and the cardinality K ∗
ij and
ij can be viewed as estimates. In fact, when β = ∞, µt
ij converge to µ∗
ij and K t
ij and
K t
K ∗
ij , as we will now explain.
ij = 1 + X
Suppose the graph is singly connected, β = ∞, and transmissions are synchronous. Then,
K t−1
(4)
K t
,
ui
u∈N (i)\j
for all (i, j ) ∈ ~E . This is a recursive characterization of |Sij |, and it is easy to see that it
yi + P
converges in a number of iterations equal to the diameter of the graph. Now consider the
1 + P
iteration
ui µt−1
u∈N (i)\j K t−1
ui
ij =
µt
,
u∈N (i)\j K t−1
ui
for all (i, j ) ∈ ~E . A simple inductive argument shows that at each time t, µt
ij is an average
ij nodes in Sij , and after a number of iterations equal to the
among observations at K t

,

y =

yi + P
diameter of the graph, µt = µ∗ . Further, for any i ∈ V ,
1 + P
u∈N (i) Kuiµui
u∈N (i) Kui
i converges to y . This interpretation can be extended to the asynchronous case where it
so xt
elucidates the fact that µt and K t become µ∗ and K ∗ after every pair of nodes in the graph
has established bilateral communication through some sequence of transmissions among
adjacent nodes.
Suppose now that the graph has cycles. If β = ∞, for any (i, j ) ∈ ~E that is part of a cycle,
ij ← 1+P
ij → ∞ whether transmissions are synchronous or asynchronous, so long as messages
K t
are transmitted along each edge of the cycle an inﬁnite number of times. A heuristic ﬁx
u∈N (i)\j K t−1
might be to compose the iteration (4) with one that attenuates: ˜K t
,
ui
ij ← ˜K t
ij /(1 + ij ˜K t
ij ). Here, ij > 0 is a small constant. The message is essentially
and K t
unaffected when ij ˜K t
ij is small but becomes increasingly attenuated as ˜K t
ij grows. This is
exactly the kind of attenuation carried out by consensus propagation when βQij = 1/ij <
∞. Understanding why this kind of attenuation leads to desirable results is a subject of our
analysis.

2.2 Relation to Belief Propagation

Consensus propagation can also be viewed as a special case of belief propagation. In this
context, belief propagation is used to approximate the marginal distributions of a vector
x ∈ Rn conditioned on the observations y ∈ Rn . The mode of each of the marginal
distributions approximates y .
Take the prior distribution over (x, y) to be the normalized product of potential func-
tions {ψi (·)|i ∈ V } and compatibility functions {ψβ
ij (·)|(i, j ) ∈ E }, given by ψi (xi ) =
exp(−(xi − yi )2 ), and ψβ
ij (xi , xj ) = exp(−βQij (xi − xj )2 ), where Qij , for each
(i, j ) ∈ ~E , and β are positive constants. Note that β can be viewed as an inverse temper-
Let Γ be a positive semideﬁnite symmetric matrix such that xT Γx = P
ature parameter; as β increases, components of x associated with adjacent nodes become
increasingly correlated.
(i,j )∈E Qij (xi −
xj )2 . Note that when Qij = 1 for all (i, j ) ∈ E , Γ is the graph Laplacian. Given the vector
ψi (xi ) Y
pβ (x) ∝ Y
ij (xi , xj ) = exp (cid:0)−kx − yk2
2 − βxT Γx(cid:1) .
y of observations, the conditional density of x is
ψβ
i∈V
(i,j )∈E
Let xβ denote the mode of pβ (·). Since the distribution is Gaussian, each component xβ
i
is also the mode of the corresponding marginal distribution. Note that xβ it is the unique
solution to the positive deﬁnite quadratic program
kx − yk2
2 + βxT Γx.

minimize
x
The following theorem, whose proof can be found in [1], suggests that if β is sufﬁciently
Theorem 1. P
large each component xβ
i can be used as an estimate of the mean value ¯y .
i = ¯y , for all i ∈ V .
i xβ
i /n = ¯y and limβ↑∞ xβ
In belief propagation, messages are passed along edges of a Markov random ﬁeld. In our
case, because of the structure of the distribution pβ (·), the relevant Markov random ﬁeld

(5)

(6)

ij (xj ) = exp
M t

has the same topology as the graph (V , E ). The message Mij (·) passed from node i to
Z
node j is a distribution on the variable xj . Node i computes this message using incoming
i ) Y
messages from other nodes as deﬁned by the update equation
M t−1
i ) dx0
ui (x0
ψij (x0
i , xj )ψi (x0
ij (xj ) = κ
M t
i .
u∈N (i)\j
Here, κ is a normalizing constant. Since our underlying distribution pβ (·) is Gaussian,
exp (cid:0)−K t
ij )2 (cid:1). Then, (6) is equivalent to synchronous consensus propagation
it is natural to consider messages which are Gaussian distributions.
In particular, let
ij ) ∈ R × R+ parameterize Gaussian message M t
ij (·) according to M t
ij (xj ) ∝
(µt
ij , K t
ij (xj − µt
iterations for K t and µt .
 ,
−(xj − yj )2 − X
j (xj ) ∝ ψj (xj ) Y
The sequence of densities
pt
i∈N (j )
i∈N (j )
is meant to converge to an approximation of the marginal conditional distribution of xj .
j (·). It is easy to show that,
As such, an approximation to xβ
j is given by maximizing pt
j = Xj (µt , K t ). With this and aforementioned correspon-
the maximum is attained by xt
dences, we have shown that consensus propagation is a special case of belief propagation.
Readers familiar with belief propagation will notice that in the derivation above we have
used the sum product form of the algorithm. In this case, since the underlying distribution
is Gaussian, the max product form yields equivalent iterations.

ij (xj − µt
ij )2
K t

3 Convergence

The following theorem is our main convergence result.
(i) There are unique vectors (µβ , K β ) such that K β = F (K β ), and
Theorem 2.
µβ = G (µβ , K β ).
(ii) Assume that each edge (i, j ) ∈ ~E appears inﬁnitely often in the sequence of
communication sets {Ut}. Then, independent of the initial condition (µ0 , K 0 ),
limt→∞ K t = K β , and limt→∞ µt = µβ .
(iii) Given (µβ , K β ), if xβ = X (µβ , K β ), then xβ is the mode of the distribution
pβ (·).
The proof of this theorem can be found in [1], but it rests on two ideas. First, notice that,
according to the update equation (1), K t evolves independently of µt . Hence, we analyze
K t ﬁrst. Following the work of [7], we prove that the functions {Fij (·)} are monotonic.
This property is used to establish convergence to a unique ﬁxed point. Next, we analyze µt
assuming that K t has already converged. Given ﬁxed K , the update equations for µt are
linear, and we establish that they induce a contraction with respect to the maximum norm.
This allows us to establish existence of a ﬁxed point and asynchronous convergence.

4 Convergence Time for Regular Graphs

In this section, we will study the convergence time of synchronous consensus propagation.
For  > 0, we will say that an estimate ˜x of ¯y is -accurate if k ˜x − ¯y1k2,n ≤ . Here, for
√
integer m, k · k2,m is the norm on Rm deﬁned by kxk2,m = kxk2 /
m. We are interested
in the number of iterations required to obtain an -accurate estimate of the mean ¯y .

4.1 The Case of Regular Graphs

+

(7)

ij =
µt

We will restrict our analysis of convergence time to cases where (V , E ) is a d-regular graph,
for d ≥ 2. Extension of our analysis to broader classes of graphs remains an open issue.
ij = yi , and K 0 = [k0 ]ij for
We will also make simplifying assumptions that Qij = 1, µ0
some scalar k0 ≥ 0.
In this restricted setting, the subspace of constant K vectors is invariant under F . This
implies that there is some scalar kβ > 0 so that K β = [kβ ]ij . This kβ is the unique solution
to the ﬁxed point equation kβ = (1+ (d− 1)kβ )/((1+ (1+ (d− 1)kβ )/β ). Given a uniform
initial condition K 0 = [k0 ]ij , we can study the sequence of iterates {K t} by examining
the scalar sequence {kt}, deﬁned by kt = (1 + (d − 1)kt−1 )(1 + (1 + (d − 1)kt−1 )/β ).
In particular, we have K t = [kt ]ij , for all t ≥ 0.
(cid:19) X
(cid:18)
Similarly, in this setting, the equations for the evolution of µt take the special form
µt−1
1
1 −
yi
ui
1 + (d − 1)kt−1
1 + (d − 1)kt−1
d − 1 .
u∈N (i)\j
Deﬁning γt = 1/(1 + (d − 1)kt ), we have, in vector form,
µt = γt−1 ˆy + (1 − γt−1 ) ˆP µt−1 ,
where ˆy ∈ Rnd is a vector with ˆyij = yi and ˆP ∈ Rnd×nd
is a doubly stochastic matrix.
+
The matrix ˆP corresponds to a Markov chain on the set of directed edges ~E . In this chain,
an edge (i, j ) transitions to an edge (u, i) with u ∈ N (i)\ j , with equal probability assigned
(Aµ)j = P
to each such edge. As in (3), we associate each µt with an estimate xt of xβ according to
xt = y/(1 + dkβ ) + dkβ Aµt/(1 + dkβ ), where A ∈ Rn×nd
is a matrix deﬁned by
+
i∈N (j ) µij /d.
of mixing time associated with ˆP . Let ˆP ? be the Ces `aro limit ˆP ? = limt→∞ Pt−1
Deﬁne the Ces `aro mixing time τ ? by τ ? = supt≥0 k Pt
The update equation (7) suggests that the convergence of µt is intimately tied to a notion
ˆP τ /t.
τ =0
τ =0 ( ˆP τ − ˆP ? )k2,nd . Here, k·k2,nd is
the matrix norm induced by the corresponding vector norm k · k2,nd . Since ˆP is a stochastic
matrix, ˆP ? is well-deﬁned and τ ? < ∞. Note that, in the case where ˆP is aperiodic,
irreducible, and symmetric, τ ? corresponds to the traditional deﬁnition of mixing time: the
inverse of the spectral gap of ˆP .
A time t∗ is said to be an -convergence time if estimates xt are -accurate for all t ≥ t∗ .
The following theorem, whose proof can be found in [1], establishes a bound on the -
convergence time of synchronous consensus propagation given appropriately chosen β , as
a function of  and τ ? .
Theorem 3. Suppose k0 ≤ kβ . If d = 2 there exists a β = Θ((τ ? /)2 ) and if d > 2 there
exists a β = Θ(τ ? /) such that some t∗ = O((τ ? /) log(τ ? /)) is an -convergence time.
Alternatively, suppose k0 = kβ . If d = 2 there exists a β = Θ((τ ? /)2 ) and if d > 2 there
exists a β = Θ(τ ? /) such that some t∗ = O((τ ? /) log(1/)) is an -convergence time.
In the ﬁrst part of the above theorem, k0 is initialized arbitrarily so long as k0 ≤ kβ .
Typically, one might set k0 = 0 to guarantee this. The second case of interest is when
k0 = kβ , so that kt = kβ for all t ≥ 0 Theorem 3 suggests that initializing with k0 = kβ
leads to an improvement in convergence time. However, in our computational experience,
we have found that an initial condition of k0 = 0 consistently results in faster convergence
than k0 = kβ . Hence, we suspect that a convergence time bound of O((τ ? /) log(1/))
also holds for the case of k0 = 0. Proving this remains an open issue. Theorems 3 posits
choices of β that require knowledge of τ ? , which may be both difﬁcult to compute and also

requires knowledge of the graph topology. This is not a major restriction, however. It is not
difﬁcult to imagine variations of Algorithm 1 which use a doubling sequence of guesses for
the Ces ´aro mixing time τ ? . Each guess leads to a choice of β and a number of iterations t∗
to run with that choice of β . Such a modiﬁed algorithm would still have an -convergence
time of O((τ ? /) log(τ ? /)).

5 Comparison with Pairwise Averaging

Using the results of Section 4, we can compare the performance of consensus propagation
to that of pairwise averaging. Pairwise averaging is usually deﬁned in an asynchronous
setting, but there is a synchronous counterpart which works as follows. Consider a doubly
stochastic symmetric matrix P ∈ Rn×n such that Pij = 0 if (i, j ) /∈ E . Evolve estimates
according to xt = P xt−1 , initialized with x0 = y . Clearly xt = P t y → ¯y1 as t ↑ ∞.
In the case of a singly-connected graph, synchronous consensus propagation converges
exactly in a number of iterations equal to the diameter of the graph. Moreover, when
β = ∞, this convergence is to the exact mean, as discussed in Section 2.1. This is the best
one can hope for under any algorithm, since the diameter is the minimum amount of time
required for a message to travel between the two most distant nodes. On the other hand, for
a ﬁxed accuracy , the worst-case number of iterations required by synchronous pairwise
averaging on a singly-connected graph scales at least quadratically in the diameter [18].
The rate of convergence of synchronous pairwise averaging is governed by the relation
kxt − ¯y1k2,n ≤ λt
2 , where λ2 is the second largest eigenvalue of P . Let τ2 = 1/ log(1/λ2 ),
and call it the mixing time of P .
In order to guarantee -accuracy (independent of y ),
t > τ2 log(1/) sufﬁces and t = Ω(τ2 log(1/)) is required [6].
Consider d-regular graphs and ﬁx a desired error tolerance . The number of iterations
required by consensus propagation is Θ(τ ? log τ ? ), whereas that required by pairwise av-
eraging is Θ(τ2 ). Both mixing times depend on the size and topology of the graph. τ2
is the mixing time of a process on nodes that transitions along edges whereas τ ? is the
mixing time of a process on directed edges that transitions towards nodes. An important
distinction is that the former process is allowed to “backtrack” where as the latter is not.
By this we mean that a sequence of states {i, j, i} can be observed in the vertex process,
but the sequence {(i, j ), (j, i)} cannot be observed in the edge process. As we will now il-
lustrate through an example, it is this difference that makes τ2 larger than τ ? and, therefore,
pairwise averaging less efﬁcient than consensus propagation.
In the case of a cycle (d = 2) with an even number of nodes n, minimizing the mixing
time over P results in τ2 = Θ(n2 ) [19]. For comparison, as demonstrated in the following
theorem (whose proof can be found in [1]), τ ? is linear in n.
√
Theorem 4. For the cycle with n nodes, τ ? ≤ n/
2.
Intuitively, the improvement in mixing time arises from the fact that the edge process moves
around the cycle in a single direction and therefore explores the entire graph within n
iterations. The vertex process, on the other hand, randomly transitions back and forth
among adjacent nodes, relying on chance to eventually explore the entire cycle.
The cycle example demonstrates a Θ(n/ log n) advantage offered by consensus propaga-
tion. Comparisons of mixing times associated with other graph topologies remains an issue
for future analysis. But let us close by speculating on a uniform grid of n nodes over the
m-dimensional unit torus. Here, n1/m is an integer, and each vertex has 2m neighbors,
each a distance n−1/m away. With P optimized, it can be shown that τ2 = Θ(n2/m ) [20].
We put forth a conjecture on τ ? .
Conjecture 1. For the m-dimensional torus with n nodes, τ ? = Θ(n(2m−1)/m2 ).

Acknowledgments

The authors wish to thank Balaji Prabhakar and Ashish Goel for their insights and comments. The
ﬁrst author was supported by a Benchmark Stanford Graduate Fellowship. This research was sup-
ported in part by the National Science Foundation through grant IIS-0428868 and a supplement to
grant ECS-9985229 provided by the Management of Knowledge Intensive Dynamic Systems Pro-
gram (MKIDS).

References
[1] C. C. Moallemi and B. Van Roy. Consensus propagation. Technical report, Manage-
ment Science & Engineering Deptartment, Stanford University, 2005. URL: http://www.
moallemi.com/ciamac/papers/cp-2005.pdf.
[2] L. Xiao, S. Boyd, and S. Lall. A scheme for robust distributed sensor fusion based on average
consensus. To appear in the proceedings of IPSN, 2005.
[3] C. C. Moallemi and B. Van Roy. Distributed optimization in adaptive networks. In Advances in
Neural Information Processing Systems 16, 2004.
[4] J. N. Tsitsiklis. Problems in Decentralized Decision-Making and Computation. PhD thesis,
Massachusetts Institute of Technology, Cambridge, MA, 1984.
[5] D. Kempe, A. Dobra, and J. Gehrke. Gossip-based computation of aggregate information. In
ACM Symposium on Theory of Computing, 2004.
[6] S. Boyd, A. Ghosh, B. Prabhakar, and D. Shah. Gossip algorithms: Design, analysis and
applications. To appear in the proceedings of INFOCOM, 2005.
[7] P. Rusmevichientong and B. Van Roy. An analysis of belief propagation on the turbo decod-
ing graph with Gaussian densities. IEEE Transactions on Information Theory, 47(2):745–765,
2001.
[8] S. Tatikonda and M. I. Jordan. Loopy belief propagation and Gibbs measures. In Proceedings
of the 18th Conference on Uncertainty in Artiﬁcial Intelligence, 2002.
[9] T. Heskes. On the uniqueness of loopy belief propagation ﬁxed points. Neural Computation,
16(11):2379–2413, 2004.
[10] A. T. Ihler, J. W. Fisher III, and A. S. Willsky. Message errors in belief propagation. In Advances
in Neural Information Processing Systems, 2005.
[11] G. Forney, F. Kschischang, and B. Marcus. Iterative decoding of tail-biting trelisses. In Pro-
ceedings of the 1998 Information Theory Workshop, 1998.
[12] S. M. Aji, G. B. Horn, and R. J. McEliece. On the convergence of iterative decoding on graphs
with a single cycle. In Proceedings of CISS, 1998.
[13] Y. Weiss and W. T. Freeman. Correctness of local probability propagation in graphical models
with loops. Neural Computation, 12:1–41, 2000.
[14] M. Bayati, D. Shah, and M. Sharma. Maximum weight matching via max-product belief prop-
agation. preprint, 2005.
[15] V. Saligrama, M. Alanyali, and O. Savas. Asynchronous distributed detection in sensor net-
works. preprint, 2005.
[16] Y. Weiss and W. T. Freeman. Correctness of belief propagation in Gaussian graphical models
of arbitrary topology. Neural Computation, 13:2173–2200, 2001.
[17] D. P. Bertsekas and J. N. Tsitsiklis. Parallel and Distributed Computation: Numerical Methods.
Athena Scientiﬁc, Belmont, MA, 1997.
[18] S. Boyd, P. Diaconis, J. Sun, and L. Xiao. Fastest mixing Markov chain on a path. submitted to
The American Mathematical Monthly, 2003.
[19] S. Boyd, A. Ghosh, B. Prabhakar, and D. Shah. Mixing times for random walks on geometric
random graphs. To appear in the proceedings of SIAM ANALCO, 2005.
[20] S. Roch. Bounded fastest mixing. preprint, 2004.

