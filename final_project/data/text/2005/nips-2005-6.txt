Fast Information Value
for Graphical Models

Brigham S. Anderson
School of Computer Science
Carnegie Mellon University
Pittsburgh, PA 15213
brigham@cmu.edu

Andrew W. Moore
School of Computer Science
Carnegie Mellon University
Pittsburgh, PA 15213
awm@cs.cmu.edu

Abstract

Calculations that quantify the dependencies between variables are vital
to many operations with graphical models, e.g., active learning and sen-
sitivity analysis. Previously, pairwise information gain calculation has
involved a cost quadratic in network size. In this work, we show how
to perform a similar computation with cost linear in network size. The
loss function that allows this is of a form amenable to computation by
dynamic programming. The message-passing algorithm that results is
described and empirical results demonstrate large speedups without de-
crease in accuracy. In the cost-sensitive domains examined, superior ac-
curacy is achieved.

1 Introduction

In a diagnosis problem, one wishes to select the best test (or observation) to make in order
to learn the most about a system of interest. Medical settings and disease diagnosis imme-
diately come to mind, but sensor management (Krishnamurthy, 2002), sensitivity analysis
(Kjrulff & van der Gaag, 2000), and active learning (Anderson & Moore, 2005) all make
use of similar computations. These generally boil down to an all-pairs analysis between
observable variables (queries) and the variables of interest (targets.)
A common technique in the (cid:2)eld of diagnosis is to compute the mutual information between
each query and target, then select the query that is expected to provide the most information
(Agostak & Weiss, 1999). Likewise, a sensitivity analysis between the query variable
and the target variables can be performed (Laskey, 1995; Kjrulff & van der Gaag, 2000).
However, both suffer from a quadratic blowup with respect to the number of queries and
targets.
In the current paper we present a loss function which can be used in a message-passing
framework to perform the all-pairs computation with cost linear in network size. We de-
scribe the loss function in Section 2, we describe a polynomial expression for network-
wide expected loss in Section 3, and in Section 4 we present a message-passing scheme
to perform this computation ef(cid:2)ciently for each node in the network. Section 5 shows the
empirical speedups and accuracy gains achieved by the algorithm.

1.1 Graphical Models
To simplify presentation, we will consider only Bayesian networks, but the results gen-
eralize to any graphical model. We also restrict the class of networks to those without
undirected loops, or polytrees, of which Junction trees are a member. We have a Bayesian
Network B , which is composed of an independence graph, G and parameters for CPT ta-
bles. The independence graph G = (X ; E ) is a directed acyclic graph (DAG) in which
X is a set of N discrete random variables fx1 ; x2 ; :::; xN g 2 X , and the edges de(cid:2)ne the
independence relations. We will denote the marginal distribution of a single node P (xjB)
by (cid:25)x , where ((cid:25)x )i is P (x = i). We will omit conditioning on B for the remainder of the
paper. We indicate the number states a node x can assume as jxj.
Additionally, each node x is assigned a cost matrix Cx , in which (Cx )ij is the cost of be-
lieving x = j when in fact the true value x(cid:3) = i. A cost matrix of all zeros indicates that
one is not interested in the node’s value. The cost matrix C is useful because inhomoge-
neous costs are a common feature in most realistic domains. This ubiquity results from the
fact that information almost always has a purpose, so that some variables are more relevant
than others, some states of a variable are more relevant than others, and confusion between
some pairs of states are more relevant than between other pairs.
For our task, we are given B , and wish to estimate P (X ) accurately by iteratively selecting
the next node to observe. Although typically only a subset of the nodes are queryable, we
will for the purposes of this paper assume that any node can be queried. How do we select
the most informative node to query? We must (cid:2)rst de(cid:2)ne our objective function, which is
determined by our de(cid:2)nition of error.

2 Risk Due to Uncertainty

The underlying error function for the information gain computation will be denoted
E rror(P (X )jjX (cid:3) ), which quanti(cid:2)es the loss associated with the current belief state, P (X )
given the true values X (cid:3) . There are several common candidates for this role, a log-loss
function, a log-loss function over marginals, and an expected 0-1 misclassi(cid:2)cation rate
(Kohavi & Wolpert, 1996). Constant factors have been omitted.

(1)
(2)

(3)

P (u(cid:3) )

E rrorlog (P (X )jjX (cid:3) ) = (cid:0) log P (X (cid:3) )
E rrormlog (P (X )jjX (cid:3) ) = (cid:0) Xu2X
log P (u(cid:3) )
E rror01 (P (X )jjX (cid:3) ) = (cid:0) Xu2X
Where X is the set of nodes, and u(cid:3) is the true value of node u. The error function of
Equation 1 will prove insuf(cid:2)cient for our needs as it cannot target individual node errors,
while the error function of Equation 2 results in an objective function that is quadratic in
cost to compute.
We will be exploring a more general form of Equation 3 which allows arbitrary weights to
be placed on different types of misclassi(cid:2)cations. For instance, we would like to specify
that misclassifying a node’s state as 0 when it is actually 1 is different from misclassifying
it as 0 when it is actually in state 2. Different costs for each node can be speci(cid:2)ed with cost
matrices Cu for u 2 X . The (cid:2)nal error function is

E rror(P (X )jjX (cid:3) ) = Xu2X

juj
Xi

P (u = i)Cu [u(cid:3) ; i]

(4)

P (x)E rrorP (X jjx)

Where C [i; j ] is the ij th element of the matrix C , and juj is the number of states that
the node u can assume. The presence of the cost matrix Cu in Equation 4 constitutes a
signi(cid:2)cant advantage in real applications, as they often need to specify inhomogeneous
costs.
There is a separate consideration, that of query cost, or cost(x), which is the cost incurred
by the action of observing x (e.g., the cost of a medical test.) If both the query cost and
the misclassi(cid:2)cation cost C are formulated in the same units, e.g., dollars, then they form
a coherent decision framework. The query costs will be omitted from this presentation for
clarity.
In general, one does not actually know the true values X (cid:3) of the nodes, so one cannot
directly minimize the error function as described. Instead, the expected error, or risk, is
used.
Risk(P (X )) = Xx
which for the error function of Equation 4 reduces to
Risk(P (X )) = Xu2X Xj Xk
= Xu2X
(cid:25)T
u Cu (cid:25)u
where ((cid:25)u )i = P (u = i). This is the objective we will minimize. It quanti(cid:2)es (cid:147)On av-
erage, how much is our current ignorance going cost us?(cid:148) For comparison, note that the
log-loss function, E rrorlog , results in an entropy risk function Risklog (P (X )) = H (X ),
and the log-loss function over the marginals, E rrormlog , results in the risk function
Riskmlog (P (X )) = Pu2X H (u).
Ultimately, we want to (cid:2)nd the nodes that have the greatest effect on Risk(P (X )), so we
must condition Risk(P (X )) on the beliefs at each node. In other words, if we learned
that the true marginal probabilities of node x were (cid:25)x , what effect would that have on our
current risk, or rather, what is Risk(P (X )jP (x) = (cid:25)x )? Discouragingly, however, any
change in (cid:25)x propagates to all the other beliefs in the network. It seems as if we must
perform several network evaluations for each node, a prohibitive cost for networks of any
appreciable size. However, we will show that in fact dynamic programming can perform
this computation for all nodes in only two passes through the network.

P (u = j )P (u = k)Cu [j; k ]

(5)

(6)

(7)

3 Risk Calculation
To clarify our objective, we wish to construct a function Ra ((cid:25)) for each node a, where
Ra ((cid:25)) = Risk(P (X )jP (a) = (cid:25)). Suppose, for instance, that we learn that the value
of node a is equal to 3. Our P (X ) is now constrained to have the marginal P (a) = (cid:25) 0
a ,
a )3 = 1 and equals zero elsewhere. If we had the function Ra in hand, we could
where ((cid:25) 0
simply evaluate Ra ((cid:25) 0
a ) to immediately compute our new network-wide risk, which would
account for all the changes in beliefs to all the other nodes due to learning that a = 3. This
is exactly our objective; we would like to precompute Ra for all a 2 X . De(cid:2)ne
Ra ((cid:25)) = Risk(P (X )jP (a) = (cid:25))
u Cu (cid:25)u (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)P (a)=(cid:25)
= Xu2X
(cid:25)T
This simply restates the risk de(cid:2)nition of Equation 7 under the condition that P (a) = (cid:25) .
As shown in the next theorem, the function Ra has a surprisingly simple form.

(9)

(8)

Theorem 3.1. For any node x, the function Rx ((cid:25)) is a second-degree polynomial function
of the elements of (cid:25)

Proof. De(cid:2)ne the matrix P
ujv for every pair of nodes (u; v), such that (P
ujv )ij = P (u =
j jv = i). Recall that the the beliefs at node x have a strictly linear relationship to the beliefs
of node u, since

((cid:25)u )i = Xk
is equivalent to (cid:25)u = Pujx(cid:25)x . Substituting P

P (u = ijx = k)P (x = k)

ujx(cid:25)x for (cid:25)u in Equation 9 obtains
ujxCuPujx(cid:25)x (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:25)x=(cid:25)
Rx ((cid:25)) = Xu2X
(cid:25)T
PT
x
ujxCuPujx! (cid:25)
= (cid:25)T  Xu2X
PT
= (cid:25)T (cid:2)x(cid:25)

(10)

(11)

(12)

(13)

Where (cid:2)x is an jxj (cid:2) jxj matrix.

Note that the matrix (cid:2)x is suf(cid:2)cient to completely describe Rx , so we only need to consider
the computation of (cid:2)x for x 2 X . From Equation 12, we see a simple equation for
computing these (cid:2)x directly (though expensively):
(cid:2)x = Xu2X

PT
ujxCuP

(14)

ujx

Example #1
Given the 2-node network a ! b, how do we calculate Ra ((cid:25)), the total risk associated with
our beliefs about the value of node a? Our objective is thus to determine

Ra ((cid:25)) = Risk(P (a; b)jP (a) = (cid:25))
= (cid:25)T (cid:2)a(cid:25)

(15)
(16)

Equation 14 will give (cid:2)a as

bja

with P

aja + PT
bjaCbP

(cid:2)a = PT
ajaCaP
= Ca + PT
bjaCbP
bja
aja = I by de(cid:2)nition. The individual coef(cid:2)cients of (cid:2)a are thus
(cid:18)aij = Caij + Xk Xl
Now we can compute the relation between any marginal (cid:25) at node a and our total network-
wide risk via Ra ((cid:25)). However, using Equation 14 to compute all the (cid:2) would require
evaluating the entire network once per node. The function can, however, be decomposed
further, which will enable much more ef(cid:2)cient computation of (cid:2)x for x 2 X .

P (b = k ja = i)P (b = lja = j )Cbkl

(17)
(18)

(19)

3.1 Recursion
To create an ef(cid:2)cient message-passing algorithm for computing (cid:2)x for all x 2 X , we will
x , where W is a subset of the network over which Risk(P (X )) is summed.
introduce (cid:2)W
(20)
x = Xu2W
(cid:2)W
PT
ujxCuP
This is otherwise identical to Equation 14. It implies, for instance, that (cid:2)x
x = Cx . More
importantly, these matrices can be usefully decomposed as follows.
Theorem 3.2. (cid:2)W
if x and W are conditionally independent given y .
y jx(cid:2)W
x = PT
P
y

ujx

y jx

P

ujy

(21)

(P

ujy

P

y jx)ij =

ujx = P

Proof. Note that P

P (u = ijy = k)P (y = k jx = j )

y jx for u 2 X , since
jy j
Xk
(22)
= P (u = ijx = j )
(23)
= (P
ujx )ij
Step (21) is only true if x and u are conditionally independent given y . Substituting this
result into Equation 20, we conclude
x = Xu2W
(cid:2)W
= Xu2W
PT
PT
ujy(cid:2)u
y jx
u
y jx   Xu2W
= PT
y jx(cid:2)W
= PT
P
y jx
y

ujy
y jx
ujy ! P

PT
ujxCuP

PT
ujy(cid:2)u
u

(26)

(27)

(25)

P

y jx

ujx

P

P

(24)

Example #2
Suppose we now have a 3-node network, a ! b ! c, and we are only interested in the
effect that node a has on the network-wide Risk . Our objective is to compute
Ra ((cid:25)) = Risk(P (a; b; c)jP (a) = (cid:25))
= (cid:25)T (cid:2)a(cid:25)

(28)
(29)

where (cid:2)a is by de(cid:2)nition
(30)
(cid:2)a = (cid:2)abc
a
(31)
= Ca + PT
bja + PT
bjaCbP
cjaCcP
cja
Using Theorem 3.2 and the fact that a is conditionally independent of c given b, we know
(32)
(cid:2)abc
a = (cid:2)a
a + PT
bja(cid:2)bc
P
b
(33)
cjb(cid:2)c
b + PT
b = (cid:2)b
(cid:2)bc
P
c

bja

cjb

Substituting 33 into 32

bja (cid:16)(cid:2)b
cjb(cid:17) P
cjb(cid:2)c
b + PT
a + PT
(cid:2)a = (cid:2)a
P
c
bja (cid:16)Cb + PT
cjb(cid:17) P
(35)
= Ca + PT
cjbCcP
bja
Note that the coef(cid:2)cient (cid:2)a is obtained from probabilities between neighboring nodes only,
without having to explicitly compute P
cja .

(34)

bja

4 Message Passing
We are now ready to de(cid:2)ne message passing. Messages are of two types; in-messages and
out-messages. They are denoted by (cid:21) and (cid:22), respectively. Out-messages (cid:22) are passed from
parent to child, and in-messages (cid:21) are passed from child to parent. The messages from x to
y will be denoted as (cid:22)xy and (cid:21)xy . In the discrete case, (cid:22)xy and (cid:21)xy will both be matrices
of size jy j (cid:2) jy j. The messages summarize the effect that y has on the part of the network
that y is d-separated from by x. Messages relate to the (cid:2) coef(cid:2)cients by the following
de(cid:2)nition

(36)
(cid:21)yx = (cid:2)ny
x
(37)
(cid:22)yx = (cid:2)ny
x
where the (nonstandard) notation (cid:2)ny
x indicates the matrix (cid:2)V
x for which V is the set of all
the nodes in X that are reachable by x if y were removed from the graph. In other words,
x is summarizing the effect that x has on the entire network except for the part of the
(cid:2)ny
network that x can only reach through y .
Propagation: The message-passing scheme is organized to recursively compute the (cid:2)
matrices using Theorem 3.2. As can be seen from Equations 36 and 37, the two types of
messages are very similar in meaning. They differ only in that passing a message from a
parent to child automatically separates the child from the rest of the network the parent is
connected to, while a child-to-parent message does not necessarily separate the parent from
the rest of the network that the child is connected to (due to the (cid:147)explaining away(cid:148) effect.)
The contruction of the (cid:22)-message involves a short sequence of basic linear algebra. The
(cid:22)-message from x to child c is created from all other messages entering x except those
from c. The de(cid:2)nition is
(cid:21)vx1
xjc 0
(cid:22)ux + Xv2ch(x)nc
@Cx + Xu2pa(x)
(cid:22)xc = PT
A
The (cid:21)-messages from x to parent u are only slightly more involved. To account for the
(cid:147)explaining away(cid:148) effect, we must construct (cid:21)xu directly from the parents of x.
xju 0
(cid:21)cx1
@Cx + Xc2ch(x)
(cid:21)xu =PT
A
(cid:21)cw1
w ju 0
(cid:22)vw + Xc2ch(w)nx
@Cw + Xv2pa(w)
Xw2pa(x)nu
PT
A
Messages are constructed (or (cid:147)sent(cid:148)) whenever all of the required incoming messages are
present and that particular message has not already been sent. For example, the out-
message (cid:22)xc can be sent only when messages from all the parents of x and all the children
of x (save c) are present. The overall effect of this constraint is a single leaves-inward
propagation followed by a single root-outward propagation.
Initialization and Termination: Initialization occurs naturally at any singly-connected
(leaf) node x, where the message is by de(cid:2)nition Cx . Termination occurs when no more
messages meet the criteria for sending. Once all message propagation is (cid:2)nished, for each
node x the coef(cid:2)cients (cid:2)x can be computed by a simple summation:
(cid:21)cx + Xu2par(x)
(cid:2)x = Xc2ch(x)

(cid:22)ux + Cx

(38)

P

xju+

(39)

(40)

P

xjc

P

w ju

200

150

s
c
e
S

100

50

0
0

MI
Cost Prop

200

400
600
Number of Nodes

800

1000

Figure 1: Comparison of execution times with synthetic polytrees.

Propagation runs in time linear in the number of nodes once the initial local probabilities
are calculated. The local probabilities required are the matrices P for each parent-child
probability,e.g., P (child = j jparent = i), and for each pair (not set) of parents that share
a child, P (parent = j jcoparent = i). These are all immediately available from a junction
tree, or they can be obtained with a run of belief propagation.
It is worth noting that the apparent complexity of the (cid:21); (cid:22) message propagation equations
is due to the Bayes Net representation. The equivalent factor graph equations (not shown)
are markedly more succinct.

5 Experiments

The performance of the message-passing algorithm (hereafter CostProp) was compared
with a standard information gain algorithm which uses mutual information (hereafter MI).
The error function used by MI is from Equation 2, where E rrormlog (P (X )jjX (cid:3) ) =
Px2X log P (x(cid:3) ), with a corresponding risk function Risk(P (X )) = Px2X H (x). This
corresponds to selecting the node x that has the highest summed mutual information with
each of the target nodes (in this case, the set of target nodes is X and the set of query nodes
is also X .) The computational cost of MI grows quadratically as the product of the number
of queries and of targets.
In order to test the speed and relative accuracy of CostProp, we generated random polytrees
with varying numbers of trinary nodes. The CPT tables were randomly generated with a
slight bias towards lower-entropy probabilities. The code was written in Matlab using the
Bayes Net Toolbox (Murphy, 2005).
Speed: We generated polytrees of sizes ranging from 2 to 1000 nodes and ran the MI
algorithm, the CostProp algorithm, and a random-query algorithm on each. The two non-
random algorithms were run using a junction tree, the build time of which was not included
in the reported run times of either algorithm. Even with the relatively slow Matlab code, the
speedup shown in Figure 1 is obvious. As expected, CostProp is many orders of magnitude
faster than the MI algorithm, and shows a qualitative difference in scaling properties.
Accuracy: Due to the slow running time of MI, the accuracy comparison was performed
on polytrees of size 20. For each run, a true assignment X (cid:3) was generated from the tree, but
were initially hidden from the algorithms. Each algorithm would then determine for itself
the best node to observe, receive the true value of that node, then select the next node to
observe, et cetera. The true error at each step was computed as the 0-1 error of Equation 3.
The reduction in error plotted against number of queries is shown in Figure 2. With uniform

t
s
o
C
 
e
u
r
T

120

100

80

60

40

20

0

Random
MI
Cost Prop

5

10
Number of Queries

15

20

t
s
o
C
 
e
u
r
T

7000

6000

5000

4000

3000

2000

1000

0
0

Random
MI
Cost Prop

5

10
Number of Queries

15

20

Figure 2: Performance on synthetic poly-
trees with symmetric costs.

Figure 3: Performance on synthetic poly-
trees with asymmetric costs.

cost matrices, performance of MI and CostProp are approximately equal on this task, but
both are better than random. We next made the cost matrices asymmetric by initializing
them such that confusing one pair of states was 100 times more costly than confusing the
other two pairs. The results of Figure 3 show that CostProp reduces error faster than MI,
presumably because it can accomodate the cost matrix information.

6 Discussion
We have described an all-pairs information gain calculation that scales linearly with net-
work size. The objective function used has a polynomial form that allows for an ef(cid:2)cient
message-passing algorithm. Empirical results demonstrate large speedups and even im-
proved accuracy in cost-sensitive domains. Future work will explore other applications of
this method, including sensitivity analysis and active learning. Further research into other
uses for the belief polynomials will also be explored.

References
Agostak, J. M., & Weiss, J. (1999). Active Fusion for Diagnosis Guided by Mutual Information.
Proceedings of the 2nd International Conference on Information Fusion.
Anderson, B. S., & Moore, A. W. (2005). Active learning for hidden markov models: Objective
functions and algorithms. Proceedings of the 22nd International Conference on Machine Learning.
Kjrulff, U., & van der Gaag, L. (2000). Making sensitivity analysis computationally ef(cid:2)cient.
Kohavi, R., & Wolpert, D. H. (1996). Bias Plus Variance Decomposition for Zero-One Loss Func-
tions. Machine Learning : Proceedings of the Thirteenth International Conference. Morgan
Kaufmann.
Krishnamurthy, V. (2002). Algorithms for optimal scheduling and management of hidden markov
model sensors. IEEE Transactions on Signal Processing, 50, 1382(cid:150)1397.
Laskey, K. B. (1995). Sensitivity Analysis for Probability Assessments in Bayesian Networks. IEEE
Transactions on Systems, Man, and Cybernetics.
Murphy, K. (2005). Bayes net toolbox for matlab. U. C. Berkeley. http://www.ai.mit.edu/(cid:152)
murphyk/Software/BNT/bnt.html.

