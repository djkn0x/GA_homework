The Forgetron:
A Kernel-Based Perceptron on a Fixed Budget

Ofer Dekel Shai Shalev-Shwartz Yoram Singer
School of Computer Science & Engineering
The Hebrew University, Jerusalem 91904, Israel
{oferd,shais,singer}@cs.huji.ac.il

Abstract

The Perceptron algorithm, despite its simplicity, often performs well on
online classiﬁcation tasks. The Perceptron becomes especi ally effective
when it is used in conjunction with kernels. However, a common dif-
ﬁculty encountered when implementing kernel-based online algorithms
is the amount of memory required to store the online hypothesis, which
may grow unboundedly. In this paper we present and analyze the For-
getron algorithm for kernel-based online learning on a ﬁxed memory
budget. To our knowledge, this is the ﬁrst online learning al gorithm
which, on one hand, maintains a strict limit on the number of examples
it stores while, on the other hand, entertains a relative mistake bound.
In addition to the formal results, we also present experiments with real
datasets which underscore the merits of our approach.

1 Introduction

The introduction of the Support Vector Machine (SVM) [8] sparked a widespread interest
in kernel methods as a means of solving (binary) classiﬁcati on problems. Although SVM
was initially stated as a batch-learning technique, it signiﬁcantly in ﬂuenced the develop-
ment of kernel methods in the online-learning setting. Online classiﬁcation algorithms that
can incorporate kernels include the Perceptron [6], ROMMA [5], ALMA [3], NORMA [4],
Ballseptron [7], and the Passive-Aggressive family of algorithms [1]. Each of these algo-
rithms observes examples in a sequence of rounds, and constructs its classiﬁcation function
incrementally, by storing a subset of the observed examples in its internal memory. The
classiﬁcation function is then de ﬁned by a kernel-dependen
t combination of the stored ex-
amples. This set of stored examples is the online equivalent of the support set of SVMs,
however in contrast to the support, it continually changes as learning progresses. In this
paper, we call this set the active set, as it includes those examples that actively de ﬁne the
current classiﬁer. Typically, an example is added to the act ive set every time the online al-
gorithm makes a prediction mistake, or when its con ﬁdence in a prediction is inadequately
low. A rapid growth of the active set can lead to signiﬁcant co mputational difﬁculties. Nat-
urally, since computing devices have bounded memory resources, there is the danger that
an online algorithm would require more memory than is physically available. This problem
becomes especially eminent in cases where the online algorithm is implemented as part of
a specialized hardware system with a small memory, such as a mobile telephone or an au-

tonomous robot. Moreover, an excessively large active set can lead to unacceptably long
running times, as the time-complexity of each online round scales linearly with the size of
the active set.

Crammer, Kandola, and Singer [2] ﬁrst addressed this proble m by describing an online
kernel-based modiﬁcation of the Perceptron algorithm in wh ich the active set does not ex-
ceed a prede ﬁned budget. Their algorithm removes redundant examples from the active set
so as to make the best use of the limited memory resource. Weston, Bordes and Bottou [9]
followed with their own online kernel machine on a budget. Both techniques work rela-
tively well in practice, however they both lack a theoretical guarantee on their prediction
accuracy. In this paper we present the Forgetron algorithm for online kernel-based classi-
ﬁcation. To the best of our knowledge, the Forgetron is the ﬁr
st online algorithm with a
ﬁxed memory budget which also entertains a formal worst-cas e mistake bound. We name
our algorithm the Forgetron since its update builds on that of the Perceptron and since it
gradually forgets active examples as learning progresses.

This paper is organized as follows. In Sec. 2 we begin with a more formal presentation of
our problem and discuss some difﬁculties in proving mistake bounds for kernel-methods
on a budget. In Sec. 3 we present an algorithmic framework for online prediction with a
prede ﬁned budget of active examples. Then in Sec. 4 we derive a concrete algorithm within
this framework and analyze its performance. Formal proofs of our claims are omitted due
to the lack of space. Finally, we present an empirical evaluation of our algorithm in Sec. 5.

2 Problem Setting

Online learning is performed in a sequence of consecutive rounds. On round t the online
algorithm observes an instance xt , which is drawn from some prede ﬁned instance domain
X . The algorithm predicts the binary label associated with that instance and is then pro-
vided with the correct label yt ∈ {−1, +1}. At this point, the algorithm may use the
instance-label pair (xt , yt ) to improve its prediction mechanism. The goal of the algorithm
is to correctly predict as many labels as possible.

The predictions of the online algorithm are determined by a hypothesis which is stored
in its internal memory and is updated from round to round. We denote the hypothesis
used on round t by ft . Our focus in this paper is on margin based hypotheses, namely,
ft is a function from X to R where sign(ft (xt )) constitutes the actual binary prediction
and |ft (xt )| is the con ﬁdence in this prediction. The term yf (x) is called the margin
of the prediction and is positive whenever y and sign(f (x)) agree. We can evaluate the
performance of a hypothesis on a given example (x, y ) in one of two ways. First, we can
check whether the hypothesis makes a prediction mistake, namely determine whether y =
sign(f (x)) or not. Throughout this paper, we use M to denote the number of prediction
mistakes made by an online algorithm on a sequence of examples (x1 , y1 ), . . . , (xT , yT ).
The second way we evaluate the predictions of a hypothesis is by using the hinge-loss
function, de ﬁned as,
if yf (x) ≥ 1
ℓ(cid:0)f ; (x, y )(cid:1) = (cid:26) 0
1 − yf (x) otherwise
The hinge-loss penalizes a hypothesis for any margin less than 1. Additionally, if y 6=
sign(f (x)) then ℓ(f , (x, y )) ≥ 1 and therefore the cumulative hinge-loss suffered over a
sequence of examples upper bounds M . The algorithms discussed in this paper use kernel-
based hypotheses that are de ﬁned with respect to a kernel ope rator K : X × X → R which
adheres to Mercer’s positivity conditions [8]. A kernel-based hypothesis takes the form,
k
Xi=1

αiK (xi , x) ,

f (x) =

.

(1)

(2)

where x1 , . . . , xk are members of X and α1 , . . . , αk are real weights. To facilitate the
derivation of our algorithms and their analysis, we associate a reproducing kernel Hilbert
space (RKHS) with K in the standard way common to all kernel methods. Formally,
let HK be the closure of the set of all hypotheses of the form given in Eq. (2). For
i=1 αiK (xi , x) and g (x) = Pl
any two functions, f (x) = Pk
j=1 βj K (zj , x), de ﬁne
the inner product between them to be, hf , g i = Pk
i=1 Pl
j=1 αiβj K (xi , zj ). This inner-
product naturally induces a norm de ﬁned by kf k = hf , f i1/2 and a metric kf − gk =
(hf , f i − 2hf , g i + hg , g i)1/2 . These de ﬁnitions play an important role in the analysis of
our algorithms. Online kernel methods typically restrict themselves to hypotheses that are
de ﬁned by some subset of the examples observed on previous ro unds. That is, the hy-
pothesis used on round t takes the form, ft (x) = Pi∈It αiK (xi , x), where It is a subset
of {1, . . . , (t-1)} and xi is the example observed by the algorithm on round i. As stated
above, It is called the active set, and we say that example xi is active on round t if i ∈ It .
Perhaps the most well known online algorithm for binary classiﬁcation is the Percep-
tron [6]. Stated in the form of a kernel method, the hypotheses generated by the Perceptron
take the form ft (x) = Pi∈It yiK (xi , x). Namely, the weight assigned to each active
example is either +1 or −1, depending on the label of that example. The Perceptron ini-
tializes I1 to be the empty set, which implicitly sets f1 to be the zero function. It then
updates its hypothesis only on rounds where a prediction mistake is made. Concretely, on
round t, if ft (xt ) 6= yt then the index t is inserted into the active set. As a consequence, the
size of the active set on round t equals the number of prediction mistakes made on previous
rounds. A relative mistake bound can be proven for the Perceptron algorithm. The bound
holds for any sequence of instance-label pairs, and compares the number of mistakes made
by the Perceptron with the cumulative hinge-loss of any ﬁxed hypothesis g ∈ HK , even
one de ﬁned with prior knowledge of the sequence.
Theorem 1. Let K be a Mercer kernel and let (x1 , y1 ), . . . , (xT , yT ) be a sequence of
examples such that K (xt , xt ) ≤ 1 for all t. Let g be an arbitrary function in HK and
de ﬁne ˆℓt = ℓ(cid:0)g ; (xt , yt )(cid:1). Then the number of prediction mistakes made by the Perceptron
on this sequence is bounded by, M ≤ kgk2 + 2 PT
ˆℓt .
t=1
Although the Perceptron is guaranteed to be competitive with any ﬁxed hypothesis g ∈
HK , the fact that its active set can grow without a bound poses a serious computational
problem. In fact, this problem is common to most kernel-based online methods that do not
explicitly monitor the size of It .
As discussed above, our goal is to derive and analyze an online prediction algorithm which
resolves these problems by enforcing a ﬁxed bound on the size of the active set. Formally,
let B be a positive integer, which we refer to as the budget parameter. We would like to
devise an algorithm which enforces the constraint |It | ≤ B on every round t. Furthermore,
we would like to prove a relative mistake bound for this algorithm, analogous to the bound
stated in Thm. 1. Regretfully, this goal turns out to be impossible without making additional
assumptions. We show this inherent limitation by presenting a simple counterexample
which applies to any online algorithm which uses a prediction function of the form given
in Eq. (2), and for which |It | ≤ B for all t. In this example, we show a hypothesis g ∈ HK
and an arbitrarily long sequence of examples such that the algorithm makes a prediction
mistake on every single round whereas g suffers no loss at all. We choose the instance space
X to be the set of B + 1 standard unit vectors in RB+1 , that is X = {ei}B+1
i=1 where ei is the
vector with 1 in its i’th coordinate and zeros elsewhere. K is set to be the standard inner-
product in RB+1 , that is K (x, x′ ) = hx, x′ i. Now for every t, ft is a linear combination
of at most B vectors from X . Since |X | = B + 1, there exists a vector xt ∈ X which
is currently not in the active set. Furthermore, xt is orthogonal to all of the active vectors
and therefore ft (xt ) = 0. Assume without loss of generality that the online algorithm we

are using predicts yt to be −1 when ft (x) = 0. If on every round we were to present
the online algorithm with the example (xt , +1) then the online algorithm would make a
prediction mistake on every round. On the other hand, the hypothesis ¯g = PB+1
i=1 ei is a
member of HK and attains a zero hinge-loss on every round. We have found a sequence of
examples and a ﬁxed hypothesis (which is indeed de ﬁned by mor
e than B vectors from X )
that attains a cumulative loss of zero on this sequence, while the number of mistakes made
by the online algorithm equals the number of rounds. Clearly, a theorem along the lines of
Thm. 1 cannot be proven.

One way to resolve this problem is to limit the set of hypotheses we compete with to a sub-
set of HK , which would naturally exclude ¯g . In this paper, we limit the set of competitors
to hypotheses with small norms. Formally, we wish to devise an online algorithm which is
competitive with every hypothesis g ∈ HK for which kgk ≤ U , for some constant U . Our
counterexample indicates that we cannot prove a relative mistake bound with U set to at
least √B + 1, since that was the norm of ¯g in our counterexample. In this paper we come
close to this upper bound by proving that our algorithms can compete with any hypothesis
with a norm bounded by 1
4 p(B + 1)/ log(B + 1).
3 A Perceptron with “Shrinking ” and “Removal ” Steps

The Perceptron algorithm will serve as our starting point. Recall that whenever the Per-
ceptron makes a prediction mistake, it updates its hypothesis by adding the element t to
It . Thus, on any given round, the size of its active set equals the number of prediction
mistakes it has made so far. This implies that the Perceptron may violate the budget con-
straint |It | ≤ B . We can solve this problem by removing an example from the active set
whenever its size exceeds B . One simple strategy is to remove the oldest example in the
active set whenever |It | > B . Let t be a round on which the Perceptron makes a predic-
tion mistake. We apply the following two step update. First, we perform the Perceptron’s
t = It ∪ {t} denote the resulting active set. If |I ′
update by adding t to It . Let I ′
t | ≤ B
we are done and we set It+1 = I ′
t . Otherwise, we apply a removal step by ﬁnding the
t \ {rt }. The resulting
t , and setting It+1 = I ′
oldest example in the active set, rt = min I ′
algorithm is a simple modiﬁcation of the kernel Perceptron, which conforms with a ﬁxed
budget constraint. While we are unable to prove a mistake bound for this algorithm, it is
nonetheless an important milestone on the path to an algorithm with a ﬁxed budget and a
formal mistake bound.
The removal of the oldest active example from It may signiﬁcantly change the hypothesis
and effect its accuracy. One way to overcome this obstacle is to reduce the weight of old
examples in the de ﬁnition of the current hypothesis. By cont rolling the weight of the oldest
active example, we can guarantee that the removal step will not signiﬁcantly effect the
accuracy of our predictions. More formally, we rede ﬁne our h ypothesis to be,
ft = Xi∈It
where each σi,t is a weight in (0, 1]. Clearly, the effect of removing rt from It depends on
the magnitude of σrt ,t .
Using the ideas discussed above, we are now ready to outline the Forgetron algorithm. The
Forgetron initializes I1 to be the empty set, which implicitly sets f1 to be the zero function.
On round t, if a prediction mistake occurs, a three step update is performed. The ﬁrst step
is the standard Perceptron update, namely, the index t is inserted into the active set and the
t denote the active set which results from this update, and
weight σt,t is set to be 1. Let I ′
let f ′
t denote the resulting hypothesis, f ′
t (x) = ft (x) + ytK (xt , x). The second step of the
update is a shrinking step in which we scale f ′ by a coefﬁcient φt ∈ (0, 1]. The value of

σi,tyiK (xi , ·) ,

φt is intentionally left unspeciﬁed for now. Let f ′′
t denote the resulting hypothesis, that is,
t . Setting σi,t+1 = φt σi,t for all i ∈ I ′
t , we can write,
t = φtf ′
f ′′
t (x) = Xi∈I ′
f ′′
σi,t+1 yiK (xi , x) .
t
The third and last step of the update is the removal step discussed above. That is, if the bud-
get constraint is violated and |I ′
t | > B then It+1 is set to be I ′
t \ {rt} where rt = min I ′
t .
Otherwise, It+1 simply equals I ′
t . The recursive de ﬁnition of the weight σi,t can be unrav-
eled to give the following explicit form, σi,t = Qj∈It−1 ∧ j≥i φj . If the shrinking coefﬁ-
cients φt are sufﬁciently small, then the example weights σi,t decrease rapidly with t, and
particularly the weight of the oldest active example can be made arbitrarily small. Thus, if
φt is small enough, then the removal step is guaranteed not to cause any signiﬁcant damage.
Alas, aggressively shrinking the online hypothesis with every update might itself degrade
the performance of the online hypothesis and therefore φt should not be set too small. The
delicate balance between safe removal of the oldest example and over-aggressive scaling is
our main challenge. To formalize this tradeoff, we begin with the mistake bound in Thm. 1
and investigate how it is effected by the shrinking and removal steps.

if t ∈ J ∧ |It | = B
otherwise

We focus ﬁrst on the removal step. Let J denote the set of rounds on which the Forgetron
makes a prediction mistake and de ﬁne the function,
Ψ(σ , φ , µ) = (σ φ)2 + 2 σ φ(1 − φ µ) .
Let t ∈ J be a round on which |It | = B . On this round, example rt is removed from the
t (xrt ) be the signed margin attained by f ′
t on the active example
active set. Let µt = yrt f ′
being removed. Finally, we abbreviate,
Ψt = (cid:26) Ψ(σrt ,t , φt , µt )
0
Lemma 1 below states that removing example rt from the active set on round t increases the
mistake bound by Ψt . As expected, Ψt decreases with the weight of the removed example,
σrt ,t+1 . In addition, it is clear from the de ﬁnition of Ψt that µt also plays a key role in
determining whether xrt can be safely removed from the active set. We note in passing
that [2] used a heuristic criterion similar to µt to dynamically choose which active example
to remove on each online round.
Turning to the shrinking step, for every t ∈ J we de ﬁne,
if kft+1k ≥ U
Φt = 
1
if kf ′
t k ≤ U ∧ kft+1k < U
φt
φt kf ′
t k
if kf ′
t k > U ∧ kft+1k < U

U
Lemma 1 below also states that applying the shrinking step on round t increases the mistake
bound by U 2 log(1/Φt ). Note that if kft+1k ≥ U then Φt = 1 and the shrinking step on
round t has no effect on our mistake bound. Intuitively, this is due to the fact that, in
this case, the shrinking step does not make the norm of ft+1 smaller than the norm of our
competitor, g .
Lemma 1. Let (x1 , y1 ), . . . , (xT , yT ) be a sequence of examples such that K (xt , xt ) ≤ 1
for all t and assume that this sequence is presented to the Forgetron with a budget constraint
B . Let g be a function in HK for which kgk ≤ U , and de ﬁne ˆℓt = ℓ(cid:0)g ; (xt , yt )(cid:1). Then,
T
ˆℓt! +  Xt∈J
log (1/Φt)! .
M ≤  kgk2 + 2
Ψt + U 2 Xt∈J
Xt=1

.

.

The ﬁrst term in the bound of Lemma 1 is identical to the mistak e bound of the standard
Perceptron, given in Thm. 1. The second term is the consequence of the removal and
shrinking steps. If we set the shrinking coefﬁcients in such a way that the second term is at
ˆℓt + M
most M
2 , then the bound in Lemma 1 reduces to M ≤ kgk2 + 2 Pt
2 . This can be
ˆℓt , which is twice the bound of the Perceptron algorithm.
restated as M ≤ 2kgk2 + 4 Pt
The next lemma states sufﬁcient conditions on φt under which the second term in Lemma 1
is indeed upper bounded by M
2 .
Lemma 2. Assume that the conditions of Lemma 1 hold and that B ≥ 83. If the shrinking
coefﬁcients φt are chosen such that,

15
32

M

Ψt ≤

log (1/Φt) ≤

Xt∈J
and Xt∈J
then the following holds, Pt∈J Ψt + U 2 Pt∈J log (1/Φt) ≤ M
2
In the next section, we de ﬁne the speciﬁc mechanism used by th
e Forgetron algorithm to
choose the shrinking coefﬁcients φt . Then, we conclude our analysis by arguing that this
choice satisﬁes the sufﬁcient conditions stated in Lemma 2,
and obtain a mistake bound as
described above.

M ,

log(B + 1)
2(B + 1)

.

4 The Forgetron Algorithm

We are now ready to de ﬁne the speciﬁc choice of
φt used by the Forgetron algorithm.
On each round, the Forgetron chooses φt to be the maximal value in (0, 1] for which the
damage caused by the removal step is still manageable. To clarify our construction, de ﬁne
i ≤ t} and Mt = |Jt |. In words, Jt is the set of rounds on which the
Jt = {i ∈ J :
algorithm made a mistake up until round t, and Mt is the size of this set. We can now
rewrite the ﬁrst condition in Lemma 2 as,
Xt∈JT
Instead of the above condition, the Forgetron enforces the following stronger condition,

Ψt ≤

MT .

15
32

(3)

15
32

(4)

Mi .

∀i ∈ {1, . . . , T }, Xt∈Ji
Ψt ≤
Ψt . Let i denote a round on which the
This is done as follows. De ﬁne, Qi = Pt∈Ji−1
algorithm makes a prediction mistake and on which an example must be removed from
the active set. The i’th constraint in Eq. (4) can be rewritten as Ψi + Qi ≤ 15
32 Mi . The
Forgetron sets φi to be the maximal value in (0, 1] for which this constraint holds, namely,
32 Mi(cid:9). Note that Qi does not depend
φi = max (cid:8)φ ∈ (0, 1] : Ψ(σri ,i , φ , µi ) + Qi ≤ 15
on φ and that Ψ(σri ,i , φ, µi ) is a quadratic expression in φ. Therefore, the value of φi can
be found analytically. The pseudo-code of the Forgetron algorithm is given in Fig. 1.
Having described our algorithm, we now turn to its analysis. To prove a mistake bound
it sufﬁces to show that the two conditions stated in Lemma 2 ho ld. The ﬁrst condition of
the lemma follows immediately from the de ﬁnition of φt . Using strong induction on the
size of J , we can show that the second condition holds as well. Using these two facts, the
following theorem follows as a direct corollary of Lemma 1 and Lemma 2.

IN PUT: Mercer kernel K (·, ·) ; budget parameter B > 0
IN IT IAL IZ E : I1 = ∅ ; f1 ≡ 0 ; Q1 = 0 ; M0 = 0
For t = 1, 2, . . .
receive instance xt
; predict label: sign(ft (xt ))
receive correct label yt
If ytft (xt ) > 0
set It+1 = It , Qt+1 = Qt , Mt = Mt−1 , and ∀i ∈ It set σi,t+1 = σi,t
Else
set Mt = Mt−1 + 1
(1) set I ′
t = It ∪ {t}
If |I ′
t | ≤ B
set It+1 = I ′
t , Qt+1 = Qt , σt,t = 1, and ∀i ∈ It+1 set σi,t+1 = σi,t
Else
(2) de ﬁne rt = min It
choose φt = max{φ ∈ (0, 1] : Ψ(σrt ,t , φ , µt ) + Qt ≤ 15
32 Mt}
set σt,t = 1 and ∀i ∈ I ′
t set σi,t+1 = φt σi,t
set Qt+1 = Qt + Ψt
(3) set It+1 = I ′
t \ {rt}
de ﬁne ft+1 = Pi∈It+1
σi,t+1 yiK (xi , ·)
Figure 1: The Forgetron algorithm.

Theorem 2. Let (x1 , y1 ), . . . , (xT , yT ) be a sequence of examples such that K (xt , xt ) ≤ 1
for all t. Assume that this sequence is presented to the Forgetron algorithm from Fig. 1 with
a budget parameter B ≥ 83. Let g be a function in HK for which kgk ≤ U , where U =
4 p(B + 1)/ log(B + 1), and de ﬁne ˆℓt = ℓ(cid:0)g ; (xt , yt )(cid:1). Then, the number of prediction
1
mistakes made by the Forgetron on this sequence is at most,
T
ˆℓt
Xt=1
M ≤ 2 kgk2 + 4

5 Experiments and Discussion

In this section we present preliminary experimental results which demonstrate the mer-
its of the Forgetron algorithm. We compared the performance of the Forgetron with the
method described in [2], which we abbreviate by CKS. When the CKS algorithm exceeds
its budget, it removes the active example whose margin would be the largest after the re-
moval. Our experiment was performed with two standard datasets: the MNIST dataset,
which consists of 60,000 training examples, and the census-income (adult) dataset, with
200,000 examples. The labels of the MNIST dataset are the 10 digit classes, while the set-
ting we consider in this paper is that of binary classiﬁcatio n. We therefore generated binary
problems by splitting the 10 labels into two sets of equal size in all possible ways, totaling
(cid:0)10
5 (cid:1)/2 = 126 classiﬁcation problems. For each budget value, we ran the tw o algorithms on
all 126 binary problems and averaged the results. The labels in the census-income dataset
are already binary, so we ran the two algorithms on 10 different permutations of the ex-
amples and averaged the results. Both algorithms used a ﬁfth degree non-homogeneous
polynomial kernel. The results of these experiments are summarized in Fig. 2. The ac-
curacy of the standard Perceptron (which does not depend on B ) is marked in each plot

0.3

0.25

0.2

0.15

0.1

0.05

r
o
r
r
e
 
e
g
a
r
e
v
a

Forgetron
CKS

r
o
r
r
e
 
e
g
a
r
e
v
a

0.3

0.25

0.2

0.15

0.1

0.05

Forgetron
CKS

1000

2000
4000
3000
budget size − B

5000

6000

200 400 600 800 1000 1200 1400 1600 1800
budget size − B

Figure 2: The error of different budget algorithms as a function of the budget size B on the census-
income (adult) dataset (left) and on the MNIST dataset (right). The Perceptron’s active set reaches
a size of 14,626 for census-income and 1,886 for MNIST. The Perceptron’s error is marked with a
horizontal dashed black line.

using a horizontal dashed black line. Note that the Forgetron outperforms CKS on both
datasets, especially when the value of B is small. In fact, on the census-income dataset, the
Forgetron achieves almost the same performance as the Perceptron with only a ﬁfth of the
active examples. In contrast to the Forgetron, which performs well on both datasets, the
CKS algorithm performs rather poorly on the census-income dataset. This can be partly
attributed to the different level of difﬁculty of the two cla ssiﬁcation tasks. It turns out that
the performance of CKS deteriorates as the classiﬁcation ta sk becomes more difﬁcult. In
contrast, the Forgetron seems to perform well on both easy and difﬁcult classiﬁcation tasks.

In this paper we described the Forgetron algorithm which is a kernel-based online learning
algorithm with a ﬁxed memory budget. We proved that the Forge tron is competitive with
any hypothesis whose norm is upper bounded by U = 1
4 p(B + 1)/ log(B + 1). We
further argued that no algorithm with a budget of B active examples can be competitive
with every hypothesis whose norm is √B + 1, on every input sequence. Bridging the
small gap between U and √B + 1 remains an open problem. The analysis presented in
this paper can be used to derive a family of online algorithms of which the Forgetron is
only one special case. This family of algorithms, as well as complete proofs of our formal
claims and extensive experiments, will be presented in a long version of this paper.

References
[1] K. Crammer, O. Dekel, J. Keshet, S. Shalev-Shwartz, and Y. Singer. Online passive
aggressive algorithms. Technical report, The Hebrew University, 2005.
[2] K. Crammer, J. Kandola, and Y. Singer. Online classiﬁcat ion on a budget. NIPS, 2003.
[3] C. Gentile. A new approximate maximal margin classiﬁcat ion algorithm. JMLR, 2001.
[4] J. Kivinen, A. J. Smola, and R. C. Williamson. Online learning with kernels. IEEE
Transactions on Signal Processing, 52(8):2165 –2176, 2002.
[5] Y. Li and P. M. Long. The relaxed online maximum margin algorithm. NIPS, 1999.
[6] F. Rosenblatt. The Perceptron: A probabilistic model for information storage and
organization in the brain. Psychological Review, 65:386 –407, 1958.
[7] S. Shalev-Shwartz and Y. Singer. A new perspective on an old perceptron algorithm.
COLT, 2005.
[8] V. N. Vapnik. Statistical Learning Theory. Wiley, 1998.
[9] J. Weston, A. Bordes, and L. Bottou. Online (and ofﬂine) o n an even tighter budget.
AISTATS, 2005.

