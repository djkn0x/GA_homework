Learning Inﬂuence among Interacting
Markov Chains

Dong Zhang
IDIAP Research Institute
CH-1920 Martigny, Switzerland
zhang@idiap.ch

Daniel Gatica-Perez
IDIAP Research Institute
CH-1920 Martigny, Switzerland
gatica@idiap.ch

Samy Bengio
IDIAP Research Institute
CH-1920 Martigny, Switzerland
bengio@idiap.ch

Deb Roy
Massachusetts Institute of Technology
Cambridge, MA 02142, USA
dkroy@media.mit.edu

Abstract

We present a model that learns the in ﬂuence of interacting Markov chains
within a team. The proposed model is a dynamic Bayesian network
(DBN) with a two-level structure: individual-level and group-level. In-
dividual level models actions of each player, and the group-level models
actions of the team as a whole. Experiments on synthetic multi-player
games and a multi-party meeting corpus show the effectiveness of the
proposed model.

1 Introduction

In multi-agent systems, individuals within a group coordinate and interact to achieve a goal.
For instance, consider a basketball game where a team of players with different roles, such
as attack and defense, collaborate and interact to win the game. Each player performs a set
of individual actions, evolving based on their own dynamics. A group of players interact
to form a team. Actions of the team and its players are strongly correlated, and different
players have different inﬂuence on the team. Taking another example, in conversational
settings, some people seem particularly capable of driving the conversation and dominating
its outcome. These people, skilled at establishing the leadership, have the largest in ﬂuence
on the group decisions, and often shift the focus of the meeting when they speak [8].

In this paper, we quantitatively investigate the in ﬂuence of individual players on their team
using a dynamic Bayesian network, that we call two-level in ﬂuence model. The proposed
model explicitly learns the inﬂuence of individual player on the team with a two-level
structure. In the ﬁrst
level, we model actions of individual players. In the second one, we
model team actions as a whole. The model is then applied to determine (a) the in ﬂuence of
players in multi-player games, and (b) the in ﬂuence of participants in meetings.

The paper is organized as follows. Section 2 introduces the two-level in ﬂuence model.
Section 3 reviews related models. Section 4 presents results on multi-player games, and
Section 5 presents results on a meeting corpus. Section 6 provides concluding remarks.

individual player state
i S t 
i S  t+1 
i S  t-1 

   t-1

    t

     t+1

team state

G S  t-1 

G S t 

G S  t+1 

i O  t-1 
i O t 
observation
(a) 
Q=1

1 S

i O  t+1 

Q

2 S

Q=2

Q=N
N S

(c) 

player A

1 S  t-1 
 S

player B

2 S  t-1 
 S

G S

player C

3 S   t-1 
 S

1 S t 

2 S  t 

3 S  t 

1 S  t+1 

2 S  t+1 

3 S   t+1 

(b) 

Figure 1: (a) Markov Model for individual player.
(b) Two-level in ﬂuence model (for
simplicity, we omit the observation variables of individual Markov chains, and the switch-
ing parent variable Q). (c) Switching parents. Q is called a switching parent of S G , and
fS 1 (cid:1) (cid:1) (cid:1) SN g are conditional parents of S G . When Q = i, S i is the only parent of S G .

2 Two-level Inﬂuence Model

P (S; O)=

The proposed model, called two-level in ﬂuence model, is a dynamic Bayesian network
(DBN) with a two-level structure: the player level and the team level (Fig. 1). The player
level represents the actions of individual players, evolving based on their own Markovian
dynamics (Fig. 1 (a)). The team level represents group-level actions (the action belongs to
the team as a whole, not to a particular player). In Fig. 1 (b), the arrows up (from players to
team) represent the inﬂuence of the individual actions on the group actions, and the arrows
down (from team to players) represent the in ﬂuence of the group actions on the individual
actions. Let O i and S i denote the observation and state of the ith player respectively, and
SG denotes the team state. For N players, and observation sequences of identical length
T , the joint distribution of our model is given by
N
T
T
N
T
N
Y
Y
Y
Y
Y
Y
t jS 1
t(cid:0)1 ; SG
t jS i
P (S i
t (cid:1) (cid:1) (cid:1) SN
P (SG
t jS i
P (O i
P (S i
t(cid:0)1 ):
t )
t )
1 )
t=2
t=1
t=1
i=1
i=1
i=1
Regarding the player level, we model the actions of each individual with a ﬁrst-order
Markov model (Fig. 1 (a)) with one observation variable O i and one state variable S i .
Furthermore, to capture the dynamics of all the players interacting as a team, we add a
hidden variable S G (team state), which is responsible to model the group-level actions.
Different from individual player state that has its own Markovian dynamics, team state is
not directly inﬂuenced by its previous state . S G could be seen as the aggregate behav-
iors of the individuals, yet provides a useful level of description beyond individual actions.
There are two kinds of relationships between the team and players: (1) The team state at
time t inﬂuences
the players’ states at the next time (down arrow in Fig. 1 (b)). In other
words, the state of the ith player at time t + 1 depends on its previous state as well as on
t ). (2) The team state at time t is in ﬂuenced by all the
the team state, i.e., P (S i
t ; SG
t+1 jS i
players’ states at the current time (up arrow in Fig. 1 (b)), resulting in a conditional state
transition distribution P (S G
t ).
t jS 1
t (cid:1) (cid:1) (cid:1) SN
To reduce the model complexity, we add one hidden variable Q in the model, to switch
parents for S G . The idea of switching parent (also called Bayesian multi-nets in [3]) is as
follows: a variable -S G in this case- has a set of parents fQ; S 1 (cid:1) (cid:1) (cid:1) SN g (Fig. 1(c)). Q is
the switching parent that determines which of the other parents to use, conditioned on the
current value of the switching parent. fS 1 (cid:1) (cid:1) (cid:1) SN g are the conditional parents. In Fig. 1(c),
Q switches the parents of S G among fS 1 (cid:1) (cid:1) (cid:1) SN g, corresponding to the distribution
N
X
i=1

t ; Q = ijS 1
t (cid:1) (cid:1) (cid:1) SN
P (SG
t )

t jS 1
t (cid:1) (cid:1) (cid:1) SN
P (SG
t ) =

(1)

(2)

=

N
X
i=1

P (Q = ijS 1
t (cid:1) (cid:1) (cid:1) SN
t jS i
t )P (SG
t (cid:1) (cid:1) (cid:1) SN
t ; Q = i)

(3)

=

t jS i
(cid:11)iP (SG
t ):

t jS i
P (Q = i)P (SG
t ) =

N
N
X
X
i=1
i=1
From Eq. 3 to Eq. 4, we made two assumptions: (i) Q is independent of fS 1 (cid:1) (cid:1) (cid:1) SN g;
t . The distribution over the switching-parent
t only depends on S i
and (ii) when Q = i, S G
variable P (Q) essentially describes how much in ﬂuence or contribution the state transitions
of the player variables have on the state transitions of the team variable. We refer to (cid:11) i =
P (Q = i) as the inﬂuence value of the ith player. Obviously, PN
i=1 (cid:11)i = 1. If we further
assume that all player variables have the same number of states NS , and the team variable
has NG possible states, the joint log probability is given by

(4)

log P (S; O) =

NS
X
j=1

z i
j;1 (cid:1) log P (S i
1 = j )

+

{z
initial probability

}

T
X
t=1
|

N
X
i=1

NS
X
j=1

z i
j;t (cid:1) log P (O i
t jS i
t = j )

{z
emission probability

}

N
X
i=1
|
NS
X
j=1

g;

+

+

}

(5)

NS
X
k=1

NG
X
g=1

NS
X
k=1

NG
X
g=1

N
X
i=1

g ;t (cid:1) z i
zG
k;t (cid:1) logf

t = g jS i
(cid:11)iP (SG
t = k)

{z
group inf luence on individual transition

t(cid:0)1 = k ; SG
t = j jS i
g ;t(cid:0)1 (cid:1) log P (S i
k;t(cid:0)1 (cid:1) zG
j;t (cid:1) z i
z i
t(cid:0)1 = g)

T
X
t=2
|
N
T
X
X
t=1
i=1
|
{z
}
individual inf luence on group
where the indicator variable zj;t = 1 if St = j , otherwise zj;t = 0. We can see that the
S ). For T = 2000; NS = 10; NG = 5; N = 4, a
model has complexity O(T (cid:1) N (cid:1) NG (cid:1) N 2
total of 106 operations is required, which is still tractable.
For the model implementation, we used the Graphical Models Toolkit (GMTK) [4], a DBN
system for speech, language, and time series data. Speciﬁcally , we used the switching par-
ents feature of GMTK, which greatly facilitates the implementation of the two-level model
to learn the inﬂuence values using the Expectation Maximization (EM) algorithm. Since
EM has the problem of local maxima, good initialization is very important. To initialize
the emission probability distribution in Eq. 5, we ﬁrst
train individual action models (Fig.
1 (a)) by pooling all observation sequences together. Then we use the trained emission
distribution from the individual action model to initialize the emission distribution of the
two-level inﬂuence model.This procedure is beneﬁcial because we use data from all indi-
vidual streams together, and thus have a larger amount of training data for learning.

3 Related Models
The proposed two-level inﬂuence model is related to a number of models, namely mixed-
memory Markov model (MMM) [14, 11], coupled HMM (CHMM) [13], in ﬂuence model
[1, 2, 6] and dynamical systems trees (DSTs) [10]. MMMs decompose a complex model
into mixtures of simpler ones, for example, a K-order Markov model, into mixtures of ﬁrst-
order models: P (St jSt(cid:0)1St(cid:0)2 (cid:1) (cid:1) (cid:1) St(cid:0)K ) = PK
i=1 (cid:11)iP (St jSt(cid:0)i ). The CHMM models
interactions of multiple Markov chains by directly linking the current state of one stream
with the previous states of all the streams (including itself): P (S i
t(cid:0)1 ).
t(cid:0)1S 2
t jS 1
t(cid:0)1 (cid:1) (cid:1) (cid:1) SN
However, the model becomes computationally intractable for more than two streams. The
inﬂuence model [1, 2, 6] simpliﬁes
the state transition distribution of the CHMM into a

Figure 2: (a) A snapshot of the multi-player games: four players move along the pathes
labeled in the map. (b) A snapshot of four-participant meetings.

convex combination of pairwise conditional distributions, i.e., P (S i
t(cid:0)1S 2
t jS 1
t(cid:0)1 (cid:1) (cid:1) (cid:1) SN
t(cid:0)1 ) =
PN
t jS j
t(cid:0)1 ). We can see that in ﬂuence model and MMM take the same strategy
j=1 (cid:11)j iP (S i
to reduce complex models with large state spaces to a combination of simpler ones with
smaller state spaces. In [2, 6], the in ﬂuence model was used to analyze speaking patterns
in conversations (i.e., turn-taking) to determine how much in ﬂuence one participant has on
others. In such model, (cid:11)j i is regarded as the in ﬂuence of the j th player on the ith player.
All these models, however, limit themselves to modeling the interactions between individ-
ual players, i.e., the inﬂuence of one player on another player. The proposed two-level
inﬂuence model extends these models by using the group-level variable S G that allows
to model the inﬂuence between all the players and the team: P (S G
t jS 1
t S 2
t (cid:1) (cid:1) (cid:1) SN
t ) =
PN
t ), and additionally conditioning the dynamics of each player on the team
i=1 (cid:11)iP (SG
t jS i
state: P (S i
t ).
t ; SG
t+1 jS i
DSTs [10] have a tree structure that models interacting processes through the parent hidden
Markov chains. There are two differences between DSTs and our model: (1) In DSTs, the
parent chain has its own Markovian dynamics, while the team state of our model is not
directly inﬂuenced by the previous team state. Thus, our model captures the emergent
phenomena in which the group action is “nothing more”
than the aggregate behaviors of
individuals, yet it provides a useful level of representation beyond individual actions. (2)
The inﬂuence between players and team in our model is “bi-direction”
(up and down arrows
in Fig. 1(b)). In DSTs, the inﬂuence between child and parent chains is “uni-direction ”:
parent chains could inﬂuence
their
child chains, while child chains could not in ﬂuence
parent chains.

4 Experiments on Synthetic Data

We ﬁrst
test our model on multi-player synthetic games, in which four players (labeled
A-D) move along a number of predetermined paths manually labeled in a map (Fig. 2(a)),
based on the following rules:
(cid:15) Game I: Player A moves randomly. Player B and C are meticulously following
player A. Player D moves randomly.
(cid:15) Game II: Player A moves randomly. Player B is meticulously following player
A. Player C moves randomly. Player D is meticulously following player C .
(cid:15) Game III: All four players, A, B , C and D , move randomly.
A follower moves randomly until it lies on the same path of its target, and after that it tries
to reach the target by following the target’s direction. The initial positions and speeds of
players are randomly generated. The observation of an individual player is its motion tra-
jectory in the form of a sequence of positions, (x1 ; y1 ); (x2 ; y2 ) (cid:1) (cid:1) (cid:1) (xt ; yt ), each of which
belongs to one of 20 predetermined paths in the map. Therefore, we set NS = 20. The
number of team states is set to NG = 5. In experiments, we found that the ﬁnal
results
were not sensitive to the speciﬁc number of team states for this dataset in a wide range.
The length of each game sequence is T = 2000 frames. EM iterations were stopped once

e
u
l
a
V
 
e
c
n
e
u
l
f
n
I

1

0.8

0.6

0.4

0.2

0

Game I

Game II

Game III

Player A
Player B
Player C
Player D

10

20
EM Iterations

30

e
u
l
a
V
 
e
c
n
e
u
l
f
n
I

1

0.8

0.6

0.4

0.2

0

Player A
Player B
Player C
Player D

20

40
EM Iterations

60

e
u
l
a
V
 
e
c
n
e
u
l
f
n
I

1

0.8

0.6

0.4

0.2

0

Player A
Player B
Player C
Player D

20

40
EM Iterations

60

Figure 3: Inﬂuence values with respect to the EM iterations in different games.

the relative difference in the global log likelihood was less than 2%.

Fig. 3 shows the learned inﬂuence value for each of the four players in the different games
with respect to the number of EM iterations. We can see that for Game I, player A is the
leader player based on the deﬁned rules. The ﬁnal
learned in ﬂuence value for player A is
almost 1, while the inﬂuence for the rest three players are almost 0. For Game II, player
A and player C are both leaders based on the deﬁned rules. The learned in ﬂuence values
for player A and C are indeed close to 0:5, which indicates they have similar in ﬂuence on
the team. For Game III, the four players are moving randomly, and the learned in ﬂuence
values are around 0:25, which indicates that all players have similar in ﬂuence on the team.
The results on these toy data suggest that our model is capable of learning sensible values
for f(cid:11)i g, in good agreement with the concept of in ﬂuence we have described before.

5 Experiments on Meeting Data

As an application of the two-level in ﬂuence model, we investigate the in ﬂuence of partici-
pants in meetings. Status, dominance, and in ﬂuence are important concepts in social psy-
chology for which our model could be particularly suitable in a (dynamic) conversational
setting [8]. We used a public meeting corpus (available at http://mmm.idiap.ch),
which consists of 30 ﬁ ve-minute four-participant meetings collected in a room equipped
with synchronized multi-channel audio and video recorders [12]. A snapshot of the meet-
ing is shown in Fig. 2 (b). These meetings have pre-deﬁned topics and an action agenda,
designed to ensure discussions and monologues. Manual speech transcripts are also avail-
able. We ﬁrst describe how we manually collected in ﬂuence judgements, and the perfor-
mance measure we used. We then report our results using audio and language features,
compared with simple baseline methods.

5.1 Manually Labeling Inﬂuence Values and the Performance Measure

The manual annotation of inﬂuence of meeting participants is to some degree a subjective
task, as a deﬁnite ground-truth does not exist. In our case, each meeting was labeled by
three independent annotators who had no access to any information about the participants
(e.g. job titles and names). This was enforced to avoid any bias based on prior knowledge
of the meeting participants (e.g. a student would probably assign a large in ﬂuence value to
his supervisor). After watching an entire meeting, the three annotators were asked to assign
a probability-based value (ranging from 0 to 1, all adding up to 1) to meeting participants,
which indicated their inﬂuence in the meeting (Fig. 5(b-d)). From the three annotations, we
computed the pairwise Kappa statistics [7], a commonly used measure for inter-rate agree-
ment. The obtained pairwise Kappa ranges between 0:68 and 0:72, which demonstrates a
good agreement among the different annotators. We estimated the ground-truth in ﬂuence
values by averaging the results from the three annotators (Fig. 5(a)).

We use Kullback-Leibler (KL) divergence to evaluate the results. For the j th meet-
distribution ~P (Q), and the ground
ing, given an automatically determined in ﬂuence
the KL divergence is given by: D j ( ~P kP ) =
truth inﬂuence
distribution P (Q),

silence

speaking

person A 
    audio 
 0011100001111100111111000
language    
 0022200003333300444444000

person B 
 0000001100000011000000111
    audio 
language    
 0000002200000033000000444

timeline

timeline

Figure 4: Illustration of state sequences using audio and language features respectively:
Using audio, there are two states: speaking and silence. Using language, the number of
states equals PLSA topics plus one silence state.

~P (Q=i)
PN
~P (Q = i) log2
P (Q=i) , where N is the number of participants. The smaller D j , the
i=1
better the performance (if ~P = P ) Dj = 0). Note that KL divergence is not symmetric.
M PM
j=1 Dj ( ~P kP ),
We calculate the average KL divergence for all the meetings: D = 1
where M is the number of meetings.

5.2 Audio and Language Features

We ﬁrst extract audio features useful to detect speaking turns in conversations. We com-
pute the SRP-PHAT measure using the signals from a 8-microphone array [12], which is
a continuous value indicating the speech activity from a particular participant. We use a
Gaussian emission probability, and set NS = 2, each state corresponding to speaking and
non-speaking (silence), respectively (Fig. 4).

Additionally, language features were extracted from manual transcripts. After removing
stop words, the meeting corpus contains 2175 unique terms. We then employed proba-
bilistic latent semantic analysis (PLSA) [9], which is a language model that projects doc-
uments in the high-dimensional bag-of-words space into a topic-based space of lower di-
mension. Each dimension in this new space represents a “topic”,
and each document is
represented as a mixture of topics. In our case, a document corresponds to one speech ut-
terance (ts ; te ; w1w2 (cid:1) (cid:1) (cid:1) wk ), where ts is the start time, te is the end time, and w1w2 (cid:1) (cid:1) (cid:1) wk
is a sequence of words. PLSA is thus used as a feature extractor that could potentially
capture “topic turns”
in meetings.

We embedded PLSA into our model by treating the states of individual players as instances
of PLSA topics (similar to [5]). Therefore, the PLSA model determines the emission prob-
ability in Eq. 5. We repeat the PLSA topic within the same utterance (ts (cid:20) t (cid:20) te ). The
topic for the silence segments was set to 0 (Fig. 4). We can see that using audio-only fea-
tures can be seen as a special case of using language features, by using only one topic in
the PLSA model (i.e., all utterances belong to the same topic). We set 10 topics in PLSA
(NS = 10), and set NG = 5 using simple reasonable a priori knowledge. EM iterations
were stopped once the relative difference in the global log likelihood was less than 2%.

5.3 Results and Discussions

We compare our model with a method based on the speaking length (how much time each
of the participants speaks). In this case, the in ﬂuence value of a meeting participant is
deﬁned to be proportional to his speaking length: P (Q = i) = Li = PN
i=1 Li , where Li is
the speaking length of participant i. As a second baseline model, we randomly generated
1000 combinations of inﬂuence values (under the constraint that the sum of the four values
equals 1), and report the average performance.

The results are shown in Table 1 (left) and Fig. 5(e-h). We can see that the results of the
three methods: model + language, model + audio, and speaking-length (Fig. 5 (e-g)) are
signiﬁcantly better than the result of randomization (Fig. 5 (h)). Using language features

2

4

2

4

2

4

2

4

5

10

15

20

25

30

5

10

15

20

25

30

5

10

15

20

25

30

5

10

15

20

25

30

1

0.5

0
(a)
1

0.5

0
(c)
1

0.5

0
(e)

1

0.5

0
(g)

2

4

2

4

2

4

2

4

5

10

15

20

25

30

5

10

15

20

25

30

5

10

15

20

25

30

5

10

15

20

25

30

1

0.5

0
(b)
1

0.5

0
(d)
1

0.5

0
(f)
1

0.5

0
(h)

Figure 5: Inﬂuence values of the 4 participants (y-axis) in the 30 meetings (x-axis) (a)
ground-truth (average of the three human annotations: A1 ; A2 ; A3 ). (b) A1 : human anno-
tation 1 (c) A2 : human annotation 2 (d) A3 : human annotation 3 (e) our model + language
(f) our model + audio (g) speaking-length (h) randomization.

Table 1: Results on meetings (“model ”
KL divergence
Method
0.106
model + Language
0.135
model + Audio
0.226
Speaking length
Randomization
0.863

denotes the two-level in ﬂuence model).
Human Annotation KL divergence
0.090
Ai vs. Aj
0.053
Ai vs. Ai
Ai vs. GT
0.037

with our model achieves the best performance. Our model (using either audio or language
features) outperforms the speaking-length based method, which suggests that the learned
inﬂuence distributions are in better accordance with the in ﬂuence distributions from human
judgements. As shown in Fig. 4, using audio features can be seen as a special case of using
language features. We use language features to capture “topic turns” by factorizing the two
states: “speaking, silence”
into more states: “topic1,
topic2, ..., silence”. We can see that
the result using language features is better than that using audio features. In other words,
compared with “speaking turns”,
“topic turns”
improves the performance of our model to
learn the inﬂuence of participants in meetings.

It is interesting to look at the KL divergence between any pair of the three human anno-
tations (Ai vs. Aj ), any one against the average of the others (Ai vs. Ai ), and any one
against the ground-truth (Ai vs. GT). The average results are shown in Table 1 (right).
We can see that the result of “ Ai vs. GT ”
is the best, which is reasonable since “GT ”
is
the average of A1 , A2 , and A3 . Fig. 6(a) shows the histogram of KL divergence between
any pair of human annotations for the 30 meetings. The histogram has a distribution of
(cid:22) = 0:09; (cid:27) = 0:11. We can see that the results of our model (language: 0:106, audio:
0:135) are very close to the mean ((cid:22) = 0:09), which indicates that our model is comparable
to human performance.

With our model, we can calculate the cumulative in ﬂuence of each meeting participant over
time. Fig. 6(b) shows such an example using the two-level in ﬂuence model with audio
features. We can see that the cumulative in ﬂuence is related to the meeting agenda: The
meeting starts with the monologue of person1 (monologue1). The in ﬂuence of person1 is
almost 1, while the inﬂuences of the other persons are nearly 0. When four participants are

0.18

0.15

0.12

0.09

0.06

0.03

0
0

e
u
l
a
V
 
e
c
n
e
u
l
f
n
I

1

0.8

0.6

0.4

0.2

0

Person1
Person2
Person3
Person4

discussion

1
e
u
g
o
l
o
n
o
m

n
o
i
s
s
u
c
s
i
d

4
e
u
g
o
l
o
n
o
m

1

2
3
Time (min.)

4

5

(b)

0.1

0.2
0.4
0.3
KL divergence

0.5

0.6

(a)

Figure 6: (a) Histogram of KL divergence between any pair of the human annotations
(Ai vs. Aj ) for the 30 meetings. (b) The evolution of cumulative in ﬂuence over time (5
minutes). The dotted vertical lines indicate the predeﬁned meeting agenda.

involved in a discussion, the inﬂuence of person1 decreases, and the in ﬂuences of the other
three persons increase. The inﬂuence of person4 increases quickly during monologue4.
The ﬁnal
inﬂuence of participants becomes stable in the second discussion.

6 Conclusions
We have presented a two-level inﬂuence model that learns the in ﬂuence of all players within
a team. The model has a two-level structure: individual-level and group-level. Individual
level models actions of individual players and group-level models the group as a whole.
Experiments on synthetic multi-player games and a multi-party meeting corpus showed the
effectiveness of the proposed model. More generally, we anticipate that our approach to
multi-level inﬂuence modeling may provide a means for analyzing a wide range of social
dynamics to infer patterns of emergent group behaviors.

Acknowledgements
This work was supported by the Swiss National Center of Competence in Research on Interactive
Multimodal Information Management (IM2), and the EC project AMI (Augmented Multi-Party In-
teraction) (pub. AMI-124). We thank Florent Monay (IDIAP) and Jeff Bilmes (University of Wash-
ington) for sharing PLSA code and the GMTK. We also thank the annotators for their efforts.
References
[1] C. Asavathiratham. The inﬂuence model: A tractable representation for the dynamics of net-
worked markov chains. Ph.D. dissertation, Dept. of EECS, MIT, Cambridge, 2000.
[2] S. Basu, T. Choudhury, B. Clarkson, and A. Pentland. Learning human interactions with the
inﬂuence model. MIT Media Laboratory Technical Note No. 539, 2001.
[3] J. Bilmes. Dynamic bayesian multinets. In Uncertainty in Artiﬁcial
Intelligence, 2000.
[4] J. Bilmes and G. Zweig. The graphical models toolkit: An open source software system for
speech and time series processing. Proc. ICASSP, vol. 4:3916 –3919, 2002.
[5] D. Blei and P. Moreno. Topic segmentation with an aspect hidden markov model. Proc. of ACM
SIGIR conference on Research and development in information retrieval, pages 343–348, 2001.
[6] T. Choudhury and S. Basu. Modeling conversational dynamics as a mixed memory markov
process. Proc. of Intl. Conference on Neural Information and Processing Systems (NIPS), 2004.
[7] J.A. Cohen. A coefﬁcient of agreement for nominal scales. Educ Psych Meas, 20:37–46, 1960.
[8] S. L. Ellyson and J. F. Dovidio, editors. Power, Dominance, and Nonverbal Behavior. Springer-
Verlag., 1985.
[9] T. Hofmann. Unsupervised learning by probabilistic latent semantic analysis.
Learning, 42:177–196 , 2001.
[10] A. Howard and T. Jebara. Dynamical systems trees. In Uncertainty in Artiﬁcial
Intelligence’01.
[11] K. Kirchhoff, S. Parandekar, and J. Bilmes. Mixed-memory markov models for automatic
language identiﬁcation.
IEEE Int. Conf. on Acoustics, Speech, and Signal Processing, 2000.
[12] I. McCowan, D. Gatica-Perez, S. Bengio, G. Lathoud, M. Barnard, and D. Zhang. Automatic
analysis of multimodal group actions in meetings.
In IEEE Transactions on PAMI, volume
27(3), 2005.
[13] N. Oliver, B. Rosario, and A. Pentland. Graphical models for recognizing human interactions.
Proc. of Intl. Conference on Neural Information and Processing Systems (NIPS), 1998.
[14] L. K. Saul and M. I. Jordan. Mixed memory markov models: Decomposing complex stochastic
processes as mixtures of simpler ones. Machine Learning, 37(1):75–87, 1999.

In Machine

