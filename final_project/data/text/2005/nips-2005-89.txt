Fixing two weaknesses of the Spectral Method

Kevin J. Lang
Yahoo Research
3333 Empire Ave, Burbank, CA 91504
langk@yahoo-inc.com

Abstract

We discuss two intrinsic weaknesses of the spectral graph partitioning
method, both of which have practical consequences. The ﬁrst
is that
spectral embeddings tend to hide the best cuts from the commonly used
hyperplane rounding method. Rather than cleaning up the resulting sub-
optimal cuts with local search, we recommend the adoption of ﬂo w-based
rounding. The second weakness is that for many “po wer law” graphs, the
spectral method produces cuts that are highly unbalanced, thus decreas-
ing the usefulness of the method for visualization (see ﬁgure 4(b)) or
as a basis for divide-and-conquer algorithms. These balance problems,
which occur even though the spectral method’s quotient-style objective
function does encourage balance, can be ﬁx ed with a stricter balance con-
straint that turns the spectral mathematical program into an SDP that can
be solved for million-node graphs by a method of Burer and Monteiro.

1 Background

Graph partitioning is the NP-hard problem of ﬁnding a small graph cut subject to the con-
straint that neither side of the resulting partitioning of the nodes is “too small ”. We will be
dealing with several versions: the graph bisection problem, which requires perfect 1
2 : 1
2
3 ), which requires at least
balance; the (cid:12) -balanced cut problem (with (cid:12) a fraction such as 1
(cid:12) : (1 (cid:0) (cid:12) ) balance; and the quotient cut problem, which requires the small side to be large
enough to “pay for”
the edges in the cut. The quotient cut metric is c= min(a; b), where c
is the cutsize and a and b are the sizes of the two sides of the cut. All of the well-known
variants of the quotient cut metric (e.g. normalized cut [15]) have similar behavior with
respect to the issues discussed in this paper.

The spectral method for graph partitioning was introduced in 1973 by Fiedler and Donath
& Hoffman [6]. In the mid-1980’s Alon & Milman [1] proved that spectral cuts can be at
worst quadratically bad; in the mid 1990’s Guattery & Miller [10] proved that this analysis
is tight by exhibiting a family of n-node graphs whose spectral bisections cut O(n2=3 )
edges versus the optimal O(n1=3 ) edges. On the other hand, Spielman & Teng [16] have
proved stronger performance guarantees for the special case of spacelike graphs.

The spectral method can be derived by relaxing a quadratic integer program which encodes
the graph bisection problem (see section 3.1). The solution to this relaxation is the “Fiedler
vector”, or second smallest eigenvector of the graph’s discrete Laplacian matrix, whose
elements xi can be interpreted as an embedding of the graph on the line. To obtain a

(A) Graph with nearly balanced 8-cut

(B) Spectral Embedding

(C) Notional Flow-based Embedding

Figure 1: The spectral embedding hides the best solution from hyperplane rounding.

speciﬁc
to this embedding. The hyperplane
cut, one must apply a “rounding method”
rounding method chooses one of the n (cid:0) 1 cuts which separate the nodes whose x i values
lie above and below some split value ^x.

2 Using ﬂo w to ﬁnd cuts that are hidden from hyperplane rounding

Theorists have long known that the spectral method cannot distinguish between deep cuts
and long paths, and that this confusion can cause it to cut a graph in the wrong direction
thereby producing the spectral method’s worst-case behavior [10]. In this section we will
show by example that even when the spectral method is not fooled into cutting in the wrong
direction, the resulting embedding can hide the best cuts from the hyperplane rounding
method. This is a possible explanation for the frequently made empirical observation (see
e.g. [12]) that hyperplane roundings of spectral embeddings are noisy and therefore beneﬁt
from cleanup with a local search method such as Fiduccia-Matheyses [8].

Consider the graph in ﬁgure 1(a), which has a near-bisection cutting 8 edges. For this graph
the spectral method produces the embedding shown in ﬁgure 1(b), and recommends that we
make a vertical cut (across the horizontal dimension which is based on the Fiedler vector).
This is correct in a generalized sense, but it is obvious that no hyperplane (or vertical line
in this picture) can possibly extract the optimal 8-edge cut.

Some insight into why spectral embeddings tend to have this problem can be obtained
from the spectral method’s electrical interpretation. In this view the graph is represented
by a resistor network [7]. Current ﬂo wing in this network causes voltage drops across the
resistors, thus determining the nodes’ voltages and hence their positions. When current
ﬂo ws through a long series of resistors, it induces a progressive voltage drop. This is what
causes the excessive length of the embeddings of the horizontal girder-like structures which
are blocking all vertical hyperplane cuts in ﬁgure 1(b).

If the embedding method were somehow not based on current, but rather on ﬂo w, which
does not distinguish between a pipe and a series of pipes, then the long girders could retract
into the two sides of the embedding, as suggested by ﬁgure 1(c), and the best cut would
be revealed. Because theoretical ﬂo w-like embedding methods such as [14] are currently
not practical, we point out that in cases like ﬁgure 1(b), where the spectral method has not
chosen an incorrect direction for the cut, one can use an S-T max ﬂo w problem with the
ﬂo w running in the recommended direction (horizontally for this embedding) to extract the
good cut even though it is hidden from all hyperplanes.

We currently use two different ﬂo w-based rounding methods. A method called MQI looks
for quotient cuts, and is already described in [13]. Another method, that we shall call Mid-
ﬂo w, looks for (cid:12) -balanced cuts. The input to Midﬂo w is a graph and an ordering of its
nodes (obtained e.g. from a spectral embedding or from the projection of any embedding
onto a line). We divide the graph’s nodes into 3 sets F, L, and U. The sets F and L respec-
tively contain the ﬁrst (cid:12)n and last (cid:12)n nodes in the ordering, and U contains the remaining

)
e
d
i
s
 
l
l
a
m
s
 
f
o
 
e
z
i
s
 
/
 
e
z
i
s
t
u
c
(
 
 
e
r
o
c
s
 
t
u
c
 
t
n
e
i
t
o
u
q

 0.01

 0.004

 0.003

 0.002

e
c
n
a
l
a
b
 
0
5
-
0
5

t
i
l
p
s
 
s
o
p
-
g
e
n

r

c t o

e

r   v

d l e

Hyperplane roundings   o f   F i e

0.00268
0.00232

Best hyperplane rounding of Fiedler Vector
Best improvement with local search

0.00138 Midflow
rounding
beta = 1/4

0.00145 Midflow rounding of Fiedler Vector
beta = 1/3

 0.001
 60000

 80000

 100000
 200000
 180000
 160000
 140000
 120000
number of nodes on ’left’ side of cut  (out of 324800)

 220000

 240000

Figure 2: A typical example (see section 2.1) where ﬂo w-based rounding beats hyperplane
rounding, even when the hyperplane cuts are improved with Fiduccia-Matheyses search.
Note that for this spacelike graph, the best quotient cuts have reasonably good balance.

U = n (cid:0) 2(cid:12)n nodes, which are “up for grabs”. We set up an S-T max ﬂo w problem with
one node for every graph node plus 2 new nodes for the source and sink. For each graph
edge there are two arcs, one in each direction, with unit capacity. Finally, the nodes in F are
pinned to the source and the nodes in L are pinned to sink by in ﬁnite capacity arcs. This
max-ﬂo w problem can be solved by a good implementation of the push-relabel algorithm
(such as Goldberg and Cherkassky’s hi pr [4]) in time that empirically is nearly linear
with a very good constant factor. Figure 6 shows that solving a MidFlow problem with
hi pr can be 1000 times cheaper than ﬁnding a spectral embedding with ARPACK.

When the goal is ﬁnding good (cid:12) -balanced cuts, MidFlow rounding is strictly more powerful
than hyperplane rounding; from a given node ordering hyperplane rounding chooses the
best of U + 1 candidate cuts, while MidFlow rounding chooses the best of 2U candidates,
including all of those considered by hyperplane rounding. [Similarly, MQI rounding is
strictly more powerful than hyperplane rounding for the task of ﬁnding good quotient cuts.]

2.1 A concrete example

The plot in ﬁgure 2 shows a number of cuts in a 324,800 node nearly planar graph derived
from a 700x464 pixel downward-looking view of some clouds over some mountains.1 The
y-axis of the plot is quotient cut score; smaller values are better. We note in passing that
the commonly used split point ^x = 0 does not yield the best hyperplane cut. Our main
point is that the two cuts generated by MidFlow rounding of the Fiedler vector (with (cid:12) = 1
3
and (cid:12) = 1
4 ) are nearly twice as good as the best hyperplane cut. Even after the best
hyperplane cut has been improved by taking the best result of 100 runs of a version of
Fiduccia-Matheyses local search, it is still much worse than the cuts obtained by ﬂo w-
based rounding.

1The graph’s edges are unweighted but are chosen by a randomized rule which is more likely to
include an edge between two neighboring pixels if they have a similar grey value. Good cuts in the
graph tend to run along discontinuities in the image, as one would expect.

 1

q
u
o
t
i
e
n
t
 
c
u
t
 
s
c
o
r
e
 
 
 
 
 
 
(
s
m
a
l
l
e
 0.1
r
 
i
s
 
b
e
t
t
e
r
)

SDP-LB

Scatter plot showing cuts in a
"power-law graph" (Yahoo Groups)

 10
 100
(worse balance)

 1k
 10k
size of small side

 100k
 1M
(better balance)

Figure 3: This scatter plot of cuts in a 1.6 million node collaborative ﬁltering graph shows
a surprising relationship between cut quality and balance (see section 3). The SDP lower
bound proves that all balanced cuts are worse than the unbalanced cuts seen on the left.

2.2 Effectiveness on real graphs and benchmarks

We have found the ﬂo w-based Midﬂo w and MQI rounding methods to be highly ef-
fective in practice on diverse classes of graphs including space-like graphs and power
law graphs. Results for real-world power law graphs are shown in ﬁgure 5. Results
for a number of FE meshes can be found on the Graph Partitioning Archive website
http://staffweb.cms.gre.ac.uk/ ˜c.walshaw/partition , which keeps
track of the best nearly balanced cuts ever found for a number of classic bench-
marks. Using ﬂo w-based rounding to extract cuts from spectral-type embeddings,
we have found new record cuts for the majority of the largest graphs on the site,
including fe body, t60k, wing, brack2, fe tooth, fe rotor, 598a,
144, wave, m14b, and auto. It is interesting to note that the spectral method previ-
ously did not own any of the records for these classic benchmarks, although it could have
if ﬂo w-based rounding had been used instead of hyperplane rounding.

3 Finding balanced cuts in “po wer law” graphs

The spectral method does not require cuts to have perfect balance, but the denominator in
its quotient-style objective function does reward balance and punish imbalance. Thus one
might expect the spectral method to produce cuts with fairly good balance, and this is what
does happen for the class of spacelike graphs that inform much of our intuition.

However, there are now many economically important “po wer law”
[5] graphs whose best
quotient cuts have extremely bad balance. Examples at Yahoo include the web graph, social
graphs based on DLBP co-authorship and Yahoo IM buddy lists, a music similarity graph,
and bipartite collaborative ﬁltering graphs relating Yahoo Groups with users, and advertis-
ers with search phrases. To save space we show one scatter plot (ﬁgure 3) of quotient cut
scores versus balance that is typical for graphs from this class. We see that apparently there
is a tradeoff between these two quantities, and in fact the quotient cut score gets better as

Figure 4: Left: a social graph with octopus structure as predicted by Chung and Lu [5].
Center: a “normalized cut” Spectral embedding chops off one tentacle per dimension.
Right: an SDP embedding looks better and is more useful for ﬁnding balanced cuts.

balance gets worse, which is exactly the opposite of what one would expect.

When run on graphs of this type, the spectral method (and other quotient cut methods such
as Metis+MQI [13]) wants to chop off tiny pieces. This has at least two bad practical
effects. First, cutting off a tiny piece after paying for a computation on the whole graph
kills the scalability of divide and conquer algorithms by causing their overall run time to
increase e.g. from n log n to n2 . Second, low-dimensional spectral embeddings of these
graphs (see e.g. ﬁgure 4(b) are nearly useless for visualization, and are also very poor
inputs for clustering schemes that use a small number of eigenvectors.

These problems can be avoided by solving a semideﬁnite relaxation of graph bisection that
has a much stronger balance constraint. This SDP (explained in the next section) has a
long history, with connections to papers going all the way back to Donath and Hoffman
[6] (via the concept of “eigen value optimization”).
In 2004, Arora, Rao, and Vazirani [14]
proved the best-ever approximation guarantee for graph partitioning by analysing a version
of this SDP which was augmented with certain triangle inequalities that serve much the
same purpose as ﬂo w (but which are too expensive to solve for large graphs).

3.1 A semideﬁnite program which strengthens the balance requirement

The graph bisection problem can be expressed as a Quadratic Integer Program as follows.
There is an n-element column vector x of indicator variables xi , each of which assigns one
node to a particular side of the cut by assuming a value from the set f(cid:0)1; 1g. With these
4 xT Lx (where L is the graph’s discrete Laplacian
indicator values, the objective function 1
matrix) works out to be equal to the number of edges crossing the cut. Finally, the require-
ment of perfect balance is expressed by the constraint xT e = 0, where e is a vector of all
ones. Since this QIP exactly encodes the graph bisection problem, solving it is NP-hard.

The spectral relaxation of this QIP attains solvability by allowing the indicator variables to
assume arbitrary real values, provided that their average squared magnitude is 1.0. After
this change, the objective function 1
4 xT Lx is now just a lower bound on the cutsize. More
interestingly for the present discussion, the balance contraint xT e = 0 now permits a
qualitatively different kind of balance where a tiny group of nodes moves a long way out
from the origin where the nodes acquire enough leverage to counterbalance everyone else.
For graphs where the best quotient cut has good balance (e.g. meshes) this does not actually
happen, but for graphs whose best quotient cut has bad balance, it does happen, as can be
seen in ﬁgure 4(b).

These undesired solutions could be ruled out by requiring the squared magnitudes of the
indicator values to be 1.0 individually instead of on average. However, in one dimension
that would require picking values from the set f(cid:0)1; 1g, which would once again cause the
problem to be NP-hard. Fortunately, there is a way to escape from this dilemma which was
brought to the attention of the CS community by the Max Cut algorithm of Goemans and
Williamson [9]: if we allow the indicator variables to assume values that are r-dimensional
unit vectors for some sufﬁciently large r ,2 then the program is solvable even with the strict
requirement that every vector has squared length 1.0. After a small change of notation to
reﬂect
the fact that the collected indicator variables now form an n by r matrix X rather
than a vector, this idea results in the nonlinear program

min (cid:26) 1
4

L (cid:15) (XX T ) : diag(XX T ) = e; eT (XX T )e = 0(cid:27)

which becomes an SDP by a change of variables from XX T to the “Gram matrix ” G:

min (cid:26) 1
4

L (cid:15) G : diag(G) = e; eT Ge = 0; G (cid:23) 0(cid:27)

(1)

(2)

The added constraint G (cid:23) 0 requires G to be positive semideﬁnite, so that it can be factored
to get back to the desired matrix of indicator vectors X .

3.2 Methods for solving the SDP for large graphs

Interior point methods cannot solve (2) for graphs with more than a few thousand nodes,
but newer methods achieve better scaling by ensuring that all dense n by n matrices have
only an implicit (and approximate) existence. A good example is Helmberg and Rendl’s
program SBmethod [11], which can solve the dual of (2) for graphs with about 50,000
nodes by converting it to an equivalent “eigen value optimization” problem. The output of
SBmethod is a low-rank approximate spectral factorization of the Gram matrix, consisting
of an estimated rank r , plus an n by r matrix X whose rows are the nodes’ indicator
vectors. SBmethod typically produces r-values that are much smaller than n or even
p2n. Moreover they seem to match the true dimensionality of simple spacelike graphs.
For example, for a 3-d mesh we get r = 4, which is 3 dimensions for the manifold plus one
more dimension for the hypersphere that it is wrapped around.

Burer and Monteiro’s direct low-rank solver SDP-LR scales even better [2]. Surprisingly,
their approach is to essentially forget about the SDP (2) and instead use non-linear pro-
gramming techniques to solve (1). Speciﬁcally , they use an augmented Lagrangian ap-
proach to move the constraints into the objective function, which they then minimize using
limited memory BFGS. A follow-up paper [3] provides a theoretical explanation of why
the method does not fall into bad local minima despite the apparent non-convexity of (1).
We have successfully run Burer and Monteiro’s code on large graphs containing more than
a million nodes. We typically run it several times with different small ﬁx ed values of r ,
and then choose the smallest r which allows the objective function to reach its best known
value. On medium-size graphs this produces estimates for r which are in rough agreement
with those produced by SBmethod. The run time scaling of SDP-LR is compared with
that of ARPACK and hi pr in ﬁgure 6.

2 In the original work r = n, but there are theoretical reasons for believing that r (cid:24)
enough [3], plus there is empirical evidence that much smaller values work in practice.

p2n is big

 0.3

 0.25

 0.2

 0.15

 0.1

 0.05

)
r
e
t
t
e
b
 
s
i
 
r
e
l
l
a
m
s
(
 
e
r
o
c
s
 
t
u
c
 
t
n
e
i
t
o
u
q

s

e

n

e r p l a

p

y

c tr a l  +   H

e

p

S

SDP + Hyperplanes

SDP + Flow

Social Graph
(DBLP Coauthorship)

 0
 10k
(worse balance)

 20k

 30k
 40k
size of small side

 50k

 60k
 70k
(better balance)

e
r
o
c
s
 
t
u
c
 
t
n
e
i
t
o
u
q

 1.6

 1.4

 1.2

 1

 0.8

 0.6

 0.4

 0.2

 0

Spectral + Hyperplanes

SDP + Hyperplanes

SDP + Flow

 0

40k
10k
(worse balance)

90k

Bipartite Graph
(Yahoo Groups vs Users)
160k 250k 360k 490k 640k 810k
1M
(better balance)
size of small side

 1

 0.8

 0.6

 0.4

 0.2

e
r
o
c
s
 
t
u
c
 
t
n
e
i
t
o
u
q

 0

 0

 0.04

 0.035

 0.03

 0.025

 0.02

 0.015

 0.01

 0.005

e
r
o
c
s
 
t
u
c
 
t
n
e
i
t
o
u
q

s

e

n

p l a

r

e

p

a l   +   H y

c t r

e

S p

SDP + Hyperplanes

SDP + Flow

Social Graph
(Yahoo Instant Messenger)
 100k  200k  300k  400k  500k  600k  700k  800k  900k
 1M
(better balance)
(worse balance)
size of small side

l
a
r
t
c
e
p
S

 0
 200k
 100k
(worse balance)

 300k
 500k
 400k
size of small side

SDP

D

P   +  Flo w
S
Web Graph
(TREC WT10G)
 600k
 800k
 700k
(better balance)

Figure 5: Each of these four plots contains two lines showing the results of sweeping a hy-
perplane through a spectral embedding and through one dimension of an SDP embedding.
In all four cases, the spectral line is lower on the left, and the SDP line is lower on the right,
which means that Spectral produces better unbalanced cuts and the SDP produces better
balanced cuts. Cuts obtained by rounding random 1-d projections of the SDP embedding
using Midﬂo w (to produce (cid:12) -balanced cuts) followed by MQI (to improve the quotient cut
score) are also shown; these ﬂo w-based cuts are consistently better than hyperplane cuts.

3.3 Results

We have used the minbis program from Burer and Monteiro’s SDP-LR v0.130301
package (with r < 10) to approximately solve (1) for several large graphs including: a
130,000 node social graph representing co-authorship in DBLP; a 1.9 million node social
graph built from the buddy lists of a subset of the users of Yahoo Instant Messenger; a
1.6 million node bipartite graph relating Yahoo Groups and users; and a 1.5 million node
graph made by symmetrizing the TREC WT10G web graph. It is clear from ﬁgure 5 that
in all four cases the SDP embedding leads to better balanced cuts, and that ﬂo w-based
rounding works better hyperplane rounding. Also, ﬁgures 4(b) and 4(c) show 3-d Spectral
and SDP embeddings of a small subset of the Yahoo IM social graph; the SDP embedding
is qualitatively different and arguably better for visualization purposes.

Acknowledgments

We thank Satish Rao for many useful discussions.

References

[1] N. Alon and V.D. Milman. (cid:21)1 , isoperimetric inequalities for graphs, and superconcentrators.
Journal of Combinatorial Theory, Series B, 38:73–88, 1985.

