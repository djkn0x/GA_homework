Localization in Ad-Hoc Sensor Network: A
Machine Learning Based Approach
Vineet Abhishek, CS229 Project Report, Fall 2005

1

Abstract — We present a new approach to Ad-Hoc sensor net-
work localization from pairwise received signal strength (RSSI).
Localization problem is viewed as a classiﬁcation problem. We
map the output of Support Vector Machine (SVM) to probability
and present various schemes for estimating nodes’ locations from
it. We show that application of Laplace Eigenmaps followed by
an appropriate Afﬁne Transformation gives a good esitmate of
nodes’ position.

Index Terms — Support Vector Machine (SVM), Radio Signal
Strength Indicator (RSSI)

I . IN TRODUC T ION
I N a wireless sensor network,
the data collected from
different sensor nodes needs to be correlated together for a
meaningful interpretation and application. This often requires
relating sensor data to its physical location. Localization form
the very ﬁrst step in the sensor network based applications.
The majority of the localization algorithms use information
such as time of arrival of signal, angle of arrival of signal
(using directional antennas) or RSSI measurements for lo-
calization. Typically, RSSI is not the most accurate indicator
for device location as it can be subject to various multi-path
and fading effects, which may also be varying randomly over
time. The other parameters like the angle of arrival and timing
based indicators provide more accurate observations relating
to the location of the node. However, they require a dedicated
hardware co-located with the sensor node for logging and
providing this information. In case of RSSI, the information
is already available to the sensor node and no extra hardware
is required. This is particularly useful for energy constraint
nodes.
The traditional localization approach use range estimate
as the ﬁrst step in the localization process. Using signal
propagation models, as estimate is formed about the distance
between a pair of points. However, accuracy of such scheme
is limited by the ranging errors. Range free localization from
RSSI data is a non standard problem and there have been only
few attempts so far in this diretion. In [1], authors described
a simple nearest neighbour classiﬁcation algorithm to obtain
coarse localization of objects. A kernel based localization
algorithm is proposed in [2].
Motivated by the nature of the problem and some recent
work in this area, we explore the use of a learning algorithm
for solving this problem. We present a new approach to this
problem and discuss and analyze some schems for estimating
locations from RSSI data.
This report is organized as following. In section II, the prob-
lem statement is introduced. We give a deatiled description of

our approach in section III which forms the major part of
this report. The performance of various proposed schemes is
analyzed in section IV. Conclusions are given in section V.

I I . LOCAL I ZAT ION IN AD -HOC S EN SOR N ETWORK
A. Problem Statement
Let X1 , X2 . . . Xm , Xm+1 . . . Xm+n denote the locations
of m + n sensor nodes in R3 . We assume that position
of ﬁrst m nodes are unknown and represent
this set by
Xu = {X1 , X2 . . . Xm}. Also, we assume that position of
last n nodes are known and represent this set by Xk =
{Xm+1 , Xm+2 . . . Xm+n }. We call the nodes in Xk as Becon
nodes. In general n << m. For every pair of nodes (i, j ) we
are gievn Sij , the signal strength that sensor j receives from
node i. Our problem is to recover the positions of all the nodes
∈ Xu .

B. Brief description of Algorithm
Given any pair of nodes (Xi , Xj ), we train SVM to assign
label 1 to it if ||Xi − Xj ||2 < Ro or −1 otherwise, where the
choice of Ro is up to us. Training is done on the set of becon
nodes. We form a feature vector which is robust to signal
variations. Once we have this pairwise classiﬁcation output,
we map the SVM output to probability by ﬁtting the data to
a logistic regression as described in [4]. Our intution is that
a pair of points which are very close will be assigned label 1
with probability close to 1 and points which are very far apart
will be assigned label 1 with probability very close to 0. We
then use this pairwise probability to estimate the postion of
unknown nodes by various schemes as described in the next
section.

I I I . D ETA I L ED D E SCR I PT ION O F TH E ALGOR I THM
A. Training SVM and Classiﬁcation
Consider a pair of nodes (i, j ). Our intution is that two
nodes are close in space if they receive the similar signal
(cid:17)
(cid:16) ||S ik−S jk||2
strengths from all the other nodes. Thus, the feature vector
for nodes (i, j ) is given by φ(i, j ) where it’s k th element
φ(i, j )k = exp
. This choice of feature vector
τ
makes system robust
to fading and interference, which is
commonly observed in wireless signals. So, if there is some
obstruction in the line of sight between node i and node k
and if node j is close to node i then Sjk will also show the
variations similar to that observed in Sik . Note that to reduce
the training complexity, we can conside only those nodes k
for which at least one of Sik or Sjk have value greater than

some pre determined threshold, though, we haven’t done this
in our current implementation.
With this choice of features, we train the SVM to answer
if the distance between a pair of nodes is less than Ro .
All possible pairs of becon nodes are used for training. We
implement this using SMO algorithm with L1 regularization
[3]. Once trained, we store the classiﬁcation output in matrix
Y and value of SVM before thresholding in a matrix S where
yij = 1 if SVM output for nodes (i, j ) is > 0 and yij = −1
otherwise. Similarly, sij = wtφ(i, j ) − b denotes SVM output
for nodes (i,j) before thresholding.

B. Mapping SVM output to probability
We use the approach given in [4] to map SVM to proba-
bility. This is done by ﬁrst ﬁtting the parameters of a logistic
regression function g(s) =
1
1+exp(As+B ) and then evaluting
g(sij ) for each sij ∈ S. This gives us a matrix P where
Pij = g(sij ) = P [||Xi − Xj ||2 < Ro ].
For ﬁtting the parameters A and B , we form following log-
X
likelihood function and maximize is with respect to to A and
B.
(A, B ) = arg max
A,B
f

(t(f )log(g(f )) + (1 − t(f ))log(g(f )))

(1)
where f is SVM output for a pair of becon nodes after it has
been trained on the becon nodes and t(f) is the corresponding
lable which takes value 0 and 1 instead of −1 and 1.
In order to get an unbiased estimate of the probability, we
split the training data into three parts, trained SVM on all
combinations of two out of three, and used the output of that
SVM on the third part and corresponding labels of third part
for ﬁtting logistic regression parameters.

(2)

wij Xij

C. Estimating locations
We use the matrix P obtained earlier for estimating the
Xi = X
locations. One possible approach is to write the position of
node i as the weighted sum of its neighbours.
j∈N (i)
where N (i) denoted the neighbours of node i which can be
taken as those nodes j for which entries Ci,j is 1. An obvious
way method to choose wij is to take them in proportion
to pij . A sequential algorithm can be formed as follows:
We ﬁrst
ﬁnd the position of nodes which has maximum
number of neighbour with known locations (for the very ﬁrst
pass, the node with maximum number of becon nodes in its
neighbourhood). We compute the location of this node as
the weighted sum of locations of its neigbours with known
locations. As further node locations becomes known, they help
in locating other nodes. This scheme is very simple but is
prone to error propogation. Fig. 2 shows the outcome of such
scheme.
mX
|| m+nX
An alternative would be to use joint detection which tries
to minimize
i=1
i=1

wi,j Xj − X i||2

(3)

2

If Pu , Qu , Ru and Pk , Qk , Rk are column vectors denoting the
x,y and z co-ordinates of nodes in Xu and Xk respectively,
and if we partition weight matrix W as W = [Wu Wk ] then
it can be shown that minimizing (3) gives
u − Wu + I )−1 (Wk Pk − W T
u Wu − W T
Pu = (W T
u WkXk ) (4)
and similar expressions can be obtained for Qu and Ru . We
call this as M inN orm2 scheme.
Though, we are doing a joint detection, when positions of all
the nodes are unknown, a trivial solution for (3) is given when
all the nodes are at single point. In presence of some becon
nodes, nodes won’t stick to one point but they will still have
the tendency of converging towards the center since number
of becon nodes are very small compared to unknown nodes
as shown in ﬁg. 3. An alternative would be to minimize ﬁrst
norm instead of second norm, but this improves the results
only by a small margin.
SLE = X
A better solution is given by an application of Laplace
Eigenmaps [5]. This involves minimizing the cost function
wi,j ||Zi − Zj ||2
i,j
X
subject to constraintsX
Zi = 0; and
i
i
The constraints remove the translation ambiguity and the
tendency to put all the points at origin. We take the weights
wi,j = Pi,j . The intution behind using this optimization
problem is that nodes for which Pi,j is close to 1 are likely to
Let W denote the weight matrix. We de ﬁne ui = P
be close and nodes for which Pi,j is close to zero are likely
to be far apart.
j wij
and L = diag [u1 , . . . , uN ] − W . Let (λk , bf vk ) be the
eigne value decomposition of L which are arranged in the
increasing order by magnitude of eigenvalues. Then the op-
timal lowest cost 3-dimsensional solution to (5) is given by
Zi = [v2 (i, . . . , v4 (i]T .
the co-ordinate system for Z 0
However,
i s and Xi s are
different. We map Zi to Xi by the follwong way. We assume
that in a noise free environment Xi are obtained from Zi by
an afﬁne transformation

||Zi ||2 = 1;

(6)

(5)

Xi = AZi + b
(7)
where A is 3 × 3 matrix and b is a 3 × 1 matrix. We estimate
A and b by posing a least square error problem over becon
X
i s and Z 0
nodes estimate given by X 0
i s.
||AZi + b − Xi ||2
(A, b) = arg min
A,b
i∈Xk
Once we know A and b, we map back to the original co-
ordinate system by using (7). The results are shown in ﬁg.
4.

(8)

A similar approach based on nodes connectivity has been
tried in [6] but our approach differ in a sense that we have a
de ﬁnite scheme for choosing weights by using SVM probabil-
ity values and we propose the use of an Afﬁne transformation
to go back to the original co-ordinate system.

IV. T E ST R E SU LT S
We test the validity of the algorithm by simulation. We use
the signal model described in [2] for evaluting the perfor-
mance. Each sensor location x is assumed to receive from a
sensor located at x0 a signal value following a fading channel
model: s(x, x0 ) = exp( −||x−x0 ||
) + N (0, σ2 ), where N (0, σ2 )
σ1
is the independently generated Gaussina random variable with
zero mean and variance σ2 . This has nothing to do with the
choice of the feature vector and a polynomial decay function
was found to give similar reuslts.
Simulations are carried out for three different values of
noise power σ2 = 0.01, 0.05, 0.1 while σ1 = 1.7 is kept
ﬁxed. The percentage classiﬁcation errors for these values
of noise were found to be 2.82, 3.1, 3.85 respectively. The
parameters for ﬁne localization error is presented in table 1-3
where the values are normalized, so they repesent the error
that would have occured in an area of 1 × 1. As expected, the
performance deteriorates with the increase in the noise power.
Moreover, Laplace Eigenmaps perform much better than the
other schemes.
Fig. 1 shows the outcome of a typical initial calssiﬁcation
stage. Here the all the points which are within Ro distance
from center node are marked withing the large circle. A blue
point means a classi ﬁcation label 1 while a red point means
a classiﬁcation label −1. Figs. 2-4 show the outcome of
the sequential, M inN orm2 and Laplace Eigenmaps schemes
respectively for the worst case noise power of 0.1. Blue dots
denote the true position of sensor nodes while red dots denote
their estimated position. A cross denotes a becon node.
We also tried to test out algorithm on the actual data [7]
for Chipcon CC1000. Since our data consisted had only 16
nodes which were partially connected only, we were not able
to perform the inital classi ﬁcation with good accuracy. We
obtained percentage classiﬁcation error to be arond 30. But
this was mainly due to very small number of nodes and an
even smaller fraction of becon nodes on which training was
done. We intend to evaluate our alogrithm on a large network
of actual sensor nodes in near future.

V. CONC LU S ION S AND FU TUR E WORK
We present a new learning algorithm for Ad-Hoc sensor
network localization and show that mapping output of SVM to
probability followed by application of Lapalce Eigenmaps and
Afﬁne transformation gives a good estimate of node locations
from RSSI data only. Our algorithm is particularly useful in a
dense sensor network.
Our contribution in this project is to show a completely
different approach to solving a difﬁcult problem of localization
from RSSI data. We do not claim that our algorithm is better
than the existing ones but we show that a learning algorithm
can be applied for this problem.
Our immediate future goal is to test the algorithm on a large
actual sensor network. We would also like to use apply thin
plate spline transformation instead of Afﬁne transformation
to map back to the original co-ordinate system once we have
the outcome of the laplace eigenmaps. Current implementation
of SVM has high computational complexity for the training.

3

TABLE I
P ER FORMANC E W I TH NO I S E POW ER σ2 = 0.01

Sequential
M inN orm2
Lap Eigmap

Norm Max Abs Err
0.2574
0.4046
0.2232

Norm Mean Err
0.1229
0.1233
0.0666

Norm Std Dev
0.0683
0.0969
0.0440

TABLE II
P ER FORMANC E W I TH NO I S E POW ER σ2 = 0.05

Sequential
M inN orm2
Lap Eigmap

Norm Max Abs Err
0.2808
0.4379
0.2502

Norm Mean Err
0.1265
0.1335
0.0713

Norm Std Dev
0.0686
0.1034
.0482

Attempts can be made to reduce the complexity of the training
phase by a good choice of Kernel which doesn’t require
computing feature explicitly, or by limiting the size of the
feature vector. A study can be made to ﬁnd better schemes
for choosing the weights or to ﬁnd the optimal weights. A
distribute version of the algorithm can also be developed.

V I . ACKNOW LEDG EM EN T
The author would like to thank Professor Andrew Ng and
Ashutosh Saxena for insightful discussions. The author is also
grateful to Kannan Srinivasan for providing the real RSSI data.

R E F ER ENC E S
[1] Bahl, P. and Padmanabhan, V. N., “RADAR: An in-building
, INFOCOM
RF-based user location and tracking system ”
(2). 775-784, 2000.
[2] Xuanlong Nguyen, Miahael I. Jordan, and Bruno Sinop-
oli, “A kernel-based learning approach to ad hoc sensor
, IACM Transactions on Sensor Net-
network localization”
works, Volume 1, Issue 1, 134 - 152, Aug 2005.
[3] Platt, J., “Fast Training of Support Vector Machines using
, Advances in Kernel
Sequential Minimal Optimization”
Methods - Support Vector Learning, 1999.
[4] Platt, J., “Probabilistic Outputs for Support Vector Ma-
chines and Comparisons to Regularized Likelihood Meth-
, Advances in Large Margin Classiﬁers, 1999.
ods”
[5] M. Belkin, P. Niyogi,
“Laplacian Eigenmaps for Di-
, Neural
mensionality Reduction and Data Representation”
Computation, 15 (6):1373-1396, Jun 2003.
[6] N. Patwari and A. O. Hero, “RAdaptive Neighborhoods
,
in
for Manifold Learning-based Sensor Localization ”
Proceedings of the 2005 Signal Processing and Wireless
Communications Conference (SPAWC), New York City,
5-8 June 2005.
[7] http://cvs.sourceforge.net/viewcvs.py/tinyos/tinyos-
1.x/tools/matlab/contrib/kamin/chipconRSSI/

TABLE III
P ER FORMANC E W I TH NO I S E POW ER σ2 = 0.1

Sequential
M inN orm2
Lap Eigmap

Norm Max Abs Err
0.3395
0.4162
0.2200

Norm Mean Err
0.1363
0.1259
0.0674

Norm Std Dev
0.0730
0.0990
0.0450

4

(a) Coarse Localization: A typical output

(b) Sequential localization scheme

Fig. 1. Simulation results

(a) Minimizing second norm (M inN orm2 )

(b) Laplace Eigen value Map

Fig. 2. Simulation results

