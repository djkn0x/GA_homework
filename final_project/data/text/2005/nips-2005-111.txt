Unbiased Estimator of Shape Parameter for
Spiking Irregularities under Changing
Environments

Keiji Miura
Kyoto University
JST PRESTO

Masato Okada
University of Tokyo
JST PRESTO
RIKEN BSI

Shun-ichi Amari
RIKEN BSI

Abstract

We considered a gamma distribution of interspike intervals as a statisti-
cal model for neuronal spike generation. The model parameters consist
of a time-dependent ﬁring rate and a shape parameter that characterizes
spiking irregularities of individual neurons. Because the environment
changes with time, observed data are generated from the time-dependent
ﬁring rate, which is an unknown function. A statistical model with an
unknown function is called a semiparametric model, which is one of the
unsolved problem in statistics and is generally very difﬁcult to solve. We
used a novel method of estimating functions in information geometry to
estimate the shape parameter without estimating the unknown function.
We analytically obtained an optimal estimating function for the shape
parameter independent of the functional form of the ﬁring rate. This
estimation is efﬁcient without Fisher information loss and better than
maximum likelihood estimation.

1

Introduction

The ﬁring patterns of cortical neurons look very noisy [1]. Consequently, probabilis-
tic models are necessary to describe these patterns [2, 3, 4]. For example, Baker and
Lemon showed that the ﬁring patterns recorded from motor areas can be explained using a
continuous-time rate-modulated gamma process [5]. Their model had a rate parameter, ξ ,
and a shape parameter, κ, that was related to spiking irregularity. ξ was assumed to be a
function of time because it depended largely on the behavior of the monkey. κ was assumed
to be unique to individual neurons and constant over time.
The assumption that κ is unique to individual neurons is also supported by other studies
[6, 7, 8]. However, these indirect supports are not conclusive. Therefore, we need to ac-
curately estimate κ to make the assumption more reliable. If the assumption is correct,
neurons may be identi ﬁed by κ estimated from the spiking patterns, and κ may provide
useful information about the function of a neuron. In other words, it may be possible to
classify neurons according to functional ﬁring patterns rather than static anatomical prop-
erties. Thus, it is very important to accurately estimate κ in the ﬁeld of neuroscience.
In reality, however, it is very difﬁcult to estimate all the parameters in the model from

the observed spike data. The reason for this is that the unknown function for the time-
dependent ﬁring rate, ξ (t), has inﬁnite degrees of freedom. This kind of estimation problem
is called the semiparametric model [9] and is one of the unsolved problems in statistics. Are
there any ingenious methods of estimating κ accurately to overcome this difﬁculty?
Ikeda pointed out that the problem we need to consider is the semiparametric model [10].
However, the problem remains unsolved. There is a method called estimating functions
[11, 12] for semiparametric problems, and a general theory has been developed [13, 14,
15] from the viewpoint of information geometry [16, 17, 18]. However, the method of
estimating functions cannot be applied to our problem in its original form.

In this paper, we consider the semiparametric model suggested by Ikeda instead of the
continuous-time rate-modulated gamma process.
In this discrete-time rate-modulated
model, the ﬁring rate varies for each interspike interval. This model is a mixture model
and can represent various types of interspike interval distributions by adjusting its weight
function. The model can be analyzed by using the method of estimating functions for
semiparametric models.

Various attempts have been made to solve semiparametric models. Neyman and Scott
pointed out that the maximum likelihood method does not generally provide a consistent
estimator when the number of parameters and observations are the same [19]. In fact, we
show that maximum likelihood estimation for our problem is biased. Ritov and Bickel
considered asymptotic attainability of information bound purely mathematically [20, 21].
However, their results were not practical for application to our problem. Amari and Kawan-
abe showed a practical method of estimating ﬁnite parameters of interest without estimating
an unknown function [15]. This is the method of estimating functions. If this method can
be applied, κ can be estimated consistently independent of the functional form of a ﬁring
rate.

In this paper, we show that the model we consider here is the “exponential form ” de ﬁned
by Amari and Kawanabe [15]. However, an asymptotically unbiased estimating function
does not exist unless multiple observations are given for each ﬁring rate, ξ . We show that
if multiple observations are given, the method of estimating functions can be applied. In
that case, the estimating function of κ can be analytically obtained, and κ can be estimated
consistently independent of the functional form of a ﬁring rate. In general, estimation using
estimating functions is not efﬁcient. However, for our problem, this method yielded an
optimal estimator in the sense of Fisher information [15]. That is, we obtained an efﬁcient
estimator.

2 Simple case

We considered the following statistical model of inter spike intervals proposed by Ikeda
[10]. Interspike intervals are generated by a gamma distribution whose mean ﬁring rate
ξ at each observation is determined randomly
changes over time. The mean ﬁring rate
(cid:1)
according to an unknown probability distribution, k(ξ ). The model is described as

p(T ; κ, k(ξ )) =

q(T ; ξ , κ)k(ξ )dξ ,

where

(ξκ)κ
T κ−1 e−ξκT
q(T ; ξ , κ) =
Γ(κ)
= eξ(−κT )+(κ−1) log(T )−(−κ log(ξκ)+log Γ(κ))
≡ eξs(T ,κ)+r(T ,κ)−ψ(κ,ξ) .

(1)

(2)

Here, T denotes an interspike interval. We de ﬁned s, r , and ψ as
s(T , κ) = −κT ,
(3)
r(T , κ) = (κ − 1) log(T ), and
(4)
ψ(κ, ξ ) = −κ log(ξκ) + log Γ(κ)
(5)
to demonstrate that the model is the exponential form de ﬁned by Amari and Kawanabe
[15]. Note that this type of model is called a semiparametric model because it has both
unknown ﬁnite parameters, κ, and function, k(ξ ).
In this mixture model, {ξ (1) , ξ (2) , . . .} is an unknown sequence where ξ is independently
and identically distributed according to a probability density function k(ξ ). Then, l-th
observation T (l) is distributed according to q(T (l) ; ξ (l) , κ). In effect, T is independently
and identically distributed according to p(T ; κ, k(ξ )).
An estimating function is a function of κ whose zero-crossing provides an estimate of κ,
analogous to the derivative with respect to κ of the log-likelihood function. Note that the
zero-crossings of the derivatives of the log-likelihood function with respect to parameters
provide an maximum likelihood estimator.

Let us calculate the estimating function following Amari and Kawanabe [15] to estimate
κ without estimating k(ξ ). They showed that for the exponential form of mixture dis-
tributions, the estimating function, uI , is given by the projection of the score function,
u = ∂κ log p, as
uI (T , κ) = u − E [u|s]
= (∂κ s − E [∂κ s|s]) · Eξ [ξ |s] + ∂κ r − E [∂κ r|s]
= ∂κ r − E [∂κ r|s],
(cid:2)
ξk(ξ ) exp(ξ · s − ψ)dξ
(cid:2)
k(ξ ) exp(ξ · s − ψ)dξ
κ = −T = ∂κ s,
E [∂κ s|s] =
s
(8)
holds because the number of random variables, T , and s are the same. For the same reason,
E [∂κ r|s] = log(T ) = ∂κ r.
(9)

Eξ [ξ |s] =

The relation,

(6)

(7)

where

.

Then,

uI = 0.
(10)
This means that the set of estimating functions is an empty set. Therefore, we proved that
no asymptotically unbiased estimating function of κ exists for the model.
Two or more random variables may be needed. Let us consider the multivariate model
(cid:1) n(cid:3)
described as

p(T1 , ..., Tn ; κ, k(ξ1 , ..., ξn )) =

q(Ti ; ξi , κ)k(ξ1 , ..., ξn )dξ .

(11)

i=1
Here, the number of random variables and s are also the same, and uI becomes an empty
set.
This result can be understood intuitively as follows. When the mean, µ, and variance, σ ,
of a normal distribution are estimated from a single observation, x, they are estimated as
µ = x and σ = 0. Similarly, ξ and κ of a gamma distribution, q(T ; ξ , κ), are estimated
T and κ = ∞ corresponding to 0 variance. Two or
from a single observation, T , as ξ = 1
more observations are required to estimate κ. For the semiparametric model considered in
this section, only one observation is given for each ξ . Two or more observations are needed
for each ξ .

3 Cases with multiple observations for each ξ

Next we consider the case where m observations are given for each ξ (l) , which may
be distributed according to k(ξ ). Here, a consistent estimator of κ exists. Let {T } =
{T1 , . . . , Tm } be the m observations, which are generated from the same distribution spec-
iﬁed by ξ and κ. We have N such observations {T (l) }, l = 1, . . . , N , with a common κ
m } are generated from the same ﬁring rate ξ (l) . Let
and different ξ (l) . Thus, {T (l)
, . . . , T (l)
us take one {T }. The probability model can be written as
1
(cid:1) m(cid:3)
p({T }; κ, k(ξ )) =

q(Ti ; ξ , κ)k(ξ )dξ ,

(12)

i=1

where
m(cid:3)

i=1

m(cid:3)

(ξκ)κ
T κ−1
e−ξκTi
q(Ti ; ξ , κ) =
(cid:4)m
(cid:4)m
i
Γ(κ)
i=1
= eξ(−κ
i=1 log(Ti )−(−mκ log(ξκ)+m log Γ(κ))
Ti )+(κ−1)
i=1
≡ e(ξ·s({T },κ)+r({T },κ)−ψ(κ,ξ)) .

(13)

(14)

(15)

(16)

(17)

(18)

(19)

We de ﬁned s, r , and ψ as
s({T }, κ) = −κ

m(cid:5)

Ti ,
m(cid:5)

i=1
r({T }, κ) = (κ − 1)
log(Ti ), and
i=1
ψ(κ, ξ ) = −mκ log(ξκ) + m log Γ(κ).
Then, the estimating function is given by
uI ({T }, κ) = u − E [u|s]
= (∂κ s − E [∂κ s|s]) · Eξ [ξ |s] + ∂κ r − E [∂κ r|s]
= ∂κ r − E [∂κ r|s]
m(cid:5)
log(Ti ) − mE [log(T1 )|s],

=

i=1

where we used

E [∂κ s|s] =
s
κ = ∂κ s.
To calculate the conditional expectation of log T1 , let us use Bayes ’s Theorem:
p(T |s) =
p(T , s)
p(s)

.

By transforming random variables, (T1 , T2 , T3 , ..., Tm ), into (s, T2 , T3 , ..., Tm ), we have
(cid:1) (cid:3)
m(cid:5)
(cid:1)
m−1(cid:3)
i=1
i

Ti )k(ξ )dξdT

p(s) =

ξmκ esξ k(ξ )dξ .

(20)

q(Ti ; ξ , κ)δ(s + κ
(−s)mκ−1
Γ(κ)m

B (iκ, κ)

=

i=1

where the beta function is de ﬁned as

B (x, y) =

Γ(x)Γ(y)
Γ(x + y)

=

(x − 1)!(y − 1)!
(x + y − 1)!

.

(cid:1)

m(cid:3)

Similarly, we have
E [log(T1 )|s] =
log(T1 )
q(Ti )δ(s + κ
i=1
κ ) − φ(mκ) + φ(κ),
= log(− s
where the digamma function is de ﬁned as

m(cid:5)

i=1

Ti )k(ξ )dξdT 1
p(s)

(21)

(22)

Γ(cid:1) (κ)
φ(κ) =
.
(23)
Γ(κ)
Note that E [log(T1 )|s] does not depend on the unknown function, k(ξ ). Thus, we have
m(cid:5)
m(cid:5)
uI ({T }, κ) =
log(Ti ) − m log(
Ti ) + mφ(mκ) − mφ(κ).

(24)

i=1

i=1

The form of uI can be understood as follows. If we scale T as t = ξT , we have E [t] = 1.
Then, we can show that uI does not depend on ξ , because
log(T ) − E [log T |s] = log(t) − E [log t|s].
This implies that we can estimate κ without estimating ξ . The method of estimating func-
tion only works for gamma distributions. It crucially depends on the fact that the estimating
function is invariant under scaling of T .
κ can be estimated consistently from N independent observations, {T (l) } =
{T (l)
m }, l = 1, . . . , N , as the value of κ that solves
, . . . , T (l)
1
N(cid:5)

(25)

uI ({T (l) }, ˆκ) = 0.

(26)

q(Ti ; ξ , κ)uI dT )k(ξ )dξ
(cid:1)

l=1
In fact, the expectation of uI is 0 independent of k(ξ ):
(cid:1)
(cid:1) m(cid:3)
(
(cid:1)
(cid:1)

E [uI ] =

=

=

i=1
Eq [uI |s]p(s)ds ·
k(ξ )dξ
Eq [log t − E [log t|s]|s]p(s)ds
(cid:6)m
q(ti ; 1, κ).
where Eq denotes the expectation for
i=1
uI yields an efﬁcient estimating function [15, 21]. An efﬁcient estimator is one whose
variance attains the Cramer-Rao lower bound asymptotically. Thus, there is no estimator
of κ whose mean-square estimation error is smaller than that given by uI . As uI does
not depend on k(ξ ), it is the optimal estimating function whatever k(ξ ) is, or whatever the
sequence ξ (1) , . . . , ξ (N ) is.

= 0,

(27)

Maximum likelihood
Proposed method

0
4

0
3

0
2

5
1

0
1

5

κ^

2

5

10 20

50

200

500

Number of observations

Figure 1: Biases of ˆκ for maximum likelihood estimation and proposed method for m = 2.
The dotted line represents the true value, κ = 4. The maximum likelihood estimation is
biased even when an in ﬁnite number of observations are given while the estimating function
is asymptotically unbiased.

The maximum likelihood estimation for this problem is given by
m(cid:5)
log(Ti ) + m log( ˆξ ) + m log κ − mφ(κ),

uM LE =

where

i=1

m(cid:5)

Ti .

1
ˆξ

=

1
m

(28)

(29)

i=1
uM LE is similar to uI but different in terms of constant. As a result, the maximum likeli-
hood estimator ˆκ is biased (Figure 1).
So far, we have assumed that the ﬁring rates for m observations are the same. Instead, let
us consider a case where the ﬁring rates have some relation. For example, consider the case
(cid:1)
where Eq [t1 ] = 2Eq [t2 ]. The model can be written as

p(t1 , t2 ; κ, k(ξ )) =

q(t1 ; ξ , κ)q(t2 ; 2ξ , κ)k(ξ )dξ .

(30)

This model can be derived from Eq. (12) by rescaling as T1 = t1 and T2 = 2t2 . Note that
q(2T ; ξ , κ) = q(T ; 2ξ , κ) because T always appears as ξT in q(T ; ξ , κ). Thus, Eq. (12)
includes various kinds of models.

4 General case
Let us consider a general case where the ﬁring rate changes stepwise. That is, {ξ1 , . . . , ξn }
is distributed according to k({ξ}) = k(ξ1 , . . . , ξn ) and ma observations are given for each
ξa . The model can be written as
p({T }; κ, k({ξ}))
(cid:1) m1(cid:3)
m2(cid:3)

mn(cid:3)

in ; ξn , κ)k({ξ})dξ1 dξ2 . . . dξn ,
q(T (n)

=

q(T (1)
i1 ; ξ1 , κ)

q(T (2)
i2 ; ξ2 , κ) . . .

i1=1

i2=1

in=1

where

m1(cid:3)

m2(cid:3)

mn(cid:3)

q(T (1)
i1 ; ξ1 , κ)
m1(cid:5)

i1=1
= exp(ξ1 (−κ
m1(cid:5)
i1=1

+(κ − 1)(
n(cid:5)
i1=1

q(T (n)
in ; ξn , κ)
mn(cid:5)

in=1
i2 ) + . . . + ξn (−κ
T (2)
mn(cid:5)

in=1

q(T (2)
i2 ; ξ2 , κ) . . .
m2(cid:5)

i2=1
i1 ) + ξ2 (−κ
T (1)
m2(cid:5)
log T (2)
i2 + . . . +
maκ log(κ) − n(cid:5)
i2=1
a=1

log T (1)
i1 +
n(cid:5)

i2=1

a=1

ma log Γ(κ)).

log T (n)
in )

in=1

T (n)
in )

(31)

(32)

+

a=1
We de ﬁned sa , r , and ψ as
sa ({T (a) }, κ) = −κ

maκ log(ξa ) +
ma(cid:5)

(33)

(34)

n(cid:5)

maκ log(κ) +

T (a)
,
ia
n(cid:5)
ma(cid:5)
ia=1
r({T }, κ) = (κ − 1)
log T (a)
ia ),
(
maκ log(ξa ) − n(cid:5)
ψ(κ, {ξ}) = − n(cid:5)
a=1
ia=1
a=1
a=1
Then,
uI ({T }, κ) = u − E [u|s]
= (∂κ s − E [∂κ s|s]) · E [ξ |s] + ∂κ r − E [∂κ r|s]
= ∂κ r − E [∂κ r|s]
(36)
ma(cid:5)
n(cid:5)
{ ma(cid:5)
ia ) + maφ(maκ) − maφ(κ)}.
− ma log(
T (a)
log T (a)
ia
a=1
ia=1
ia=1
Thus, κ is estimated with equal weight for every observation. Note that the conditional
expectations can be calculated independently for each set of random variables. uI yields
an efﬁcient estimating function. As this does not depend on k({ξ}), uI is the optimal
estimating function at any k({ξ}). There is no information loss. Note that k({ξ}) can
include correlations among ξa ’s. Nevertheless, the result is very similar to that of the
previous section.

ma log Γ(κ). (35)

a=1

=

5 Summary and discussion

We estimated the shape parameter, κ, of the semiparametric model suggested by Ikeda
without estimating the ﬁring rate, ξ . The maximum likelihood estimator is not consistent
for this problem because the number of nuisance parameters, ξ , increases with increasing
observations, T . We showed that Ikeda ’s model is the exponential form de ﬁned by Amari
and Kawanabe [15] and can be analyzed by a method of estimating functions for semi-
parametric models. We found that an estimating function does not exist unless multiple
observations are given for each ﬁring rate, ξ . If multiple observations are given, a method
of estimating functions can be applied. In that case, the estimating function of κ can be an-
alytically obtained, and κ can be estimated consistently independent of the functional form
of the ﬁring rate, k(ξ ). In general, the estimating function is not efﬁcient. However, this
method provided an optimal estimator in the sense of Fisher information for our problem.
That is, we obtained an efﬁcient estimator.

Acknowledgments

We are grateful to K. Ikeda for his helpful discussions. This work was supported in part by
grants from the Japan Society for the Promotion of Science (Nos. 14084212 and 16500093).

References

[1] G. R. Holt, W. R. Softky, C. Koch, and R. J. Douglas, Comparison of discharge variability in
vitro and in vivo in cat visual cortex neurons, J. Neurophysiol., Vol. 75, pp. 1806-14, 1996.
[2] H. C. Tuckwell, Introduction to theoretical neurobiology: volume 2, nonlinear and stochastic
theories, Cambridge University Press, Cambridge, 1988.
[3] Y. Sakai, S. Funahashi, and S. Shinomoto, Temporally correlated inputs to leaky integrate-
and-ﬁre models can reproduce spiking statistics of cortical neurons, Neural Netw., Vol. 12, pp.
1181-1190, 1999.
[4] D. R. Cox and P. A. W. Lewis, The statistical analysis of series of events, Methuen, London,
1966.
[5] S. N. Baker and R. N. Lemon, Precise spatiotemporal repeating patterns in monkey primary
and supplementary motor areas occur at chance levels, J. Neurophysiol., Vol. 84, pp. 1770-80,
2000.
[6] S. Shinomoto, K. Shima, and J. Tanji, Differences in spiking patterns among cortical neurons,
Neural Comput.,Vol. 15, pp. 2823-42, 2003.
[7] S. Shinomoto, Y. Miyazaki, H. Tamura, and I. Fujita, Regional and laminar differences in in
vivo ﬁring patterns of primate cortical neurons, J. Neurophysiol., in press.
[8] S. Shinomoto, K. Miura, and S. Koyama, A measure of local variation of inter-spike intervals,
Biosystems, Vol. 79, pp. 67-72, 2005.
[9] J. Pfanzagl, Estimation in semiparametric models, Springer-Verlag, Berlin, 1990.
[10] K. Ikeda, Information geometry of interspike intervals in spiking neurons, Neural Comput., in
press.
[11] V. P. Godambe, An optimum property of regular maximum likelihood estimation, Ann. Math.
Statist., Vol. 31, pp. 1208-1211, 1960.
[12] V. P. Godambe (ed.), Estimating functions, Oxford University Press, New York, 1991.
[13] S. Amari, Dual connections on the Hilbert bundles of statistical models, In C. T. J. Dodson
(ed.), Geometrization of statistical theory, pp. 123-152, University of Lancaster Department of
Mathematics, Lancaster, 1987.
[14] S. Amari and M. Kumon, Estimation in the presence of inﬁnitely many nuisance parameters -
geometry of estimating functions, Ann. Statist., Vol. 16, pp. 1044-1068, 1988.
[15] S. Amari and M. Kawanabe, Information geometry of estimating functions in semi-parametric
statistical models, Bernoulli, Vol. 3, pp. 29-54, 1997.
[16] H. Nagaoka and S. Amari, Differential geometry of smooth families of probability distributions,
Technical Report 82-7, University of Tokyo, 1982.
[17] S. Amari and H. Nagaoka, Methods of information geometry, American Mathematical Society,
Providence, RI, 2001.
[18] S. Amari, Information geometry on hierarchy of probability distributions, IEEE Transactions
on Information Theory, Vol. 47, pp. 1701-1711, 2001.
[19] J. Neyman and E. L. Scott, Consistent estimates based on partially consistent observations,
Econometrica, Vol. 32, pp. 1-32, 1948.
[20] Y. Ritov and P. J. Bickel, Achieving information bounds in non and semiparametric models,
Ann. Statist., Vol. 18, pp. 925-938, 1990.
[21] P. J. Bickel, C. A. J. Klaassen, Y. Ritov, and J. A. Wellner, Efﬁcient and adaptive estimation for
semiparametric models, Johns Hopkins University Press, Baltimore, MD, 1993.

