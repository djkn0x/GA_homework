Learning vehicular dynamics, with application
to modeling helicopters

Pieter Abbeel
Computer Science Dept.
Stanford University
Stanford, CA 94305

Varun Ganapathi
Computer Science Dept.
Stanford University
Stanford, CA 94305

Andrew Y. Ng
Computer Science Dept.
Stanford University
Stanford, CA 94305

Abstract

We consider the problem of modeling a helicopter’s dynamics based on
state-action trajectories collected from it. The contribution of this pa-
per is two-fold. First, we consider the linear models such as learned by
C I F ER (the industry standard in helicopter identi ﬁcation), and s how that
the linear parameterization makes certain properties of dynamical sys-
tems, such as inertia, fundamentally difﬁcult to capture. W e propose an
alternative, acceleration based, parameterization that does not suffer from
this deﬁciency, and that can be learned as efﬁciently from da
ta. Second, a
Markov decision process model of a helicopter’s dynamics would explic-
itly model only the one-step transitions, but we are often interested in a
model’s predictive performance over longer timescales. In this paper, we
present an efﬁcient algorithm for (approximately) minimiz ing the pre-
diction error over long time scales. We present empirical results on two
different helicopters. Although this work was motivated by the problem
of modeling helicopters, the ideas presented here are general, and can be
applied to modeling large classes of vehicular dynamics.

Introduction
1
In the last few years, considerable progress has been made in ﬁnding good controllers for
helicopters. [7, 9, 2, 4, 3, 8] In designing helicopter controllers, one typically begins by
constructing a model for the helicopter’s dynamics, and then uses that model to design a
controller. In our experience, after constructing a simulator (model) of our helicopters, pol-
icy search [7] almost always learns to ﬂy (hover) very well in simulation, but may perform
less well on the real-life helicopter. These differences between simulation and real-life
performance can therefore be directly attributed to errors in the simulator (model) of the
helicopter, and building accurate helicopter models remains a key technical challenge in
autonomous ﬂight. Modeling dynamical systems (also referr ed to as system identi ﬁcation)
is one of the most basic and important problems in control. With an emphasis on helicopter
aerodynamics, in this paper we consider the problem of learning good dynamical models
of vehicles.

Helicopter aerodynamics are, to date, somewhat poorly understood, and (unlike most ﬁxed-
wing aircraft) no textbook models will accurately predict the dynamics of a helicopter from
only its dimensions and speci ﬁcations. [5, 10] Thus, at leas t part of the dynamics must be
learned from data. C I F ER R(cid:13) (Comprehensive Identi ﬁcation from Frequency Responses) i s
the industry standard for learning helicopter (and other rotorcraft) models from data. [11, 6]

C I F ER uses frequency response methods to identify a linear model.

The models obtained from C I F ER fail to capture some important aspects of the helicopter
dynamics, such as the effects of inertia. Consider a setting in which the helicopter is ﬂying
forward, and suddenly turns sideways. Due to inertia, the helicopter will continue to travel
in the same direction as before, so that it has “sideslip,” me aning that its orientation is
not aligned with its direction of motion. This is a non-linear effect that depends both on
velocity and angular rates. The linear C I F ER model is unable to capture this. In fact, the
models used in [2, 8, 6] all suffer from this problem. The core of the problem is that
the naive body-coordinate representation used in all these settings makes it fundamentally
difﬁcult for the learning algorithm to capture certain prop erties of dynamical systems such
as inertia and gravity. As such, one places a signi ﬁcantly he avier burden than is necessary
on the learning algorithm.

In Section 4, we propose an alternative parameterization for modeling dynamical systems
that does not suffer from this deﬁciency. Our approach can be viewed as a hybrid of physi-
cal knowledge and learning. Although helicopter dynamics are not fully understood, there
are also many properties —such as the direction and magnitude
of acceleration due to grav-
ity; the effects of inertia; symmetry properties of the dynamical system; and so on—which
apply to all dynamical systems, and which are well-understood. All of this can therefore be
encoded as prior knowledge, and there is little need to demand that our learning algorithms
learn them. It is not immediately obvious how such prior knowledge can be encoded into
a complex learning algorithm, but we will describe an acceleration based parameterization
in which this can be done.

Given any model class, we can choose the parameter learning criterion used to learn a
model within the class. C I F ER ﬁnds the parameters that minimize a frequency domain er-
ror criterion. Alternatively, we can minimize the squared one-step prediction error in the
time domain. Forward simulation on a held-out test set is a standard way to assess model
quality, and we use it to compare the linear models learned using C I F ER to the same linear
models learned by optimizing the one-step prediction error. As suggested in [1], one can
also learn parameters so as to optimize a “lagged criterion”
that directly measures simula-
tion accuracy—i.e., predictive accuracy of the model over lo ng time scales. However, the
EM algorithm given in [1] is expensive when applied in a continuous state-space setting. In
this paper, we present an efﬁcient algorithm that approxima tely optimizes the lagged cri-
terion. Our experiments show that the resulting model consistently outperforms the linear
models trained using C I F ER or using the one-step error criterion. Combining this with the
acceleration based parameterization results in our best helicopter model.

2 Helicopter state, input and dynamics
The helicopter state s comprises its position (x, y , z ), orientation (roll φ, pitch θ , yaw
ω ), velocity ( ˙x, ˙y , ˙z ) and angular velocity ( ˙φ, ˙θ , ˙ω ). The helicopter is controlled via a 4-
dimensional action space:

1. u1 and u2 : The longitudinal (front-back) and latitudinal (left-right) cyclic pitch
controls cause the helicopter to pitch forward/backward or sideways, and can
thereby also affect acceleration in the longitudinal and latitudinal directions.
2. u3 : The tail rotor collective pitch control affects tail rotor thrust, and can be used
to yaw (turn) the helicopter.
3. u4 : The main rotor collective pitch control affects the pitch angle of the main
rotor’s blades, by rotating the blades around an axis that runs along the length of
the blade. As the main rotor blades sweep through the air, the resulting amount of
upward thrust (generally) increases with this pitch angle; thus this control affects
the main rotor’s thrust.

Following standard practice in system identi ﬁcation ([8, 6 ]), the original 12-dimensional
helicopter state is reduced to an 8-dimensional state represented in body (or robot-centric)
coordinates sb = (φ, θ , ˙x, ˙y , ˙z , ˙φ, ˙θ , ˙ω). Where there is risk of confusion, we will use su-
perscript s and b to distinguish between spatial (world) coordinates and body coordinates.
The body coordinate representation speci ﬁes the helicopte r state using a coordinate frame
in which the x, y , and z axes are forwards, sideways, and down relative to the current ori-
entation of the helicopter, instead of north, east and down. Thus, ˙xb is the forward velocity,
whereas ˙xs is the velocity in the northern direction. (φ and θ are always expressed in world
coordinates, because roll and pitch relative to the body coordinate frame is always zero.)
By using a body coordinate representation, we encode into our model certain “symmetries ”
of helicopter ﬂight, such as that the helicopter’s dynamics are the same regardless of its ab-
solute position (x, y , z ) and heading ω (assuming the absence of obstacles). Even in the
reduced coordinate representation, only a subset of the state variables needs to be modeled
explicitly using learning. Given a model that predicts only the angular velocities ( ˙φ, ˙θ , ˙ω),
we can numerically integrate to obtain the orientation (φ, θ , ω).
We can integrate the reduced body coordinate states to obtain the complete world coor-
dinate states.
Integrating body-coordinate angular velocities to obtain world-coordinate
angles is nonlinear, thus the model resulting from this process is necessarily nonlinear.

3 Linear model
The linear model we learn with C I F ER has the following form:
t − gθt” ∆t,
t + C1 (u1 )t + D1” ∆t,
t = “Cx ˙xb
t = “Cφ ˙φb
˙φb
t+1 − ˙φb
˙xb
t+1 − ˙xb
t + gφt + D0” ∆t,
t = “Cy ˙yb
t + C2 (u2 )t + D2” ∆t,
t = “Cθ ˙θb
t+1 − ˙θb
˙θb
t+1 − ˙yb
˙yb
t + g + C4 (u4 )t + D4” ∆t,
t = “Cz ˙z b
˙z b
t+1 − ˙z b
˙ω b
t+1 − ˙ω b
t = `Cω ˙ωb
t + C3 (u3 )t + D3 ´ ∆t,
φt+1 − φt = ˙φb
θt+1 − θt = ˙θb
t ∆t,
t ∆t.
Here g = 9.81m/s2 is the acceleration due to gravity and ∆t is the time discretiza-
tion, which is 0.1 seconds in our experiments. The free parameters in the model are
Cx , Cy , Cz , Cφ , Cθ , Cω , which model damping, and D0 , C1 , D1 , C2 , D2 , C3 , D3 , C4 , D4 ,
which model the inﬂuence of the inputs on the states. 1 This parameterization was chosen
using the “coherence” feature selection algorithm of
C I F ER. C I F ER takes as input the state-
t , ˙φb
t , ˙θb
action sequence {( ˙xb
t , φt , θt , ut )}t and learns the free parameters using a
t , ˙y b
t , ˙z b
t , ˙ω b
frequency domain cost function. See [11] for details.

Frequency response methods (as used in C I F ER) are not the only way to estimate the free
parameters. Instead, we can minimize the average squared prediction error of next state
given current state and action. Doing so only requires linear regression. In our experi-
ments (see Section 6) we compare the simulation accuracy over several time-steps of the
differently learned linear models. We also compare to learning by directly optimizing the
simulation accuracy over several time-steps. The latter approach is presented in Section 5.

4 Acceleration prediction model
Due to inertia, if a forward- ﬂying helicopter turns, it will have sideslip (i.e., the helicopter
will not be aligned with its direction of motion). The linear model is unable to capture the
sideslip effect, since this effect depends non-linearly on velocity and angular rates. In fact,
the models used in [2, 8, 6] all suffer from this problem. More generally, these models
do not capture conservation of momentum well. Although careful engineering of (many)
additional non-linear features might ﬁx individual effect s such as, e.g., sideslip, it is unclear
how to capture inertia compactly in the naive body-coordinate representation.

1D0 captures the sideways acceleration caused by the tail rotor’s thrust.

From physics, we have the following update equation for velocity in body-coordinates:
t (cid:17) ∗ (cid:0)( ˙x, ˙y , ˙z )b
t+1 = R (cid:16)( ˙φ, ˙θ , ˙ω)b
(1)
t + ( ¨x, ¨y , ¨z )b
( ˙x, ˙y , ˙z )b
t ∆t(cid:1) .
t (cid:17) is the rotation matrix that transforms from the body-coordinate frame
Here, R (cid:16)( ˙φ, ˙θ , ˙ω)b
at time t to the body-coordinate frame at time t + 1 (and is determined by the angular veloc-
ity ( ˙φ, ˙θ , ˙ω)b
t denotes the acceleration vector in body-coordinates
t at time t); and ( ¨x, ¨y , ¨z )b
at time t. Forces and torques (and thus accelerations) are often a fairly simple function of
inputs and state. This suggests that a model which learns to predict the accelerations, and
then uses Eqn. (1) to obtain velocity over time, may perform well. Such a model would
naturally capture inertia, by using the velocity update of Eqn. (1). In contrast, the models
of Section 3 try to predict changes in body-coordinate velocity. But the change in body-
coordinate velocity does not correspond directly to physical accelerations, because the
body-coordinate velocity at times t and t + 1 are expressed in different coordinate frames.
Thus, ˙xb
t is not the forward acceleration—because
t+1 and ˙xb
t are expressed in dif-
t+1 − ˙xb
˙xb
ferent coordinate frames. To capture inertia, these models therefore need to predict not only
the physical accelerations, but also the non-linear inﬂuen ce of the angular rates through the
rotation matrix. This makes for a difﬁcult learning problem , and puts an unnecessary bur-
den on the learning algorithm. Our discussion above has focused on linear velocity, but a
similar argument also holds for angular velocity.

The previous discussion suggests that we learn to predict physical accelerations and then
integrate the accelerations to obtain the state trajectories. To do this, we propose:
t = Cφ ˙φt + C1 (u1 )t + D1 ,
¨φb
¨xb
t = Cx ˙xb
t + (gx )b
t ,
t = Cθ ˙θt + C2 (u2 )t + D2 ,
¨θb
t + (gy )b
t = Cy ˙y b
¨y b
t + D0 ,
¨z b
t = Cz ˙z b
t + (gz )b
¨ω b
t + C4 (u4 )t + D4 .
t = Cω ˙ωt + C3 (u3 )t + D3 ,
Here (gx )b
t are the components of the gravity acceleration vector in each of the
t , (gy )b
t , (gz )b
body-coordinate axes at time t; and C· , D· are the free parameters to be learned from data.
The model predicts accelerations in the body-coordinate frame, and is therefore able to take
advantage of the same invariants as discussed earlier, such as invariance of the dynamics to
the helicopter’s (x, y , z ) position and heading (ω ). Further, it additionally captures the fact
that the dynamics are invariant to roll (φ) and pitch (θ) once the (known) effects of gravity
are subtracted out.

Frequency domain techniques cannot be used to learn the acceleration model above, be-
cause it is non-linear. Nevertheless, the parameters can be learned as easily as for the
linear model in the time domain: Linear regression can be used to ﬁnd the parameters that
minimize the squared error of the one-step prediction in acceleration.2

5 The lagged error criterion
To evaluate the performance of a dynamical model, it is standard practice to run a simula-
tion using the model for a certain duration, and then compare the simulated trajectory with
the real state trajectory. To do well on this evaluation criterion, it is therefore important for
the dynamical model to give not only accurate one-step predictions, but also predictions
that are accurate at longer time-scales. Motivated by this, [1] suggested learning the model
parameters by optimizing the following “lagged criterion”
:
PT −H
t=1 PH
(2)
h=1 kˆst+h|t − st+hk2
2 .
Here, H is the time horizon of the simulation, and ˆst+h|t is the estimate (from simulation)
of the state at time t + h given the state at time t.

2Note that, as discussed previously, the one-step difference of body coordinate velocities is not
the acceleration. To obtain actual accelerations, the velocity at time t + 1 must be rotated into the
body-frame at t before taking the difference.

Unfortunately the EM-algorithm given in [1] is prohibitively expensive in our continuous
state-action space setting. We therefore present a simple and fast algorithm for (approx-
imately) minimizing the lagged criterion. We begin by considering a linear model with
update equation:

st+1 − st = Ast + But ,
where A, B are the parameters of the model. Minimizing the one-step prediction error
would correspond to ﬁnding the parameters that minimize the expected squared difference
between the left and right sides of Eqn. (3).

(3)

By summing the update equations for two consecutive time steps, we get that, for simula-
tion to be exact over two time steps, the following needs to hold:
(4)
st+2 − st = Ast + But + Aˆst+1|t + But+1 .
Minimizing the expected squared difference between the left and right sides of Eqn. (4)
would correspond to minimizing the two-step prediction error. More generally, by sum-
ming up the update equations for h consecutive timesteps and then minimizing the left
and right sides’ expected squared difference, we can minimize the h-step prediction error.
Thus, it may seem that we can directly solve for the parameters that minimize the lagged
criterion of Eqn. (2) by running least squares on the appropriate set of linear combinations
of state update equations.

The difﬁculty with this procedure is that the intermediate s tates in the simulation—for
example, ˆst+1|t in Eqn. (4) —are also an implicit function of the parameters A and B . This
is because ˆst+1|t represents the result of a one-step simulation from st using our model.
Taking into account the dependence of the intermediate states on the parameters makes the
right side of Eqn. (4) non-linear in the parameters, and thus the optimization is non-convex.
If, however, we make an approximation and neglect this dependence, then optimizing the
objective can be done simply by solving a linear least squares problem.

This gives us the following algorithm. We will alternate between a simulation step that
ﬁnds the necessary predicted intermediate states, and a lea st squares step that solves for the
new parameters.
L EARN -LAGG ED -L IN EAR:

1. Use least squares to minimize the one-step squared prediction error criterion to obtain an
initial model A(0) , B (0) . Set i = 1.
2. For all t = 1, . . . , T , h = 1, . . . , H , simulate in the current model to compute ˆst+h|t .
3. Solve the following least squares problem:
( ¯A, ¯B ) = arg minA,B PT −H
h=1 k(st+h − st ) − (Ph−1
t=1 PH
τ =0 Aˆst+τ |t + But+τ )k2
2 .
4. Set A(i+1) = (1 − α)A(i) + α ¯A, B (i+1) = (1 − α)B (i) + α ¯B .3

5. If kA(i+1) − A(i) k + kB (i+1) − B (i) k ≤  exit. Otherwise go back to step 2.

Our helicopter acceleration prediction model is not of the simple form st+1 − st =
Ast + But described above. However, a similar derivation still applies: The change in
velocity over several time-steps corresponds to the sum of changes in velocity over several
single time-steps. Thus by adding the one-step acceleration prediction equations as given
in Section 4, we might expect to obtain equations corresponding to the acceleration over
several time-steps. However, the acceleration equations at different time-steps are in dif-
ferent coordinate frames. Thus we ﬁrst need to rotate the equ ations and then add them. In
the algorithm described below, we rotate all accelerations into the world coordinate frame.
t = Apos st + Bposut , and
The acceleration equations from Section 4 give us ( ¨x, ¨y , ¨z )b

3This step of the algorithm uses a simple line search to choose the stepsize α.

(a)

(b)

Figure 1: The XCell Tempest (a) and the Bergen Industrial Twin (b) used in our experiments.

( ¨φ, ¨θ , ¨ω)b
t = Arot st + Brotut , where Apos , Bpos , Arot , Brot are (sparse) matrices that con-
tain the parameters to be learned.4 This gives us the L EARN -LAGG ED -ACC E L ERAT ION
algorithm, which is identical to L EARN -LAGG ED -L IN EAR except that step 3 now solves
the following least squares problems:
h−1
T −H
H
X
X
X
τ =0
t=1
h=1

ˆRbt+τ →s “( ¨x, ¨y , ¨z )b
t+τ − (Aˆst+τ |t + But+τ )” k2
2

( ¯Apos , ¯Bpos ) = arg min
A,B

k

( ¯Arot , ¯Brot ) = arg min
A,B

h−1
T −H
H
X
X
X
τ =0
t=1
h=1
Here ˆRbt→s denotes the rotation matrix (estimated from simulation using the current
model) from the body frame at time t to the world frame.

t+τ − (Aˆst+τ |t + But+τ )” k2
ˆRbt+τ →s “( ¨φ, ¨θ , ¨ω)b
2

k

6 Experiments

We performed experiments on two RC helicopters: an XCell Tempest and a Bergen Indus-
trial Twin helicopter. (See Figure 1.) The XCell Tempest is a competition-class aerobatic
helicopter (length 54”, height 19”), is powered by a 0.91-si
ze, two-stroke engine, and has
an unloaded weight of 13 pounds. It carries two sensor units: a Novatel RT2 GPS receiver
and a Microstrain 3DM-GX1 orientation sensor. The Microstrain package contains triaxial
accelerometers, rate gyros, and magnetometers, which are used for inertial sensing. The
larger Bergen Industrial Twin helicopter is powered by a twin cylinder 46cc, two-stroke
engine, and has an unloaded weight of 18 lbs.
It carries three sensor units: a Novatel
RT2 GPS receiver, MicroStrain 3DM-G magnetometers, and an Inertial Science ISIS-IMU
(triaxial accelerometers and rate gyros).
For each helicopter, we collected data from two separate ﬂig hts. The XCell Tempest train
and test ﬂights were 800 and 540 seconds long, the Bergen Indu strial Twin train and test
ﬂights were each 110 seconds long. A highly optimized Kalman ﬁlter integrates the sen-
sor information and reports (at 100Hz) 12 numbers corresponding to the helicopter’s state
(x, y , z , ˙x, ˙y , ˙z , φ, θ , ω , ˙φ, ˙θ , ˙ω). The data is then downsampled to 10Hz before learning.
For each of the helicopters, we learned the following models:

1. Linear-One-Step: The linear model from Section 3 trained using linear regression to
minimize the one-step prediction error.
2. Linear-C I FER: The linear model from Section 3 trained using C I F ER .
3. Linear-Lagged: The linear model from Section 3 trained minimizing the lagged criterion.
4. Acceleration-One-Step: The acceleration prediction model from Section 4 trained using
linear regression to minimize the one step prediction error.
5. Acceleration-Lagged: The acceleration prediction model from Section 4 trained mini-
mizing the lagged criterion.

4For simplicity of notation we omit the intercept parameters here, but they are easily incorporated,
e.g., by having one additional input which is always equal to one.

For Linear-Lagged and Acceleration-Lagged we used a horizon H of two seconds (20
simulation steps). The CPU times for training the different algorithms were: Less than one
second for linear regression (algorithms 1 and 4 in the list above); one hour 20 minutes
(XCell Tempest data) or 10 minutes (Bergen Industrial Twin data) for the lagged criteria
(algorithms 3 and 5 above); about 5 minutes for C I F ER. Our algorithm optimizing the
lagged criterion appears to converge after at most 30 iterations. Since this algorithm is only
approximate, we can then use coordinate descent search to further improve the lagged cri-
terion.5 This coordinate descent search took an additional four hours for the XCell Tempest
data and an additional 30 minutes for the Bergen Industrial Twin data. We report results
both with and without this coordinate descent search. Our results show that the algorithm
presented in Section 5 works well for fast approximate optimization of the lagged criterion,
but that locally greedy search (coordinate descent) may then improve it yet further.

For evaluation, the test data was split in consecutive non-overlapping two second windows.
(This corresponds to 20 simulation steps, s0 , . . . , s20 .) The models are used to predict the
state sequence over the two second window, when started in the true state s0 . We report
the average squared prediction error (difference between the simulated and true state) at
each timestep t = 1, . . . , 20 throughout the two second window. The orientation error is
measured by the squared magnitude of the minimal rotation needed to align the simulated
orientation with the true orientation. Velocity, position, angular rate and orientation errors
are measured in m/s, m, rad/s and rad (squared) respectively. (See Figure 2.)
We see that Linear-Lagged consistently outperforms Linear-C I FER and Linear-One-
Step. Similarly, for the acceleration prediction models, we have that Acceleration-
Lagged consistently outperforms Acceleration-One-Step. These experiments support
the case for training with the lagged criterion.
The best acceleration prediction model, Acceleration-Lagged, is signi ﬁcantly more ac-
curate than any of the linear models presented in Section 3. This effect is mostly present
in the XCell Tempest data, which contained data collected from many different parts of
the state space (e.g., ﬂying in a circle); in contrast, the Be rgen Industrial Twin data was
collected mostly near hovering (and thus the linearization assumptions were somewhat less
poor there).

7 Summary

We presented an acceleration based parameterization for learning vehicular dynamics. The
model predicts accelerations, and then integrates to obtain state trajectories. We also de-
scribed an efﬁcient algorithm for approximately minimizin g the lagged criterion, which
measures the predictive accuracy of the algorithm over both short and long time-scales.
In our experiments, learning with the acceleration parameterization and using the lagged
criterion gave signi ﬁcantly more accurate models than prev ious approaches. Using this ap-
proach, we have recently also succeeded in learning a model for, and then autonomously
ﬂying, a “funnel ” aerobatic maneuver, in which the helicopt
er ﬂies in a circle, keeping the
tail pointed at the center of rotation, and the body of the helicopter pitched backwards at a
steep angle (so that the body of the helicopter traces out the surface of a funnel). (Details
will be presented in a forthcoming paper.)

Acknowledgments. We give warm thanks to Adam Coates and to helicopter pilot Ben Tse
for their help on this work.

5We used coordinate descent on the criterion of Eqn. (2), but reweighted the errors on velocity,
angular velocity, position and orientation to scale them to roughly the same order of magnitude.

100

80

60

40

20

y
t
i
c
o
l
e
v

250

200

150

100

50

n
o
i
t
i
s
o
p

XCell Tempest
1

e
t
a
r
 
r
a
l
u
g
n
a

0.8

0.6

0.4

0.2

1.4

1.2

1

0.8

0.6

0.4

0.2

n
o
i
t
a
t
n
e
i
r
o

0

0

0.5

1.5

2

1
t (s)

0

0

0.5

1
t (s)

1.5

2

0

0

0.5

1
t (s)

1.5

2

0

0

0.5

1.5

2

1
t (s)

2.5

2

1.5

1

0.5

y
t
i
c
o
l
e
v

3

2.5

2

1.5

1

0.5

n
o
i
t
i
s
o
p

Bergen Industrial Twin
0.06

e
t
a
r
 
r
a
l
u
g
n
a

0.05

0.04

0.03

0.02

0.01

0.015

0.01

0.005

n
o
i
t
a
t
n
e
i
r
o

0

0

0.5

1.5

2

1
t (s)

0

0

0.5

1
t (s)

1.5

2

0

0

0.5

1
t (s)

1.5

2

0

0

0.5

1.5

2

1
t (s)

Figure 2: (Best viewed in color.) Average squared prediction errors throughout two-second sim-
ulations. Blue, dotted: Linear-One-Step. Green, dash-dotted: Linear-C I FER. Yellow, triangle:
Linear-Lagged learned with fast, approximate algorithm from Section 5. Red, dashed: Linear-
Lagged learned with fast, approximate algorithm from Section 5 followed by greedy coordinate de-
scent search. Magenta, solid: Acceleration-One-Step. Cyan, circle: Acceleration-Lagged learned
with fast, approximate algorithm from Section 5. Black,*: Acceleration-Lagged learned with fast,
approximate algorithm from Section 5 followed by greedy coordinate descent search. The magenta,
cyan and black lines (visually) coincide in the XCell position plots. The blue, yellow, magenta and
cyan lines (visually) coincide in the Bergen angular rate and orientation plots. The red and black lines
(visually) coincide in the Bergen angular rate plot. See text for details.

References
[1] P. Abbeel and A. Y. Ng. Learning ﬁrst order Markov models for control. In NIPS 18, 2005.
[2] J. Bagnell and J. Schneider. Autonomous helicopter control using reinforcement learning policy
search methods. In International Conference on Robotics and Automation. IEEE, 2001.
[3] V. Gavrilets, I. Martinos, B. Mettler, and E. Feron. Control logic for automated aerobatic ﬂight
of miniature helicopter. In AIAA Guidance, Navigation and Control Conference, 2002.
[4] V. Gavrilets, I. Martinos, B. Mettler, and E. Feron. Flight test and simulation results for an
autonomous aerobatic helicopter. In AIAA/IEEE Digital Avionics Systems Conference, 2002.
[5] J. Leishman. Principles of Helicopter Aerodynamics. Cambridge University Press, 2000.
[6] B. Mettler, M. Tischler, and T. Kanade. System identiﬁcation of small-s ize unmanned helicopter
dynamics. In American Helicopter Society, 55th Forum, 1999.
[7] Andrew Y. Ng, Adam Coates, Mark Diel, Varun Ganapathi, Jamie Schulte, Ben Tse, Eric
Berger, and Eric Liang. Autonomous inverted helicopter ﬂight via reinfo rcement learning. In
International Symposium on Experimental Robotics, 2004.
[8] Andrew Y. Ng, H. Jin Kim, Michael Jordan, and Shankar Sastry. Autnonomous helicopter ﬂight
via reinforcement learning. In NIPS 16, 2004.
[9] Jonathan M. Roberts, Peter I. Corke, and Gregg Buskey. Low-cost ﬂight control system for a
small autonomous helicopter. In IEEE Int’l Conf. on Robotics and Automation, 2003.
[10] J. Seddon. Basic Helicopter Aerodynamics. AIAA Education Series. America Institute of
Aeronautics and Astronautics, 1990.
[11] M.B. Tischler and M.G. Cauffman. Frequency response method for rotorcraft system identiﬁ-
cation: Flight application to BO-105 couple rotor/fuselage dynamics. Journal of the American
Helicopter Society, 1992.

