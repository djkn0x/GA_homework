Learning Cue-Invariant Visual Responses

Jarmo Hurri
HIIT Basic Research Unit, University of Helsinki
P.O.Box 68, FIN-00014 University of Helsinki, Finland

Abstract

Multiple visual cues are used by the visual system to analyze a scene;
achromatic cues include luminance, texture, contrast and motion. Single-
cell recordings have shown that the mammalian visual cortex contains
neurons that respond similarly to scene structure (e.g., orientation of
a boundary), regardless of the cue type conveying this information.
This paper shows that cue-invariant response properties of simple- and
complex-type cells can be learned from natural image data in an unsuper-
vised manner. In order to do this, we also extend a previous conceptual
model of cue invariance so that it can be applied to model simple- and
complex-cell responses. Our results relate cue-invariant response proper-
ties to natural image statistics, thereby showing how the statistical mod-
eling approach can be used to model processing beyond the elemental
response properties visual neurons. This work also demonstrates how to
learn, from natural image data, more sophisticated feature detectors than
those based on changes in mean luminance, thereby paving the way for
new data-driven approaches to image processing and computer vision.

1

Introduction

When segmenting a visual scene, the brain utilizes a variety of visual cues. Spatiotempo-
ral variations in the mean luminance level (cid:150) which are also called (cid:2)rst-order cues (cid:150) are
computationally the simplest of these; the name ’(cid:2)rst-order’ comes from the idea that a
single linear (cid:2)ltering operation can detect these cues. Other types of visual cues include
contrast, texture and motion; in general, cues related to variations in other characteristics
than mean luminance are called higher-order (also called non-Fourier) cues; the analysis of
these is thought to involve more than one level of processing/(cid:2)ltering. Single-cell record-
ings have shown that the mammalian visual cortex contains neurons that are selective to
both (cid:2)rst- and higher-order cues. For example, a neuron may exhibit similar selectivity
to the orientation of a boundary, regardless of whether the boundary is a result of spatial
changes in mean luminance or contrast [1]. Monkey cortical areas V1 and V2, and cat cor-
tical areas 17 and 18, contain both simple- (orientation-, frequency- and phase-selective)
and complex-type (orientation- and frequency-selective, phase-invariant) cells that exhibit
such cue-invariant response properties [2, 1, 3, 4, 5]. Previous research has been unable to
pinpoint the connectivity that gives rise to cue-invariant responses.
Recent computational modeling of the visual system has produced fundamental results
relating stimulus statistics to (cid:2)rst-order response properties of simple and complex cells
(see, e.g., [6, 7, 8, 9]). The contribution of this paper is to introduce a similar, natural image

A

First stage
filters

Rectification

Second stage
filters

Nonlinear
stream

Linear
stream

IMAGE

IMAGE

Integration

B

Input

Simple-

cell

level

Complex-

cell

level

Complex-

cell

output

First-order

Feedback

cells

path

IMAGE

a,c

b,d

Cue-invariant

cells

IMAGE

g

+

e

f

h

+

+

+

Figure 1: (A) The two-stream model [1], with a linear stream (on the right) and a nonlinear
stream (on the left). The linear stream responds to (cid:2)rst-order cues, while the nonlinear
stream responds to higher-order cues.
In the nonlinear stream, the stimulus (image) is
(cid:2)rst (cid:2)ltered with multiple high-frequency (cid:2)lters, whose outputs are transformed nonlin-
early (recti(cid:2)ed), and subsequently used as inputs for a second-stage (cid:2)lter. Cue-invariant
(B) Our
responses are obtained when the outputs of these two streams are integrated.
model of cue-invariant responses. The model consists of simple cells, complex cells and
a feedback path leading from a population of high-frequency (cid:2)rst-order complex cells to
low-frequency cue-invariant simple cells. In a cue-invariant simple cell, the feedback is
(cid:2)ltered with a (cid:2)lter that has similar spatial characteristics as the feedforward (cid:2)lter of the
cell. The output of a cue-invariant simple cell is given by the sum of the linearly (cid:2)ltered
input and the (cid:2)ltered feedback. Note that while our model results in cue-invariant response
properties, it is not a model of cue integration, because in the sum the two paths can can-
cel out. However, this simpli(cid:2)cation does not affect our results, that is, learning, since
the summed output is not used in learning (see Section 3), or measurements, which excite
only one of the paths signi(cid:2)cantly and do not consider integration effects (see Figures 3
and 4). In this instance of the model, the high-frequency cells prefer horizontal stimuli,
while the low-frequency cue-invariant cells prefer vertical stimuli; in other instances, this
relationship can be different. For actual (cid:2)lters used in an implementation of this model, see
Figure 2. Lowercase letters a(cid:150)g refer to the corresponding sub(cid:2)gures in Figure 2.

statistics -based framework for cue-invariant responses of both simple and complex cells.
In order to achieve this, we also extend the two-stream model of cue-invariant responses
(Figure 1A) to account for cue-invariant responses at both simple- and complex-cell levels.
The rest of this paper is organized as follows. In Section 2 we describe our version of the
two-stream model of cue-invariant responses, which is based on feedback from complex
cells to simple cells. In Section 3 we formulate an unsupervised learning rule for learning
these feedback connections. We apply our learning rule to natural image data, and show
that this results in the emergence of connections that give rise to cue-invariant responses at
both simple- and complex-cell levels. We end this paper with conclusions in Section 4.

2 A model of cue-invariant responses

The most prominent model of cue-invariant responses introduced in previous research is
the two-stream model (see, e.g., [1]), depicted in Figure 1A. In this research we have ex-
tended this model so that it can be applied directly to model the cue-invariant responses of
simple and complex cells. Our model, shown in Figure 1B, employs standard linear-(cid:2)lter

c

d

a

b

e

g

f

h

Figure 2: The (cid:2)lters used in an implementation of our model. The reader is referred to
Figure 1B for the correspondence between sub(cid:2)gures (a)(cid:150)(h) and the schematic model of
Figure 1B. (a) The feedforward (cid:2)lter (Gabor function [10]) of a high-frequency (cid:2)rst-order
simple cell; the (cid:2)lter has size 19 (cid:2) 19 pixels, which is the size of the image data in our
experiments. (b) The feedforward (cid:2)lter of another (cid:2)rst-order simple cell. This feedforward
(cid:2)lter is otherwise similar to the one in (a), except that there is a phase difference of (cid:25)=2
between the two; together, the feedforward (cid:2)lters in (a) and (b) are used to implement an
energy model of a complex cell. (c) A lattice of size 7 (cid:2) 7 of high-frequency (cid:2)lters of the
type shown in (a); these (cid:2)lters are otherwise identical, except that their spatial locations
vary. (d) A lattice of (cid:2)lters of the type shown in (b). Together, the lattices shown in (c)
and (d) are used to implement a 7 (cid:2) 7 lattice of energy-model complex cells with different
spatial positions; the output of this lattice is the feedback relayed to the low-frequency cue-
invariant cells. (e,f ) Feedforward (cid:2)lters of low-frequency simple cells. (g) A feedback
(cid:2)lter of size 7 (cid:2) 7 for the simple cell whose feedforward (cid:2)lter is shown in (e); in order to
avoid confusion between feedforward (cid:2)lters and feedback (cid:2)lters, the latter are visualized
as lattices of slightly rounded rectangles. (h) A feedback (cid:2)lter for the simple cell whose
feedforward (cid:2)lter is shown in (f). The feedback (cid:2)lters in (g) and (h) have been obtained by
applying the learning algorithm introduced in this paper (see Section 3 for details).

models of simple cells and energy models of complex cells [10], and a feedback path from
the complex-cell level to the simple-cell level. This feedback path introduces a second,
nonlinear input stream to cue-invariant cells, and gives rise to cue-invariant responses in
these cells. To avoid confusion between the two types of (cid:2)lters (cid:150) one type operating on
the input image and the other on the feedback (cid:150) we will use the term ’feedforward (cid:2)lter’
for the former and the term ’feedback (cid:2)lter’ for the latter. Figure 2 shows the feedforward
and feedback (cid:2)lters of a concrete instance (implementation) of our model. Gabor functions
[10] are used to model simple-cell feedforward (cid:2)lters.
Figure 3 illustrates the design of higher-order gratings, and shows how the complex-cell
lattice of the model transforms higher-order cues into feedback activity patterns that re-
semble corresponding (cid:2)rst-order cues. A quantitative evaluation of the model is given
in Figure 4. These measurements show that our model possesses the fundamental cue-
invariant response properties: in our model, a cue-invariant neuron has similar selectivity
to the orientation, frequency and phase of a grating stimulus, regardless of cue type (see
(cid:2)gure caption for details). We now proceed to show how the feedback (cid:2)lters of our model
(Figures 2g and h) can be learned from natural image data.

3 Learning feedback connections in an unsupervised manner

3.1 The objective function and the learning algorithm

In this section we introduce an unsupervised algorithm for learning feedback connection
weights from complex cells to simple cells. When this learning algorithm is applied to
natural image data, the resulting feedback (cid:2)lters are those shown in Figures 2g and h (cid:150) as

cue type

luminance

texture

contrast

A

D

I

sinusoidal constituents
of stimulus

stimulus
[equation]
B

feedback
activity
C

E

J

F

[=A]
G

[=DE+(1-D)F]
K

[=IJ]

H

L

Figure 3: The design of grating stimuli with different cues, and the feedback activity for
these gratings. Design of grating stimuli: Each row illustrates how, for a particular cue, a
grating stimulus is composed of sinusoidal constituents; the equation of each stimulus (B,
G, K) as a function of the constituents is shown under the stimulus. Note that the orienta-
tion, frequency and phase of each grating is determined by the (cid:2)rst sinusoidal constituent
(A, D, I); here these parameters are the same for all stimuli. Here (E) and (F) are two
different textures, and (I) is called the envelope and (J) the carrier of a contrast-de(cid:2)ned
stimulus. Feedback activity: The rightmost column shows the feedback activity (cid:150) that is,
response of the complex-cell lattice (see Figures 2c and d) (cid:150) for the three types of stimuli.
(C) There is no response to the luminance stimuli, since the orientation and frequency of
the stimulus are different from those of the high-frequency feedforward (cid:2)lters. (H, L) For
other cue types, the lattice detects the locations of energy of the vertical high-frequency
constituent (E, J), thereby resulting in feedback activity that has a spatial pattern similar to
a corresponding luminance pattern (A). Thus, the complex-cell lattice transforms higher-
order cues into activity patterns that resemble (cid:2)rst-order cues, and these can subsequently
produce a strong response in a feedback (cid:2)lter (compare (H) and (L) with the feedback (cid:2)lter
in Figure 2g). For a quantitative evaluation of the model with these stimuli, see Figure 4.

was shown in Figure 4, these feedback (cid:2)lters give rise to cue-invariant response properties.
The intuitive idea behind the learning algorithm is the following: in natural images, higher-
order cues tend to coincide with (cid:2)rst-order cues. For example, when two different textures
are adjacent, there is often also a luminance border between them; two examples of this
phenomenon are shown in Figure 5. Therefore, cue-invariant response properties could
be a result of learning in which large responses in the feedforward channel ((cid:2)rst-order
responses) have become associated with large responses in the feedback channel (higher-
order responses). Previous research has demonstrated the importance of such energy de-
pendencies in modeling the visual system (see, e.g., [11, 9, 12, 13, 14]).
To turn this idea into equations, let us introduce some notation. Let vector c(n) =
[c1 (n) c2 (n) (cid:1) (cid:1) (cid:1) cK (n)]T denote the responses of a set of K (cid:2)rst-order high-frequency
complex cells for the input image with index n: In our case the number of these complex
cells is K = 7 (cid:2) 7 = 49 (see Figures 2c and d), so the dimension of this vector is 49.
This vectorization can be done in a standard manner [15] by scanning values from the 2D
lattice column-wise into a vector; when the learned feedback (cid:2)lter is visualized, the (cid:2)lter
is (cid:147)unvectorized(cid:148) with a reverse procedure. Let s(n) denote the response of a single low-

standard
simple cell
(without feedback)

0
(cid:25)=2
cue orientation

(cid:25)

1

0

1

0

0
0.1 0.2 0.3
cue frequency

1

0

(cid:0)1

(cid:25)
0
cue phase

2(cid:25)

C

e
s
n
o
p
s
e
r

F
e
s
n
o
p
s
e
r

I
e
s
n
o
p
s
e
r

cue-invariant
simple cell
(with feedback)

1

0

1

0

0
(cid:25)=2
cue orientation

(cid:25)

0
0.1 0.2 0.3
cue frequency

(cid:25)
0
cue phase

2(cid:25)

1

0

(cid:0)1

0.5

0

0
(cid:25)=2
carrier orientation

(cid:25)

0.5

0

0
0.1 0.2 0.3
carrier frequency

A

e
s
n
o
p
s
e
r

D
e
s
n
o
p
s
e
r

G
e
s
n
o
p
s
e
r

J

e
s
n
o
p
s
e
r

L
e
s
n
o
p
s
e
r

cue-invariant
complex cell
(with feedback)

0
(cid:25)=2
cue orientation

(cid:25)

0
0.1 0.2 0.3
cue frequency

1

0

1

0

1

0

0

(cid:25)
cue phase

2(cid:25)

0.5

0

0
(cid:25)=2
carrier orientation

(cid:25)

0.5

0

0
0.1 0.2 0.3
carrier frequency

B

e
s
n
o
p
s
e
r

E
e
s
n
o
p
s
e
r

H
e
s
n
o
p
s
e
r

K

e
s
n
o
p
s
e
r

M
e
s
n
o
p
s
e
r

Figure 4: Our model ful(cid:2)lls the fundamental properties of cue-invariant responses. The
plots show tuning curves for a cue-invariant simple cell (cid:150) corresponding to the (cid:2)lters of
Figures 2e and g (cid:150) and complex cell of our new model (two leftmost columns), and a
standard simple-cell model without feedback processing (rightmost column). Solid lines
show responses to luminance-de(cid:2)ned gratings (Figure 3B), dotted lines show responses to
texture-de(cid:2)ned gratings (Figure 3G), and dashed lines show responses to contrast-de(cid:2)ned
gratings (Figure 3K). (A(cid:150)I) In our model, a neuron has similar selectivity to the orien-
tation, frequency and phase of a grating stimulus, regardless of cue type; in contrast, a
standard simple-cell model, without the feedback path, is only selective to the parameters
of a luminance-de(cid:2)ned grating. The preferred frequency is lower for higher-order gratings
than for (cid:2)rst-order gratings; similar observations have been made in single-cell recordings
[4]. (J(cid:150)M) In our model, the neurons are also selective to the orientation and frequency
of the carrier (Figure 3J) of a contrast-de(cid:2)ned grating (Figure 3K), thus conforming with
single-cell recordings [1]. Note that these measurements were made with the feedback
(cid:2)lters learned by our unsupervised algorithm (see Section 3); thus, these measurements
con(cid:2)rm that learning results in cue-invariant response properties.

A

B

A

F

B

G

C

H

D

I

E

J

Figure 5: Two examples of co-
inciding (cid:2)rst- and higher-order
Image in (A)
boundary cues.
contains a near-vertical
lumi-
nance boundary across the im-
age; the boundary in (B) is near-
horizontal. In both (A) and (B),
texture is different on different
sides of the luminance border.
(For image source, see [8].)

Figure 6: (A-D, F-I) Feedback (cid:2)lters (top row)
learned from natural image data by using our un-
supervised learning algorithm;
the bottom row
shows the corresponding feedforward (cid:2)lters. For
a quantitative evaluation of the cue-invariant re-
sponse properties resulting from the learned (cid:2)l-
ters (A) and (B), see Figure 4. (E, J) The result
of a control experiment, in which Gaussian white
noise was used as input data; (J) shows the feed-
forward (cid:2)lter used in this control experiment.

(1)

frequency simple cell for the input image with index n: In our learning algorithm all the
feedforward (cid:2)lters are (cid:2)xed and only a feedback (cid:2)lter is learned; this means that c(n) and
s(n) can be computed for all n (all images) prior to applying the learning algorithm.
Let us denote the K -dimensional feedback (cid:2)lter with w ; this (cid:2)lter is learned by our algo-
rithm. Let b(n) = wT c(n); that is, b(n) is the signal obtained when the feedback activity
from the complex-cell lattice is (cid:2)ltered with the feedback (cid:2)lter; the overall activity of a cue-
invariant simple cell is then s(n) + b(n): Our objective function measures the correlation
of energies of the feedforward response s(n) and the feedback response b(n):
f (w) = E (cid:8)s2 (n)b2 (n)(cid:9) = wT E (cid:8)s2 (n)c(n)c(n)T (cid:9) w = wT M w ;
where M = E (cid:8)s2 (n)c(n)c(n)T (cid:9) is a positive-semide(cid:2)nite matrix that can be computed
from samples prior to learning. To keep the output of the feedback (cid:2)lter b(n) bounded, we
enforce a unit energy constraint on b(n), leading into constraint
h(w) = E (cid:8)b2 (n)(cid:9) = wT E (cid:8)c(n)c(n)T (cid:9) w = wT Cw = 1;
where C = E (cid:8)c(n)c(n)T (cid:9) is also positive-semide(cid:2)nite and can be computed prior to
learning. The problem of maximizing objective (1) with constraint (2) is a well-known
quadratic optimization problem with a norm constraint, the solution of which is given by
an eigenvalue-eigenvector problem (see below). However, in order to handle the case where
C is not invertible (cid:150) which will be the case below in our experiments (cid:150) and to attenuate
the noise in the data, we (cid:2)rst use a technique called dimensionality reduction (see, e.g.,
[15]). Let C = EDE T be the eigenvalue decomposition of C ; in the decomposition, the
eigenvectors corresponding to the r smallest eigenvalues (subspaces with smallest energy;
the exact value for r is given in Section 3.2) have been dropped out, so E is a K (cid:2) (K (cid:0) r)
matrix of K (cid:0) r eigenvectors and D is a (K (cid:0) r) (cid:2) (K (cid:0) r) diagonal matrix containing
the largest eigenvalues. Now let v = D 1=2E T w . A one-to-one correspondence between
v and w can be formed by using the pseudoinverse solution w = ED(cid:0)1=2v : Now let
z (n) = D(cid:0)1=2E T c(n): Using these de(cid:2)nitions of v and z (n); it is straightforward to
show that the objective and constraint become f (v) = v T E (cid:8)s2 (n)z (n)z (n)T (cid:9) v and
h(v) = kvk2 = 1: The global maximum v opt is the eigenvector of E (cid:8)s2 (n)z (n)z (n)T (cid:9)
that corresponds to the largest eigenvalue.

(2)

In practice learning from sampled data s(n) and c(n) proceeds as follows. First the eigen-
value decomposition of C is computed. Then the transformed data set z (n) is computed,
and v opt is calculated from the eigenvalue-eigenvector problem. Finally, the optimal (cid:2)lter
wopt is obtained from the pseudoinverse relationship. In learning from sampled data, all
expectations are replaced with sample averages.

3.2 Experiments

The algorithm described above was applied to natural image data, which was sampled from
a set of over 4,000 natural images [8]. The size of the sampled image patches was 19 (cid:2) 19
pixels, and the number of samples was 250,000. The local mean (DC component) was
removed from each image sample.
Simple-cell feedforward responses s(n) were computed using the (cid:2)lter shown in Figure 2e,
and the set of high-frequency complex-cell lattice activities c(n) was computed using the
(cid:2)lters shown in Figures 2c and d. A form of contrast gain control [16], which can be used
to compensate for the large variation in contrast in natural images, was also applied to the
natural image data: prior to (cid:2)ltering a natural image sample with a feedforward (cid:2)lter, the
energy of the image was normalized inside the Gaussian modulation window of the Gabor
function [10] of the feedforward (cid:2)lter. This preprocessing tends to weaken contrast bor-
ders, implying that in our experiments, learning higher-order responses is mostly based on
texture boundaries that coincide with luminance boundaries. It should be noted, however,
that in spite of this preprocessing step, the resulting feedback (cid:2)lters produce cue-invariant
responses to both texture- and contrast-de(cid:2)ned cues (see Figure 4). In order to make the
components of c(n) have zero mean, and focus on the structure of feedback activity pat-
terns instead of overall constant activation, the local mean (DC component) was removed
from each c(n): To attenuate the noise in the data, the dimensionality of c(n) was reduced
to 16 (see Section 3.1); this retains 85% of original signal energy.
The algorithm described in Section 3.1 was then applied to this data. The resulting feed-
back (cid:2)lter is shown in Figure 6A (see also Figure 2g). Data sampling, preprocessing and
the learning algorithm were then repeated, but this time using the feedforward (cid:2)lter shown
in Figure 2f; the feedback (cid:2)lter obtained from this run is shown in Figure 6B (see also
Figure 2h). The measurements in Figure 4 show that these feedback (cid:2)lters result in cue-
invariant response properties at both simple- and complex-cell levels. Thus, our unsu-
pervised algorithm learns cue-invariant response properties from natural image data. The
results shown in Figures 6C and D were obtained with feedforward (cid:2)lters whose orienta-
tion was different from vertical, demonstrating that the observed phenomenon applies to
other orientations also (in these experiments, the orientation of the high-frequency (cid:2)lters
was orthogonal to that of the low-frequency feedforward (cid:2)lter).
To make sure that the results shown in Figures 6A(cid:150)D are not a side effect of the preprocess-
ing or the structure of our model, but truly re(cid:3)ect the statistical properties of natural image
data, we ran a control experiment by repeating our (cid:2)rst experiment, but using Gaussian
white noise as input data (instead of natural image data). All other steps, including pre-
processing and dimensionality reduction, were the same as in the original experiment. The
result is shown in Figure 6E; as can be seen, the resulting (cid:2)lter lacks any spatial structure.
This veri(cid:2)es that our original results do re(cid:3)ect the statistics of natural image data.

4 Conclusions

This paper has shown that cue-invariant response properties can be learned from natural
image data in an unsupervised manner. The results were based on a model in which there is
a feedback path from complex cells to simple cells, and an unsupervised algorithm which
maximizes the correlation of the energies of the feedforward and (cid:2)ltered feedback signals.

The intuitive idea behind the algorithm is that in natural visual stimuli, higher-order cues
tend to coincide with (cid:2)rst-order cues. Simulations were performed to validate that the
learned feedback (cid:2)lters give rise to in cue-invariant response properties.
Our results are important for three reasons. First, for the (cid:2)rst time it has been shown that
cue-invariant response properties of simple and complex cells emerge from the statistical
properties of natural images. Second, our results suggest that cue invariance can result from
feedback from complex cells to simple cells; no feedback from higher cortical areas would
thus be needed. Third, our research demonstrates how higher-order feature detectors can
be learned from natural data in an unsupervised manner; this is an important step towards
general-purpose data-driven approaches to image processing and computer vision.

Acknowledgments

The author thanks Aapo Hyv(cid:228)rinen and Patrik Hoyer for their valuable comments. This
research was supported by the Academy of Finland (project #205742).

References
[1] I. Mareschal and C. Baker, Jr. A cortical locus for the processing of contrast-de(cid:2)ned contours.
Nature Neuroscience 1(2):150(cid:150)154, 1998.
[2] Y.-X. Zhou and C. Baker, Jr. A processsing stream in mammalian visual cortex neurons for
non-Fourier responses. Science 261(5117):98(cid:150)101, 1993.
[3] A. G. Leventhal, Y. Wang, M. T. Schmolesky, and Y. Zhou. Neural correlates of boundary
perception. Visual Neuroscience 15(6):1107(cid:150)1118, 1998.
[4] I. Mareschal and C. Baker, Jr. Temporal and spatial response to second-order stimuli in cat area
18. Journal of Neurophysiology 80(6):2811(cid:150)2823, 1998.
[5] J. A. Bourne, R. Tweedale, and M. G. P. Rosa. Physiological responses of New World monkey
V1 neurons to stimuli de(cid:2)ned by coherent motion. Cerebral Cortex 12(11):1132(cid:150)1145, 2002.
[6] B. A. Olshausen and D. Field. Emergence of simple-cell receptive (cid:2)eld properties by learning
a sparse code for natural images. Nature 381(6583):607(cid:150)609, 1996.
[7] A. Bell and T. J. Sejnowski. The independent components of natural scenes are edge (cid:2)lters.
Vision Research 37(23):3327(cid:150)3338, 1997.
[8] J. H. van Hateren and A. van der Schaaf. Independent component (cid:2)lters of natural images com-
pared with simple cells in primary visual cortex. Proceedings of the Royal Society of London B
265(1394):359(cid:150)366, 1998.
[9] A. Hyv(cid:228)rinen and P. O. Hoyer. A two-layer sparse coding model learns simple and complex
cell receptive (cid:2)elds and topography from natural images. Vision Research 41(18):2413(cid:150)2423,
2001.
[10] P. Dayan and L. F. Abbott. Theoretical Neuroscience. The MIT Press, 2001.
[11] O. Schwartz and E. P. Simoncelli. Natural signal statistics and sensory gain control. Nature
Neuroscience 4(8):819(cid:150)825, 2001.
[12] J. Hurri and A. Hyv(cid:228)rinen. Simple-cell-like receptive (cid:2)elds maximize temporal coherence in
natural video. Neural Computation 15(3):663(cid:150)691, 2003.
[13] J. Hurri and A. Hyv(cid:228)rinen. Temporal and spatiotemporal coherence in simple-cell responses:
a generative model of natural image sequences. Network: Computation in Neural Systems
14(3):527(cid:150)551, 2003.
[14] Y. Karklin and M. S. Lewicki. Higher-order structure of natural images. Network: Computation
in Neural Systems 14(3):483(cid:150)499, 2003.
[15] A. Hyv(cid:228)rinen, J. Karhunen, and E. Oja. Independent Component Analysis. John Wiley & Sons,
2001.
[16] D. J. Heeger. Normalization of cell responses in cat striate cortex. Visual Neuroscience
9(2):181(cid:150)197, 1992.

