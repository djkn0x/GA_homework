A Connectionist Model for Constructive
Modal Reasoning

Artur S. d’Avila Garcez
Department of Computing, City University London
London EC1V 0HB, UK
aag@soi.city.ac.uk

Lu´ıs C. Lamb
Institute of Informatics, Federal University of Rio Grande do Sul
Porto Alegre RS, 91501-970, Brazil
LuisLamb@acm.org

Dov M. Gabbay
Department of Computer Science, King’s College London
Strand, London, WC2R 2LS, UK
dg@dcs.kcl.ac.uk

Abstract

We present a new connectionist model for constructive, intuitionistic
modal reasoning. We use ensembles of neural networks to represent in-
tuitionistic modal theories, and show that for each intuitionistic modal
program there exists a corresponding neural network ensemble that com-
putes the program. This provides a massively parallel model for intu-
itionistic modal reasoning, and sets the scene for integrated reasoning,
knowledge representation, and learning of intuitionistic theories in neural
networks, since the networks in the ensemble can be trained by examples
using standard neural learning algorithms.

1

Introduction

Automated reasoning and learning theory have been the subject of intensive investigation
since the early developments in computer science [14]. However, while (machine) learn-
ing has focused mainly on quantitative and connectionist approaches [16], the reasoning
component of intelligent systems has been developed mainly by formalisms of classical
and non-classical logics [7, 9]. More recently, the recognition of the need for systems that
integrate reasoning and learning into the same foundation, and the evolution of the ﬁelds of
cognitive and neural computation, has led to a number of proposals that attempt to integrate
reasoning and learning [1, 3, 12, 13, 15].

We claim that an effective integration of reasoning and learning can be obtained by neural-
symbolic learning systems [3, 4]. Such systems concern the application of problem-speci ﬁc
symbolic knowledge within the neurocomputing paradigm. By integrating logic and neural

networks, they may provide (i) a sound logical characterisation of a connectionist system,
(ii) a connectionist (parallel) implementation of a logic, or (iii) a hybrid learning system
bringing together advantages from connectionism and symbolic reasoning.

Intuitionistic logical systems have been advocated by many as providing adequate logical
foundations for computation (see [2] for a survey). We argue, therefore, that intuitionism
could also play an important part in neural computation. In this paper, we follow the re-
search path outlined in [4, 5], and develop a computational model for integrated reasoning,
representation, and learning of intuitionistic modal knowledge. We concentrate on reason-
ing and knowledge representation issues, which set the scene for connectionist intuitionistic
learning, since effective knowledge representation should precede learning [15]. Still, we
base the representation on standard, simple neural network architectures, aiming at future
work on experimental learning within the model proposed here.

A key contribution of this paper is the proposal to shift the notion of logical implication
(and negation) in neural networks from the standard notion of implication as a partial func-
tion from input to output (and of negation as failure to activate a neuron), to an intuitionistic
notion which we will see can be implemented in neural networks if we make use of network
ensembles. We claim that the intuitionistic interpretation introduced here will make sense
for a number of problems in neural computation in the same way that intuitionistic logic is
more appropriate than classical logic in a number of computational settings. We will start
by illustrating the proposed computational model in an appropriate constructive reasoning,
distributed knowledge representation scenario, namely, the wise men puzzle [7]. Then, we
will show how ensembles of Connectionist Inductive Learning and Logic Programming
(C-ILP) networks [3] can compute intuitionistic modal knowledge. The networks are set
up by an Intuitionistic Modal Algorithm introduced in this paper. A proof that the algorithm
produces a neural network ensemble that computes a semantics of its associated intuitionis-
tic modal theory is then given. Furthermore, the networks in the ensemble are kept simple
and in a modular structure, and may be trained from examples with the use of standard
learning algorithms such as backpropagation [11].

In Section 2, we present the basic concepts of intuitionistic reasoning used in the paper. In
Section 3, we motivate the proposed model using the wise men puzzle. In Section 4, we
introduce the Intuitionistic Modal Algorithm, which translates intuitionistic modal theories
into neural network ensembles, and prove that the ensemble computes a semantics of the
theory. Section 5 concludes the paper and discusses directions for future work.

2 Background

In this section, we present some basic concepts of arti ﬁcial neural networks and intuition-
istic programs used throughout the paper. We concentrate on ensembles of single hidden
layer feedforward networks, and on recurrent networks typically with feedback only from
the output to the input layer. Feedback is used with the sole purpose of denoting that the
output of a neuron should serve as the input of another neuron when we run the network,
i.e. the weight of any feedback connection is ﬁxed at 1. We use bipolar semi-linear acti-
vation functions h(x) =
1+e−βx − 1 with inputs in {−1, 1}. Throughout, we will use 1 to
2
denote truth-value true, and −1 to denote truth-value f alse.
Intuitionistic logic was originally developed by Brouwer, and later by Heyting and Kol-
mogorov [2]. In intuitionistic logics, a statement that there exists a proof of a proposition
x is only made if there is a constructive method of the proof of x. One of the consequences
of Brouwer’s ideas is the rejection of the law of the excluded middle, namely α ∨ ¬α, since
one cannot always state that there is a proof of α or of its negation, as accepted in classi-
cal logic and in (classical) mathematics. The development of these ideas and applications
in mathematics has led to developments in constructive mathematics and has inﬂuenced

several lines of research on logic and computing science [2].

An intuitionistic modal language L includes propositional letters (atoms) p, q , r..., the con-
nectives ¬, ∧, an intuitionistic implication ⇒, the necessity (¤) and possibility (♦) modal
operators, where an atom will be necessarily true in a possible world if it is true in every
world that is related to this possible world, while it will be possibly true if it is true in some
world related to this world. Formally, we interpret the language as follows, where formulas
are denoted by α, β , γ ...

Deﬁnition 1
(Kripke Models for Intuitionistic Modal Logic) Let L be an intuitionistic
language. A model for L is a tuple M = hΩ, R, vi where Ω is a set of worlds, v is a
mapping that assigns to each ω ∈ Ω a subset of the atoms of L, and R is a reﬂexive,
transitive, binary relation over Ω, such that: (a) (M, ω) |= p iff p ∈ v(ω) (for atom p);
(b) (M, ω) |= ¬α iff for all ω ′ such that R(ω , ω ′ ), (M, ω ′ ) 6² α; (c) (M, ω) |= α ∧ β iff
(M, ω) |= α and (M, ω) |= β ; (d) (M, ω) |= α ⇒ β iff for all ω ′ with R(ω , ω ′ ) we have
(M, ω ′ ) |= β whenever we have (M, ω ′ ) |= α; (e) (M, ω) |= ¤α iff for all ω ′ ∈ Ω if
R(ω , ω ′ ) then (M, ω ′ ) |= α; (f) (M, ω) |= ♦α iff there exists ω ′ ∈ Ω such that R(ω , ω ′ )
and (M, ω ′ ) |= α.

We now deﬁne labelled intuitionistic programs as sets of intuitionistic rules, where each
rule is labelled by the world at which it holds, similarly to Gabbay’s Labelled Deductive
Systems [8].

Deﬁnition 2
(Labelled Intuitionistic Program) A Labelled Intuitionistic Program is a ﬁnite
set of rules C of the form ωi : A1 , ..., An ⇒ A0 (where “ ,” abbreviates “ ∧”, as usual),
and a ﬁnite set of relations R between worlds ωi (1 ≤ i ≤ m) in C , where Ak (0 ≤ k ≤ n)
are atoms and ωi is a label representing a world in which the associated rule holds.

To deal with intuitionistic negation, we adopt the approach of [10], as follows. We rename
any negative literal ¬A as an atom A′ not present originally in the language. This form of
renaming allows our deﬁnition of labelled intuitionistic p rograms above to consider atoms
only. For example, given A1 , ..., A′
k , ..., An ⇒ A0 , where A′
k is a renaming of ¬Ak , an
interpretation that assigns true to A′
k represents that ¬Ak is true; it does not represent that
Ak is false. Following Deﬁnition 1 (intuitionistic negation) , A′ will be true in a world ωi if
and only if A does not hold in every world ωj such that R(ωi , ωj ).
Finally, we extend labelled intuitionistic programs to include modalities.

Deﬁnition 3
(Labelled Intuitionistic Modal Program) A modal atom is of the form M A
where M ∈ {¤, ♦} and A is an atom. A Labelled Intuitionistic Modal Program is a ﬁnit e
set of rules C of the form ωi : M A1 , ..., M An ⇒ M A0 , where M Ak (0 ≤ k ≤ n) are
modal atoms and ωi is a label representing a world in which the associated rule holds, and
a ﬁnite set of (accessibility) relations R between worlds ωi (1 ≤ i ≤ m) in C .

3 Motivating Scenario

In this section, we consider an archetypal testbed for distributed knowledge representation,
namely, the wise men puzzle [7], and model it intuitionistically in a neural network ensem-
ble. Our aim is to illustrate the combination of neural networks and intuitionistic modal
reasoning. The formalisation of our computational model will be given in Section 4.

A certain king wishes to test his three wise men. He arranges them in a circle so that they
can see and hear each other. They are all perceptive, truthful and intelligent, and this is
common knowledge in the group. It is also common knowledge among them that there are
three red hats and two white hats, and ﬁve hats in total. The ki ng places a hat on the head

of each wise man in a way that they are not able to see the colour of their own hats, and
then asks each one whether they know the colour of the hats on their heads.

The puzzle illustrates a situation in which intuitionistic implication and intuitionistic nega-
tion occur. Knowledge evolves in time, with the current knowledge persisting in time. For
example, at the ﬁrst round it is known that there are at most tw o white hats on the wise
men’s heads. Then, if the wise men get to a second round, it becomes known that there is
at most one white hat on their heads.1 This new knowledge subsumes the previous knowl-
edge, which in turn persists. This means that if A ⇒ B is true at a world t1 then A ⇒ B
will be true at a world t2 that is related to t1 (intuitionistic implication). Now, in any sit-
uation in which a wise man knows that his hat is red, this knowledge - constructed with
the use of sound reasoning processes - cannot be refuted. In other words, in this puzzle, if
¬A is true at world t1 then A cannot be true at a world t2 that is related to t1 (intuitionistic
negation).

We model the wise men puzzle by constructing the relative knowledge of each wise man
along time points. This allows us to explicitly represent the relativistic notion of knowl-
edge, which is a principle of intuitionistic reasoning. For simplicity, we refer to wise man
1 (respectively, 2 and 3) as agent 1 (respectively, 2 and 3). The resulting model is a two-
dimensional network ensemble (agents × time), containing three networks in each dimen-
sion. In addition to pi - denoting the fact that wise man i wears a red hat - to model each
agent’s individual knowledge, we need to use a modality Kj , j ∈ {1, 2, 3}, which repre-
sents the relative notion of knowledge at each time point t1 , t2 , t3 . Thus, Kj pi denotes the
fact that agent j knows that agent i wears a red hat. The K modality above corresponds to
the ¤ modality in intuitionistic modal reasoning, as customary in the logics of knowledge
[7], and as exempli ﬁed below.

First, we model the fact that each agent knows the colour of the others’ hats. For example,
if wise man 3 wears a red hat (neuron p3 is active) then wise man 1 knows that wise man
3 wears a red hat (neuron K p3 is active for wise man 1). We then need to model the
reasoning process of each wise man. In this example, let us consider the case in which
neurons p1 and p3 are active. For agent 1, we have the rule t1 : K1¬p2 ∧ K1¬p3 ⇒ K1 p1 ,
which states that agent 1 can deduce that he is wearing a red hat if he knows that the other
agents are both wearing white hats. Analogous rules exist for agents 2 and 3. As before,
the implication is intuitionistic, so that it persists at t2 and t3 as depicted in Figure 1 for
wise man 1 (represented via hidden neuron h1 in each network). In addition, according to
the philosophy of intuitionistic negation, we may only conclude that agent 1 knows ¬p2 , if
in every world envisaged by agent 1, p2 is not derived. This is illustrated with the use of
dotted lines in Figure 1, in which, e.g., if neuron K p2 is not active at t3 then neuron K ¬p2
will be active at t2 . As a result, the network ensemble will never derive p2 (as one should
expect), and thus it will derive K1¬p2 and K3¬p2 .2

4 Connectionist Intuitionistic Modal Reasoning

The wise men puzzle example of Section 3 shows that simple, single-hidden layer neural
networks can be combined in a modular structure where each network represents a possible
world in the Kripke structure of Deﬁnition 1. The way that the networks should then be
inter-connected can be deﬁned by following a semantics for ⇒ and ¬, and for ¤ and ♦ from
intuitionistic logic. In this section, we see how exactly we construct a network ensemble

1This is because if there were two white hats on their heads, one of them would have known (and
have said), in the ﬁrst round, that his hat was red, for he would have b een seeing the other two with
white hats.
2To complete the formalisation of the problem, the following rules should also hold at t2 (and at
t3 ): K1¬p2 ⇒ K1 p1 and K1¬p3 ⇒ K1 p1 . Analogous rules exist for agents 2 and 3.

----1 

----1 

Kp1 

Kp2  Kp3 

K(cid:216)(cid:216)(cid:216)(cid:216)p2 

K(cid:216)(cid:216)(cid:216)(cid:216)p3 

  h1    h2 

  h3 

  h4 

  h5 

wise man 1 at point t3 

 K(cid:216)(cid:216)(cid:216)(cid:216)p2 

K(cid:216)(cid:216)(cid:216)(cid:216)p3 
  

Kp1  Kp2  Kp3 

K(cid:216)(cid:216)(cid:216)(cid:216)p2 

K(cid:216)(cid:216)(cid:216)(cid:216)p3 

----1 

  h1 

  h2 

  h3    h4 

  h5 

Kp1 

Kp2  Kp3 

K(cid:216)(cid:216)(cid:216)(cid:216)p2 

K(cid:216)(cid:216)(cid:216)(cid:216)p3 

 K(cid:216)(cid:216)(cid:216)(cid:216)p2 

  K(cid:216)(cid:216)(cid:216)(cid:216)p3 

  h1 

  h2    h3  h4 

  h5 

wise man 1 at point t2 

----1 

 K(cid:216)(cid:216)(cid:216)(cid:216)p2 

K(cid:216)(cid:216)(cid:216)(cid:216)p3 
  

wise man 1 at point t1 

Figure 1: Wise men puzzle: Intuitionistic negation and implication.

given an intuitionistic modal program. We introduce a translation algorithm, which takes
the program as input and produces the ensemble as output by setting the initial architecture,
set of weights, and thresholds of the networks according to a Kripke semantics for the
program. We then prove that the translation is correct, and thus that the network ensemble
can be used to compute the logical consequences of the program in parallel.

Before we present the algorithm, let us illustrate informally how ⇒, ¬, ¤, and ♦ are repre-
sented in the ensemble. We follow the key idea behind Connectionist Modal Logics (CML)
to represent Kripke models in neural networks [6]. Each possible world is represented by
a single hidden layer neural network. In each network, input and output neurons represent
atoms or modal atoms of the form A, ¬A, ¤A, or ♦A, while each hidden neuron encodes
a rule. For example, in Figure 1, hidden neuron h1 encodes a rule of the form A ∧ B ⇒ C .
Thresholds and weights must be such that the hidden layer computes a logical and of the
input layer, while the output layer computes a logical or of the hidden layer.3 Furthermore,
in each network, each output neuron is connected to its corresponding input neuron with a
weight ﬁxed at 1.0 (as depicted in Figure 1 for K ¬p2 and K ¬p3 ), so that chains of the form
A ⇒ B and B ⇒ C can be represented and computed. This basically characterises C-ILP
networks [3]. Now, in CML, we allow for an ensemble of C-ILP networks, each network
representing knowledge in a (learnable) possible world. In addition, we allow for a number
of ﬁxed feedforward and feedback connections to occur among different networks in the
ensemble, as shown in Figure 1. These are deﬁned as follows: i n the case of ¤, if neuron
¤A is activated (true) in network (world) ωi then A must be activated in every network
ωj that is related to ωi (this is analogous to the situation in which we activate K1p3 and
K2 p3 whenever p3 is active). Dually, if A is active in every ωj then ¤A must be activated

3For example, if A ∧ B ⇒ D and C ⇒ D then a hidden neuron h1 is used to connect A and B
to D , and a hidden neuron h2 is used to connect C to D such that if h1 or h2 is activated then D is
activated.

in ωi (this is done with the use of feedback connections and a hidden neuron that computes
a logical and, as detailed in the algorithm below). In the case of ♦, if ♦A is activated in
network ωi then A must be activated in at least one network ωj that is related to ωi (we do
this by choosing an arbitrary ωj to make A active). Dually, if A is activated in any ωj that is
related to ωi then ♦A must be activated in ωi (this is done with the use of a hidden neuron
that computes a logical or, also as detailed in the algorithm below). Now, in the case of ⇒,
according to the semantics of intuitionistic implication, ωi : A ⇒ B and R(ωi , ωj ) imply
ωj : A ⇒ B . We implement this by copying the neural representation of A ⇒ B from
ωi to ωj , as done via h1 in Figure 1. Finally, in the case of ¬, we need to make sure that
¬A is activated in ωi if, for every ωj such that R(ωi , ωj ), A is not active in ωj . This is im-
plemented with the use of negative weights (to account for the fact that the non-activation
of a neuron needs to activate another neuron), as depicted in Figure 1 (dashed arrows), and
detailed in the algorithm below.

We are now in a position to introduce the Intuitionistic Modal Algorithm. Let P =
{P1 , ..., Pn } be a labelled intuitionistic modal program with rules of the form ωi
:
M A1 , ..., M Ak → M A0 , where each Aj (0 ≤ j ≤ k) is an atom and M ∈ {¤, ♦},
1 ≤ i ≤ n. Let N = {N1 , ..., Nn } be a neural network ensemble with each network Ni
corresponding to program Pi . Let q denote the number of rules occurring in P . Consider
that the atoms of Pi are numbered from 1 to ηi such that the input and output layers of Ni
are vectors of length ηi , where the j-th neuron represents the j-th atom of Pi . In addition,
let Amin denote the minimum activation for a neuron to be considered active (or true),
Amin ∈ (0, 1); for each rule rl in each program Pi , let kl denote the number of atoms in
the body of rule rl , and let µl denote the number of rules in Pi with the same consequent
as rl (including rl ). Let M AXrl (kl , µl ) denote the greater of kl and µl for rule rl , and
let M AXP (k1 , ..., kq , µ1 , ..., µq ) denote the greatest of k1 , ..., kq , µ1 , ..., µq for program
P . Below, we use k as a shorthand for k1 , ..., kq , and µ as a shorthand for µ1 , ..., µq . The
equations in the algorithm come from the proof of Theorem 1, given in the sequel.
Intuitionistic Modal Algorithm

1. Rename each modal atom M Aj by a new atom not occurring in P of the form A¤
j if M = ¤, or
A♦
j if M = ♦;
2. For each rule rl of the form A1 , ..., Ak ⇒ A0 in Pi (1 ≤ i ≤ n) such that R(ωi , ωj ), do: add a
rule A1 , ..., Ak ⇒ A0 to Pj (1 ≤ j ≤ n).
3. Calculate Amin > (M AXP (k,µ, n) − 1)Á(M AXP (k,µ, n) + 1);
4. Calculate W ≥ (2Áβ ) · (ln (1 + Amin )− ln (1 − Amin ))Á(M AXP (k,µ) · (Amin − 1)+Amin +
1);
5. For each rule rl of the form A1 , ..., Ak ⇒ A0 (k ≥ 0) in Pi (1 ≤ i ≤ n), do:

(a) Add a neuron Nl to the hidden layer of neural network Ni associated with Pi ; (b) Connect each
neuron Ai (1 ≤ i ≤ k) in the input layer of Ni to Nl and set the connection weight to W ; (c)
Connect Nl to neuron A0 in the output layer of Ni and set the connection weight to W ; (d) Set the
threshold θl of Nl to θl = ((1 + Amin ) · (kl − 1) Á2)W ; (e) Set the threshold θA0 of A0 in the
output layer of Ni to θA0 = ((1 + Amin ) · (1 − µl )Á2)W. (f) For each atom of the form A ′ in rl ,
do:

(i) Add a hidden neuron NA′ to Ni ; (ii) Set the step function s(x) as the activation function of
NA′ ;4 (iii) Set the threshold θA′ of NA′ such that n − (1 + Amin ) < θA′ < nAmin ; (iv) For each

4Any hidden neuron created to encode negation (such as h4 in Figure 1) shall have a non-linear
activation function s(x) = y , where y = 1 if x > 0, and y = 0 otherwise. Such neurons en-
code (meta-level) knowledge about negation, while the other hidden neurons encode (object-level)
knowledge about the problem domain. The former are not expected to be trained by examples and,
as a result, the use of the step function will simplify the algorithm. The latter are to be trained, and
therefore require a differentiable, semi-linear activation function.

network Nj corresponding to program Pj (1 ≤ j ≤ n) in P such that R(ωi , ωj ), do: Connect the
output neuron A of Nj to the hidden neuron NA′ of Ni and set the connection weight to −1; and
Connect the hidden neuron NA′ of Ni to the output neuron A′ of Ni and set the connection weight
to W I such that W I > h−1 (Amin ) +µA′ .W + θA′ .

6. For each output neuron A♦
j in network Ni , do:
(a) Add a hidden neuron AM
and an output neuron Aj to an arbitrary network Nz such that
j
R(ωi , ωz ); (b) Set the step function s(x) as the activation function of AM
j , and set the semi-linear
function h(x) as the activation function of Aj ; (c) Connect A♦
j in Ni to AM
j and set the connection
weight to 1; (d) Set the threshold θM of AM
such that −1 < θM < Amin ; (e) Set the threshold θAj
j
of Aj in Nz such that θAj = ((1 + Amin ) · (1 − µAj )Á2)W ; (f) Connect AM
to Aj in Nz and set
j
the connection weight to W M > h−1 (Amin ) + µAj W + θAj .

7. For each output neuron A¤
j in network Ni , do:
(a) Add a hidden neuron AM
to each Nu (1 ≤ u ≤ n) such that R(ωi , ωu ), and add an output
j
neuron Aj to Nu if Aj /∈ Nu ; (b) Set the step function s(x) as the activation function of AM
j , and
set the semi-linear function h(x) as the activation function of Aj ; (c) Connect A¤
j in Ni to AM
j and
set the connection weight to 1; (d) Set the threshold θM of AM
such that −1 < θM < Amin ; (e) Set
j
the threshold θAj of Aj in each Nu such that θAj = ((1 + Amin ) · (1 − µAj )Á2)W ; (f) Connect
AM
to Aj in Nu and set the connection weight to W M > h−1 (Amin ) + µAj W + θAj .
j
8. For each output neuron Aj in network Nu such that R(ωi , ωu ), do:
(a) Add a hidden neuron A∨
j to Ni ; (b) Set the step function s(x) as the activation function of A∨
j ;
(c) For each output neuron A♦
j in Ni , do:

j and set the connection weight to 1; (ii) Set the threshold θ∨ of A∨
(i) Connect Aj in Nu to A∨
j such
j to A♦
that −nAmin < θ∨ < Amin − (n − 1); (iii) Connect A∨
j in Ni and set the connection weight
to W M > h−1 (Amin ) + µAj W + θAj .
9. For each output neuron Aj in network Nu such that R(ωi , ωu ), do:
(a) Add a hidden neuron A∧
j to Ni ; (b) Set the step function s(x) as the activation function of A∧
j ;
(c) For each output neuron A¤
j in Ni , do:

(i) Connect Aj in Nu to A∧
j and set the connection weight to 1; (ii) Set the threshold θ∧ of A∧
j such
j to A¤
that n − (1 + Amin ) < θ∧ < nAmin ; (iii) Connect A∧
j in Ni and set the connection weight
to W M > h−1 (Amin ) + µAj W + θAj .
Finally, we prove that N is equivalent to P .

Theorem 1 (Correctness of Intuitionistic Modal Algorithm) For any intuitionistic modal
program P there exists an ensemble of neural networks N such that N computes the intu-
itionistic modal semantics of P .
Proof The algorithm to build each individual network in the ensemble is that of C-ILP,
which we know is provably correct [3]. The algorithm to include modalities is that of
CML, which is also provably correct [6]. We need to consider when modalities and intu-
itionistic negation are to be encoded together. Consider an output neuron A0 with neurons
M (encoding modalities) and neurons n (encoding negation) among its predecessors in a
network’s hidden layer. There are four cases to consider. (i) Both neurons M and neurons
n are not activated: since the activation function of neurons M and n is the step function,
their activation is zero, and thus this case reduces to C-ILP. (ii) Only neurons M are acti-
vated: from the algorithm above, A0 will also be activated (with minimum input potential
W M + ς , where ς ∈ R). (iii) Only neurons n are activated: as before, A0 will also be
activated (now with minimum input potential W I + ς ). (iv ) Both neurons M and neurons
n are activated: the input potential of A0 is at least W M + W I + ς . Since W M > 0 and
W I > 0, and since the activation function of A0 , h(x), is monotonically increasing, A0
will be activated whenever both M and n neurons are activated. This completes the proof.

5 Concluding Remarks

In this paper, we have presented a new model of computation that integrates neural net-
works and constructive, intuitionistic modal reasoning. We have deﬁned labelled intu-
itionistic modal programs, and have presented an algorithm to translate the intuitionistic
theories into ensembles of C-ILP neural networks, and showed that the ensembles com-
pute a semantics of the corresponding theories. As a result, each ensemble can be seen as a
new massively parallel model for the computation of intuitionistic modal logic. In addition,
since each network can be trained efﬁciently using, e.g., ba ckpropagation, one can adapt the
network ensemble by training possible world representations from examples. Work along
these lines has been done in [4, 5], where learning experiments in possible worlds settings
were investigated. As future work, we shall consider learning experiments based on the
constructive model introduced in this paper. Extensions of this work also include the study
of how to represent other non-classical logics such as branching time temporal logics, and
conditional logics of normality, which are relevant for cognitive and neural computation.
Acknowledgments
Artur Garcez is partly supported by the Nufﬁeld Foundation and The Roya l Society. Luis Lamb is
partly supported by the Brazilian Research Council CNPq and by the CAPES and FAPERGS foun-
dations.

References

[1] A. Browne and R. Sun. Connectionist inference models. Neural Networks, 14(10):1331–1355,
2001.
[2] D. Van Dalen. Intuitionistic logic. In D. M. Gabbay and F. Guenthner, editors, Handbook of
Philosophical Logic, volume 5. Kluwer, 2nd edition, 2002.
[3] A. S. d’Avila Garcez, K. Broda, and D. M. Gabbay. Neural-Symbolic Learning Systems: Foun-
dations and Applications. Perspectives in Neural Computing. Springer-Verlag, 2002.
[4] A. S. d’Avila Garcez and L. C. Lamb. Reasoning about time and knowledge in neural-symbolic
learning systems. In Advances in Neural Information Processing Systems 16, Proceedings of
NIPS 2003, pages 921–928, Vancouver, Canada, 2004. MIT Pres s.
[5] A. S. d’Avila Garcez, L. C. Lamb, K. Broda, and D. M. Gabbay. Applying connectionist modal
logics to distributed knowledge representation problems.
International Journal on Artiﬁcial
Intelligence Tools, 13(1):115–139, 2004.
[6] A. S. d’Avila Garcez, L. C. Lamb, and D. M. Gabbay. Connectionist modal logics. Theoretical
Computer Science. Forthcoming.
[7] R. Fagin, J. Halpern, Y. Moses, and M. Vardi. Reasoning about Knowledge. MIT Press, 1995.
[8] D. M. Gabbay. Labelled Deductive Systems. Clarendom Press, Oxford, 1996.
[9] D. M. Gabbay, C. Hogger, and J. A. Robinson, editors. Handbook of Logic in Artiﬁcial Intelli-
gence and Logic Programming, volume 1-5, Oxford, 1994-1999. Clarendom Press.
[10] M. Gelfond and V. Lifschitz. Classical negation in logic programs and disjunctive databases.
New Generation Computing, 9:365–385, 1991.
[11] D. E. Rumelhart, G. E. Hinton, and R. J. Williams. Learning representations by back-
propagating errors. Nature, 323:533–536, 1986.
[12] L. Shastri. Advances in SHRUTI: a neurally motivated model of relational knowledge rep-
resentation and rapid inference using temporal synchrony. Applied Intelligence, 11:79–108,
1999.
[13] G. G. Towell and J. W. Shavlik. Knowledge-based artiﬁcial neura l networks. Artiﬁcial Intelli-
gence, 70(1):119–165, 1994.
[14] A. M. Turing. Computer machinery and intelligence. Mind, 59:433–460, 1950.
[15] L. G. Valiant. Robust logics. Artiﬁcial Intelligence , 117:231–253, 2000.
[16] V. Vapnik. The nature of statistical learning theory. Springer-Verlag, 1995.

