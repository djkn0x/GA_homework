P r e d i c t i o n   a n d  C h a n g e   D e t e c t i o n  

 
 
 
 
 

Scott Brown 
Mark Steyvers 
scottb@uci.edu 
msteyver@uci.edu 
University  o f California, Irvine  University  o f California, Irvine 
Irvine, CA 92697 
Irvine, CA 92697 

Abstract 

We measure the ability o f human obs ervers to predict the next datum 
in  a  sequence  that  is  generated  b y  a  simple  statistical  process  
undergoing  change at random points in  time. Accurate performance 
in  this  task  requires  the  identification  of  changepoints.  We  asses s  
individual  differences  b etwe en  obs ervers  b oth  empirically,  and 
using two kinds of models: a Ba ye sian approach for change detecti on 
and  a  family  of  cognitivel y  plausible  fast  and  frugal models.  Some  
individuals  detect 
too  many  changes  and  hence  perform 
sub-optimally  due  t o  exc ess  variability.  Other  individuals  do  not 
detect enough changes, and perform sub-optimally b ecaus e they fail 
to notice short-term temporal trends. 

1   I n t r o d u c t i o n  

Decisi on-making  often  requires  a  rapid  response  to  change.  For  example,  stock  
analysts  need  to  quickly  detect  changes  in  the  market  in  order  to  adjust  investment 
strategies. Coaches need to track changes in a play er’s performance in order to adjust 
strategy.  When  tracking  changes,  there  are  costs  invol ved  when  either more  or  less 
changes  are  observ ed  than  actually  oc curred.  For  example,  when  using  an  overl y  
conservative  change  detection  criterion,  a  stock  analy st  might  miss  important 
short-term  trends  and  interpret  them  as  random  fluctuations  instead.  On  the  other 
hand, a change may also be dete cted too readily. For example, in basketball, a player 
who makes  a  series  of  consecutive  baskets  is  o ft en  identified  as  a  “hot hand” player  
whos e  underlying  ability  is  perceiv ed  to  have  suddenly  increased  [1,2].  This might 
lead to sub-optimal passing strategies, based on random fluctuations.  

We are interested in explaining individual diff erences in a sequential prediction task. 
Obs ervers are shown stimuli generated from a simple statistical process with the task 
o f predicting  the next datum  in the  sequence. The latent parameters  of  the  statistical 
process change discretely at random points in time. Perfo rmance in this task depends 
on  the  accurate  detection  of  those  changepoints,  as  well  as  inference  about  future 
outcomes  based on the outcome s that followed the most rec ent inferred changepoint. 
There is much prior research in statistics on the problem o f identif ying changepoints 
[3,4,5]. In this paper, we adopt a Ba ye sian approach to the changepoint identification 
problem  and  develop  a  simple  inference  procedure  to  predict  the  next  datum  in  a 
sequence.  The  Bay esian  model  serves  as  an  ideal  obs erver  model  and  is  useful  to 
characterize the ways in which individuals deviate from optimality.  

 

The plan  of  the paper is as  follows. We  first  introduce  the  sequential prediction task 
and discuss a Bay esian analysis o f this prediction problem. We then discuss the results 
from  a  few  individuals  in  this  prediction  task  and  show  how  the  Bay esian  approach 
can  capture  individual  differences  with  a  single  “twitchiness”  parameter  that 
describes how readily changes are perceived in random sequences. We will show that 
some individuals are too twitch y: their performance is too  variable b ecause the y base  
their  predictions  on  too  little  of  the  recent  data.    Other  individuals  are  not  twitchy  
enough, and they fail to capture fast changes in the data. We also show how behavior 
can  be  explained  with  a  set  of  fast  and  frugal  models  [6].  These  are  cognitivel y  
realistic models that operate under plausible computational constraints. 

2   A   p r e d i c t i o n   t a s k   w i t h   m u l t i p l e   c h a n g e p o i n t s  

In the prediction task, stimuli are presented sequentially and the task is to predict the 
next  stimulus  in  the  sequence.  After  t  trials,  the  obs erver  has  been  presented  with 
stimuli y1, y2, …, y t and the task is to make a prediction about y t+1. After the prediction 
is  made,  the  actual  outcome  y t+1  is  revealed  and  the  next  trial  proceeds  to  the 
prediction of y t+2. This procedure starts with y1 and is repeated for T trials. 

The obs ervations yt are D-dimensional vectors with elements sampled from binomial 
distributions.    The  parameters  of  those  distributions  change  discretely  at  random 
points  in  time  such  that  the  mean  increases  or  decreases  after  a  change  point.  This 
generates  a  sequence  of  o bservation  vectors,  y1,  y2,  …,  yT,  where  each  y t  =  {y t ,1  … 
y t ,D}. Each of the yt ,d is sampled from a binomial distribution Bin(θ t,d,K), so 0 ≤ y t ,d  ≤ 
K.  The parameter vector θ t ={θ t ,1 … θt ,D} changes depending on the locations of the 
changepoints.  At  each  time  step, 
x is  a  binary  indicator  f or  the  occurrence  of  a 
t

changepoint  occurring  at  time  t+1. The  parameter  α  determines  the probabilit y  o f  a 
change occurring in the sequence. The generative model is specifi ed b y the foll owing 
algorithm: 

 

1. For d=1..D sample θ1 ,d from a Uniform(0,1) distribution 

2. For t=2..T, 

(a) Sample x t -1 from a Bernoulli(α) distribution  

(b) If x t -1=0, then θt=θ t -1, else 

f or d=1..D sample θ t ,d from a Uniform(0,1) distribution 

(c) f or d=1..D, sample y t from a Bin(θ t,d,K) distribution  

 

Table 1 shows s ome data generated from the changepoint model with T=20, α=.1,and 
D=1. In the prediction task, y will be obs erved, but x and θ are not. 

 

t

x

θ

y

Table 1: Example data 

1

0

2

0

3

0

4

1

5

0

6

0

7

1

8

0

9 10 11 12 13 14 15 16 17 18 19 20

0

0

0

0

1

0

1

0

0

0

0

0

.68 .68 .68 .68 .48 .48 .48 .74 .74 .74 .74 .74 .74 .19 .19 .87 .87 .87 .87 .87
8  

9

7

1

8

9

8

7

4

4

9

3

6

8

4

8

7

8

2

9

 

 

3   A   B a y e s i a n   p r e d i c t i o n   m o d e l  

In both our Baye sian and fast-and-frugal analyse s, the prediction task is decompos ed  
into two inference procedures. First, the changepoint locations are identified. This is 
f ollow ed  b y  predictive  inference  for  the  next  outcome   based  on  the  most  recent 
changepoint  locations.  Sev eral  Bay esian  approaches  have  be en  developed  f or 
changepoint  problems  involving  single  or  multiple  changepoints  [3,5].  We  apply  a 
Markov  Chain  Monte  Carlo  (MCMC)  analysis  to  approximate  the  joint  posterior 
distribution  over  changepoint  assignments x while  integrating  out θ. Gibbs  sampling 
will be used to sample from this posterior marginal distribution. The samples can then 
be us ed to predict the next outcome in the sequence.  

3 . 1  

I n f e r e n c e   f o r   c h a n g e p o i n t   a s s i g n m e n t s .  

To  apply  Gi bb s  sampling,  we  evaluate  the  conditional  probability  o f  assigning  a 
changepoint at time i, given all other changepoint assignments and the current α value. 
B y integrating out θ, the conditional probability is 
= ∫
θ

(
|
P x x
i
−

(
P x
i

,
θ α

(1) 

x
−

,
y

α

)

)

y

,

,

,

 

 

|

i

i

 

where 

 represents all switch point assignments except xi. This can be simplified b y  

x
i
−
considering the location of the most recent changepoint prec eding and following time 
L
i  and  the  outcomes  o ccurring  betw een  these  locations.  Let
n b e  the number  of  time  
i
steps  from  the  last  changepoint  up  to  and  including  the  current  time  step  i  such  that 
R
=0 for 0<j< L
n be the number of time steps that 
n . Similarly, let 
i
i

=1 and 

L

L

x
i n
−
i

x
i n
−

j

+

i

follow  time  step  i  up  to  the  next  changepoint  such  that 

x
i n
+
i

R

=1  and 

x
i n
+

j

−

R

i

=0  for 

0<j<

R
n .  Let
i

L

y
i

= ∑

L

y

k

and 

R

y
i

= ∑

i n
k k i n
−
< ≤ +
i
i
changepoint assignment can then be simplified to   

k i
< ≤

y
k

R

(
=
|
P x m x
i
−

i

)

∝

 

        

⎧
⎪
⎪⎪
⎨
⎪
⎪
α
⎪⎩

(
Γ +
1

L
y
i j
,

+

(
1

−

α

)

D
∏
j
1
=

(
Γ +
1

)

L
y
i j
,

D
∏
j
1
=

(
Γ +
1

L
Kn
i
(
Γ +
2

(
)
Γ +
R
1
y
i j
,
(
Γ +
2
)
)

L
Kn
i

L
y
i j
,

−

L
Kn
i
+

L
Kn
i
(
Γ +
1
(
Γ +
2

+

R
Kn
i
)

R
Kn
i
)
R
Kn
i

R
y
i j
,

(
Γ +
1
)

.  The  update  equation  for  the 

 

−

L
y
i j
,

−

R
y
i j
,

)

R
Kn
i

−

R
y
i j
,

)

 

(2) 

m

=

0

m

=

1

We initialize the Gibbs sampler b y sampling each x t from a Bernoulli(α) distribution. 
All  changepoint  assignments  are  then  updated  sequentially  b y  the  Gibb s  sampling 
equation abov e. The sampler is run for M iterations after which one set of changepoint 
assignments  is  saved.  The  Gibbs  sampler  is  then  restarted  multiple  times  until  S 
samples have b een collected.    

Although we could have included an update equation for α, in this analysis we treat α 
as a known constant. This will be useful when characterizing the diff erences betw een 
human obs ervers in terms of diff erences in α.  

3 . 2   P r e d i c t i v e   i n f e r e n c e  

 

The next latent parameter value θ t+1 and outcome y t+1  can be predicted on the basis o f  
o bs erved outcomes that occurred after the last inferred changepoint: 
t
(
)
∑
θ
1
i t
*
= +

y
,          

round

(3) 

y
,
i j

K

K

t

1,
+

j

t

1,
+

j

/

θ

t

1,
+

j

=

=

where  t*  is  the  location  of  the  most  recent  change  point.  B y  considering  multiple 
Gibb s  samples,  we  get  a  distribution  over  outcomes   y t+1.  We  base  the  model 
predictions on the mean of this distribution.  

3 . 3  

I l l u s t r a t i o n   o f   m o d e l   p e r f o r m a n c e  

Figure  1  illustrates  the  performance  of  the  model  on  a  one  dimensional  sequence 
(D=1)  generated  from  the  changepoint  model  with  T=160,  α=0.05,  and  K=10.  The 
Gibb s  sampler  was  run  for M=30  iterations  and  S=200  samples  w ere  colle cted.  The 
top  panel  shows  the  actual  changepoints  (triangles)  and  the  distribution  of  
changepoint  assignments  averaged  over  samples.  The  bottom  panel  shows  the 
o bs erved data y  (thin  lines)  as well  as the θ values  in the generative model  (rescaled 
betw een 0 and 10).  

At  locations  with  large  changes  betwe en  obs ervations,  the  marginal  changepoint 
probability is quite high. At other locations, the true change in the mean is very small, 
and  the model  is less  likely  to put in  a  changepoint. The low er right panel  shows  the 
distribution over predicted θ t+1 values.  

 

t
x

1

0.5

0

10

t
y

5

0

θ
t+1

1

0.5

0

160

 

20

40

60

80

100

120

140

Figure 1. Results of mod el simulation.  

 

4   P r e d i c t i o n   e x p e r i m e n t  

We  tested  performance  of  9  human  observ ers  in  the  prediction  task.  The  observ ers 
included  the  authors,  a  visitor,  and  one  student  who  w ere  aware  of  the  statistical 
nature  of  the task  as well  as naïve  students. The  obs ervers were  seated  in  front  of  an 
LCD  touch  screen  displaying  a  two-dimensional  grid  of  11  x  11  buttons.  The 
changepoint  model  was  used  to  g enerate  a  sequence  o f  T=1500  stimuli  for  tw o  
binomial  variables  y1  and  y2  (D=2,  K=10).  The  change  probability  α  was  set  to  0.1. 
The  two  variables y1  and y2  specified  the  two-dimensional  button location. The  same 
sequence was used for all obs ervers. 

On each trial, the ob server touched a button on the grid displayed on the touch screen. 
Following each button press, the button corresponding to the next {y1,y2} outcome in 
the sequence was highlighted. Observers were instructed to press the button that best  
predicted the next location of the highlighted button. The 1500 trials were divided into 

 
 
 

three  blo cks  o f  500  trials.  Breaks  were  allow ed  be twe en  blocks.  The  whole 
experiment lasted betw een 15 and 30 minutes. Figure 2 shows the first 50 trials from 
the  third  block  o f  the  experiment.  The  top  and  bottom  panels  show  the  actual 
outcomes  for  the  y1  and  y2  button grid  co ordinates  as well  as the predictions  for  two  
o bs ervers  (SB  and MY). The  figure  shows  that  at  trial  15,  the y1  and  y2  co ordinates 
show  a  large  shift  follow ed  b y  an  immediate  shift  in  obs erver’s MY  predictions  (on 
trial 16). Observer SB waits until trial 17 to make a shift. 

 

10

5

0

10

5

0

outcomes

SB  predic t ions
M Y  predict ions

0

5

10

15

20

25
Trial

30

35

40

45

50

 

Figure 2. Trial b y trial predictions from two o b servers.  

 

4 . 1   T a s k   e r r o r    

We  asses sed  prediction  performance  b y  comparing  the  prediction  with  the  actual 
outcome in the sequence. Task error was measured by normalized city-bl ock distance   
1
T
∑
2
t
=

task error=

(4) 

y
t

O
,2

y
t

O
,1

y
t

(
T

1)

−

y
t

, 2

−

,1

+

−

where yO represents the ob server’s prediction. Note that the v er y first trial is excluded 
from this calculation. Even though more suitable probabilistic measures for prediction 
error  could  have  be en  adopted,  we  wanted  to  allow   comparison  of  ob serv er’s 
performance with both probabilistic and non-probabilistic models.  Task error ranged 
from 2.8 (for participant MY) to 3.3 (for ML).  We also asses sed the performance o f  
fiv e  models  –  their  task  errors  ranged  from  2.78  to  3.20.    The  Bay esian  models 
(Section 3) had the low est task errors, just below 2.8. This fits with our definition of  
the  Ba yesian models  as  “ideal  obs erver” models  –  their  task  error  is  lower  than  any  
other  model’s  and  any  human  obs erver’s  task  error.    The  fast  and  frugal  models 
(Section 5) had task errors ranging from 2.85 to 3.20. 

5   M o d e l i n g   R e s u l t s  

We  will  refer  to  the  models  with  the  following  letter  cod es:  B=Ba ye sian  Model, 
LB=limited Bay esian model, FF1..3=fast and frugal models 1..3. We assessed model  
fit  b y  comparing  the  model’s  prediction  against  the  human  obs ervers’  predictions, 
again using a normalized city-blo ck distance  

 
 
model error=

1

T
(

1)

−

T
∑
2
t
=

y
t

M
,1

−

y
t

O
,1

+

y
t

M
,2

−

y
t

O
, 2

 

(5) 

where  yM  represents  the  model’s  prediction.  The  model  error  for  each  individual 
o bs erver  is  shown  in  Figure  3.  It  is  important  to  note  that  because  each  model  is 
associated with  a  set  of  free parameters,  the parameters  optimized  for  task  error  and 
model  error  are  different.  For  Figure  3,  the  parameters  w ere  optimized  to minimize 
Equation  (5)  for  each  individual  obs erver,  showing  the  extent to which  these models 
can  capture  the  performance  o f  individual  observ ers,  not  necessarily  providing  the 
be st task performance. 

B

LB

FF1

FF2

FF3

r
o
r
r
E
 
l
e
d
o
M

2

1.5

1

0.5

0

MY

MS

MM

EJ

PH

NP

DN

SB

ML

 

Figure 3. Model error for each individual obs erver.1  

5 . 1   B a y e s i a n   p r e d i c t i o n   m o d e l s  

 

At  each  trial  t,  the model  was  provided  with  the  sequence  o f  all  previous  outcomes.  
The Gibbs sampling and inference procedures from Eq. (2) and (3) were applied with 
M=30 iterations and S=200 samples. The change probability α was a free parameter. In 
the full Bay esian model, the whole sequence o f o bs ervations up to the current trial is 
available  for prediction,  leading to  a memory  requirement  of up  to T=1500 trials –  a 
ps y chologically  unreasonable  assumption.  We  therefore  also  simulated  a  limited 
Ba y esian  model  (LB)  where  the  obs erved  s equence  w as  truncated  to  the  last  10 
outc omes.  The LB model showed almost no decrement in task performance compared 
to the full Bay esian model.  Figure 3 also shows that it fit human data quite well.  

5 . 2  

I n d i v i d u a l   D i f f e r e n c e s  

The right-hand panel of Figure 4 plots each observ er’s task error as a function of the 
mean city-bl ock distance betw een their subsequent button presses.  This shows a clear 
U-shaped function.  Observers with very variable predictions (e.g., ML and DN) had 
large  average  changes  betw een  succes siv e  button  pushes,  and  also  had  large  task 
error: These obs ervers were too “twitchy”.  Observers with very small average button 
changes  (e.g.,  SB  and  NP)  were  not  twitchy  enough,  and  also  had  large  task  error.  
Obs ervers  in  the middle had the low est  task  error (e.g., MS  and MY).   The left-hand 
panel  of  Figure  4  show s  the  same  data,  but  with  the  x-axis  based  on  the  Ba yesian 
model  fits.   Instead  of using mean  button  change distance  to index  twitchiness  (as  in 

                                                        
1 Error bars indicate  bootstrapped 95%  confidence intervals .  

 
 
 

the  right-hand  panel),  the  left-hand  panel  uses  the  estimated  α  parameters  from  the 
Ba y esian model.  A similar U-shaped pattern is observ ed: individuals with too large or 
too small α estimates have large task errors. 

NP

 

3.3

SB

r
o
r
r
E
 
k
s
a
T

3.2

3.1

3

2.9

2.8

SB

NP

EJ

ML

DN

PH

MM

MS

MY

r
o
r
r
E
 
k
s
a
T

3.3

3.2

3.1

3

2.9

2.8

ML

DN

PH

MM

MS

MY

EJ

B

-4

10

-3

10

-2

10

α

-1

10

0

10

0.5

1

1.5
2
Mean  Bu t ton  Change

2.5

3

 

Figure  4.  Task  error  vs.  “twitchiness”.  Left-hand  panel  indexes  twitchiness  using 
estimated  α  parameters  from  Bay esian  model  fits.  Right-hand  panel  uses  mean 
distance betw e en successi ve predictions. 

 

5 . 3   F a s t - a n d - F r u g a l   ( F F )   p r e d i c t i o n   m o d e l s  

 

These models perform the prediction task using simple heuristics that are cognitivel y  
plausible. The FF models keep a short memory o f previou s stimulus values and make 
predictions using the same two-step process as the Bay esian model. First, a decision is 
made as to whether the latent parameter θ has changed. Second, remembered stimulus 
values that occurred after the most recently detected changepoint are used to generate 
the next prediction. 

A  simple  heuristic  is  used  to  detect  changepoints:  If  the  distance  betw een  the  most 
recent observation and prediction is greater than some threshold amount, a change is 
inferred. We defined  the distance  betwe en  a prediction  (p)  and  an  obs ervation  (y) as 
the difference betwe en the log-likelihoods o f y assuming θ=p and θ=y.  Thus, if fB(. |θ, 
K) is the binomial density with parameters θ and K, the distance betw een o bservation 
y and prediction p is defined as d(y,p)=log(fB(y |y,K))-log(fB(y |p,K)). A changepoint on 
time  step  t+1  is  inferred  whenever  d(y t,pt)>C.  The  parameter  C  governs  the 
twitchiness  of  the model predictions.   If C  is  large,  only  ver y dramatic  changepoints 
will be detected, and the model will be too conservative.  If C is small, the model will 
be t o o twitch y, and will detect changepoints on the basis o f small random fluctuations. 

Predictions  are  based  on  the most recent M  observations, which  are kept  in memory,  
unless  a  changepoint  has  been  detected  in  which  case  only  those  o bs ervations 
oc curring after the changepoint are used for prediction.  The prediction for time step 
t+1 is simply the mean of these o bservations, say p.  Human observ ers were reticent to 
make predictions ver y clos e to the boundaries.  This was modeled b y  allowing the FF 
model to change its prediction for the next time step, yt+1, towards the mean prediction 
(0.5).  This change refle cts a two-wa y  bet.  If the probability o f a change occurring is 
α, the best guess will be 0.5 if that change occurs, or the mean p if the change does not 
oc cur.  Thus, the prediction made is actually y t+1=1/2 α+(1-α)p.  Note that we do not 
allow perfect knowledge o f the probability o f a changepoint, α.  Instead, an estimated 
value o f α is us ed based on the number of changepoints detected in the data series up 
to time t. 

 

The FF model nests two simpler FF models that are ps ychologicall y interesting.  If the 
twitchiness threshold parameter C becomes arbitrarily large, the model never detects a 
change  and  instead  becomes  a  continuous  running  average model.   Predictions  from 
this  model  are  simply  a  boxcar  smooth  of  the  data.  Alternatively,  if  w e  assume  no 
memory  the  model  must  based  each  prediction  on  only  the  previous  stimulus  (i.e., 
M=1).    Abo ve,  in  Figure  3,  we  labeled  the  complete  FF   model  as  FF1,  the  boxcar 
model as FF2 and the memoryle ss model FF3. 

Figure  3  showed  that  the  complete  FF  mod el  (FF1)  fit  the  data  from  all  observers  
significantly  b etter  than  either  the  boxcar  model  (FF2)  or  the  memoryless  mod el  
(FF3).  Exceptions were o bserv ers PH, DN and ML, for whom all three FF model fit 
equally w ell.  This result  suggests  that  our  obs ervers were  (mostl y) doing more than 
just keeping a running average of the data, or using only the most recent obs ervation.  
The  FF1  model  fit  the  data  about  as  well  as  the  Ba yesi an  models  for  all  observ ers 
except MY  and MS.  Note  that,  in general,  the FF1 and Bay esian model  fits  are  very  
go od:  the  average  city  blo ck  distance  betwe en  the  human  data  and  the  model 
prediction is around 0.75 (out of 10) buttons on both the x- and y-axes. 

6   C o n c l u s i o n  

We used an online prediction task to study  changepoint detection.  Human observ ers 
had  to  predict  the  next  observation  in  stochastic  sequences  containing  random 
changepoints.    We  showed  that  some  obs ervers  are  too  “twitch y”:  The y  perform 
po orly on the prediction task becaus e the y se e changes where only random fluctuation 
exists.  Other obs ervers are not twitchy enough, and they perform poorly be cause the y  
fail to see small changes.  We dev elop ed a Ba ye sian changepoint detection model that 
performed  the  task  optimally,  and  also  provided  a  good  fit  to  human  data  when 
sub-optimal  parameter  settings  were  used.    Finally,  we  dev elop ed  a  fast-and-frugal 
model  that  showed  how  participants  may  be  able  to  perf orm  well  at  the  task  using 
minimal information and simple decision heuristics. 

A c k n o w l e d g m e n t s  

We  thank  Eric-Jan Wagenmakers  and Mike  Yi  for  usefu l  discussions  related  to  this 
w ork.  This  work  was  supported  in  part  b y  a  grant  from  the  US  Air  Force  Of fice  o f  
Scientific Res earch (AFOSR grant number FA9550-04-1-0317). 

R e f e r e n c e s  

[1] Gilovich, T., Vallone, R. and Tversky, A. (1985). The hot hand in basketball: on the 
misperception of random sequences. Cognitive Psychology17, 295-314. 

[2] Albright, S.C. (1993a). A statistical analysis of hitting streaks in baseball. Journal of the 
American Statistical Association, 88, 1175-1183. 

[3] Stephens, D.A. (1994). Bayesian retrospective multiple changepoint  identification . Applied 
Statistics 43(1), 159-178. 

[4]  Carlin,  B .P.,  Gelfand,  A.E .,  &  Smith,  A.F.M.  (1992).  Hierarchical  Bayesian  analysis   of  
changepoint problems. Applied Statistics 41(2),  389-405.  

[5] Green, P.J. (1995). Reversible jump Markov chain Monte  Carlo  computation and Bayesian 
model determination. Biometrika 82(4),  711-732.  

[6]  Gigerenzer,  G.,  &  Goldstein,  D.G .  (1996).  Reasoning  the  fast  and  frugal  way : Models  of  
bounded rationality.  Psychological Review,  103,  650-669.  

