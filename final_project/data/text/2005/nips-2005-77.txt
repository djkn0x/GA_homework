From Batch to Transductive Online Learning

Sham Kakade
Toyota Technological Institute
Chicago, IL 60637
sham@tti-c.org

Adam Tauman Kalai
Toyota Technological Institute
Chicago, IL 60637
kalai@tti-c.org

Abstract

It is well-known that everything that is learnable in the difﬁcult online
setting, where an arbitrary sequences of examples must be labeled one at
a time, is also learnable in the batch setting, where examples are drawn
independently from a distribution. We show a result in the opposite di-
rection. We give an efﬁcient conversion algorithm from batch to online
that is transductive: it uses future unlabeled data. This demonstrates the
equivalence between what is properly and efﬁciently learnable in a batch
model and a transductive online model.

1 Introduction

There are many striking similarities between results in the standard batch learning setting,
where labeled examples are assumed to be drawn independently from some distribution,
and the more difﬁcult online setting, where labeled examples arrive in an arbitrary se-
quence. Moreover, there are simple procedures that convert any online learning algorithm
to an equally good batch learning algorithm [8]. This paper gives a procedure going in the
opposite direction.
It is well-known that the online setting is strictly harder than the batch setting, even for
the simple one-dimensioanl class of threshold functions on the interval [0, 1]. Hence, we
consider the online transductive model of Ben-David, Kushilevitz, and Mansour [2]. In
this model, an arbitrary but unknown sequence of n examples (x1 , y1 ), . . . , (xn , yn ) ∈
X × {−1, 1} is ﬁxed in advance, for some instance space X . The set of unlabeled examples
is then presented to the learner, Σ = {xi |1 ≤ i ≤ n}. The examples are then revealed, in an
online manner, to the learner, for i = 1, 2, . . . , n. The learner observes example xi (along
with all previous labeled examples (x1 , y1 ), . . . , (xi−1 , yi−1 ) and the unlabeled example
set Σ) and must predict yi . The true label yi is then revealed to the learner. After this
occurs, the learner compares its number of mistakes to the minimum number of mistakes of
any of a target class F of functions f : X → {−1, 1} (such as linear threshold functions).
Note that our results are in this type of agnostic model [7], where we allow for arbitrary
labels, unlike the realizable setting, i.e., noiseless or PAC models, where it is assumed that
the labels are consistent with some f ∈ F .
With this simple transductive knowledge of what unlabeled examples are to come, one
can use existing expert algorithms to inefﬁciently learn any class of ﬁnite VC dimension,
similar to the batch setting. How does one use unlabeled examples efﬁciently to guarantee
good online performance?

Our efﬁcient algorithm A2 converts a proper1 batch algorithm to a proper online algorithm
(both in the agnostic setting). At any point in time, it has observed some labeled examples.
It then “hallucinates” random examples by taking some number of unlabeled examples and
labeling them randomly. It appends these examples to those observed so far and predicts
according to the batch algorithm that ﬁnds the hypothesis of minimum empirical error on
the combined data.
The idea of “hallucinating” and optimizing has been used for designing efﬁcient online
algorithms [6, 5, 1, 10, 4] in situations where exponential weighting schemes were inefﬁ-
cient. The hallucination analogy was suggested by Blum and Hartline [4]. In the context
of transductive learning, it seems to be a natural way to try to use the unlabeled examples
in conjunction with a batch learner. Let #mistakes(f , σn ) denote the number of mistakes
of a function f ∈ F on a particular sequence σn ∈ (X × {−1, 1})n , and #mistakes(A, σn )
denote the same quantity for a transductive online learning algorithm A. Our main theorem
is the following.
Theorem 1. Let F be a class of functions f : X → {−1, 1} of VC dimension d. There
is an efﬁcient randomized transductive online algorithm that, for any n > 1 and σn ∈
(cid:112)
(X × {−1, 1})n ,
E[#mistakes(A2 , σn )] ≤ minf ∈F #mistakes(f , σn ) + 2.5n3/4
The algorithm is computationally efﬁcient in the sense that it runs in time poly(n), given
an efﬁcient proper batch learning algorithm.
(cid:112)
One should note that the bound on the error rate is the same as that of the best f ∈ F plus
O(n−1/4
d log(n)), approaching 0 at a rate related to the standard VC bound.
It is well-known that, without regard to computational efﬁciency, the learnable classes of
functions are exactly those with ﬁnite VC dimension. Consequently, the classes of func-
tions learnable in the batch and transductive online settings are the same. The classes of
functions properly learnable by computationally efﬁcient algorithms in the proper batch
and transductive online settings are identical, as well.
In addition to the new algorithm, this is interesting because it helps justify a long line of
work suggesting that whatever can be done in a batch setting can also be done online.
Our result is surprising in light of earlier work by Blum showing that a slightly different
online model is harder than its batch analog for computational reasons and not information-
theoretic reasons [3].
In Section 2, we deﬁne the transductive online model. In Section 3, we analyze the easier
case of data that is realizable with respect to some function class, i.e., when there is some
function of zero error in the class. In Section 4, we present and analyze the hallucination
algorithm. In Section 5, we discuss open problems such as extending the results to improper
learning and the efﬁcient realizable case.

d log n.

2 Models and deﬁnitions

The transductive online model considered by Ben-David, Kushlevitz, and Mansour [2],
consists of an instance space X and label set Y which we will always take to be bi-
nary Y = {−1, 1}. An arbitrary n > 0 and arbitrary sequence of labeled examples
(x1 , y1 ), . . . , (xn , yn ) is ﬁxed. One can think of these as being chosen by an adversary
who knows the (possibly randomized) learning algorithm but not the realization of its ran-
dom coin ﬂips. For notational convenience, we deﬁne σi to be the subsequence of ﬁrst i
1A proper learning algorithm is one that always outputs a hypothesis h ∈ F .

labeled examples,

σi = (x1 , y1 ), (x2 , y2 ), . . . , (xi , yi ),
and Σ to be the set of all unlabeled examples in σn ,
Σ = {xi | i ∈ {1, 2, . . . , n}}.

A transductive online learner A is a function that takes as input n (the number of examples
to be predicted), Σ ⊆ X (the set of unlabeled examples, |Σ| ≤ n), xi ∈ Σ (the example
to be tested), and σi−1 ∈ (Σ × Y )i−1 (the previous i − 1 labeled examples) and outputs a
prediction ∈ Y of yi , for any 1 ≤ i ≤ n. The number of mistakes of A on the sequence
σn = (x1 , y1 ), . . . , (xn , yn ) is,
#mistakes(A, σn ) = |{i | A(n, Σ, xi , σi−1 ) (cid:54)= yi }|.
If A is computed by a randomized algorithm, then we similarly deﬁne E[#mistakes(A, σn )]
where the expectation is taken over the random coin ﬂips of A. In order to speak of the
learnability of a set F of functions f : X → Y , we deﬁne
#mistakes(f , σn ) = |{i | f (xi ) (cid:54)= yi}|.
Formally, paralleling agnostic learning [7],2 we deﬁne an efﬁcient transductive online
learner A for class F to be one for which the learning algorithm runs in time poly(n)
and achieves, for any  > 0,
E[#mistakes(A, σn )] ≤ minf ∈F #mistakes(f , σn ) + n,
for n =poly(1/).3

2.1 Proper learning
Proper batch learning requires one to output a hypothesis h ∈ F . An efﬁcient proper
batch learning algorithm for F is a batch learning algorithm B that, given any  > 0, with
n = poly(1/) many examples from any distribution D , outputs an h ∈ F of expected
error E[PrD [h(x) (cid:54)= y ]] ≤ minf ∈F PrD [f (x) (cid:54)= y ] +  and runs in time poly(n).
Observation 1. Any efﬁcient proper batch learning algorithm B can be converted into an
efﬁcient empirical error minimizer M that, for any n, given any data set σn ∈ (X × Y )n ,
outputs an f ∈ F of minimal empirical error on σn .

Proof. Running B only on σn , B is not guaranteed to output a hypothesis of minimum
empirical error. Instead, we set an error tolerance of B to  = 1/(4n), and give it examples
drawn uniformly from the distribution D which is uniform over the data σn (a type of
bootstrap). If B indeed returns a hypothesis h of error less than 1/n more than the best
f ∈ F , it must be a hypothesis of minimum empirical error on σn . By Markov’s inequality,
with probability at most 1/4, the generalization error is more than 1/n. By repeating
several times and take the best hypothesis, we get a success probability exponentially close
to 1. The runtime is polynomial in n.

To deﬁne proper learning in an online setting, it is helpful to think of the following alter-
native deﬁnition of transductive online learning. In this variation, the learner must output
a sequence of hypotheses h1 , h2 , . . . , hn : X → {−1, 1}. After the ith hypothesis hi is
output, the example (xi , yi ) is revealed, and it is clear whether the learner made an error.
Formally, the (possibly randomized) algorithm A(cid:48) still takes as input n, Σ, and σi−1 (but
2 It is more common in online learning to bound the total number of mistakes of an online algo-
rithm on an arbitrary sequence. We bound its error rate, as is usual for batch learning.
3The results in this paper could be replaced by high-probability 1 − δ bounds at a cost of log 1/δ .

no longer xi ), and outputs hi : X → {−1, 1} and errs if hi (xi ) (cid:54)= yi . To see that this
model is equivalent to the previous deﬁnition, note that any algorithm A(cid:48) that outputs hy-
potheses hi can be used to make predictions hi (xi ) on example i (it errs if hi (xi ) (cid:54)= yi ).
It is equally true but less obvious than any algorithm A in the previous model can be con-
verted to an algorithm A(cid:48) in this model. This is because A(cid:48) can be viewed as outputting
hi : X → {−1, 1}, where the function hi is deﬁned by setting hi (x) equal to be the predic-
tion of algorithm A on the sequence σi−1 followed by the example x, for each x ∈ X , i.e.,
hi (x) = A(n, Σ, x, σi−1 ). (The same coins can be used if A and A(cid:48) are randomized.) A
(possibly randomized) transductive online algorithm in this model is deﬁned to be proper
for family of functions F if it always outputs hi ∈ F .

3 Warmup: the realizable case
In this section, we consider the realizable special case in which there is some f ∈ F which
correctly labels all examples. In particular, this means that we only consider sequences
σn for which there is an f ∈ F with #mistakes(f , σn ) = 0. This case will be helpful to
analyze ﬁrst as it is easier.
Fix arbitrary n > 0 and Σ = {x1 , x2 , . . . , xn} ⊆ X , |Σ| ≤ n. Say there are at most L
different ways to label the examples in Σ according to functions f ∈ F , so 1 ≤ L ≤ 2|Σ| .
In the transductive online model, L is determined by Σ and F only. Hence, as long as
prediction occurs only on examples x ∈ Σ, there are effectively only L different functions
in F that matter, and we can thus pick L such functions that give rise to the L different
labelings. On the ith example, one could simply take majority vote of fj (xi ) over consistent
labelings fj (the so-called halving algorithm), and this would easily ensure at most log2 (L)
mistakes, because each mistake eliminates at least half of the consistent labelings. One can
also use the following proper learning algorithm.

Proper transductive online learning algorithm in the realizable case:
• Preprocessing: Given the set of unlabeled examples Σ, take L func-
tions f1 , f2 , . . . , fL ∈ F that give rise to the L different labelings
of x ∈ Σ.4
• ith prediction: Output a uniformly random function f from the fj
consistent with σi−1 .

The above algorithm, while possibly very inefﬁcient, is easy to analyze.
Theorem 2. Fix a class of binary functions F of VC dimension d. The above random-
ized proper learning algorithm makes an expected d log(n) mistakes on any sequence of
examples of length n ≥ 2, provided that there is some mistake-free f ∈ F .

Proof. Let Vi be the number of labelings fj consistent with the ﬁrst i examples, so that
L = V0 ≥ V1 ≥ · · · ≥ Vn ≥ 1 and L ≤ nd , by Sauer’s lemma [11] for n ≥ 2, where
d is the VC dimension of F . Observe that the number of consistent labelings that make
a mistake on the ith example are exactly Vi−1 − Vi . Hence, the total expected number of
(cid:182)
(cid:181)
≤ n(cid:88)
n(cid:88)
≤ Vn(cid:88)
mistakes is,
Vi−1 − Vi
1
1
1
Vi−1 − 1
Vi + 1
Vi−1
Vi−1
i=1
i=1
i=2
4More formally, take L functions with the following properties: for each pair 1 ≤ j, k ≤ L with
j (cid:54)= k , there exists x ∈ Σ such that fj (x) (cid:54)= fk (x), and for every f ∈ F , there exists a 1 ≤ j ≤ L
with f (x) = fj (x) for all x ∈ Σ.

≤ log(L).

1
i

+

+ . . .

Hence the above algorithm achieves an error rate of O(d log(n)/n), which quickly ap-
proaches zero for large n. Note that, this closely matches what one achieves in the batch
setting. Like the batch setting, no better bounds can be given up to a constant factor.

4 General setting

We now consider the more difﬁcult unrealizable setting where we have an unconstrained
sequence of examples (though we still work in a transductive setting). We begin by pre-
senting an known (inefﬁcnet) extension to the halving algorithm of the previous section,
that works in the agnostic (unrealizable) setting that is similar to the previous algorithm.

Inefﬁcient proper transductive online learning algorithm A1 :
• Preprocessing: Given the set of unlabeled examples Σ, take L func-
tions f1 , f2 , . . . , fL that give rise to the L different labelings of
x ∈ Σ. Assign an initial weight w1 = w2 = . . . = wL = 1 to
each function.
(cid:181)
(cid:182)
• Output fj , where 1 ≤ j ≤ L is chosen with probability
(cid:113)
• Update: for each j for which fj (xi ) (cid:54)= yi , reduce wj ,
1 −
wj := wj
log L
.
n

wj
w1+...+wL

.

(cid:112)
Using an analysis very similar to that of Weighted Majority [9], one can show that, for any
n > 1 and sequence of examples σn ∈ (X × {−1, 1})n ,
E[#mistakes(A1 , σn )] = minf ∈F #mistakes(f , σn ) + 2
dn log n,
where d is the VC dimension of F . Note the similarity to the standard VC bound.

4.1 Efﬁcient algorithm

We can only hope to get an efﬁcient proper online algorithm when there is an efﬁcient
proper batch algorithm. As mentioned in section 2.1, this means that there is a batch
algorithm M that, given any data set, efﬁciently ﬁnds a hypothesis h ∈ F of minimum
empirical error. (In fact, most proper learning algorithms work this way to begin with.)
Using this, our efﬁcient algorithm is as follows.

Efﬁcient transductive online learning algorithm A2 :
• Preprocessing: Given the set of unlabeled examples Σ, create a hal-
lucinated data set τ as follows.
1. For each example x ∈ Σ, choose integer rx uniformly at random
such that − 4√
n ≤ rx ≤ 4√
n.
2. Add |rx | copies of the example x labeled by the sign of rx ,
(x, sgn(rx )), to τ .
• To predict on xi : output hypothesis M (τ σi−1 ) ∈ F , where τ σi−1
is the concatenation of the hallucinated examples and the observed
labeled examples so far.

The current algorithm predicts f (xi ) based on f = M (τ σi−1 ). We ﬁrst begin by analyzing
the hypothetical algorithm that used the function chosen on the next iteration, i.e. predict
f (xi ) based on f = M (τ σi ). (Of course, this is impossible to implement because we do
not know σi when predicting f (xi ).)

Lemma 1. Fix any τ ∈ (X × Y )∗ and σn ∈ (X × Y )n . Let A(cid:48)
2 be the algorithm that, for
each i, predicts f (xi ) based on f ∈ F which is any empirical minimizer on the concate-
nated data τ σi , i.e., f = M (τ σi ). Then the total number of mistakes of A(cid:48)
2 is,
2 , σn ) ≤ minf ∈F #mistakes(f , τ σn ) − minf ∈F #mistakes(f , τ ).
#mistakes(A(cid:48)

It is instructive to ﬁrst consider the case where τ is empty, i.e., there are no hallucinated
examples. Then, our algorithm that predicts according to M (σi−1 ) could be called “follow
the leader,” as in [6]. The above lemma means that if one could use the hypothetical “be
the leader” algorithm then one would make no more mistakes than the best f ∈ F . The
proof of this case is simple. Imagine starting with the ofﬂine algorithm that uses M (σn )
on each example x1 , . . . , xn . Now, on the ﬁrst n − 1 examples, replace the use of M (σn )
by M (σn−1 ). Since M (σn−1 ) is an error-minimizer on σn−1 , this can only reduce the
number of mistakes. Next replace M (σn−1 ) by M (σn−2 ) on the ﬁrst n − 2 examples, and
so on. Eventually, we reach the hypothetical algorithm above, and we have only decreased
our number of mistakes. The proof of the above lemma follows along these lines.

(1)

#mistakes(g0 , τ ) +

mi ≤ #mistakes of gt on τ σt .

Proof of Lemma 1. Fix empirical minimizers gi on τ σi for i = 0, 1, . . . , n, i.e., gi =
M (τ σi ). For i ≥ 1, let mi be 1 if gi (xj ) (cid:54)= yj and 0 otherwise. We argue by induc-
t(cid:88)
tion on t that,
#mistakes(g0 , τ ) +
i=1
t+1(cid:88)
For t = 0, the two are trivially equal. Assuming it holds for t, we have,
i=1

mi ≤ #mistakes(gt , τ σt ) + mt+1
≤ #mistakes(gt+1 , τ σt ) + mt+1
= #mistakes(gt+1 , τ σt+1 ).
The ﬁrst inequality above holds by induction hypothesis, and the second follows from the
(cid:80)n
fact that gt is an empirical minimizer of τ σt . The equality establishes (1) for t + 1 and thus
completes the induction. The total mistakes of the hypothetical algorithm proposed in the
i=1 mi , which gives the lemma by rearranging (1) for t = n.
lemma is
Lemma 2. For any σn ,
Eτ [minf ∈F #mistakes(f , τ σn )] ≤ Eτ [|τ |/2] + minf ∈F #mistakes(f , σn ).
(cid:112)
For any F of VC dimension d,
Eτ [minf ∈F #mistakes(f , τ )] ≥ Eτ [|τ |/2] − 1.5n3/4

d log n.

Proof. For the ﬁrst part of the lemma, let g = M (σn ) be an empirical minimizer on σn .
Then,
Eτ [minf ∈F #mistakes(f , τ σn )] ≤ Eτ [#mistakes(g , τ σn )] = Eτ [|τ |/2]+#mistakes(g , σn ).
The last inequality holds because, since each example in τ is equally likely to have a ±
label, the expected number of mistakes of any ﬁxed g ∈ F on τ is E[|τ |/2].
Fix any f ∈ F . For the second part of the lemma, observe that we can write the number of
|τ | − (cid:80)n
mistakes of f on τ as,
i=1 f (xi )ri
2

#mistakes(f , τ ) =

.

(cid:112)
(cid:80)n
i=1 f (xi )ri ≤ 3n3/4
Hence it sufﬁces to show that, maxf ∈F
log(L).
(cid:80)n
Now Eri [f (xi )ri ] = 0 and |f (xi )ri | ≤ n1/4 . Next, Chernoff bounds (on the scaled ran-
(cid:80)
dom variables f (xi )rin−1/4 ) imply that, for any α ≤ 1, with probability at most e−nα2 /2 ,
i=1 f (xi )rin−1/4 ≥ nα. Put another way, for any β < n, with probability at most
(cid:80)
f (xi )rin−1/4 ≥ β . As observed before, we can reduce the problem to
e−n−3/2 β 2 /2 ,
the L different labelings.
In other words, we can assume that there are only L differ-
(cid:82) ∞
(cid:80)n
f (xi )ri ≥ β for any f ∈ F
ent functions. By the union bound, the probability that
is at most Le−n−3/2 β 2 /2 . Now the expectation of a non-negative random variable X is
(cid:90) ∞
(cid:112)
0 Pr[X ≥ x]dx. Let X = maxf ∈F
E[X ] =
i=1 f (xi )ri . In our case,
(cid:112)
(cid:112)
E[X ] ≤
Le−n−3/4 x2 /2dx
√
2 log(L)n3/4 +
2 log(L)n3/4
2 log(L)n3/4 + 1.254n3/4 ≤ 3
log(L)n3/4 .
By Mathematica, the above is at most
Finally, we use the fact that L ≤ nd by Sauer’s lemma.
Unfortunately, we cannot use the algorithm A(cid:48)
2 . However, due to the randomness we have
added, we can argue that algorithm A2 is quite close:
Lemma 3. For any σn , for any i, with probability at least 1 − n−1/4 over τ , M (τ σi−1 ) is
an empirical minimizer of τ σi .
Proof. Deﬁne, F+ = {f ∈ F | f (xi ) = 1} and F− = {f ∈ F | f (xi ) = −1}. WLOG,
we may assume that F+ and F− are both nonempty. For if not, i.e., if all f ∈ F predict
the same sign f (xi ), then the sets of empirical minimizers of τ σi−1 and τ σi are equal and
the lemma holds trivially. For any sequence π ∈ (X × Y )∗ , deﬁne,
s+ (π) = minf ∈F+ #mistakes(f , π) and s− (π) = minf ∈F− #mistakes(f , π).
Next observe that, if s+ (π) < s− (π) then M (π) ∈ F+ . Similarly if s− (π) < s+ (π) then
M (π) ∈ F− . If they are equal then f (xi ) can be an empirical minimizer in either. WLOG
let us say that the ith example is (xi , 1), i.e., it is labeled positively. This implies that
s+ (τ σi−1 ) = s+ (τ σi ) and s− (τ σi−1 ) = s− (τ σi ) + 1. It is now clear that if M (τ σi−1 ) is
not also an empirical minimizer of τ σi then s+ (τ σi−1 ) = s− (τ σi−1 ).
Now the quantity ∆ = s+ (τ σi−1 )− s− (τ σi−1 ) is directly related to rxi , the signed random
number of times that example xi is hallucinated. If we ﬁx σn and the random choices rx
for each x ∈ Σ \ {xi }, as we increase or decrease ri by 1, ∆ correspondingly increases or
decreases by 1. Since ri was chosen from a range of size 2(cid:98)n1/4 (cid:99) + 1 ≥ n1/4 , ∆ = 0 with
probability at most n−1/4 .

We are now ready to prove the main theorem.

Proof of Theorem 1. Combining Lemmas 1 and 2, if on each period i, we used any mini-
most minf ∈F #mistakes(f , σn ) + 1.5n3/4√
mizer of empirical error on the data τ σi , we would have a total number of mistakes of at
d log n. Suppose A2 does end up using such
a minimizer on all but p periods. Then, its total number of mistakes can only be p larger
than this bound. By Lemma 3, the expected number p of periods i in which an empirical
(cid:112)
minimizer of τ σi is not used is ≤ n3/4 . Hence, the expected total number of mistakes of
A2 is at most,
Eτ [#mistakes(A2 , σn )] ≤ minf ∈F #mistakes(f , σn ) + 1.5n3/4
d log n + n3/4 .
The above implies the theorem.

Remark 1. The above algorithm is still costly in the sense that we must re-run the batch
error minimizer for each prediction we would like to make. Using an idea quite similar to
the “follow the lazy leader” algorithm in [6], we can achieve the same expected error while
only needing to call M with probability n−1/4 on each example.
Remark 2. The above analysis resembles previous analysis of hallucination algorithms.
However, unlike previous analyses, there is no exponential distribution in the hallucination
here yet the bounds still depend only logarithmically on the number of labelings.

5 Conclusions and open problems

We have given an algorithm for learning in the transductive online setting and established
several results between efﬁcient proper batch and transductive online learnability. In the
realizable case, however, we have not given a computationally efﬁcient algorithm. Hence,
it is an open question as to whether efﬁcient learnability in the batch and transductive on-
line settings are the same in the realizable case. In addition, our computationally efﬁcient
algorithm requires polynomially more examples than its inefﬁcient counterpart. It would
√
be nice to have the best of both worlds, namely a computationally efﬁcient algorithm that
achieves a number of mistakes that is at most O(
dn log n). Additionally, it would be nice
to remove the restriction to proper algorithms.
Acknowledgements. We would like to thank Maria-Florina Balcan, Dean Foster, John
Langford, and David McAllester for helpful discussions.

References
[1] B. Awerbuch and R. Kleinberg. Adaptive routing with end-to-end feedback: Distributed learning
and geometric approaches. In Proc. of the 36th ACM Symposium on Theory of Computing, 2004.
[2] S. Ben-David, E. Kushilevitz, and Y. Mansour. Online learning versus ofﬂine learning. Machine
Learning 29:45-63, 1997.
[3] A. Blum. Separating Distribution-Free and Mistake-Bound Learning Models over the Boolean
Domain. SIAM Journal on Computing 23(5): 990-1000, 1994.
[4] A. Blum, J. Hartline. Near-Optimal Online Auctions. In Proceedings of the Proceedings of the
Sixteenth Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), 2005.
[5] J. Hannan. Approximation to Bayes Risk in Repeated Plays. In M. Dresher, A. Tucker, and
P. Wolfe editors, Contributions to the Theory of Games, Volume 3, p. 97-139, Princeton Univer-
sity Press, 1957.
[6] A. Kalai and S. Vempala. Efﬁcient algorithms for the online decision problem. In Proceedings
of the 16th Conference on Computational Learning Theory, 2003.
[7] M. Kearns, R. Schapire, and L. Sellie. Toward Efﬁcient Agnostic Learning. Machine Learning,
17(2/3):115–141, 1994.
[8] N. Littlestone. From On-Line to Batch Learning. In Proceedings of the 2nd Workshop on Com-
putational Learning Theory, p. 269-284, 1989.
[9] N. Littlestone and M. Warmuth. The Weighted Majority Algorithm. Information and Computa-
tion, 108:212-261, 1994.
[10] H. Brendan McMahan and Avrim Blum. Online Geometric Optimization in the Bandit Setting
Against an Adaptive Adversary. In Proceedings of the 17th Annual Conference on Learning
Theory, COLT 2004.
[11] N. Sauer. On the Densities of Families of Sets. Journal of Combinatorial Theory, Series A, 13,
p 145-147, 1972.
[12] V. N. Vapnik. Estimation of Dependencies Based on Empirical Data, New York: Springer Ver-
lag, 1982.
[13] V. N. Vapnik. Statistical Learning Theory, New York: Wiley Interscience, 1998.

