Worst-Case Bounds for Gaussian Process Models

Sham M. Kakade
University of Pennsylvania

Matthias W. Seeger
UC Berkeley

Dean P. Foster
University of Pennsylvania

Abstract

We present a competitive analysis of some non-parametric Bayesian al-
gorithms in a worst-case online learning setting, where no probabilistic
assumptions about the generation of the data are made. We consider
models which use a Gaussian process prior (over the space of all func-
tions) and provide bounds on the regret (under the log loss) for com-
monly used non-parametric Bayesian algorithms — including Gaussian
regression and logistic regression — which show how these algorithms
can perform favorably under rather general conditions. These bounds ex-
plicitly handle the inﬁnite dimensionality of these non-parametric classes
in a natural way. We also make formal connections to the minimax and
minimum description length (MDL) framework. Here, we show precisely
how Bayesian Gaussian regression is a minimax strategy.

Introduction
1
We study an online (sequential) prediction setting in which, at each timestep, the learner is
given some input from the set X , and the learner must predict the output variable from the
set Y . The sequence {(xt , yt )| t = 1, . . . , T } is chosen by Nature (or by an adversary), and
importantly, we do not make any statistical assumptions about its source: our statements
hold for all sequences. Our goal is to sequentially code the next label yt , given that we
have observed x≤t and y<t (where x≤t and y<t denote the sequences {x1 , . . . xt} and
{y1 , . . . yt−1 }). At each time t, we have a conditional distribution P (·|x≤t , y<t ) over Y ,
which is our prediction strategy that is used to predict the next variable yt . We then incur
the instantaneous loss − log P (yt |x≤t , y<t ) (referred to as log loss), and the cumulative
loss is the sum of these instantaneous losses over t = 1, . . . , T .
Let Θ be a parameter space indexing elementary prediction rules in some model class,
where P (y |x, θ) for θ ∈ Θ is a conditional distribution over Y called the likelihood. An ex-
pert is a single atom θ ∈ Θ, or, more precisely, the algorithm which outputs the predictive
distribution P (·|xt , θ) for every t. We are interested in bounds on the regret — the differ-
ence in the cumulative loss of a given adaptive prediction strategy and the the cumulative
loss of the best possible expert chosen in hindsight from a subset of Θ.
Kakade and Ng [2004] considered a parametric setting where Θ = Rd , X = Rd , and
the prediction rules were generalized linear models, in which P (y |x, θ) = P (y |θ · x).
They derived regret bounds for the Bayesian strategy (assuming a Gaussian prior over Θ),
which showed that many simple Bayesian algorithms (such as Gaussian linear regression
and logistic regression) perform favorably when compared, in retrospect, to the best θ ∈ Θ.
Importantly, these regret bounds have a time and dimensionality dependence of the form
2 log T — a dependence common in in most MDL procedures (see Grunwald [2005]). For
d
Gaussian linear regression, the bounds of Kakade and Ng [2004] are comparable to the best
bounds in the literature, such as those of Foster [1991], Vovk [2001], Azoury and Warmuth

[2001] (though these latter bounds are stated in terms of the closely related square loss).
In this paper, we provide worst-case regret bounds on Bayesian non-parametric methods,
which show how these algorithms can have low regret. In particular, we examine the case
where the prior (over functions) is a Gaussian process — thereby extending the work of
Kakade and Ng [2004] to inﬁnite-dimensional spaces of experts. There are a number of
important differences between this and the parametric setting. First, it turns out that the
natural competitor class is the reproducing kernel Hilbert space (RKHS) H. Furthermore,
the notion of dimensionality is more subtle, since the space H may be inﬁnite dimensional.
In general, there is no apriori reason that any strategy (including the Bayesian one) should
be able to compete favorably with the complex class H. However, for some input se-
quences x≤T and kernels, we show that it is possible to compete favorably. Furthermore,
the relation of our results to Kakade and Ng [2004] is made explicit in Section 3.2.
Our second contribution is in making formal connections to minimax theory, where we
show precisely how Bayesian Gaussian regression is a minimax algorithm. In a general
setting, Shtarkov [1987] showed that a certain normalized maximum likelihood (NML) dis-
tribution minimizes the regret in the worst case. Unfortunately, for some “complex” model
classes, there may exist no strategy which achieves ﬁnite regret, and so the NML distribu-
tion may not exist.1 Gaussian density estimation (formally described in Example 4.2) is
one such case where this NML distribution does not exist. If one makes further restrictions
(on Y ), then minimax results can be derived, such as in Takimoto and Warmuth [2000],
Barron et al. [1998], Foster and Stine [2001].
Instead of making further restrictions, we propose minimizing a form of a penalized regret,
where one penalizes more “complex” experts as measured by their cost under a prior q(θ).
This penalized regret essentially compares our cumulative loss to the loss of a two part code
(common in MDL, see Grunwald [2005]), where one ﬁrst codes the model θ under a prior
q and then codes the data using this θ . Here, we show that a certain normalized maximum
a posteriori distribution is the corresponding minimax strategy, in general. Our main result
here is in showing that for Gaussian regression, the Bayesian strategy is precisely this
minimax strategy. The differences between this result and that of Takimoto and Warmuth
[2000] are notable. In the later, they assume Y ⊂ R is bounded and derive (near) minimax
algorithms which hold the variance of their predictions constant at each timestep (so they
effectively deal with the square loss). Under Bayes rule, the variance of the predictions
adapts, which allows the minimax property to hold with Y = R being unbounded.
Other minimax results have been considered in the non-parametric setting. The work of
Opper and Haussler [1998] and Cesa-Bianchi and Lugosi [2001] provide minimax bounds
in some non-parametric cases (in terms of a covering number of the comparator class),
though they do not consider input sequences.
The rest of the paper is organized as follows: Section 2 summarizes our model, Section 3
presents and discusses our bounds, and Section 4 draws out the connections to the minimax
and MDL framework. All proofs are available in a forthcoming longer version of this paper.

2 Bayesian Methods with Gaussian Process Priors
Z
With a Bayesian prior distribution Pbayes (θ) over Θ, the Bayesian predicts yt using the rule
P (yt |xt , θ)Pbayes (θ |x<t , y<t ) dθ
Pbayes (yt |x≤t , y<t ) =
where the posterior is given by
Pbayes (θ |x<t , y<t ) ∝ P (y<t |x<t , θ)Pbayes (θ).
1For these cases, the normalization constant of the NML distribution is not ﬁnite.

t−1Y
Assuming the Bayesian learner models the data to be independent given θ , then
P (y<t |x<t , θ) =
P (yt0 |xt0 , θ) .
t0=1
It is important to stress that these are “working assumptions” in the sense that they lead to
a prediction strategy (the Bayesian one), but the analysis does not make any probabilistic
− TX
assumptions about the generation of the data. The cumulative loss of the Bayesian strategy
is then
log Pbayes (yt |x≤t , y<t ) = − log Pbayes (y≤T |x≤T ).
t=1
which follows form the chain rule of conditional probabilities.
In this paper, we are interested in non-parametric prediction, which can be viewed as work-
ing with an inﬁnite-dimensional function space Θ — assume Θ consists of real-valued
functions u(x). The likelihood P (y |x, u(·)) is thus a distribution over y given x and the
function u(·). Similar to Kakade and Ng [2004] (where they considered generalized linear
models), we make the natural restriction that P (y |x, u(·)) = P (y |u(x)). We can think of
u as a latent function and of P (y |u(x)) as a noise distribution. Two particularly important
cases are that of Gaussian regression and logistic regression. In Gaussian regression, we
have that Y = R and that P (y |u(x)) = N (y |u(x), σ2 ) (so y is distributed as a Gaus-
In logistic regression, Y = {−1, 1} and
sian with mean u(x) and ﬁxed variance σ2 ).
P (y |u(x)) = (1 + e−yu(x) )−1 .
In this paper, we consider the case in which the prior dPbayes (u(·)) is a zero-mean Gaus-
sian process (GP) with covariance function K , i.e. a real-valued random process which has
the property that for every ﬁnite set x1 , . . . , xn the random vector (u(x1 ), . . . , u(xn ))T is
multivariate Gaussian, distributed as N (0, K ), where K ∈ Rn,n is the covariance (or
kernel) matrix with K i,j = K (xi , xj ). Note that K has to be a positive semideﬁnite func-
tion in that for all ﬁnite sets x1 , . . . , xn the corresponding kernel matrices K are positive
semideﬁnite.
Finally, we specify the subset of experts we would like the Bayesian prediction strategy to
ﬁnite kernel expansions (over any x1 , . . . , xn ) of the form f (x) = Pn
compete against. Every positive semideﬁnite kernel K is associated with a unique repro-
ducing kernel Hilbert space (RKHS) H, deﬁned as follows: consider the linear space of all
the inner productX

i=1 αiK (x, xi ) with
= X
X
βj K (·, yj )
αiK (·, xi ),
ﬁnite kernel expansions f (x) = Pn
i
i,j
j
K
and deﬁne the RKHS H as the completion of this space. By construction, H contains all
i=1 αiK (x, xi ) with
kf k2
K = αT K α , K i,j = K (xi , xj ) .
(1)
The characteristic property of H is that all (Dirac) evaluation functionals are represented in
H itself by the functions K (·, xi ), meaning (f , K (·, xi ))K = f (xi ). The RKHS H turns
out to be the largest subspace of experts for which our results are meaningful.

αiβj K (xi , yj ).

3 Worst-Case Bounds

In this section, we present our worst-case bounds, give an interpretation, and relate the
results to the parametric case of Kakade and Ng [2004]. The proofs are available in a
forthcoming longer version.

Theorem 3.1: Let (x≤T , y≤T ) be a sequence from (X × Y )T . For all functions f in the
RKHS H associated with the prior covariance function K , we have
1
1
− log Pbayes (y≤T |x≤T ) ≤ − log P (y≤T |x≤T , f (·)) +
log |I + cK | ,
kf k2
K +
2
2
where kf kK is the RKHS norm of f , K = (K (xt , xt0 )) ∈ RT ,T is the kernel matrix over
the input sequence x≤T , and c > 0 is a constant such that for all yt ∈ y≤T ,
− d2
du2 log P (yt |u) ≤ c

for all u ∈ R.

The proof of this theorem parallels that provided by Kakade and Ng [2004], with a number
of added complexities for handling GP priors. For the special case of Gaussian regression
where c = σ−2 , the following theorem shows the stronger result that the bound is satisﬁed
with an equality for all sequences.
Theorem 3.2: Assume P (yt |u(xt )) = N (yt |u(xt ), σ2 ) and that Y = R. Let (x≤T , y≤T )
(cid:27)
(cid:26)
be a sequence from (X × Y )T . Then,
− log Pbayes (y≤T |x≤T ) = min
− log P (y≤T |x≤T , f (·)) +
log (cid:12)(cid:12)I + σ−2K (cid:12)(cid:12)
f ∈H
1
2
and the minimum is attained for a kernel expansion over x≤T .

kf k2
K

+

1
2

(2)

This equality has important implications in our minimax theory (in Corollary 4.4, we make
this precise). It is not hard to see that the equality does not hold for other likelihoods.

3.1
Interpretation
K and log |I + cK |. We discuss each in turn.
The regret bound depends on two terms, kf k2
The dependence on kf k2
K states the intuitive fact that a meaningful bound can only be
obtained under smoothness assumptions on the set of experts. The more complicated f is
(as measured by k · kK ), the higher the regret may be. The equality shows in Theorem 3.2
shows this dependence is unavoidable. We come back to this dependence in Section 4.
Let us now interpret the log |I + cK | term, which we refer to as the regret term. The
constant c, which bounds the curvature of the likelihood, exists for most commonly used
exponential family likelihoods. For logistic regression, we have c = 1/4, and for the
Gaussian regression, we have c = σ−2 . Also, interestingly, while f is an arbitrary function
in H, this regret term depends on K only at the sequence points x≤T .
For most inﬁnite-dimensional kernels and without strong restrictions on the inputs, the
regret term can be as large as Ω(T ) — the sequence can be chosen s.t. K ≈ c0I , which
implies that log |I + cK | ≈ T log(1 + cc0 ). For example, for an isotropic kernel (which
is a function of the norm kx − x0 k2 ) we can choose the xt to be mutually far from each
other. For kernels which barely enforce smoothness — e.g. the Ornstein-Uhlenbeck kernel
exp(−bkx − x0 k1 ) — the regret term can easily Ω(T ). The cases we are interested in are
those where the regret term is o(T ), in which case the average regret tends to 0 with time.
A spectral interpretation of this term helps us understand the behavior.
If we let the
TX
λ1 , λ2 , . . . λT be the eigenvalues of K , then
log(1 + cλt ) ≤ c tr K
log |I + cK | =
t=1

where tr K is the trace of K . This last quantity is closely related to the “degrees of
freedom” in a system (see Hastie et al. [2001]). Clearly, if the sum of the eigenvalues has
a sublinear growth rate of o(T ), then the average regret tends to 0. Also, if one assumes
that the input sequence, x≤T , is i.i.d. then the above eigenvalues are essentially the process
eigenvalues.
In a forthcoming longer version, we explore this spectral interpretation in
more detail and provide a case using the exponential kernel in which the regret grows as
O(poly(log T )). We now review the parametric case.

3.2 The Parametric Case
Here we obtain a slight generalization of the result in Kakade and Ng [2004] as a special
case. Namely, the familiar linear model — with u(x) = θ · x, θ , x ∈ Rd and Gaussian
With X = (x1 , . . . xT )T we have that a kernel expansion f (x) = P
prior θ ∼ N (0, I ) — can be seen as a GP model with the linear kernel: K (x, x0 ) = x · x0 .
i αixi · x = θ · x with
log |I + cK | = log (cid:12)(cid:12)I + cX TX (cid:12)(cid:12)
K = αTX X Tα = kθk2
θ = X Tα , and kf k2
2 , so that H = {θ · x | θ ∈ Rd}, and so
Therefore, our result gives an input-dependent version of the result of Kakade and Ng
[2004]. If we make the further assumption that kxk2 ≤ 1 (as done in Kakade and Ng
(cid:19)
(cid:18)
[2004]), then we can obtain exactly their regret term:
log |I + cK | ≤ d log
1 + cT
d
which can seen by rotating K into an diagonal matrix and maximizing the expression sub-
ject to the constraint that kxk2 ≤ 1 (i.e. that the eigenvalues must sum to 1).
In general, this example shows that if K is a ﬁnite-dimension kernel such as the linear or
the polynomial kernel, then the regret term is only O(log T ).

4 Relationships to Minimax Procedures and MDL

This section builds the framework for understanding the minimax property of Gaussian re-
gression. We start by reviewing Shtarkov’s theorem, which shows that a certain normalized
maximum likelihood density is the minimax strategy (when using the log loss). In many
cases, this minimax strategy does not exist — in those cases where the minimax regret is
inﬁnite. We then propose a different, penalized notion of regret, and show that a certain
normalized maximum a posteriori density is the minimax strategy here. Our main result
(Corollary 4.4) shows that for Gaussian regression the Bayesian strategy is precisely this
minimax strategy

4.1 Normalized Maximum Likelihood
Here, let us assume that there are no inputs — sequences consist of only yt ∈ Y . Given a
measurable space with base measure µ, we employ a countable number of random variables
yt in Y . Fix the sequence length T and deﬁne the model class F = {Q(·|θ) | θ ∈ Θ)},
where Q(·|θ) denotes a joint probability density over Y T with respect to µ.
We assume that for our model class there exists a parameter, θml (y≤T ), maximizing the
likelihood Q(y≤T |θ) over Θ for all y≤T ∈ Y T . We make this assumption to make the
connections to maximum likelihood (and, later, MAP) estimation clear. Deﬁne the regret
of a joint density P on y≤T as:
R(y≤T , P , Θ) = − log P (y≤T ) − inf
{− log Q(y≤T |θ)}
θ∈Θ
= − log P (y≤T ) + log Q(y≤T |θml (y≤T )).

(3)

(4)

where the latter step uses our assumption on the existence of θml (y≤T ).
Deﬁne the minimax regret with respect to Θ as:
sup
R(Θ) = inf
y≤T ∈Y T
P
where the inf is over all probability densities on Y T .
The following theorem due to Shtarkov [1987] characterizes the minimax strategy.

R(y≤T , P , Θ)

Theorem 4.1: [Shtarkov, 1987]If the following density exists (i.e. if it has a ﬁnite normal-
ization constant), then deﬁne it to be the normalized maximum likelihood (NML) density.
R Q(y≤T |θml (y≤T ))dµ(y≤T )
Q(y≤T |θml (y≤T ))
If Pml exists, it is a minimax strategy, i.e. for all y≤T , the regret R(y≤T , Pml , Θ) does not
exceed R(Θ).

Pml (y≤T ) =

(5)

Note that this density exists only if the normalizing constant is ﬁnite, which is not the case
in general. The proof is straightforward using the fact that the NML density is an equalizer
— meaning that it has constant regret on all sequences.
log R Q(y≤T |θml (y≤T ))dµ(y≤T ).
Proof:
regret R(y≤T , Pml , Θ)
the
constant
the
is
First
note
that
To see this, simply substitute Eq. 5 into Eq. 4
and simplify.
For convenience, deﬁne the regret of any P as R(P , Θ) = supy≤T ∈Y T R(y≤T , P , Θ). For
any P 6= Pml (differing on a set with positive measure), there exists some y≤T such that
P (y≤T ) < Pml (y≤T ), since the densities are normalized. This implies that
R(P , Θ) ≥ R(y≤T , P , Θ) > R(y≤T , Pml , Θ) = R(Pml , Θ)
where the ﬁrst step follows from the deﬁnition of R(P , Θ),
the second from
− log P (y≤T ) > − log Pml (y≤T ), and the last from the fact that Pml is an equalizer (its
regret is constant on all sequences). Hence, P has a strictly larger regret, implying that Pml
(cid:3)
is the unique minimax strategy.
Unfortunately, in many important model classes, the minimax regret R(Θ) is not ﬁnite, and
the NML density does not exist. We now provide one example (see Grunwald [2005] for
further discussion).

Example 4.2: Consider a model which assumes the sequence is generated i.i.d. from
a Gaussian with unknown mean and unit variance. Speciﬁcally, let Θ = R, Y = R,
and P (y≤T |θ) be the product ΠT
t=1N (yt ; θ , 1).
It is easy to see that for this class the
minimax regret is inﬁnite and Pml does not exist (see Grunwald [2005]). This example
can be generalized to the Gaussian regression model (if we know the sequence x≤T in
advance). For this problem, if one modiﬁes the space of allowable sequences (i.e. Y T is
modiﬁed), then one can obtain ﬁnite regret, such as those in Barron et al. [1998], Foster
and Stine [2001]. This technique may not be appropriate in general.

4.2 Normalized Maximum a Posteriori
To remedy this problem, consider placing some structure on the model class F =
{Q(·|θ)|θ ∈ Θ}. The idea is to penalize Q(·|θ) ∈ F based on this structure. The mo-
tivation is similar to that of structural risk minimization [Vapnik, 1998]. Assume that Θ is

a measurable space and place a prior distribution with density function q on Θ. Deﬁne the
penalized regret of P on y≤T as:
Rq (y≤T , P , Θ) = − log P (y≤T ) − inf
{− log Q(y≤T |θ) − log q(θ)} .
θ∈Θ
Note that − log Q(y≤T |θ) − log q(θ) can be viewed as a “two part” code, in which we
ﬁrst code θ under the prior q and then code y≤T under the likelihood Q(·|θ). Unlike the
standard regret, the penalized regret can be viewed as a comparison to an actual code.
These two part codes are common in the MDL literature (see Grunwald [2005]). However,
in MDL, they consider using minimax schemes (via Pml ) for the likelihood part of the code,
while we consider minimax schemes for this penalized regret.
Again, for clarity, assume there exists a parameter, θmap (y≤T ) maximizing log Q(y≤T |θ)+
log q(θ). Notice that this is just the maximum aposteriori (MAP) parameter, if one were to
use a Bayesian strategy with the prior q (since the posterior density would be proportional
to Q(y≤T |θ)q(θ)). Here,
Rq (y≤T , P , Θ) = − log P (y≤T ) + log Q(y≤T |θmap (y≤T )) + log q(θmap (y≤T ))
Similarly, with respect to Θ, deﬁne the minimax penalized regret as:
Rq (y≤T P , Θ)
sup
Rq (Θ) = inf
y≤T ∈Y T
P
where again the inf is over all densities on Y T . If Θ is ﬁnite or countable and Q(·|θ) > 0
for all θ , then the Bayes procedure has the desirable property of having penalized regret
which is non-positive.2 However, in general, the Bayes procedure does not achieve the
minimax penalized regret, Rq (Θ), which is what we desire — though, for one case, we
show that it does (in the next section).
We now characterize this minimax strategy in general.
Theorem 4.3: Deﬁne the normalized maximum a posteriori (NMAP) density, if it exists, as:
R Q(y≤T |θmap (y≤T ))q(θmap (y≤T )) dµ(y≤T ) .
Q(y≤T |θmap (y≤T ))q(θmap (y≤T ))
If Pmap exists, it is a minimax strategy for the penalized regret, i.e. for all y≤T , the penalized
regret Rq (y≤T , Pmap , Θ) does not exceed Rq (Θ).

Pmap (y≤T ) =

(6)

The proof relies on Pmap being an equalizer for the penalized regret and is identical to that
of Theorem 4.1 — just replace all quantities with their penalized equivalents.

4.3 Bayesian Gaussian Regression as a Minimax Procedure

We now return to the setting with inputs and show how the Bayesian strategy for the Gaus-
sian regression model is a minimax strategy for all input sequences x≤T . If we ﬁx the input
sequence x≤T , we can consider the competitor class to be F = {P (y≤T |x≤T , θ) | θ ∈
Θ)}. In other words, we make the more stringent comparison against a model class which
has full knowledge of the input sequence in advance. Importantly, note that the learner only
observes the past inputs x<t at time t.
the Gaussian regression model, with likelihood P (y≤T |x≤T , u(·)) =
Consider
N (y≤T |u(x≤T ), σ2I ), where u(·) is some function and I is the T × T identity. For
= P
≥
θ Q(y≤T |θ)q(θ)
2To
that Pbayes (y≤T )
observe
simply
this,
see
Q(y≤T |θmap (y≤T ))q(θmap (y≤T )) and take the − log of both sides.

but instead deﬁne Θ = {u(·)| u(x) = PT
technical reasons, we do not deﬁne the class of competitor functions Θ to be the RKHS H,
t=1 αtK (x, xt ), α ∈ RT } — the set of kernel
expansions over x≤T . The model class is then F = {P (·|x≤T , u(·)) | u ∈ Θ}. The rep-
resenter theorem implies that competing against Θ is equivalent to competing against the
RKHS.
It is easy to see that for this case, the NML density does not exist (recall Example 4.2) — the
comparator class Θ contains very complex functions. However, the case is quite different
for the penalized regret. Now let us consider using a GP prior. We choose q to be the
corresponding density over Θ, which means that q(u) is proportional to exp(−kuk2
K /2),
where kuk2
K = αT K α with K i,j = K (xi , xj ) (recall Eq. 1). Now note that the penalty
− log q(u) is just the RKHS norm kuk2
K /2, up to an additive constant.
Using Theorem 4.3 and the equality in Theorem 3.2, we have the following corollary,
which shows that the Bayesian strategy is precisely the NMAP distribution (for Gaussian
regression).

Corollary 4.4: For any x≤T , in the Gaussian regression setting described above — where
F and Θ are deﬁned with respect to x≤T and where q is the GP prior over Θ — we
have that Pbayes is a minimax strategy for the penalized regret, i.e. for all y≤T , the regret
Rq (y≤T , Pbayes , Θ) does not exceed Rq (Θ). Furthermore, Pbayes and Pmap are densities of
the same distribution.
Importantly, note that, while the competitor class F is constructed with full knowledge of
x≤T in advance, the Bayesian strategy, Pbayes , can be implemented in an online manner in
that it only needs to know x<t for prediction at time t.
Acknowledgments

We thank Manfred Opper and Manfred Warmuth for helpful discussions.
References
K. S. Azoury and M. Warmuth. Relative loss bounds for on-line density estimation with the expo-
nential family of distributions. Machine Learning, 43(3), 2001.
A. Barron, J. Rissanen, and B. Yu. The minimum description length principle in coding and modeling.
IEEE Trans. Information Theory, 44, 1998.
Nicolo Cesa-Bianchi and Gabor Lugosi. Worst-case bounds for the logarithmic loss of predictors.
Machine Learning, 43, 2001.
D. P. Foster. Prediction in the worst case. Annals of Statistics, 19, 1991.
D. P. Foster and R. A. Stine. The competitive complexity ratio. Proceedings of 2001 Conf on Info
Sci and Sys, WP8, 2001.
P.D. Grunwald. A tutorial introduction to the minimum description length principle. Advances in
MDL: Theory and Applications, 2005.
T. Hastie, R. Tibshirani, , and J. Friedman. The Elements of Statistical Learning. Springer, 2001.
S. M. Kakade and A. Y. Ng. Online bounds for bayesian algorithms. Proceedings of Neural Infor-
mation Processing Systems, 2004.
M. Opper and D. Haussler. Worst case prediction over sequences under log loss. The Mathematics
of Information Coding, Extraction and Distribution, 1998.
Y. Shtarkov. Universal sequential coding of single messages. Problems of Information Transmission,
23, 1987.
E. Takimoto and M. Warmuth. The minimax strategy for Gaussian density estimation. Proc. 13th
Annu. Conference on Comput. Learning Theory, 2000.
Vladimir N. Vapnik. Statistical Learning Theory. Wiley, 1st edition, 1998.
V. Vovk. Competitive on-line statistics. International Statistical Review, 69, 2001.

