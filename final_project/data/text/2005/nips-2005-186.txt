Oblivious Equilibrium: A Mean Field
Approximation for Large-Scale Dynamic Games

Gabriel Y. Weintraub, Lanier Benkard, and Benjamin Van Roy
Stanford University
{gweintra,lanierb,bvr}@stanford.edu

Abstract

We propose a mean-ﬁeld approximation that dramatically reduces the
computational complexity of solving stochastic dynamic games. We pro-
vide conditions that guarantee our method approximates an equilibrium
as the number of agents grow. We then derive a performance bound to
assess how well the approximation performs for any given number of
agents. We apply our method to an important class of problems in ap-
plied microeconomics. We show with numerical experiments that we are
able to greatly expand the set of economic problems that can be analyzed
computationally.

1 Introduction

In this paper we consider a class of inﬁnite horizon non-zero sum stochastic dynamic
games. At each period of time, each agent has a given state and can make a decision.
These decisions together with random shocks determine the evolution of the agents’ states.
Additionally, agents receive proﬁts depending on the current states and decisions. There
is a literature on such models which focusses on computation of Markov perfect equilibria
(MPE) using dynamic programming algorithms. A major shortcoming of, however, is the
computational complexity associated with solving for the MPE. When there are more than
a few agents participating in the game and/or more than a few states per agent, the curse of
dimensionality renders dynamic programming algorithms intractable.
In this paper we consider a class of stochastic dynamic games where the state of an agent
captures its competitive advantage. Our main motivation is to consider an important class of
models in applied economics, namely, dynamic industry models of imperfect competition.
However, we believe our methods can be useful in other contexts as well. To clarify the
type of models we consider, let us describe a speciﬁc example of a dynamic industry model.
Consider an industry where a group of ﬁrms can invest to improve the quality of their
products over time. The state of a given ﬁrm represents its quality level. The evolution
of quality is determined by investment and random shocks. Finally, at every period, given
their qualities, ﬁrms compete in the product market and receive proﬁts. Many real world
industries where, for example, ﬁrms invest in R&D or advertising are well described by
this model.
In this context, we propose a mean-ﬁeld approximation approach that dramatically sim-
pliﬁes the computational complexity of stochastic dynamic games. We propose a simple

algorithm for computing an “oblivious” equilibrium in which each agent is assumed to
make decisions based only on its own state and knowledge of the long run equilibrium
distribution of states, but where agents ignore current information about rivals’ states. We
prove that, if the distribution of agents obeys a certain “light-tail” condition, when the num-
ber of agents becomes large the oblivious equilibrium approximates a MPE. We then derive
an error bound that is simple to compute to assess how well the approximation performs
for any given number of agents.
We apply our method to analyze dynamic industry models of imperfect competition. We
conduct numerical experiments that show that our method works well when there are sev-
eral hundred ﬁrms, and sometimes even tens of ﬁrms. Our method, which uses simple code
that runs in a couple of minutes on a laptop computer, greatly expands the set of economic
problems that can be analyzed computationally.

2 A Stochastic Dynamic Game

In this section, we formulate a non-zero sum stochastic dynamic game. The system evolves
over discrete time periods and an inﬁnite horizon. We index time periods with nonnegative
integers t ∈ N (N = {0, 1, 2, . . .}). All random variables are deﬁned on a probability space
(Ω, F , P ) equipped with a ﬁltration {Ft : t ≥ 0}. We adopt a convention of indexing by t
variables that are Ft -measurable.
There are n agents indexed by S = {1, ..., n}. The state of each agent captures its ability
to compete in the environment. At time t, the state of agent i ∈ S is denoted by xit ∈ N.
s ∈ N∞ (cid:12)(cid:12)(cid:12) P∞
n
o
We deﬁne the system state st to be a vector over individual states that speciﬁes, for each
state x ∈ N, the number of agents at state x in period t. We deﬁne the state space S =
. For each i ∈ S , we deﬁne s−i,t ∈ S to be the state of the
x=0 s(x) = n
competitors of agent i; that is, s−i,t (x) = st (x) − 1 if xit = x, and s−i,t (x) = st (x),
otherwise.
In each period, each agent earns proﬁts. An agent’s single period expected proﬁt
πm (xit , s−i,t ) depends on its state xit , its competitors’ state s−i,t and a parameter m ∈
<+ . For example, in the context of an industry model, m could represent the total number
of consumers, that is, the size of the pie to be divided among all agents. We assume that for
all x ∈ N, s ∈ S , m ∈ <+ , πm (x, s) > 0 and is increasing in x. Hence, agents in larger
states earn more proﬁts.
In each period, each agent makes a decision. We interpret this decision as an investment
to improve the state at the next period. If an agent invests µit ∈ <+ , then the agent’s state
at time t + 1 is given by, xi,t+1 = xit + w(µit , ζi,t+1 ), where the function w captures
the impact of investment on the state and ζi,t+1 reﬂects uncertainty in the outcome of
investment. For example, in the context of an industry model, uncertainty may arise due to
the risk associated with a research endeavor or a marketing campaign. We assume that for
all ζ , w(µ, ζ ) is nondecreasing in µ. Hence, if the amount invested is larger it is more likely
the agent will transit next period to a better state. The random variables {ζit |t ≥ 0, i ≥ 1}
are i.i.d.. We denote the unit cost of investment by d.
Each agent aims to maximize expected net present value. The interest rate is assumed to
be positive and constant over time, resulting in a constant discount factor of β ∈ (0, 1) per
time period. The equilibrium concept we will use builds on the notion of a Markov perfect
equilibrium (MPE), in the sense of [3]. We further assume that equilibrium is symmetric,
such that all agents use a common stationary strategy. In particular, there is a function µ
such that at each time t, each agent i ∈ S makes a decision µit = µ(xit , s−i,t ). Let M
denote the set of strategies such that an element µ ∈ M is a function µ : N × S → <+ .

We deﬁne the value function V (x, s|µ0 , µ) to be the expected net present value for an agent
" ∞X
#
at state x when its competitors’ state is s, given that its competitors each follows a common
(cid:12)(cid:12)(cid:12)xit = x, s−i,t = s
strategy µ ∈ M, and the agent itself follows strategy µ0 ∈ M. In particular,
V (x, s|µ0 , µ) = Eµ0 ,µ
β k−t (π(xik , s−i,k ) − dιik )
k=t
where i is taken to be the index of an agent at state x at time t, and the subscripts of
the expectation indicate the strategy followed by agent i and the strategy followed by its
competitors. In an abuse of notation, we will use the shorthand, V (x, s|µ) ≡ V (x, s|µ, µ),
to refer to the expected discounted value of proﬁts when agent i follows the same strategy
µ as its competitors.
An equilibrium to our model comprises a strategy µ ∈ M that satisfy the following condi-
tion:
V (x, s|µ0 , µ) = V (x, s|µ)
∀x ∈ N, ∀s ∈ S .
(2.1)

,

sup
µ0∈M

Under some technical conditions, one can establish existence of an equilibrium in pure
strategies [4]. With respect to uniqueness, in general we presume that our model may
have multiple equilibria. Dynamic programming algorithms can be used to optimize agent
strategies, and equilibria to our model can be computed via their iterative application. How-
ever, these algorithms require compute time and memory that grow proportionately with the
number of relevant system states, which is often intractable in contexts of practical interest.
This difﬁculty motivates our alternative approach.

3 Oblivious Equilibrium

We will propose a method for approximating MPE based on the idea that when there are
a large number of agents, simultaneous changes in individual agent states can average out
because of a law of large numbers such that the normalized system state remains roughly
constant over time. In this setting, each agent can potentially make near-optimal decisions
based only on its own state and the long run average system state. With this motivation,
we consider restricting agent strategies so that each agent’s decisions depend only on the
agent’s state. We call such restricted strategies oblivious since they involve decisions made
without full knowledge of the circumstances — in particular, the state of the system. Let
˜M ⊂ M denote the set of oblivious strategies. Since each strategy µ ∈ ˜M generates
decisions µ(x, s) that do not depend on s, with some abuse of notation, we will often drop
the second argument and write µ(x).
" ∞X
#
Let ˜sµ be the long-run expected system state when all agents use an oblivious strategy
(cid:12)(cid:12)(cid:12)xit = x
µ ∈ ˜M. For an oblivious strategy µ ∈ ˜M we deﬁne an oblivious value function
β k−t (π(xik , ˜sµ ) − dιik )
˜V (x|µ0 , µ) = Eµ0
k=t
This value function should be interpreted as the expected net present value of an agent that
is at state x and follows oblivious strategy µ0 , under the assumption that its competitors’
state will be ˜sµ for all time. Again, we abuse notation by using ˜V (x|µ) ≡ ˜V (x|µ, µ)
to refer to the oblivious value function when agent i follows the same strategy µ as its
competitors.
We now deﬁne a new solution concept: an oblivious equilibrium consists of a strategy
µ ∈ ˜M that satisfy the following condition:
˜V (x|µ0 , µ) = ˜V (x|µ),
sup
(3.1)
µ0∈ ˜M

∀x ∈ N.

.

In an oblivious equilibrium ﬁrms optimize an oblivious value function assuming that its
competitors’ state will be ˜sµ for all time. The optimal strategy obtained must be µ. It
is straightforward to show that an oblivious equilibrium exists under mild technical condi-
tions. With respect to uniqueness, we have been unable to ﬁnd multiple oblivious equilibria
in any of the applied problems we have considered, but similarly with the case of MPE, we
have no reason to believe that in general there is a unique oblivious equilibrium.

4 Asymptotic Results

In this section, we establish asymptotic results that provide conditions under which obliv-
ious equilibria offer close approximations to MPE as the number of agents, n, grow. We
consider a sequence of systems indexed by the one period proﬁt parameter m and we as-
sume that the number of agents in system m is given by n(m) = am, for some a > 0.
Recall that m represents, for example, the total pie to be divided by the agents so it is
reasonable to increase n(m) and m at the same rate.
We index functions and random variables associated with system m with a superscript
(m). From this point onward we let ˜µ(m) denote an oblivious equilibrium for system m.
Let V (m) and ˜V (m) represent the value function and oblivious value function, respectively,
when the system is m. To further abbreviate notation we denote the expected system state
associated with ˜µ(m) by ˜s(m) ≡ ˜s ˜µ(m) . The random variable s(m)
denotes the system state
t
at time t when every agent uses strategy ˜µ(m) . We denote the invariant distribution of
{s(m)
: t ≥ 0} by q (m) . In order to simplify our analysis, we assume that the initial system
t
is a stationary process; s(m)
state s(m)
is sampled from q (m) . Hence, s(m)
is distributed
t
t
0
according to q (m) for all t ≥ 0. It will be helpful to decompose s(m)
according to s(m)
t =
t
t n(m) , where f (m)
f (m)
is the random vector that represents the fraction of agents in each
t
state. Similarly, let ˜f (m) ≡ E [f (m)
+ | P
] denote the expected fraction of agents in each state.
With some abuse of notation, we deﬁne πm (xit , f−i,t , n) ≡ πm (xit , n · f−i,t ). We assume
t
that for all x ∈ N, f ∈ S1 , πm (x, f , n(m) ) = Θ(1), where S1 = {f ∈ <∞
x∈N f (x) =
1}. If m and n(m) grow at the same rate, one period proﬁts remain positive and bounded.
Our aim is to establish that, under certain conditions, oblivious equilibria well-approximate
MPE as m grows. We deﬁne the following concept to formalize the sense in which this
approximation becomes exact.
Deﬁnition 4.1. A sequence ˜µ(m) ∈ M possesses the asymptotic Markov equilibrium
(cid:21)
(cid:20)
(AME) property if for all x ∈ N,
| ˜µ(m) )
sup
µ0∈M

|µ0 , ˜µ(m) ) − V (m) (x, s(m)
t

= 0 .

lim
m→∞ E ˜µ(m)

V (m) (x, s(m)
t

The deﬁnition of AME assesses approximation error at each agent state x in terms of the
amount by which an agent at state x can increase its expected net present value by de-
viating from the oblivious equilibrium strategy ˜µ(m) , and instead following an optimal
(non-oblivious) best response that keeps track of the true system state. The system states
are averaged according to the invariant distribution.
It may seem that the AME property is always obtained because n(m) is growing to inﬁnity.
However, recall that each agent state reﬂects its competitive advantage and if there are
agents that are too “dominant” this is not necessarily the case. To make this idea more
concrete, let us go back to our industry example where ﬁrms invest in quality. Even when
there are a large number of ﬁrms, if the market tends to be concentrated — for example,
if the market is usually dominated by a single ﬁrm with a an extremely high quality —

g(x) =

the AME property is unlikely to hold. To ensure the AME property, we need to impose a
“light-tail” condition that rules out this kind of domination.
Note that d ln πm (y ,f ,n)
is the semi-elasticity of one period proﬁts with respect to the fraction
(cid:12)(cid:12)(cid:12)(cid:12) .
(cid:12)(cid:12)(cid:12)(cid:12) d ln πm (y , f , n)
df (x)
of agents in state x. We deﬁne the maximal absolute semi-elasticity function:
max
m∈<+ ,y∈N,f ∈S1 ,n∈N
df (x)
For each x, g(x) is the maximum rate of relative change of any agent’s single-period proﬁt
that could result from a small change in the fraction of agents at state x. Since larger
competitors tend to have greater inﬂuence on agent proﬁts, g(x) typically increases with x,
and can be unbounded.
Finally, we introduce our light-tail condition. For each m, let ˜x(m) ∼ ˜f (m) , that is, ˜x(m)
is a random variable with probability mass function ˜f (m) . ˜x(m) can be interpreted as the
state of an agent that is randomly sampled from among all agents while the system state is
distributed according to its invariant distribution.
i ≤ ,
h
Assumption 4.1. For all states x, g(x) < ∞. For all  > 0, there exists a state z such that
g( ˜x(m) )1{ ˜x(m)>z}

E

for all m.

Put simply, the light tail condition requires that states where a small change in the fraction
of agents has a large impact on the proﬁts of other agents, must have a small probability
under the invariant distribution. In the previous example of an industry where ﬁrms invest
in quality this typically means that very large ﬁrms (and hence high concentration) rarely
occur under the invariant distribution.
Theorem 4.1. Under Assumption 4.1 and some other regularity conditions1 , the sequence
˜µ(m) of oblivious equilibria possesses the AME property.

5 Error Bounds

While the asymptotic results from Section 4 provide conditions under which the approxi-
mation will work well as the number of agents grows, in practice one would also like to
know how the approximation performs for a particular system. For that purpose we derive
performance bounds on the approximation error that are simple to compute via simula-
tion and can be used to asses the accuracy of the approximation for a particular problem
instance.
E (cid:2)supµ0∈M V (x, st |µ0 , ˜µ) − V (x, st | ˜µ)(cid:3) . The expectation is over the invariant distribu-
We consider a system m and to simplify notation we suppress the index m. Consider an
oblivious strategy ˜µ. We will quantify approximation error at each agent state x ∈ N by
tion of st . The next theorem provides a bound on the approximation error. Recall that ˜s
is the long run expected state in oblivious equilibrium (E [st ]). Let ax (y) be the expected
discounted sum of an indicator of visits to state y for an agent starting at state x that uses
strategy ˜µ .
E [∆π(st )] + X
Theorem 5.1. For any oblivious equilibrium ˜µ and state x ∈ N,
E [∆V ] ≤ 1
ax (y) (π(y , ˜s) − E [π(y , st )]) ,
1 − β
y∈N
1 In particular, we require that the single period proﬁt function is “smooth” as a function of its
arguments. See [5] for details.

(5.1)

supµ0∈M V (x, st |µ0 , ˜µ) − V (x, st | ˜µ)
=
where ∆V
maxy∈N (π(y , s) − π(y , ˜s)).
The error bound can be easily estimated via simulation algorithms. In particular, note that
the bound is not a function of the true MPE or even of the optimal non-oblivious best
response strategy.

and ∆π(s)

=

6 Application: Industry Dynamics

Many problems in applied economics are dynamic in nature. For example, models involv-
ing the entry and exit of ﬁrms, collusion among ﬁrms, mergers, advertising, investment in
R&D or capacity, network effects, durable goods, consumer learning, learning by doing,
and transaction or adjustment costs are inherently dynamic. [1] (hereafter EP) introduced
an approach to modeling industry dynamics. See [6] for an overview. Computational com-
plexity has been a limiting factor in the use of this modeling approach. In this section we
use our method to expand the set of dynamic industries that can be analyzed computation-
ally.
Even though our results apply to more general models where for example ﬁrms make exit
and entry decisions, here we consider a particular case of an EP model which itself is a
particular case of the model introduced in Section 2. We consider a model of a single-good
industry with quality differentiation. The agents are ﬁrms that can invest to improve the
quality of their product over time. In particular xit is the quality level of ﬁrm i at time t.
µit represents represents the amount of money invested by ﬁrm i at time t to improve its
quality. We assume the one period proﬁt function is derived from a logit demand system
and where ﬁrms compete setting prices. In this case, m represents the market size. See [5]
for more details about the model.

6.1 Computational Experiments

In this section, we discuss computational results that demonstrate how our approximation
method signiﬁcantly expands the range of relevant EP-type models like the one previously
introduced that can be studied computationally.
First, we propose an algorithm to compute oblivious equilibrium [5]. Whether this al-
gorithm is guaranteed to terminate in a ﬁnite number of iterations remains an open issue.
However, in over 90% of the numerical experiments we present in this section, it converged
in less than ﬁve minutes (and often much less than this). In the rest, it converged in less
than ﬁfteen minutes.
Our ﬁrst set of results investigate the behavior of the approximation error bound under
several different model speciﬁcations. A wide range of parameters for our model could
reasonably represent different real world industries of interest. In practice the parameters
would either be estimated using data from a particular industry or chosen to reﬂect an
industry under study. We begin by investigating a particular set of representative parameter
values. See [5] for the speciﬁcations.
For each set of parameters, we use the approximation error bound to compute an upper
bound on the percentage error in the value function, E [supµ0 ∈M V (x,s|µ0 , ˜µ)−V (x,s| ˜µ)]
, where
E [V (x,s| ˜µ)]]
˜µ is the OE strategy and the expectations are taken with respect to s. We estimate the
expectations using simulation. We compute the previously mentioned percentage approxi-
mation error bound for different market sizes m and number of ﬁrms n(m) . As the market
size increases, the number of ﬁrms increases and the approximation error bound decreases.
In our computational experiments we found that the most important parameter affecting

the approximation error bounds was the degree of vertical product differentiation, which
indicates the importance consumers assign to product quality. In Figure 1 we present our
results. When the parameter that measures the level of vertical differentiation is low the
approximation error bound is less than 0.5% with just 5 ﬁrms, while when the parameter is
high it is 5% for 5 ﬁrms, less than 3% with 40 ﬁrms, and less than 1% with 400 ﬁrms.

Figure 1: Percentage approximation error bound for ﬁxed number of ﬁrms.

Most economic applications would involve from less than ten to several hundred ﬁrms.
These results show that the approximation error bound may sometimes be small (<2%) in
these cases, though this would depend on the model and parameter values for the industry
under study.
Having gained some insight into what features of the model lead to low values of the
approximation error bound, the question arises as to what value of the error bounds is
required to obtain a good approximation. To shed light on this issue we compare long-run
statistics for the same industry primitives under oblivious equilibrium and MPE strategies.
A major constraint on this exercise is that it requires the ability to actually compute the
MPE, so to keep computation manageable we use four ﬁrms here. We compare the average
values of several economic statistics of interest under the oblivious equilibrium and the
MPE invariant distributions. The quantities compared are: average investment, average
producer surplus, average consumer surplus, average share of the largest ﬁrm, and average
share of the largest two ﬁrms. We also computed the actual beneﬁt from deviating and
keeping track of the industry state (the actual difference E [supµ0 ∈M V (x,s|µ0 , ˜µ)−V (x,s| ˜µ)]
).
E [V (x,s| ˜µ)]]
Note that the the latter quantity should always be smaller than the approximation error
bound.
From the computational experiments we conclude the following (see [5] for a table with
the results):

1. When the bound is less than 1% the long-run quantities estimated under oblivious
equilibrium and MPE strategies are very close.
2. Performance of the approximation depends on the richness of the equilibrium in-
vestment process. Industries with a relatively low cost of investment tend to have
a symmetric average distribution over quality levels reﬂecting a rich investment
process. In this cases, when the bound is between 1-20%, the long-run quantities
estimated under oblivious equilibrium and MPE strategies are still quite close. In
industries with high investment cost the industry (system) state tends to be skewed,
reﬂecting low levels of investment. When the bound is above 1% and there is little
investment, the long-run quantities can be quite different on a percentage basis
(5% to 20%), but still remain fairly close in absolute terms.

3. The performance bound is not tight. For a wide range of parameters the perfor-
mance bound is as much as 10 to 20 times larger than the actual beneﬁt from
deviating.

The previous results suggest that MPE dynamics are well-approximated by oblivious equi-
librium strategies when the approximation error bound is small (less than 1-2% and in some
cases even up to 20 %). Our results demonstrate that the oblivious equilibrium approxima-
tion signiﬁcantly expands the range of applied problems that can be analyzed computation-
ally.

7 Conclusions and Future Research

The goal of this paper has been to increase the set of applied problems that can be addressed
using stochastic dynamic games. Due to the curse of dimensionality, the applicability of
these models has been severely limited. As an alternative, we proposed a method for ap-
proximating MPE behavior using an oblivious equilibrium, where agents make decisions
only based on their own state and the long run average system state. We began by show-
ing that the approximation works well asymptotically, where asymptotics were taken in
the number of agents. We also introduced a simple algorithm to compute an oblivious
equilibrium.
To facilitate using oblivious equilibrium in practice, we derived approximation error
bounds that indicate how good the approximation is in any particular problem under study.
These approximation error bounds are quite general and thus can be used in a wide class of
models. We use our methods to analyze dynamic industry models of imperfect competition
and showed that oblivious equilibrium often yields a good approximation of MPE behavior
for industries with a couple hundred ﬁrms, and sometimes even with just tens of ﬁrms.
We have considered very simple strategies that are functions only of an agent’s own state
and the long run average system state. While our results show that these simple strategies
work well in many cases, there remains a set of problems where exact computation is not
possible and yet our approximation will not work well either. For such cases, our hope
is that our methods will serve as a basis for developing better approximations that use
additional information, such as the states of the dominant agents. Solving for equilibria
of this type would be more difﬁcult than solving for oblivious equilibria, but is still likely
to be computationally feasible. Since showing that such an approach would provide a
good approximation is not a simple extension of our results, this will be a subject of future
research.

References
[1] R. Ericson and A. Pakes. Markov-perfect industry dynamics: A framework for empir-
ical work. Review of Economic Studies, 62(1):53 – 82, 1995.
[2] R. L. Goettler, C. A. Parlour, and U. Rajan. Equilibrium in a dynamic limit order
market. Forthcoming, Journal of Finance, 2004.
[3] E. Maskin and J. Tirole. A theory of dynamic oligopoly, I and II. Econometrica,
56(3):549 – 570, 1988.
[4] U. Doraszelski and M. Satterthwaite. Foundations of Markov-perfect industry dynam-
ics: Existence, puriﬁcation, and multiplicity. Working Paper, Hoover Institution, 2003.
[5] G. Y. Weintraub, C. L. Benkard, and B. Van Roy. Markov perfect industry dynamics
with many ﬁrms. Submitted ofr publication, 2005.
[6] A. Pakes. A framework for applied dynamic analysis in i.o. NBER Working Paper
8024, 2000.

