Invariant Common Spatial Patterns: Alleviating
Nonstationarities in Brain-Computer Interfacing

Benjamin Blankertz1,2

Motoaki Kawanabe2

Ryota Tomioka3

Friederike U. Hohlefeld4

Vadim Nikulin5

Klaus-Robert Müller 1,2

1TU Berlin, Dept. of Computer Science, Machine Learning Laboratory, Berlin, Germany
2Fraunhofer FIRST (IDA), Berlin, Germany
3Dept. Mathematical Informatics, IST, The University of Tokyo, Japan
4Berlin School of Mind and Brain, Berlin, Germany
5Dept. of Neurology, Campus Benjamin Franklin, Charité University Medicine Berlin, Germany
{blanker,krm}@cs.tu-berlin.de

Abstract

Brain-Computer Interfaces can suffer from a large variance of the subject condi-
tions within and across sessions. For example vigilance ﬂuc tuations in the indi-
vidual, variable task involvement, workload etc. alter the characteristics of EEG
signals and thus challenge a stable BCI operation. In the present work we aim to
de ﬁne features based on a variant of the common spatial patte rns (CSP) algorithm
that are constructed invariant with respect to such nonstationarities. We enforce
invariance properties by adding terms to the denominator of a Rayleigh coefﬁcient
representation of CSP such as disturbance covariance matrices from ﬂuctuations
in visual processing. In this manner physiological prior knowledge can be used
to shape the classiﬁcation engine for BCI. As a proof of conce pt we present a
BCI classiﬁer that is robust to changes in the level of pariet al a-activity. In other
words, the EEG decoding still works when there are lapses in vigilance.

1 Introduction

Brain-Computer Interfaces (BCIs) translate the intent of a subject measured from brain signals di-
rectly into control commands, e.g. for a computer application or a neuroprosthesis ([1, 2, 3, 4, 5, 6]).
The classical approach to brain-computer interfacing is operant conditioning ([2, 7]) where a ﬁxed
translation algorithm is used to generate a feedback signal from the electroencephalogram (EEG).
Users are not equipped with a mental strategy they should use, rather they are instructed to watch
a feedback signal and using the feedback to ﬁnd out ways to vol untarily control it. Successful BCI
operation is reinforced by a reward stimulus. In such BCI systems the user adaption is crucial and
typically requires extensive training. Recently machine learning techniques were applied to the BCI
ﬁeld and allowed to decode the subject’s brain signals, plac ing the learning task on the machine side,
i.e. a general translation algorithm is trained to infer the speciﬁc characteristics of the user’s brain
signals [8, 9, 10, 11, 12, 13, 14]. This is done by a statistical analysis of a calibration measurement
in which the subject performs well-de ﬁned mental acts like i magined movements. Here, in principle
no adaption of the user is required, but it is to be expected that users will adapt their behaviour
during feedback operation. The idea of the machine learning approach is that a ﬂexible adaption
of the system relieves a good amount of the learning load from the subject. Most BCI systems are
somewhere between those extremes.

1

Although the proof-of-concept of machine learning based BCI systems1 was given some years ago,
several major challenges are still to be faced. One of them is to make the system invariant to non
task-related ﬂuctuations of the measured signals during fe edback. These ﬂuctuations may be caused
by changes in the subject’s brain processes, e.g. change of task involvement, fatigue etc., or by
artifacts such as swallowing, blinking or yawning. The calibration measurement that is used for
training in machine learning techniques is recorded during 10-30 min, i.e. a relatively short period
of time and typically in a monotone atmosphere, so this data does not contain all possible kinds of
variations to be expected during on-line operation.
The present contribution focusses on invariant feature extraction for BCI. In particular we aim to
enhance the invariance properties of the common spatial patterns (CSP, [15]) algorithm. CSP is the
solution of a generalized eigenvalue problem and has as such a strong link to the maximization of a
Rayleigh coefﬁcient, similar to Fisher’s discriminant ana lysis. Prior work by Mika et al. [16] in the
context of kernel Fisher’s discriminant analysis contains the key idea that we will follow: noise and
distracting signal aspects with respect to which we want to make our feature extractor invariant is
added to the denominator of a Rayleigh coefﬁcient. In other w ords, our prior knowledge about the
noise type helps to re-design the optimization of CSP feature extraction. We demonstrate how our
invariant CSP (iCSP) technique can be used to make a BCI system invariant to changes in the power
of the parietal a-rhythm (see Section 2) re ﬂecting, e.g. changes in vigilanc e. Vigilance changes
are among the most pressing challenges when robustifying a BCI system for long-term real-world
applications.
In principle we could also use an adaptive BCI, however, adaptation typically has a limited time
scale which might not allow to follow ﬂuctuations quickly en ough. Furthermore online adaptive BCI
systems have so far only been operated with 4-9 channels. We would like to stress that adaptation and
invariant classiﬁcation are no mutually exclusive alterna tives but rather complementary approaches
when striving for the same goal: a BCI system that is invariant to undesired distortions and non-
stationarities.

2 Neurophysiology and Experimental Paradigms
Neurophysiological background. Macroscopic brain activity during resting wakefulness contains
distinct ‘idle’ rhythms located over various brain areas, e.g. the parietal a-rhythm (7-13 Hz) can
be measured over the visual cortex [17] and the m-rhythm can be measured over the pericentral
sensorimotor cortices in the scalp EEG, usually with a frequency of about 8 –14 Hz ([18]). The
strength of the parietal a-rhythm re ﬂects visual processing load as well as attention and fatigue
resp. vigilance.
The moment-to-moment amplitude ﬂuctuations of these local
rhythms re ﬂect variable functional
states of the underlying neuronal cortical networks and can be used for brain-computer interfacing.
Speciﬁcally, the pericentral m- and b rythms are diminished, or even almost completely blocked, by
movements of the somatotopically corresponding body part, independent of their active, passive or
re ﬂexive origin. Blocking effects are visible bilateral bu t with a clear predominance contralateral to
the moved limb. This attenuation of brain rhythms is termed event-related desynchronization (ERD)
and the dual effect of enhanced brain rhythms is called event-related synchronization (ERS) (see
[19]).
Since a focal ERD can be observed over the motor and/or sensory cortex even when a subject is only
imagining a movement or sensation in the speciﬁc limb, this f eature can be used for BCI control: The
discrimination of the imagination of movements of left hand vs. right hand vs. foot can be based on
the somatotopic arrangement of the attenuation of the m and/or b rhythms. However the challenge
is that due to the volume conduction EEG signal recorded at the scalp is a mixture of many cortical
activities that have different spatial localizations; for example, at the electrodes over the mortor
cortex, the signal not only contains the m-rhythm that we are interested in but also the projection of
parietal a-rhythm that has little to do with the motor-imagination. To this end, spatial ﬁltering is an
indispensable technique; that is to take a linear combination of signals recorded over EEG channels
and extract only the component that we are interested in.
In particular the CSP algorithm that
optimizes spatial ﬁlters with respect to discriminability is a good candidate for feature extraction.

Experimental Setup.
In this paper we evaluate the proposed algorithm on off-line data in which
the nonstationarity is induced by having two different background conditions for the same primary

1Note: In our exposition we focus on EEG-based BCI systems that does not rely on evoked potentials (for
an extensive overview of BCI systems including invasive and systems based on evoked potentials see [1]).

2

0

−0.05

−0.1

−0.15

−0.2

−0.25

−0.3

0.5

0.4

0.3

0.2

0.1

0

Figure 1: Topographies of r2 –values (multiplied by
the sign of the difference) quantifying the difference
in log band-power in the alpha band (8–12 Hz) be-
tween different recording sessions: Left: Difference
between imag_move and imag_lett. Due to lower
visual processing demands, alpha power in occipi-
tal areas is stronger in imag_lett. Right: Difference
between imag_move and sham_feedback. The latter
has decreased alpha power in centro-parietal areas.
Note the different sign in the colormaps.

task. The ultimate challenge will be on-line feedback with strong ﬂuctuations of task demands etc,
a project envisioned for the near future.
We investigate EEG recordings from 4 subjects (all from whom we have an ‘invariance measure-
ment’, see below). Brain activity was recorded from the scalp with multi-channel ampliﬁers using
55 EEG channels.
In the ‘calibration measurement’ all 4.5 –6 seconds one of 3 d ifferent visual stimuli indicated for 3
seconds which mental task the subject should accomplish during that period. The investigated men-
tal tasks were imagined movements of the left hand, the right hand, and the right foot. There were
two types of visual stimulation: (1: imag_lett) targets were indicated by letters (L, R, F) appearing at
a central ﬁxation cross and (2:
imag_move) a randomly moving small rhomboid with either its left,
right or bottom corner ﬁlled to indicate left or right hand or
foot movement, respectively. Since the
movement of the object was independent from the indicated targets, target-uncorrelated eye move-
ments are induced. Due to the different demands in visual processing, the background brain activity
can be expected to differ substancially in those two types of recordings. The topography of the
r2 –values (bi-serial correlation coefﬁcient of feature valu
es with labels) of the log band-power dif-
ference between imag_move and imag_lett is shown in the left plot of Fig. 2. It shows a pronounced
differene in parietal areas.
A sham_feedback paradigm was designed in order to charaterize invariance properties needed for
stable real-world BCI applications. In this measurement the subjects received a fake feedback se-
quence which was preprogrammed. The aim of this recording was to collect data during a large
variety of mental states and actions that are not correlated with the BCI control states (motor im-
agery of hands and feet). Subjects were told that they could control the feedback in some way that
they should ﬁnd out, e.g. with eye movements or muscle activi ty. They were instructed not to per-
form movements of hands, arms, legs and feet. The type of feedback was a standard 1D cursor
control. In each trial the cursor starts in the middle and should be moved to either the left or right
side as indicated by a target cue. When the cursor touched the left or right border, a response (correct
or false) was shown. Furthermore the number of hits and misses was shown. The preprogrammed
‘feedback’ signal was constructed such that it was random in the beginning and then alternating peri-
ods of increasingly more hits and periods with chance level performance. This was done to motivate
the subjects to try a variety of different actions and to induce different states of mood (satisfaction
during ‘successful’ periods and anger resp. disfavor during ‘failure’). The right plot of Fig. 2 visual-
izes the difference in log band-power between imag_move and sham_feedback. A decreased alpha
power in centro-parietal areas during sham_feedback can be observed. Note that this recording in-
cludes much more variations of background mental activity than the difference between imag_move
and imag_lett.

3 Methods

Common Spatial Patterns (CSP) Analysis. The CSP technique ([15]) allows to determine spatial
ﬁlters that maximize the variance of signals of one conditio n and at the same time minimize the
variance of signals of another condition. Since variance of band-pass ﬁltered signals is equal to band-
power, CSP ﬁlters are well suited to discriminate mental sta tes that are characterized by ERD/ERS
effects ([20]). As such it has been well used in BCI systems ([8, 14]) where CSP ﬁlters are calculated
individually for each subject on the data of a calibration measurement.
Technically the Common Spatial Pattern (CSP) [21] algorithm gives spatial ﬁlters based on a dis-
criminative criterion. Let X1 and X2 be the (time × channel) data matrices of the band-pass ﬁltered

3

EEG signals (concatenated trials) under the two conditions (e.g., right-hand or left-hand imagination,
respectively2) and S1 and S2 be the corresponding estimates of the covariance matrices Si = X >
i Xi .
We de ﬁne the two matrices Sd and Sc as follows:
Sd = S(1) − S(2)
Sc = S(1) + S(2)
v ∈ RC (C is the number of channels) can be obtained by extremizing the

: discriminative activity matrix,
: common activity matrix.

The CSP spatial ﬁlter
Rayleigh coefﬁcient:

.

v> Sc v,

s.t.

(1)

{max, min}v∈RC

v>Sd v
v> Sc v
This can be done by solving a generalized eigenvalue problem.
Sd v = lScv.
(2)
The eigenvalue l is bounded between −1 and 1; a large positive eigenvalue corresponds to a pro-
jection of the signal given by v that has large power in the ﬁrst condition but small in the sec ond
condition; the converse is true for a large negative eigenvalue. The largest and the smallest eigen-
values correspond to the maximum and the minimum of the Rayleigh coefﬁcient problem (Eq. (1)).
Note that v> Sd v = v>S1 v − v>S2 v is the average power difference in two conditions that we want
to maximize. On the other hand, the projection of the activity that is common to two classes v> Sc v
should be minimized because it doesn’t contribute to the discriminability. Using the same idea from
[16] we can rewrite the Rayleigh problem (Eq. (1)) as follows:
v>S1 v − v>S2 v = l,

min
v∈RC
which can be interpreted as ﬁnding the minimum norm v with the condition that the average power
difference between two conditions to be l. The norm is de ﬁned by the common activity matrix Sc .
In the next section, we extend the notion of Sc to incorporate any disturbances that is common to
two classes that we can measure a priori.
In this paper we call ﬁlter the generalized eigenvectors v j ( j = 1, . . . ,C) of the generalized eigenvalue
problem (Eq. (2)) or a similar problem discussed in the next section. Moreover we denote by V the
matrix we obtain by putting the C generalized eigenvectors into columns, namely V = {v j }C
j=1 ∈
RC×C and call patterns the row vectors of the inverse A = V −1 . Note that a ﬁlter v j ∈ RC has its
corresponding pattern a j ∈ RC ; a ﬁlter v j extracts only the activity spanned by a j and cancels out all
other activities spanned by ai (i 6= j); therefore a pattern a j tells what the ﬁlter v j is extracting out
(see Fig. 2).
For classiﬁcation the features of single-trials are calcul ated as the log-variance in CSP projected
signals. Here only a few (2 to 6) patterns are used. The selection of patterns is typically based on
eigenvalues. But when a large amount of calibration data is not available it is advisable to use a
more re ﬁned technique to select the patterns or to manually c hoose them by visual inspection. The
variance features are approximately chi-square distributed. Taking the logarithm makes them similar
to gaussian distributions, so a linear classiﬁer (e.g., lin ear discriminant analysis) is ﬁne.
For the evaluation in this paper we used the CSPs corresponding the the two largest and the two
smallest eigenvalues and used linear disciminant analysis for classiﬁcation. The CSP algorithm,
several extentions as well as practical issues are reviewed in detail in [15].

Invariant CSP. The CSP spatial ﬁlters extracted as above are optimized for t he calibration mea-
surement. However, in online operation of the BCI system different non task-related modulations
of brain signals may occur which are not suppressed by the CSP ﬁlters. The reason may be that
these modulations have not been recorded in the calibration measurement or that they have been so
infrequent that they are not consistently re ﬂected in the st atistics (e.g. when they are not equally
distributed over the two conditions).
The proposed iCSP method minimizes the in ﬂuence of modulati ons that can be characterized in
advance by a covariance matrix. In this manner we can code neurophysiological prior knowledge

2We use the term covariance for zero-delay second order statistics between channels and not for the statis-
tical variability. Since we assume the signal to be band-pass ﬁltered, the second order statistics reﬂects band
power.

4

or further information such as the tangent covariance matrix ([22]) into such a covariante matrix X.
In the following motivation we assume that X is the covariance matrix of a signal matrix Y . Using
such that var(X1 v(1)
the notions from above, the objective is then to calculate spatial ﬁlters v(1)
j ) is
j
j ) are minimized. Dually spatial ﬁlters v(2)
maximized and var(X2 v(1)
j ) and var(Y v(1)
are determined
j
that maximize var(X2 v(2)
j ) and var(Y v(2)
j ) and minimize var(X1v(2)
j ).
Pratically this can be accomplished by solving the following two generalized eigenvalue problems:
V (1)>S1V (1) = D(1)
((1−x)(S1 + S2 ) + xX)V (1) = I
and V (1)>
V (2)>S2V (2) = D(2)
((1−x)(S1 + S2 ) + xX)V (2) = I
and V (2)>
(4)
where x ∈ [0, 1] is a hyperparameter to trade-off the discrimination of the training classes (X1 ,
X2 ) against invariance (as characterized by X). Section 4 discusses the selection of parame-
ter x. Filters v(1)
provide not only high var(X1 v(1)
j with high eigenvalues d (1)
j ) but also small
j
>
((1 − x)S2 + xX) v(1)
j = 1 − (1 − x)d (1)
v(1)
, i.e. small var(X2 v(1)
j ) and small var(Y v(1)
j ). The dual
j
j
is true for the selection of ﬁlters from v(2)
.
j
Note that for x = 0.5 there is a strong connection to the one-vs-rest strategy for 3-class CSP ([23]).
Features for classiﬁcation are calculated as log-variance using the two ﬁlters from each of v(1)
and
j
v(2)
corresponding to the largest eigenvalues. Note that the idea of iCSP is in the spirit of the
j
invariance constraints in (kernel) Fisher’s Discriminant proposed in [16].

(3)

A Theoretical Investigation of iCSP by Inﬂuence Analysis.
As mentioned, iCSP is aiming at
robust spatial ﬁltering against disturbances whose covari ance X can be anticipated from prior knowl-
edge. In ﬂuence analysis is a statistical tool with which we c an assess robustness of inference proce-
dures [24]. Basically, it evaluates the effect in inference procedures, if we add a small perturbation
of O(e), where e (cid:28) 1. For example, in ﬂuence functions for the component analys es such as PCA
and CCA have been discussed so far [25, 26]. We applied the machinery to iCSP, in order to check
whether iCSP really reduces in ﬂuence caused by the disturba nce at least in local sense. For this
purpose, we have the following lemma (its proof is included in the Appendix).
Lemma 1 (In ﬂuence of generalized eigenvalue problems) Let lk and wk be k-th eigenvalue and
eigenvector of the generalized eigvenvalue problem
Aw = lBw,
(5)
respectively. Suppose that the matrices A and B are perturbed with small matrices eD and eP where
e(cid:28) 1. Then the eigenvalues ewk and eigenvectors elk of the purterbed problem
(A + eD) ew = el(B + eP) ew
can be expanded as lk + eck + o(e) and wk + ey
k + o(e), where
1
k = −Mk (D − lkP)wk −
k (D − lkP)wk ,
y
ck = w>
(w>
(7)
k Pwk )wk ,
2
Mk := B−1/2 (B−1/2AB−1/2 − lk I )+B−1/2 and the sufﬁx ’+’ denotes Moore-Penrose matrix inverse.

(6)

The generalized eigenvalue problem eqns (3) and (4) can be rephrased as
S1 v = d {(1 − x)(S1 + S2 ) + xX}v,
S2 u = c{(1 − x)(S1 + S2 ) + xX}u.
For simplicity, we consider here the simplest perturbation of the covariances as S1 → S1 + eX and
S2 → S1 + eX. In this case, the perturbation matrices in the lemma can be expressed as D1 = X,
D2 = X, P = 2(1 − x)X. Therefore, we get the expansions of the eigenvalues and eigenvectors as
dk + ec1k , ck + ec2k , vk + ey
1k and uk + ey
2k , where
Xvk ,
c2k = {1 − 2(1 − x)ck}u>
c1k = {1 − 2(1 − x)dk}v>
k
k
Xvk )vk ,
1k = −{1 − 2(1 − x)dk}M1kXvk − (1 − x)(v>
y
k
2k = −{1 − 2(1 − x)ck}M2kXuk − (1 − x)(u>
Xuk )uk ,
y
k

(8)
(9)
(10)

Xuk ,

5

original CSP
original CSP − error:   10.7% / 11.4% / 12.9% / 37.9%
10.7%
11.4%
12.9%
37.9%

invariant CSP
invariant CSP − error:   9.3% / 10.0% / 9.3% / 11.4%
9.3%
10.0%
9.3%
11.4%

errors

a=0
alpha=0.0

a=0.5
alpha=0.5

a=1
alpha=1.0

a=2
alpha=2.0

a=0
alpha=0.0

a=0.5
alpha=0.5

a=1
alpha=1.0

a=2
alpha=2.0

filter

pattern

filter

pattern

Figure 2: Comparison of CSP and iCSP on test data with arti ﬁci ally increased occipital alpha. The upper plots
show the classi ﬁer output on the test data with different deg rees of alpha added (factors a= 0, 0.5, 1, 2). The
lower panel shows the ﬁlter/pattern coefﬁcients topograph
ically mapped on the scalp from original CSP (left)
and iCSP (right). Here the invariance property was deﬁned wi
th respect to the increase in the alpha activity in
the visual cortex (occipital location) using an eyes open/eyes closed recording. See Section 3 for the deﬁnition
of ﬁlter and pattern.

M1k := S−1/2 (S−1/2S1S−1/2 − dk I )+S−1/2 , M2k := S−1/2 (S−1/2S2S−1/2 − dk I )+S−1/2 , and S :=
(1 − x)(S1 + S2 ) + xX. The implication of the result is the following. If x = 1 − 1
(resp. x =
2dk
) is satisﬁed, the O(e) term c1k (resp. c2k ) of the k-th eigenvalue vanishes and also the k-th
1 − 1
2ck
eigenvector does coincide with the one for the original problem up to e order, because the ﬁrst term
1k (resp. y
of y
2k ) becomes zero (we note that dk and ck also depend on x).
4 Evaluation
Test Case with Constructed Test Data. To validate the proposed iCSP, we ﬁrst applied it to
speciﬁcally constructed test data. iCSP was trained ( x = 0.5) on motor imagery data with the invari-
ance characterized by data from a measurement during ‘eyes open’ (approx. 40 s) and ‘eyes closed’
(approx. 20 s). The motor imagery test data was used in its original form and variants that were
modiﬁed in a controlled manner: From another data set during ‘eyes closed’ we extracted activity
related to increased occipital alpha activity (backprojection of 5 ICA components) and added this
with 3 different factors (a = 0.5, 1, 2) to the test data.
The upper plots of Fig. 2 display the classiﬁer output on the c onstructed test data. While the per-
formance of the original CSP is more and more deteriorated with increased alpha mixed in, the
proposed iCSP method maintains a stable performance independent of the amount of increased al-
pha activity. The spatial ﬁlters that were extracted by CSP a nalysis vs. the proposed iCSP often
look quite similar. However, tiny but apparently important differences exist. In the lower panel of
Fig. 2 the ﬁlter ( v j ) pattern (a j ) pairs from original CSP (left) and iCSP (right) are shown. The ﬁlters
from two approaches resemble each other strongly. However, the corresponding patterns reveal an
important difference. While the pattern of the original CSP has positive weights at the right occipital
side which might be susceptible to a modulations, the corresponding iCSP has not. A more detailed
inspection shows that both ﬁlters have a focus over the right
(sensori-) motor cortex, but only the
invariant ﬁlter has a spot of opposite sign right posterior t o it. This spot will ﬁlter out contributions
coming from occipital/parietal sites.

Model selection for iCSP. For each subject, a cross-validation was performed for different values
of x on the training data (session imag_move) and the x resulting in minimum error was chosen. For
the same values of x the iCSP ﬁlters + LDA classiﬁer trained on
imag_move were applied to calcu-

6

 Subject  zv

test
train

0

0.2

0.6

0.4
xi
 Subject  zq

0.8

test
train

 Subject  cv

test
train

0

0.2

0.6

0.4
xi
 Subject  zk

0.8

test
train

35

30

25

20

15

10

5

0

35

30

25

20

15

10

5

]
%
[
 
r
o
r
r
e

]
%
[
 
r
o
r
r
e

35

30

25

20

15

10

5

0

35

30

25

20

15

10

5

]
%
[
 
r
o
r
r
e

]
%
[
 
r
o
r
r
e

0.6

0.8

0

0

25

20

15

10

5

]
%
[
 
r
o
r
r
e

cv
zv
zk
zq

0

0

0

0.2

0.2

0.8

0.6

CSP
iCSP
0.4
0.4
xi
xi
Figure 3: Modelselection and evaluation. Left subplots: Selection of hyperparameter x of the iCSP method.
For each subject, a cross-validation was performed for different values of x on the training data (session
imag_move), see thin black line, and the x resulting in minimum error was chosen (circle). For the same
values of x the iCSP ﬁlters + LDA classi ﬁer trained on
imag_move were applied to calculate the test error
on data from imag_lett (thick colorful line). Right plot: Test error in all four recordings for classical CSP
and the proposed iCSP (with model parameter x chosen by cross-validation on the training set as described in
Section 4).

late the test error on data from imag_lett. Fig. 3 (left plots) shows the result of this procedure. The
shape of the cross-validation error on the training set and the test error is very similar. Accordingly,
the selection of values for parameter x is successful. For subject zq x = 0 was chosen, i.e. classical
CSP. The case for subject zk shows that the selection of x may be a delicate issue. For larges val-
ues of x cross-validation error and test error differ dramatically. A choice of x > 0.5 would result
in bad performance of iCSP, while this effect could have not been predicted so severely from the
cross-validation of the training set.

Evaluation of Performance with Real BCI Data. For evaluation we used the imag_move session
(see Section 2) as training set and the imag_lett session as test set. Fig 3 (right plot) compares
the classiﬁcation error obtained by classical CSP and by the proposed method iCSP with model
parameter x chosen by cross-validation on the training set as described above. Again an excellent
improvement is visible.

5 Concluding discussion
EEG data from Brain-Computer Interface experiments are highly challenging to evaluate due to
noise, nonstationarity and diverse artifacts. Thus, BCI provides an excellent testbed for testing the
quality and applicability of robust machine learning methods (cf. the BCI Competitions [27, 28]).
Obviously BCI users are subject to variations in attention and motivation. These types of non-
stationarities can considerably deteriorate the BCI classiﬁer performance. In present paper we pro-
posed a novel method to alleviate this problem.
A limitation of our method is that variations need to be characterized in advance (by estimating an
appropriate covariance matrix). At the same time this is also a strength of our method as neuro-
physiological prior knowledge about possible sources of non-stationarity is available and can thus
be taken into account in a controlled manner. Also the selection of hyperparameter x needs more
investigation, cf. the case of subject zk in Fig. 3. One strategy to pursue is to update the covariance
matrix X online with incoming test data. (Note that no label information is needed.) Online learning
(learning algorithms for adaptation within a BCI session) could also be used to further stabilize the
system against unforeseen changes. It remains to future research to explore this interesting direction.

Appendix: Proof of Lemma 1.
By substituting the expansions of elk and ewk to Eq.(6) and taking the O(e) term, we get
k + Dwk = lk By
Ay
k + lk Pwk + ck Bwk .
Eq.(7) can be obtained by multiplying w>
k to Eq.(11) and applying Eq.(5). Then, from Eq.(11),
(A − lk B)y
k = −(D − lk P)wk + ck Bwk = −(A − lk B)Mk (D − lk P)wk ,

(11)

7

j Bwk = djk and
holds, where we used the constraints w>
(A − lk B)Mk = (cid:229)
j = I − Bwk w>
Bw jw>
k .
j 6=k

(12)

B−1/2AB−1/2 − lk I = (cid:229) j 6=k lj B1/2w j w>
j B1/2
by
proven
be
can
Eq.(12)
and
j B1/2 . Since span{wk } is the kernel of the operator A − lk B,
(B−1/2AB−1/2 − lk I )+ = (cid:229) j 6=k 1/lj B1/2w j w>
k = −Mk (D − lk P)wk + cwk . By a multiplication with w>
k can be explained as y
y
k B, the constant c turns
k Byk = −w>
k BMk = 0> and w>
out to be c = −w>
k Pwk /2, where we used the fact w>
k Pwk /2 derived from the
k (B + eP)ewk = 1.
normalization ew>

ends in Graz

IEEE Trans.

Electroencephalogr. Clin.

References
[1] J. R. Wolpaw, N. Birbaumer, D. J. McFarland, G. Pfurtscheller, and T. M. Vaughan, “Brain-computer interfaces for com munication and
control”, Clin. Neurophysiol., 113: 767–791, 2002.
[2] N. Birbaumer, N. Ghanayim, T. Hinterberger, I. Iversen, B. Kotchoubey, A. K übler, J. Perelmouter, E. Taub, and H. Flo r, “A spelling
device for the paralysed”, Nature, 398: 297–298, 1999.
[3] G. Pfurtscheller, C. Neuper, C. Guger, W. Harkam, R. Ramoser, A. Schlögl, B. Obermaier, and M. Pregenzer, “Current Tr
Brain-computer Interface (BCI)”,
IEEE Trans. Rehab. Eng., 8(2): 216–219, 2000.
[4] J. Millán,Handbook of Brain Theory and Neural Networks, MIT Press, Cambridge, 2002.
[5] E. A. Curran and M. J. Stokes, “Learning to control brain a ctivity: A review of the production and control of EEG components for driving
brain-computer interface (BCI) systems ”, Brain Cogn., 51: 326–336, 2003.
[6] G. Dornhege, J. del R. Millán, T. Hinterberger, D. McFarland, and K.-R. M üller, eds., Toward Brain-Computer Interfacing, MIT Press,
Cambridge, MA, 2007.
[7] T. Elbert, B. Rockstroh, W. Lutzenberger, and N. Birbaumer, “Biofeedback of Slow Cortical Potentials. I”,
Neurophysiol., 48: 293–301, 1980.
[8] C. Guger, H. Ramoser, and G. Pfurtscheller, “Real-time E EG analysis with subject-speciﬁc spatial patterns for a Bra in Computer Interface
(BCI)”,
IEEE Trans. Neural Sys. Rehab. Eng., 8(4): 447–456, 2000.
[9] B. Blankertz, G. Curio, and K.-R. M üller, “Classifying S ingle Trial EEG: Towards Brain Computer Interfacing”, in: T . G. Diettrich,
S. Becker, and Z. Ghahramani, eds., Advances in Neural Inf. Proc. Systems (NIPS 01), vol. 14, 157–164, 2002.
[10] L. Parra, C. Alvino, A. C. Tang, B. A. Pearlmutter, N. Yeung, A. Osman, and P. Sajda, “Linear spatial integration for s ingle trial detection
in encephalography”, NeuroImage, 7(1): 223–230, 2002.
[11] E. Curran, P. Sykacek, S. Roberts, W. Penny, M. Stokes, I. Jonsrude, and A. Owen, “Cognitive tasks for driving a Brain Computer
Interfacing System: a pilot study”,
IEEE Trans. Rehab. Eng., 12(1): 48–54, 2004.
[12] J. Millán, F. Renkens, J. M. no, and W. Gerstner, “Non-invasive brain-actuated control of a mobile robot by human EEG ”,
Biomed. Eng., 51(6): 1026–1033, 2004.
[13] N. J. Hill, T. N. Lal, M. Schröder, T. Hinterberger, B. Wi lhelm, F. Nijboer, U. Mochty, G. Widman, C. E. Elger, B. Schöl kopf, A. K übler,
and N. Birbaumer, “Classifying EEG and ECoG Signals without Subject Training for Fast BCI Implementation: Comparison of Non-
IEEE Trans. Neural Sys. Rehab. Eng., 14(6): 183–186, 2006.
Paralysed and Completely Paralysed Subjects ”,
“The non-invasive Berlin Brain-Computer
[14] B. Blankertz, G. Dornhege, M. Krauledat, K.-R. M üller,
In-
and G. Curio,
terface:
539–550, 2007, URL
Fast Acquisition of Effective Performance in Untrained Subjects ”, NeuroImage, 37(2):
http://dx.doi.org/10.1016/j.neuroimage.2007.01.051.
-Trial Analysis ”,
[15] B. Blankertz, R. Tomioka, S. Lemm, M. Kawanabe, and K.-R. M üller, “Optimizing Spatial Filters for Robust EEG Single
IEEE Signal Proc. Magazine, 25(1): 41–56, 2008, URL http://dx.doi.org/10.1109/MSP.2008.4408441.
[16] S. Mika, G. R ätsch, J. Weston, B. Schölkopf, A. Smola, an d K.-R. M üller, “Invariant Feature Extraction and Classiﬁc
ation in Kernel
Spaces ”, in: S. Solla, T. Leen, and K.-R. M üller, eds., Advances in Neural Information Processing Systems, vol. 12, 526–532, MIT Press,
2000.
en”, Archiv für Psychiatrie und Nervenkrankheiten , 99(6): 555–574, 1933.
Über das Elektroenkephalogramm des Mensch
[17] H. Berger, “
[18] H. Jasper and H. Andrews, “Normal differentiation of oc cipital and precentral regions in man”, Arch. Neurol. Psychiat. (Chicago), 39:
96–115, 1938.
[19] G. Pfurtscheller and F. H. L. da Silva, “Event-related E EG/MEG synchronization and desynchronization: basic principles ”, Clin. Neuro-
physiol., 110(11): 1842–1857, 1999.
[20] Z. J. Koles, “The quantitative extraction and topograp hic mapping of the abnormal components in the clinical EEG ”, Electroencephalogr.
Clin. Neurophysiol., 79(6): 440–447, 1991.
[21] K. Fukunaga, Introduction to statistical pattern recognition, Academic Press, Boston, 2nd edn., 1990.
[22] B. Schölkopf, Support vector learning, Oldenbourg Verlag, Munich, 1997.
[23] G. Dornhege, B. Blankertz, G. Curio, and K.-R. M üller, “ Boosting bit rates in non-invasive EEG single-trial classiﬁcations by feature
combination and multi-class paradigms ”,
IEEE Trans. Biomed. Eng., 51(6): 993–1002, 2004.
[24] F. R. Hampel, E. M. Ronchetti, P. J. Rousseeuw, and W. A. Stahel, Robust Statistics: The Approach Based on Inﬂuence Function s, Wiley,
New York, 1986.
[25] F. Critchley, “Inﬂuence in principal components analy sis ”, Biometrika, 72(3): 627–636, 1985.
[26] M. Romanazzi, “Inﬂuence in Canonical Correlation Anal ysis ”, Psychometrika, 57(2): 237–259, 1992.
[27] B. Blankertz, K.-R. M üller, G. Curio, T. M. Vaughan, G. S chalk, J. R. Wolpaw, A. Schlögl, C. Neuper, G. Pfurtscheller , T. Hinterberger,
M. Schröder, and N. Birbaumer, “The BCI Competition 2003: Pr ogress and Perspectives in Detection and Discrimination of EEG Single
Trials ”,
IEEE Trans. Biomed. Eng., 51(6): 1044–1051, 2004.
[28] B. Blankertz, K.-R. M üller, D. Krusienski, G. Schalk, J . R. Wolpaw, A. Schlögl, G. Pfurtscheller, J. del R. Millán, M . Schröder, and
N. Birbaumer, “The BCI Competition III: Validating Alterna tive Approachs to Actual BCI Problems ”,
IEEE Trans. Neural Sys. Rehab.
Eng., 14(2): 153–159, 2006.

8

