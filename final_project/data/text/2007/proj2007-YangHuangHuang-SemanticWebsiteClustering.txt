Semantic Website Clustering 
I-Hsuan Yang, Yu-tsun Huang, Yen-Ling Huang  

 

1.  Abstract 
We  propose  a  new  approach  to  cluster  the  web  pages. 
Utilizing  an  iterative  reinforced  algorithm,  the  model 
extracts  semantic  feature  vectors  from  user  click-through 
data.  We  then  use  LSA  (Latent  Semantic  Analysis)  to 
reduce  the  feature  dimension  and  K-means  algorithm  to 
cluster  documents.  Compared  to  the  traditional  way  of 
feature  extraction  (lexical  binomial  model),  our  new 
model  has  better  purity  (75%)  and  F-measure  (52%). We 
can further use features combined from both methods and 
reach  purity  82%  and  F-measure  52%.  Moreover,  the 
same method  can  be used  to  cluster  queries,  and with  the 
result purity 74% and F-measure 43%. 
 
 
2.  Introduction 
As  the  tremendous  fast  growing  speed  of  the  number  of 
web  pages  on  the  Internet,  automatic  approach  for 
clustering web pages  are more desirable  than  ever before. 
Many  research  groups  are  developing  various  techniques 
trying  to  solve  the web page clustering problem and  there 
are  also  many  applications  available  as  well.  Besides  the 
lexical  features  which  are  used  for  traditional  clustering 
method,  we  further  consider  utilizing  click-through 
features 
in  order 
to  capture  more  relationship  on 
semantics. We  revise and  improve  the  iterative  reinforced 
algorithm  to  define  new  similarity  measure  in  several 
dimensions  on  which  we  can  build  semantic  cluster  on 
both query and web pages.  

In  the  traditional  cluster,  it  uses  only  the  text  to  build 
features,  but  there  is  a  lot  of  information  such  as  picture, 
multimedia,  meta-data,  hyperlinks… 
that  won’t  be 
captured. Since the click through data is manipulated by a 
huge  set  of  users,  it  can  be  seen  as  the  judgment  from 
actual users. Therefore, the real semantic similarity can be 
easily  observed  via  calculating  the  users’  real  clicks. We 
will  use  the  AOL  click-through  logs  and  web  pages 
automatically  crawled  from  the  Internet  as  the  training 
data. We  then compare  the performance between our new 
features  and  traditional  lexical  based  features.  We  also 
use  User  perception  test  as  our  evaluation  method. 
Besides  web  page  clustering,  we  can  use  this  method  as 
clustering  query  terms.  There  are  also  useful  applications 
for query  term cluster,  such as also  try  suggestions, query 
term auto completion.  

3.  Proposed Approach 
 

Figure 1: Clustering Model Flow Diagram 

 

 
3.1  Semantic feature vector extraction (blue blocks in 
Figure 1) 

 

Instead  of  lexical  frequency,  we  want  to  use  the  real 
semantic  meaning  of  each  web  page.  Using  the  AOL 
click-through  data  fits  our  needs,  since  those  clicks  are 
judged  from  real  users’  cognition  and  conception.  We 
assume  the  relevance  between  queries  and  documents  is 
very  accurate  based  on  a  great  deal  of  data  cumulated. 
Here the documents are web pages. 
Whenever  a  user  clicks  a  link  from  the  search  result  page 
we  use  the  query  and  URL  field  (cid:1731)(cid:1843) , (cid:1830)(cid:1732)  to  build  our 
(AOL  data  is  from  Google  search  engine),  it  produces  a 
vector  containing  five  fields:  user’s  ID  (usually  cookie 
number),  query,  query  timestamp,  item  rank,  URL.  Here 
bipartite graph model.  
3.1.1  Bipartite Graph Model 
 
],  they  used  a  bipartite  graph 
In  Xue’s  recent  work  [1
model  to  fit  the  click  through 
data  scenario  and  improved  the 
search  result  relevance.  One 
node 
of 
left 
hand 
side 
represents  one  query  key  word 
and one node of  right hand  side 
contains  node (cid:1869)(cid:3036)  (cid:1482)(cid:1861) (cid:1488) (cid:4668)1, … , (cid:1865)(cid:4669) 
represents 
document. 
one 
at  left  and  (cid:1856)(cid:3037)  (cid:1482)(cid:1862) (cid:1488) (cid:4668)1, … , (cid:1866)(cid:4669) at 
Assume there are m queries and 
n 
documents, 
the 
graph 
(cid:1869)(cid:3036)   to  (cid:1856)(cid:3037)   if  and  only  if  t
right.  There  exists  a  link  from 
here  is  at  least  one  click  data 

containing  the  tuple  (cid:1731)(cid:1843)(cid:3036) , (cid:1830)(cid:3037) (cid:1732) .  Moreover,  each  link  has 
weight  (cid:1839)(cid:3036)(cid:3037) ,  which  means  the  frequency  of  the  tuple 
(cid:1731)(cid:1843)(cid:3036) , (cid:1830)(cid:3037) (cid:1732).  It  can  be  seen  as  one  kind  of  relevance  between 
(cid:1843)(cid:3036)  and (cid:1830)(cid:3037) .  
sizes  (cid:1865) (cid:3404) (cid:1866) (cid:1542) 100  and  (cid:1865) (cid:3404) (cid:1866) (cid:1542) 1000 .  Therefore,  the 
 
n  this  pr
I
oject,  since  the  difficulty  of  labeling  the  gold 
standard  clustering, we  use  a  subgraph with  two  different 
input of this model is the raw AOL click-through data and 
output will be a data structure of a bipartite graph. 
 
 
.1.2  Naïve Method Feature Vector 
3
 
or each document, we will produce a  feature vector with 
F
(cid:1839)(cid:3036)(cid:3037)
dimension  m  (the  num  of  total  queries).  Define  the 
(cid:1849)(cid:3036)(cid:3037) (cid:3404)
∑
(cid:1839)(cid:3038)(cid:3037)
normalized frequency: 
 
(cid:3038)(cid:1488)(cid:4668)(cid:2869),…,(cid:3040)(cid:4669)
r  document (cid:1856)(cid:3037) , (cid:1862) (cid:1488) (cid:4668)1, … , (cid:1866)(cid:4669),  i
 
feature vector(cid:1731)(cid:1849)(cid:2869)(cid:3037) , (cid:1849)(cid:2870)(cid:3037) , … , (cid:1849)(cid:3040)(cid:3037) (cid:1732). 
 
t  contains  the 
herefore,  fo
T
 
.1.3 
Itera
3
tion Method I 
 
he features from naïve method can be used for clustering 
T
original  weight  (cid:1849)  is  very  sparse.  Here,  we  utilize  an 
itself,  but  there  are  some  problems  to  overcome:  noise, 
incompleteness, sparseness and volatility. The point  is we 
don’t  want  too  many  zeros’  in  one  vector,  whereas  the 
iteration method to fix the problem of raw click data. This 
pages.  Here  we  define  (cid:1845)(cid:3018) (cid:4670)(cid:1869)(cid:3046) , (cid:1869)(cid:3047) (cid:4671)  to  be  the  similarity 
method  is  based  on  the  assumption  of  co-visited  method: 
between  queries  (cid:1869)(cid:3046)  and  (cid:1869)(cid:3047) ,  and  (cid:1845)(cid:3005) (cid:4670)(cid:1856)(cid:3046) , (cid:1856)(cid:3047) (cid:4671)  to  be  the 
Web  pages  are  similar  if  they  are  visited  by  similar 
similarity  between  documents  (cid:1856)(cid:3046)  and  (cid:1856)(cid:3047) .  (cid:1845)(cid:3005)  and  (cid:1845)(cid:3018)  are 
queries,  and  queries  are  similar  if  they  visit  similar  web 
(cid:1845)(cid:3018)(cid:4666)(cid:2868)(cid:4667) (cid:3404) (cid:3420)0 (cid:4666)(cid:1869)(cid:3046) (cid:3405) (cid:1869)(cid:3047) (cid:4667)
1 (cid:4666)(cid:1869) (cid:3404) (cid:1869)(cid:3047) (cid:4667)
initialized to 1 if the components are identical. 
(cid:1845)(cid:3005)(cid:4666)(cid:2868)(cid:4667) (cid:3404) (cid:3420)0 (cid:4666)(cid:1856)(cid:3046) (cid:3405) (cid:1856)(cid:3047) (cid:4667)
(cid:3046)
 
1 (cid:4666)(cid:1856)(cid:3046) (cid:3404) (cid:1856)(cid:3047) (cid:4667) 
 
(cid:1844)(cid:1857)(cid:1868)(cid:1857)(cid:1853)(cid:1872) (cid:1873)(cid:1866)(cid:1872)(cid:1861)(cid:1864)  (cid:1855)(cid:1867)(cid:1866)(cid:1874)(cid:1857)(cid:1870)(cid:1859)(cid:1857)(cid:4668) nd update until converge: 
 
 we  se the update rul
F
or each iteration,
u
e based on the co-
(cid:1829)
visited assumption above a
(cid:1845)(cid:3018) (cid:4670)(cid:1869)(cid:3046) , (cid:1869)(cid:3047) (cid:4671) (cid:3404)
|(cid:1841)(cid:4666)(cid:1869)(cid:3046) (cid:4667)||(cid:1841)(cid:4666)(cid:1869)(cid:3047) (cid:4667)| (cid:3533) (cid:3533) (cid:1845)(cid:3018) (cid:4670)(cid:1841)(cid:3036) (cid:4666)(cid:1869)(cid:3046) (cid:4667), (cid:1841) (cid:3037) (cid:4666)(cid:1869)(cid:3047) (cid:4667)(cid:4671)
|(cid:3016)(cid:4666)(cid:3044)(cid:3295)(cid:4667)|
|(cid:3016)(cid:4666)(cid:3044)(cid:3294) (cid:4667)|
  
(cid:3037)(cid:2880)(cid:2869)
(cid:3036)(cid:2880)(cid:2869)
(cid:1829)
(cid:1845)(cid:3005) (cid:4670)(cid:1856)(cid:3046) , (cid:1856)(cid:3047) (cid:4671) (cid:3404)
|(cid:1835)(cid:4666)(cid:1856)(cid:3046) (cid:4667)||(cid:1835)(cid:4666)(cid:1856)(cid:3047) (cid:4667)| (cid:3533) (cid:3533) (cid:1845)(cid:3005) (cid:4670)(cid:1835) (cid:3036) (cid:4666)(cid:1856)(cid:3046) (cid:4667), (cid:1835) (cid:3037) (cid:4666)(cid:1856)(cid:3047) (cid:4667)(cid:4671)
|(cid:3010)(cid:4666)(cid:3031) (cid:4667)|
|(cid:3010)(cid:4666)(cid:3031) (cid:4667)|
(cid:3295)
(cid:3294)
(cid:4669) 
(cid:3037)(cid:2880)(cid:2869)
(cid:3036)(cid:2880)(cid:2869)
 

 

Where (cid:1829)  
(cid:1841)(cid:4666)(cid:1869)(cid:3046) (cid:4667) represents  all  the  out-links  for  query (cid:1869)(cid:3046) ,  and (cid:1835)(cid:4666)(cid:1856)(cid:3046) (cid:4667) 
represents  all  the  in-links  for  document (cid:1856)(cid:3046) .  After  several 
  b
  here. 
is  the  decay  factor,  and  is  set  to e  0.7
100  and  20~25  runs  for  size  1000),  (cid:1845)(cid:3018)  and  (cid:1845)(cid:3005)  will 
runs  of  iteration  (in  our  experiments,  10~15  runs  for  size 
converge  to  a  fixed  number  and  to  be  output  to  the 
semantic feature vector extraction model. 
 (cid:1839)(cid:3036)(cid:3037) , 
 
.1.4 
Iteration Method II 
3
 
ince  Iteration  method  I  doesn’t  use  the  frequency
S
 (cid:1844)(cid:1857)(cid:1868)(cid:1857)(cid:1853)(cid:1872) (cid:1873)(cid:1866)(cid:1872)(cid:1861)(cid:1864)  (cid:1855)(cid:1867)(cid:1866)(cid:1874)(cid:1857)(cid:1870)(cid:1859)(cid:1857)(cid:4668)  
Iteration method II uses the weighted version. The revised 
version of the update rule: 
(cid:1829)
(cid:1845)(cid:3018) (cid:4670)(cid:1841) (cid:3036) (cid:4666)(cid:1869)(cid:3046) (cid:4667), (cid:1841) (cid:3037) (cid:4666)(cid:1869)(cid:3047) (cid:4667)(cid:4671) 
(cid:1845)(cid:3018) (cid:4670)(cid:1869)(cid:3046) , (cid:1869)(cid:3047) (cid:4671) (cid:3404)
(cid:3533) (cid:4666)(cid:1839)(cid:3036)(cid:3046) (cid:3397) (cid:1839) (cid:3037)(cid:3047) (cid:4667)
∑
(cid:1839) (cid:3036)(cid:3037)
(cid:3036)(cid:1488)(cid:3016)(cid:4666)(cid:3044)(cid:3294)(cid:4667),(cid:3037)(cid:1488)(cid:3016)(cid:4666)(cid:3044)(cid:3295)(cid:4667)
(cid:3036)(cid:1488)(cid:3016)(cid:4666)(cid:3044)(cid:3294)(cid:4667),(cid:3037)(cid:1488)(cid:3016)(cid:4666)(cid:3044)(cid:3295)(cid:4667)
(cid:1829)
(cid:4669) 
(cid:1845)(cid:3005) (cid:4670)(cid:1835) (cid:3036) (cid:4666)(cid:1856)(cid:3046) (cid:4667), (cid:1835) (cid:3037) (cid:4666)(cid:1856)(cid:3047) (cid:4667)(cid:4671) 
(cid:1845)(cid:3005) (cid:4670)(cid:1856)(cid:3046) , (cid:1856)(cid:3047) (cid:4671) (cid:3404)
(cid:3533) (cid:4666)(cid:1839)(cid:3036)(cid:3046) (cid:3397) (cid:1839) (cid:3037)(cid:3047) (cid:4667)
∑
(cid:1839) (cid:3036)(cid:3037)
 
(cid:3036)(cid:1488)(cid:3010) (cid:4666)(cid:3031)(cid:3294) (cid:4667),(cid:3037)(cid:1488)(cid:3010) (cid:4666)(cid:3031)(cid:3295)(cid:4667)
(cid:3036)(cid:1488)(cid:3010)(cid:4666)(cid:3031)(cid:3294) (cid:4667),(cid:3037)(cid:1488)(cid:3010)(cid:4666)(cid:3031)(cid:3295)(cid:4667)
 
nI  our experiments, it converges a little faster than method 
I. 
   (cid:1482)(cid:1871), (cid:1872) (cid:1488) (cid:4668)1, … , (cid:1865)(cid:4669)
have  (cid:1845)(cid:3018) (cid:4670)(cid:1869)(cid:3046) , (cid:1869)(cid:3047) (cid:4671)
 
(cid:1845)(cid:3005) (cid:4670)(cid:1856)(cid:3046) , (cid:1856)(cid:3047) (cid:4671)(cid:1482)(cid:1871), (cid:1872) (cid:1488) (cid:4668)1, … , (cid:1866)(cid:4669) ,  and  (cid:1849)(cid:3036)(cid:3037)  (cid:1482)(cid:1861) (cid:1488) (cid:4668)1, … , (cid:1865)(cid:4669), (cid:1862) (cid:1488)
.1.5 
Semantic Feature Vector 
3
(cid:4668)1, … , (cid:1866)(cid:4669) .  Here  we  will  use  the  co-visited  assumption 
 
again:  for  each  pair (cid:1861) , (cid:1862) (cid:1875)(cid:1860)(cid:1857)(cid:1870)(cid:1857) (cid:1861) (cid:1488) (cid:4668)1, … , (cid:1865)(cid:4669), (cid:1862) (cid:1488) (cid:4668)1, … , (cid:1866)(cid:4669), 
, 
Now  we 
first  taking  all  of  the  queries  (cid:1869)(cid:3038)  which  is  similar  to  (cid:1869)(cid:3037)  
( (cid:1845)(cid:3018) (cid:4670)(cid:1869)(cid:3046) , (cid:1869)(cid:3047) (cid:4671) (cid:3410) 0.01(cid:4667) , 
(cid:1845)(cid:3018) (cid:4670)(cid:1869)(cid:3046) , (cid:1869)(cid:3047) (cid:4671) (cid:3400) (cid:1849)(cid:3038)(cid:3037) ,  and  assign  this  summation  to  (cid:1849)(cid:3036)(cid:3037)(cid:4593) . 
Therefore,  the  vector  (cid:1731)(cid:1849)(cid:2869)(cid:3037)(cid:4593) , (cid:1849)(cid:2870)(cid:3037)(cid:4593) , … , (cid:1849)(cid:3040)(cid:3037)(cid:4593) (cid:1732)  will  be  the 
semantic feature vector of document (cid:1856)(cid:3037) . 
then  sum  up  all 
the  values 
(cid:1849)(cid:1314)(cid:3036)(cid:3037) (cid:3404) (cid:3533) (cid:1845)(cid:3018) (cid:4670)(cid:1869)(cid:3038) , (cid:1869)(cid:3036) (cid:4671) (cid:3400) (cid:1849)(cid:3038)(cid:3037)
(cid:3038) :(cid:3020)(cid:3266) (cid:4670)(cid:3044)(cid:3286) ,(cid:3044)(cid:3284) (cid:4671)(cid:3001)(cid:2868).(cid:2868)(cid:2869)
 
3.2  Lexi
cal Feature Vector Extraction (green bl
in Figure 1) 
 
We  use  lexical  words  as  features  to  define  the  similarity 
between  documents  in  terms  of  lexical  meaning.  Two 
documents  would  be  considered  highly  related  if  they 
share  plenty  of  common  lexical  words.  We  build  a  web 
crawler to extract all the content text in each document (In 
this  paper  it’s  actually  website)  ,applying  the  Porter 
stemming  algorithm  and  stop  word  filter  to  filter  out 
unnecessary  word  to  create  the  lexicon  for  all  training 
data.  We  build  the  index  for  each  document  from  the 
lexicon  and  thus  the  feature  for  each  document  is 
consisted of all the lexicon words in the lexicon. 

ocks 

3.3  Latent Semantic Analysis  (pink blocks  in Figure 1) 
 
Since we have a relatively sparse data even after applying 
the iteration method, we use LSA to reduce the dimension 
the  eigenvector  for  Σ(cid:3021) Σ  and  ΣΣ(cid:3021) ,  we  set  a  target 
of  the  feature  vector  for  the  document  and  condense  the 
feature  vector  to  more  “concept”  space.  Using  the 
standard SVD decomposition to get the singular value and 
dimension  k  equal  to  the  number  of  clusters  labeled  in 
gold-standard  clustering  (k=21  in  our  experiment)  and 
reduce 
to  k-
the  higher  dimension  feature  vector 
dimension feature vector. 
 
3.4  Combine Semantic F

eatures with Lexical Features 

We  think  that  the  two  different  kind  of  feature  are 
essentially  complementary.  By  combining  these  two 
feature  sets  we  can  achieve  better  performance.  The 
lexical  features  can  capture  the  lexical  relation  between 
documents and queries while the semantic feature sets can 
capture  the  semantic  relationships.  As  shown  in  the 
Figure 2 below, we apply LSA to reduce the dimension to 
2-D  to show distribution of our  training data  in 2-D space 
demonstrating 
can 
features 
idea.  Semantic 
the 
significantly  help  to  explore  the  relationship  between 
documents which could be hard to see in lexical features.  

Figure 2: Document data distribution in 2-D projection 

provides  the  users  an  easier  way  to  navigate  and  browse 
on the Internet. 
 
3

.6.2  Document-to-Document Search 

By  constructing  the  clusters  of  relevant  documents,  given 
a  specific  document,  we  can  search  for  the  documents 
which  are  highly  related  in  terms  of  both  lexical  and 
semantic. 

3.6.3  Query-to Query Search 

By  constructing  the  clusters  of  relevant  query,  given  a 
specific  query,  we  can  provide  the  user  other  highly 
relevant  query 
terms  as 
the  common  “also 
try” 
functionality  widely  used  on  search  engines  and  e-
commerce documents. 
 (cid:1856)(cid:3037)  
(cid:1731)(cid:1849)(cid:2869)(cid:3037)(cid:4593) , (cid:1849)(cid:2870)(cid:3037)(cid:4593) , … , (cid:1849)(cid:3040)(cid:3037)(cid:4593) (cid:1732).  This  vector  can  be  utilized  to  build 
3.6.4 
Semantic Relevance Web Search 
additional  metadata (cid:1849)(cid:2869)(cid:3037) · (cid:1869)(cid:2869) (cid:3397) (cid:1849)(cid:2870)(cid:3037) · (cid:1869)(cid:2870) (cid:3397) (cid:1710) (cid:3397) (cid:1849)(cid:3040)(cid:3036) · (cid:1869)(cid:3040) . 
 
For (cid:1856)(cid:3037) .  This  metadata  will  improve  search  result  quality 
ment
will  have  the  feature  vector 
In  our  model,  docu
by  adding  the  semantic  meaning  into  the  relevance 
between  query  and  document.  By  adjusting  weight  for 
semantic  relevant  metadata,  we  can  have  different  kinds 
of search result (semantically or lexically). 
 
4  Experiment 
 
D

ata description 

4.1 

 
3.5  K-means Algorithm 

 

We  use  K-means  algorithm
  to  cluster  websites  and  user 
queries  terms  respectively.  We  set  the  k  equal  to  the 
number of clusters labeled in gold-standard clustering and 
start  with  random  seeds.  The  purity,  precision,  recall  and 
F-measure are computed by averaging several trials.  

3.6  Application 

This approach can

 be applied to several applications.  

3.6.1  Automatic web categorization 
 
We  always  need  a  good  way  to  automa
tically  categorize 
p
the  web  ages  on  the  Internet.  The  growing  speed  of  the 
Internet  is  too  fast  that  the  cost  of  manually  categorizing 
the  web  pages  by  hand  is  extremely  expensive  or  even 
unaffordable.  An  automatically  generated  clustering 

We  use  AOL  click-through  log  data  collection  as  our 
training  data.  This  collection  consists  of  ~20M  web 
queries  collected  from  ~650k  users  over  three  months 
from  01 March,  2006  -  31 May,  2006.  The  data  is  sorted 
by  anonymous  user  ID  and  sequentially  arranged.  This 
click-through  data  collection  provides  real  query  log  data 
that  is  based  on  real  users.  It  could  be  used  for 
personalization,  query  reformulation  or  other  types  of 
search  research.  The  detail  statistics  of  the  collection  is 
showed in Table 1. 
 

Table 1 : AOL Click-Through dataset stats 

Basic Collection Statistics 
lines of data 
instances of new queries (w/ or w/o click-
through) 
requests for "next page" of results 
user click-through events 
queries w/o user click-through 
unique (normalized) query 
unique user ID's 

36,389,567 
21,011,340 

7,887,022 
19,442,629
 
16,946,938 
10,154,742 
657,426 

Every  data  entry  in  this  click-through  collection  data  has 
the  columns  {AnonID,  Query,  QueryTime,  ItemRank, 
ClickURL}. 

AnonID - an anonymous user ID number.  
Query  - the query issued by the user, case shifted with most punctuation 
removed. 
QueryTime - the time at which the query was submitted for search. 
ItemRank  - if the user clicked on a search result, the rank of the item on 
which they clicked is listed. 
ClickURL    -  if  the  user clicked on a  search  result,  the domain portion of 
the URL in the clicked result is listed. 
 
We  extract  two  test  dataset  as  our  development  set.  The 
smaller  set  contains  approximately  100  user  queries  and 
documents.  The  larger  set  contains  approximately  1000 
user  queries  and  documents. After  ranking  all  the  queries 
and documents by  the frequency  in our dataset, we  ignore 
the  first  50  queries  and  documents  in  order  to  reduce  the 
number  of  navigational  search  in  our  dataset  and  extract 
the  queries,  documents  and  corresponding  links  between 
them in two different sizes as our test set. 
 
4.2  Experiment procedure 
 
We  conduct  the  experiment  on  both  semantic  feature 
vector  and  lexical  feature  vector  and  also  the  composite 
feature  vector.  Various  parameters  of  linear  combination 
of  the  two  feature  vector  are  used  for  the  composite 
feature vector and we perform the experiments on two test 
sets of different  size. The gold-standard clustering  for our 
development  sets  are  manually  labeled  by  human  for 
evaluation  purpose.  The  experiment  result  and  clustering 
example will be showed in the following section. 
 
4.3  Evaluation Measures 
 
There  are  three  main  approaches  for  the  clustering 
evaluation:  gold-standard, 
task-oriented 
and  user 
evaluation. In our experiment, we use gold-standard as the 
evaluation measures  for  our  clustering.  For  gold-standard 
approach,  we  manually  construct  an  ideal  clustering  by 
human  labeling.  The  ideal  clusters  are  then  compared 
against  the  machine  generated  clusters.  A  machine 
generated  clustering  is  considered  perfect  if  it  matches 
ideal clustering in gold-standard. There are two ways for a 
cluster  to be  less  than perfect: It may have poor quality as 
it doesn’t match any cluster well in the gold-standard, and 
it  may  have  poor  coverage  to  those  websites  in  gold-
standard  clustering. We  use  Purity  [3]  and  F-measure  [3] 
as  our  evaluation  measures  for  a  clustering.  They  are 
based on the precision and recall of the clusters. Precision 
is  defined  as  the  fraction  of  documents  in  the  cluster  that 
also  appear  in  the  gold-standard.  Recall  is  defined  as  the 
fraction  of  documents  in  the  gold-standard  cluster  that 

also  appear  in  the  machine  generated  cluster.  Therefore, 
the  Purity  of  a  clustering  is  the  average  precision  of  all 
clusters  relative  to  their  best  matching  clusters  in  the 
gold-standard. The F-measure is defined as the average F-
measure  of  the  clusters  relative  to  the  clusters  in  gold-
standard. 
 
4.4  Result 
 
We conduct the experiment on two tasks: 
•  Internet Website Clustering 
•  User Query Clustering 

For website clustering, we conduct the experiment on two 
development  sets. We  have  7  result  sets  corresponding  to 
7  different  feature  vectors.  In  Result  R0-R2  we  only  use 
the  semantic  features  to  generate  the  clustering.  In Result 
L  we  only  use  lexical  features  to  generate  the  clustering 
and  in Result C0-C1 we use the composite features which 
contain both semantic and lexical information. 

In  the  Table  2  below,  we  can  see  that  naïve  method  and 
result  L  which  only  use  lexical  features  give  us  baseline 
results.  Iteration method  I  and  II both  perform  better  than 
naïve method as expected. We get even better  result at 82% 
of  purity  and  52%  of  F-measure  when  combining  those 
two  feature  sets  together  which  is  reasonable  since  we 
expect the two feature sets to be complementary. In Table 
3 we show the experiment result on development set 2.  

Due  to  the  limitation  of  affordable  work  of  manually 
labeling gold-standard, we use a  slightly different method 
to  evaluate  the  clustering. We  only  label  part  of  the gold-
standard  and  selectively  match  the  machine  generated 
clusters  to  the  best  matched  cluster  in  the  partial  gold-
standard  and  only  evaluate  the  purity  here  to  understand 
show  the  result  with  different  parameter  (cid:1853)(cid:1864)(cid:1868)(cid:1860)(cid:1853)  for  the 
mainly  the  quality  of  the  clustering.  Same  trend  can  be 
observed  as  in  development  set  1  that  the  iteration 
methods  perform  better  than  the  naïve  method.  We  also 
interpolation  parameter  when  combining  the  two  feature 
sets  for  Naïve  method,  iteration  method  I  and  iteration 
method II in Figure 3-5. 

 

Table 2: Experiment result for document development set 1 
Website Development Set 1 (size = 100) 
 F-measure 
Purity 
 
0.4448 
0.7249 
Result R0 
0.6942 
0.4872 
Result R1 
0.5154 
0.7465 
Result R2 
0.4062 
0.7766 
Result L 
0.4827 
0.7989 
Result C0 
0.4959 
0.8149 
Result C1 
0.8156 
0.5154 
Result C2 
 

Precision 
0.7249 
0.6942 
0.7346 
0.7412 
0.6491 
0.6863 
0.7465 

Recall 
0.4209 
0.4583 
0.5019 
0.3484 
0.4612 
0.481 
0.5019 

 

r document develo
periment result for
Table 3: Exp
opment set 2 
ment Set 2 (size = 
W
Website Developm
1000) 
Purity 
 
0.4514 
R
Result R0 
0.5811 
R
Result R1 
0.5687 
R
Result R2 
0.5356 
R
Result L 
0.638 
R
Result C0 
0.6046 
R
Result C1 
0.6536 
R
Result C2 

 

ethod 
Result for Naïve Me
e 3: Experiment R
Figure

Naive M
Method

purity
precision
recall
F‐measure

2 0.3 0.4 0.5 0.6 0
0 0.1 0.2
.7 0.8 0.9 1

alpha

sult for Iteration M
4: Experiment Res
Figure 4
Method I 

Iteration
 Model I

purity

precision

recall

F‐measure

2 0.3 0.4 0.5 0.6 0
0 0.1 0.2
.7 0.8 0.9 1

alpha

ethod II 
ult for Iteration M
5: Experiment Resu
Figure 5

Iteration 

Model II

 

 

purity

precision

recall

F‐measure

 

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

2 0.3 0.4 0.5 0.6 0
0 0.1 0.2
.7 0.8 0.9 1

alpha

 
ser  query  data
ment  on  the  us
uct  the  experim
We  also  condu
W
. 
on  3.1,  we  can
cribed  in  Sectio
e  method  desc
Using  the  same
U
n 
the  similarity
a
also  compute 
y  between  use
er  queries  and
d 
generate cluster
g
ring on user qu
ueries.  

 

query development
riment result for q
Table 4: Exper
t set 
User Q
Query Developme
ent Set 1 (size = 1
100) 
Recall 
Precision 
 
 F-measure
Purity 
 
0.7589 
0.3135 
0.7589 
0.3733 
t R0 
Resul
0.419 
0.6751 
0.4346 
0.7377 
t R1 
Resul
0.3468 
0.7224 
0.3988 
0.7154 
Resul
t R2 
g result 
In Fi
gure 6 below w
we show the ac
ctual clustering
elopment set 1.
Website Deve
m Result C2 for 
from
 It is easy 
websites in term
e that similar w
to see
ms of both lexi
ical and 
sema
antic meaning a
are clustered to
ogether. 
 

Figure 6: Clust
tering example forr website developmment set 1 

 

 

 

5  C
Conclusion
we  utilize  the
e  semantic 
In  th
his  web  cluste
ering  project, 
data  to  extra
click-through 
act  feature 
rmation  from 
infor
ction model com
ors. This novel
vecto
l feature extrac
mplements 
the 
traditional  lex
xical  feature 
extraction  m
ethod  and 
provi
ides  an  effec
ctive  way  to 
generate  sem
mantic  rich 
od  also  overc
teration  metho
ering.  The  it
clust
comes  the 
e  nature  of  clic
eness  from  the
culty  of  sparse
diffic
ck-through 
oint  representin
s  to  a  fixed  po
and  converges
data 
ng  the  real 
simil
larity  between
n  queries  and
d  documents. 
Using  the 
lexical  feature
emantic  and  l
bination  of  se
comb
es  we  can 
achie
eve  the  best  p
performance  in
n  terms  of  clu
uster  purity 
and F
F-measure. 
6  R
Reference 
en, Y. Yu, W.-
J. Zeng, Z. Che
G.-R. Xue, H.-J
[1] G
-Y. Ma, W. 
X
Xi,  W.G.  Fan. 
Optimizing  W
Web  Search  U
Using  Web 
Click-through  D
C
Data.  In  Proce
eedings  of  the
e  thirteenth 
nce  on  Inform
onal  conferen
ACM  internatio
A
mation  and 
nowledge  ma
kn
anagement,  W
Washington  D.
.C.,  USA. 
November 08-1
N
3, 2004. 
howdhury,  C.  T
[2]  G
G.  Pass,  A.  Ch
Torgeson,    "A 
Picture  of 
national  Confe
  First  Intern
  The
earch" 
S
ference  on 
, Hong Kong, 
mation Systems
calable Inform
S
June, 2006. 
d  Clustering  a
ationship-based
[3]  A
A.  Strehl.  Rela
and  Cluster 
onal  Data  Mi
E
Ensembles  for 
High-dimensi
ining.  PhD 
th
hesis,  Faculty
y  of 
the  Gra
aduate  Schoo
ol  of  The 
exas at Austin,
University of Te
U
, 2002. 

 

