    Image Processing for Bubble Detection in Microfluidics   

                                                  Chen Fang 
                                    Mechanical Engineering Department 
                                                        Stanford University 

Introduction 
      Starting  from  recently  years,  microfluidics  devices  have  been  widely  used  to  build  the  biomedical  devices  and 
micro  fuel  cells.  In  the  research  on  microfludics,  high  speed  camera  is  widely  used  to  record  the  motion  of  liquid 

bubbles  in  the  microchannel,  based  on  which  the  dynamics  of  bubbles  can  be  interpreted.  However,  the  mechanical 

vibration  of  the  system  causes  the  channel  to  deviate  from  its  original  position  during  the  image  acquisition  process. 

Figure  1(a)  shows  a  typical  image  of  a  silicon microchannel with  sidewall water  injection,  in which  the  injected water 

bubble  and  the  skewness  of  the  channel  are  evident.  Hence,  it  is  necessary  to  perform  the  skewness  and  translation 

correction on the raw  images acquired by  the high  speed camera before  the correct information of  the bubble trajectory 

can be  obtained from  the  images.    Also,  to  extract  the motion  information from a huge number  of  images, we  need  to 

isolate  the  front  bubble  object  from  the  background  image,  which  will  facilitate  the  automatic  calculation  of  bubble 

velocity.   

      The  spatial  deviation  of  the  image  can  be  decomposed  into  angular  and  translational  components.  In  the  current 

project, we will first develop  an algorithm  to efficiently calculate  the angular deviation of the  image based on solving a 

minimization  problem  using  Least  Square  SVM.  Also,  the  translation  correction  of  image  can  be  accomplished  in  a 

straightforward  way.  After  the  realignment  of  the  image  is  finished,  the  moving  bubble  can  be  separated  from  the 

background image by using Gaussian mixture model and EM algorithm  to classify each pixel  in  the image as either the 

foreground or background. The test result shows that the present skewness correction algorithm works very well for the 

tilt angle less than 20 degree. Also, the background separation algorithm can successfully distinguish the moving object 

from  the  background  image  with  still  droplets  in  it  for  various  illumination  conditions.  The  major  advantage  of  the 

current approach is that no iteration is required and computation is very cheap.       

Skewness Correction   

    To correct for the angular deviation, we first convert the original gray-scale image (Fig.1(a)-4(a)) into binary 
image(Fig.1(b)-4(b)). Suppose the image tilt angle should be corrected by  α , then the white pixel at (
,x y ) is moved 

to (

'
',
x y ), where we have: 





x

'

'

y





=


θ
'

θ


  
x
  
  
y

  ,    where     


θ
'

θ






=





cos

α

−

sin

sin

α α
cos


α



                                            (1) 

Since the biggest feature in the binary images is a pair of straight black lines representing the channel border, to 
implement the skewness correction, we only need to calculate theθ, such that the projection of the black pixels onto 
the y axis after the correction assumes the minimal value, i.e.: 
N
∑
=
1
i

                                          (2) 

N
−∑
'
(
y
i
=
1
i

−
θ
[ ,
x y

    or   

2

T
] )

θ
( [

,
x y
i
i

T
]

−
y

' 2
)

min

min

Here, we construct a training data set {

, }
iX Y corresponding to all the black pixels in the image, such that 
i

iX

2
R∈  

indicates the x, y coordinates of the pixel, and 

iY R∈   can be set as a constant. If we use 

(
f X

)

=

X bθ
+

θ
, (

≠

0)

to 

regress  {

iX Y , then the regression error is : 
, }
i

ε

=

(
f X

)

− =
Y

θ
+ −                                                                                             (3) 
X b Y

T
]

θ
( [

T
] )

min

,
x y
i
i

−
θ
[ ,
x y

It is interesting to recognize that the skewness correction objective (2) can be expressed as: 
N
∑
=
1
i
N
∑
=
1
i
N
∑
=
1
i

                                                                                    (4) 

ε
− − − − −
b Y
b Y
i

min

min

ε
(
i

ε
(
i

=

=

2

)

2

2

)

In deriving (4), we recognized that 

iY R∈   is set as a constant in our application.   

By comparing (3) and (4), we find that to determine  θ  , it is equivalent to regress the training set  {

iX Y   using the 
, }
i

linear equation 

(
f X

)

=

+
X bθ

θ
, (

≠

0)

.   

1

min

Here, we use the least square SVM to implement the regression. In particular, we consider the minimization problem: 
n
∑                                                                                                       (5) 
2
ζ
e
i
2
=
1
i
− − =
b e
i

2
−
θ
X

. .
s t Y
i

T
θθ

+

1

0

i

By constructing the Lagrangian function, taking derivative with respect to 

,b eθ and Lagrangian multiplier a, we 
,

have: 

0



1

N

T
1
N
γ−

Ω −

  
b
  
I α
 

N

1

=

 
0
 
 
Y

                                                                                              (6) 

with 

Y

= K
1[
,
y

,

y

N

]T

,1]T
N = K , 
, 1
[1,

= K
α α α
,
,
1[
N

]T

, 

NI

is  an  N N×

identity  matrix,  and  the  kernel  matrix 

Ω ∈ R

N N×

  with 

Ω =
ij

T
x x
i

j

. Since the intercept b does not influence the  θ, (6) can be simplified as: 

Ω =
a

Iaγ−
1

                                                                                                                            (7) 

Then non-zero vector  a correspond to the first eigenvector of  
N
= ∑
=
1
i

Finally, the correction angular displacement 

a X
i

θ

T
i

 

Ω ∈ R

N N×

. 

After finishing the skewness correction, the next step is moving the image in X and Y direction to finally finish the 

image alignment. In the present case, such alignment can be achieved based on the position of the water injection point. 

We will not talk about this part in detail. 

 

Moving Bubble Detection 

To  estimate  the  bubble  trajectory  in  an  automatic  manner, we  need  moving  bubble  detection  algorithm  to  separate  the 

moving  bubble  from  the  channel  and  other  still  objects  in  the  background  for  each  frame  in  the  video  sequence.  The 

easiest  way  to  detect  moving  object  in  an  image  includes  obtaining  the  background  image  first,  and  then  subtract  the 

background  image  from  the  original  image,  leaving  the  foreground  moving  objects.  However,  this  technique  is  not 

applicable to the present study, since the background image varies with the fluctuation of the illumination condition and 

the  existence  of  some  other  still  droplets  during  the  image  capture  process,  making  it  very  difficult  to  find  a  general 

background  image  applicable  to  all  frames  in  the  video.    Here,  we  consider  a  single  pixel  and  the  distribution  of  its 

values  over  time.  At  a  specific moment,  a  particular  pixel  may  be  either  in  the  background  state  or  in  the  foreground 

state.  Thus,  the  intensity  value 

,x yi

  of  a  pixel  (x,  y)  can  be  treated  as  the  weighted  sum  of  two  Gaussian 

distributions: 
φ
=
,
,
b ackg rou n d x y

,
x y

i

g

,
,
ba ckgro un d x y

+

(1

−

φ
,
,
b ackg rou n d x y

)

g

,
,
fo regro u nd x y

w here

:

,
,
b ackg rou n d x y

,
,
foreg rou nd x y

(cid:2)

(cid:2)

N

(

µ
,
,
ba ckgro u nd x y

,

N

(

µ
,
,
fo reg ro un d x y

,

∑

∑

,
,
ba ckgro un d x y

,
,
foreg rou nd x y

)

)

g

g

 

The model for pixel (x,y)  is parameterized by the parameter 

(8)

 

θ
,
x y

=

φ µ
,
{
,
,
,
,
l x y
l x y

,

Σ

,
,
l x y

|

l

∈

{

,
foreground background

}}

(9)

 

Let i be the pixel intensity, L be a random variable indicating the label of the pixel in the image, our model defines the 

probability distribution:   

=
(
, )
, ( ,
P L l I x y t

=

i

|

θ
)

=

φ
,
,
l x y
n

π
(2 )

2

|

Σ

,
,
l x y

exp(

−

1

2

1

2

|

(
i

−

µ
,
,
l x y

T
)

Σ

−
1
,
,
l x y

(
i

−

µ
,
,
l x y

))

(10)

 

Knowing the parameter  θ  of the above probability distribution of each pixel, we can classify each pixel as either 
background or foreground based on the highest posteriori probability (
. 
=
, ))
| ( ,
P L l I x y t

θ
Here, our objective is to find parameters

=

arg max
θ

∏

T
=
1
t

=
(
P L l
t

, ( ,
, ) |
I x y t

θ
)

, by taking derivative, it can be found 

that: 

φ
,
,
l x y

=

µ
,
,
l x y

=

N

,
,
l x y

T
M

,
,
l x y

N

,
,
l x y

 

∑

=

,
,
l x y

Z

N

,
,
l x y

,
,
l x y

−

T
µ µ
,
,
,
,
l x y
l x y

 

w h e r e

N

,
,
l x y

=

M

,
,
l x y

=

Z

,
,
l x y

=

T
∑
=
1
t
T
∑
=
1
t
T
∑
=
1
t

1{

L

,
,
x y t

=

l

}

(1{

L

,
,
x y t

=

} (
, ) )
,
l I x y t

(1{

L

,
,
x y t

=

T
} (
, ) )
,
, ) (
,
l I x y t I x y t

T

Since we do not have the labels 

x y tL
,
,

  for the training data, the above equations can not be calculated directly. Instead, 

we calculate a sequence of parameter settings, in which each setting is found by using the previous one to classify the 

l x yθ , we can use the expect 
data. In particular, suppose at the current step we have some distribution parameterized by ,
,

values of different labels according to 

l x yθ   as an estimate of their true value. Taking 
,
,

l x yN
,
,

as an example, we have: 

N

,
,
l x y

=

[
E N

,
,
l x y

|

θ
,
,
l x y

]

=

T
∑
=
1
t

(
P L
t

=

θ
|
, ),
( ,
l I x y t
,
,
l x y

)

(11)

 

To classify each new frame, this approach requires calculating the summation over all the previous frames, which is 

quite expensive. As an alternative way, whenever we classify a new frame, we add its contribution to the current 

statistics, which means that we are increasing our training set at each step, without reprocessing the previous frames in 

the training set. Hence, we have following algorithm: 

Initialize 

l x yθ   for each pixel in the first image in the video. 
,
,

For each new frame { 

        For each pixel in the new frame { 

              1. Update the parameter 

l x yθ   for mixture model: 
,
,

N

,
,
l x y

= −
:
(1

α
)

N

+

α
(
P L
t

=

θ
, ),
|
( ,
l I x y t
,
,
l x y

)

,
,
l x y

M

,
,
l x y

= −
:
(1

)
a M

+

α
(
P L
t

=

|
, ),
( ,
l I x y t

θ
,
,
l x y

) ( ,
, )
I x y t

,
,
l x y

Z

,
,
l x y

= −
:
(1

)
a Z

+

α
(
P L
t

=

θ
, ),
|
( ,
l I x y t
,
,
l x y

,
,
l x y

T
) ( ,
, )
, ) ( ,
I x y t I x y t

θ
,
,
l x y

=

(
f N

,

M

,

Z

,
,
l x y

)

,
,
l x y

,
,
l x y

 

(12)

2. Classify the pixel as background or foreground, based on the current mixture model 

} 

} 

 

  Since the illumination condition may change over the time, each frame’s contribution to the background image need to 
be weighted according how far it is away from the current frame. Therefore, we introduce the relaxation factor  α   in 
(12).  α   lies between 0 and 1; The influence of the previous image on the current image decays exponentially with the 
distance. In the present study, we choose  α=0.5. 

 

Result 

Figure1 through Figure 4 shows the image processing result for four frames using the present algorithm for skew 

correction and moving bubble extraction. It is shown that the skewness correction method works very well for the 

images in various angles. In particular, the algorithm is not susceptible to the noise (scattered black pixels) in the binary 

image converted from the source image. Also, the moving bubble is successfully separated from the background 

channel. In particular, the algorithm correctly classifies the still bubble in the channel as background and excludes it 

from the resulted moving bubble image. By recognizing that such still object may exist at any place in the channel and 

may not be correctly removed by directly subtracting a predetermined background image from the source image, the 
advantage of our method is evident.   

Summary 

In the present study, we correct a sequence of skew images by solving a minimization problem based on LS SVM. The 

moving bubble object is extracted by classifying each pixel in the image using Gaussian mixture model. The result is 

quite satisfactory for the present application. The major advantage of the current methods is that no iteration is involved 

in both steps. In particular, the correction angle can be directly obtained by calculating the eigenvector of the resulted 

matrix, and the classification model for the pixels in the current frame can be updated by adding the contribution of the 

present image to the parameters of the previous image. Therefore, the computation is very cheap and an implementation 

in real time is possible.   

 

 

 

 

 

 

y 

x 

Water injection point 

Moving bubble 

Still bubble 

               

 

 
     
  Fig.1      image processing result for frame 1 ((a) original image, (b) binary image, (c) corrected image, (d) extracted moving bubble, 

note our algorithm can successfully remove the still bubble from the extracted image) 

 

 

   
Fig.2      image processing result for frame 2 

     

 

 

Fig.3      image processing result for frame 3 

     

   

     

