Cooled and Relaxed Survey Propagation for MRFs

Hai Leong Chieu1,2 , Wee Sun Lee2
1Singapore MIT Alliance
2Department of Computer Science
National University of Singapore
haileong@nus.edu.sg,leews@comp.nus.edu.sg

Yee-Whye Teh
Gatsby Computational Neuroscience Unit
University College London
ywteh@gatsby.ucl.ac.uk

Abstract

We describe a new algorithm, Relaxed Survey Propagation (RSP), for ﬁnding
MAP conﬁgurations in Markov random ﬁelds. We compare its performance with
state-of-the-art algorithms including the max-product belief propagation, its se-
quential tree-reweighted variant, residual (sum-product) belief propagation, and
tree-structured expectation propagation. We show that it outperforms all ap-
proaches for Ising models with mixed couplings, as well as on a web person
disambiguation task formulated as a supervised clustering problem.

1

Introduction

Energy minimization is the problem of ﬁnding a maximum a posteriori (MAP) conﬁguration in a
Markov random ﬁeld (MRF). A MAP conﬁguration is an assignment of values to variables that
maximizes the probability (or minimizes the energy) in the MRF. Energy minimization has many
applications; for example, in computer vision it is used for applications such as stereo matching [11].
As energy minimization in general MRFs is computationally intractable, approximate inference al-
gorithms based on belief propagation are often necessary in practice. Such algorithms are split into
two classes: max-product and variants address the problem by trying to ﬁnd a MAP conﬁguration
directly, while sum-product and variants return approximate marginal distributions which can be
used to estimate a MAP conﬁguration. It has been shown that the max-product algorithm converges
to neighborhood optimums [18], while the sum-product algorithm converges to local minima of the
Bethe approximation [20]. Convergence of these algorithms are important for good approximations.
Recent work (e.g. [16, 8]) on sufﬁcient conditions for convergence of sum-product algorithms sug-
gests that they converge better on MRFs containing potentials with small strengths. In this paper,
we propose a novel algorithm, called Relaxed Survey Propagation (RSP), based on performing the
sum-product algorithm on a relaxed MRF. In the relaxed MRF, there is a parameter vector y that
can be optimized for convergence. By optimizing y to reduce the strengths of potentials, we show
empirically that RSP converges on MRFs where other algorithms fail to converge.
The relaxed MRF is built in two steps, by ﬁrst (i) converting the energy minimization problem into
its weighted MAX-SAT equivalent [17], and then (ii) constructing a relaxed version of the survey
propagation MRF proposed in [14]. We prove that the relaxed MRF has approximately equal joint
distribution (and hence the same MAP and marginals) as the original MRF, independent (to a large
extent) of the parameter vector y. Empirically, we show that RSP, when run at low temperatures
(“cooled”), performs well for the application of energy minimization. For max-product algorithms,
we compare against the max-product algorithm and its sequential tree-reweighted variant, which
is guaranteed to converge [11]. For sum-product algorithms, we compare against residual belief
propagation [6] as a state-of-the-art asynchronous belief propagation algorithm, as well as the tree-
structured expectation propagation [15], which has been shown to be a special case of generalized
belief propagation [19]. We show that RSP outperforms all approaches for Ising models with mixed
couplings, as well as in a supervised clustering application for web person disambigation.

(a) G = (V , F )
(b) W = (B , C )
Figure 1: The variables x1 , x2 in (a) are binary, resulting in 4 variables in (b). The clauses α1 to α4
in (b) are entries in the factor a in (a), γ1 and γ2 (resp. γ3 and γ4 ) are from b (resp. c). β (1) and
β (2) are the positivity clauses. The relaxed MRF for RSP has a similar form to the graph in (b).
2 Preliminaries
A MRF, G = (V , F ), is deﬁned by a set of variables V , and a set of factors F = {Φa}, where
each Φa is a non-negative function depending on Xa ⊆ V . We assume for simplicity that variables
in V have the same cardinality q , taking values in Q = {1, .., q}. For Xi ∈ V and Xa ⊆ V ,
(cid:81)
we denote by xi the event that Xi = xi , and by xa the event Xa = xa . To simplify notation,
we will sometimes write i ∈ V for Xi ∈ V , or a ∈ F for Φa ∈ F . The joint distribution over
E (x) = (cid:80)
a Φa (xa ) where Z is the normalization factor. When each
conﬁgurations is deﬁned by P (x) = 1
Z exp(−E (x)/T ) where
Z
Φa is a positive function, the joint distribution can be written as P (x) = 1
a − log Φa (xa ) is the energy function, and the temperature T is set to 1. A factor graph
[13] is a graphical representation of a MRF, in the form of a bipartite graph with two types of nodes,
the variables and the factors. Each factor Φa is connected to the variables in Xa , and each variable
Xi is connected to the set of factors, N (i), that depends on it. See Figure 1(a) for a simple example.

Weighted MAX-SAT conversion [17]: Before describing RSP, we describe the weighted MAX-
SAT (WMS) conversion of the energy minimization problem for a MRF. The WMS problem is a
generalization of the satisﬁability problem (SAT). In SAT, a set of boolean variables are constrained
by a boolean function in conjunctive normal form, which can be treated as a set of clauses. Each
clause is a set of literals (a variable or its negation), and is satisﬁed if one of its literals evaluates to
1. The SAT problem consist of ﬁnding a conﬁguration that satisﬁes all the clauses. In WMS, each
clause has a weight, and the WMS problem consists of ﬁnding a conﬁguration with maximum total
weight of satisﬁed clauses (called the weight of the conﬁguration). We describe the conversion [17]
of a MRF G = (V , F ) into a WMS problem W = (B , C ), where B is the set of boolean variables
and C the set of weighted clauses. Without lost of generality, we normalize factors in F to take
values in (0, 1]. For each Xi ∈ V , introduce the variables σ(i,xi ) ∈ B as the predicate that Xi = xi .
For convenience, we index variables in B either by k or by (i, xi ), denote factors in F with Roman
alphabet (e.g. a, b, c) and clauses in C with Greek alphabet (e.g. α, β , γ ). For a clause α ∈ C , we
denote by C (α) as the set of variables in α. There are two types of clauses in C : interaction and
positivity clauses.
Deﬁnition 1. Interaction clauses: For each entry Φa (xa ) in Φa ∈ F , introduce the clause α =
∨xi∈xa σ(i,xi ) with the weight wα = − log(Φa (xa )). We write α (cid:64) a to show that the clause α
comes from the factor Φa ∈ F , and we denote a = src(α) to be the factor Φa ∈ F for which α (cid:64) a.
The violation of an interaction clause corresponding to Φa (xa ) entails that σ(i,xi ) = 1 for all xi ∈
xa . This correspond to the event that Xi = xi for Xi ∈ Xa .
weights wβ (i) = 2 ∗ (cid:80)
Deﬁnition 2. Positivity clauses: for Xi ∈ V , introduce the clause β (i) = ∨xi∈Qσ(i,xi ) with
wα , where Ci is the set of interaction clauses containing any vari-
α∈Ci
able in {σ(i,xi ) }xi∈Q . For Xi ∈ V , we denote β (i) as the corresponding positivity clause in C , and
for a positivity clause β ∈ C , we denote src(β ) for the corresponding variable in V .
Positivity clauses have large weights to ensure that for each Xi ∈ V , at least one predicate in
{σ(i,xi ) }xi∈Q equals 1. To map σ back to a conﬁguration in the original MRF, exactly one variable
in each set of {σ(i,xi )}xi∈Q can take the value 1. We call such conﬁgurations valid conﬁgurations:

a12bc: factors: variablesσ(1,1)σ(1,2)β(1)σ(2,1)σ(2,2)β(2)α1α4α3α2γ3γ1γ2γ4ασασσ is a negative literal in ασ is a positive literal in αLegend:Deﬁnition 3. A conﬁguration is valid if ∀Xi ∈ V , exactly one of the indicators {σi,xi }xi∈Q equals
1. There are two types of invalid conﬁgurations: MTO conﬁgurations where more than one variable
in the set {σi,xi }xi∈Q equals 1, and AZ conﬁgurations where all variables in the set equals zero .
For valid conﬁgurations σ , let x(σ) be the corresponding conﬁguration of σ in V .
For valid conﬁgurations σ , and for each a ∈ F , exactly one interaction clause in {α}α(cid:64)a is violated:
when α corresponding to Φa (xa ) is violated, we have Xa = xa in x(σ). Valid conﬁgurations have
locally maximal weights [17]: MTO conﬁgurations have low weights since in all interaction clauses,
variables appear as negative literals. AZ conﬁgurations have low weights because they violate the
positivity clauses. See Figure 1 for an example of a WMS equivalent of a simple factor graph.

3 Relaxed Survey Propagation

(1)

VALα (σC (α) ) =

In this section, we transform the WMS problem W = (B , C ) into another MRF, Gs = (Vs , Fs ),
based on the construction of the MRF for survey propagation [14]. We show (in Section 3.1) that
under this framework, we are able to remove MTO conﬁgurations, and AZ conﬁgurations have
negligible probability. In survey propagation, in addition to the values {0, 1}, variables can take a
third value, * (“joker” state), signifying that the variable is free to take either 0 or 1, without violating
any clause. In this section, we assume that variables σk take values in {0, 1, ∗}.
Deﬁnition 4. [14] A variable σk is constrained by the clause α ∈ C if it is the unique
satisfying variable for clause α (all other variables violate α). Deﬁne CONk,α (σC (α) ) =
δ(σk is constrained by α), where δ(P ) equals 1 if the predicate P is true, and 0 otherwise.
We introduce the parameters {ya}a∈F and {yi }i∈V by modifying the deﬁnition of VAL in [14]:
Deﬁnition 5. An assignment σ is invalid for clause α if and only if all variables are unsatisfying
exp(wα )
except for exactly one for which σk = ∗. (In this case, σk cannot take * as it is constrained). Deﬁne
if σC (a) satisﬁes α
exp(−ysrc(α) )
if σC (a) violates α
0
if σC (a) is invalid
The term exp(−ysrc(α) ) is the penalty for violating clauses, with src(α) ∈ V ∪ F deﬁned in Deﬁ-
nitions 1 and 2. For interaction clauses, we index ya by a ∈ F because among valid conﬁgurations,
exactly one clause in the group {α}α(cid:64)a is violated, and exp(−ya ) becomes a constant factor. Posi-
tivity clauses are always satisﬁed and the penalty factor will not appear for valid conﬁgurations.
Deﬁnition 6. [14] Deﬁne the parent set Pi of a variable σk to be the set of clauses for which σk is
the unique satisfying variable, (i.e. the set of clauses constraining σk ).
We now construct the MRF Gs = (Vs , Fs ) where variables λk ∈ Vs are of the form λk = (σk , Pk ),
with σk variables in the WMS problem W = (B , C ). (See Figure 1). We deﬁne single-variable
(cid:40) ω0 if Pk = ∅, σk (cid:54)= ∗
compatibilities (Ψk ) and clause compatibilities (Ψα ) as in [14]:
ω∗ if Pk = ∅, σk = ∗
Ψk (λk = {σk , Pk }) =
Ψα (λα = {σk , Pk }k∈C (α) ) = VALα (σC (α) ) × (cid:89)
, where ω0 + ω∗ = 1
1 for any other valid (σk , Pk )
δ((α ∈ Pk ) = CONα,k (σC (α) )), (3)
k∈C (α)
where δ is deﬁned in Deﬁnition 4. The single-variable compatibilities Ψk (λk ) are deﬁned so that
when σk is unconstrained (i.e. Pk = ∅), Ψk (λk ) takes the values ω∗ or ω0 depending on whether
σk equals *. The clause compatibilities introduce the clause weights and penalties into the joint
exp (wα ) (cid:89)
(cid:89)
distribution. The factor graph has the following underlying distribution:
exp(−ysrc(α) ),
P ({σk , Pk }k ) ∝ ωn0
0 ωn∗∗
α∈UNSAT(σ)
α∈SAT(σ)
where n0 is the number of unconstrained variables in σ , and n∗ the number of variables taking ∗.
Comparing RSP with SP-ρ in [14], we see that

(2)

(4)

Theorem 1. In the limit where all ya , yi → ∞, RSP is equivalent to SP-ρ [14], with ρ = ω∗ .
satisﬁed and the term (cid:81)
Taking y to inﬁnity correspond to disallowing violated constraints, and SP-ρ was formulated for
satisﬁable SAT problems, where violated constraints are forbidden. In this case, all clauses must be
α∈C exp(wα ) in Equation 4 is a constant, and P (σ) ∝ ωn0
0 ωn∗∗ .
3.1 Main result

In the following, we assume the following settings: (1) ω∗ = 1 and ω0 = 0 ; (2) for positivity clauses
β (i), let yi = 0 ; and (3) in the original MRF G = (V , F ), single-variable factors are deﬁned on
all variables (we can always deﬁne uniform factors). Under these settings, we will prove the main
result that the joint distribution on the relaxed MRF is approximately equal to that on the original
MRF, and that RSP estimates marginals on the original MRF. First, we prove the following lemma:
Lemma 1. The joint probability over valid conﬁgurations on Gs is proportional to the joint proba-
bility of the corresponding conﬁgurations on the original MRF, G = (V , F ).
a∈F exp(ya ) is a constant factor. Let W = (cid:80)
penalty term for violated constraints (cid:81)
Proof. For valid conﬁgurations, all positivity clauses are satisﬁed, and for each a ∈ F , all valid
conﬁgurations have one violated constraint in the set of interaction clauses {α}α(cid:64)a . Hence the
α∈C wα be the
wγ ) ∝ (cid:89)
wγ ) = exp(W − (cid:88)
P (σ) ∝ exp( (cid:88)
sum of all weights. For a valid conﬁguration σ ,
Φa (x(σ))
a∈F
γ∈SAT(σ)
γ∈UNSAT(σ)

Lemma 2. All conﬁgurations containing * have zero probability in the MRF Gs , and there is a
one-to-one mapping between conﬁgurations λ = {σk , Pk }k∈Vs and conﬁgurations σ = {σk }k∈B
Proof. Single-variable factors on G translate into single-literal clauses in the WMS formulation,
which in turn becomes single-variable factors in Gs . For a variable λk = (σk , Pk ) with a single-
variable factor, Ψα , we have VALα (σk = ∗) = 0. This implies Ψα (λk = (∗, Pk )) = 0.
Lemma 3. MTO conﬁgurations have n0 (cid:54)= 0 and since ω0 = 0, they have zero probability.
Proof. In MTO conﬁgurations, ∃(i, xi , x(cid:48)
= 1. The positivity clause β (i) is hence
i ), σi,xi = σi,x(cid:48)
i
non-constraining for these variables, and since all other clauses connected to them are interaction
clauses and contain them as negative literals, both variables are unconstrained. Hence n0 (cid:54)= 0, and
from Equation 4, for ω0 = 0, they have zero probability.

The above lemma lead to the following theorem:
Theorem 2. Assuming that exp(wβ (i) ) (cid:29) 1 for all Xi ∈ V , the joint distribution over the relaxed
beliefs at each node, B (σ(i,xi ) = 1), is an estimate of P (Xi = xi ), and (cid:80)
MRF Gs = (Vs , Fs ) is approximately equal to the joint distribution over the original MRF, G =
(V , F ). Moreover, RSP estimates the marginals on the original MRF, and at the ﬁxed points, the
xi∈Q B (σ(i,xi ) = 1) ≈ 1.
if we assume that the probability of AZ in-
We can understand the above theorem as follows:
valid conﬁgurations is negligible (equivalent to assuming that the probability of violating positivity
clauses are negligible, i.e. exp(wi ) (cid:29) exp(−ysrc(β (i)) ) = 1), then we have only valid conﬁgura-
tions left. MTO invalid conﬁgurations are ruled out by Lemma 3. Since the positivity clauses have
large weights, exp(wi ) (cid:29) 1 are usually satisﬁed. Hence RSP, as the sum-product algorithm on the
relaxed MRF, returns estimations of the marginals P (Xi = xi ) as B (σ(i,xi ) = 1).
Valid conﬁgurations have a joint probability with the factor (cid:81)
3.2 Choosing y
a∈F exp(−ya ) while AZ conﬁgura-
marginals satisfying (cid:80)
tions do not. However, Theorem 2 states that, if exp(wi ) (cid:29) 1, AZ conﬁgurations have negligi-
ble probability. Empirically, we observe that for a large range of values of {ya }a∈F , RSP returns
B (σ(i,xi ) = 1) ≈ 1, indicating that AZ conﬁgurations do indeed have
negligible probability. We can hence select the values of {ya }a∈F for better convergence properties.
xi

where

(cid:80)
We describe heuristics based on the sufﬁcient conditions for convergence of sum-product algorithms
in [16]. To simplify notations, we write the conditions for a MRF with pairwise factors Φa ,
(cid:16) 1
(cid:17)(cid:17)
(cid:16) Φa (xi ,xj )
a∈N (j )\b N (Φa ) < 1
maxXj ∈V ,b∈N (j )
Φa (x(cid:48)
i ,x(cid:48)
j )
tanh
supxj (cid:54)=x(cid:48)
N (Φa ) = supxi (cid:54)=x(cid:48)
4 log
Φa (xi ,x(cid:48)
Φa (x(cid:48)
j )
i ,xj )
j
i
Mooij and Kappen [16] have also derived another condition based on the spectral radius of a ma-
trix having N (Φa ) as entries. These conditions lead us to believe that the sum-product algorithm
converges better on MRFs with small N (Φa ) (or the “strengths” of potentials in [8]). To calculate
(cid:26) exp(−ysrc(α) )
N (Ψα ) for the interaction clause α, we characterize these factors as follows:
if clause α is violated, i.e. (σk , σl ) = (0, 0)
As ya are shared among α (cid:64) a, we choose ya to minimize (cid:80)
α(cid:64)a N (Ψα ) = (cid:80)
Ψα ((σk , Pk ), (σl , Pl )) =
(6)
exp(wα )
otherwise
4 |wα+ya |.
α(cid:64)a tanh 1
A good approximation for ya would be the median of {−wα}α(cid:64)a . For our experiments, we divide
the search range for ya into 10 bins, and use fminsearch in Matlab to ﬁnd a local minimum.

(5)

3.3 Update equations and efﬁciency

While each message in RSP has large cardinality, we show in the supplementary material that,
under the settings of Section 3.1, the update equations can be simpliﬁed such that each factor passes
a single number to each variable. The interaction clause α sends a number να→(i,v) to each (i, x) ∈
C (α), and the positivity clauses β (i) sends a number µβ (i)→(i,x) to (i, x) for each x ∈ Q. The
µβ→(i,x) = (cid:88)
(cid:89)
update equations are as follows: (proofs in the supplementary material):
να→(i,x(cid:48) ) + exp(−wi )
µβ (j )→(j,x(cid:48) ) + exp(−ysrc(α) − wα ) (cid:81)
x(cid:48) (cid:54)=x
α∈N (i,x(cid:48) )\β (i)
µβ (j )→(j,x(cid:48) ) + (cid:81)
γ∈N (j,x(cid:48) )\{β (j ),α} νγ→(j,x(cid:48) )
; B (σ(i,x) = 1) ∝ (cid:89)
να→(i,x) =
γ∈N (j,x(cid:48) )\{β (j ),α} νγ→(j,x(cid:48) )
B (σ(i,x) = 0) ∝ µβ (i)→(i,x)
; B (σ(i,x) = ∗) = 0
να→(i,x)
α∈N (i,x)\β (i)

(8)

(7)

(9)

We found empirically that the schedule of message updates affect convergence to a large extent. A
good schedule is to update all the ν -messages ﬁrst (by updating the groups of ν -messages belonging
to each factor a ∈ F together), and then updating the µ-messages together. This seems to work
better than the schedule deﬁned by residual belief propagation [6] on the relaxed MRF.
In terms of efﬁciency, for a MRF with N pairwise factors, the sum-product algorithm has 2N q real
numbers in the factor to variable messages, and RSP has 2N q + q . Empirically, we observe that RSP
on the relaxed MRF runs as fast as the simple sum-product algorithm on the original MRF, with an
overhead for determining the values of y.

4 Experimental Results

While Ising models with attractive couplings are exactly solvable by graph-cut algorithms, general
Ising models with mixed couplings on complete graphs are NP-hard [4], and graph cut algorithms
are not applicable to graphs with mixed couplings [12]. In this section, we perform three sets of
experiments to show that RSP outperforms other approaches: the ﬁrst set compares RSP and the
residual belief propagation on a simple graph, the second set compares the performance of various
methods on randomly generated graphs with mixed couplings, and the third set applies RSP to the
application of the web person disambiguation task.
A simple example: we use a 4-node complete graph of binary variables, with the two sets of factors
deﬁned in Figure 2(a), for  = +1 and -1. The case  = −1 was used in [8] to illustrate how the
strengths of potentials affect convergence of the sum-product algorithm. We also show the case of
 = +1 (an attractive network) as a case where the sum-product algorithm converges well. Both sets
of graphs ( = +1 or −1) have uniform marginals, and 2 MAP conﬁgurations (modes). In Figure

(c)  = −1
(a) 4-node (binary) complete graph
(b)  = +1
Figure 2: In Figure (a), we deﬁne factors under the two settings:  = ±1. Figure (b) and (c) show
the L2 distance between the returned marginals and the nearest mode of the graph. Circles on the
lines mean failure to converge, where we take the marginals at the last iteration.
2(b) and 2(c), we show experimental results for  = +1 and −1. In each case, we vary ω from 0 to
12, and for each ω , run residual belief propagation (RBP) damped at 0.5 and RSP (undamped) on the
corresponding graph. Both methods are randomly initialized. We plot the L2 distance between the
√
returned marginals and the nearest mode marginals (marginals with probability one on the modes).
0.5 ≈ 0.7. For small ω , both methods
The correct marginals are uniform, where the L2 distance is
converge to the correct marginals. As ω is increased, for  = +1 in Figure 2(b), both approaches
converge to marginals with probability 1 on one of the modes. For  = −1, however, RSP converges
again to marginals indicating a mode, while RBP faces convergence problems for ω ≥ 8.
Increasing ω corresponds to increasing N (Ψi,j ), and the sum-product algorithm fails to converge for
large ω when  = −1. When the algorithms converge for large ω , they converge not to the correct
marginals, but to a MAP conﬁguration. Increasing ω has the same effect as decreasing the tem-
perature of a network: the behavior of sum-product algorithm approaches that of the max-product
algorithm, i.e. the max-product algorithm is the sum-product algorithm at the zero temperature limit.
H (s) = − (cid:80)
i,j θi,j si sj − (cid:80)
Ising models with mixed couplings: we conduct experiments on complete graphs of size 20
with different percentage of attractive couplings, using the Ising model with the energy function:
i θi si ,where si∈{−1, 1}. We draw θi from U [0, 0.1]. To control the
percentage of attractive couplings, we draw θi,j from U [0, α], and randomly assign negative signs
to the θi,j with probability (1 − ρ), where ρ is the percentage of attractive couplings required. We
vary α from 1 to 3. In Figure 3, we plot the difference between the optimal energy (obtained with a
brute force search) and the energy returned by each of the following approaches: RSP, max-product
belief propagation (MBP), the convergent tree reweighted max product belief propagation (TRW-S)
[11], residual sum-product belief propagation (RBP) [6], and tree-structured expecation propagation
(TEP) [15]. Each point on the graph is the average over 30 randomly generated networks. In Table
1, we compare RSP against these methods. When an algorithm does not converge, we take its result
at the last iteration. We damp RBP and TEP with a 0.5 damping factor. For RSP, MBP, TRW-S and
RBP, we randomly initialize the initial messages, and take the best result after 5 restarts. For TEP,
we use ﬁve different trees consisting of a maximal spanning tree and four random stars [19]. For
RSP, RBP and TEP, which are variants of the sum product algorithm, we lower the temperature by
a factor of 2 each time the method converges and stop when the method fails to converge or if the
results are not improved over the last temperature. We observe that MBP outperforms TRW-S con-
stantly: this agrees with [11] that MBP outperforms TRW-S for graphs with mixed couplings. While
the performance of TRW-S remains constant from 25% to 75%, the sum-product based algorithms
(RBP and TEP) improve as the percentage of attractive potentials is increased. In all three cases,
RSP is one of the best performing methods, beaten only by TEP at 2 points on the 50% graph. TEP,
being of the class of generalized belief propagation [19], runs signiﬁcantly slower than RSP.
training SV M cluster , they have to minimize E (x) = (cid:80)
Supervised clustering: Finley and Joachims [7] formulated SV M cluster , which learns an item-
pair similarity measure, Sim(i, j ), to minimize a correlation clustering objective on a training set. In
i,j Sim(i, j )δ(xi , xj ) where xi ∈ {1, .., U }
are cluster-ids of item i, and U an upper-bound on the number of clusters. They tried a greedy and
a linear programming approach, and concluded that the two approaches are comparable.
Due to time constraints, we did not implement SV M cluster : instead we test our inference algorithms
on the pairwise classiﬁcation clustering (PCC) baseline in [7]. The PCC baseline trains svmlight [9]
on training item-pairs, and run the classiﬁer through all test pairs. For each test pair (i, j ), we apply
softmax to the classiﬁer outputs to obtain the probability pi,j that the pair is in the same cluster.

Ψi,j(xi,xj)=!exp(Ωi,j/4)ifxi=xjexp(−Ωi,j/4)ifxi"=xjΩ=ω01101100(a) 75%
(b) 50%
(c) 25%
Figure 3: Experiments on the complete graph Ising model with mixed couplings (legend in (a)),
with different percentage of attractive couplings. The y-axis shows, in log scale, the average energy
difference between the conﬁguration found by the algorithm and the optimal solution.
25% attractive
50% attractive
75% attractive
2.5
2
1.5
2.5
2
2.5
2
1.5
13/3
16/0
13/3
10/2
14/0
1/0
0/0
2/0
28/1
30/0
27/0
27/0
29/0
25/0
22/0
24/0
21/0
15/2
16/6
9/1
12/0
2/0
0/0
0/0
16/2
10/2
15/4
6/2
11/2
2/0
0/0
2/0
0/0
0/0
0/1
0/2
0/2
0/10
0/4
0/4

α
mbp
trw-s
rbp
tep
opt

1.5
11/5
29/0
14/2
9/3
0/8

3
15/2
27/0
17/0
15/2
0/2

1
7/6
28/0
22/0
14/3
0/7

3
9/6
28/1
13/5
6/5
0/7

1
20/2
29/0
22/0
23/1
0/6

1
2/0
26/0
1/0
2/0
0/0

3
1/0
25/0
0/0
0/0
0/0

Table 1: Number of trials (out of 30) where RSP does better/worse than various methods. In partic-
ular, the last row (opt) shows the number of times that RSP does worse than the optimal solution.
Deﬁning Sim(i, j ) = log(pi,j /(1 − pi,j )), we minimize E (x) to cluster the test set. We found that
the various inference algorithms perform poorly on the MRF for large U , even when they converge
(probably due to a large number of minima in the approximation). We are able to obtain lower energy
conﬁgurations by the recursive 2-way partitioning procedure in [5] used for graph cuts. (Graph cuts
do not apply here as weights can be negative). This procedure involves recursively running, for e.g.
RSP, on the MRF for E (x) with U = 2, and applying the Kernighan-Lin algorithm [10] for local
reﬁnements among current partitions. Each time RSP returns a conﬁguration that partitions the data,
we run RSP on each of the two partitions. We terminate the recursion when RSP assigns a same
value to all variables, placing all remaining items in one cluster.
We use the web person disambiguation task deﬁned in SemEval-2007 [1] as the test application.
Training data consists of 49 sets of web pages (we use 29 sets with more than 50 documents), where
each set (or domain) are results from a search query on a person name. The test data contains another
30 domains. Each domain is manually annotated into clusters, with each cluster containing pages
referring to a single individual. We use a simple feature ﬁltering approach to select features that
are useful across many domains in the training data. Candidate features include (i) words occurring
in only one document of the document-pair, (ii) words co-ocurring in both documents, (iii) named
entity matches between the documents, and (iv) topic correlation features. For comparison, we
replace RSP with MBP and TRW-S as inference algorithms (we did not run RBP and TEP as they
are very slow on these problems because they often fail to converge). We also implemented the
greedy algorithm (Greedy) in [7]. We tried using the linear programming approach but free off-the-
shelf solvers seem unable to scale to these problems. Results comparing RSP with Greedy, MBP
and TRW-S are shown in Table 2. The F-measure attained by RSP for this SemEval task [1] is
equal to the systems ranked second and third out of 16 participants (ofﬁcial results yet unpublished).
We found that although TRW-S is guaranteed to converge, it performs poorly. RSP converges far
better than MBP, but due to the Kernighan-Lin corrections that we run at each iteration, results can
sometimes be corrected to a large extent by the local reﬁnements.
Method
Number of test domains where RSP attains lower/higher energy E (x) than Method
Percentage of convergence over all runs
F-measure of purity and inverse purity [1]

TRW-S
16/7
100% *
74.61%

RSP
0/0
91%
75.08%

MBP
9/6
74%
74.97%

Greedy
22/5
-
74.78%

Table 2: Results for the web person disambiguation task. (*: TRW-S is guaranteed to converge)
5 Related work and conclusion

In this paper, we formulated RSP, generalizing the formulation of SP-ρ in [14]. SP-ρ is the sum-
product interpretation for the survey propagation (SP) algorithm [3]. SP has been shown to work well

for hard instances of 3-SAT, near the phase transition where local search algorithms fail. However,
its application has been limited to constraint satisfaction problems [3]. In RSP, we took inspiration
from the SP-y algorithm [2] in adding a penalty term for violated clauses. SP-y works on MAX-
SAT problems and SP can be considered as SP-y with y taken to ∞, hence disallowing violated
constraints. This is analogous to the relation between RSP and SP-ρ [14] (See Theorem 1). RSP is
however different from SP-y since we address weighted MAX-SAT problems. Even if all weights
are equal, RSP is still different from SP-y , which, so far, does not have a sum-product formulation on
an alternative MRF. We show that while RSP is the sum-product algorithm on a relaxed MRF, it can
be used for solving the energy minimization problem. By tuning the strengths of the factors (based
on convergence criteria in [16]) while keeping the underlying distribution approximately correct,
RSP converges well even at low temperatures. This enables it to return low-energy conﬁgurations
on MRFs where other methods fail. As far as we know, this is the ﬁrst application of convergence
criteria to aid convergence of belief propagation algorithms, and this mechanism can be used to
exploit future work on sufﬁcient conditions for the convergence of belief propagation algorithms.

Acknowledgments
We would like to thank Yee Fan Tan for his help on the web person disambiguation task, and Tomas
Lozano-Perez and Leslie Pack Kaelbling for valuable comments on the paper. The research is par-
tially supported by ARF grant R-252-000-240-112.

References
[1] “Web person disambiguation task at SemEval,” 2007. [Online]. Available: http://nlp.uned.es/weps/task-
description-2.html
[2] D. Battaglia, M. Kolar, and R. Zecchina, “Minimizing energy below the glass thresholds,” Physical Re-
view E, vol. 70, 2004.
[3] A. Braunstein, M. Mezard, and R. Zecchina, “Survey propagation: An algorithm for satisﬁability,” Ran-
dom Struct. Algorithms, vol. 27, no. 2, 2005.
[4] B. A. Cipra, “The Ising model is NP-complete,” SIAM News, vol. 33, no. 6, 2000.
[5] C. Ding, “Spectral clustering,” ICML ’04 Tutorial, 2004.
[6] G. Elidan, I. McGraw, and D. Koller, “Residual belief propagation: Informed scheduling for asynchronous
message passing,” in UAI, 2006.
[7] T. Finley and T. Joachims, “Supervised clustering with support vector machines,” in ICML, 2005.
[8] T. Heskes, “On the uniqueness of loopy belief propagation ﬁxed points,” Neural Computation, vol. 16,
2004.
[9] T. Joachims, Learning to Classify Text Using Support Vector Machines: Methods, Theory and Algorithms.
Norwell, MA, USA: Kluwer Academic Publishers, 2002.
[10] B. Kernighan and S. Lin, “An efﬁcient heuristic procedure for partitioning graphs,” Bell Systems Techni-
cal Report, 1970.
[11] V. Kolmogorov, “Convergent tree-reweighted message passing for energy minimization,” IEEE Transac-
tions on Pattern Analysis and Machine Intelligence, vol. 28, no. 10, 2006.
[12] V. Kolmogorov and R. Zabih, “What energy functions can be minimized via graph cuts?” IEEE Transac-
tions on Pattern Analysis and Machine Intelligence, vol. 26, no. 2, 2004.
[13] F. Kschischang, B. Frey, and H. Loeliger, “Factor graphs and the sum-product algorithm,” IEEE Transac-
tions on Information Theory, vol. 47, no. 2, 2001.
[14] E. Maneva, E. Mossel, and M. Wainwright, “A new look at survey propagation and its generalizations,”
2004. [Online]. Available: http://arxiv.org/abs/cs.CC/0409012
[15] T. Minka and Y. Qi, “Tree-structured approximations by expectation propagation,” in NIPS, 2004.
[16] J. M. Mooij and H. J. Kappen, “Sufﬁcient conditions for convergence of loopy belief propagation,” in
UAI, 2005.
[17] J. D. Park, “Using weighted MAX-SAT engines to solve MPE,” in AAAI, 2002.
[18] Y. Weiss and W. T. Freeman, “On the optimality of solutions of the max-product belief-propagation algo-
rithm in arbitrary graphs,” IEEE Transactions on Information Theory, vol. 47, no. 2, 2001.
[19] M. Welling, T. Minka, and Y. W. Teh, “Structured region graphs: Morphing EP into GBP,” in UAI, 2005.
[20] J. S. Yedidia, W. T. Freeman, and Y. Weiss, “Constructing free-energy approximations and generalized
belief propagation algorithms,” IEEE Transactions on Information Theory, vol. 51, no. 7, 2005.

