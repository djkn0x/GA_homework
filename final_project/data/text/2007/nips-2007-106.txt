Non-Parametric Modeling of Partially Ranked Data

Guy Lebanon
Department of Statistics, and
School of Elec. and Computer Engineering
Purdue University - West Lafayette, IN
lebanon@stat.purdue.edu

Yi Mao
School of Elec. and Computer Engineering
Purdue University - West Lafayette, IN
ymao@ecn.purdue.edu

Abstract

Statistical models on full and partial rankings of n items are often of limited prac-
tical use for large n due to computational consideration. We explore the use of
non-parametric models for partially ranked data and derive ef(cid:2)cient procedures for
their use for large n. The derivations are largely possible through combinatorial
and algebraic manipulations based on the lattice of partial rankings. In particular,
we demonstrate for the (cid:2)rst time a non-parametric coherent and consistent model
capable of ef(cid:2)ciently aggregating partially ranked data of different types.

1

Introduction

Rankers such as humans, search engines, and classi(cid:2)ers, output full or partial rankings representing
preference relations over n items. The absence of numeric scores or the lack of calibration between
existing numeric scores output by the rankers necessitates modeling rankings rather than numeric
scores. To effectively analyze ranked data, a statistical model has the following desiderata.

(1) Handle ef(cid:2)ciently a very large number of items n by reverting to partial rather than full rankings.
(2) Probability assignment to full and partial rankings should be coherent and contradiction-free.
(3) Conduct inference based on training data consisting of partial rankings of different types.
(4) Correct retrieval of the underlying process as training data increases (statistical consistency).
(5) In the case of large n convergence of the estimator to the underlying process can be extremely
slow for fully ranked data but should be much faster when restricted to simpler partial
rankings.

In this paper, we present a model achieving the above requirements without any parametric assump-
tions on the underlying generative process. The model is based on the non-parametric Parzen win-
dow estimator with a Mallows kernel on permutations. By considering partial rankings as censored
data we are able to de(cid:2)ne the model on both full and partial rankings in a coherent and contradiction-
free manner. Furthermore, we are able to estimate the underlying structure based on data containing
partial rankings of different types. We demonstrate computational ef(cid:2)ciency for partial rankings,
even in the case of a very large n, by exploiting the combinatorial and algebraic structure of the lat-
tice of partial rankings. We start below by reviewing basic concepts concerning partially ranked data
(see [1] for further details) and the Mallows model and then proceed to de(cid:2)ne our non-parametric
estimator. We conclude by demonstrating computational ef(cid:2)ciency and some experiments.

2 Permutations and Cosets

A permutation (cid:25) is a bijective function (cid:25) : f1; : : : ; ng ! f1; : : : ; ng associating with each item
i 2 f1; : : : ; ng a rank (cid:25)(i) 2 f1; : : : ; ng. In other words, (cid:25)(i) denotes the rank given to item i

1

and (cid:25)(cid:0)1 (i) denotes the item assigned to rank i. We denote a permutation (cid:25) using the following
vertical bar notation (cid:25)(cid:0)1 (1)j(cid:25)(cid:0)1 (2)j (cid:1) (cid:1) (cid:1) j(cid:25)(cid:0)1 (n). For example, the permutation (cid:25)(1) = 2; (cid:25)(2) =
3; (cid:25)(3) = 1 would be denoted as 3j1j2. In this notation the numbers correspond to items and the
locations of the items in their corresponding compartments correspond to their ranks. The collection
of all permutations of n items forms the non-Abelian symmetric group of order n, denoted by Sn ,
using function composition as the group operation (cid:25)(cid:27) = (cid:25) (cid:14) (cid:27) . We denote the identity permutation
by e. The concept of inversions and the result below, taken from [7], will be of great use later on.
De(cid:2)nition 1. The inversion set of a permutation (cid:25) is the set of pairs
def
= f(i; j ) : i < j; (cid:25)(i) > (cid:25)(j )g (cid:26) f1; : : : ; ng (cid:2) f1; : : : ; ng

U ((cid:25))

whose cardinality is denoted by i((cid:25))

def
= jU ((cid:25))j.

For example, i(e) = j;j = 0, and i(3j2j1j4) = jf(1; 2); (1; 3); (2; 3)gj = 3.
Proposition 1 (e.g., [7]). The map (cid:25) 7! U ((cid:25)) is a bijection.

When n is large, the enormous number of permutations raises dif(cid:2)culties in using the symmetric
group for modeling rankings. A reasonable solution is achieved by considering partial rankings
which correspond to cosets of the symmetric group. For example, the subgroup of Sn consisting of
all permutations that (cid:2)x the top k positions is denoted S1;:::;1;n(cid:0)k = f(cid:25) 2 Sn : (cid:25)(i) = i; i =
1; : : : ; kg: The right coset S1;:::;1;n(cid:0)k (cid:25) = f(cid:27)(cid:25) : (cid:27) 2 S1;:::;1;n(cid:0)k g is the set of permutations
consistent with the ordering of (cid:25) on the k top-ranked items. It may thus be interpreted as a partial
ranking of the top k items, that does not contain any information concerning the relative ranking of
the bottom n(cid:0)k items. The set of all such partial rankings forms the quotient space Sn =S1;:::;1;n(cid:0)k .
Figure 1 (left) displays the set of permutations that corresponds to a partial ranking of the top 2 out
of 4 items. We generalize this concept to arbitrary partial rankings using the concept of composition.
De(cid:2)nition 2. A composition of n is a sequence (cid:13) = ((cid:13)1 ; : : : ; (cid:13)r ) of positive integers whose sum is n.

Note that in contrast to a partition, in a composition the order of the integers matters. A com-
position (cid:13) = ((cid:13)1 ; : : : ; (cid:13)r ) corresponds to a partial ranking with (cid:13)1 items in the (cid:2)rst position,
(cid:13)2 items in the second position and so on. For such a partial ranking it is known that the (cid:2)rst
set of (cid:13)1 items are to be ranked before the second set of (cid:13)2 items etc., but no further infor-
mation is conveyed about the orderings within each set. The partial ranking S1;:::;1;n(cid:0)k (cid:25) of
the top k items is a special case corresponding to (cid:13) = (1; : : : ; 1; n (cid:0) k). More formally, let
N1 = f1; : : : ; (cid:13)1 g; N2 = f(cid:13)1 + 1; : : : ; (cid:13)1 + (cid:13)2 g; (cid:1) (cid:1) (cid:1) ; Nr = f(cid:13)1 + (cid:1) (cid:1) (cid:1) + (cid:13)r(cid:0)1 + 1; : : : ; ng: Then
the subgroup S(cid:13) contains all permutations (cid:25) for which the set equalities (cid:25)(Ni ) = Ni ; 8i holds (all
permutations that only permute within each Ni ). A partial ranking of type (cid:13) is equivalent to a coset
S(cid:13) (cid:25) = f(cid:27)(cid:25) : (cid:27) 2 S(cid:13) ; (cid:25) 2 Sng and the set of such partial rankings forms the quotient space Sn =S(cid:13) .
The vertical bar notation described above is particularly convenient for denoting partial rankings. We
list items 1; : : : ; n separated by vertical bars, indicating that items on the left side of each vertical
bar are preferred to (ranked higher than) items on the right side of the bar. For example, the partial
ranking displayed in Figure 1 (left) is denoted by 3j1j2; 4. In the notation above, the ordering of
items not separated by a vertical line is meaningless, and for consistency we use the conventional
ordering e.g., 1j2; 3j4 rather than 1j3; 2j4.
The set of all partial rankings

def
(1)
= fS(cid:13) (cid:25) : (cid:25) 2 Sn ; 8(cid:13) g
Wn
which includes all full rankings (cid:25) 2 Sn , is a subset of all possible partial orders on f1; : : : ; ng.
While the formalism of partial rankings in Wn cannot realize all partial orderings, it is suf(cid:2)ciently
powerful to include many useful naturally occurring orderings as special cases. Furthermore, as
demonstrated in later sections, it enables simpli(cid:2)cation of the otherwise overwhelming computa-
tional dif(cid:2)culty. Special cases include the following partial rankings.

(cid:15) (cid:25) 2 Sn corresponds to permutation or a full ordering e.g. 3j2j4j1.
(cid:15) S1;n(cid:0)1(cid:25) e.g. 3j1; 2; 4, corresponds to selection of the top alternative such as a multiclass
classi(cid:2)cation.
(cid:15) S1;:::;1;n(cid:0)k (cid:25) e.g. 1j3j2; 4, corresponds to top k ordering such as the ranked list of top k
webpages output by search engines.

2

(cid:15) Sk;n(cid:0)k (cid:25) e.g. 1; 2; 4j3; 5, corresponds to a more preferred and a less preferred dichotomy
such as a multilabel classi(cid:2)cation.

In the cases above, we often have a situation where n is large (or even approaching in(cid:2)nity as in the
third example above) but k is of manageable size. Traditionally, data from each one of the special
cases above was modeled using different tools and was considered fundamentally different. That
problem was aggravated as different special cases were usually handled by different communities
such as statistics, computer science, and information retrieval.
In constructing a statistical model on permutations or cosets, it is essential to relate one permutation
to another. We do this using a distance function on permutations d : Sn (cid:2) Sn ! R that satis(cid:2)es the
usual metric function properties, and in addition is invariant under item relabeling or right action of
the symmetric group [1] d((cid:25) ; (cid:27)) = d((cid:25)(cid:28) ; (cid:27)(cid:28) ) 8 (cid:25) ; (cid:27); (cid:28) 2 Sn . There have been many propositions
for such right-invariant distance functions, the most popular of them being Kendall’s tau [3]
n(cid:0)1
X
X
i=1
l>i
where I (x) = 1 for x > 0 and I (x) = 0 otherwise. Kendall’s tau d((cid:25) ; (cid:27)) can be interpreted as the
number of pairs of items for which (cid:25) and (cid:27) have opposing orderings (called disconcordant pairs) or
the minimum number of adjacent transpositions needed to bring (cid:25)(cid:0)1 to (cid:27)(cid:0)1 (adjacent transposition
(cid:3)ips a pair of items having adjacent ranks). By right invariance, d((cid:25) ; (cid:27)) = d((cid:25)(cid:27) (cid:0)1 ; e) which, for
Kendall’s tau equals the number of inversions i((cid:25)(cid:27)(cid:0)1 ). This is an important observation that will
allow us to simplify many expressions concerning Kendall’s tau using the theory of permutation
inversions from the combinatorics literature.

I ((cid:25)(cid:27)(cid:0)1 (i) (cid:0) (cid:25)(cid:27)(cid:0)1 (l))

d((cid:25) ; (cid:27)) =

(2)

3 The Mallows Model and its Extension to Partial Rankings

(3)

(4)

The Mallows model [5] is a simple model on permutations based on Kendall’s tau distance using a
location parameter (cid:20) and a spread parameter c (which we often treat as a constant)
p(cid:20) ((cid:25)) = exp ((cid:0)cd((cid:25) ; (cid:20)) (cid:0) log  (c))
(cid:25) ; (cid:20) 2 Sn
c 2 R+ :
The normalization term   doesn’t depend on (cid:20) and has the closed form
 (c) = X
e(cid:0)c d((cid:25) ;(cid:20)) = (1 + e(cid:0)c )(1 + e(cid:0)c + e(cid:0)2c ) (cid:1) (cid:1) (cid:1) (1 + e(cid:0)c + (cid:1) (cid:1) (cid:1) + e(cid:0)(n(cid:0)1)c )
(cid:25)2Sn
as shown by the fact that d((cid:25) ; (cid:27)) = i((cid:25)(cid:27)(cid:0)1 ) and the following proposition.
q i((cid:25)) = Qn(cid:0)1
j=1 Pj
Proposition 2 (e.g., [7]). For q > 0, P(cid:25)2Sn
k=0 qk .
Model (3) has been motivated on axiomatic grounds by Mallows and has been a major focus of
statistical modeling on permutations. A natural extension to partially ranked data is to consider a
partial ranking as censored data equivalent to the set of permutations in its related coset:
def
p(cid:20) ((cid:28) ) =  (cid:0)1 (c) X
= X
(cid:28) 2S(cid:13) (cid:25)
(cid:28) 2S(cid:13) (cid:25)
Fligner and Verducci [2] have shown that in the case of (cid:13) = (1; : : : ; 1; n (cid:0) k) the above summation
has a closed form expression. However, the apparent absence of a closed form formula for more
general partial rankings prevented the widespread use of the above model for large n and encouraged
more ad-hoc and heuristic models [1, 6]. This has become especially noticeable due to a new surge
of interest, especially in the computer science community, in partial ranking models for large n.
The ranking lattice presented next enables extending Fligner and Verducci’s closed form to a more
general setting which is critical to the practicality of our non-parametric estimator.

exp ((cid:0)c d((cid:28) ; (cid:20))) :

p(cid:20) (S(cid:13) (cid:25))

(5)

4 The Ranking Lattice

Partial rankings S(cid:13) (cid:25) relate to each other in a natural way by expressing more general, more speci(cid:2)c
or inconsistent ordering. We de(cid:2)ne below the concepts of partially ordered sets and lattices and then
relate them to partial rankings by considering the set of partial rankings Wn as a lattice. Some of
the de(cid:2)nitions below are taken from [7], where a thorough introduction to posets can be found.

3

1

PSfrag replacements
2
(cid:27)1 (cid:25)
Ranks  
3

1

(cid:25)

(cid:13)
1;2;3

Items:
web pages
movies
labels
etc.

1

2

3

4

2

3

4

PSfrag replacements

S1;1;2 (cid:25) = f(cid:27)1 (cid:25) ; (cid:27)2 (cid:25)g = 3j1j2; 4

4

1

2

3

4

(cid:27)2 (cid:25)

(cid:13)
1j2;3

(cid:13)
1;2j3

(cid:13)
1;3j2

(cid:13)
2j1;3

(cid:13)
3j1;2

(cid:13)
2;3j1

asdf

(cid:13)
1j2j3

(cid:13)
1j3j2

(cid:13)
2j1j3

(cid:13)
3j1j2

(cid:13)
2j3j1

(cid:13)
3j2j1

Figure 1: A partial ranking corresponds to a coset or a set of permutations (left). The Hasse diagram
of W3 . Some lines are dotted for 3D visualization purposes (right).

De(cid:2)nition 3. A partially ordered set or poset (Q; (cid:22)), is a set Q endowed with a binary relation (cid:22)
satisfying 8x; y ; z 2 Q (i) re(cid:3)exibility: x (cid:22) x, (ii) anti-symmetry: x (cid:22) y and y (cid:22) x ) x = y , and
(iii) transitivity: x (cid:22) y and y (cid:22) z ) x (cid:22) z .

We write x (cid:30) y when x (cid:22) y and x 6= y . We say that y covers x when x (cid:30) y and there is no
z 2 Q such that x (cid:30) z (cid:30) y . A (cid:2)nite poset is completely described by its covering relation. The
planar Hasse diagram of (Q; (cid:22)) is the graph connecting the elements of Q as nodes using edges that
correspond to the covering relation. An additional requirement is that if y covers x then y is drawn
higher than x. Two elements x; y are comparable if x (cid:22) y or y (cid:22) x and otherwise are incomparable.
The set of partial rankings Wn de(cid:2)ned in (1) is naturally endowed with the partial order of ranking
re(cid:2)nement i.e. (cid:25) (cid:30) (cid:27) if (cid:25) re(cid:2)nes (cid:27) or alternatively if we can get from (cid:25) to (cid:27) by dropping vertical
lines [4]. Figure 1 (right) shows the Hasse diagram of W3 .
A lower bound z of two elements in a poset x; y satis(cid:2)es z (cid:22) x and z (cid:22) y . The greatest lower
bound of x; y or in(cid:2)mum is a lower bound of x; y that is greater than or equal to any other lower
bound of x; y . In(cid:2)mum, and the analogous concept of supremum are denoted by x ^ y and x _ y
or Vfx1 ; : : : ; xk g and Wfx1 ; : : : ; xk g respectively. Two elements x; y 2 Wn are consistent if there
exists a lower bound in Wn . Note that consistency is a weaker relation than comparability. For
example, 1j2; 3j4 and 1; 2j3; 4 are consistent but incomparable while 1j2; 3j4 and 2j1; 3j4 are both
inconsistent and incomparable. Using the vertical bar notation, two elements are inconsistent iff
there exists two items i; j that appear on opposing sides of a vertical bar in x; y i.e. x = (cid:1) (cid:1) (cid:1) ijj (cid:1) (cid:1) (cid:1)
while y = (cid:1) (cid:1) (cid:1) j ji (cid:1) (cid:1) (cid:1) . A poset for which ^ and _ always exist is called a lattice. Lattices satisfy
many useful combinatorial properties - one of which is that they are completely described by the ^
and _ operations. While the ranking poset is not a lattice, it may be turned into one by augmenting
it with a minimum element ^0.
Proposition 3. The union ~Wn
Proof. Since ~Wn is (cid:2)nite, it is enough to show existence of ^; _ for pairs of elements [7]. We begin
by showing existence of x ^ y . If x; y are inconsistent, there is no lower bound in Wn and therefore
the unique lower bound ^0 is also the in(cid:2)mum x ^ y . If x; y are consistent, their in(cid:2)mum may be
obtained as follows. Since x and y are consistent, we do not have a pair of items i; j appearing
as ijj in x and j ji in y . As a result we can form a lower bound z to x; y by starting with a list of
numbers and adding the vertical bars that are in either x or y , for example for x = 3j1; 2; 5j4 and
y = 3j2j1; 4; 5 we have z = 3j2j1; 5j4. The resulting z 2 Wn , is smaller than x and y since by
construction it contains all preferences (encoded by vertical bars) in x and y . It remains to show
that for every other lower bound z 0 to x and y we have z 0 (cid:22) z . If z 0 is comparable to z , z 0 (cid:22) z
since removing any vertical bar from z results in an element that is not a lower bound. If z 0 is not
comparable to z , then both z ; z 0 contain the vertical bars in x and vertical bars in y possibly with
some additional ones. By construction z contains only the essential vertical bars to make it a lower
bound and hence z 0 (cid:30) z , contradicting the assumption that z ; z 0 are non-comparable. By Proposition
3.3.1 of [7] a poset for which an in(cid:2)mum is always de(cid:2)ned and that has a supremum element is
necessarily a lattice. Since we just proved that ^ always exists for ~Wn and 1; : : : ; n = W ~Wn , the
proof is complete.

def
= Wn [ f^0g of the ranking poset and a minimum element is a lattice.

4

1; : : : ; n

1; : : : ; n

S(cid:13) (cid:25) S(cid:21)(cid:27)

S(cid:13) (cid:25)
S(cid:21)(cid:27)

PSfrag replacements

PSfrag replacements

^0

^0

Figure 2: Censored data in the Hasse diagram of ~Wn corresponding to two partial rankings with
the same (left) and different (right) number of vertical bars. The two big triangles correspond to the
Hasse diagram of Figure 1 (right) with permutations occupying the bottom level.

5 Non-Parametric Models on the Ranking Lattice

The censored data approach to partial ranking described by Equation (5) may be generalized to
arbitrary probability models p on Sn . Extending a probability model p on Sn to ~Wn by de(cid:2)ning it
to be zero on ~Wn n Sn and considering the partial ranking model
g(S(cid:13) (cid:25)) = X
p((cid:27)) = X
(cid:27)2S(cid:13) (cid:25)
(cid:28) (cid:22)S(cid:13) (cid:25)

(cid:28) 2 ~Wn :

p((cid:28) );

(6)

The function g , when restricted to partial rankings of the same type G = fS(cid:13) (cid:25) : (cid:25) 2 Sn g
constitutes a distribution over G. The relationship between p and g may be more elegantly described
through M ¤obius inversion on lattices: for the functions p; g : ~Wn ! [0; 1] de(cid:2)ned above we have
iff p((cid:28) ) = X
g((cid:28) ) = X
(cid:28) 0(cid:22)(cid:28)
(cid:28) 0(cid:22)(cid:28)

g((cid:28) 0 )(cid:22)((cid:28) 0 ; (cid:28) )

(cid:28) ; (cid:28) 0 2 ~Wn

p((cid:28) 0 )

(7)

where (cid:22) : ~Wn (cid:2) ~Wn ! R is the M ¤obius function of the lattice ~Wn [7].
For large n, modeling partial, rather than full rankings is a computational necessity. It is tempting to
construct a statistical model on partial rankings directly without reference to an underlying permuta-
tion model, e.g. [1, 6]. However, doing so may lead to contradicting probabilities in the permutation
level i.e. there exists no distribution p on Sn consistent with the speci(cid:2)ed values of g at g(S(cid:13) (cid:25))
and g(S(cid:21)(cid:27)), (cid:13) 6= (cid:21). Figure 2 illustrates this problem for partial rankings with the same (left) and
different (right) number of vertical bars. Verifying that no contradictions exist involves solving a
lengthy and complicated set of equations. The alternative we present of starting with a permutation
model p : Sn ! R and extending it to g via the M ¤obius inversion is a simple and effective way of
avoiding such lack of coherence.
Identifying partially ranked training data D = fS(cid:13)i (cid:25)i : i = 1; : : : ; mg as censored data, a non-
parametric Parzen window estimator based on the Mallows kernel is

^p((cid:25)) =

m
X
i=1

(cid:25) 2 Sn

^g(S(cid:21)(cid:25)) =

exp((cid:0)cd((cid:25) ; (cid:28) ))

1
m  (c)

1
m  (c)

1
jS(cid:13)i j X
(cid:28) 2S(cid:13)i (cid:25)i
where we used the fact that jS(cid:13)i (cid:25)i j = jS(cid:13)i ej = jS(cid:13)i j, or its censored data extension
m
X
i=1

X
(cid:28) 2S(cid:13)i (cid:25)i
Model (8) and its partial ranking extension (9) satisfy requirement 3 in Section 1 since D contains
partial rankings of possibly different types. Similarly, by the censored data interpretation of partial
rankings, they satisfy requirement 2. Requirement 4 holds as m; c ! 1 by standard properties of
the Parzen window estimator. Requirement 5 holds since ^g in (9) restricted to G = fS(cid:13) (cid:25) : (cid:25) 2 Sn g
becomes a consistent model on a much smaller probability space. Requirement 1 is demonstrated
in the next section by deriving an ef(cid:2)cient computation of (9). In the case of a very large number
of items reverting to partial ranking of type (cid:13) is a crucial element. The coherence between ^p, ^g and

1
jS(cid:13)i j X
(cid:20)2S(cid:21) (cid:25)

S(cid:13) (cid:25) 2 ~Wn :

exp((cid:0)cd((cid:20); (cid:28) ))

(8)

(9)

5

the nature of D are important factors in modeling partially ranked data. In the next section we show
that even for n ! 1 (as is nearly the case for web-search), the required computation is feasible
as it depends only on the complexity of the composition (cid:13) characterizing the data D and the partial
rankings on which ^g is evaluated.
6 Ef(cid:2)cient Computation and Inversion Combinatorics

a(cid:13)
k ((cid:28) )

b(cid:13)
kl ((cid:28) )

a(cid:13)
k ((cid:28) ) +

b(cid:13)
kl ((cid:28) )

k
X
j=1

(cid:13)j (cid:20)

l(cid:0)1
X
j=1

(s; t) : s < t ;

(10)

(11)

8(cid:28) 2 Sn

where

k
X
j=1

(cid:13)j

(s; t) : s < t ;

k(cid:0)1
X
j=1

k(cid:0)1
X
j=1

(cid:13)j < (cid:28) (cid:0)1 (t) (cid:20)

(cid:13)j < (cid:28) (cid:0)1 (t) < (cid:28) (cid:0)1 (s) (cid:20)

9=
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
;
(cid:13)j < (cid:28) (cid:0)1 (s) (cid:20)

Computational ef(cid:2)ciency of the inner summations in Equations (8)-(9) is crucial to the practical
application of the estimators ^p; ^g . By considering how the pairs constituting i((cid:28) ) decompose with
respect to certain cosets we can obtain ef(cid:2)cient computational schemes for (8),(9).
Proposition 4. The following decomposition of i((cid:28) ) with respect to a composition (cid:13) holds
r
r
r
X
X
X
i((cid:28) ) =
l=k+1
k=1
k=1
8<
= (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
def
:
9=
8<
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
= (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
def
;
:
Proof. First note that by the right invariance of Kendall’s tau d((cid:28) ; (cid:27)) = i((cid:28) (cid:27) (cid:0)1 ), we have i((cid:28) ) =
i((cid:28) (cid:0)1 ) and we may decompose i((cid:28) (cid:0)1 ) instead of i((cid:28) ). The set appearing in the de(cid:2)nition of a(cid:13)
k ((cid:28) )
contains all label pairs (s; t) that are inversions of (cid:28) (cid:0)1 and that appear in the k-compartment of the
decomposition (cid:13) . The set appearing in the de(cid:2)nition of b(cid:13)
kl ((cid:28) ) contains label pairs (s; t) that are
inversions of (cid:28) (cid:0)1 and for which s and t appear in the l and k compartments of (cid:13) respectively. Since
any inversion pair appear in either one or two compartments, the decomposition holds.
Decomposition (10) is actually a family of decompositions as it holds for all possible compo-
sitions (cid:13) . For example, i((cid:28) ) = 4 for (cid:28) = 4j1j3j2 2 S4(cid:0)2(cid:25) = 1; 4j2; 3, with inversions
(4; 1); (4; 3); (4; 2); (3; 2) for (cid:28) (cid:0)1 . The (cid:2)rst compartment 1; 4 contains the inversion (4; 1) and so
a(cid:13)
1 ((cid:28) ) = 1. The second compartment 2; 3 contains the inversion (3; 2) and so a(cid:13)
2 ((cid:28) ) = 1. The cross
compartment inversions are (4; 3); (4; 2) making b(cid:13)
12 ((cid:28) ) = 2. The signi(cid:2)cance of (10) is that as we
sum over all representatives of the coset (cid:28) 2 S(cid:13) (cid:25) the cross compartmental inversions b(cid:13)
kl ((cid:28) ) remain
constant while the within-compartmental inversions a(cid:13)
k ((cid:28) ) vary over all possible combinations. This
leads to powerful extensions of Proposition 2 which in turn lead to ef(cid:2)cient computation of (8), (9).
Proposition 5. For (cid:25) 2 Sn , q > 0, and a composition (cid:13) we have
(cid:13)s(cid:0)1
r
Y
Y
s=1
j=1

l=k+1 b(cid:13)
k=1 Pr
q i((cid:28) ) = qPr
kl ((cid:25))

(cid:13)j

:

(12)

j
X
k=0

qk :

l
X
j=1

X
(cid:28) 2S(cid:13) (cid:25)

(13)

Proof.
X
(cid:28) 2S(cid:13) (cid:25)

q i((cid:28) ) = X
(cid:28) 2S(cid:13) (cid:25)

l=k+1 b(cid:13)
l=k+1 b(cid:13)
k=1 a(cid:13)
k=1 Pr
kl ((cid:28) ) = qPr
k=1 Pr
k ((cid:28) )+Pr
qPr
kl ((cid:25)) X
(cid:28) 2S(cid:13) (cid:25)

k=1 a(cid:13)
qPr
k ((cid:28) )

l=k+1 b(cid:13)
k=1 Pr
= qPr
kl ((cid:25))

l=k+1 b(cid:13)
k=1 Pr
q i((cid:28) ) = qPr
kl ((cid:25))

(cid:13)s(cid:0)1
j
r
r
X
Y
Y
X
Y
s=1
s=1
j=1
(cid:28) 2S(cid:13)s
k=0
Above, we used two ideas: (i) disconcordant pairs between two different compartments of the coset
S(cid:13) (cid:25) are invariant under change of the coset representative, and (ii) the number of disconcordant
pairs within a compartment varies over all possible choices enabling the replacement of the summa-
tion by a sum over a lower order symmetric group.
l=k+1 b(cid:13)
An important feature of (13) is that only the (cid:2)rst and relatively simple term qPr
k=1 Pr
kl ((cid:25))
depends on (cid:25) . The remaining terms depend only on the partial ranking type (cid:13) and thus may be
pre-computed and tabulated for ef(cid:2)cient computation. The following two corollaries generalize the
well known Proposition 2 to arbitrary cosets enabling ef(cid:2)cient computation of (8), (9).

qk :

6

(cid:21)(cid:31)(cid:13)
(1; n (cid:0) 1)
(1; (cid:1) (cid:1) (cid:1) ; 1; n (cid:0) k)
(k ; n (cid:0) k)

(1; n (cid:0) 1)
O(1)
O(k)
O(k)

(1; (cid:1) (cid:1) (cid:1) ; 1; n (cid:0) t)
O(1)
O(k + t)
O(k + t)

(t; n (cid:0) t)
O(1)
O(k + t)
O(k + t)

Table 1: Computational complexity for computing Equation (9) for each training example. Notice
the independence of the complexity terms from n.

(cid:20) 2 Sn .

l=k+1 b(cid:13)
k=1 Pr
Corollary 1. P(cid:28) 2S(cid:13) (cid:25) q i((cid:28) (cid:20)) = qPr
s=1 Q(cid:13)s(cid:0)1
j=1 Pj
kl ((cid:25)(cid:20)) Qr
k=0 qk
Proof. Using group theory, it can be shown that the set equality (S(cid:13) (cid:25))(cid:20) = S(cid:13) ((cid:25)(cid:20)) holds. As a
result, P(cid:28) 2S(cid:13) (cid:25) q i((cid:28) (cid:20)) = P(cid:28) 02S(cid:13) ((cid:25)(cid:20)) q i((cid:28) 0 ) . Proposition 5 completes the proof.
Corollary 2. The partial ranking extension corresponding to the Mallows model p(cid:20) is
s=1 Q(cid:13)s(cid:0)1
j=1 Pj
p(cid:20) (S(cid:13) (cid:25)) = Qr
k=0 e(cid:0)kc
Qn(cid:0)1
j=1 Pj
k=0 e(cid:0)kc
Proof. Using Corollary 1 we have
p(cid:20) ((cid:28) ) = P(cid:28) 2S(cid:13) (cid:25) exp((cid:0)c d((cid:28) ; (cid:20)))
p(cid:20) (S(cid:13) (cid:25)) = X
P(cid:28) 2Sn
exp((cid:0)c d((cid:28) ; (cid:20)))
(cid:28) 2S(cid:13) (cid:25)
= P(cid:28) 2S(cid:13) (cid:25) (exp((cid:0)c))i((cid:28) (cid:20)(cid:0)1 )
Qn(cid:0)1
j=1 Pj
k=0 e(cid:0)kc

= P(cid:28) 2S(cid:13) (cid:25) exp((cid:0)c i((cid:28) (cid:20)(cid:0)1 ))
Qn(cid:0)1
j=1 Pj
k=0 e(cid:0)kc
s=1 Q(cid:13)s(cid:0)1
kl ((cid:25)(cid:20)(cid:0)1 ) Qr
j=1 Pj
k=0 e(cid:0)kc
l=k+1 b(cid:13)
k=1 Pr
= e(cid:0)c Pr
Qn(cid:0)1
j=1 Pj
k=0 e(cid:0)kc

l=k+1 b(cid:13)
l=k+1 b(cid:13)
k=1 Pr
kl ((cid:25)(cid:20)(cid:0)1 ) / e(cid:0)c Pr
k=1 Pr
e(cid:0)c Pr
kl ((cid:25)(cid:20)(cid:0)1 )

Despite its daunting appearance, the expression in Corollary 2 can be computed relatively easily. The
fraction does not depend on (cid:25) or (cid:20) and in fact may be considered as a normalization constant that
may be easily pre-computed and tabulated. The remaining term is relatively simple and depends on
the location parameter (cid:20) and the coset representative (cid:25) . Corollary 2 and Proposition 6 below (whose
proof is omitted due to lack of space), provide ef(cid:2)cient computation for the estimators (8), (9). The
complexity of computing (14) and (8), (9) for some popular partial ranking types appears in Table 1.
Proposition 6.

X
(cid:27)2S(cid:21) (cid:25)1

X
(cid:28) 2S(cid:13) (cid:25)2

e(cid:0)c d((cid:27);(cid:28) ) = 0
@ X
(cid:28) 2(cid:25)1 (cid:25)(cid:0)1
2

S(cid:13)

r
Y
k=1

r
Y
l=k+1

kl ((cid:28) )1
e(cid:0)c b(cid:21)
A

0
@

r
Y
s=1

(cid:21)s(cid:0)1
Y
j=1

j
X
k=0

e(cid:0)kc1
A :

(14)

7 Applications

Figure 3 (top left) compares the average test log-likelihood between the Mallows model and the non-
parametric model with different c as a function of training size averaged over 10 cross validations.
We use fully ranked APA election data (rankings are ballots for (cid:2)ve APA presidential candidates),
and during each iteration, 30% of the examples are randomly selected for testing. The parameters
of the Mallows model are estimated by maximum likelihood. The (cid:2)gure illustrates the advantage
of using a non-parametric estimator over the parametric Mallows model given enough training data.
Also note when c increases, the non-parametric model approaches the empirical histogram thus per-
forming worse for small datasets and better for large datasets. To visualize the advantage of the
non-parametric model over the Mallows model we display in Figure 3 (bottom row) their estimated
probabilities by scaling the vertices of the permutation polytope proportionally. The displayed poly-
tope has vertices corresponding to rankings of 4 items and whose edges correspond to an adjacent
transposition (Kendall’s tau distance is the shortest path between two vertices). In this case the four
ranked items are movies no. 357, 1356, 440, 25 from the EachMovie dataset containing rankings
of 1628 movies. Note how the probabilities assigned by the Mallows model (left) form a unimodal
function centered at 2j1j3j4 while the non-parametric estimator (right) discovers the true modes
2j3j1j4 and 4j1j2j3 that were undetected by the Mallows model.

7

Figure 3 (top right) demonstrates modeling partial rankings of a much larger n. We used 10043
rankings from the Jester dataset which contains user rankings of n = 100 jokes. We kept the partial
ranking type of the testing data (cid:2)xed at (5; n (cid:0) 5) and experimented with different censoring of the
training data. The (cid:2)gure illustrates the slower consistency rate for fully ranked training data and the
statistical bene(cid:2)t in censoring full rankings in the training data. This striking statistical advantage
demonstrates the achievement of property 5 in Section 1 and is independent of the computational
advantage obtained from censoring the training data.

d
o
o
h
i
l
e
k
i
l
(cid:127)
g
o
l
 
e
g
a
r
e
v
a

(cid:127)4.65

(cid:127)4.7

(cid:127)4.75

(cid:127)4.8

(cid:127)4.85

(cid:127)4.9

(cid:127)17.5

(cid:127)18

(cid:127)18.5

d
o
o
h
i
l
e
k
i
l
(cid:127)
g
o
l
 
e
g
a
r
e
v
a

 

…

(cid:127)20

(cid:127)40

(cid:127)60

(cid:127)80

mallows
c=1
c=2
c=5

 

 

(k(6),n(cid:127)k(6))
(k(0),n(cid:127)k(0))
(1,1,n(cid:127)2)
(k(8),n(cid:127)k(8))
(1,n(cid:127)1)

(1,1,1,n(cid:127)3)
(1,1,1,1,1,n(cid:127)5)
fully ranked

800

1600

2400
# of samples

2341

3200

4000

 

1000

2000

4000
# of samples

3000

2341

5000

6000

7000

3241

2431

2314

3241

2431

2314

3421

4231

3421

4231

3214

3214

4321

3412

4312

3142

2413

2134

2143

4321

4213

3124

4213

3124

1234

3412

4312

3142

2413

2134

2143

1234

1324

1243

1324

1243

4123

4123

4132

1342

1423

4132

1342

1423

1432

1432

Figure 3: Top row: Average test log-likelihood as a function of the training size: Mallows model vs.
non-parametric model for APA election data (left) and non-parametric model with different partial
ranking types for Jester data (right). Bottom row: Visualizing estimated probabilities for EachMovie
data by permutation polytopes: Mallows model (left) and non-parametric model for c = 2 (right).

8 Discussion
In this paper, we demonstrate for the (cid:2)rst time a non-trivial effective modeling framework satisfying
properties 1-5 in Section 1. The key component is our ability to ef(cid:2)ciently compute (14) for simple
partial ranking types and large n. Table 1 indicates the resulting complexity scales up with complex-
ity of the composition k but is independent of n which is critical for modeling practical situations
of k (cid:28) n partial rankings. Experiments show the statistical advantage of the non-parametric partial
ranking modeling in addition to its computational feasibility.
References
[1] D. E. Critchlow. Metric Methods for Analyzing Partially Ranked Data. Springer, 1986.
[2] M. A. Fligner and J. S. Verducci. Distance based ranking models. Journal of the Royal Statistical Society
B, 43:359(cid:150)369, 1986.
[3] M. G. Kendall. A new measure of rank correlation. Biometrika, 30, 1938.
[4] G. Lebanon and J. Lafferty. Conditional models on the ranking poset. In Advances in Neural Information
Processing Systems, 15, 2003.
[5] C. L. Mallows. Non-null ranking models. Biometrika, 44:114(cid:150)130, 1957.
[6] J. I. Marden. Analyzing and modeling rank data. CRC Press, 1996.
[7] R. P. Stanley. Enumerative Combinatorics, volume 1. Cambridge University Press, 2000.

8

