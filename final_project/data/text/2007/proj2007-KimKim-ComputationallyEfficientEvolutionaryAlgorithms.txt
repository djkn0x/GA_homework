Computationally Ef ﬁcient Evolutionary Algorithms:
Enhanced by On-line Machine Learning

Jong-Han Kim and Taehoon Kim

Abstract — An ef ﬁcient evolutionary optimization algorithm
of which the convergence is improved is proposed. A “ma-
chine” which learns the parameter-cost relations on-line is
implemented inside the evolutionary algorithm, and the ma-
chine reuses the parameter-cost information as training sets to
update the hypothesis functions. As the populations converge
and regression accuracy improves, some portion of the cost
evaluations are substituted with machine-learned regressions,
and they are put into the selection process. This signiﬁcantly
reduces the computational load and running time, because the
training/computation of the machine is much cheaper than
the actual cost function evaluations. Also, this implies that
the effective number of offsprings can be easily increased,
which leads to improved convergence with little increase of the
computational load. The improved convergence is shown by a
simple numerical examples and a practical design problem.

I . IN TRODUC T ION

Evolution-based optimization methods have a number of
advantages over traditional hill-climbing ( e.g., gradient
descent, Newton’s method) techniques. Unlike the gradient-
based methods, evolutionary algorithms can easily escape
from local minima, eventually converging toward the global
minimum. Also, the evolutionary algorithms can be applied
to any type of cost functions, since they do not require the
gradient or any higher order information. For cost functions
with discontinuities or peaky noise components, the gradient
is not always well-deﬁned or computed with poor numerical
accuracy, which frequently results in failure of gradient-
based algorithms[1].
However, evolutionary computation requires numerous
cost function evaluations, which normally yields to heavy
computational burdens. The cost
functions encountered
in practical optimization problems typically involve time-
consuming computations such as numerical integration or
large matrix inversion, therefore frequent evaluation of the
cost function is not desirable. In standard evolutionary algo-
rithms, a population of sample points evolves to select better
individuals based on the ﬁtness measure, by the processes
called selection/reproduction. These processes inherently im-
pose repetitive evaluations of the cost functions within the
previously-visited domains, of which the ranges reduce as
the population evolves toward next generations. However,
conventional evolutionary algorithms use the computed cost

This work was conducted as a term project for CS229 machine learning
class. The authors are grateful to Prof. Min-Jea Tahk at KAIST for his
guidance and discussions on evolutionary algorithms and applications.
J.-H. Kim and T. Kim are with the Department of Aeronau-
tics and Astronautics, Stanford University, CA 94305. {jonghank,
taehoonk}@stanford.edu

information only for the ﬁtness evaluation and dispose of
them without storing.
We claim that this wastefulness can be improved by using
machine learning techniques. A “machine” which learns the
parameter-cost relations is implemented inside the algorithm.
As the algorithm evaluates the cost function repetitively, the
machine reuses those information as training sets to update
the hypothesis functions. Since the region in which the cost
is evaluated contracts around the optimum as the generation
number increases, the regression performance around the
optimum gradually improves as they evolve; i.e., the machine
learns the large-scale macroscopic views of the cost functions
in the early stages of the evolution, and the scale reduces as
the population evolves, eventually achieving a very accurate
approximation around the optimum in the local microscopic
views. As the regression accuracy improves, some portion
of the cost evaluations are substituted with machine-learned
regressions, and will be put into the selection process. This
signi ﬁcantly reduces the computational
load and running
time, because the training/computation of the machine is
much cheaper than the actual cost function evaluations. The
proposed algorithm is ﬁrst shown using a simple numerical
example, then applied to a practical autopilot design opti-
mization problem.

I I . PRO PO S ED SCH EM E

A. Evolutionary Algorithms
Typical evolutionary algorithms ﬁnd optimal solutions by
iterating the following steps.

Conventional Evolutionary Algorithm:
1) Initialization
2) Offspring generation (Nλ )
3) Cost evaluation
4) Fitness evaluation and selection for the next generation
(Nµ + Nλ 7−→ Nµ : number of parents)
5) Check termination condition

where Nµ and Nλ represent the number of parents and
offsprings in each generation. Increasing Nλ typically leads
to rapid convergence in a small number of generations,
however, the computational demands per each generation
increases linearly with Nλ ,
thus actual convergence rate
(convergence per unit
time, or convergence per number
of function evaluations) does not reduce signi ﬁcantly. The
proposed algorithm introduces a way to increase effective
Nλ without increasing the computational load linearly.

Initialize

Weight vectors
wi

Generate Offsprings

Generate Additional Offsprings

Cost Evaluations

Neural Networks

Selection

Terminate?

Initialize

x
1

x
2

1

Weight vector
           v

J

Σ

g(y)

g(y)

g(y)

g(y)

1

Fig. 1.
Computationally efﬁcient evolutionary algorithm (S haded areas
represent the additional processes)

B. Efﬁcient Evolutionary Algorithm
In the proposed algorithm, we add a machine which
learns
the parameter-cost
relations,
and consequently
several additional steps are needed to train it and use
it. Given that
the computational cost
required by the
machine training/computation is much cheaper than the
cost evaluation (a reasonable assumption for practical
optimization problems with complex cost functions),
the
load increased by these extra steps is assumed to be
negligible. The ﬂow chart is shown in Fig. 1.

Efﬁcient Evolutionary Algorithm:
1) Initialization
2) Offspring generation (Nλ )
3) Cost evaluation (and machine training)
4) Additional offspring generation (Nλ′ )
5) Cost evaluation by additional offspring
(by machine computation)
6) Fitness evaluation and selection for the next generation
(Nµ + Nλ + Nλ′ 7−→ Nµ )
7) Check termination condition

C. Multilayer Feedforward Neural Networks
Multilayer feedforward neural networks with a single
hidden layer are implemented to learn and approximate the
parameter-cost relations. The structures are shown in Fig. 2.
· · · g(wT
1 z ) g(wT
J (x) = [ g(wT
Nhu z ) 1 ] v
2 z )
where z = [xT 1]T , x ∈ Rn , wi ∈ Rn+1 , 1 ≤ i ≤ Nhu ,
v ∈ RNhu+1 , and g(y) = 1/(1 + e−y ). Nhu represents the
number of hidden units.
The neural networks are trained on-line as the evolutionary
algorithm evaluates the cost function. The gradient descent
back-propagation algorithm to minimize the error function
1
2 (y (k) − J (k) )2 was used[2].
E = Pk

Fig. 2. Multilayer feedforward neural networks

Output layer update:

δ = − ∂E /∂J (k) = (y (k) − J (k) )
vi := vi + µδg(wT
i z (k) )
vNhu+1 := vNhu+1 + µδ

1 ≤ i ≤ Nhu
µ: learning rate

Input layer update:

ǫi = δvi g ′ (wT
i z (k) ))
wi := wi + ν ǫi z (k)

1 ≤ i ≤ Nhu
ν : learning rate

where the superscript (k) represents the k-th training set.

I I I . NUM ER ICA L EXAM P L E
The proposed optimization scheme is demonstrated in a
simple numerical example.

A. Introductory Example
The ﬁrst example is a single-variable optimization prob-
lem. This function has its global minimum at x∗ = 0,
with f (x∗ ) = 0. Fig 3 shows the function on −10 ≤
x ≤ 10. Since this function has many local minima, any
gradient-based algorithm may not be a good tool for global
optimization.

minimize f (x) = 1 − e−x2 /20 cos(2x)

Approximation performances are shown by snapshots at
several generations, in Fig. 3 (1st generation) and Fig.4 (11th
and 21st generation). In both plots, solid curves are obtained
by using neural networks, and dotted are the actual cost
function curves.
Fig. 5 compares the convergence histories of both con-
ventional and proposed evolutionary algorithms based on 50
runs each. For both of algorithms, Nµ = 10 and Nλ = 30 are
chosen as the evolurionaty algorithm (EA) setup parameters,
and Nλ′ = 30 and Nhu = 10 are chosen additionally for the
proposed algorithm (which effectively doubles the offspring
population). We can observe that the proposed algorithm

2

1.8

1.6

1.4

1.2

J

1

0.8

0.6

0.4

0.2

0
−10

Generation 1

Conventional evolutionary algorithm

100

t
s
o
C

10−5

100

t
s
o
C

10−5

0

20

40

60

80

100

Proposed evolutionary algorithm

−5

0
x

5

10

0

20

40

60

Generation

80

100

Fig. 3. Cost function f (x) = 1 − e−x2 /20 cos(2x)

Fig. 5. Convergence histories of conventional vs. proposed algorithm

Generation 11

Generation 21

2

1.8

1.6

1.4

1.2

J

1

0.8

0.6

0.4

0.2

0
−4

−3

−2

−1

0

1

2

3

x

J

0.09

0.08

0.07

0.06

0.05

0.04

0.03

0.02

0.01

0
−0.1

−0.05

0

0.05

0.1

0.15

0.2

0.25

x

Fig. 4. Snapshots at the 11th and 21st generation

converges earlier than the original algorithm, while some
runs of the original algorithm failed to converge to the global
minimum.
For this toy example, a function evaluation is just com-
puting simple explicit
functions, and does not
require
heavy computational load; it is even cheaper than train-
ing/computing the machine. Therefore, actual time to conver-
gence is increased by applying the new technique. However,
in case of practical problems with time-consuming cost
functions, the proposed algorithm will reduce the actual time
to convergence. We will see this in the next chapter.

IV. A P P L ICAT ION - AU TO P I LOT D E S IGN
A practical autopilot design problem is chosen as the
application problem.

A. F-15 Longitudinal Dynamics
Fig. 7 shows the normal acceleration control loop of an
F-15 ﬁghter.[3] The design parameters are the ampli ﬁer gain
Samp , and the rate gyro gain Srg .

TABLE I
NUM ER ICA L DATA FOR A CRU I S E FL IGH T COND I T ION
h(m)
6,096
U (m/sec)
189.63

CD
0.05
c
Cmq
2U
-0.0512

CL
0.24
CDα
0.35

CLα
4.17
Cmα
-0.29

CLδe
0.4
Cmδe
-0.5

100

10−2

10−4

t
s
o
C

10−6

10−8

10−10

0

Medians based on 50 runs each

Conventional algorithm
Proposed algorithm

20

40

60

Generation

80

100

Fig. 6. Convergence histories (median)

Transfer function

˙θ
δe

=

az
δe

=

mU
S q Cmδe s − Cmδe Czα + Cmα Czδe
  mU Iy
!
(S q)2 c s2 − ( Iy
S qc Czα + mU
c
2U Cmq )s
S q
2U Cmq Czα − mU
+( c
S q Cmα )
Iy
S qc Czδe s2 − c
2U Cmq C zδe s + Cmδe Czα − Cmα Czδe
!
πU   mU Iy
(S q)2 c s2 − ( Iy
S qc Czα + mU
c
2U Cmq )s
180g
S q
+( c
2U Cmq Czα − mU
S q Cmα )

az,cmd

+

-

  Samp

+

+

  10
s+10

Aircraft
Dynamics

az

  .
θ

δe

  Srg

Fig. 7. Normal acceleration control loop for F-15 aircraft

1.2

1

0.8

0.6

0.4

0.2

0

d
m
c
,
z
a
 
/
 
z
a

Cost :
Inbetween area

Reference model
Actual response

−0.2

0

1

2

3

Time

4

5

Fig. 8. Cost function for certain Samp and Srg

=

|az (t) − az ,ref (t)| dt

B. Cost Function
The desired reference model was set by a second order
model with ωn = 2(rad/s) and ζ = 0.9.
ω2
az ,ref
n
s2 + 2ζ ωn s + ω2
az ,cmd
n
The two parameters (Samp and Srg ) are to be optimized so
that the response signal is as close to the reference signal
as possible. For faithful implication of this objective, the
optimization problem is deﬁned as follows[4]. A graphical
interpretation is presented in Fig. 8.
minimize J (Samp , Srg ) = Z tf
ti
C. Improved Convergence
The evolution histories of the parameters by a conventional
algorithm are presented in Fig. 9. Note that some runs failed
to converge to the global optimum, because of the small
offspring population (Nµ = 10 and Nλ = 30). The evolution
by the proposed algorithm (with Nλ′ = 30 and Nhu = 10)
are shown in Fig. 10, where all the trial runs converged to the
correct global optimum. We can observe that the convergence
is signi ﬁcantly improved by the proposed algorithm, with li
t-
tle increase of computational load. For this speci ﬁc proble m,
less than 10% of computational load is additionally required
for neural network training and computation. However this
number depends on the complexity of cost functions, and
will be much smaller for problems with more complicated
cost functions.

V. CONC LU S ION
Computationally efﬁcient evolutionary algorithms are de-
veloped. Neural networks are implemented inside the evolu-
tionary algorithm, learning the parameter-cost relations. On-
line training leads the approximation accuracy to improve as
the populations evolve. Then additional offspring populations
whose cost values are computed by the neural networks
are generated. Because the computational load additionally

p
m
a
S

10

8

6

4

2

0

0

2

1.5

g
r
S

1

0.5

0

0

10

8

6

4

2

0

0

2

1.5

p
m
a
S

g
r
S

1

0.5

0

0

Conventional evolutionary algorithm

10

20

30

40

50

60

70

80

90

100

Conventional evolutionary algorithm

10

20

30

40

50
Generation

60

70

80

90

100

Fig. 9. Evolution histories for a conventional algorithm

Proposed evolutionary algorithm

10

20

30

40

50

60

70

80

90

100

Proposed evolutionary algorithm

10

20

30

40

50
Generation

60

70

80

90

100

Fig. 10. Evolution histories for the proposed algorithm

required for these processes is usually much less than that
required for the actual cost evaluations in practical optimiza-
tion problems, these proceses increase the effective offspring
populations with little increase of computational load.
The proposed algorithm was applied to a numerical ex-
ample and a practical autopilot design problem. It was
demonstrated to improve convergence characteristics with-
out severely increasing computational load, compared to a
conventional algorithm.

R E F ER ENC E S
[1] T.B ¨ack, Evolutionary Algorithms in Theory and Practice, Oxford
University Press, 1996.
[2] S.Haykin, Neural Networks - A Comprehensive Foundation, 2nd ed.,
Prentice Hall, 1999
[3] J.H. Blakelock, Automatic Control of Aircraft and Missiles, 2nd ed.,
Wiley, 1991.
[4] C.S.Park and M.J.Tahk, ”A Co-evolutionary Minimax Solve r and its
Application to Autopilot Design,” Preceeding of AIAA Guidance,
Navigation, and Control Conference, Boston, USA, pp.408-415, Aug.
1998.

