Collective Inference on Markov Models
for Modeling Bird Migration

Daniel Sheldon

M. A. Saleh Elmohamed
Cornell University
Ithaca, NY 14853
{dsheldon,kozen}@cs.cornell.edu
saleh@cam.cornell.edu

Dexter Kozen

Abstract

We investigate a family of inference problems on Markov models, where many
sample paths are drawn from a Markov chain and partial information is revealed
to an observer who attempts to reconstruct the sample paths. We present algo-
rithms and hardness results for several variants of this problem which arise by re-
vealing different information to the observer and imposing different requirements
for the reconstruction of sample paths. Our algorithms are analogous to the clas-
sical Viterbi algorithm for Hidden Markov Models, which ﬁnds the single most
probable sample path given a sequence of observations. Our work is motivated by
an important application in ecology: inferring bird migration paths from a large
database of observations.

1

Introduction

Hidden Markov Models (HMMs) assume a generative model for sequential data whereby a sequence
of states (or sample path) is drawn from a Markov chain in a hidden experiment. Each state generates
an output symbol from alphabet Σ, and these output symbols constitute the data or observations. A
classical problem, solved by the Viterbi algorithm, is to ﬁnd the most probable sample path given
certain observations for a given Markov model. We call this the single path problem; it is well suited
to labeling or tagging a single sequence of data. For example, HMMs have been successfully applied
in speech recognition [1], natural language processing [2], and biological sequencing [3].
We introduce two generalizations of the single path problem for performing collective inference on
Markov models, motivated by an effort to model bird migration patterns using a large database of
static observations. The eBird database hosted by the Cornell Lab of Ornithology contains millions
of bird observations from throughout North America, reported by the general public using the eBird
web application.1 Observations report location, date, species and number of birds observed. The
eBird data set is very rich; the human eye can easily discern migration patterns from animations
showing the observations as they unfold over time on a map of North America.2 However, the
eBird data are static, and they do not explicitly record movement, only the distributions at different
points in time. Conclusions about migration patterns are made by the human observer. Our goal is
to build a mathematical framework to infer dynamic migration models from the static eBird data.
Quantitative migration models are of great scientiﬁc and practical import: for example, this problem
arose out of an interdisciplinary project at Cornell University to model the possible spread of avian
inﬂuenza in North America through wild bird migration.
The migratory behavior for a species of birds can be modeled using a single generative process
that independently governs how individual birds ﬂy between locations, giving rise to the following
1http://ebird.org
2http://www.avianknowledge.net/visualization

1

inference problem: a hidden experiment simultaneously draws many independent sample paths from
a Markov chain, and the observations reveal aggregate information about the collection of sample
paths at each time step, from which the observer attempts to reconstruct the paths. For example, the
eBird data estimate the geographical distribution of a species on successive days, but do not track
individual birds.
We discuss two problems within this framework. In the multiple path problem, we assume that
exactly M independent sample paths are drawn from the Markov model, and the observations reveal
the number of paths that output symbol α at time t, for each α and t. The observer seeks the
most likely collection of paths given the observations. The fractional path problem is a further
generalization in which paths are divisible entities. The observations reveal the fraction of paths that
output symbol α at time t, and the observer’s job is to ﬁnd the most likely (in a sense to be deﬁned
later) weighted collection of paths given the observations. Conceptually, the fractional path problem
can be derived from the multiple path problem by letting M go to inﬁnity; or it has a probabilistic
interpretation in terms of distributions over paths.
After discussing some preliminaries in section 2, sections 3 and 4 present algorithms for the multiple
and fractional path problems, respectively, using network ﬂow techniques on the trellis graph of the
Markov model. The multiple path problem in its most general form is NP-hard, but can be solved
as an integer program. The special case when output symbols uniquely identify their associated
states can be solved efﬁciently as a ﬂow problem; although the single path problem is trivial in this
case, the multiple and fractional path problems remain interesting. The fractional path problem can
be solved by linear programming. We also introduce a practical extension to the fractional path
problem, including slack variables allowing the solution to deviate slightly from potentially noisy
observations. In section 5, we demonstrate our techniques with visualizations for the migration of
Archilochus colubris, the Ruby-throated Hummingbird, devoting some attention to a challenging
problem we have neglected so far: estimating species distributions from eBird observations.
We brieﬂy mention some related work. Caruana et al. [4] and Phillips et al. [5] used machine
learning techniques to model bird distributions from observations and environmental features. For
problems on sequential data, many variants of HMMs have been proposed [3], and recently, con-
ditional random ﬁelds (CRFs) have become a popular alternative [6]. Roth and Yih [7] present an
integer programming inference framework for CRFs that is similar to our problem formulations.

2 Preliminaries

2.1 Data Model and Notation

A Markov model (V , p, Σ, σ) is a Markov chain with state set V and transition probabilities p(u, v)
for all u, v ∈ V . Each state generates a unique output symbol from alphabet Σ, given by the mapping
σ : V → Σ. Although some presentations allow each state to output multiple symbols with different
emission probabilities, we lose no generality assuming that each state emits a unique symbol — to
encode a model where state v output multiple symbols, we simply duplicate v for each symbol and
encode the emission probabilities into the transitions. Of course, σ need not be one-to-one. It is
useful to think of σ as a partition of the states, letting Vα = σ−1 (α) be the set of all states that
output α. We assume each model has a distinguished start state s and output symbol start.
Let Y = V T be the set of all possible sample paths of length T . We represent a path y ∈ Y as a row
vector y = (y1 , . . . , yT ), and a collection of M paths as the M × T matrix Y = (yit ), with each
λ on Y , where λ(y) = QT −1
row yi· representing an independent sample path. The transition probabilities induce a distribution
t=1 p(yt , yt+1 ). We will also consider arbitrary distributions π over Y ,
letting Y = (Y1 , . . . , YT ) denote a random path from π . Then, for example, we write Prπ [Yt = u]
to be the probability under π that the tth state is u, and Eπ [f (Y )] to be the expected value of f (Y )
for any function f of a random path Y drawn from π . Note that Y (boldface) denotes a matrix of
M paths, while Y denotes a random path.

2.2 The Trellis Graph and Viterbi as Shortest Path

To develop our ﬂow-based algorithms, it is instructive to build upon a shortest-path interpretation of
the Viterbi algorithm [7]. In an instance of the single path problem we are given a model (V , p, Σ, σ)

2

(b)
(a)
Figure 1: Trellis graph for Markov model with states {s, u, v , w} and alphabet {start, 0, 1}. States u
and v output the symbol 0, and state w outputs the symbol 1. (a) The bold path is feasible for the speciﬁed
observations, with probability p(s, u)p(u, u)p(u, w). (b) Infeasible edges have been removed (indicated by
light dashed lines), and probabilities changed to costs. The bold path has cost c(s, u) + c(u, u) + c(u, w).

and observations α1 , . . . , αT , and we seek the most probable path y given these observations. We
call path y feasible if σ(yt ) = αt for all t; then we wish to maximize λ(y) over feasible y. The
problem is conveniently illustrated using the trellis graph of the Markov model (Figure 1). Here, the
states are replicated for each time step, and edges connect a state at time t to its possible successors
at time t + 1, labeled with the transition probability. A feasible path must pass through partition
Vαt at step t, so we can prune all edges incident on other partitions, leaving only feasible paths. By
deﬁning the cost of an edge as c(u, v) = − log p(u, v), and letting the path cost c(y) be the sum
of its edge costs, straightforward algebra shows that arg maxy λ(y) = arg miny c(y), i.e., the path
of maximum probability becomes the path of minimum cost under this transformation. Thus the
Viterbi algorithm ﬁnds the shortest feasible path in the trellis using edge lengths c(u, v).

3 Multiple Path Problem

In the multiple path problem, M sample paths are drawn from the model and the observations reveal
the number of paths Nt (α) that output α at time t, for all α and t; or, equivalently, the multiset At
of output symbols at time t. The objective is to ﬁnd the most probable collection Y that is feasible,
meaning it produces multisets A1 , . . . , AT . The probability λ(Y) is just the product of the path-wise
T −1Y
MY
MY
probabilities:
t=1
i=1
i=1
Then the formal speciﬁcation of this problem is
λ(Y) subject to |{i : yi,t ∈ Vα}| = Nt (α) for all α, t.
max
Y

p(yi,t , yi,t+1 ).

(2)

λ(Y) =

λ(yi ) =

(1)

3.1 Reduction to the Single Path Problem

A naive approach to the multiple path problem reduces it to the single path problem by creating a new
Markov model on state set V M where state hv1 , . . . , vM i encodes an entire tuple of original states,
MY
and the transition probabilities are given by the product of the element-wise transition probabilities:
p(hu1 , . . . , uM i, hv1 , . . . , vM i) =
i=1
A state from the product space V M corresponds to an entire column of the matrix Y , and by chang-
ing the order of multiplication in (1), we see that the probability of a path in the new model is equal
to the probability of the entire collection of paths in the old model. To complete the reduction, we
form a new alphabet ˆΣ whose symbols represent multisets of size M on Σ. Then the solution to (2)
can be found by running the Viterbi algorithm to ﬁnd the most likely sequence of states from V M
that produce output symbols (multisets) A1 , . . . , AT . The running time is polynomial in |V M | and
| ˆΣ|, but exponential in M .

p(ui , vi ).

3

p(u,u)p(u,w)p(s,u)uvw01V0V1V0V0V1V10startObservationssc(u,u)c(u,w)c(s,u)uvw01V0V1V0V0V1V10startObservationss3.2 Graph Flow Formulation

(IP)

xt+1
vw

for all v , t,

Can we do better than the naive approach? Viewing the cost of a path as the cost of routing one
unit of ﬂow along that path in the trellis, a minimum cost collection of M paths is equivalent to a
minimum cost ﬂow of M units through the trellis — given M paths, we can route one unit along each
to get a ﬂow, and we can decompose any ﬂow of M units into paths each carrying a single unit of
ﬂow. Thus we can write the optimization problem in (2) as the following ﬂow integer program, with
additional constraints that the ﬂow paths generate the correct observations. The decision variable
min X
uv indicates the ﬂow traveling from u to v at time t; or, the number of sample paths that transition
xt
from u to v at time t.
uv = X
s.t. X
c(u, v)xt
uv
u,v ,t
X
xt
w
u
uv = Nt (α)
xt
u∈Vα ,v∈V
uv ∈ N
for all u, v , t.
xt
The ﬂow conservation constraints (3) are standard: the ﬂow into v at time t is equal to the ﬂow
leaving v at time t + 1. The observation constraints (4) specify that Nt (α) units of ﬂow leave
uv = X
X
uv = X
trellis, by summing over all α,X
partition Vα at time t. These also imply that exactly M units of ﬂow pass through each level of the
xt
xt
u∈Vα ,v∈V
α
α
u,v
Without the observation constraints, IP would be an instance of the minimum-cost ﬂow problem [8],
which is solvable in polynomial time by a variety of algorithms [9]. However, we cannot hope to
encode the observation constraints into the ﬂow framework, due to the following result.
Lemma 1. The multiple path problem is NP-hard.

Nt (α) = M .

for all α, t,

(3)

(4)

The proof of Lemma 1 is by reduction from SET COVER, and is omitted. One may use a general
purpose integer program solver to solve IP directly; this may be efﬁcient in some cases despite the
lack of polynomial time performance guarantees. In the following sections we discuss alternatives
that are efﬁciently solvable.

3.3 An Efﬁcient Special Case

In the special case when σ is one-to-one, the output symbols uniquely identify their generating
states, so we may assume that Σ = V , and the output symbol is always the name of the current state.
To see how the problem IP simpliﬁes, we now have Vu = {u} for all u, so each partition consists of
X
a single state, and the observations completely specify the ﬂow through each node in the trellis:
(40 )
uv = Nt (u)
for all u, t.
xt
v
Substituting the new observation constraints (40 ) for time t + 1 into the RHS of the ﬂow conservation
X
constraints (3) for time t yield the following replacements:
uv = Nt+1 (v)
for all v , t.
xt
u
This gives an equivalent set of constraints, each of which refers only to variables xt
uv for a single
t. Hence the problem can be decomposed into T − 1 disjoint subproblems for t = 1, . . . , T − 1.
The tth subproblem IPt is given in Figure 2(a), and illustrated on the trellis in Figure 2(b). State
u at time t has a supply of Nt (u) units of ﬂow coming from the previous step, and we must route
Nt+1 (v) units of ﬂow to state v at time t + 1, so we place a demand of Nt+1 (v) at the corresponding
node. Then the problem reduces to ﬁnding a minimum cost routing of the supply from time t to meet
the demand at time t + 1, solved separately for all t = 1, . . . , T − 1. The problem IPt an instance
of the transportation problem [10], a special case of the minimum-cost ﬂow problem. There are a
variety of efﬁcient algorithms to solve both problems [8, 9], or one may use a general purpose linear
program (LP) solver; any basic solution to the LP relaxation of IPt is guaranteed to be integral [8].

(30 )

4

(IPt )

min X
s.t. X
c(u, v)xt
uv
u,v
X
u
v

uv = Nt+1 (v)
xt

uv = Nt (u)
xt
uv ∈ N
xt
(a)

(30 )

(40 )

∀v ,

∀u,
∀u, v .

(b)

Figure 2: (a) The deﬁnition of subproblem IPt . (b) Illustration on the trellis.

(RELAX)

xt+1
vw

for all v , t,

4 Fractional Path Problem
In the fractional path problem, a path is a divisible entity. The observations specify qt (α), the
Q
fraction of paths that output α at time t, and the observer chooses π(y) fractional units of each
path y, totaling one unit, such that qt (α) units output α at time t. The objective is to maximize
y∈Y λ(y)π(y) . Put another way, π is a distribution over paths such that Prπ [Yt ∈ Vα ] = qt (α),
i.e., qt speciﬁes the marginal distribution over symbols at time t. By taking the logarithm, an equiv-
alent objective is to maximize Eπ [log λ(Y )], so we seek the distribution π that maximizes the
expected log-probability of a path Y drawn from π . Conceptually, the fractional path problem arises
by letting M → ∞ in the multiple path problem and normalizing to let qt (α) = Nt (α)/M specify
the fraction of paths that output α at time t. Operationally, the fractional path problem is modeled
min X
by the LP relaxation of IP, which routes one splittable unit of ﬂow through the trellis.
uv = X
s.t. X
c(u, v)xt
uv
u,v ,t
X
X
xt
w
u
uv = qt (α)
xt
u∈Vα
v∈V
uv ≥ 0
for all u, v , t.
xt
It is easy to see that a unit ﬂow x corresponds to a probability distribution π . Given any distribution
uv = Prπ [Yt = u, Yt+1 = v ]; then x is a ﬂow because the probability a path enters v at
π , let xt
time t is equal to the probability it leaves v at time t + 1. Conversely, given a unit ﬂow x, any path
decomposition assigning ﬂow π(y) to each y ∈ Y is a probability distribution because the total ﬂow
is one. In general, the decomposition is not unique, but any choice yields a distribution π with the
X
X
uv = X
X
Pr [Yt = u, Yt+1 = v ] = X
same objective value. Furthermore, under this correspondence, x satisﬁes the marginal constraints
(5) if and only if π has the correct marginals:
xt
u∈Vα
v∈V
v∈V
u∈Vα
u∈Vα
uv = X
X
Finally, we can rewrite the objective function in terms of paths:
π(y)c(y) = Eπ [c(Y )] = Eπ [− log λ(Y )] .
c(u, v)xt
y∈Y
u,v ,t
By switching signs and changing from minimization to maximization, we see that RELAX solves
the fractional path problem. This problem is very similar to maximum entropy or minimum cross
entropy modeling, but the details are slightly different: such a model would typically ﬁnd the dis-
tribution π with the correct marginals that minimizes the cross entropy or Kullback-Leibler di-
vergence [11] between λ and π , which, after removing a constant term, reduces to minimizing
Eλ [− log π(Y )]. Like IP, the RELAX problem also decomposes into subproblems in the case when
σ is one-to-one, but this simpliﬁcation is incompatible with the slack variables introduced in the
following section.

Pr [Yt = u] = Pr [Yt ∈ Vα ] .

for all α, t,

(5)

5

041320SupplyDemandtt+1v1v2v3v1v2v3c(v1,v1)Nt(·)Nt+1(·)4.1
Incorporating Slack
In our application, the marginal distributions qt (·) are themselves estimates, and it is useful to allow
the LP to deviate slightly from these marginals to ﬁnd a better overall solution. To accomplish this,
X
X
we add slack variables δ t
u into the marginal constraints (5), and charge for the slack in the objective
function. The new marginal constraints are
(50 )
and we add the term P
uv = qt (α) + δ t
for all α, t,
xt
α
u∈Vα
v∈V
α | into the objective function to charge for the slack, using a standard
α |δ t
α,t γ t
LP trick [8] to model the absolute value term. The slack costs γ t
α can be tailored to individual input
values; for example, one may want to charge more to deviate from a conﬁdent estimate. This will
depend on the speciﬁc application. We also add the necessary constraints to ensure that the new
marginals q 0
t (α) = qt (α) + δ t
α form a valid probability distribution for all t.

5 Demonstration

In this section, we demonstrate our techniques by using the fractional path problem to create visual-
izations showing likely migration routes of Archilochus colubris, the Ruby-throated Hummingbird,
a common bird whose range is relatively well covered by eBird observations. We work in dis-
cretized space and time, dividing the map into grid cells and the year into weeks. We must specify
the Markov model governing transitions between locations (grid cells) in successive weeks; also,
we require estimates qt (·) for the weekly distributions of hummingbirds across locations. Since the
actual eBird observations are highly non-uniform in space and time, estimating weekly distribu-
tions requires signiﬁcant inference for locations with few or no observations. In the appendix, we
outline one approach based on harmonic energy minimization [12], but we may use any technique
that produces weekly distributions qt (u) and slack costs γ t
u . Improving these estimates, say, by
incorporating important side information such as climate and habitat features, could signiﬁcantly
improve the overall model. Finally, although our ﬁnal observations qt (·) are distributions over states
(locations) and not output symbols — i.e., σ is one-to-one — we cannot use the simpliﬁcation from
section 3.3 because we incorporate slack into the model.

5.1

eBird Data

Launched in 2002, eBird is a citizen science project run by the Cornell Lab of Ornithology, lever-
aging the data gathering power of the public. On the eBird website, birdwatchers submit checklists
of birds they observe, indicating a count for each species, along with the location, date, time and
additional information. Our data set consists of the 428,648 complete checklists from 19953 through
2007, meaning the reporter listed all species observed. This means we can infer a count of zero, or
a negative observation, for any species not listed. Using a land cover map from the United States
Geological Survey (USGS), we divide North America into grid cells that are roughly 225 km on a
side. All years of data are aggregated into one, and the year is divided into weeks so t = 1, . . . , 52
represents the week of the year.

5.2 Migration Inference

Given weekly distributions qt (u) and slack costs γ t
u (see the appendix), it remains to specify
the Markov model. We use a simple Gaussian model favoring short ﬂights, letting p(u, v) ∝
exp(−d(u, v)2 /σ2 ), where d(u, v) measures the distance between grid cell centers. This corre-
sponds to a squared distance cost function. To reduce problem size, we omitted variables xt
uv from
the LP when d(u, v) > 1350 km, effectively setting p(u, v) = 0. We also found it useful to impose
u ≤ qt (u) on the slack variables so no single value could increase by more than a
upper bounds δ t
factor of two. Our ﬁnal LP, which was solved using the MOSEK optimization toolbox, had 78,521
constraints and 3,031,116 variables.
Figure 3 displays the migration paths our model inferred for the four weeks starting on the dates
indicated. The top row shows the distribution and paths inferred by the model; grid cells colored
3Users may enter historical observations.

6

Week 10
March 5

Week 20
May 14

Week 30
July 28

Week 40
October 1

Figure 3: Ruby-throated Hummingbird migration. See text for description.

in lighter shades have more birds (higher values for q 0
t (u)). Arrows indicate ﬂight paths (xt
uv )
between the week shown and the following week, with line width proportional to ﬂow xt
uv .
In
the bottom row, the raw data is given for comparison. White dots indicate negative observations;
black squares indicate positive observations, with size proportional to count. Locations with both
positive and negative observations appear a charcoal color. The inferred distributions and paths are
consistent with both seasonal ranges and written accounts of migration routes. For example, in the
summary paragraph on migration from the Archilochus colubris species account in Birds of North
America [13], Robinson et al. write “Many ﬂy across Gulf of Mexico, but many also follow coastal
route. Routes may differ for north- and southbound birds.”

Acknowledgments

We are grateful to Daniel Fink, Wesley Hochachka and Steve Kelling from the Cornell Lab of
Ornithology for useful discussions. This work was supported in part by ONR Grant N00014-01-1-
0968 and by NSF grant CCF-0635028. The views and conclusions herein are those of the authors
and do not necessarily represent the ofﬁcial policies or endorsements of these organizations or the
US Government.

References

[1] L. R. Rabiner. A tutorial on hidden Markov models and selected applications in speech recognition.
Proceedings of the IEEE, 77(2):257–286, 1989.
[2] E. Charniak. Statistical techniques for natural language parsing. AI Magazine, 18(4):33–44, 1997.
[3] R. Durbin, S. Eddy, A. Krogh, and G. Mitchison. Biological sequence analysis: Probabilistic models of
proteins and nucleic acids. Cambridge University Press, 1998.
[4] R. Caruana, M. Elhawary, A. Munson, M. Riedewald, D. Sorokina, D. Fink, W. M. Hochachka, and
S. Kelling. Mining citizen science data to predict prevalence of wild bird species. In SIGKDD, 2006.
[5] S. J. Phillips, M. Dud´ık, and R. E. Schapire. A maximum entropy approach to species distribution mod-
eling. In ICML, 2004.
[6] J. Lafferty, A. McCallum, and F. Pereira. Conditional random ﬁelds: Probabilistic models for segmenting
and labeling sequence data. ICML, 2001.
[7] D. Roth and W. Yih. Integer linear programming inference for conditional random ﬁelds. ICML, 2005.

7

[8] V. Chv ´atal. Linear Programming. W.H. Freeman, New York, NY, 1983.
[9] A. V. Goldberg, S. A. Plotkin, and E. Tardos. Combinatorial algorithms for the generalized circulation
problem. Math. Oper. Res., 16(2):351–381, 1991.
[10] G. B. Dantzig. Application of the simplex method to a transportation problem.
In T. C. Koopmans,
editor, Activity Analysis of Production and Allocation, volume 13 of Cowles Commission for Research in
Economics, pages 359–373. Wiley, 1951.
[11] J. Shore and R. Johnson. Properties of cross-entropy minimization. IEEE Trans. on Information Theory,
27:472–482, 1981.
[12] X. Zhu, Z. Ghahramani, and J. Lafferty. Semi-supervised learning using Gaussian ﬁelds and harmonic
functions. In ICML, 2003.
[13] T. R. Robinson, R. R. Sargent, and M. B. Sargent. Ruby-throated Hummingbird (Archilochus colubris). In
A. Poole and F. Gill, editors, The Birds of North America, number 204. The Academy of Natural Sciences,
Philadelphia, and The American Ornithologists’ Union, Washington, D.C., 1996.
[14] D. Aldous and J. Fill. Reversible Markov Chains and Random Walks on Graphs. Monograph in Prepara-
tion, http://www.stat.berkeley.edu/users/aldous/RWG/book.html.

A Estimating Weekly Distributions from eBird

Our goal is to estimate qt (u), the fraction of birds in grid cell u during week t. Given enough
observations, we can estimate qt (u) using the average number of birds counted per checklist, a
quantity we call the rate rt (u). However, even for a bird with good eBird coverage, there are cells
with few or no observations during some weeks. To ﬁll these gaps, we use the harmonic energy
minimization technique [12] to determine values for empty cells based on neighbors in space and
time. This technique uses a graph-based similarity structure, in our case the 3-dimensional lattice
built on points ut , where ut represents cell u during week t. Edges are weighted, with weights
representing similarity between points. Point ut is connected to its four grid neighbors in time slice
t by edges of unit weight, excluding edges between cells separated by water (speciﬁcally, when the
line connecting the centers is more than half water). Point ut is also connected to points ut−1 and
ut+1 with weight 1/4, to achieve some temporal smoothing.
Harmonic energy minimization learns a function f on the graph; the idea is to match rt (u) on points
with sufﬁcient data and ﬁnd values for other points according to the similarity structure. To this
end, we designate some boundary points for which the value of f is ﬁxed by the data, while other
points are interior points. The value of f at interior point ut is determined by the expected value
of the following random experiment: perform a random walk starting from ut , following outgoing
edges with probability proportional to their weight. When the walk ﬁrst hits a boundary point
vt0 , terminate and accept the boundary value f (vt0 ). In this way, the values at interior points are
a weighted average of nearby boundary values, where “nearness” is interpreted as the absorption
probability in an absorbing random walk. We derive a measure of conﬁdence in the value f (ut )
from the same experiment: let h(ut ) be the expected number of steps for the random walk from ut
to hit the boundary (the hitting time of the boundary set [14]). When h(ut ) is small, ut is close to
the boundary and we are more conﬁdent in f (ut ).
Rather than choosing a threshold on the number of observations required to be a boundary point,
we create a soft boundary by designating all points ut as interior points, and adding one boundary
node to the graph structure for each observation, connected by an edge of unit weight to the cell
in which it occurred, with value equal to the number of birds observed. As point ut gains more
observations, its behavior approaches that of a hard boundary: with probability approaching one, the
walk from ut will reach an observation in the ﬁrst step, so f (ut ) will approach rt (u), the average of
the observations. As a conservative measure, each node is also connected to a sink with boundary
value 0, to prevent values from propagating over very long distances.
in cell u at time t. Finally, we normalize ˆq for each time slice t, taking qt (u) = ˆqt (u)/ P
We compute h and f iteratively using standard techniques. Since f (ut ) approximates the rate rt (u),
we multiply by the land mass of cell u to get an estimate ˆqt (u) for the (relative) number of birds
u ˆqt (u).
u = γ0 /h(ut ) to be inversely proportional to boundary hitting time, with
For slack costs, we set γ t
γ0 ≈ 261 chosen in conjunction with the transition costs in section 5.2 so the average cost for a unit
of slack is the same as moving 600 km.

8

