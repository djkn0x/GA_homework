Face Detection using Independent Component Analysis

Aditya Ra jgarhia
CS 229 Final Pro ject Report

December 14, 2007

1

Introduction

A commonly used approach for detecting faces is based on
the techniques of “boosting” and “cascading”, which allow
for real-time face detection. However, systems based on
boosted cascades have been shown to suﬀer from low de-
tection rates in the later stages of the cascade. Yet, such
face detectors are preferable to other methods due to their
extreme computational eﬃciency.
A given natural image typically contains many more back-
ground patterns than face patterns. In fact, the number of
background patterns may be 1,000 to 100,000 times larger
than the number of face patterns. This means that if one de-
sires a high face detection rate, combined with a low number
of false detections in an image, one needs a very speciﬁc clas-
siﬁer. Publications in the ﬁeld often use the rough guideline
that a classiﬁer should yield a 90% detection rate, combined
with a false-positive rate in the order of 10−6 .
In this pro ject we introduce a novel variation of the boost-
ing process that uses features extracted by Independent
Component Analysis (ICA), which is a statistical technique
that reveals the hidden factors that underlie sets of ran-
dom variables or signals. The information describing a face
may be contained in both linear as well as high-order de-
pendencies among the image pixels. These high-order de-
pendencies can be captured eﬀectively by representation in
ICA space [Barlow, 1989]. Moreover, it has been argued
in [Bartlett and Movellan, 2002] that the metric induced by
ICA is superior to other methods in the sense that it may
provide a representation that is more robust to the eﬀect of
noise such as variations in lightening. We propose that fea-
tures extracted from such a representation may be boosted
better in the later stages of the cascade, thus leading to im-
proved detection rates while maintaining comparable speed.

2 Robust Real-Time Face Detec-
tion

from a very large set of potential features. The third contri-
bution is a method for combining classiﬁers in a “cascade”
which allows background regions of the image to be quickly
discarded while spending more computation on promising
face-like regions.

2.1 Features
The detection procedure classiﬁes images based on the value
of simple features, as opposed to using the image pixels di-
rectly. The most common reason for doing so is that features
can act to encode ad-hoc domain knowledge that is diﬃcult
to learn using a ﬁnite quantity of training data. For this
system, there is also a second critical motivation for fea-
tures: the feature-based system operates much faster than
a pixel based system. The task is to ﬁnd suitable features
for detecting ob jects in images.
Viola and Jones use three kinds of features. The value of a
two-rectangle feature is the diﬀerence between the sum of the
pixels within the two rectangular regions. A three-rectangle
feature computes the sum within two outside rectangles sub-
tracted from the sum in a center rectangle. Finally, a four-
rectangle feature computes the diﬀerence between diagonal
pairs of rectangles.

2.2
Integral Image
Rectangle features can be computed very rapidly using an
intermediate representation for the image that is called the
integral image. The integral image at location x, y contains
ii(x, y) = X
the sum of the pixels above and to the left of x, y inclusive:
i(x0 , y 0 ),
x0≤x,y 0≤y
where ii(x, y) is the integral image and i(x, y) is the original
image. Using the following pair of recurrences:
s(x, y) = s(x, y − 1) + i(x, y)

[Viola and Jones, 2001] described a face detection frame-
work that is capable of processing images extremely rapidly
while achieving high detection rates. There are three key
contributions of this detection framework. The ﬁrst is the
introduction of a new image representation called the “Inte-
gral Image” which allows the features used by the detector
to be computed very quickly. The second is a simple and
eﬃcient classiﬁer which is built using the AdaBoost learning
algorithm to select a small number of critical visual features

ii(x, y) = ii(x − 1, y) + s(x, y)
(where s(x, y) is the cumulative row sum, s(x, −1) = 0, and
ii(−1, y) = 0) the integral image can be computed in one
pass over the original image. Using the integral image, any
rectangular sum can be calculated in four array references.
Clearly the diﬀerence between two rectangular sums can be
calculated in eight references. Since the two-rectangle fea-
tures deﬁned above involve adjacent rectangular sums they

1

can be computed in six array references, and eight and nine
references in the cases of three and four-rectangle features
respectively.

that within any single image, an overwhelming ma jority of
sub-windows are negative.

2.3 Learning Classiﬁcation Functions

There are 160,000 rectangle features associated with each
image sub-window of 24 x 24 pixels, a number far larger
than the number of pixels. Even though each feature can
be computed eﬃciently, computing the complete set is pro-
hibitively expensive. The hypothesis is that a very small
number of these features can be combined to form an eﬀec-
tive classiﬁer. The main challenge, then, is to ﬁnd these fea-
tures. In this system, a variant of AdaBoost is used to select
the features and to train the classiﬁer. The formal guaran-
tees provided by the AdaBoost learning procedure are quite
strong. It has been proved in [Freund and Schapire, 1996]
that the training error of the strong classiﬁer approaches
zero exponentially in the number of rounds. More impor-
tantly, a number of results were later proved about general-
ization performance.
Drawing an analogy between weak classiﬁers and features,
AdaBoost is an eﬀective procedure for searching out a small
number of good “features” which nevertheless have signiﬁ-
cant variety. In support of this goal, the weak learning algo-
rithm is designed to select the single rectangle feature which
best separates the positive and negative examples. For each
feature, the weak learner describes the optimal threshold
classiﬁcation function, such that the minimum number of ex-
amples are misclassiﬁed. A weak classiﬁer h(x, f , p, θ) thus
consists of a feature (f ), a 24 x 24 pixel sub-window of the
image (x), a threshold (θ) and a polarity (p) indicating the
direction of the inequality:
(
1
if pf (x) < pθ
0 otherwise

h(x, f , p, θ) =

The weak classiﬁers used (thresholded single features) can
thus be viewed as single node decision trees, and the ﬁnal
strong classiﬁer takes the form of a perceptron (a weighted
combination of weak classiﬁers followed by a threshold).

2.4 The Attentional Cascade

A cascade of classiﬁers is used, which achieves increased
detection performance while radically reducing computation
time. Simpler classiﬁers are used to reject the ma jority of
sub-windows before more complex classiﬁers are called upon
to achieve low false positive rates.
Stages in the cascade are constructed by training clas-
siﬁers using AdaBoost. The overall form of the detection
process is that of a degenerate decision tree, or cascade. A
positive result from the ﬁrst classiﬁer triggers the evaluation
of a second classiﬁer which has also been adjusted to achieve
very high detection rates. A positive result from the second
classiﬁer triggers a third classiﬁer, and so on. A negative
outcome at any point leads to immediate rejection of the
sub-window. The structure of the cascade reﬂects the fact

Figure 1: Schematic depiction of the attention cascade.

3 Boosting in ICA Feature Space

In Sec. 2.3, we described the boosting process in Haar-like
feature space. The classiﬁcation power of the described sys-
tem is limited when the weak classiﬁers derived from simple
local features become too weak to be boosted, especially
in the later stages of the cascade training. Empirically,
it has been observed in [Zhang, Li and Gatica-Perez, 2004]
that when the discriminating power of a strong classiﬁer
reaches a certain point, e.g. a detection rate of 90% and
a false alarm rate of 10−6 , non-face examples become very
similar to the face examples in terms of the Haar-like fea-
tures. The histograms of the face and non-face examples for
any feature can barely be diﬀerentiated, and the empirical
probability of misclassiﬁcation for the weak classiﬁers ap-
proaches 50%. At this stage, boosting becomes ineﬀective
because the weak learners are too weak to be boosted. This
issue has been discussed in the past in [Valiant, 1984]. One
way to address this problem is to use better weaker clas-
siﬁers in a diﬀerent feature space, which is more powerful.
We propose to boost in ICA coeﬃcient space. As we show,
weak classiﬁers in this global feature space have suﬃcient
classiﬁcation power for boosting to be eﬀective in the later
stages of the cascade.
First, we shall explicate the two architectures for perform-
ing ICA for representing faces.

3.1 Architecture 1: Statistically Indepen-
dent Basis Images
The goal here is to ﬁnd a set of statistically independent
basis images. We organize the face mixtures in matrix x so
that the images are in rows and the pixels are in columns.
In this approach, ICA ﬁnds a matrix W such that the rows
of u = Wx are as statistically independent as possible. The
source images estimated by the rows of u are then used as
basis images to represent faces. Face image representation
consists of the coordinates of these images with respect to
the image basis deﬁned by the rows of u, as shown in Fig.
3. These coordinates are contained in the mixing matrix
A =W−1 .
The number of IC’s found by the FastICA algorithm (de-
scribe in [Hyvarinen, 1999]) corresponds to the dimension-
ality of the input. In order to have control over the number

2

Figure 5: The factorial code representation consisted of the
independent coeﬃcients, u, for the linear combination of
basis images in A that comprised each face image x.

codes for encoding complex ob jects that are characterized
by high-order combinations of features.
We organize the data matrix x such that rows represent
diﬀerent pixels and columns represent diﬀerent images. This
corresponds to treating the columns of A =W−1 as a set of
basis images (see Fig. 4). The ICA representations are then
in the columns of u = Wx. Each column of u contains the
coeﬃcients of the basis images in A for reconstructing each
image in x (see Fig. 5). ICA attempts to make the outputs,
u, as independent as possible.

4 Boosting ICA Features

In AdaBoost learning, each weak classiﬁer is constructed
based on the histogram of a single feature derived from ICA
coeﬃcients (b1 , b2 , ..., bm ). At each round of boosting, one
ICA coeﬃcient, the one which is most eﬀective for discrimi-
nating between face and non-face classes, is selected by Ad-
aBoost.
As stated earlier, the distributions of the two classes in
the Haar-like feature space almost completely overlap in the
later stages of the cascade training. In that case, we pro-
pose to switch feature spaces and construct weak features in
the ICA space. We do need to address the question of which
stage in the cascade we should switch from the Haar-like fea-
tures to the ICA features. It is quite evident that ICA fea-
tures are much more computationally expensive than Haar-
like features. Now, if we used ICA features in early stages
of boosting, we would have to extract ICA features from
a very large number of sub-windows, and the speed of the
face detection system would be too slow for real-time per-
formance. On the other hand, if we used ICA features in
very late stages of boosting, the performance improvement
gained from their superiority would be limited. Therefore,
we shall determine the switching stage based on the trade
oﬀ between speed and performance improvement.

5 Experimental Results

First, we provide the implementation details for our system.
The discussion includes details on the structure and training
of the detector, as well as results on large real-world testing
sets. We also consider the importance the size and quality of
the training data set towards creating an accurate classiﬁer,
and present results for two training sets of diﬀerent sizes.
Due to time limitations, we were unable to train a cascade of

Figure 2: Image synthesis model for Architecture I.

Figure 3: The independent basis image representation con-
sists of the coeﬃcients, b, for the linear combination of in-
dependent basis images, u, that comprised each face image
x.

of ICs extracted, instead of performing ICA directly on the
nr original images, we perform ICA on ﬁrst m PC eigenvec-
tors of the images set, where m < nr . Recall that the ICA
model assumes that the images in x are a linear combina-
tion of a set of unknown statistically independent sources.
Thus, the ICA model is unaﬀected by replacing the original
images with a linear combination of those images.

3.2 Architecture II: A Factorial Face Code
The goal in Architecture 1 was to ﬁnd a set of spatially inde-
pendent basis images. Now, although the basis images ob-
tained in that architecture are approximately independent,
the coeﬃcients that code each feature are not necessarily in-
dependent. Architecture II uses ICA to ﬁnd a representation
in which the coeﬃcients used to code images are statisti-
cally independent, i.e., a factorial face code. [Barlow, 1989]
and [Atick, 1992] have discussed the advantages of factorial

Figure 4: Image synthesis model for Architecture II.

3

Figure 6: Example face images from the training set.

classiﬁers. However, we did implement separate AdaBoost
classiﬁers based on Haar and ICA features.

Figure 7: Example face images from the testing set.

5.1 Training Datasets

Figure 8: Example non-face images from the testing set.

The training data set we used is the the publicly available
MIT-CBCL face database. This data set is not ideal for the
purpose of training a classiﬁer due a low resolution of 19
x 19 pixels. In fact, [Viola and Jones, 2001] report that an
increased resolution of 24 x 24 pixels results in much higher
accuracy of the face detector. However, the data set will
serve our purpose of comparing our detection system with
their original system, which we shall train using the same
training set.
The original MIT-CBCL training set contains 2,429 face
images and 4,548 non-face images in 19 x 19 grayscale PGM
format images. The training faces are only roughly aligned,
i.e., they were cropped manually around each face just above
the eyebrows and about half-way between the mouth and
the chin.
We also created an extended version of the MIT-CBCL
data set by randomly mirroring, rotating, translating and
scaling the original images by small amounts to obtain a
set of 17,495 faces and 113,939 non-face images. Although
the additional images are just variants of the original ones,
the performance of the classiﬁer is aﬀected signiﬁcantly, as
shown subsequently.
All face and non-face images in the training set were his-
togram equalized to increase the local contrasts of the im-
ages. This allows for areas of lower local contrast to gain a
higher contrast without aﬀecting the global contrast.

extended training set of 17,495 faces and 113,939 non-faces
was similarly pro jected onto the ICA basis extracted from
the 2,249 face images to produce another strong classiﬁer.
While experimenting with diﬀerent numbers of faces from
which we extract the ICA features, we found that larger
numbers of faces result in better performance of the detec-
tor. However, extracting the independent components is
a very memory-intensive task, and our memory limitations
did not allow us to use more than 5,000 images. In the fu-
ture, we would like to use the 17,495 face images from the
extended training set to extract the ICA features as opposed
to just pro jecting them onto the basis extracted using less
features.
During testing, a given image is similarly pro jected on the
above-mentioned ICA features to obtain the ICA coeﬃcients
for that image. The AdaBoost classiﬁer then uses these
coeﬃcients to predict the class of the test image.
For training the H-Boost system, we ﬁrst created the in-
tegral image representation for the training set, and then
performed AdaBoost on the Haar-like features that are ob-
tained using this integral image. We were unable to train
the Haar classiﬁer on the extended data set due to memory
limitations.

5.2

ICA and Haar Features

5.3 Experiments on Real-World Test Sets

Two face detection systems were trained: One using Haar
features (we call this H-Boost ) and the other using Archi-
tecture I ICA features (we call this I-Boost ). We trained
both types of classiﬁers with several diﬀerent numbers of
features ranging from 50 features to 350 features.
In the
following sections, we shall present the results for H-Boost
and I-Boost classiﬁers trained using 200 Haar-like and ICA
features respectively, since this choice resulted in the highest
detection rates.
For training the I-Boost system, we ﬁrst extracted the
ICA features from the 2,429 face images in the MIT-CBCL
training set. Next, all the 2,429 face images and the 4,548
non-face images from the training set were pro jected onto
the set of ICA features to obtain the ICA coeﬃcients of these
images. AdaBoost was performed on the coeﬃcients of these
6,977 training images to produce the strong classiﬁer. The

A number of experiments were performed to evaluate the
system. We tested our system on the MIT-CBCL face test
set, which consists of 472 faces and 23,573 non-faces. The
testing images are of the same size as the training images,
and are also cropped similarly. Considerable pose and light-
ning variations are represented by the test set, as can be
seen in Fig. 8. The test face images are clearly more chal-
lenging to identify as compared to the training ones seen in
Fig. 6, even for a human.
Fig. 9 shows the performance of our detection system
(I-Boost) as well as that of a detector based on Haar-like
features (H-Boost). Note that the H-Boost detector used
is not the same as the Viola-Jones detector, since it is not
cascaded. Clearly, the I-Boost detector performs better than
H-Boost for all false positive rates. Moreover, using the
extended training set signiﬁcantly improves the accuracy.

4

Figure 9: Detection rates for various numbers of false positives on the MIT-CBCL test set containing 472 faces and 23,573
non-faces.

6 Conclusions

In this pro ject we introduced a novel algorithm for detecting
faces, based on features derived from Independent Compo-
nent Analysis. Motivated by the fact that the weak learners
based on the simple Haar-like features are too weak in the
later stages of the cascade, we propose to boost ICA fea-
tures in the later stages. The global ICA feature space com-
plements the local Haar-like feature space. The algorithm
selects the most eﬀective features from ICA features using
AdaBoost.
Various experiments were performed to show the advan-
tage of using ICA features for face detection. The results
can be stated as follows:
• ICA features are better at discriminating between face
and non-face images as compared to Haar-like features.
• Increasing the size of the training set as well as the
size of images for ICA feature extraction signiﬁcantly
improves the detection rate for a given false positive
rate.

Although we have not yet implemented the cascaded de-
tector, the results from the AdaBoost classiﬁer show that
our system achieves high accuracy on the MIT-CBCL test
set. Most importantly, though, we have showed that ICA
features are, in fact, better than Haar-like features at dis-
criminating between faces and non-faces. Hence, we are
optimistic that a cascaded detections system which com-
bines Haar-like and ICA features would demonstrate higher
accuracy than a detector based only on Haar-like features.
The computational eﬃciency of FastICA, coupled with the
fact that the ma jority of images are rejected in the early
stages of the cascade, should ensure that performance is not
aﬀected ostensibly.

7 Future Work

A larger training set would be essential for the detector to
be of practical use. In particular, the number of non-face
images would have to be drastically increased in order to
decrease false positives. Moreover, as mentioned earlier, us-
ing a larger number of face images to extract ICA features
would also improve the accuracy.

5

Implementing the cascade is required in order to achieve
the ultimate aim of our work, i.e., to improve the accuracy
of the Viola-Jones detector while maintaining real-time de-
tection speed. We would also like to compare our system
with other state-of-the-art detection systems such as those
based on Neural Networks and Support Vector Machines.
It was mentioned in Sec. 5.2 that we have used the Ar-
chitecture I ICA features in the I-Boost classiﬁer. Another
task in the future would be to implement Architecture II
features as described in Sec. 3.2 and to compare the results.

References

P. Viola and M. Jones. Robust Real-time Ob ject Detection.
In International Journal of Computer Vision, pages 137-
154, 2001.

H.B. Barlow. Unsupervised learning. In Neural Computa-
tion, page 295-311, 1989.

M.S. Bartlett, J.R. Movellan, T.J. Sejnowski. Face Recog-
nition by Independent Component Analysis. In IEEE
Trans. on Neural Networks, pages 1450-1464, November
2002.

Y. Freund and R. E. Schapire. Experiments with a new
boosting algorithm. In Machine Learning: Proceedings of
the Thirteenth International Conference, pages 148-156,
1996.

A. Hyvarinen. Fast and Robust Fixed-Point Algorithms for
Independent Component Analysis. In IEEE Transactions
on Neural Networks, pages 626-634, 1999.

D. Zhang, S. Z. Li, and D. Gatica-Perez. Real-Time Face
Detection Using Boosting Learning in Hierarchical Feature
Spaces. In Proceedings of International Conference on Pat-
tern Recognition, Cambridge, August 2004.

L. Valiant. A Theory of the Learnable. In Communications
of ACM, 1984.

J.J. Atick. Could information theory provide an ecological
theory of sensory processing? In Network, page 213-251,
1992.

