Predicting Brain States from fMRI Data:
Incremental Functional Principal Component
Regression

S. Ghebreab
ISLA/HCS lab, Informatics Institute
University of Amsterdam, The Netherlands
ghebreab@science.uva.nl

A.W.M. Smeulders
ISLA lab, Informatics Institute
University of Amsterdam, The Netherlands
smeulders@science.uva.nl

P. Adriaans
HCS lab, Informatics Institute
University of Amsterdam, The Netherlands
pietera@science.uva.nl

Abstract

We propose a method for reconstruction of human brain states directly from func-
tional neuroimaging data. The method extends the traditional multivariate re-
gression analysis of discretized fMRI data to the domain of stochastic functional
measurements, facilitating evaluation of brain responses to complex stimuli and
boosting the power of functional imaging. The method searches for sets of voxel
time courses that optimize a multivariate functional linear model in terms of R2 -
statistic. Population based incremental learning is used to identify spatially dis-
tributed brain responses to complex stimuli without attempting to localize func-
tion ﬁrst. Variation in hemodynamic lag across brain areas a nd among subjects
is taken into account by voxel-wise non-linear registration of stimulus pattern to
fMRI data. Application of the method on an international test benchmark for
prediction of naturalistic stimuli from new and unknown fMRI data shows that
the method successfully uncovers spatially distributed parts of the brain that are
highly predictive of a given stimulus.

1

Introduction

To arrive at a better understanding of human brain function, functional neuroimaging traditionally
studies the brain’s responses to controlled stimuli. Controlled stimuli have the beneﬁt of leading to
clear and often localized response signals in fMRI as they are speci ﬁcally designed to a ﬀect only
certain brain functions. The drawback of controlled stimuli is that they are a reduction of reality: one
cannot be certain whether the response is due to the reduction or due to the stimulus. Naturalistic
stimuli open the possibility to avoid the question whether the response is due to the reduction or
the signal. Naturalistic stimuli, however, carry a high information content in their spatio-temporal
structure that is likely to instigate complex brain states. The immediate consequence hereof is that
one faces the task of isolating relevant responses amids complex patterns.

To reveal brain responses to naturalistic stimuli, advanced signal processing methods are required
that go beyond conventional mass univariate data analysis. Univariate techniques generally lack
suﬃcient power to capture the spatially distributed response of the brain to naturalistic stimuli. Mul-
tivariate pattern techniques, on the other hand, have the capacity to identify patterns of information
when they are present across the full spatial extent of the brain without attempting to localize func-

tion. Here, we propose a multivariate pattern analysis approach for predicting naturalistic stimuli
on the basis of fMRI data. Inverting the task from correlating stimuli with fMRI data to predicting
stimuli from fMRI data makes it easier to evaluate brain responses to naturalistic stimuli and may
extend the power of functional imaging substantially [1].

Various multivariate approaches for reconstruction of brain states directly from fMRI measurements
have recently been proposed. In most of these approaches, a classi ﬁer is trained directly on the fMRI
data to discriminate between known diﬀerent brain states. This classi ﬁer is then used to predict br ain
states on the basis of new and unknown fMRI data alone. Such approaches have been used to predict
what percept is dominant in a binocular rivalry protocol [2], what the orientation is of structures sub-
jects are viewing [3] and what the semantic category is of objects [4] and words [5] subjects see on
a screen. In one competition [6], participants trained pattern analyzers on fMRI of subjects viewing
two short movies as well as on the subject’s movie feature ratings. Then participants employed the
analyzers to predict the experience of subjects watching a third movie based purely on fMRI data.
Very accurate predictions were reported for identifying the presence of speci ﬁc time varying movie
features (e.g. faces, motion) and the observers who coded the movies [7].

We propose an incremental multivariate linear modeling approach for functional covariates, i.e.
where both the fMRI data and external stimuli are continuous. This approach diﬀers fundamentally
from existing multivariate linear approaches (e.g. [8]) that instantly ﬁt a given model to the data
within the linear framework under the assumption that both the data and the model are discrete.
Contemporary neuroimaging studies increasingly use high-resolution fMRI to accurately capture
continuous brain processes, frequently instigated by continuous stimulations. Hence, we propose
the use of functional data analysis [9], which treats data, or the processes giving rise to them, as
functions. This not only allows to overcome limitations in neuroimaing studies due to the large
number of data points compared to the number of samples, but also allows to exploit the fact that
functions deﬁned on a speci ﬁc domain form an inner product ve
ctor space, and in most circum-
stances can be treated algebraically like vectors [10].

We extend classical multivariate regression analysis of fMRI data [11] to stochastic functional mea-
surements. We show that, cast into an incremental pattern searching framework, functional multi-
variate regression provides a powerful technique for fMRI-based prediction of naturalistic stimuli.

2 Method

In the remainder, we consider stimuli data and data produced by fMRI scanners as continuous func-
tions of time, sampled at the scan interval and subject to observational noise. We treat the data
within a functional linear model where both the predictant and predictor are functional, but where
the design matrix that takes care of the linear mapping between the two is vectorial.

2.1 The Predictor

The predictor data are derived directly from the four-dimensional fMRI data I (x, t), where x ∈ ℜ3
denotes the spatial position of a voxel and t denotes its temporal position. We represent each of
the S voxel time courses in functional form by f s (t), with t denoting the continuous path parameter
and s = 1, ..., S . Rather than directly using voxel time courses for prediction, we use their principal
components to eliminate collinearity in the predictor set. Following [10], we use functional principal
component analysis. Viviani et al. [10] showed that functional principal components analysis is
more eﬀective than is its ordinary counterpart in recovering the signal of interest in fMRI data, even
if limited or no prior knowledge of the hemodynamic function or experimental design is speci ﬁed.
In contrast to [10], however, our approach incrementally zooms in on stimuli-related voxel time
courses for dimension reduction (see section 2.5).
Given the set of S voxel time courses represented by the vector of functionals f (t) = [ f1 (t), ..., fS (t)]T ,
functional principal components analysis extracts main modes of variation in f (t). The number
of modes to retain is determined from the proportion of the variance that needs to be explained.
Assuming this is Q, the central concept is that of taking the linear combination
f sq = Zt

f s (t)αq (t)dt

(1)

where f sq is the principal component score value of voxel time course f s (t) in dimension q. Principal
components αq (t), q = 1, .., Q are sought for one-by-one by optimizing

1
S

f 2
sq

αq (t) = max
q (t)
α∗

S
Xs=1
where αq (t) is subject to the following orthonormal constraints
Zt
Zt
The mapping of f s (t) onto the subspace spanned by the ﬁrst Q principal component curves results in
the vector of scalars f s = [ f s1 , ..., f sQ ]. We deﬁne the S × Q matrix F = [f1 , ..., fS ]T of principal com-
ponents scores as our predictor data in linear regression. That is, we perform principal component
regression with F as model, allowing to naturally deal with temporal correlations, multicollinearity
and systematic signal variation.

αk (t)αq (t)dt = 0, k ≤ q.

αq (t)2dt = 1

(2)

(3)

2.2 The Predictand

We represent the stimulus pattern by the functional (t), t being the continuous time parameter. We
register (t) to each voxel time course f s (t) in order to be able to compare equivalent time points
on stimulus and brain activity data. Alignment reduces to ﬁn ding the warping function ω s (t) that
produces the warped stimulus function

g s (t) = (ω s (t)).
The time warping function ω s (t) is strictly monotonic, diﬀerentiable up to a certain order and takes
care of a small shift and nonlinear transformation. A global alignment criteria and least squares
estimation is used:

(4)

s (t)) − f s (t))2dt.
((ω∗

s Zt
ω s (t) = min
ω∗
Registration of (t) to all voxel time courses S results in predictand data g(t) = [g1 (t), ..., gS (t)]T ,
where g(t) is (t) registered onto voxel times-course f (t). Our motivation for using voxel-wise
registration over standard convolution of stimulus (t) with the hemodynamic reponse function, is
the large variability in hemodynamic delays across brain regions and subjects. A non -linear warp
of (t) does not guarantee an outcome that is associated with brain physiology, however it allows
to capture unknown subtle localized variations in hemodynamic delays across brain regions and
subjects.

(5)

2.3 The Model

We employ the predictor data to explain the predictand data within a linear modeling approach, i.e.
our multivariate linear model is deﬁned as

g(t) = Fβ(t) + ǫ (t)
(6)
with β(t) = [β1 (t), ..., βQ (t)]T being the Q× 1 vector of regression functions. The regression functions
are estimated by least squares minimization such that
(t) Zt
ˆβ(t) = min
β∗
under the assumption that the residual functions ǫ (t) = [ǫ1 (t), ...., ǫS (t)]T are independent and nor-
mally distributed with zero mean. The estimated regression functions provide the best estimate of
g(t) in least squares sense:

(g(t) − Fβ∗ (t))2dt,

(7)

ˆg(t) = F ˆβ(t).
Given a new (sub)set of voxel time courses, prediction of a stimulus pattern now reduces to comput-
ing the matrix of principal component scores from this new set and weighting these scores by the
estimated regression functions ˆβ(t).

(8)

2.4 The Objective

The overall ﬁt of the model to the data is expressed in terms of adjusted R2 statistic. The functional
counterpart of the traditional R2 is computed on the basis of g(t), its mean ¯g(t) and its estimation
ˆg(t). For the voxel set S ,

˙gS (t) =

S
(g s (t) − ¯g(t))2
Xs=1
S
(g s (t) − ˆg s (t))2
Xs=1
are derived, where the ﬁrst term is the variation of the respo nse about its mean and the second the
error sum of squares function. The adjusted R-square function is then deﬁned as
¨gS (t)/S − Q − 1
˙gS (t)/S − 1
where degrees of freedom S − Q − 1 and S − 1 adjust the R-square. Our objective is to ﬁnd the set
of voxel time courses S deﬁned as

RS (t) = 1 −

¨gS (t) =

(9)

(10)

(11)

S ∗ ⊂S Zt
S = max
where S ∗ denotes a subset of the entire collection of voxels time courses S extracted from a single
fMRI scan. That is, we aim at ﬁnding spatially distributed vo xel responses S that best explain the
naturalistic stimuli, without making any prior assumptions about location and size of voxel subsets.

RS ∗ (t)dt

(12)

2.5 The Search

In order to eﬃciently ﬁnd the subset of voxels that maximizes Equation (12 ), we use Population-
Based Incremental Learning (PBIL) [12], which combines Genetic Algorithms with Competitive
Learning. The PBIL algorithm uses a probability vector to explore the space of solutions. It in-
crementally generates solutions by sampling from that probability vector, evaluates these solutions
and selects promising ones to update the probability vector. Here, at increment i, the probability
1 , ..., mi
S ] is used to generate a population of N solutions Mi = [mi
1 , ..., pi
vector pi = [ pi
N ], where
n = [mi
n1 , ..., mi
each member is an S-vector of binary values: mi
nS ]. A value of 1 for mn s means
that for solution n the corresponding voxel time course f s (t) is included in the predictor set, while
n is evaluated in terms of its adjusted R2 value, and
a value 0 indicates exclusion. Each member mi
the members with highest values form the joint probability vector p∗ . A new probability vector is
subsequently constructed for the next generation via competitive learning:
pi+1 = γpi + (1 − γ)p∗ .
(13)
The learning parameter γ controls the search: a low value enables to focus entirely on the most
recent voxel subset while a low value ensures that previously selected voxel subsets are exploited.
In order to ensure spatial coherence and limit computation load, we employ the PBIl algorithm not
on single time courses, but on averages of spatial clusters of voxel time courses. That is, we ﬁrst
spatially cluster voxel locations as shown in Figure 1, then compute average time course for each
cluster and then explore the averages via PBIL for model building.

2.6 The Prediction

The subset of voxel time courses that results from population based incremental learning deﬁnes
the most predictive voxel locations and associated regression functions. Given new and spatially
normalized fMRI data, represented by ˜f (t) = [ ˜f1 (t), ..., ˜fS (t)]T , prediction of a stimulus then reduces
to computing

˜g(t) = ˜F ˆβ(t).
(14)
In here, ˜g(t) is the vector of predicted stimuli of which the mean is considered to be the sought stim-
ulus. The matrix ˜F is the principal component scores matrix obtained from performing functional
principal components analysis on subset ˜fS (t), with S referring to the set of most predictive voxels
as determined by training.

Figure 1: Examples of K-means clustering of voxel locations using Euclidean distance. Left: 1024-
means clustering output. Right: 512-means clustering output. Diﬀerent gray values indicate diﬀer-
ent clusters in a spatially normalized brain atlas.

3 Experiments and Results

3.1 Experiment

Evaluation of our method is done on a data subset from the 2006 Pittsburgh brain activity interpre-
tation competition (PBAIC) [6, 7], involving fMRI scans of three diﬀerent subjects and two movie
sessions. In each session, a subject viewed a new Home Improvement sitcom movie for approxi-
mately 20 minutes. The 20-minute movie contained 5 interruptions where no video was present, only
a white ﬁxation cross on a black background. All three subjec ts watched the same two movies. The
scans produced volumes with approximately 35,000 brain voxels, each approximately 3.28mm by
3.28mm by 3.5mm, with one volume produced every 1.75 seconds. These scans were preprocessed
(motion correction, slice time correction, linear trend removal) and spatially normalized (non-linear
registration to the Montreal Neurological Institute brain atlas).

After fMRI scanning, the three subjects watched the movie again to rate 30 movie features at time
intervals corresponding to the fMRI scan rate. In our experiments, we focus on the 13 core movie
features: amusement, attention, arousal, body parts, environmental sounds, faces, food, language,
laughter, motion, music, sadness and tools. The real-valued ratings were convolved with a hemo-
dynamic response function (HRF) modeled by two gamma functions, then subjected to voxel-wise
non-linear registration as described in 2.2.

For training and testing our model, we removed parts corresponding with video presentations of a
white ﬁxation cross on a black background. Taking into accou nt the hemodynamic lag, we divided
each fMRI scan and each subject rating into 6 parts corresponding with the movie on parts. On
average each movie part contained 105 discrete measurements. We then functionalized these parts
by ﬁtting a 30 coe ﬃcient B-spline to each voxel’s discrete time course. This resulted in 18 data
sets for training (3 subjects × 6 movie parts) and another 18 for testing. We used movie 1 data for
training and movie 2 data for prediction, and vice versa. We performed data analysis at two levels.
For each feature, ﬁrst the individual brain scans were analy zed with our method, resulting in a ﬁrst
sifting of voxels. First-level analysis results for a given feature were then subjected to second level
analysis to identify across subject predictive voxels. Pearson product-moment correlation coeﬃcient
between manual feature rating functions and the automatically predicted feature functions was used
as an evaluation measure.

3.2 Results

All results were obtained with Q = 4 principal component dimensions, learning parameter value
γ = 0.6 and K-means clustering with 1024 clusters for all movie features. These values for Q
and γ produced overall highest average cross correlation value in a small parameter optimization
experiment (data not shown here). Little performance diﬀerences were seen for various numbers of
dimensions, indicating that the essential information can be captured with as little as 4 dimension.
Signi ﬁcant performance di ﬀerences across features, however, were observed for diﬀerent learning
parameter values, indicating considerable variation in brain response to distinct stimuli.

Manual versus Predicted Feature Ratings

      Manual
     Prediction

s
n
o
i
t
c
n
u
f

0.6

0.5

0.4

0.3

0.2

0.1

0

−0.1

0

0.2

0.4
0.6
arguments

0.8

1

Figure 2: Left: normalized cross correlation values from cross-validation for 13 core movie features.
Right: functionalized subject3 (solid red) and predicted (dotted blue) rating for the language feature
of part 5 of movie 1.

Figure 2 (left) shows the average of 2 × 18 cross correlation coeﬃcients from cross validation for all
13 movie features. For features faces, language and motion cross correlation values above 0.5 were
obtained, meaning that there is a signi ﬁcant degree of match between the subject ratings and the
predicted ratings. Reasonable predictions were also obtained for features arousal and body parts.
Our results are consistent with top 3 rank entries of 2006 PBAIC in that features faces and language
are reliably predicted. These entries used recurrent neural networks, ridge regression and a dynamic
Gaussian Markov Random Field modeling on the entire test data benchmark, yielding across feature
average cross correlations of: 0.49, 0.49 and 0.47 respectively. Here, the feature average cross
correlation value based on the reduced training data set is 0.36. Note, that in the 2006 competition
our method ranked ﬁrst in the actor category [6]. We were able to accurately predict which actor the
subjects were seeing purely based on fMRI scans [7].

The best single result, with highest cross correlation value of 0.76, was obtained for feature language
of subject 3 watching part 5 of movie 1. For this feature, ﬁrst
level analysis of each of the 18 training
data sets associated with movie 2 produced a total number of 1738 predictive voxels. In the second
level analysis, these voxels were analyzed again to arrive at a reduced data set of 680 voxels for
building the multivariate functional linear model and determining regression functions β(t). For
prediction of feature language, corresponding voxel time courses were extracted from the fMRI data
of subject 3 watching movie 1 part 5, and weighted by β(t). The manual rating of feature language
of movie 1 part 5 by subject 3 and the average of the automatically predicted feature functions are
shown in Figure 2 (right).

Figure 3: Glass view, gray level image with color overlay and surface rendering of 1738 voxels from
ﬁrst level analysis. Color denotes predictive power and cro ss hair shows most predictive location.

Figure 3 shows glass view, gray level image with color overlay and surface rendering of the 1738
voxels (approximately 40 clusters) from ﬁrst level analysi s. The cross hair shows the voxel location
in Brodman area 47 that was found to be predictive across most subjects and movie parts: it was
selected in 6 out of 18 training items (see color bar). The predictive locations correspond with
the left and right inferior frontal gyrus, which are known to be involved in language processing.
The distributed nature of these clusters is consistent with earlier ﬁndings that processing involved
in language occurs in diﬀuse brain regions, including primary auditory and visual cortex, frontal
regions in the left and right hemisphere, in homologues regions [13].

As we are dealing with curves, the possibility exists to explore additional data characteristics such as
curvature. We performed an experiment with 1st order derivative functions, rather than the original
functions to exploit potentially available higher order structure. Figure 4 (left) shows the cross
correlation for 1st order derivative functions. The cross correlation values are similar to the ones
shown in Figure 2. The average cross correlation value is slightly better than for the original data:
0.38. This may indicate that higher order structures may contain more predictive power.

In order to get insight in the eﬀect of non-linear warping on prediction performance, we conducted
an experiment in which we used convolutions of the stimulus (t) with diﬀerent forms of a HRF
function modeled by two gamma functions. Various HRF functions were obtained by varing the
delay of response (relative to onset), delay of undershoot (relative to onset), dispersion of response,
dispersion of undershoot, ratio of response to undershoot. To determine g s (t), we convolved (t)
with 16 diﬀerent HRF functions, and selected the convolved one with highest cross correlation with
f s (t) to be g s (t). Hence, we parametrically modeled the HRF and learned its parameters from the
data.

Figure 4 (right) shows the results of the experiments with convolution of stimuli data with HRF
models learned from the data. As can be seen, the cross correlation values are much lower compared
to the values in Figure 2 (left). The average cross correlation value is 0.31. Hence, non-linear
warping of stimulus onto voxel time course signi ﬁcantly enh ances the predictive power of our model.
This suggests that non-linear warping is a potential alternative for determining the best possible HRF
estimate to overcome potential negative consequences of assuming HRF consistency across subjects
or brain regions [14].

Figure 4: Left: normalized cross correlation values from cross-validation for 13 core movie features,
using 1st order derivative data. Right: cross correlation values from cross-validation for 13 core
movie features, using HRF convoluted rather than warped stimuli data.

4 Conclusion

Functional data analysis provides the possibility to fully exploit structure in inherently continuous
data such as fMRI. The advantage of functional data analysis for principal component analysis of
fMRI data was recently demonstrated in [10]. Here, we proposed a functional linear model that
treats fMRI and stimuli as stochastic functional measurements. Cast into an incremental pattern
searching framework, the method provides the ability to identify important covariance structure

of spatially distributed brain responses and stimuli, i.e. it directly couples activation across brain
regions rather than ﬁrst localizing and then integrating fu nction. The method is suited for unbiased
probing of functional characteristics of brain areas as well as for exposing meaningful relations
between complex stimuli and distributed brain responses. This ﬁnding is supported by the good
prediction performance of our method in the 2006 PBAIC international competition for brain activity
interpretation. We are currently extending the method with new objective functions, dimension
reduction techniques and multi-target search techniques to cope with multiple (interacting) stimuli.
Also, in this work we made use of spatial clusters at a single hierarchical level. Preliminary results
with hierarchical clustering to arrive at ”supervoxels ” at
diﬀerent spatial resolutions, seem to further
improve prediction power.

References

[1] J. Haynes and G. Rees. Decoding mental states from brain activity in humans. Nature Neuro-
science, 7(8):523–534, 2006.
[2] J. Haynes and G. Rees. Predicting the orientation of invisible stimuli from activity in human
primary visual cortex. Nature Neuroscience, 7(5):686–691, 2005.
[3] Y. Kamitani and F. Tong. Decoding the visual and subjective contents of the human brain.
Nature Neuroscience, 8(5):679–685, 2005.
[4] S.M. Polyn, V.S. Natu, J.D. Cohen, and K.A. Norman. Category-speci ﬁc cortical activity
precedes retrieval during memory search. Science, 310(5756):1963–1966, 2005.
[5] T.M. Mitchell, R. Hutchinson, R.S. Niculescu, F. Pereira, X. Wang, M. Just, and S. Newman.
Learning to decode cognitive states from brain images. Machine Learning, 57(1-2), 2004.
[6] W. Schneider, A. Bartels, E. Formisano, J. Haxby, R. Goebel, T. Mitchell, T. Nichols, and
G. Siegle. Competition: Inferring experience based cognition from fmri.
In Proceedings
Organization of Human Brain Mapping Florence Italy June 15, 2006.
[7] Editorial. What’s on your mind. Nature Neuroscience, 6(8):981, 2006.
[8] K.J. Worsley, J.B. Poline, K.J. Friston, and A.C. Evans. Characterizing the response of pet and
fmri data using multivariate linear models. Neuroimage, 6, 1997.
[9] J. Ramsay and B. Silverman. Functional Data Analysis. Springer-Verlag, 1997.
[10] R. Viviani, G. Grohn, and M. Spitzer. Functional principal component analysis of fmri data.
Human Brain Mapping, 24:109–129, 2005.
[11] D.B. Rowe and R.G. Hoﬀmann. Multivariate statistical analysis in fmri. IEEE Engineering in
Medicine and Biology, 25:60–64, 2006.
[12] Shumeet Baluja. Population-based incremental learning: A method for integrating genetic
search based function optimization and competitive learning. Technical Report CMU-CS-94-
163, Computer Science Department, Carnegie Mellon University, Pittsburgh, PA, 1994.
[13] M.A. Gernsbacher and M.P. Kaschak. Neuroimaging studies of language production and com-
prehension. Annual Review of Psychology, 54:91–114, 2003.
[14] D.A. Handwerker, J.M. Ollinger, and M. D’Esposito. Variation of bold hemodynamic response
function across subjects and brain regions and their eﬀects on statistical analysis. NeuroImage,
8(21):1639–1651, 2004.

