Local Algorithms for Approximate Inference in
Minor-Excluded Graphs

Kyomin Jung
Dept. of Mathematics, MIT
kmjung@mit.edu

Devavrat Shah
Dept. of EECS, MIT
devavrat@mit.edu

Abstract

We present a new local approximation algorithm for computing MAP and log-
partition function for arbitrary exponential family distribution represented by a
ﬁnite-valued pair-wise Markov random ﬁeld (MRF), say G. Our algorithm is
based on decomposing G into appropriately chosen small components; computing
estimates locally in each of these components and then producing a good global
solution. We prove that the algorithm can provide approximate solution within
arbitrary accuracy when G excludes some ﬁnite sized graph as its minor and G
has bounded degree: all Planar graphs with bounded degree are examples of such
graphs. The running time of the algorithm is Θ(n) (n is the number of nodes in
G), with constant dependent on accuracy, degree of graph and size of the graph
that is excluded as a minor (constant for Planar graphs).
Our algorithm for minor-excluded graphs uses the decomposition scheme of
Klein, Plotkin and Rao (1993). In general, our algorithm works with any decom-
position scheme and provides quantiﬁable approximation gu arantee that depends
on the decomposition scheme.

1 Introduction

Markov Random Field (MRF) based exponential family of distribution allows for representing dis-
tributions in an intuitive parametric form. Therefore, it has been successful for modeling in many
applications Speciﬁcally, consider an exponential family on n random variables X = (X1 , . . . , Xn )
represented by a pair-wise (undirected) MRF with graph structure G = (V , E ), where vertices
V = {1, . . . , n} and edge set E ⊂ V × V . Each Xi takes value in a ﬁnite set Σ (e.g. Σ = {0, 1}).
The joint distribution of X = (Xi ): for x = (xi ) ∈ Σn ,
Pr[X = x] ∝ exp 
ψij (xi , xj )
X
φi (xi ) + X
 .
i∈V
(i,j)∈E
: Σ → R+ 4
Here, functions φi
: Σ2 → R+ are as-
= {x ∈ R : x ≥ 0}, and ψij
sumed to be arbitrary non-negative (real-valued) functions.1 The two most important computa-
tional questions of interest are: (i) ﬁnding maximum a-post eriori (MAP) assignment x∗ , where
x∗ = arg maxx∈Σn Pr[X = x]; and (ii) marginal distributions of variables, i.e. Pr[Xi =
for x ∈ Σ, 1 ≤ i ≤ n. MAP is equivalent to a minimal energy assignment (or ground state)
x];
where energy, E (x), of state x ∈ Σn is de ﬁned as E (x) = −H(x) + Constant, where H(x) =
Pi∈V φi (xi )+P(i,j)∈E ψij (xi , xj ). Similarly, computing marginal is equivalent to computing log-
log Z = log (cid:16)Px∈Σn exp (cid:16)Pi∈V φi (xi ) + P(i,j)∈E ψij (xi , xj )(cid:17)(cid:17) .
partition function, de ﬁned as
In this paper, we will ﬁnd ε-approximation solutions of MAP and log-partition function: that is, ˆx
and log ˆZ such that: (1 − ε)H(x∗ ) ≤ H(ˆx) ≤ H(x∗ ),
(1 − ε) log Z ≤ log ˆZ ≤ (1 + ε) log Z.

(1)

1Here, we assume the positivity of φi ’s and ψij ’s for simplicity of analysis.

1

Previous Work. The question of ﬁnding MAP (or ground state) comes up in many i mportant appli-
cation areas such as coding theory, discrete optimization, image denoising.Similarly, log-partition
function is used in counting combinatorial objects loss-probability computation in computer net-
works, etc. Both problems are NP-hard for exact and even (constant) approximate computation for
arbitrary graph G. However, applications require solving this problem using very simple algorithms.
A plausible approach is as follows. First, identify wide class of graphs that have simple algorithms
for computing MAP and log-partition function. Then, try to build system (e.g. codes) so that such
good graph structure emerges and use the simple algorithm or else use the algorithm as a heuristic.

Such an approach has resulted in many interesting recent results starting the Belief Propagation
(BP) algorithm designed for Tree graph [1].Since there a vast literature on this topic, we will recall
only few results. Two important algorithms are the generalized belief propagation (BP) [2] and the
tree-reweighted algorithm (TRW) [3,4].Key properties of interest for these iterative procedures are
the correctness of ﬁxed points and convergence. Many result s characterizing properties of the ﬁxed
points are known starting from [2]. Various sufﬁcient condi tions for their convergence are known
starting [5]. However, simultaneous convergence and correctness of such algorithms are established
for only speciﬁc problems, e.g. [6].

about properties of TRW. The TRW
Finally, we discuss two relevant results. The ﬁrst result is
algorithm provides provable upper bound on log-partition function for arbitrary graph [3]However,
to the best of authors’ knowledge the error is not quantiﬁed. The TRW for MAP estimation has
a strong connection to speciﬁc Linear Programming (LP) rela xation of the problem [4]. This was
made precise in a sequence of work by Kolmogorov [7], Kolmogorov and Wainwright [8] for binary
MRF. It is worth noting that LP relaxation can be poor even for simple problems.

The second is an approximation algorithm proposed by Globerson and Jaakkola [9] to compute
log-partition function using Planar graph decomposition (PDC). PDC uses techniques of [3] in con-
junction with known result about exact computation of partition function for binary MRF when G is
Planar and the exponential family has speciﬁc form. Their al gorithm provides provable upper bound
for arbitrary graph. However, they do not quantify the error incurred. Further, their algorithm is
limited to binary MRF.

Contribution. We propose a novel local algorithm for approximate computation of MAP and log-
partition function. For any ε > 0, our algorithm can produce an ε-approximate solution for MAP
and log-partition function for arbitrary MRF G as long as G excludes a ﬁnite graph as a minor
(precise de ﬁnition later). For example, Planar graph exclu des K3,3 , K5 as a minor. The running
time of the algorithm is Θ(n), with constant dependent on ε, the maximum vertex degree of G and
the size of the graph that is excluded as minor. Speciﬁcally,
for a Planar graph with bounded degree,
it takes ≤ C (ε)n time to ﬁnd ε-approximate solution with log log C (ε) = O(1/ε). In general, our
algorithm works for any G and we can quantify bound on the error incurred by our algorithm. It is
worth noting that our algorithm provides a provable lower bound on log-partition function as well
unlike many of previous works.

The precise results for minor-excluded graphs are stated in Theorems 1 and 2. The result concerning
general graphs are stated in the form of Lemmas 2-3-4 for log-partition and Lemmas 5-6-7 for MAP.

Techniques. Our algorithm is based on the following idea: First, decompose G into small-size
connected components say G1 , . . . , Gk by removing few edges of G. Second, compute estimates
(either MAP or log-partition) in each of Gi separately. Third, combine these estimates to produce a
global estimate while taking care of the effect induced by removed edges. We show that the error in
the estimate depends only on the edges removed. This error bound characterization is applicable for
arbitrary graph.

Klein, Plotkin and Rao [10]introduced a clever and simple decomposition method for minor-
excluded graphs to study the gap between max- ﬂow and min-cut
for multicommodity ﬂows. We
use their method to obtain a good edge-set for decomposing minor-excluded G so that the error
induced in our estimate is small (can be made as small as required).

In general, as long as G allows for such good edge-set for decomposing G into small components,
our algorithm will provide a good estimate. To compute estimates in individual components, we
use dynamic programming. Since each component is small, it is not computationally burdensome.

2

However, one may obtain further simpler heuristics by replacing dynamic programming by other
method such as BP or TRW for computation in the components.

2 Preliminaries
Here we present useful de ﬁnitions and previous results abou t decomposition of minor-excluded
graphs from [10,11].
De ﬁnition 1 (Minor Exclusion) A graph H is called minor of G if we can transform G into H
through an arbitrary sequence of the following two operations: (a) removal of an edge; (b) merge
two connected vertices u, v: that is, remove edge (u, v) as well as vertices u and v; add a new vertex
and make all edges incident on this new vertex that were incident on u or v . Now, if H is not a minor
of G then we say that G excludes H as a minor.

The explanation of the following statement may help understand the de ﬁnition: any graph H with
r nodes is a minor of Kr , where Kr is a complete graph of r nodes. This is true because one may
obtain H by removing edges from Kr that are absent in H . More generally, if G is a subgraph of
G0 and G has H as a minor, then G0 has H as its minor. Let Kr,r denote a complete bipartite graph
with r nodes in each partition. Then Kr is a minor of Kr,r . An important implication of this is as
follows: to prove property P for graph G that excludes H , of size r, as a minor, it is sufﬁcient to
prove that any graph that excludes Kr,r as a minor has property P. This fact was cleverly used by
Klein et. al. [10] to obtain a good decomposition scheme described next. First, a de ﬁnition.
De ﬁnition 2 ( (δ, ∆)-decomposition) Given graph G = (V , E ), a randomly chosen subset of edges
B ⊂ E is called (δ, ∆) decomposition of G if the following holds: (a) For any edge e ∈ E ,
Pr(e ∈ B ) ≤ δ . (b) Let S1 , . . . , SK be connected components of graph G0 = (V , E \B ) obtained by
removing edges of B from G. Then, for any such component Sj , 1 ≤ j ≤ K and any u, v ∈ Sj the
shortest-path distance between (u, v) in the original graph G is at most ∆ with probability 1.

The existence of (δ, ∆)-decomposition implies that it is possible to remove δ fraction of edges so
that graph decomposes into connected components whose diameter is small. We describe a simple
and explicit construction of such a decomposition for minor excluded class of graphs. This scheme
was proposed by Klein, Plotkin, Rao [10] and Rao [11].

DeC(G, r, ∆)

(0) Input is graph G = (V , E ) and r, ∆ ∈ N. Initially, i = 0, G0 = G, B = ∅.
(1) For i = 0, . . . , r − 1, do the following.
(a) Let S i
be the connected components of Gi .
1 , . . . , S i
ki
j , 1 ≤ j ≤ ki , pick an arbitrary node vj ∈ S i
(b) For each S i
j .
j .
j rooted at vj in S i
◦ Create a breadth- ﬁrst search tree T i
j uniformly at random from {0, . . . , ∆ − 1}.
◦ Choose a number Li
j .
j , . . . in T i
j be the set of edges at level Li
◦ Let B i
j , 2∆ + Li
j , ∆ + Li
◦ Update B = B ∪ki
j .
j=1 B i
(c) set i = i + 1.
(3) Output B and graph G0 = (V , E \B ).

As stated above, the basic idea is to use the following step recursively (upto depth r of recursion):
in each connected component, say S , choose a node arbitrarily and create a breadth- ﬁrst search tree,
say T . Choose a number, say L, uniformly at random from {0, . . . , ∆ − 1}. Remove (add to B ) all
edges that are at level L + k∆, k ≥ 0 in T . Clearly, the total running time of such an algorithm is
O(r(n + |E |)) for a graph G = (V , E ) with |V | = n; with possible parallel implementation across
different connected components.
The algorithm DeC(G, r, ∆) is designed to provide a good decomposition for class of graphs that
exclude Kr,r as a minor. Figure 1 explains the algorithm for a line-graph of n = 9 nodes, which
excludes K2,2 as a minor. The example is about a sample run of DeC(G, 2, 3) (Figure 1 shows the
ﬁrst iteration of the algorithm).

3

G0

L1

1
 

 


2
 

 


3
 

 


4
  

  


5
 

 


6
 

 


7
 

 


8
 

 


9
  

  


5
 

 

  

  


4

 

 


3

2
  

 

1

 

6

7

 

 

8

9

 

T1

G1

  

                       

1

2

3

4

5

6

7

8

9

S1

S2

S3

S4

S5

Figure 1: The ﬁrst of two iterations in execution of DeC(G, 2, 3) is shown.

Lemma 1 If G excludes Kr,r as a minor,
(r/∆, O(∆))-decomposition of G.

then algorithm DeC(G, r, ∆) outputs B which is

It is known that Planar graph excludes K3,3 as a minor. Hence, Lemma 1 implies the following.
Corollary 1 Given a planar graph G,
the algorithm DeC(G, 3, ∆) produces (3/∆, O(∆))-
decomposition for any ∆ ≥ 1.

3 Approximate log Z
Here, we describe algorithm for approximate computation of log Z for any graph G. The algorithm
uses a decomposition algorithm as a sub-routine. In what follows, we use term D ECOM P for a
generic decomposition algorithm. The key point is that our algorithm provides provable upper and
lower bound on log Z for any graph; the approximation guarantee and computation time depends on
the property of D ECOM P. Speciﬁcally, for Kr,r minor excluded G (e.g. Planar graph with r = 3),
we will use DeC(G, r, ∆) in place of D ECOM P. Using Lemma 1, we show that our algorithm based
on DeC provides approximation upto arbitrary multiplicative accuracy by tuning parameter ∆.

LOG PART IT ION(G)

(1) Use D ECOM P(G) to obtain B ⊂ E such that
(a) G0 = (V , E \B ) is made of connected components S1 , . . . , SK .
(2) For each connected component Sj , 1 ≤ j ≤ K , do the following:
(a) Compute partition function Zj restricted to Sj by dynamic programming(or exhaus-
tive computation).
(3) Let ψL
ij = min(x,x0 )∈Σ2 ψij (x, x0 ), ψU
ij = max(x,x0 )∈Σ2 ψij (x, x0 ). Then
KX
KX
log Zj + X
log Zj + X
log ˆZUB =
log ˆZLB =
j=1
j=1
(i,j)∈B
(i,j)∈B
(4) Output: lower bound log ˆZLB and upper bound log ˆZUB .

ψL
ij ;

ψU
ij .

In words, LOG PART IT ION(G) produces upper and lower bound on log Z of MRF G as follows:
decompose graph G into (small) components S1 , . . . , SK by removing (few) edges B ⊂ E using
D ECOM P(G). Compute exact log-partition function in each of the components. To produce bounds
log ˆZLB , log ˆZUB take the summation of thus computed component-wise log-partition function along
with minimal and maximal effect of edges from B .
Analysis of LOG PART IT ION for General G : Here, we analyze performance of LOG PART I -
T ION for any G. In the next section, we will specialize our analysis for minor excluded G when
LOG PART IT ION uses DeC as the D ECOM P algorithm.
Lemma 2 Given an MRF G described by (1), the LOG PART IT ION produces log ˆZLB , log ˆZUB such
that
log ˆZUB − log ˆZLB = X
(cid:0)ψU
ij (cid:1) .
ij − ψL
(i,j)∈B

log ˆZLB ≤ log Z ≤ log ˆZUB ,

4

It takes O (cid:0)|E |K Σ|S ∗ | (cid:1) + TDECOMP time to produce this estimate, where |S ∗ | = maxK
j=1 |Sj | with
D ECOM P producing decomposition of G into S1 , . . . , SK in time TDECOMP .
ij i .
D+1 hP(i,j)∈E ψU
Lemma 3 If G has maximum vertex degree D then, log Z ≥ 1
ij − ψL
Lemma 4 If G has maximum vertex degree D and the D ECOM P(G) produces B that is (δ, ∆)-
decomposition, then
E hlog ˆZUB − log ˆZLBi ≤ δ(D + 1) log Z,
w.r.t. the randomness in B , and LOG PART IT ION takes time O(nD|Σ|D∆

) + TDECOMP .

Analysis of LOG PART IT ION for Minor-excluded G : Here, we specialize analysis of LOG PAR -
T IT IONfor minor exclude graph G. For G that exclude minor Kr,r , we use algorithm DeC(G, r, ∆).
Now, we state the main result for log-partition function computation.
Theorem 1 Let G exclude Kr,r as minor and have D as maximum vertex degree. Given ε > 0, use
LOG PART IT ION algorithm with DeC(G, r, ∆) where ∆ = d r(D+1)
e. Then,
ε
E hlog ˆZUB − log ˆZLBi ≤ ε log Z.
Further, algorithm takes (nC (D, |Σ|, ε)), where constant C (D, |Σ|, ε) = D|Σ|DO(rD/ε)

log ˆZLB ≤ log Z ≤ log ˆZUB ;

.

We obtain the following immediate implication of Theorem 1.
Corollary 2 For any ε > 0, the LOG PART IT ION algorithm with DeC algorithm for constant degree
Planar graph G based MRF, produces log ˆZLB , log ˆZUB so that
(1 − ε) log Z ≤ log ˆZLB ≤ log Z ≤ log ˆZUB ≤ (1 + ε) log Z,
in time O(nC (ε)) where log log C (ε) = O(1/ε).

4 Approximate MAP
Now, we describe algorithm to compute MAP approximately. It is very similar to the LOG PAR -
T IT ION algorithm: given G, decompose it into (small) components S1 , . . . , SK by removing (few)
edges B ⊂ E . Then, compute an approximate MAP assignment by computing exact MAP restricted
to the components. As in LOG PART IT ION, the computation time and performance of the algorithm
depends on property of decomposition scheme. We describe algorithm for any graph G; which will
be specialized for Kr,r minor excluded G using DeC(G, r, ∆).

MODE(G)

(1) Use D ECOM P(G) to obtain B ⊂ E such that
(a) G0 = (V , E \B ) is made of connected components S1 , . . . , SK .
(2) For each connected component Sj , 1 ≤ j ≤ K , do the following:
(a) Through dynamic programming (or exhaustive computation) ﬁnd exact MAP x∗,j for
component Sj , where x∗,j = (x∗,j
)i∈Sj .
i
(3) Produce output cx∗ , which is obtained by assigning values to nodes using x∗,j , 1 ≤ j ≤ K .
Analysis of MODE for General G : Here, we analyze performance of MODE for any G. Later,
we will specialize our analysis for minor excluded G when it uses DeC as the D ECOM P algorithm.
Lemma 5 Given an MRF G described by (1), the MODE algorithm produces outputs cx∗ such that
ij (cid:1) ≤ H(cx∗ ) ≤ H(x∗ ). It takes O (cid:0)|E |K Σ|S ∗ | (cid:1) + TDECOMP time to
H(x∗ ) − P(i,j)∈B (cid:0)ψU
ij − ψL
j=1 |Sj | with D ECOM P producing decomposition of G into
produce this estimate, where |S ∗ | = maxK
S1 , . . . , SK in time TDECOMP .
Lemma 6 If G has maximum vertex degree D , then


 X
 ≥
(i,j)∈E


 X
(i,j)∈E

1
D + 1

ij − ψL
ψU
ij


 .

H(x∗ ) ≥

1
D + 1

ψU
ij

5

Lemma 7 If G has maximum vertex degree D and the D ECOM P(G) produces B that is (δ, ∆)-
decomposition, then
E hH(x∗ ) − H(cx∗ )i ≤ δ(D + 1)H(x∗ ),
where expectation is w.r.t. the randomness in B . Further, MODE takes time O(nD|Σ|D∆

)+TDECOMP .

Analysis of MODE for Minor-excluded G : Here, we specialize analysis of MODE for minor
exclude graph G. For G that exclude minor Kr,r , we use algorithm DeC(G, r, ∆). Now, we state
the main result for MAP computation.
Theorem 2 Let G exclude Kr,r as minor and have D as the maximum vertex degree. Given ε > 0,
use MODE algorithm with DeC(G, r, ∆) where ∆ = d r(D+1)
e. Then,
ε
(1 − ε)H(x∗ ) ≤ H(cx∗ ) ≤ H(x∗ ).
Further, algorithm takes n · C (D, |Σ|, ε) time, where constant C (D, |Σ|, ε) = D|Σ|DO(rD/ε)

.

We obtain the following immediate implication of Theorem 2.
Corollary 3 For any ε > 0, the MODE algorithm with DeC algorithm for constant degree Planar
graph G based MRF, produces estimate cx∗ so that
(1 − ε)H(x∗ ) ≤ H(cx∗ ) ≤ H(x∗ ),
in time O(nC (ε)) where log log C (ε) = O(1/ε).

θij xixj

.

for x ∈ {0, 1}n2

5 Experiments
Our algorithm provides provably good approximation for any MRF with minor excluded graph
structure, with planar graph as a special case. In this section, we present experimental evaluation of
our algorithm for popular synthetic model.
Setup 1.2 Consider binary (i.e. Σ = {0, 1}) MRF on an n × n lattice G = (V , E ):

Pr(x) ∝ exp 
θi xi + X
X
 ,
(i,j )∈E
i∈V
Figure 2 shows a lattice or grid graph with n = 4 (on the left side). There are two scenarios for
choosing parameters (with notation U [a, b] being uniform distribution over interval [a, b]):
(1) Varying interaction. θi is chosen independently from distribution U [−0.05, 0.05] and θij chosen
independent from U [−α, α] with α ∈ {0.2, 0.4, . . . , 2}.
(2) Varying ﬁeld. θij is chosen independently from distribution U [−0.5, 0.5] and θi chosen indepen-
dently from U [−α, α] with α ∈ {0.2, 0.4, . . . , 2}.
The grid graph is planar. Hence, we run our algorithms LOG PART IT ION and MODE , with decom-
position scheme DeC(G, 3, ∆), ∆ ∈ {3, 4, 5}. We consider two measures to evaluate performance:
n2 | log Z alg − log Z |; and error in H(x∗ ), de ﬁned as
n2 |H(xalg − H(x∗ )|.
1
1
error in log Z , de ﬁned as
We compare our algorithm for error in log Z with the two recently very successful algorithms –
Tree re-weighted algorithm (TRW) and planar decomposition algorithm (PDC). The comparison is
plotted in Figure 3 where n = 7 and results are averages over 40 trials. The Figure 3(A) plots
error with respect to varying interaction while Figure 3(B) plots error with respect to varying ﬁeld
strength. Our algorithm, essentially outperforms TRW for these values of ∆ and perform very
competitively with respect to PDC.

The key feature of our algorithm is scalability. Speciﬁcall y, running time of our algorithm with a
given parameter value ∆ scales linearly in n, while keeping the relative error bound exactly the
same. To explain this important feature, we plot the theoretically evaluated bound on error in log Z

2Though this setup has φi , ψij taking negative values, they are equivalent to the setup considered in the
paper as the function values are lower bounded and hence afﬁne shift will make them non-negative without
changing the distribution.

6

in Figure 4 with tags (A), (B) and (C). Note that error bound plot is the same for n = 100 (A) and
n = 1000 (B). Clearly, actual error is likely to be smaller than these theoretically plotted bounds.
We note that these bounds only depend on the interaction strengths and not on the values of ﬁelds
strengths (C).

Results similar to of LOG PART IT ION are expected from MODE . We plot the theoretically evaluated
bounds on the error in MAP in Figure 4 with tags (A), (B) and (C). Again, the bound on MAP relative
error for given ∆ parameter remains the same for all values of n as shown in (A) for n = 100 and
(B) for n = 1000. There is no change in error bound with respect to the ﬁeld str ength (C).
Setup 2. Everything is exactly the same as the above setup with the only difference that grid graph
is replaced by cris-cross graph which is obtained by adding extra four neighboring edges per node
(exception of boundary nodes). Figure 2 shows cris-cross graph with n = 4 (on the right side).
We again run the same algorithm as above setup on this graph. For cris-cross graph, we obtained
its graph decomposition from the decomposition of its grid sub-graph. graph Though the cris-cross
graph is not planar, due to the structure of the cris-cross graph it can be shown (proved) that the
running time of our algorithm will remain the same (in order) and error bound will become only 3
times weaker than that for the grid graph ! We compute these theoretical error bounds for log Z and
MAP which is plotted in Figure 5. This ﬁgure is similar to the F igure 4 for grid graph. This clearly
exhibits the generality of our algorithm even beyond minor excluded graphs.
References
[1] J. Pearl, “Probabilistic Reasoning in Intelligent Syst ems: Networks of Plausible Inference,” San Francisco,
CA: Morgan Kaufmann, 1988.
[2] J. Yedidia, W. Freeman and Y. Weiss, “Generalized Belief Propagation,” Mitsubishi Elect. Res. Lab., TR-
2000-26, 2000.
[3] M. J. Wainwright, T. Jaakkola and A. S. Willsky, “Tree-ba sed reparameterization framework for analysis of
sum-product and related algorithms,”
IEEE Trans. on Info. Theory, 2003.
[4] M. J. Wainwright, T. S. Jaakkola and A. S. Willsky, “MAP es timation via agreement on (hyper)trees:
Message-passing and linear-programming approaches,”
IEEE Trans. on Info. Theory, 51(11), 2005.
[5] S. C. Tatikonda and M. I. Jordan, “Loopy Belief Propagati on and Gibbs Measure,” Uncertainty in Arti ﬁcial
Intelligence, 2002.
[6] M. Bayati, D. Shah and M. Sharma, “Maximum Weight Matchin g via Max-Product Belief Propagation,”
IEEE ISIT, 2005.
[7] V. Kolmogorov, “Convergent Tree-reweighted Message Pa ssing for Energy Minimization,”
tions on Pattern Analysis and Machine Intelligence, 2006.
[8] V. Kolmogorov and M. Wainwright, “On optimality of tree- reweighted max-product message-passing,”
Uncertainty in Arti ﬁcial Intelligence , 2005.
[9] A. Globerson and T. Jaakkola, “Bound on Partition functi on through Planar Graph Decomposition,” NIPS,
2006.
[10] P. Klein, S. Plotkin and S. Rao, “Excluded minors, netwo rk decomposition, and multicommodity ﬂow,”
ACM STOC, 1993.
[11] S. Rao, “Small distortion and volume preserving embedd ings for Planar and Euclidian metrics,” ACM
SCG, 1999.

IEEE Transac-

  

  

  


  

  

  


  

  

  


  

  

  


 

 


 

 


 

 


 

 


 

 


 

 


  

  


  

  


 

 


 

 


  

  


  

  


Grid

 

 

 


 

 

 


 

 


 

 


  

  


  

  


  

  


  

  


 

 


 

 


 

 


 

 


 

 

 


 

 

 


 

 


 

 


Cris

Figure 2: Example of grid graph (left) and cris-cross graph (right) with n = 4.

7

(1-A) Gr id, N=7

(1-B) Gird, n=7

TRW

PDC

3(cid:32)(cid:39)

4(cid:32)(cid:39)

5(cid:32)(cid:39)

(cid:865)(cid:863)(cid:868)

(cid:865)(cid:863)(cid:867)(cid:870)

(cid:865)(cid:863)(cid:867)

Z
 
E
r
r
o
r

(cid:865)(cid:863)(cid:866)(cid:870)

(cid:865)(cid:863)(cid:866)

(cid:865)(cid:863)(cid:865)(cid:870)

(cid:865)

TRW

PDC

3(cid:32)(cid:39)

4(cid:32)(cid:39)

5(cid:32)(cid:39)

Z
 
E
r
r
o
r

(cid:865)(cid:863)(cid:865)(cid:868)(cid:870)

(cid:865)(cid:863)(cid:865)(cid:868)

(cid:865)(cid:863)(cid:865)(cid:867)(cid:870)

(cid:865)(cid:863)(cid:865)(cid:867)

(cid:865)(cid:863)(cid:865)(cid:866)(cid:870)

(cid:865)(cid:863)(cid:865)(cid:866)

(cid:865)(cid:863)(cid:865)(cid:865)(cid:870)

(cid:865)

(cid:865)(cid:863)(cid:867)

(cid:865)(cid:863)(cid:869)

(cid:865)(cid:863)(cid:871)

(cid:865)(cid:863)(cid:873)

(cid:866)
(cid:866)(cid:863)(cid:867)
Interaction  Strength

(cid:866)(cid:863)(cid:869)

(cid:866)(cid:863)(cid:871)

(cid:866)(cid:863)(cid:873)

(cid:867)

(cid:865)(cid:863)(cid:867)

(cid:865)(cid:863)(cid:869)

(cid:865)(cid:863)(cid:871)

(cid:865)(cid:863)(cid:873)

(cid:866)
(cid:866)(cid:863)(cid:867)
Field Strength

(cid:866)(cid:863)(cid:869)

(cid:866)(cid:863)(cid:871)

(cid:866)(cid:863)(cid:873)

(cid:867)

Figure 3: Comparison of TRW, PDC and our algorithm for grid graph with n = 7 with respect to error in log Z . Our algorithm outperforms TRW and is
competitive with respect to PDC.

(2-A) Gr id , n=100

(2-B) Gr id, n=1000

(2-C) Grid, n=1000

5(cid:32)(cid:39)

10(cid:32)(cid:39)

20(cid:32)(cid:39)

Z
 
E
r
r
o
r
 
B
o
u
n
d

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

Z
 
E
r
r
o
r
 
B
o
u
n
d

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

0.2

0.4

0.6

0.8

1

1.2

1.4

1.6

1.8

2

0.2

0.4

0.6

0.8

1

1.2

1.4

1.6

1.8

2

(3-B) Grid, n=1000

Interaction Strength

(3-A) Grid, n=100
0.9

Interaction  Strength

5(cid:32)(cid:39)

10(cid:32)(cid:39)

20(cid:32)(cid:39)

M
A
P
 
E
r
r
o
r
 
B
o
u
n
d

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

M
A
P
 
E
r
r
o
r
 
B
o
u
n
d

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

Z
 
E
r
r
o
r
 
B
o
u
n
d

M
A
P
 
E
r
r
o
r
 
B
o
u
n
d

2.5

2

1.5

1

0.5

0

2.5

2

1.5

1

0.5

0

0.2

0.4

0.6

0.8

1

1.2

1.4

1.6

1.8

2

(3-C) Grid, n=1000

Field Strength

0.2

0.4

0.6

0.8
1
1.2
1.4
Interaction Strength

1.6

1.8

2

0.2

0.4

0.6

0.8

1

1.2

1.4

1.6

1.8

2

0.2

0.4

0.6

0.8

1

1.2

1.4

1.6

1.8

2

Interaction Strength

Field Strength

Figure 4: The theoretically computable error bounds for log Z and MAP under our algorithm for grid with n = 100 and n = 1000 under varying
interaction and varying ﬁeld model. This clearly shows scal ability of our algorithm.

(4-A) Cris Cross, n=100

5(cid:32)(cid:39)

10(cid:32)(cid:39)

20(cid:32)(cid:39)

(4-B) Cris Cross, n=1000

Z
 
E
r
r
o
r
 
B
o
u
n
d

2.5

2

1.5

1

0.5

0

0.2

0.4

0.6

0.8

1

1.2

1.4

1.6

1.8

2

0.2

0.4

0.6

0.8

1

1.2

1.4

1.6

1.8

2

(5-A) Criss Cross, n=100

Interact ion Strength

5(cid:32)(cid:39)

10(cid:32)(cid:39)

20(cid:32)(cid:39)

(5-B) Cr is Cross, n=1000

Interaction Strength

M
A
P
 
E
r
r
o
r
 
B
o
u
n
d

2.5

2

1.5

1

0.5

0

Z
 
E
r
r
o
r
 
B
o
u
n
d

M
A
P
 
E
r
r
o
r
 
B
o
u
n
d

2.5

2

1.5

1

0.5

0

2.5

2

1.5

1

0.5

0

Z
 
E
r
r
o
r
 
B
o
u
n
d

M
A
P
 
E
r
r
o
r
 
B
o
u
n
d

0.6

0.5

0.4

0.3

0.2

0.1

0

0.6

0.5

0.4

0.3

0.2

0.1

0

(4-C) Cr is Cross, n=1000

0.2

0.4

0.6

0 .8

(5-C) Cr is Cross, n=1000

1
1.2
Field Strength

1.4

1.6

1.8

2

0.2

0.4

0.6

0.8

1

1.2

1.4

1.6

1.8

2

0.2

0.4

0.6

0.8

Interaction Strength

1
1.2
Interaction Strength

1.4

1.6

1.8

2

0.2

0.4

0.6

0.8

1.4

1.6

1.8

2

1
1.2
Field Strength

Figure 5: The theoretically computable error bounds for log Z and MAP under our algorithm for cris-cross with n = 100 and n = 1000 under varying
interaction and varying ﬁeld model. This clearly shows scal ability of our algorithm and robustness to graph structure.

8

