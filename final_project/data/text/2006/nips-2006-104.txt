Uncertainty, phase and oscillatory hippocampal recall

M ´at ´e Lengyel and Peter Dayan
Gatsby Computational Neuroscience Unit
University College London
17 Queen Square, London WC1N 3AR, United Kingdom
{lmate,dayan}@gatsby.ucl.ac.uk

Abstract

Many neural areas, notably, the hippocampus, show structured, dynamical, pop-
ulation behavior such as coordinated oscillations. It has long been observed that
such oscillations provide a substrate for representing analog information in the
ﬁring phases of neurons relative to the underlying population rhythm. However,
it has become increasingly clear that it is essential for neural populations to rep-
resent uncertainty about the information they capture, and the substantial recent
work on neural codes for uncertainty has omitted any analysis of oscillatory sys-
tems. Here, we observe that, since neurons in an oscillatory network need not only
ﬁre once in each cycle (or even at all), uncertainty about the analog quantities each
neuron represents by its ﬁring phase might naturally be reported through the de-
gree of concentration of the spikes that it ﬁres. We apply this theory to memory
in a model of oscillatory associative recall in hippocampal area CA3. Although
it is not well treated in the literature, representing and manipulating uncertainty
is fundamental to competent memory; our theory enables us to view CA3 as an
effective uncertainty-aware, retrieval system.

1 Introduction

In a network such as hippocampal area CA3 that shows prominent oscillations during memory re-
trieval and other functions [1], there are apparently three, somewhat separate, ways in which neurons
might represent information within a single cycle: they must choose how many spikes to ﬁre; what
the mean phase of those spikes is; and how concentrated those spikes are about that mean. Most
groups working on the theory of spiking oscillatory networks have considered only the second of
these – this is true, for instance, of Hopﬁeld’s work on olfactory representations [2] and Yoshioka’s
[3] and Lengyel & Dayan’s work [4] on analog associative memories in CA3. Since neurons do re-
ally ﬁre more or less than one spike per cycle, and furthermore in a way that can be informationally
rich [5, 6], this poses a key question as to what the other dimensions convey.
The number of spikes per cycle is an obvious analog of a conventional ﬁring rate. Recent sophis-
ticated models of ﬁring rates of single neurons and neural populations treat them as representing
uncertainty about the quantities coded, partly driven by the strong psychophysical and computa-
tional evidence that uncertainty plays a key role in many aspects of neural processing [7, 8, 9].
Single neurons can convey the certainty of a binary proposition by ﬁring more or less strongly
[10, 11]; a whole population can use ﬁring rates to convey uncertainty about a collectively-coded
analog quantity [12].
However, if neurons can ﬁre multiple spikes per cycle, then the degree to which the spikes are
concentrated around a mean phase is an additional channel for representing information. Concen-
tration is not merely an abstract quantity; rather we can expect that the effect of the neuron on its
postsynaptic partners will be strongly inﬂuenced by the burstiness of the spikes, an effect apparent,
for instance, in the complex time-courses of short term synaptic dynamics. Here, we suggest that

concentration codes for the uncertainty about phase – highly concentrated spiking represents high
certainty about the mean phase in the cycle.
One might wonder whether uncertainty is actually important for the cases of oscillatory processing
that have been identiﬁed. One key computation for spiking oscillatory networks is memory retrieval
[3, 4]. Although it is not often viewed this way, memory retrieval is a genuinely probabilistic task
[13, 14], with the complete answer to a retrieval query not being a single memory pattern, but rather
a distribution over memory patterns. This is because at the time of the query the memory device
only has access to incomplete information regarding the memory trace that needs to be recalled.
Most importantly, the way memory traces are stored in the synaptic weight matrix implies a data
lossy compression algorithm, and therefore the original patterns cannot be decompressed at retrieval
with absolute certainty.
In this paper, we ﬁrst describe how oscillatory structures can use all three activity characteristics
at their disposal to represent two pieces of information and two forms of uncertainty (Section 2).
We then suggest that this representational scheme is appropriate as a model of uncertainty-aware
probabilistic recall in CA3. We derive the recurrent neural network dynamics that manipulate these
ﬁring characteristics such that by the end of the retrieval process neurons represent a good approx-
imation of the posterior distribution over memory patterns given the information in the recall cue
and in the synaptic weights between neurons (Section 3). We show in numerical simulations that the
derived dynamics lead to competent memory retrieval, supplemented by uncertainty signals that are
predictive of retrieval errors (Section 4).

2 Representation

Single cell The heart of our proposal is a suggestion for how to interpret the activity of a single
neuron in a single oscillatory cycle (such as a theta-cycle in the hippocampus) as representing a
probability distribution. This is a signiﬁcant extension of standard work on single-neuron represen-
tations of probability [12]. We consider a distribution over two random variables, z ∈ {0, 1}, a
Bernoulli variable (for the case of memory, representing the participation of the neuron in the mem-
ory pattern), and x ∈ [0, T ), where T is the period of the underlying oscillation, a real valued phase
variable (representing an analog quantity associated with that neuron if it participates in that pattern).
This distribution is based on three quantities associated with the neuron’s activity (ﬁgure 1A):

r the number of spikes in a cycle,
φ the circular mean phase of those spikes, under the assumption that there is at least one spike,
c the concentration of the spikes (mean resultant length of their phases, [15]), which measures how
tightly clustered they are about φ

In keeping with conventional single-neuron models, we treat r , via a (monotonically increasing)
probabilistic activation function 0 ≤ ρ(r) ≤ 1, as describing the probability that z = 1 (ﬁgure 1B),
so the distribution is q (z ; r) = ρ (r)z (1 − ρ (r))1−z . We treat the implied distribution over the true
phase x as being conditional on z . If z = 0, then the phase is undeﬁned. However, if z = 1, then the
distribution over x is a mixture of qu (x), a uniform distribution on [0, T ), and a narrow, quasi-delta,
distribution q⊥ (x; φ) (of width  (cid:28) T ) around the mean ﬁring phase (φ) of the spikes. The mixing
proportion in this case is determined by a (monotonically increasing) function 0 ≤ γ (c) ≤ 1 of the
concentration of the spikes. In total:
q (x, z ; φ, c, r) = [ρ (r) [γ (c) q⊥ (x; φ) + (1 − γ (c)) qu (x)]]z (1 − ρ (r))1−z
(1)
as shown in ﬁgure 1C. The marginal conﬁdence in φ being correct is thus λ (c, r) = γ (c) · ρ (r),
which we call ‘burst strength’. We can rewrite equation 1 in a more convenient form:
q (x, z ; φ, c, r) = [λ (c, r) q⊥ (x; φ) + (ρ (r) − λ (c, r)) qu (x)]z (1 − ρ (r))1−z

(2)

Population In the case of a population of neurons, the complexity of representing a full joint dis-
tribution P[x, z] over random variables x = {xi }, z = {zi } associated with each neuron i grows
exponentially with the number of neurons N . The natural alternative is to consider an approxima-
tion in which neurons make independent contributions, with marginals as in equation 2. The joint

Figure 1: Representing uncertainty. A) A neuron’s ﬁring times during a period [0, T ) are described
by three parameters: r , the number of spikes; φ the mean phase of those spikes; and c, the phase
concentration. B) The ﬁring rate r determines the probability ρ(r) that a Bernoulli variable associ-
ated with the unit takes the value z = 1. C) If z = 1, then φ and c jointly deﬁne a distribution over
phase which is a mixture (weighted by γ (c)) of a distribution peaked at φ and a uniform distribution.
Q (x, z; φ, c, r) = Q
whose complexity scales linearly with N .

i q (xi , zi ; φi , ci , ri )

distribution is then

(3)

Dynamics When the actual distribution P the population has to represent lies outside the class of
representable distributions Q in equation 3 with independent marginals, a key computational step is
to ﬁnd activity parameters φ, c, r for the neurons that make Q as close to P as possible. One way to
formalize the discrepancy between the two distributions is the KL-divergence
F (φ, c, r) = KL [Q (x, z; φ, c, r) k P (x, z)]
Minimizing this by gradient descent
= − ∂
= − ∂
= − ∂
F (φ, c, r)
dφi
dci
dri
dt
∂ ri
∂ ci
∂φi
dt
dt
deﬁnes dynamics for the evolution of the parameters. In general, this couples the activities of neu-
rons, deﬁning recurrent interactions within the network.1
We have thus suggested a general representational framework, in which the speciﬁcation of a com-
putational task amounts to deﬁning a P distribution which the network should represent as best as
possible. Equation 5 then deﬁnes the dynamics of the interaction between the neurons that optimizes
the network’s approximation.

F (φ, c, r)

F (φ, c, r)

τ

(4)

(5)

τ

τ

3 CA3 memory

One of the most widely considered tasks that recurrent neural networks need to solve is that of
autoassociative memory storage and retrieval. Moreover, hippocampal area CA3, which is thought
to play a key role in memory processing, exhibits oscillatory dynamics in which ﬁring phases are
known to play an important functional role. It is therefore an ideal testbed for our theory.
We characterize the activity in CA3 neurons during recall as representing the probability distribution
over memories being recalled. Treating storage from a statistical perspective, we use Bayes rule to
deﬁne a posterior distribution over the memory pattern implied by a noisy and impartial cue. This
distribution is represented approximately by the activities φi , ri , ci of the neurons in the network as
in equation 3. Recurrent dynamics among the neurons as in equation 5 ﬁnd appropriate values of
these parameters, and model network interactions during recall in CA3.

Storage We consider CA3 as storing patterns in which some neurons are quiet (zm
i = 0, for the
i = 1); their activity then deﬁning
ith neuron in the mth pattern); and other neurons are active (zm
1Of course, the ﬁring rate is really an integer variable, since it is an actual number of spikes per cycle. For
simplicitly, in the simulations below, we considered real-valued ﬁring rates – an important next step is to drop
this assumption.

Cφr=2cq(z ; r)z10ρ(r)q(x | z=1; φ, c)x0Tγ(c)φε BAm ∈ [0, T ), where T is the period of the population oscillation. M such memory
a ﬁring phase (xi
P [x, z] = Q
traces, each drawn from an (iid) prior distribution,
i [pz P (xi )]zi (1 − pz )1−zi ,
(where pz is the prior probability of ﬁring in a memory pattern; P (x) is the prior distribution for
ﬁring phases) are stored locally and additively in the recurrent synaptic weight matrix of a network
(cid:1) for i 6= j , and Wii = 0
j Ω (cid:0)xm
Wij = PM
of N neurons, W, according to learning rule Ω:
i , xm
i zm
m=1 zm
j
We assume that Ω is T ¨oplitz and periodic in T , and either symmetric or anti-symmetric:
Ω (x1 , x2 ) = Ω (x1 − x2 ) = Ω (x1 − x2 mod T ) = ±Ω (x2 − x1 ).

(6)

(7)

Posterior for memory recall Following [14, 4], we characterize retrieval in terms of the posterior
distribution over x, z given three sources of information: a recall cue (˜x, ˜z), the synaptic weight ma-
trix, and the prior over the memories. Under some basic independence assumptions, this factorizes
into three terms
P [x, z | ˜x, ˜z, W] ∝ P [x, z] · P [˜x, ˜z | x, z] · P [W | x, z]
(8)
The ﬁrst term is the prior (equation 6). The second term is the likelihood of receiving noisy or partial
(cid:21)zi (cid:20)(cid:16)
(cid:21)1−zi
(cid:20)(cid:16)
(cid:17) ˜zi
(cid:17) ˜zi (1 − η1 )1− ˜zi
P [˜x, ˜z | x, z] = Y
recall cue (˜x, ˜z) if the true pattern to be recalled was (x, z):
(1 − η0 ) ˜P0 ( ˜xi )
η1 ˜P1 ( ˜xi | xi )
i
where η1 = P [ ˜z = 1 | z = 1] and η0 = P [ ˜z = 0 | z = 0] are the probabilities of the presence or
absence of a spike in the input given the presence or absence of a spike in the memory to be recalled,
˜P1 ( ˜x | x) and ˜P0 ( ˜x) are distributions of the phase of an input spike if there was or was not a spike
(cid:17)1/2 .
ing (x, z). Making a factorized approximation P [W | x, z] ’ (cid:16)Q
in the memory to be recalled.
The last term in equation 8 is the likelihood that weight matrix W arose from M patterns includ-
i,j 6=i P [Wij | xi , zi , xj , zj ]
Since the learning rule is additive and memory traces are drawn iid, the likelihood of a synaptic
(cid:21)
(cid:20)
weight is approximately Gaussian for large M , with a quadratic log-likelihood [4]:
(Wij − µW ) Ω (xi , xj ) − 1
log P [Wij | xi , zi , xj , zj ] +c= zi zj
Ω2 (xi , xj )
2
σ2
W
W are the mean and variance of the distribution of synaptic weights after storing
where µW and σ2
M − 1 random memory traces (µW = 0 for antisymmetric Ω).

η1− ˜zi
0

(10)

(9)

Dynamics for memory recall Plugging the posterior from equation 8 to the general dynamics
equation 5 yields the neuronal update rules that will be appropriate for uncertainty-aware memory
recall, and which we treat as a model of recurrent dynamics in CA3.
We give the exact formulæ for the dynamics in the supplementary material. They can be shown
to couple together the various activity parameters of the neurons in appropriate ways, for instance
weighting changes to φi for neuron i according to the burst strength of its presynaptic inputs, and
increasing the concentration when the log posterior of the ﬁring phase of the neuron, given that it
should ﬁre, log P[φi |zi = 1, ˜x, ˜z, W], is greater than the average of the log posterior.
These dynamics generalize, and thus inherit, some of the characteristics of the purely phase-based
network suggested in [4]. This means that they also inherit the match with physiologically-measured
phase response curves (PRCs) from in vitro CA3 neurons that were measured to test this suggestion
[16]. The key difference here is that we expect the magnitude (though not the shape) of the inﬂuence
of a presynaptic neuron on the phase of a postsynaptic one to scale with its rate, for high concentra-
tion. Preliminary in vitro results show that PRCs recorded in response to burst stimulation are not
qualitatively different from PRCs induced by single spikes; however, it remains to be seen if their
magnitude scales in the way implied by the dynamics here.

Figure 2: A single retrieval trial in the network. Time evolution of ﬁring phases (left panels),
concentrations (middle panels), and rates (right panels) of neurons that should (top row) or should
not (bottom row) participate in the memory pattern being retrieved. Note that ﬁring phases in the top
row are plotted as a difference from the stored ﬁring phases so that φ = 0 means perfect retrieval.
Color code shows precision (blue: low, yellow: high) of the phase of the input to neurons, with red
lines showing cells receving incorrect input rate.

4 Simulations

Figure 2 shows the course of recall in the full network (with N = 100 neurons, and 10 stored patterns
with pz = 0.5). For didactic convenience, we consider the case that the noise in the phase input
was varied systematically for different neurons within a recall cue (a fact known to the network, ie
incorporated into its dynamics), so that it is possible to see how the differential certainty evolves over
the course of the network’s dynamics. The top left panel shows that neurons that should ﬁre in the
memory trace (ie for which z = 1) quickly converge on their correct phase, and that this convergence
usually takes a longer time for neurons receiving more uncertain input. This is paralleled by the
way their ﬁring concentrations change (top middle panel): neurons with reliable input immediately
increase their concentrations from the initial γ (c) = 0.5 value to γ (c) = 1, while for those having
more unreliable input it takes a longer time to build up conﬁdence about their ﬁring phases (and by
the time they become conﬁdent their phases are indeed correct). Neurons that should not ﬁre (z = 0)
build up their conﬁdence even more slowly, more often remain fairly uncertain or only moderately
certain about their ﬁring phases, as expressed by their concentrations (middle bottom panel) – quite
righteously. Finally, since the ﬁring rate input to the network is correct 90%, most neurons that
should or should not ﬁre do or do not ﬁre, respectively, with maximal certainty about their rate (top
and bottom right panels).
Various other metrics are important for providing insight into the operation of the network.
In
particular, we may expect there to be a relationship between the actual error in the phase of ﬁring
of the neurons recalled by the memory, and the ﬁring rates and concentrations (in the form of burst
strengths) of the associated neurons themselves. Neurons which are erring should whisper rather
than shout. Figure 3A shows just this for the network. Here, we have sorted the neurons according to
their burst strengths λ, and plotted histograms of errors in ﬁring phase for each group. The lower the
burst strength, the more likely are large errors – at least to an approximation. A similar relationship
exists between recalled (analogue) and stored (binary) ﬁring rates, where extreme values of the
recalled ﬁring rate indicate that the stored ﬁring rate was 0 or 1 with higher certainty (Figure 3B).
Figure 3C shows the results of a related analysis of experimental data kindly donated by Francesco
Battaglia. He recorded neurons in hippocampal area CA1 (not CA3, although we may hope for
some similar properties) whilst rats were shuttling on a linear track for food reward. CA1 neurons
have place ﬁelds – locations in the environment where they respond with spikes – and the phases of
these spikes relative to the ongoing theta oscillation in the hippocampus are also known to convey
information about location in space [5]. To create the plot, we ﬁrst selected epochs with high-
quality and high power theta activity in the hippocampus (to ensure that phase is well estimated).
We then computed the mean ﬁring phase within the theta cycle, φ, of each neuron as a function of the
location of the rat, separately for each visit to the same location. We assumed that the ‘true’ phase
x a neuron should recall at a given location is the average of these phases across different visits. We

012345!202z=1Phase error01234500.51z=1Concentration01234500.51z=1Firing rate01234505z=0TimePhase01234500.51z=0TimeConcentration01234500.51z=0TimeFiring rateA

B

C

Figure 3: Uncertainty signals are predictive of the error a cell is making both in simulation (A,B),
and as recorded from behaving animals (C). Burst strength signals overall uncertainty about and thus
predicts error in mean ﬁring phase (A,C), while graded ﬁring rates signal certainty about whether to
ﬁre or not (B).

then evaluated the error a neuron was making at a given location on a given visit as the difference
between its φ in that trial at that location and the ‘true’ phase x associated with that location. This
allowed us to compute statistics of the error in phase as a function of the burst strength. The curves
in the ﬁgure show that, as for the simulation, burst strength is at least partly inversely correlated with
actual phase error, deﬁned in terms of the overall activity in the population. Of course, this does not
constitute a proof of our representational theory.
One further way to evaluate the memory is to compare it to two existing associative memories that
have previously been studied, and can be seen as special cases. On one hand, our memory adds
the dimension of phase to the uncertainty-aware rate-based memory that Sommer & Dayan [14]
studied. This memory made a somewhat similar variational approximation, but, as for the mean-
ﬁeld Boltzmann machine [17], only involving r and ρ(r) and no phases.
On the other hand, the memory device can be seen as adding the dimension of rate to the phase-based
memory that Lengyel & Dayan [4] treated. Note, however, that although this phase-based network
used superﬁcially similar probabilistic principles to the one we have developed here, in fact it did
not operate according to uncertainty, since it made the key simpliﬁcation that all neurons participate
in all memories, and that they also ﬁre exactly one spike on every cycle during recall. This restricted
the dynamics of that network to perform maximum a posteriori (MAP) inference to ﬁnd the single
recalled pattern of activity that best accommodated the probabilistic constraints of the cue, the prior
and the synaptic weights, rather than being able to work in the richer space of probabilistic recall of
the dynamics we are suggesting here.
Given these roots, we can follow the logic in ﬁgure 4 and compare the performance of our memory
with these precursors in the cases for which they are designed. For instance, to compare with the
rate-based network, we construct memories which include phase information. During recall, we
present cues with relatively accurate rates, but relatively inaccurate phases, and evaluate the extent
to which the network is perturbed by the presence of the phases (which, of course, it has to store
in the single set of synaptic weights). Figure 4A shows exactly this comparison. Here, a relatively
small network (N = 100) was used, with memories that are dense (pz = 0.5), and it is therefore
a stringent test of the storage capacity. Performance is evaluated by calculating the average error
made in recalled ﬁring rates).
In the ﬁgure, the two blue curves are for the full model (with the phase information in the input
being relatively unreliable, its circular concentration parameter distributed uniformly between 0.1
and 10 across cells); the two yellow curves are for a network with only rates (which is similar to
that described, but not simulated, by Sommer & Dayan [14]). Exactly the same rate information
is provided to all networks, and is 10% inaccurate (a degree known to the dynamics in the form of
η0 and η1 ). The two ﬂat dashed lines show the performance in the case that there are no recurrent
synaptic weights at all. This is an important control, since we are potentially presenting substantial
information in the cues themselves. The two solid curves show that the full model tracks the reduced,
rate-based, model almost perfectly until the performance totally breaks down. This shows that the
phase information, and the existence of phase uncertainty and processing during recall, does not

!"0"00.10.20.30.40.50.6Error in firing phaseFrequency0.050.20.40.7burst strength00.20.40.60.8100.20.40.60.81Retrieved firing rateStored firing rate!"0"00.10.2‘Error’ in firing phaseFrequencyburst strength(spikes / cycle)0!0.50.5!1.51.5!2.52.5!3.53.5!4.5A

B

Figure 4: Recall performance compared with a rate-only network (A) and a phase-only network (B).
The full model (blue lines) performs just as well as the reduced ‘specialist’ models (yellow lines)
in comparable circumstances (when the information provided to the networks in the dimension they
shared is exactly the same). All models (solid lines) outperform the standard control of using the
input and the prior alone (dashed lines).

corrupt the network’s capacity to recall rates. Given its small size, the network is quite competent
as an auto-associator.
Figure 4B shows a similar comparison between this network and a network that only has to deal
with uncertainty in ﬁring phases but not in rates. Again, its performance at recalling phase, given
uncertain and noisy phase cues, but good rate-cues, is exactly on a par with the pure, phase-based
network. Further, the average errors are only modest, so the capacity of the network for storing
analog phases is also impressive.

5 Discussion

We have considered an interpretation of the activities of neurons in oscillating structures such as area
CA3 of the hippocampus as representing distributions over two underlying quantities, one binary and
one analogue. We also showed how this representational capacity can be used to excellent effect in
the key, uncertainty-sensitive computation of memory recall, an operation in which CA3 is known to
be involved. The resulting network model of CA3 encompasses critical aspects of its physiological
properties, notably information-bearing ﬁring rates and phases. Further, since it generalizes earlier
theories of purely phase-based memories, this model is also consistent with the measured phase
response curves of CA3 neurons, which characterize their actual dynamical interactions.
Various aspects of this new theory are amenable to experimental investigation. First, the full dy-
namics (see the supplementary material) imply that ﬁring rate and ﬁring phase should be coupled
together both pre-synpatically, in terms of the inﬂuence of timed input spikes, and post-synaptically,
in terms of how changes in the activity of a neuron should depend on its own activity. In vitro ex-
periments along the lines of those carried out before [16], in which we have precise experimental
control over pre- and post-synaptic activity can be used to test these predictions. Further, making
the sort of assumptions that underlie ﬁgure 3C, we can use data from awake behaving rats to see if
the gross statistics of the changes in the activity of the neurons ﬁt the expectations licensed by the
theory.
From a computational perspective, we have demonstrated that the network is a highly competent
associative memory, correctly recalling both binary and analog information, along with certainty
about it, and degrading gracefully in the face of overload. In fact, compared with the representation
of other analogue quantities (such as the orientation of a visually preseted bar), analogue memory
actually poses a particularly tough problem for the representation of uncertainty. This is because
for variables like orientation, a whole population is treated as being devoted to the representation
of the distribution of a single scalar value. By contrast, for analogue memory, each neuron has an
independent analogue value, and so the dimensionality of the distribution scales with the number of
neurons involved. This extra representational power comes from the ability of neurons to distribute

110100100000.050.10.150.20.250.30.350.40.45Number of stored patternsAverage errorrate!coded model w/o learningrate!coded modelfull model w/o learningfull model11010010000.10.20.30.40.50.60.70.80.9Number of stored patternsAverage errorphase!coded model w/o learningphase!coded modelfull model w/o learningfull modeltheir spikes within a cycle to indicate their uncertainty about phase (using the dimension of time in
just the same way that distributional population codes [12] used the dimension of neural space).
This dimension for representing analogue uncertainty is coupled to that of the ﬁring rate for repre-
senting binary uncertainty, since neurons have to ﬁre multiple times in a cycle to have a measurable
lack of concentration. However, this coupling is exactly appropriate given the form of the distribu-
tion assumed in equation 2, since weakly ﬁring neurons express only weak certainty about phase
in any case. In fact, it is conceivable that we could combine a different model for the ﬁring rate
uncertainty with this model for analogue uncertainty, if, for instance, it is found that neuronal ﬁring
rates covary in ways that are not anticipated from equation 2.
Finally, the most important direction for future work is understanding the uncertainty-sensitive cou-
pling between multiple oscillating memories, where the oscillations, though dynamically coordi-
nated, need not have the same frequencies. Exactly this seems to characterize the interaction be-
tween the hippocampus and the necortex during both consolidation and retrieval [18, 19].

Acknowledgments

Funding from the Gatsby Charitable Foundation. We are very grateful to Francesco Battaglia for
allowing us to use his data to produce ﬁgure 3C, and to him, and Ole Paulsen and Jeehyun Kwag for
very helpful discussions.

References
[1] Szaliszny ´o K, ´Erdi P. In The Handbook of Brain Theory and Neural Networks, 533, 2003.
[2] Hopﬁeld JJ. Nature 376:33, 1995.
[3] Yoshioka M. Physical Review E 65, 2001.
[4] Lengyel M, Dayan P. In Advances in Neural Information Processing Systems 17, 769, Cambridge, MA,
2005. MIT Press.
[5] O’Keefe J, Recce ML. Hippocampus 3:317, 1993.
[6] Huxter J, et al. Nature 425:828, 2003.
[7] Ernst M, Banks M. Nature 415:429, 2002.
[8] K ¨ording K, Wolpert D. Nature 427:244, 2004.
[9] Gold JI, Shadlen MN. Neuron 36:299, 2002.
[10] Hinton G. Neural Comput 1:143, 1990.
[11] Peterson C, Anderson J. Complex Systems 1:995, 1987.
[12] Pouget A, et al. Annu Rev Neurosci 26:381, 2003.
[13] MacKay DJC. In Maximum Entropy and Bayesian Methods, Laramie, 1990, 237, 1991.
[14] Sommer FT, Dayan P. IEEE Trans Neural Netw 9:705, 1998.
[15] Fisher NI. Statistical analysis of circular data. Cambridge University Press, 1995.
[16] Lengyel M, et al. Nat Neurosci 8:1677, 2005.
[17] Dayan P, Abbott LF. Theoretical Neuroscience. MIT Press, 2001.
[18] Siapas AG, Wilson MA. Neuron 21:1123, 1998.
[19] Jones M, Wilson M. PLoS Biol 3:e402, 2005.

