Dirichlet-Enhanced Spam Filtering
based on Biased Samples

Steffen Bickel and Tobias Scheffer
Max-Planck-Institut f ¨ur Informatik, Saarbr ¨ucken, Germany
{bickel, scheffer}@mpi-inf.mpg.de

Abstract

We study a setting that is motivated by the problem of ﬁltering spam messages
for many users. Each user receives messages according to an individual, unknown
distribution, reﬂected only in the unlabeled inbox. The spam ﬁlter for a user is
required to perform well with respect to this distribution. Labeled messages from
publicly available sources can be utilized, but they are governed by a distinct dis-
tribution, not adequately representing most inboxes. We devise a method that min-
imizes a loss function with respect to a user’s personal distribution based on the
available biased sample. A nonparametric hierarchical Bayesian model further-
more generalizes across users by learning a common prior which is imposed on
new email accounts. Empirically, we observe that bias-corrected learning outper-
forms naive reliance on the assumption of independent and identically distributed
data; Dirichlet-enhanced generalization across users outperforms a single ( “one
size ﬁts all ”) ﬁlter as well as independent ﬁlters for all users.

1 Introduction

Design and analysis of most machine learning algorithms are based on the assumption that the train-
ing data be drawn independently and from the same stationary distribution that the resulting model
will be exposed to. In many application scenarios, however, control over the data generation pro-
cess is less perfect, and so this iid assumption is often a naive over-simpli ﬁcation. In econometrics,
learning from biased samples is a common phenomenon, where the willingness to respond to sur-
veys is known to depend on several characteristics of the person queried; work that led to a method
for correcting sample selection bias for a class of regression problems has been distinguished by a
Nobel Prize [6]. In machine learning, the case of training data that is only biased with respect to the
ratio of class labels has been studied [4, 7]. Zadrozny [14] has derived a bias correction theorem that
applies when the bias is conditionally independent of the class label given the instance, and when
every instance has a nonzero probability of being drawn into the sample. Sample bias correction for
maximum entropy density estimation [3] and the analysis of the generalization error under covariate
shift [12] follow the same intuition.

In our email spam ﬁltering setting, a server handles many email accounts (in case of our industrial
partner, several millions), and delivers millions of emails per day. A magnitude of spam and “ham”
(i.e., non-spam) sources are publicly available. They include collections of emails caught in “spam
traps”
– email addresses that are published on the web in an invisible font and are harvested by
spammers [11] – the Enron corpus that was disclosed in the course of the Enron trial [8], and Spam-
Assassin data. These collections have diverse properties and none of them represents the global
distribution of all emails, let alone the distribution received by some particular user. The resulting
bias does not only hinder learning, but also leads to skewed accuracy estimates, since individuals
may receive a larger proportion of emails that a ﬁlter classiﬁes less con ﬁdently.

The following data generation model is paramount to our problem setting. An unknown process,
characterized by a distribution p(θi |β ), generates parameters θi . The θi parameterize distributions
p(x, y |θi ) over instances x (emails) and class labels y . Each p(x, y |θi ) corresponds to the i-th user’s
distribution of incoming spam (y = +1) or ham (y = −1) messages x.
The goal is to obtain a classiﬁer fi : x (cid:55)→ y for each θi that minimizes the expectation of some loss
function E(x,y)∼θi [(cid:96)(f (x), y)], deﬁned with respect to the (unknown) distribution θi .
Labeled training data L are drawn from a blend of data sources (public email archives), resulting in
a density p(x, y |λ) = p(x|λ)p(y |x, λ) with parameter λ that governs L. The relation between the
θi and λ is such that (a) any x that has nonzero probability density p(x|λ) of being drawn into the
sample L also has a nonzero probability p(x|θi ) under the target distributions θi ; and (b) the concept
of spam is consensual for all users and the labeled data; i.e., p(y |x, λ) = p(y |x, θi ) for all users i.
In addition to the (nonempty) labeled sample, zero or more unlabeled data Ui are available for each
θi and are drawn according to θi . The unlabeled sample Ui is the inbox of user i. The inbox is
empty for a newly established account and grows from there on. Our problem setting corresponds
to an application scenario in which users are not prepared to manually tag spam messages in their
inbox. Due to privacy and legal constraints, we are not allowed to personally read (or label) any
single personal email; but the unlabeled messages may be used as input to an automated procedure.
The individual distributions θi are neither independent (identical spam messages are sent to many
users), nor are they likely to be identical: distributions of inbound messages vary greatly between
(professional, recreational, American, Chinese, . . . ) email users. We develop a nonparametric hier-
archical Bayesian model that allows us to impose a common prior on new θi . Such generalization
may be particularly helpful for users with little or no available data Ui . The desired outcome of the
learning process is an array of personalized spam ﬁlters for all users.

The rest of this paper is structured as follows. We devise our solution in Section 2. In Section 3,
we study the effectiveness of correcting sample bias for spam, and of using a Dirichlet process to
generalize across users, experimentally. Section 4 concludes.

2 Learning from Biased Data
The available labeled data L are governed by p(x|λ); directly training a classiﬁer on L would there-
fore minimize the expected loss E(x,y)∼λ [(cid:96)(f (x), y)] with respect to p(x|λ). By contrast, the task is
fi that minimize, for user i, the expected loss E(x,y)∼θi [(cid:96)(f (x), y)] with respect to
to ﬁnd classiﬁers
p(x|θi ). We can minimize the loss with respect to θi from a sample L whose instances are governed
by λ when each instance is re-weighted. The weights have to be chosen such that minimizing the
loss on the weighted sample L amounts to minimizing the loss with respect to θi .
In order to derive weighting factors with this property, consider the following model of the process
that selects the labeled sample L. After drawing an instance x according to p(x|θi ), a coin s is
tossed with probability p(s|x, θi , λ). We move x into the labeled sample (and add the proper class
label) if s = 1; otherwise, x is discarded. Our previous assumption that any x with positive p(x|λ)
also has a positive p(x|θi ) implies that there exists a p(s|x, θi , λ) such that
p(x|λ) ∝ p(x|θi )p(s = 1|x, θi , λ).
(1)
That is, repeatedly executing the above process with an appropriate p(s|x, θi , λ) will create a sample
of instances governed by p(x|λ). Equation 1 deﬁnes p(s|x, θi , λ); the succeeding subsections will
be dedicated to estimating it from the available data. Since p(s|x, θi , λ) describes the discrepancy
between the sample distribution p(x|λ) and the target p(x|θi ), we refer to it as the sample bias.
But let us ﬁrst show that minimizing the loss on L with instances re-weighted by p(s|x, θi , λ)−1 in
fact minimizes the expected loss with respect to θi . The rationale behind this claim deviates only
in minor points from the proof of the bias correction theorem of [14]. Proposition 1 introduces a
normalizing constant p(s = 1|θi , λ). Its value can be easily obtained as it normalizes Equation 1.
Proposition 1 The expected loss with respect to p(x, y | ¯θi ) = p(x, y |λ) p(s=1|θi ,λ)
p(s=1|x,θi ,λ) equals the ex-
pected loss with respect to p(x, y |θi ), when p(s|x, θi , λ) satisﬁes Equation 1.

Proof. Equation 2 expands the expected value and the deﬁnition of p(x, y | ¯θi ) in Proposition 1.
Equation 3 splits p(x, y |λ). We apply the deﬁnition of p(s|x, θi , λ) (Equation 1) and obtain Equa-
(cid:90)
tion 4. Equation 4 is rewritten as an expected value.
(cid:96)(f (x), y)p(x, y |λ) p(s = 1|θi , λ)
(cid:90)
p(s = 1|x, θi , λ) d(x, y)
(cid:96)(f (x), y)p(y |x, λ)p(x|λ) p(s = |θi , λ)
(cid:90)
p(s = 1|x, θi , λ) d(x, y)
(3)
(cid:96)(f (x), y)p(y |x, θi )p(x|θi )d(x, y) = E(x,y)∼θi [(cid:96)(f (x), y)] (4)

E(x,y)∼ ¯θi [(cid:96)(f (x), y)] =

(2)

=

=

2.1
Individualized Bias Estimation
Equation 1 says that there is an unknown p(s|x, θi , λ) with p(x|λ) ∝ p(x|θi )p(s = 1|x, θi , λ)
which we call the sample bias. We will now discuss how to obtain an estimate ˆpI (s|x, θi , λ). The
individualized empirical sample bias is an estimate of the unknown true bias, conditioned on a user’s
unlabeled inbox Ui and labeled data L; hence, ˆpI (s|x, θi , λ) = p(s|x, Ui , L).
Equation 1 immediately implies

p(s = 1|x, θi , λ) ∝ p(x|λ)
(5)
p(x|θi ) ,
but neither p(x|λ) nor p(x|θi ) are known. However, distribution p(x|λ) is reﬂected in the labeled
sample L, and distribution p(x|θi ) in the unlabeled inbox Ui . Instances in L are examples that have
been selected into the labeled sample; i.e., s = 1|x ∈ L. Instances in Ui have not been selected into
the labeled sample; i.e., s = 0|x ∈ Ui . We deﬁne sUi ,L to be the vector of selection decisions for all
instances in Ui and L. That is, sUi ,L contains |Ui | elements that are 0, and |L| elements that are 1.
A density estimator ˆp(s|x, λ, θi ) can be trained on the instances in L and Ui , using vector sUi ,L as
target variable. We use a regularized logistic regression density estimator parameterized with wi :
1
ˆpI (s = 1|x, λ, θi ) = p(s = 1|x; wi ) =
1 + e(cid:104)wi ,x(cid:105) .
(cid:89)
(cid:89)
The likelihood of the density estimator is
p(s = 1|x(cid:96) , w).
p(s = 0|xu , w)
P (sUi ,L |w, Ui , L) =
(7)
x(cid:96)∈L
xu∈Ui
We train parameters wi = argmaxw log P (sUi ,L |w, Ui , L) + log η(w) (we write η(w) for the
regularizer) [15] using the fast implementation of regularized logistic regression of [9].

(6)

2.2 Dirichlet-Enhanced Bias Estimation
This section addresses estimation of the sample bias p(s|x, θn+1 , λ) for a new user n + 1 by general-
izing across existing users U1 , . . . , Un . The resulting estimate ˆpD (s|x, θn+1 , λ) will be conditioned
on the new user’s inbox Un+1 and the labeled data L, but also on all other users’ inboxes. We write
ˆpD (s|x, θn+1 , λ) = p(s|x, Un+1 ; L, U1 , . . . , Un ) for the Dirichlet-enhanced empirical sample bias.
Equation 1 says that there is a p(s = 1|x, θn+1 , λ) for user n + 1 that satisﬁes Equation 5. Let
us assume a parametric form (we employ a logistic model), and let wn+1 be the parameters that
satisfy p(s = 1|x, θn+1 , λ) = p(s = 1|x; wn+1 ) ∝ p(x|λ)/p(x|θn+1 ). We resort to a Dirichlet
process (DP) [5] G(wi ) as a model for the prior belief on wn+1 given w1 , . . . , wn . Dirichlet pro-
cess G|{α, G0} ∼ DP (α, G0 ) with concentration parameter α and base distribution G0 generates
(cid:80)n
parameters wi : The ﬁrst element w1 is drawn according to G0 ; in our case, the uninformed prior. It
generates wn+1 according to Equation 8, where δ(wi ) is a point distribution centered at wi .
wn+1 |w1 , . . . , wn ∼ αG0 +
i=1 δ(wi )
α + n

(8)

Equation 9 integrates over the parameter of the bias for new user n + 1. Equation 10 splits the
posterior into the likelihood of the sample selection coin tosses and the common prior which is

(cid:90)
modeled as a Dirichlet process.
p(s|x, Un+1 ; L, U1 , . . . , Un ) =
p(s|x; w)p(w|Un+1 ; L, U1 , . . . , Un )dw
p(w|Un+1 , L, U1 , . . . , Un ) ∝ P (sUn+1 ,L |w, Un+1 , L) ˆG(w|L, U1 , . . . , Un )
Likelihood P (sUn+1 ,L |w, Un+1 , L) is resolved in Equation 7 for a logistic model of the bias.

(9)

(10)

2.3 Estimation of the Dirichlet Process
The parameters of previous users’ bias w1 , . . . , wn constitute the prior wn+1 |{wi }n
i=1 ∼ G for user
n + 1. Since the parameters wi are not observable, an estimate wn+1 |L, {Ui }n
i=1 ∼ ˆG has to be
based on the available data. Exact calculation of this prior requires integrating over the w1 , . . . , wn ;
since this is not feasible, MCMC sampling [10] or variational approximation [1] can be used.
In our application, the model of p(s|x, θi , λ) involves a regularized logistic regression in a space of
more than 800,000 dimensions. In each iteration of the MCMC process or the variational inference
(cid:80)n
of [1], logistic density estimators for all users would need to be trained—which is prohibitive. We
therefore follow [13] and approximate the Dirichlet Process as
i=1 φi δ(w∗
ˆG(w) ≈ αG0 +
i )
(11)
α + n
Compared to the original Equation 8, the sum of point distributions at true parameters wi is replaced
by a weighted sum over point distributions at pivotal w∗
i . Parameter estimation is divided in two
steps. First, pivotal models of the sample bias are trained for each user i, solely based on a user’s
inbox and the labeled data. Secondly, parameters φi are estimated using variational EM; they express
correlations between, and allow for generalization across, multiple users. Tresp and Yu [13] suggest
i ; we implement w∗
to use a maximum likelihood estimate w∗
i by training logistic regression models
p(s = 1|x; w∗
i ) =
1
(cid:104)w∗
,x(cid:105)
i = argmaxw log P (sUi ,L |w, Ui , L)+ log η(w).
with w∗
1+e
i
Algorithmically, the pivotal models are obtained analogously to the individualized estimation of the
selection bias for each user described in Section 2.1.

(12)

.

After the pivotal models have been identiﬁed, an EM algorithm maximizes the likelihood over the
parameters φi . For the E step we rely on the assumption that the posterior is a weighted sum over
point distributions at the pivotal density estimates (Equation 13). With this assumption, the posterior
(cid:88)n
is no longer a continuous distribution and the E step resolves to the computation of a discrete number
of variational parameters φij (Equation 14).
ˆp(w|Uj , L) =
φij δ(w∗
i )
(cid:80)n
i=1
φij ∝ P (sUj ,L |w∗ , Uj , L) ˆG(w∗
i )
(14)
j=1 φij . Likelihood P (sUj ,L |w∗ , Uj , L), is calculated
Equation 11 yields the M step with φi =
as in Equation 7. The entire estimation procedure is detailed in Table 1, steps 1 through 3.

(13)

2.4
Inference
Having obtained pivotal models p(s|x; w∗
i ) and parameters φi , we need to infer the Dirichlet-
enhanced empirical sample bias p(s|x, Ui ; L, U1 , . . . , Un ). During the training procedure, i is one of
the known users from U1 , . . . , Un . At application time, we may furthermore experience a message
bound for user n + 1.
(cid:90)
Without loss of generality, we discuss the inference problem for a new user n + 1. Inserting ˆG(w)
into Eqs. 9 and 10 leads to Equation 15. Expanding ˆG(w) according to Eq. 11 yields Equation 16.
(cid:90)
p(s|x, Un+1 ; L, U1 , . . . , Un ) ∝
p(s|x; w)P (sUn+1 ,L |w, Un+1 , L) ˆG(w)dw
(cid:88)n
p(s|x; w)P (sUn+1 ,L |w, Un+1 , L)G0 (w)dw
∝ α
i )P (sUn+1 ,L |w∗
p(s|x; w∗
i , Un+1 , L)φi
i=1

(15)

+

(16)

The second summand in Equation 16 is determined by summing over the pivotal models p(s|x; w∗
i ).
The ﬁrst summand can be determined by applying Bayes’ rule in Equation 17; G0 is the uninformed
(cid:90)
(cid:90)
prior; the resulting term p(s|x, Un+1 , L) = p(s|x; w∗
n+1 ) is the outcome of a new pivotal density
estimator, trained to discriminate L against Un+1 . It is determined as in Equation 12.
p(s|x; w)P (sUn+1 ,L |w, Un+1 , L)G0 (w)dw ∝
p(s|x; w)p(w|Un+1 , L)dw (17)
= p(s|x, Un+1 , L)
(18)
The Dirichlet-enhanced empirical sample bias p(s|x, Un+1 ; L, U1 , . . . , Un ) for user n + 1 is a
weighted sum of the pivotal density estimate p(s|x; w∗
n+1 ) for user n + 1, and models p(s|x; w∗
i ) of
all users i; the latter are weighted according to their likelihood P (sUn+1 ,L |w∗
i , Un+1 , L) of observ-
ing the messages of user n + 1. Inference for the users that are available at training time is carried
out in step 4(a) of the training procedure (Table 1).

Table 1: Dirichlet-enhanced, bias-corrected spam ﬁltering.

Input: Labeled data L, unlabeled inboxes U1 , . . . , Un .
1. For all users i = 1 . . . n: Train a pivotal density estimator ˆp(s = 1|x, w∗
i ) as in Eq. 12.
2. Initialize ˆG0 (w∗
i ) by setting φi = 1 for i = 1 . . . n.
3. For t = 1, . . . until convergence:
(cid:80)n
ij from Equation 14 using ˆGt−1 and the density esti-
(a) E-step: For all i, j , estimate φt
mators p(s|x, w∗
i ).
(b) M-step: Estimate ˆGt (w∗
i ) according to Equation 11 using φi =
j=1 φt
ij .
4. For all users i:
(a) For all x ∈ L: determine empirical sample bias p(s|x, Ui ; L, U1 , . . . , Un ), condi-
tioned on the observables according to Equation 16.
(b) Train SVM classiﬁer fi : X → {spam, ham} by solving Optimization Problem 1.
Return classiﬁers fi for all users i.

2.5 Training a Bias-Corrected Support Vector Machine

Given the requirement of high accuracy and the need to handle many attributes, SVMs are widely
acknowledged to be a good learning mechanism for spam ﬁltering [2]. The ﬁnal bias-corrected SVM
(cid:80)
p(s=1|θi ,λ)
fn+1 can be trained by re-sampling or re-weighting L according to s(x) =
p(s=1|x,Un+1 ;L,U1 ,...,Un ) ,
where p(s|x, Un+1 ; L, U1 , . . . , Un ) is the empirical sample bias and p(s = 1|θi , λ) is the normalizer
x∈L s(x) = |L|. Let xk ∈ L be an example that incurs a margin violation (i.e., slack
that assures
term) of ξk . The expected contribution of xk to the SVM criterion is s(x)ξk because xk will be
drawn s(x) times on average into each re-sampled data set. Therefore, training the SVM on the
re-sampled data or optimizing with re-scaled slack terms lead to identical optimization problems.
(cid:88)m
Optimization Problem 1 Given labeled data L, re-sampling weights s(x), and regularization pa-
rameter C ; over all v, b, ξ1 , . . . , ξm , minimize
1
|v|2 +C
s(x)ξk
2
k=1
subject to ∀m
k=1 yk ((cid:104)v, xk (cid:105) + b) ≥ 1 − ξk ;

∀m
k=1 ξk ≥ 0.

(19)

(20)

The bias-corrected spam ﬁlter is trained in step 4(b) of the algorithm (Table 1).

2.6

Incremental Update

The Dirichlet-enhanced bias correction procedure is intrinsically incremental, which ﬁts into the
typical application scenario. When a new user n + 1 subscribes to the email service, the prior

Table 2: Email accounts used for experimentation.

Ham
Spam
User
Enron/Williams
Dornbos spam trap (www.dornbos.com) (part 1)
Williams
spam trap of Bruce Guenter (www.em.ca/∼bruceg/spam)
Enron/Beck
Beck
Enron/Farmer
personal spam of Paul Wouters (www.xtdnet.nl/paul/spam)
Farmer
Enron/Kaminski
spam collection of SpamArchive.org (part 1)
Kaminski
Enron/Kitchen
personal spam of the second author.
Kitchen
Enron/Lokay
spam collection of SpamAssassin (www.spamassassin.org)
Lokay
Enron/Sanders
personal spam of Richard Jones (www.annexia.org/spam)
Sanders
Usenet/de.rec.reisen.misc Dornbos spam trap (www.dornbos.com) (part 2)
German traveler
German architect Usenet/de.sci.architektur
spam collection of SpamArchive.org (part 2)

i=1 ∼ ˆG is already available. A pivotal model p(s|x, Un+1 ; L) can be trained; when
wn+1 |L, {Ui }n
Un+1 is still empty (the new user has not yet received emails), then the regularizer of the density esti-
mate p(s|x, Un+1 , L) resolves to the uniform distribution. Inference of p(s|x, Un+1 ; L, U1 , . . . , Un )
for the new user proceeds as discussed in Section 2.4.
When data Un+1 becomes available, the prior can be updated. This update is exercised by invok-
ing the EM estimation procedure with additional parameters θ∗
n+1 and φ(n+1) . The estimates of
P (sUj ,L |w∗
i , Uj , L) for all pairs of existing users i and j do not change and can be reused. The EM
procedure returns the updated prior wn+2 |L, {Ui }n+1
i=1 ∼ ˆG for the next new user n + 2.

3 Experiments

In our experiments, we study the relative beneﬁt of the following ﬁlters. The baseline is constituted
(cid:83)n+1
by a ﬁlter that is trained under
iid assumption from the labeled data. The second candidate is a “one
size ﬁts all” bias-corrected ﬁlter. Here, all users’ messages are pooled as unlabeled data and the bias
p(s|x, θn+1 , λ) is modeled by an estimator ˆpO (s|x, θn+1 , λ) = p(s|x,
i=1 Ui , L). An individ-
ually bias-corrected ﬁlter uses estimators ˆpI (s|x, θn+1 , λ) = p(s|x, Un+1 , L). Finally, we assess
the Dirichlet-enhanced bias-corrected ﬁlter. It uses the hierarchical Bayesian model to determine
the empirical bias ˆpD (s|x, θn+1 , λ) = p(s|x, Un+1 ; L, U1 , . . . , Un ) conditioned on the new user’s
messages, the labeled data, and all previous users’ messages.

Evaluating the ﬁlters with respect to the personal distributions of messages requires labeled emails
from distinct users. We construct nine accounts using real but disclosed messages. Seven of them
contain ham emails received by distinct Enron employees from the Enron corpus [8]; we use the
individuals with the largest numbers of messages from a set of mails that have been cleaned from
spam. We simulate two foreign users:
the “German traveler” receives postings to a moderated
German traveling newsgroup, the “German architect” postings to a newsgroup on architecture.

Each account is augmented with between 2551 and 6530 spam messages from a distinct source, see
Table 2. The number of ham emails varies between 1189 and 5983, reﬂecting about natural ham-
to-spam ratios. The ham section of the labeled data L contains 4000 ham emails from the Spam-
Assassin corpus, 1000 newsletters and 500 emails from Enron employee Taylor. The labeled data
contain 5000 spam emails relayed by blacklisted servers. The data are available from the authors.

The total of 76,214 messages are transformed into binary term occurrance vectors with a total of
834,661 attributes; charset and base64 decoding are applied, email headers are discarded, tokens
occurring less than 4 times are removed. SVM parameter C , concentration parameter α, and the
regularization parameter of the logistic regression are adjusted on a small reserved tuning set.
We iterate over all users and let each one play the role of the new user n + 1. We then iterate over
the size of the new user’s inbox and average 10 repetitions of the evaluation process, sampling Un+1
from the inbox and using the remaining messages as hold-out data for performance evaluation. We
train the different ﬁlters on identical samples and measure the area under the ROC curve (AUC).

Figure 1 shows the AUC performance of the iid baseline and the three bias-corrected ﬁlters for the
ﬁrst two Enron and one of the German users. Error bars indicate standard error of the difference to

Figure 1: AUC of the iid baseline and the three bias-corrected ﬁlters versus size of

|Un+1 |.

Figure 2: Average reduction of 1-AUC risk over all nine users (left); reduction of 1-AUC risk
dependent on strength of iid violation (center); number of existing users vs. training time (right).

the iid ﬁlter. Figure 2 (left) aggregates the results over all nine users by averaging the rate by which
the risk 1−AU C is reduced. We compute this reduction as 1− 1−AU Ccorrected
, where AU Ccorrected
1−AU Cbaseline
is one of the bias-corrected ﬁlters and AU Cbaseline is the AUC of the iid ﬁlter.
The beneﬁt of the individualized bias correction depends on the number of emails available for that
user; the 1 − AU C risk is reduced by 35-40% when many emails are available. The “one size ﬁts
all”
ﬁlter is almost independent of the number of emails of the new user. On average, the Dirichlet-
enhanced ﬁlter reduces the risk 1 − AU C by about 35% for a newly created account and by almost
40% when many personal emails have arrived. It outperforms the “one size ﬁts all ”
ﬁlter even for
an empty Un+1 because fringe accounts (e.g., the German users) can receive a lower weight in the
common prior. The baseline AU C of over 0.99 is typical for server-sided spam ﬁltering; a 40% risk
reduction that yields an AUC of 0.994 is still a very signiﬁcant improvement of the ﬁlter that can be
spent on a substantial reduction of the false positive rate, or on a higher rate of spam recognition.

The question occurs how strong a violation of the iid assumption the bias correction techniques can
compensate. In order to investigate, we control the violation of the iid property of the labeled data as
follows. We create a strongly biased sample by using only Enron users as test accounts θi , and not
using any Enron emails in the labeled data. We vary the proportion of strongly biased data versus
randomly drawn Enron mails in the labeled training data (no email occurs in the training and testing
data at the same time). When this proportion is zero, the labeled sample is drawn iid from the testing
distributions; when it reaches 1, the sample is strongly biased. In Figure 2 (center) we observe that,
averaged over all users, bias-correction is effective when the iid violation lies in a mid-range. It
becomes less effective when the sample violates the iid assumption too strongly. In this case, “gaps”
occur in λ; i.e., there are regions that have zero probability in the labeled data L ∼ λ but nonzero
probability in the testing data Ui ∼ θi . Such gaps render schemes that aim at reconstructing p(x|θi )
by weighting data drawn according to p(x|λ) ineffective.
Figure 2 (right) displays the total training time over the number of users. We ﬁx |Un+1 | to 16 and
vary the number of users that inﬂuence the prior. The iid baseline and the individually corrected ﬁlter
scale constantly. The Dirichlet-enhanced ﬁlter scales linearly in the number of users that constitute
the common prior; the EM algorithm with a quadratic complexity in the number of users contributes
only marginally to the training time. The training time is dominated by the training of the pivotal
models (linear complexity). The Dirichlet enhanced ﬁlter with incremental update scales favorably
compared to the “one size ﬁts all”
ﬁlter. Figure 2 is limited to the 9 accounts that we have engineered;
the execution time is in the order of minutes and allows to handle larger numbers of accounts.

 0.992 0.994 0.9962048512128328421AUCsize of user’s unlabeled inboxWilliamsDirichletone size fits allindividualiid baseline 0.986 0.988 0.99 0.9922048512128328421AUCsize of user’s unlabeled inboxBeckDirichletone size fits allindividualiid baseline 0.9968 0.997 0.99722048512128328421AUCsize of user’s unlabeled inboxGerman travelerDirichletone size fits allindividualiid baseline 0 0.1 0.2 0.3 0.42048512128328421reduction of 1-AUC risksize of user’s unlabeled inboxaverage of all nine usersDirichletone size fits allindividual 0 0.2 0.400.90.991reduction of 1-AUC riskstrength of iid violationcorrection benefit vs. iid violationindividually corrected 200 400 600 800 0 1 2 3 4 5 6 7 8secondsnumber of userstraining timeDirichlet-enhancedone size fits allDirichlet-enh. incrementalindividualiid baseline4 Conclusion

It is most natural to deﬁne the quality criterion of an email spam ﬁlter with respect to the distribution
that governs the personal emails of its user. It is desirable to utilize available labeled email data, but
assuming that these data were governed by the same distribution unduly over-simpliﬁes the problem
setting. Training a density estimator to characterize the difference between the labeled training data
and the unlabeled inbox of a user, and using this estimator to compensate for this discrepancy, im-
proves the performance of a personalized spam ﬁlter—provided that the inbox contains sufﬁciently
many messages. Pooling the unlabeled inboxes of a group of users, training a density estimator on
this pooled data, and using this estimator to compensate for the bias outperforms the individualized
bias-correction only when very few unlabeled data for the new user are available.

We developed a hierarchical Bayesian framework which uses a Dirichlet process to model the com-
mon prior for a group of users. The Dirichlet-enhanced bias correction method estimates – and com-
pensates for – the discrepancy between labeled training and unlabeled personal messages, learning
from the new user’s unlabeled inbox as well as from data of other users. Empirically, with a 35%
reduction of the 1 − AU C risk for a newly created account, the Dirichlet-enhanced ﬁlter outper-
forms all other methods. When many unlabeled personal emails are available, both individualized
and Dirichlet-enhanced bias correction reduce the 1 − AU C risk by nearly 40% on average.

Acknowledgment

This work has been supported by Strato Rechenzentrum AG and by the German Science Foundation
DFG under grant SCHE540/10-2.

References
[1] D. Blei and M. Jordan. Variational methods for the Dirichlet process. In Proceedings of the International
Conference on Machine Learning, 2004.
[2] H. Drucker, D. Wu, and V. Vapnik. Support vector machines for spam categorization. IEEE Transactions
on Neural Networks, 10(5):1048–1055, 1999.
[3] M. Dudik, R. Schapire, and S. Phillips. Correcting sample selection bias in maximum entropy density
estimation. In Advances in Neural Information Processing Systems, 2005.
[4] C. Elkan. The foundations of cost-sensitive learning. In Proceedings of the International Joint Conference
on Arti ﬁcial Intellligence , 2001.
[5] T. Ferguson. A Bayesian analysis of some nonparametric problems. Annals of Statistics, 1:209–230,
1973.
[6] J. Heckman. Sample selection bias as a speciﬁcation error. Econometrica, 47:153–161, 1979.
[7] N. Japkowicz and S. Stephen. The class imbalance problem: A systematic study. Intelligent Data Analy-
sis, 6:429–449, 2002.
[8] Bryan Klimt and Yiming Yang. The enron corpus: A new dataset for email classiﬁcation research. In
Proceedings of the European Conference on Machine Learning, 2004.
[9] P. Komarek. Logistic Regression for Data Mining and High-Dimensional Classiﬁcation . Doctoral disser-
tation, Carnegie Mellon University, 2004.
[10] R. Neal. Markov chain sampling methods for Dirichlet process mixture models. Journal of Computational
and Graphical Statistics, 9:249–265, 2000.
[11] Matthew Prince, Benjamin Dahl, Lee Holloway, Arthur Kellera, and Eric Langheinrich. Understanding
how spammers steal your e-mail address: An analysis of the ﬁrst six months of data from project honey
pot. In Proceedings of the Conference on Email and Anti-Spam, 2005.
[12] M. Sugiyama and K.-R. M ¨uller. Model selection under covariate shift. In Proceedings of the International
Conference on Artiﬁcial Neural Networks , 2005.
[13] Volker Tresp and Kai Yu. An introduction to nonparametric hierarchical Bayesian modelling with a focus
on multi-agent learning. In Switching and Learning in Feedback Systems, volume 3355 of Lecture Notes
in Computer Science, pages 290–312. Springer, 2004.
[14] Bianca Zadrozny. Learning and evaluating classiﬁers under sample selection bias. In Proceedings of the
International Conference on Machine Learning, 2004.
[15] T. Zhang and F. Oles. Text categorization based on regularized linear classiﬁers.
4(1):5–31, 2001.

Information Retrieval,

