Implicit Online Learning with Kernels

Li Cheng
S.V. N. Vishwanathan
National ICT Australia
li.cheng@nicta.com.au
SVN.Vishwanathan@nicta.com.au

Dale Schuurmans
Department of Computing Science
University of Alberta, Canada
dale@cs.ualberta.ca

Terry Caelli
National ICT Australia
terry.caelli@nicta.com.au

Shaojun Wang
Department of Computer Science and Engineering
Wright State University
shaojun.wang@wright.edu
Abstract
We present two new algorithms for online learning in reproducing kernel Hilbert
spaces. Our ﬁrst algorithm, ILK (implicit online learning with kernels), employs
a new, implicit update technique that can be applied to a wide variety of convex
loss functions. We then introduce a bounded memory version, SILK (sparse ILK),
that maintains a compact representation of the predictor without compromising
solution quality, even in non-stationary environments. We prove loss bounds and
analyze the convergence rate of both. Experimental evidence shows that our pro-
posed algorithms outperform current methods on synthetic and real data.
1
Introduction
Online learning refers to a paradigm where, at each time t, an instance xt ∈ X is presented to a
learner, which uses its parameter vector ft to predict a label. This predicted label is then compared
to the true label yt , via a non-negative, piecewise differentiable, convex loss function L(xt , yt , ft ).
The learner then updates its parameter vector to minimize a risk functional, and the process repeats.
Kivinen and Warmuth [1] proposed a generic framework for online learning where the risk func-
tional, Jt (f ), to be minimized consists of two terms: a Bregman divergence between parameters
∆G (f , ft ) := G(f ) − G(ft ) − hf − ft , ∂f G(ft )i, deﬁned via a convex function G, and the instan-
taneous risk R(xt , yt , f ), which is usually given by a function of the instantaneous loss L(xt , yt , f ).
The parameter updates are then derived via the principle
{∆G (f , ft ) + ηtR(xt , yt , f )},
Jt (f ) := argmin
ft+1 = argmin
f
f
where ηt is the learning rate. Since Jt (f ) is convex, (1) is solved by setting the gradient (or, if
necessary, a subgradient) to 0. Using the fact that ∂f ∆G (f , ft ) = ∂f G(f ) − ∂f G(ft ), one obtains
∂f G(ft+1 ) = ∂f G(ft ) − ηt∂f R(xt , yt , ft+1 ).
(2)
Since it is difﬁcult to determine ∂f R(xt , yt , ft+1 ) in closed form, an explicit update, as opposed to
the above implicit update, uses the approximation ∂f R(xt , yt , ft+1 ) ≈ ∂f R(xt , yt , ft ) to arrive at
the more easily computable expression [1]
∂f G(ft+1 ) = ∂f G(ft ) − ηt∂f R(xt , yt , ft ).
(3)
2 ||f ||2 , then ∆G (f , ft ) = 1
2 ||f − ft ||2 and ∂f G(f ) = f , and we
In particular, if we set G(f ) = 1
obtain the familiar stochastic gradient descent update
ft+1 = ft − ηt∂f R(xt , yt , ft ).
(4)
We are interested in applying online learning updates in a reproducing kernel Hilbert space (RKHS).
To lift the above update into an RKHS, H, one typically restricts attention to f ∈ H and deﬁnes [2]
||f ||2H + C · L(xt , yt , f ),
R(xt , yt , f ) := λ
(5)
2

(1)

where || · ||H denotes the RKHS norm, λ > 0 is a regularization constant, and C > 0 determines the
penalty imposed on point prediction violations.
Recall that if H is a RKHS of functions on X × Y , then its deﬁning kernel k : (X × Y )2 → R satis-
ﬁes the reproducing property; namely that hf , k((x, y), ·)iH = f (x, y) for all f ∈ H. Therefore, by
making the standard assumption that L only depends on f via its evaluations at f (x, y), one reaches
∂f L(x, y , f ) = X
the conclusion that ∂f L(x, y , f ) ∈ H, and in particular
β ˜y k((x, ˜y), ·),
˜y∈Y
for some β ˜y ∈ R. Since ∂f R(xt , yt , ft ) = λft + C · ∂f L(xt , yt , ft ), one can use (4) to obtain an
explicit update ft+1 = (1 − ηtλ)ft − ηtC · ∂f L(xt , yt , ft ), which combined with (6) shows that
tX
X
there must exist coefﬁcients αi, ˜y fully specifying ft+1 via
αi, ˜y k((xi , ˜y), ·).
˜y∈Y
i=1
In this paper we propose an algorithm ILK (implicit online learning with kernels) that solves (2)
directly, while still expressing updates in the form (7). That is, we derive a technique for computing
the implicit update that can be applied to many popular loss functions, including quadratic, hinge,
and logistic losses, as well as their extensions to structured domains (see e.g. [3])—in an RKHS. We
also provide a general recipe to check if a new convex loss function is amenable to these implicit
updates. Furthermore, to reduce the memory requirement of ILK, which grows linearly with the
number of observations (instance-label pairs), we propose a sparse variant SILK (sparse ILK) that
approximates the decision function f by truncating past observations with insigniﬁcant weights.

ft+1 =

(7)

(6)

2

Implicit Updates in an RKHS

.

(9)

(8)

As shown in (1), to perform an implicit update one needs to minimize ∆G (f , ft ) + R(xt , yt , f ). By
(cid:18) λ
(cid:19)
2 ||f ||2H , one obtains
replacing R(xt , yt , f ) with (5), and setting G(f ) = 1
1
||f ||2H + C · L(xt , yt , f )
||f − ft ||2H + ηt
ft+1 = arg min
J (f ) = argmin
2
2
f
f
Since L is assumed convex with respect to f , setting ∂f J = 0 and using an auxiliary variable
τt = ηt λ
1+ηt λ yields
ft+1 = (1 − τt )ft − (1 − τt )ηtC ∂f L(xt , yt , ft+1 ).
αi, ˜y k((xi , ˜y), ·) + X
X
t−1X
On the other hand, from the form (7) it follows that ft+1 can also be written as
αt, ˜y k((xt , ˜y), ·),
ft+1 =
˜y∈Y
˜y∈Y
i=1
∂f L(xt , yt , ft+1 ) = X
for some αj, ˜y ∈ R and j = 1, . . . , t. Since
˜y∈Y
and for ease of exposition, we assume a ﬁxed step size (learning rate) ηt = 1, consequently τt = τ ,
it follows from (9) and (10) that
for i = 1, . . . , t − 1, and ˜y ∈ Y ,
αi, ˜y = (1 − τ )αi, ˜y
(11)
for all ˜y ∈ Y .
αt, ˜y = −(1 − τ )C βt, ˜y
(12)
Note that sophisticated step size adaptation algorithms (e.g. [3]) can be modiﬁed in a straightforward
manner to work in our setting.
The main difﬁculty in performing the above update arises from the fact that βt, ˜y depends on ft+1
(see e.g. (13)) which in turn depends on βt, ˜y via αt, ˜y . The general recipe to overcome this problem
is to ﬁrst use (9) to write βt, ˜y as a function of αt, ˜y . Plugging this back into (12) yields an equation
in αt, ˜y alone, which sometimes can be solved efﬁciently. We now elucidate the details for some
well-known loss functions.

βt, ˜y k((xt , ˜y), ·),

(10)

In this case, k((xt , yt ), ·) = k(xt , ·). That is, the kernel does not depend on the
Square Loss
value of y . Furthermore, we assume that Y = R, and write
1
1
(hf (·), k(xt , ·)iH − yt )2 ,
(f (xt ) − yt )2 =
L(xt , yt , f ) =
2
2

which yields

(13)

.

.

(15a)
(15b)
(15c)

∂f L(xt , yt , f ) = (f (xt ) − yt ) k(xt , ·).
Substituting into (12) and using (9) we have
αt = −(1 − τ )C ((1 − τ )ft (xt ) + αtk(xt , xt ) − yt ).
After some straightforward algebraic manipulation we obtain the solution
αt = C (1 − τ )(yt − (1 − τ )ft (xt ))
1 + C (1 − τ )k(xt , xt )
Binary Hinge Loss As before, we assume k((xt , yt ), ·) = k(xt , ·), and set Y = {±1}. The hinge
loss for binary classiﬁcation can be written as
L(xt , yt , f ) = (ρ − yt f (xt ))+ = (ρ − yt hf , k(xt , ·)iH )+ ,
(14)
where ρ > 0 is the margin parameter, and (·)+ := max(0, ·). Recall that the subgradient is a
set, and the function is said to be differentiable at a point if this set is a singleton [4]. The binary
hinge loss is not differentiable at the hinge point, but its subgradient exists everywhere. Writing
∂f L(xt , yt , f ) = βtk(xt , ·) we have:
yt f (xt ) > ρ =⇒ βt = 0;
yt f (xt ) = ρ =⇒ βt ∈ [0, −yt ];
yt f (xt ) < ρ =⇒ βt = −yt .
We need to balance between two conﬂicting requirements while computing αt . On one hand we
want the loss to be zero, which can be achieved by setting ρ − yt ft+1 (xt ) = 0. On the other
hand, the gradient of the loss at the new point ∂f L(xt , yt , ft+1 ) must satisfy (15). We satisfy both
constraints by appropriately clipping the optimal estimate of αt .
Let ˆαt denote the optimal estimate of αt which leads to ρ − yt ft+1 (xt ) = 0. Using (9) we have
ρ − yt ((1 − τ )ft (xt ) + ˆαtk(xt , xt )) = 0, which yields
ˆαt = ρ − (1 − τ )yt ft (xt )
= yt (ρ − (1 − τ )yt ft (xt ))
.
ytk(xt , xt )
k(xt , xt )
On the other hand, by using (15) and (12) we have αt yt ∈ [0, (1 − τ )C ]. By combining the two
 ˆαt
scenarios, we arrive at the ﬁnal update
if yt ˆαt ∈ [0, (1 − τ )C ];
if yt ˆαt < 0;
0
yt (1 − τ )C if yt ˆαt > (1 − τ )C.
The updates for the hinge loss used in novelty detection are very similar.
(cid:19)
(cid:18)
Graph Structured Loss The graph-structured loss on label domain can be written as
−f (xt , yt ) + max
(∆(yt , ˜y) + f (xt , ˜y))
˜y 6=yt
+
Here, the margin of separation between labels is given by ∆(yt , ˜y) which in turn depends on the
graph structure of the output space. This a very general loss, which includes binary and multiclass
hinge loss as special cases (see e.g. [3]). We brieﬂy summarize the update equations for this case.
Let y∗ = argmax ˜y 6=yt {∆(yt , ˜y) + ft (xt , ˜y)} denote the best runner-up label for current instance
xt . Then set αt,yt = −αt,y∗ = αt , use kt (y , y 0 ) to denote k((xt , y), (xt , y 0 )) and write
−(1 − τ )ft (xt , yt ) + ∆(yt , y∗ ) + (1 − τ )ft (xt , y∗ )
ˆαt =
(kt (yt , yt ) + kt (y∗ , y∗ ) − 2kt (yt , y∗ ))

L(xt , yt , f ) =

.

(17)

αt =

(16)

αt =

(18)

The updates are now given by

0
if ˆαt < 0;
if ˆαt ∈ [0, (1 − τ )C ];
ˆαt
(1 − τ )C if ˆαt > (1 − τ )C.
Logisitic Regression Loss The logistic regression loss and its gradient can be written as
−ytk(xt , ·)
L(xt , yt , f ) = log (1 + exp(−yt f (xt ))) ,
1 + exp(yt f (xt )) .
respectively. Using (9) and (12), we obtain

∂f L(xt , yt , f ) =

(1 − τ )C yt
1 + exp(yt (1 − τ )ft (xt ) + αt ytk(xt , xt )) .
Although this equation does not give a closed-form solution, the value of αt can still be obtained by
using a numerical root-ﬁnding routine, such as those described in [5].

αt =

2.1

ILK and SILK Algorithms

We refer to the algorithm that performs implicit updates as ILK, for “implicit online learning with
kernels”. The update equations of ILK enjoy certain advantages. For example, using (11) it is easy to
tX
X
see that an exponential decay term can be naturally incorporated to down-weight past observations:
(1 − τ )t−iαi, ˜y k((xi , ˜y), ·).
ft+1 =
(19)
˜y∈Y
i=1
Intuitively, the parameter τ ∈ (0, 1) (determined by λ and η ) trades off between the regularizer and
the loss on the current sample. In the case of hinge losses—both binary and graph structured—the
weight |αt | is always upper bounded by (1 − τ )C , which ensures limited inﬂuence from outliers (cf.
(16) and (18)).
A major drawback of the ILK algorithm described above is that the size of the kernel expansion
grows linearly with the number of data points up to time t (see (10)). In many practical domains,
where real time prediction is important (for example, video surveillance), storing all the past obser-
vations and their coefﬁcients is prohibitively expensive. Therefore, following Kivinen et al. [2] and
Vishwanathan et al. [3] one can truncate the function expansion by storing only a few relevant past
observations. We call this version of our algorithm SILK, for “sparse ILK”.
Speciﬁcally, the SILK algorithm maintains a buffer of size ω . Each new point is inserted into the
buffer with coefﬁcient αt . Once the buffer limit ω is exceeded, the point with the lowest coefﬁcient
value is discarded to maintain a bound on memory usage. This scheme is more effective than the
straightforward least recently used (LRU) strategy proposed in Kivinen et al. [2] and Vishwanathan
et al. [3]. It is relatively straightforward to show that the difference between the true predictor and
its truncated version obtained by storing only ω expansion coefﬁcients decreases exponentially as
the buffer size ω increases [2].
3 Theoretical Analysis
In this section we will primarily focus on analyzing the graph-structured loss (17), establishing
relative loss bounds and analyzing the rate of convergence of ILK and SILK. Our proof techniques
adopt those of Kivinen et al. [2]. Due to the space constraints, we leave some details and analysis to
the full version of the paper. Although the bounds we obtain are similar to those obtained in [2], our
experimental results clearly show that ILK and SILK are stronger than the NORMA strategy of [2]
and its truncated variant.
3.1 Mistake Bound
We begin with a technical deﬁnition.
bounded if it satisﬁes ||ft ||2H ≤ B 2 ∀t ∈ {1, . . . , T }, P
t ||ft − ft+1 ||H ≤ D1 , and P
Deﬁnition 1 A sequence of hypotheses {(f1 , . . . , fT ) : ft ∈ H} is said to be (T , B , D1 , D2 )
t ||ft −
ft+1 ||2H ≤ D2 for some B , D1 , D2 ≥ 0. The set of all (T , B , D1 , D2 ) bounded hypothesis se-
quences is denoted as F (T , B , D1 , D2 ).

+

,

(20)

Given a ﬁxed sequence of observations {(x1 , y1 ), . . . , (xT , yT )}, and a sequence of hypotheses
{(f1 , . . . , fT ) ∈ F }, the number of errors M is deﬁned as
M := |{t : ∆f (xt , yt , y∗
t ) ≤ 0}| ,
t ) = f (xt , yt ) − f (xt , y∗
where ∆f (xt , yt , y∗
t ) and y∗
t is the best runner-up label. To keep the equa-
tions succinct, we denote ∆kt ((yt , y), ·) := k((xt , yt ), ·)−k((xt , y), ·), and ∆kt ((yt , y), (yt , y)) :=
k∆kt ((yt , y), ·)k2H = kt (yt , yt ) − 2kt (yt , y) + kt (y , y). In the following we bound the number
of mistakes M made by ILK by the cumulative loss of an arbitrary sequence of hypotheses from
F (T , B , D1 , D2 ).
Theorem 2 Let {(x1 , y1 ), . . . , (xT , yT )} be an arbitrary sequence of observations such that
(cid:0)∆(yt , yg∗
t )(cid:1), and bounded cumulative loss K := P
P
∆kt ((yt , y), (yt , y)) ≤ X 2 holds for any t, any y , and for some X > 0. For an ar-
bitrary sequence of hypotheses (g1 , · · · , gT ) ∈ F (T , B , D1 , D2 ) with average margin µ =
t ) − ∆(yt , y∗
q D2
t L(xt , yt , gt ), the num-
1| E |
t∈E
ber of mistakes of the sequence of hypotheses (f1 , · · · , fT ) generated by ILK with learning rate
(cid:19) 1
(cid:19) 1
(cid:18) K
2 (cid:18) S
ηt = η , λ = 1
T is upper-bounded by
Bη
2S
M ≤ K
+ S
2
µ2 + 2
µ2
µ2
µ
µ
√
T D2 ), µ > 0, and yg∗
t denotes the best runner-up label with

where S = X 2
4 (B 2 + BD1 + B
hypothesis gt .
When considering the stationary distribution in a separable (noiseless) scenario, this theorem allows
us to obtain a mistake bound that is reminiscent of the Perceptron convergence theorem. In partic-
ular, if we assume the sequence of hypotheses (g1 , · · · , gT ) ∈ F (T , B , D1 = 0, D2 = 0) and the
cumulative loss K = 0, we obtain a bound on the number of mistakes
M ≤ B 2X 2
.
The following theorem asserts that under mild assumptions, the cumulative risk PT
µ2
3.2 Convergence Analysis
counterpart g∗ := argming∈H PT
t=1 R(xt , yt , ft )
of the hypothesis sequence produced by ILK converges to the minimum risk of the batch learning
t=1 R(xt , yt , g) at a rate of O(T −1/2 ).
Theorem 3 Let {(x1 , y1 ), . . . , (xT , yT )} be an arbitrary sequence of observations such that
produced by ILK with learning rate ηt = ηt−1/2 , PT
∆kt ((yt , yt ), (yt , yt )) ≤ X 2 holds for any t, any y . Denote (f1 , . . . , fT ) the sequence of hypotheses
sequence, and PT
t=1 R(xt , yt , ft ) the cumulative risk of this
t=1 R(xt , yt , g) the batch cumulative risk of (g , . . . , g), for any g ∈ H. Then
R(xt , yt , ft ) ≤ TX
TX
R(xt , yt , g) + aT 1/2 + b,
t=1
t=1
λ , a = 4ηC 2X 2 + 2U 2
η , and b = U 2
TX
where U = CX
2η are constants. In particular, if
g∗ = arg min
g∈H
TX
t=1
t=1

R(xt , yt , ft ) ≤ 1
T

R(xt , yt , g∗ ) + O(T −1/2 ).

TX
t=1

1
T

(21)

(22)

we obtain

R(xt , yt , g),

tive risk P
Essentially the same theorem holds for SILK, but now with a slightly larger constant a =
In addition, denote g∗ the minimizer of the batch learning cumula-
λ )C 2X 2 + 2U 2
4 η(1 + 2
η .
t R(xt , yt , g), and f ∗ the minimizer of the minimum expected risk with R(f ∗ ) :=
minf E(x,y)∼P (x,y) R(x, y , f ). As stated in [6] for the structured risk minimization framework, as

Figure 1: The left panel depicts a synthetic data sequence containing two classes (blue crosses and red
diamonds, see the zoomed-in portion in bottom-left corner), with each class being sampled from a mix-
ture of two drifting Gaussian distributions. Performance comparison of ILK vs NORMA and truncated
NORMA on this data: Average cumulative error over 100 trials (middle), and average cumulative error
each trial (right).
the sample size T grows, T → ∞, we obtain g∗ → f ∗ in probability. This subsequently guarantees
the convergence of the average regularized risk of ILK and SILK to R(f ∗ ).
The upper bound in the above theorem can be directly plugged into Corollary 2 of Cesa-Bianchi
et al. [7] to obtain bounds on the generalization error of ILK. Let ¯f denote the average hypothesis
(cid:16)q 1
(cid:17)
produced by averaging over all hypotheses f1 , . . . , fT . Then for any δ ∈ (0, 1), with probability
at least 1 − δ , the expected risk of ¯f is upper bounded by the risk of the best hypothesis chosen in
hindsight plus a term which grows as O
.
T
4 Experiments
We evaluate the performance of ILK and SILK by comparing them to NORMA [2] and its truncated
variant. On OCR data, we also compare our algorithms to SVMD, a sophisticated step-size adap-
tation algorithm in RKHS presented in [3]. For a fair comparison we tuned the parameters of each
algorithm separately and report the best results. In addition, we ﬁxed the margin to ρ = 1 for all our
loss functions.

Binary Classiﬁcation on Synthetic Sequences The aim here is to demonstrate that ILK is better
than NORMA in coping with non-stationary distributions. Each trial of our experiment works with
2000 two-dimensional instances sampled from a non-stationary distribution (see Figure 1) and the
task is to classify the sampled points into one of two classes. The central panel of Figure 1 compares
the number of errors made by various algorithms, averaged over 100 trials. Here, ILK and SILK
make fewer mistakes than NORMA and truncated NORMA. We also tested two other algorithms,
ILK(0) obtained by setting the decay factor λ to zero, and similarly for NORMA(0). As expected,
both these variants make more mistakes because they are unable to forget the past, which is crucial
for obtaining good performance in a non-stationary environment. To further compare the perfor-
mance of ILK and NORMA we plot the relative errors of these two algorithms in the right panel of
Figure 1. As can be seen, ILK out-performs NORMA on this simple non-stationary problem.

Novelty Detection on Video Sequences As a signiﬁcant application, we applied SILK to a back-
ground subtraction problem in video data analysis. The goal is to detect the moving foreground
objects (such as cars, persons, etc) from relatively static background scenes in real time. The chal-
lenge in this application is to be able to cope with variations in lighting as well as jitter due to
shaking of the camera. We formulate the problem as a novelty detection task using a network of
classiﬁers, one for each pixel. For this task we compare the performance of SILK vs.
truncated
NORMA. (The ILK and NORMA algorithms are not suitable since their storage requirements grow
linearly). A constant buffer size ω = 20 is used for both algorithms in this application. We report
further implementation details in the full version of this paper.
The ﬁrst task is to identify people, under varying lighting conditions, in an indoor video sequence
taken with a static camera. The left hand panel of Figure 2 plots the ROC curves of NORMA and
SILK, which demonstrates the overall better performance of SILK. We sampled one of the initial
frames after the light was switched off and back on. The results are shown in the right panel of
Figure 2. As can be seen, SILK is able to recover from the change in lighting condition better than
NORMA, and is able to identify foreground objects reasonably close to the ground truth.

-400-20002004006008000500100015002000250030003500140150160170180ILK SILK ILK(0) NORMA Trunc. NORMA(0) 140160180140160180NORMA vs. ILKMistakes of ILKMistakes of NORMAFigure 2: Performance comparison of SILK vs truncated NORMA on a background subtraction (moving
object detection) task, with varying lighting conditions. ROC curve (left) and a comparison of algorithms
immediately after the lights have been switched off and on (right).

Figure 3: Performance of SILK on a road trafﬁc sequence (moving car detection) task, with a jittery
camera. Two random frames and the performance of SILK on those frames are depicted.

Our second experiment is a trafﬁc sequence taken by a camera that shakes irregularly, which creates
a challenging problem for any novelty detection algorithm. As seen from the randomly chosen
frames plotted in Figure 3 SILK manages to obtain a visually plausible detection result. We cannot
report a quantitative comparison with other methods in this case, due to the lack of manually labeled
ground-truth data.
Binary and Multiclass Classiﬁcation on OCR data We present two sets of experiments on the
MNIST dataset. The aim of the ﬁrst set experiment is to show that SILK is competitive with
NORMA and SVMD on a simple binary task. The data is split into two classes comprising the
digits 0 − 4 and 5 − 9, respectively. A polynomial kernel of degree 9 and a buffer size of ω = 128 is
employed for all three algorithms. Figure 4 (a) plots current average error rate, i.e., the total number
of errors on the examples seen so far divided by the iteration number. As can be seen, after the
initial oscillations have died out, SILK consistently outperforms SVMD and NORMA, achieving a
lower average error after one pass through the dataset. Figure 4 (b) examines the effect of buffer
size on SILK. As expected, smaller buffer sizes result in larger truncation error and hence worse
performance. With increasing buffer size the asymptotic average error decreases. For the 10-way
multiclass classiﬁcation task we set ω = 128, and used a Gaussian kernel following [3]. Figure 4 (c)
shows that SILK consistently outperforms NORMA and SVMD, while the trend with the increasing
buffer size is repeated, as shown in Figure 4 (d). In both experiments, we used the parameters for
NORMA and SVMD reported in [3], and set τ = 0.00005 and C = 100 for SILK.

5 Outlook and Discussion

In this paper we presented a general recipe for performing implicit online updates in an RKHS.
Speciﬁcally, we showed that for many popular loss functions these updates can be computed efﬁ-
ciently. We then presented a sparse version of our algorithm which uses limited basis expansions
to approximate the function. For graph-structured loss we also showed loss bounds and rates of
convergence. Experiments on real life datasets demonstrate that our algorithm is able to track non-
stationary targets, and outperforms existing algorithms.
For the binary hinge loss, when τ = 0 the proposed update formula for αt (16) reduces to the
PA-I algorithm of Crammer et al. [8]. Curiously enough, the motivation for the updates in both
cases seems completely different. While we use an implicit update formula Crammer et al. [8] use

0123456x 10−30.40.50.60.70.80.91False PositiveTrue PositiveSILKNORMAGround TruthFrame 1353SILKNORMA(a)

(b)

(d)
(c)
Figure 4: Performance comparison of different algorithms over one run of the MNIST dataset. (a) Online
binary classiﬁcation. (b) Performance of SILK using different buffer sizes. (c) Online 10-way multiclass
classiﬁcation. (d) Performance of SILK on three different buffer sizes.

a Lagrangian formulation, and a passive-aggressive strategy. Furthermore, the loss functions they
handle are generally linear (hinge loss and its various generalizations) while our updates can handle
other non-linear losses such as quadratic or logistic loss.
Our analysis of loss bounds is admittedly straightforward given current results. The use of more
sophisticated analysis and extending our bounds to deal with other non-linear loss functions is on-
going. We are also applying our techniques to video analysis applications by exploiting the structure
of the output space.

Acknowledgements

We thank Xinhua Zhang, Simon Guenter, Nic Schraudolph and Bob Williamson for carefully proof
reading the paper, pointing us to many references, and helping us improving presentation style.
National ICT Australia is funded by the Australian Government’s Department of Communications,
Information Technology and the Arts and the Australian Research Council through Backing Aus-
tralia’s Ability and the ICT Center of Excellence program. This work is supported by the IST
Program of the European Community, under the Pascal Network of Excellence, IST-2002-506778.

References
[1] J. Kivinen and M. K. Warmuth. Exponentiated gradient versus gradient descent for linear predictors.
Information and Computation, 132(1):1–64, 1997.
[2] J. Kivinen, A. J. Smola, and R. C. Williamson. Online learning with kernels. IEEE Transactions on Signal
Processing, 52(8), 2004.
[3] S. V. N. Vishwanathan, N. N. Schraudolph, and A. J. Smola. Step size adaptation in reproducing kernel
Hilbert space. Journal of Machine Learning Research, 7, 2006.
[4] R. T. Rockafellar. Convex Analysis, volume 28 of Princeton Mathematics Series. Princeton University
Press, 1970.
[5] W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery. Numerical Recipes in C: The Art of
Scientiﬁc Computing (2nd ed.). Cambridge University Press, Cambridge, 1992. ISBN 0 - 521 - 43108 - 5.
[6] V. Vapnik. Statistical Learning Theory. John Wiley and Sons, New York, 1998.
[7] N. Cesa-Bianchi, A. Conconi, and C. Gentile. On the generalization ability of on-line learning algorithms.
IEEE Trans. Information Theory, 50(9):2050–2057, 2004.
[8] K. Crammer, O. Dekel, J. Keshet, S. Shalev-Shwartz, and Y. Singer. Online passive-aggressive algorithms.
Journal of Machine Learning Research, 7:551–585, 2006.

