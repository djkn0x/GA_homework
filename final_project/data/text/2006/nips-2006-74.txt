In-Network PCA and Anomaly Detection

Ling Huang
University of California
Berkeley, CA 94720
hling@cs.berkeley.edu

XuanLong Nguyen
University of California
Berkeley, CA 94720
xuanlong@cs.berkeley.edu

Minos Garofalakis
Intel Research
Berkeley, CA 94704
minos.garofalakis@intel.com

Michael I. Jordan
University of California
Berkeley, CA 94720
jordan@cs.berkeley.edu

Anthony Joseph
University of California
Berkeley, CA 94720
adj@cs.berkeley.edu

Nina Taft
Intel Research
Berkeley, CA 94704
nina.taft@intel.com

Abstract

We consider the problem of network anomaly detection in large distributed systems. In this
setting, Principal Component Analysis (PCA) has been proposed as a method for discover-
ing anomalies by continuously tracking the projection of the data onto a residual subspace.
This method was shown to work well empirically in highly aggregated networks, that is,
those with a limited number of large nodes and at coarse time scales. This approach, how-
ever, has scalability limitations. To overcome these limitations, we develop a PCA-based
anomaly detector in which adaptive local data (cid:2)lters send to a coordinator just enough data
to enable accurate global detection. Our method is based on a stochastic matrix perturba-
tion analysis that characterizes the tradeoff between the accuracy of anomaly detection and
the amount of data communicated over the network.

1 Introduction

The area of distributed computing systems provides a promising domain for applications of machine
learning methods. One of the most interesting aspects of such applications is that learning algorithms
that are embedded in a distributed computing infrastructure are themselves part of that infrastructure
and must respect its inherent local computing constraints (e.g., constraints on bandwidth, latency,
reliability, etc.), while attempting to aggregate information across the infrastructure so as to improve
system performance (or availability) in a global sense.
Consider, for example, the problem of detecting anomalies in a wide-area network. While it is
straightforward to embed learning algorithms at local nodes to attempt to detect node-level anoma-
lies, these anomalies may not be indicative of network-level problems. Indeed, in recent work, [8]
demonstrated a useful role for Principal Component Analysis (PCA) to detect network anomalies.
They showed that the minor components of PCA (the subspace obtained after removing the compo-
nents with largest eigenvalues) revealed anomalies that were not detectable in any single node-level
trace. This work assumed an environment in which all the data is continuously pushed to a central
site for off-line analysis. Such a solution cannot scale either for networks with a large number of
monitors nor for networks seeking to track and detect anomalies at very small time scales.
Designing scalable solutions presents several challenges. Viable solutions need to process data (cid:147)in-
network(cid:148) to intelligently control the frequency and size of data communications. The key underlying
problem is that of developing a mathematical understanding of how to trade off quantization arising
from local data (cid:2)ltering against (cid:2)delity of the detection analysis. We also need to understand how
this tradeoff impacts overall detection accuracy. Finally, the implementation needs to be simple if it
is to have impact on developers.

In this paper, we present a simple algorithmic framework for network-wide anomaly detection that
relies on distributed tracking combined with approximate PCA analysis, together with supporting
theoretical analysis. In brief, the architecture involves a set of local monitors that maintain parame-
terized sliding (cid:2)lters. These sliding (cid:2)lters yield quantized data streams that are sent to a coordinator.
The coordinator makes global decisions based on these quantized data streams. We use stochastic
matrix perturbation theory to both assess the impact of quantization on the accuracy of anomaly
detection, and to design a method that selects (cid:2)lter parameters in a way that bounds the detection
error. The combination of our theoretical tools and local (cid:2)ltering strategies results in an in-network
tracking algorithm that can achieve high detection accuracy with low communication overhead; for
instance, our experiments show that, by choosing a relative eigen-error of 1:5% (yielding, approxi-
mately, a 4% missed detection rate and a 6% false alarm rate), we can (cid:2)lter out more than 90% of
the traf(cid:2)c from the original signal.
Prior Work. The original work on a PCA-based method by Lakhina et al. [8] has been extended
by [17], who show how to infer network anomalies in both spatial and temporal domains. As with
[8], this work is completely centralized. [14] and [1] propose distributed PCA algorithms distributed
across blocks of rows or columns of the data matrix; however, these methods are not applicable to
our case. Furthermore, neither [14] nor [1] address the issue of continuously tracking principal
components within a given error tolerance or the issue of implementing a communication/accuracy
tradeoff; issues which are the main focus of our work. Other initiatives in distributed monitoring,
pro(cid:2)ling and anomaly detection aim to share information and foster collaboration between widely
distributed monitoring boxes to offer improvements over isolated systems [12, 16]. Work in [2, 10]
posits the need for scalable detection of network attacks and intrusions. In the setting of simpler
statistics such as sums and counts, in-network detection methods related to ours have been explored
by [6]. Finally, recent work in the machine learning literature considers distributed constraints
in learning algorithms such as kernel-based classi(cid:2)cation [11] and graphical model inference [7].
(See [13] for a survey).

2 Problem description and background

We consider a monitoring system comprising a set of local monitor nodes M1 ; : : : ; Mn , each of
which collects a locally-observed time-series data stream (Fig. 1(a)). For instance, the monitors
may collect information on the number of TCP connection requests per second, the number of
DNS transactions per minute, or the volume of traf(cid:2)c at port 80 per second. A central coordinator
node aims to continuously monitor the global collection of time series, and make global decisions
such as those concerning matters of network-wide health. Although our methodology is generally
applicable, in this paper we focus on the particular application of detecting volume anomalies. A
volume anomaly refers to unusual traf(cid:2)c load levels in a network that are caused by anomalies such
as worms, distributed denial of service attacks, device failures, miscon(cid:2)gurations, and so on.
Each monitor collects a new data point at every time step and, assuming a naive, (cid:147)continuous push(cid:148)
protocol, sends the new point to the coordinator. Based on these updates, the coordinator keeps track
of a sliding time window of size m (i.e., the m most recent data points) for each monitor time series,
organized into a matrix Y of size m (cid:2) n (where the ith column Yi captures the data from monitor
i, see Fig. 1(a)). The coordinator then makes its decisions based solely on this (global) Y matrix.
In the network-wide volume anomaly detection algorithm of [8] the local monitors measure the total
volume of traf(cid:2)c (in bytes) on each network link, and periodically (e.g., every 5 minutes) centralize
the data by pushing all recent measurements to the coordinator. The coordinator then performs
PCA on the assembled Y matrix to detect volume anomalies. This method has been shown to work
remarkably well, presumably due to the inherently low-dimensional nature of the underlying data
[9]. However, such a (cid:147)periodic push(cid:148) approach suffers from inherent limitations: To ensure fast
detection, the update periods should be relatively small; unfortunately, small periods also imply
increased monitoring communication overheads, which may very well be unnecessary (e.g., if there
are no signi(cid:2)cant local changes across periods). Instead, in our work, we study how the monitors
can effectively (cid:2)lter their time-series updates, sending as little data as possible, yet enough so as
to allow the coordinator to make global decisions accurately. We provide analytical bounds on the
errors that occur because decisions are made with incomplete data, and explore the tradeoff between
reducing data transmissions (communication overhead) and decision accuracy.

^Y =

Anomaly

Data Flow
Result

M1

1
3
5

Y =

M2

4
7
2

M3

3
6
1

r
o
t
c
e
V
 
e
t
a
t
S

3

2

1

0

2

r
o
t
c
e
V
 
l
a
u
d
i
s
e
R

1.5

1

0.5

0

Mn

2
5
8

x 1018

Mon

Tue

Wed

Thu

Fri

Sat

Sun

x 1017

Mon

Tue

Wed

Thu

Fri

Sat

Sun

(a) The system setup

(b) Abilene network traf(cid:2)c data

Figure 1: (a) The distributed monitoring system; (b) Data sample (kyk2 ) collected over one week (top); its
projection in residual subspace (bottom). Dashed line represents a threshold for anomaly detection.

Using PCA for centralized volume anomaly detection. As observed by Lakhina et al. [8], due to
the high level of traf(cid:2)c aggregation on ISP backbone links, volume anomalies can often go unno-
ticed by being (cid:147)buried(cid:148) within normal traf(cid:2)c patterns (e.g., the circle dots shown in the top plot in
Fig 1(b)). On the other hand, they observe that, although, the measured data is of seemingly high
dimensionality (n = number of links), normal traf(cid:2)c patterns actually lie in a very low-dimensional
subspace; furthermore, separating out this normal traf(cid:2)c subspace using PCA (to (cid:2)nd the principal
traf(cid:2)c components) makes it much easier to identify volume anomalies in the remaining subspace
(bottom plot of Fig. 1(b)).
As before, let Y be the global m (cid:2) n time-series data matrix, centered to have zero mean, and let
y = y(t) denote a n-dimensional vector of measurements (for all links) from a single time step t.
Formally, PCA is a projection method that maps a given set of data points onto principal compo-
nents ordered by the amount of data variance that they capture. The set of n principal components,
i=1 , are de(cid:2)ned as:
fvi gn
i(cid:0)1
Xj=1
Yvj vT
kxk=1 k(Y (cid:0)
vi = arg max
j )xk
m YT Y. As shown in [9],
and are the n eigenvectors of the estimated covariance matrix A := 1
PCA reveals that the Origin-Destination (OD) (cid:3)ow matrices of ISP backbones have low intrinsic
dimensionality: For the Abilene network with 41 links, most data variance can be captured by the
(cid:2)rst k = 4 principal components. Thus, the underlying normal OD (cid:3)ows effectively reside in a
(low) k -dimensional subspace of Rn . This subspace is referred to as the normal traf(cid:2)c subspace
Sno . The remaining (n (cid:0) k) principal components constitute the abnormal traf(cid:2)c subspace Sab .
Detecting volume anomalies relies on the decomposition of link traf(cid:2)c y = y(t) at any time step into
normal and abnormal components, y = yno + yab , such that (a) yno corresponds to modeled normal
traf(cid:2)c (the projection of y onto Sno ), and (b) yab corresponds to residual traf(cid:2)c (the projection of y
onto Sab ). Mathematically, yno (t) and yab (t) can be computed as
yno (t) = PPT y(t) = Cnoy(t)
yab (t) = (I (cid:0) PPT )y(t) = Cab y(t)
and
where P = [v1 ; v2 ; : : : ; vk ] is formed by the (cid:2)rst k principal components which capture the dom-
inant variance in the data. The matrix Cno = PPT represents the linear operator that performs
projection onto the normal subspace Sno , and Cab projects onto the abnormal subspace Sab .
As observed in [8], a volume anomaly typically results in a large change to yab ; thus, a useful metric
for detecting abnormal traf(cid:2)c patterns is the squared prediction error (SPE):

SPE (cid:17) kyab k2 = kCabyk2
(essentially, a quadratic residual function). More formally, their proposed algorithm signals a vol-
ume anomaly if SPE > Q(cid:11) , where Q(cid:11) denotes the threshold statistic for the SPE residual function
at the 1 (cid:0) (cid:11) con(cid:2)dence level. Such a statistical test for the SPE residual function, known as the
Q-statistic [4], can be computed as a function Q(cid:11) = Q(cid:11) ((cid:21)k+1 ; : : : ; (cid:21)n ) of the (n (cid:0) k) non-principal
eigenvalues of the covariance matrix A.

Distr. Monitors

Y1(t)
?
Filter/
Predict

(cid:14)1

-

R1(t)

Y2(t)
?
Filter/
Predict

R2(t)

(cid:14)2

-

-

Yn(t)
?
Filter/
Predict

(cid:14)n

-

Rn(t)

Coordinator

Input: (cid:15)

6

Anomaly

w

q

?
Perturbation
Analysis

(cid:30)

(cid:18)

Subspace
Method
6

?
Adaptive
(cid:14)1 ; : : : ; (cid:14)n

w

Figure 2: Our in-network tracking and detection framework.
3 In-network PCA for anomaly detection

We now describe our version of an anomaly detector that uses distributed tracking and approximate
PCA analysis. A key idea is to curtail the amount of data each monitor sends to the coordinator.
Because our job is to catch anomalies, rather than to track ongoing state, we point out that the
coordinator only needs to have a good approximation of the state when an anomaly is near. It need
not track global state very precisely when conditions are normal. This observation makes it intuitive
that a reduction in data sharing between monitors and the coordinator should be possible. We curtail
the amount of data (cid:3)ow from monitors to the coordinator by installing local (cid:2)lters at each monitor.
These (cid:2)lters maintain a local constraint, and a monitor only sends the coordinator an update of its
data when the constraint is violated. The coordinator thus receives an approximate, or (cid:147)perturbed,(cid:148)
view of the data stream at each monitor and hence of the global state. We use stochastic matrix
perturbation theory to analyze the effect on our PCA-based anomaly detector of using a perturbed
global matrix. Based on this, we can choose the (cid:2)ltering parameters (i.e., the local constraints) so as
to limit the effect of the perturbation on the PCA analysis and on any deterioration in the anomaly
detector’s performance. All of these ideas are combined into a simple, adaptive distributed protocol.

3.1 Overview of our approach

Fig. 2 illustrates the overall architecture of our system. We now describe the functionality at the
monitors and the coordinator. The goal of a monitor is to track its local raw time-series data, and to
decide when the coordinator needs an update. Intuitively, if the time series does not change much,
or doesn’t change in a way that affects the global condition being tracked, then the monitor does not
send anything to the coordinator. The coordinator assumes that the most recently received update
is still approximately valid. The update message can be either the current value of the time series,
or a summary of the most recent values, or any function of the time series. The update serves as a
prediction of the future data, because should the monitor send nothing in subsequent time intervals,
then the coordinator uses the most recently received update to predict the missing values.
For our anomaly detection application, we (cid:2)lter as follows. Each monitor i maintains a (cid:2)ltering
window Fi (t) of size 2(cid:14)i centered at a value Ri (i.e., Fi (t) = [Ri (t) (cid:0) (cid:14)i ; Ri (t) + (cid:14)i ]). At each
time t, the monitor sends both Yi (t) and Ri (t) to the coordinator only if Yi (t) =2 Fi , otherwise it
sends nothing. The window parameter (cid:14)i is called the slack; it captures the amount the time series
can drift before an update to the coordinator needs to be sent. The center parameter R i (t) denotes
the approximate representation, or summary, of Yi (t). In our implementation, we set Ri (t) equal
to the average of last (cid:2)ve signal values observed locally at monitor i. Let t(cid:3) denote the time of the
most recent update happens. The monitor needs to send both Y i (t(cid:3) ) and Ri (t(cid:3) ) to the coordinator
when it does an update, because the coordinator will use Y i (t(cid:3) ) at time t(cid:3) and Ri (t(cid:3) ) for all t > t(cid:3)
until the next update arrives. For any subsequent t > t(cid:3) when the coordinator receives no update
from that monitor, it will use Ri (t(cid:3) ) as the prediction for Yi (t).
The role of the coordinator is twofold. First, it makes global anomaly-detection decisions based
upon the received updates from the monitors. Secondly, it computes the (cid:2)ltering parameters (i.e., the
slacks (cid:14)i ) for all the monitors based on its view of the global state and the condition for triggering an
anomaly. It gives the monitors their slacks initially and updates the value of their slack parameters
when needed. Our protocol is thus adaptive. Due to lack of space we do not discuss here the
method for deciding when slack updates are needed. The global detection task is the same as in the

centralized scheme. In contrast to the centralized setting, however, the coordinator does not have
an exact version of the raw data matrix Y; it has the approximation ^Y instead. The PCA analysis,
including the computation of Sab is done on the perturbed covariance matrix ^A := A (cid:0) (cid:1). The
magnitude of the perturbation matrix (cid:1) is determined by the slack variables (cid:14) i (i = 1; : : : ; M ).

3.2 Selection of (cid:2)ltering parameters

A key ingredient of our framework is a practical method for choosing the slack parameters (cid:14) i . This
choice is critical because these parameters balance the tradeoff between the savings in data commu-
nication and the loss of detection accuracy. Clearly, the larger the slack, the less the monitor needs
to send, thus leading to both more reduction in communication overhead and potentially more in-
formation loss at the coordinator. We employ stochastic matrix perturbation theory to quantify the
effects of the perturbation of a matrix on key quantities such as eigenvalues and the eigen-subspaces,
which in turn affect the detection accuracy.
Our approach is as follows. We measure the size of a perturbation using a norm on (cid:1). We derive
an upper bound on the changes to the eigenvalues (cid:21)i and the residual subspace Cab as a function of
k(cid:1)k. We choose (cid:14)i to ensure that an approximation to this upper bound on (cid:1) is not exceeded. This
in turn ensures that (cid:21)i and Cab do not exceed their upper bounds. Controlling these latter terms, we
are able to bound the false alarm probability.
Recall that the coordinator’s view of the global data matrix is the perturbed matrix ^Y = Y + W,
where all elements of the column vector Wi are bounded within the interval [(cid:0)(cid:14)i ; (cid:14)i ]. Let (cid:21)i and
^(cid:21)i (i = 1; : : : ; n) denote the eigenvalues of the covariance matrix A = 1
m YT Y and its perturbed
^YT ^Y . Applying the classical theorems of Mirsky and Weyl [15], we obtain bounds
version ^A := 1
m
on the eigenvalue perturbation in terms of the Frobenius norm k:kF and the spectral norm k:k2 of
(cid:1) := A (cid:0) ^A, respectively:
(cid:15)eig := vuut
n
(^(cid:21)i (cid:0) (cid:21)i )2 (cid:20) k(cid:1)kF =pn and max
1
j^(cid:21)i (cid:0) (cid:21)i j (cid:20) k(cid:1)k2
Xi=1
n
i
Applying the sin theorem and results on bounding the angle of projections to subspaces [15] (see
[3] for more details), we can bound the perturbation of the residual subspace Cab in terms of the
Frobenius norm of (cid:1):
p2k(cid:1)kF
kCab (cid:0) ^CabkF (cid:20)
(cid:23)
where (cid:23) denotes the eigengap between the k th and (k + 1)th eigenvalues of the estimated covariance
matrix ^A.
To obtain practical (i.e., computable) bound on the norms of (cid:1), we derive expectation bounds
instead of worst case bounds. We make the following assumptions on the error matrix W:

(1)

(2)

1. The column vectors W1 ; : : : ; Wn are independent and radially symmetric m-vectors.
2. For each i = 1; : : : ; n, all elements of column vector Wi are i.i.d. random variables with
mean 0, variance (cid:27) 2
i ((cid:14)i ) and fourth moment (cid:22)4
i ((cid:14)i ).
i := (cid:27)2
i := (cid:22)4

Note that the independence assumption is imposed only on the error(cid:151)this by no means implies that
the signals received by different monitors are statistically independent. Under the above assumption,
we can show that k(cid:1)kF =pn is upper bounded in expectation by the following quantity:
T olF = 2vuut
i + vuut(cid:18) 1
n
n
n
n (cid:19) n
1
1
1
Xi=1
Xi=1
Xi=1
Xi=1
(cid:27)2
mn
m
mn
Similar results can be obtained for the spectral norm as well. In practice, these upper bounds are
very tight because (cid:27)1 ; : : : ; (cid:27)n tend to be small compared to the top eigenvalues. Given the tolerable
perturbation T olF , we can use Eqn. (3) to select the slack variables. For example, we can divide the
overall tolerance across monitors either uniformly or in proportion to their observed local variance.

((cid:22)4
i (cid:0) (cid:27)4
i ):

(cid:27)4
i +

(3)

(cid:21)i (cid:1)

+

3.3 Guarantee on false alarm probability

(cid:20)

(cid:14)2
i

n
Xi=1

+ 1 +

Because our approximation perturbs the eigenvalues, it also impacts the accuracy with which the
trigger is (cid:2)red. Since the trigger condition is kCabyk2 > Q(cid:11) , we must assess the impact on both
of these terms. We can compute an upper bound on the perturbation of the SPE statistic, SPE =
kCabyk2 , as follows. First, note that
p2k(cid:1)kF k ^yk
+ kCabk2vuut
jk ^Cab ^yk (cid:0) kCabykj (cid:20) k( ^Cab (cid:0) Cab ) ^yk + kCab (y (cid:0) ^y)k (cid:20)
(cid:23)
p2k(cid:1)kF
p2k(cid:1)kF k ^yk
! vuut
n
+  k ^Cabk +
Xi=1
(cid:14)2
i =: (cid:17)1 ( ^y):
(cid:23)
(cid:23)
jk ^Cab ^yk2 (cid:0) kCabyk2 j (cid:20) (cid:17)1 ( ^y)(2k ^Cab ^yk + (cid:17)1 ( ^y)) =: (cid:17)2 ( ^y):
The dependency of the threshold Q(cid:11) on the eigenvalues, (cid:21)k+1 ; : : : ; (cid:21)n , can be expressed as [4]:
1
#
Q(cid:11) = (cid:30)1 " c(cid:11)p2(cid:30)2h2
h0
0
(cid:30)1
where c(cid:11) is the (1 (cid:0) (cid:11))-percentile of the standard normal distribution, h0 = 1 (cid:0) 2(cid:30)1 (cid:30)3
3(cid:30)2
2
Pn
j for i = 1; 2; 3.
j=k+1 (cid:21)i
To assess the perturbation in false alarm probability, we start by considering the following random
variable c derived from Eqn. (5):
(cid:30)1 [(SPE=(cid:30)1 )h0 (cid:0) 1 (cid:0) (cid:30)2h0 (h0 (cid:0) 1)=(cid:30)2
1 ]
p2(cid:30)2h2
0
The random variable c essentially normalizes the random quantity kCabyk2 and is known to ap-
proximately follow a standard normal distribution [5]. The false alarm probability in the centralized
system is expressed as
Pr (cid:2)kCabyk2 > Q(cid:11) (cid:3) = Pr [c > c(cid:11) ] = (cid:11);
where the lefthand term of this equation is conditioned upon the SPE statistics being inside the
normal range. In our distributed setting, the anomaly detector (cid:2)res a trigger if k ^Cab ^yk2 > ^Q(cid:11) .
We thus only observe a perturbed version ^c for the random variable c. Let (cid:17) c denote the bound on
j^c (cid:0) cj. The deviation of the false alarm probability in our approximate detection scheme can then
be approximated as P (c(cid:11) (cid:0) (cid:17)c < U < c(cid:11) + (cid:17)c ), where U is a standard normal random variable.
4 Evaluation

(cid:30)2 h0 (h0 (cid:0) 1)
(cid:30)2
1

, (cid:30)i =

c =

(4)

(5)

(6)

;

:

We implemented our algorithm and developed a trace-driven simulator to validate our methods. We
used a one-week trace collected from the Abilene network1. The traces contains per-link traf(cid:2)c
loads measured every 10 minutes, for all 41 links of the Abilene network. With a time unit of 10
minutes, data was collected for 1008 time units. This data was used to feed the simulator. There
are 7 anomalies in the data that were detected by the centralized algorithm (and veri(cid:2)ed by hand
to be true anomalies). We also injected 70 synthetic anomalies into this dataset using the method
described in [8], so that we would have suf(cid:2)cient data to compute error rates. We used a threshold
Q(cid:11) corresponding to an 1 (cid:0) (cid:11) = 99:5% con(cid:2)dence level. Due to space limitations, we present
results only for the case of uniform monitor slack, (cid:14)i = (cid:14) .
The input parameter for our algorithm is the tolerable relative error of the eigenvalues ((cid:147)relative
eigen-error(cid:148) for short), which acts as a tuning knob. (Precisely, it is T olF =q 1
i , where T olF
n P (cid:21)2
is de(cid:2)ned in Eqn. (3).) Given this parameter and the input data we can compute the (cid:2)ltering slack (cid:14)
for the monitors using Eqn. (3). We then feed in the data to run our protocol in the simulator with the
1Abilene is an Internet2 high-performance backbone network that interconnects a large number of universi-
ties as well as a few other research institutes.

x 107

6

4

2

k
c
a
l
S

0

0

0.015

0.01

0.005

r
o
r
r
E
 
n
e
g
i
E
 
.
l
e
R

0

0

0.1

0.05

0

0

r
o
r
r
E
 
d
l
o
h
s
e
r
h
T
 
.
l
e
R

e
t
a
R
 
m
r
a
l
A
 
.
l
a
F

0.4

0.3

0.2

0.1

0

0

0.1

Upper Bound
Actual Accrued

0.005

0.01

0.005

0.01

0

0

1

0.5

d
a
e
h
r
e
v
O
 
.
m
m
o
C

0

0

0.005

0.01

0.005

0.01

0.015
(a)

0.015
(b)

0.02

0.025

0.03

0.02

0.025

0.03

e
t
a
R
 
.
c
e
t
e
D
 
d
e
s
s
i
M

0.05

0.015
(d)

0.015
(e)

0.02

0.025

0.03

0.02

0.025

0.03

0.02

0.03

0.005

0.01

0.015
0.015
(f)
(c)
Figure 3: In all plots the x-axis is the relative eigen-error. (a) The (cid:2)ltering slack. (b) Actual accrued eigen-
error. (c) Relative error of detection threshold. (d) False alarm rates. (e) Missed detection rates. (f) Communi-
cation overhead.

0.005

0.025

0.025

0.01

0.02

0.03

computed (cid:14) . The simulator outputs a set of results including: 1) the actual relative eigen errors and
the relative errors on the detection threshold Q(cid:11) ; 2) the missed detection rate, false alarm rate and
communication cost achieved by our method. The missed-detection rate is de(cid:2)ned as the fraction of
missed detections over the total number of real anomalies, and the false-alarm rate as the fraction
of false alarms over the total number of detected anomalies by our protocol, which is (cid:11) (de(cid:2)ned in
Sec. 3.3) rescaled as a rate rather than a probability. The communication cost is computed as the
fraction of number of messages that actually get through the (cid:2)ltering window to the coordinator.
The results are shown in Fig. 3. In all plots, the x-axis is the relative eigen-error. In Fig. 3(a) we plot
the relationship between the relative eigen-error and the (cid:2)ltering slack (cid:14) when assuming (cid:2)ltering
errors are uniformly distributed on interval [(cid:0)(cid:14); (cid:14) ]. With this model, the relationship between the
i = (cid:14)2
relative eigen-error and the slack is determined by a simpli(cid:2)ed version of Eqn. (3) (with all (cid:27) 2
3 ).
The results make intuitive sense. As we increase our error tolerance, we can (cid:2)lter more at the monitor
and send less to the coordinator. The slack increases almost linearly with the relative eigen-error
because the (cid:2)rst term in the right hand side of Eqn. (3) dominates all other terms.
In Fig. 3(b) we compare the relative eigen-error to the actual accrued relative eigen-error (de(cid:2)ned as
(cid:15)eig =q 1
i , where (cid:15)eig is de(cid:2)ned in Eqn (1)). These were computed using the slack parameters
n P (cid:21)2
(cid:14) as computed by our coordinator. We can see that the real accrued eigen-errors are always less than
the tolerable eigen errors. The plot shows a tight upper bound, indicating that it is safe to use our
model’s derived (cid:2)ltering slack (cid:14) . In other words, the achieved eigen-error always remains below the
requested tolerable error speci(cid:2)ed as input, and the slack chosen given the tolerable error is close
to being optimal. Fig. 3(c) shows the relationship between the relative eigen-error and the relative
2 . We see that the threshold for detecting anomalies decreases as we
error of detection threshold Q(cid:11)
tolerate more and more eigen-errors. In these experiments, an error of 2% in the eigenvalues leads
to an error of approximately 6% in our estimate of the appropriate cutoff threshold.
We now examine the false alarm rates achieved. In Fig. 3(d) the curve with triangles represents
the upper bound on the false alarm rate as estimated by the coordinator. The curve with circles
is the actual accrued false alarm rate achieved by our scheme. Note that the upper bound on the
false alarm rate is fairly close to the true values, especially when the slack is small. The false alarm
rate increases with increasing eigen-error because as the eigen-error increases, the corresponding
detection threshold Q(cid:11) will decrease, which in turn causes the protocol to raise an alarm more
often. (If we had plotted ^Q rather than the relative threshold difference, we would obviously see a

2Precisely, it is 1 (cid:0) ^Q(cid:11) =Q(cid:11) , where ^Q(cid:11) is computed from ^(cid:21)k+1 ; : : : ; ^(cid:21)n .

decreasing ^Q with increasing eigen-error.) We see in Fig. 3(e) that the missed detection rates remain
below 4% for various levels of communication overhead.
The communication overhead is depicted in Fig. 3(f). Clearly, the larger the errors we can tolerate,
the more overhead can be reduced. Considering these last three plots (d,e,f) together, we observe
several tradeoffs. For example, when the relative eigen-error is 1:5%, our algorithm reduces the data
sent through the network by more than 90%. This gain is achieved at the cost of approximately a
4% missed detection rate and a 6% false alarm rate. This is a large reduction in communication for
a small increase in detection error. These initial results illustrate that our in-network solution can
dramatically lower the communication overhead while still achieving high detection accuracy.

5 Conclusion

We have presented a new algorithmic framework for network anomaly detection that combines dis-
tributed tracking with PCA analysis to detect anomalies with far less data than previous methods.
The distributed tracking consists of local (cid:2)lters, installed at each monitoring site, whose parameters
are selected based upon global criteria. The idea is to track the local monitoring data only enough so
as to enable accurate detection. The local (cid:2)ltering reduces the amount of data transmitted through
the network but also means that anomaly detection must be done with limited or partial views of the
global state. Using methods from stochastic matrix perturbation theory, we provided an analysis for
the tradeoff between the detection accuracy and the data communication overhead. We were able
to control the amount of data overhead using the the relative eigen-error as a tuning knob. To the
best of our knowledge, this is the (cid:2)rst result in the literature that provides upper bounds on the false
alarm rate of network anomaly detection.

References
[1] BA I , Z . - J . , CHAN , R . AND LUK , F. Principal component analysis for distributed data sets with updating.
In Proceedings of International workshop on Advanced Parallel Processing Technologies (APPT), 2005.
[2] D R EG E R , H . , F E LDMANN , A . , PAX SON , V. AND SOMM E R , R . Operational experiences with high-
volume network intrusion detection. In Proceedings of ACM Conference on Computer and Communications
Security (CCS), 2004.
[3] HUANG , L . , NGUY EN , X . , GA RO FA LAK I S , M . , JO RDAN , M . , JO S E PH , A . AND TA F T, N . In-network
PCA and anomaly detection. Technical Report No. UCB/EECS-2007-10, EECS Department, UC Berkeley.
[4] JACK SON , J . E . AND MUDHO LKA R , G . S . Control procedures for residuals associated with principal
component analysis. In Technometrics, 21(3):341-349, 1979.
[5] J EN S EN , D . R . AND SO LOMON , H . A Gaussian approximation for the distribution of de(cid:2)nite quadratic
forms. In Journal of the American Statistical Association, 67(340):898-902, 1972.
[6] K E RA LA PU RA , R . , CO RMOD E , G . AND RAMAM I RTHAM , J . Communication-ef(cid:2)cient distributed mon-
itoring of thresholded counts. In Proceedings of ACM International Conference on Management of Data
(SIGMOD), 2006.
[7] K R E ID L , P. O . , W I L L SKY, A . Inference with minimal communication: A decision-theoretic variational
approach. In Proceedings of Neural Information Processing Systems (NIPS), 2006.
[8] LAKH INA , A . , C ROV E L LA , M . AND D IOT, C . Diagnosing network-wide traf(cid:2)c anomalies. In Proceedings
of ACM Conference of the Special Interest Group on Data Communication (SIGCOMM), 2004.
[9] LAKH INA , A . , PA PAG IANNAK I , K . , C ROV E L LA , M . , D IOT, C . , KO LAC ZYK , E . D . AND TA F T, N .
Structural analysis of network traf(cid:2)c (cid:3)ows. In Proceedings of International Conference on Measurement
and Modeling of Computer Systems (SIGMETRICS), 2004.
[10] L EV CH ENKO , K . , PATU R I , R . AND VA RGH E S E , G . On the dif(cid:2)culty of scalably detecting network
attacks. In Proceedings of ACM Conference on Computer and Communications Security (CCS), 2004.
[11] NGUY EN , X . , WA INW R IGH T, M . AND JO RDAN , M . Nonparametric decentralized detection using kernel
methods. In IEEE Transactions on Signal Processing, 53(11):4053-4066, 2005.
[12] PADMANA BHAN , V. N . , RAMA BHAD RAN , S . , AND PADHY E , J . Netpro(cid:2)ler: Pro(cid:2)ling wide-area net-
works using peer cooperation. In Proceedings of International Workshop on Peer-to-Peer Systems, 2005.
[13] P R EDD , J .B . , KU LKA RN I , S .B . , AND POO R , H .V. Distributed learning in wireless sensor networks. In
IEEE Signal Processing Magazine, 23(4):56-69, 2006.
[14] QU , Y. , O S T ROU CHOV Z , G . , SAMATOVA Z , N AND G E I S T, A . Principal component analysis for dimen-
sion reduction in massive distributed data sets. In Proceedings of IEEE International Conference on Data
Mining (ICDM), 2002.
[15] S T EWA RT, G . W. , AND SUN , J . -G . Matrix Perturbation Theory. Academic Press, 1990.
[16] Y EGN E SWA RAN , V. , BA R FO RD , P. , AND JHA , S . Global intrusion detection in the domino overlay
system. In Proceedings of Network and Distributed System Security Symposium (NDSS), 2004.
[17] ZHANG , Y. , G E , Z . -H . , G R E EN B E RG , A . , AND ROUGHAN , M . Network anomography. In Proceedings
of Internet Measurement Conference (IMC), 2005.

