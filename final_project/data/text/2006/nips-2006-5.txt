Multi-Task Feature Learning

Andreas Argyriou
Department of Computer Science
University College London
Gower Street, London WC1E 6BT, UK
a.argyriou@cs.ucl.ac.uk

Theodoros Evgeniou
Technology Management and Decision Sciences,
INSEAD,
Bd de Constance, Fontainebleau 77300, France
theodoros.evgeniou@insead.edu

Massimiliano Pontil
Department of Computer Science
University College London
Gower Street, London WC1E 6BT, UK
m.pontil@cs.ucl.ac.uk

Abstract

We present a method for learning a low-dimensional representation which is
shared across a set of multiple related tasks. The method builds upon the well-
known 1-norm regularization problem using a new regularizer which controls the
number of learned features common for all the tasks. We show that this problem
is equivalent to a convex optimization problem and develop an iterative algorithm
for solving it. The algorithm has a simple interpretation: it alternately performs a
supervised and an unsupervised step, where in the latter step we learn common-
across-tasks representations and in the former step we learn task-speciﬁc functions
using these representations. We report experiments on a simulated and a real data
set which demonstrate that the proposed method dramatically improves the per-
formance relative to learning each task independently. Our algorithm can also be
used, as a special case, to simply select – not learn – a few common features across
the tasks.

1 Introduction

Learning multiple related tasks simultaneously has been empirically [2, 3, 8, 9, 12, 18, 19, 20] as
well as theoretically [2, 4, 5] shown to often signi ﬁcantly improve performance relative to learning
each task independently. This is the case, for example, when only a few data per task are available,
together data across many related tasks.
so that there is an advantage in “pooling ”

Tasks can be related in various ways. For example, task relatedness has been modeled through
assuming that all functions learned are close to each other in some norm [3, 8, 15, 19]. This may be
the case for functions capturing preferences in users’ modeling problems [9, 13]. Tasks may also be
related in that they all share a common underlying representation [4, 5, 6]. For example, in object
recognition, it is well known that the human visual system is organized in a way that all objects1 are
represented – at the earlier stages of the visual system – using a common set of features learned, e.g.
local ﬁlters
similar to wavelets [16]. In modeling users’ preferences/choices, it may also be the case
that people make product choices (e.g. of books, music CDs, etc.) using a common set of features
describing these products.

In this paper, we explore the latter type of task relatedness, that is, we wish to learn a low-
dimensional representation which is shared across multiple related tasks. Inspired by the fact that
the well known 1(cid:0)norm regularization problem provides such a sparse representation for the single

1We consider each object recognition problem within each object category, e.g. recognizing a face among
faces, or a car among cars, to be a different task.

task case, in Section 2 we generalize this formulation to the multiple task case. Our method learns
a few features common across the tasks by regularizing within the tasks while keeping them cou-
pled to each other. Moreover, the method can be used, as a special case, to select (not learn) a few
features from a prescribed set. Since the extended problem is nonconvex, we develop an equivalent
convex optimization problem in Section 3 and present an algorithm for solving it in Section 4. A
similar algorithm was investigated in [9] from the perspective of conjoint analysis. Here we provide
a theoretical justiﬁcation of the algorithm in connection with 1-norm regularization.
The learning algorithm simultaneously learns both the features and the task functions through two
alternating steps. The ﬁrst
step consists of independently learning the parameters of the tasks’
regression or classiﬁcation functions. The second step consists of learning, in an unsupervised way,
a low-dimensional representation for these task parameters, which we show to be equivalent to
learning common features across the tasks. The number of common features learned is controlled,
as we empirically show, by the regularization parameter, much like sparsity is controlled in the case
of single-task 1-norm regularization.
In Section 5, we report experiments on a simulated and a real data set which demonstrate that the
proposed method learns a few common features across the tasks while also improving the perfor-
mance relative to learning each task independently. Finally, in Section 6 we brieﬂy compare our
approach with other related multi-task learning methods and draw our conclusions.

2 Learning sparse multi-task representations

We begin by introducing our notation. We let IR be the set of real numbers and IR+ (IR++ ) the
subset of non-negative (positive) ones. Let T be the number of tasks and deﬁne INT := f1; : : : ; T g.
For each task t 2 INT , we are given m input/output examples (xt1 ; yt1 ); : : : (xtm ; ytm ) 2 IRd (cid:2) IR.
Based on this data, we wish to estimate T functions ft : IRd ! IR, t 2 INT , which approximate
well the data and are statistically predictive, see e.g. [11].
If w; u 2 IRd , we deﬁne hw; ui := Pd
i=1 wiui , the standard inner product in IRd . For every p (cid:21) 1,
1
we deﬁne the p-norm of vector w as kwkp := (Pd
p . If A is a d (cid:2) T matrix we denote by
i=1 jwi jp )
ai 2 IRT and aj 2 IRd the i-th row and the j -th column of A respectively. For every r; p (cid:21) 1 we
1
deﬁne the (r; p)-norm of A as kAkr;p := (cid:0) Pd
p .
i=1 kai kp
r (cid:1)
We denote by Sd the set of d (cid:2) d real symmetric matrices and by Sd
+ the subset of positive semidef-
inite ones. If D is a d (cid:2) d matrix, we deﬁne trace(D) := Pd
i=1 Dii . If X is a p (cid:2) q real matrix,
range(X ) denotes the set fx 2 IRp : x = X z ; for some z 2 IRq g. We let Od be the set of d (cid:2) d
orthogonal matrices. Finally, D+ denotes the pseudoinverse of a matrix D .
2.1 Problem formulation

The underlying assumption in this paper is that the functions ft are related so that they all share a
small set of features. Formally, our hypothesis is that the functions ft can be represented as

d
Xi=1
: IRd ! IR are the features and ait 2 IR are the regression parameters. Our main
where hi
assumption is that all the features but a few have zero coefﬁcients across all the tasks.

aithi (x);

(2.1)

ft (x) =

t 2 INT ;

For simplicity, we focus on linear features, that is, hi (x) = hui ; xi, where ui 2 IRd . In addition,
we assume that the vectors ui are orthonormal. Thus, if U denotes the d (cid:2) d matrix with columns
the vectors ui , then U 2 Od . The functions ft are linear as well, that is ft (x) = hwt ; xi, where
wt = Pi aitui . Extensions to nonlinear functions may be done, for example, by using kernels along
the lines in [8, 15]. Since this is not central in the present paper we postpone its discussion to a future
occasion.
Let us denote by W the d (cid:2) T matrix whose columns are the vectors wt and by A the d (cid:2) T matrix
with entries ait . We then have that W = U A. Our assumption that the tasks share a “small ”
set

of features means that the matrix A has “man y”
rows which are identically equal to zero and, so,
the corresponding features (columns of matrix U ) will not be used to represent the task parameters
(columns of matrix W ). In other words, matrix W is a low rank matrix. We note that the problem
of learning a low-rank matrix factorization which approximates a given partially observed target
matrix has been considered in [1], [17] and references therein. We brieﬂy discuss its connection to
our current work in Section 4.
In the following, we describe our approach to computing the feature vectors u i and the parameters
ait . We ﬁrst consider the case that there is only one task (say task t) and the features u i are ﬁx ed. To
learn the parameter vector at 2 IRd from data f(xti ; yti )gm
i=1 we would like to minimize the empiri-
cal error Pm
i=1 L(yti ; hat ; U >xti i) subject to an upper bound on the number of nonzero components
of at , where L : IR (cid:2) IR ! IR+ is a prescribed loss function which we assume to be convex in the
second argument. This problem is intractable and is often relaxed by requiring an upper bound on
the 1-norm of at . That is, we consider the problem min (cid:8)Pm
1 (cid:20) (cid:11)2(cid:9),
i=1 L(yti ; hat ; U >xti i) : kat k2
or equivalently the unconstrained problem
min ( m
1 : at 2 IRd) ;
Xi=1
L(yti ; hat ; U >xti i) + (cid:13) kat k2
(2.2)
where (cid:13) > 0 is the regularization parameter. It is well known that using the 1-norm leads to sparse
solutions, that is, many components of the learned vector at are zero, see [7] and references therein.
Moreover, the number of nonzero components of a solution to problem (2.2) is “typically”
a non-
increasing function of (cid:13) [14].

We now generalize problem (2.2) to the multi-task case. For this purpose, we introduce the regular-
ization error function

E (A; U ) =

L(yti ; hat ; U >xti i) + (cid:13) kAk2
2;1 :

m
T
Xi=1
Xt=1
term in (2.3) is the average of the empirical error across the tasks while the second one is a
The ﬁrst
regularization term which penalizes the (2; 1)-norm of the matrix A. It is obtained by ﬁrst computing
the 2-norm of the (across the tasks) rows ai (corresponding to feature i) of matrix A and then the
1-norm of the vector b(A) = (ka1 k2 ; : : : ; kad k2 ). This norm combines the tasks and ensures that
common features will be selected across them.
Indeed, if the features U are prescribed and ^A minimizes the function E over A, the number of
nonzero components of the vector b( ^A) will typically be non-increasing with (cid:13) like in the case
of 1-norm single-task regularization. Moreover, the components of the vector b( ^A) indicate how
important each feature is and favor uniformity across the tasks for each feature.

(2.3)

Since we do not simply want to select the features but also learn them, we further minimize the
function E over U , that is, we consider the optimization problem
min nE (A; U ) : U 2 Od ; A 2 IRd(cid:2)T o :
This method learns a low-dimensional representation which is shared across the tasks. As in the
single-task case, the number of features will be typically non-increasing with the regularization
parameter – we shall present experimental evidence of this fact in Section 5 (see Figure 1 therein).
We note that when the matrix U is not learned and we set U = Id(cid:2)d , problem (2.4) computes
a common set of variables across the tasks. That is, we have the following convex optimization
problem
min ( T
2;1 : A 2 IRd(cid:2)T ) :
m
Xi=1
Xt=1
L(yti ; hat ; xti i) + (cid:13) kAk2
We shall return to problem (2.5) in Section 4 where we present an algorithm for solving it.

(2.5)

(2.4)

3 Equivalent convex optimization formulation

Solving problem (2.4) is a challenging task for two main reasons. First, it is a non-convex problem,
although it is separately convex in each of the variables A and U . Second, the norm kAk2;1 is
nonsmooth which makes it more difﬁcult
to optimize.

R(W; D) =

A main result in this paper is that problem (2.4) can be transformed into an equivalent convex
problem. To this end, for every W 2 IRd(cid:2)T and D 2 Sd
+ , we deﬁne the function
T
m
T
Xt=1
Xi=1
Xt=1
Theorem 3.1. Problem (2.4) is equivalent to the problem
+ ; trace(D) (cid:20) 1; range(W ) (cid:18) range(D)o :
min nR(W; D) : W 2 IRd(cid:2)T ; D 2 Sd
That is, ( ^A; ^U ) is an optimal solution for (2.4) if and only if ( ^W ; ^D) = ( ^U ^A; ^U Diag(^(cid:21)) ^U > ) is an
optimal solution for (3.2), where

L(yti ; hwt ; xti i) + (cid:13)

hwt ; D+wt i:

(3.1)

(3.2)

^(cid:21)i :=

:

k^ai k2
k ^Ak2;1
)U > . Then kai k2 = kW >ui k2 and hence

(3.3)

Proof. Let W = U A and D = U Diag( kai k2
kAk2;1
T
Xt=1
hwt ; D+wt i = trace(W >D+W ) = kAk2;1 trace(W >U Diag(kW >ui k2 )+U >W ) =
d
d
Xi=1
Xi=1
(kW >ui k2 )+ W >uiu>
kAk2;1 trace(cid:0)
i W (cid:1) = kAk2;1
Therefore, minW;D R(W; D) (cid:20) minA;U E (A; U ): Conversely, let D = U Diag((cid:21))U > . Then
T
Xt=1
hwt ; D+wt i = trace(W >U Diag((cid:21)+
i )U >W ) = trace(Diag((cid:21)+
i )AA> ) (cid:21) kAk2
2;1 ;
by Lemma 4.2. Note that the range constraint ensures that W is a multiple of the submatrix of U
which corresponds to the nonzero eigenvalues of D , and hence if (cid:21)i = 0 then ai = 0 as well.
Therefore, minA;U E (A; U ) (cid:20) minW;D R(W; D):

kW >ui k2 = kAk2
2;1 :

In problem (3.2) we have constrained the trace of D , otherwise the optimal solution would be to
simply set D = 1 and only minimize the empirical error term in (3.1). Similarly, we have imposed
the range constraint to ensure that the penalty term is bounded below and away from zero. Indeed,
without this constraint, it may be possible that DW = 0 when W does not have full rank, in which
case there is a matrix D for which PT
t=1 hwt ; D+wt i = trace(W >D+W ) = 0.
We note that the rank of matrix D indicates how many common relevant features the tasks share.
Indeed, it is clear from equation (3.3) that the rank of matrix D equals the number of nonzero rows
of matrix A.

We now show that the function R in equation (3.1) is jointly convex in W and D . For this purpose,
we deﬁne the function f (w; D) = w>D+w , if D 2 Sd
+ and w 2 range(D), and f (w; D) = +1
otherwise. Clearly, R is convex provided f is convex. The latter is true since a direct computation
expresses f as the supremum of a family of convex functions, namely we have that f (w; D) =
supfw> v + trace(ED) : E 2 Sd ; v 2 IRd ; 4E + vv> (cid:22) 0g.
4 Learning algorithm

We solve problem (3.2) by alternately minimizing the function R with respect to D and the w t
(recall that wt is the t-th column of matrix W ).
When we keep D ﬁx ed, the minimization over wt simply consists of learning the parameters wt
independently by a regularization method, for example by an SVM or ridge regression type method 2 .
For a ﬁx ed value of the vectors wt , we learn D by simply solving the minimization problem
+ ; trace(D) (cid:20) 1; range(W ) (cid:18) range(D)) :
min ( T
Xt=1
hwt ; D+wt i : D 2 Sd
The following theorem characterizes the optimal solution of problem (4.1).
2As noted in the introduction, other multi-task learning methods can be used. For example, we can also
penalize the variance of the wt ’s – “forcing”them to be close to each other – as in [8]. This would only slightly
change the overall method.

(4.1)

Algorithm 1 (Multi-Task Feature Learning)
Input: training sets f(xti ; yti )gm
i=1 ; t 2 INT
Parameters: regularization parameter (cid:13)
Output: d (cid:2) d matrix D , d (cid:2) T regression matrix W = [w1 ; : : : ; wT ]
Initialization: set D = Id(cid:2)d
d
while convergence condition is not true do
for t = 1; : : : ; T do
i=1 L(yti ; hw; xti i) + (cid:13) hw; D+wi : w 2 IRd ; w 2 range(D)o
compute wt = argmin nPm
end for
1
set D = (W W > )
2
1
trace(W W > )
2
end while

Theorem 4.1. Let C = W W > . The optimal solution of problem (4.1) is

and the optimal value equals (trace C

1
2 )2 .

D =

1

2

C

trace C

1

2

We ﬁrst
introduce the following lemma which is useful in our analysis.
Lemma 4.2. For any b = (b1 ; : : : ; bd ) 2 IRd , we have that
(cid:21)i (cid:20) 1) = kbk2
inf ( d
d
Xi=1
Xi=1
1
and any minimizing sequence converges to ^(cid:21)i = jbi j
, i 2 INd .
kbk1

: (cid:21)i > 0;

b2
i
(cid:21)i

(4.2)

(4.3)

1
(cid:0) 1
Proof. From the Cauchy-Schwarz inequality we have that kbk1 = Pbi 6=0 (cid:21)
jbi j (cid:20)
i (cid:21)
2
2
i
2 (cid:20) (Pd
1
1
1
i=1 (cid:21)(cid:0)1
2 (Pbi 6=0 (cid:21)(cid:0)1
2 . Convergence to the in ﬁmum is obtained when
i b2
i b2
(Pbi 6=0 (cid:21)i )
i )
i )
(cid:0) jbj j
i=1 (cid:21)i ! 1 and jbi j
! 0 for all i; j 2 INd such that bi ; bj 6= 0. Hence (cid:21)i ! jbi j
Pd
. The
kbk1
(cid:21)i
(cid:21)j
inﬁmum is attained when bi 6= 0 for all i 2 INd .
Proof of Theorem 4.1. We write D = U Diag((cid:21))U > , with U 2 Od and (cid:21) 2 IRd
+ . We ﬁrst mini-
mize over (cid:21). For this purpose, we use Lemma 4.2 to obtain that

inf ftrace(W >U Diag((cid:21))(cid:0)1U >W ) : (cid:21) 2 IRd
++ ;

d
Xi=1
1
2 )2
minfkU >W k2
2;1 : U 2 Od g = (trace C
and a minimizing U is a system of eigenvectors of C . To see this, note that

(cid:21)i (cid:20) 1g = kU >W k2
2;1 = (cid:0)

Next we show that

d
Xi=1

kW >ui k2 (cid:1)2

:

trace(W W >uiu>
i ) = trace(C
(cid:21) (trace(C

1
1
i uiu>
i uiu>
2 ) trace(uiu>
2 uiu>
i )
i C
1
1
i ))2 = trace(C
i ) = u>
i uiu>
2 uiu>
2 uiu>
i C
1
i which implies
since uiu>
i . The equality is veriﬁed if and only if C
i = auiu>
i = uiu>
2 uiu>
i uiu>
1
1
that C
2 ui = aui , that is, if ui is an eigenvector of C . The optimal a is trace(C
2 ).

1
2 ui

1
2 in (4.2) is simply the sum of the singular values of W and is some-
The expression trace(W W > )
times called the trace norm. As shown in [10], the trace norm is the convex envelope of rank(W )
in the unit ball, which gives another interpretation of the relationship between the rank and (cid:13) in our
experiments. Using the trace norm, problem (3.2) becomes a regularization problem which depends
only on W .

18

16

14

12

10

8

6

4

2
10−4

10−2

100

15

10

5

0

100

101

Figure 1: Number of features learned versus the regularization parameter (cid:13) (see text for description).

However, since the trace norm is nonsmooth, we have opted for the above alternating minimization
strategy which is simple to implement and has a natural interpretation. Indeed, Algorithm 1 alter-
nately performs a supervised and an unsupervised step, where in the latter step we learn common
representations across the tasks and in the former step we learn task-speciﬁc functions using these
representations.

We conclude this section by noting that when matrix D in problem (3.2) is additionally constrained
to be diagonal, problem (3.2) reduces to problem (2.5). Formally, we have the following corollary.
Corollary 4.3. Problem (2.5) is equivalent to the problem
min (R(W; Diag((cid:21))) : W 2 IRd(cid:2)T ; (cid:21) 2 IRd
+ ;
and the optimal (cid:21) is given by

(cid:21)i (cid:20) 1; (cid:21)i 6= 0 when w i 6= 0)

d
Xi=1

(4.4)

(cid:21)i =

kwi k2
kW k2;1

;

i 2 INd :

(4.5)

Using this corollary we can make a simple modi ﬁcation to Algorithm 1 in order to use it for variable
selection. That is, we modify the computation of the matrix D (penultimate line in Algorithm 1) as
D = Diag((cid:21)), where the vector (cid:21) = ((cid:21)1 ; : : : ; (cid:21)d ) is computed using equation (4.5).
5 Experiments

In this section, we present experiments on a synthetic and a real data set. In all of our experiments,
we used the square loss function and automatically tuned the regularization parameter (cid:13) with leave-
one-out cross validation.
Synthetic Experiments. We created synthetic data sets by generating T = 200 task param-
eters wt from a 5-dimensional Gaussian distribution with zero mean and covariance equal to
Diag(1; 0:25; 0:1; 0:05; 0:01). These are the relevant dimensions we wish to learn. To these we
kept adding up to 20 irrelevant dimensions which are exactly zero. The training and test sets were
selected randomly from [0; 1]25 and contained 5 and 10 examples per task respectively. The outputs
yti were computed from the wt and xti as yti = hwt ; xti i + (cid:23) , where (cid:23) is zero-mean Gaussian noise
with standard deviation equal to 0:1.
We ﬁrst present, in Figure 1, the number of features learned by our algorithm, as measured by
rank(D). The plot on the left corresponds to a data set of 200 tasks with 25 input dimensions and
that on the right to a real data set of 180 tasks described in the next subsection. As expected, the
number of features decreases with (cid:13) .

Figure 2 depicts the performance of our algorithm for T = 10; 25; 100 and 200 tasks along with the
performance of 200 independent standard ridge regressions on the data. For T = 10; 25 and 100, we
averaged the performance metrics over runs on all the data so that our estimates have comparable
variance. In agreement with past empirical and theoretical evidence (see e.g. [4]), learning multiple
tasks together signiﬁcantly improves on learning the tasks independently. Moreover, the perfor-
mance of the algorithm improves when more tasks are available. This improvement is moderate for
low dimensionalities but increases as the number of irrelevant dimensions increases.

T = 200
T = 100
T = 25
T = 10
independent

T = 200
T = 100
T = 25
T = 10
independent

1.2

1.1

1

0.9

0.8

0.7

10

15

20

25

5

10

15

20

25

0.16

0.14

0.12

0.1

0.08

0.06

0.04
5

Figure 2: Test error (left) and residual of learned features (right) vs. dimensionality of the input.

5.3

5.2

5.1

5

4.9

4.8

4.7

4.6

4.5

4.4

4.3
0

50

100

150

200

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

2

4

6

8

10

12

14

0.25

0.2

0.15

0.1

0.05

0

−0.05

−0.1

TE RAM SC CPU HD CD CA CO AV WA SW GU PR

Figure 3: Test error vs. number of tasks (left) for the computer survey data set. Signiﬁcance of
features (middle) and attributes learned by the most important feature (right).

On the right, we have plotted a residual measure of how well the learned features approximate
the actual ones used to generate the data. More speciﬁcally , we depict the Frobenius norm of the
difference of the learned and actual D’s versus the input dimensionality. We observe that adding
more tasks leads to better estimates of the underlying features.
Conjoint analysis experiment. We then tested the method using a real data set about people’s
ratings of products from [13]. The data was taken from a survey of 180 persons who rated the
likelihood of purchasing one of 20 different personal computers. Here the persons correspond to
tasks and the PC models to examples. The input is represented by the following 13 binary attributes:
telephone hot line (TE), amount of memory (RAM), screen size (SC), CPU speed (CPU), hard
disk (HD), CD-ROM/multimedia (CD), cache (CA), Color (CO), availability (AV), warranty (WA),
software (SW), guarantee (GU) and price (PR). We also added an input component accounting for
the bias term. The output is an integer rating on the scale 0(cid:0) 10. Following [13], we used 4 examples
per task as the test data and 8 examples per task as the training data.
As shown in Figure 3, the performance of our algorithm improves with the number of tasks. It also
performs much better than independent ridge regressions, whose test error is equal to 16:53. In this
particular problem, it is also important to investigate which features are signi ﬁcant
to all consumers
and how they weight the 13 computer attributes. We demonstrate the results in the two adjacent
plots, which were obtained with the data for all 180 tasks. In the middle, the distribution of the
eigenvalues of D is depicted, indicating that there is a single most important feature which is shared
by all persons. The plot on the right shows the weight of each input dimension in this most important
feature. This feature seems to weight the technical characteristics of a computer (RAM, CPU and
CD-ROM) against its price. Therefore, in this application our algorithm is able to discern interesting
patterns in people’s decision process.
School data. Preliminary experiments with the school data used in [3] achieved explained variance
37:1% compared to 29:5% in that paper. These results will be reported in future work.

6 Conclusion

We have presented an algorithm which learns common sparse function representations across a pool
of related tasks. To our knowledge, our approach provides the ﬁrst convex optimization formulation
for multi-task feature learning. Although convex optimization methods have been derived for the

simpler problem of feature selection [12], prior work on multi-task feature learning has been based
on more complex optimization problems which are not convex [2, 4, 6] and, so, are at best only
guaranteed to converge to a local minimum.

Our algorithm shares some similarities with recent work in [2] where they also alternately update
the task parameters and the features. Two main differences are that their formulation is not convex
and that, in our formulation, the number of learned features is not a parameter but it is controlled by
the regularization parameter.

This work may be extended in different directions. For example, it would be interesting to explore
whether our formulation can be extended to more general models for the structure across the tasks,
like in [20] where ICA type features are learned, or to hierarchical feature models like in [18].

Acknowledgments
We wish to thank Yiming Ying and Raphael Hauser for observations on the convexity of (3.2),
Charles Micchelli for valuable suggestions and the anonymous reviewers for their useful comments.
This work was supported by EPSRC Grants GR/T18707/01 and EP/D071542/1, and by the IST
Programme of the European Commission, under the PASCAL Network of Excellence IST-2002-
506778.
References
[1] J.Abernethy, F. Bach, T. Evgeniou and J-P. Vert. Low-rank matrix factorization with attributes. Technical
report N24/06/MM, Ecole des Mines de Paris, 2006.
[2] R.K. Ando and T. Zhang. A framework for learning predictive structures from multiple tasks and unla-
beled data. J. Machine Learning Research. 6: 1817–1853, 2005.
[3] B. Bakker and T. Heskes. Task clustering and gating for Bayesian multi–task learning. J. of Machine
Learning Research, 4: 83–99, 2003.
[4] J. Baxter. A model for inductive bias learning. J. of Artiﬁcial
Intelligence Research, 12: 149–198, 2000.
[5] S. Ben-David and R. Schuller. Exploiting task relatedness for multiple task learning. Proceedings of
Computational Learning Theory (COLT), 2003.
[6] R. Caruana. Multi–task learning. Machine Learning, 28: 41–75, 1997.
[7] D. Donoho. For most large underdetermined systems of linear equations, the minimal l 1 -norm near-
solution approximates the sparsest near-solution. Preprint, Dept. of Statistics, Stanford University,
2004.
[8] T. Evgeniou, C.A. Micchelli and M. Pontil. Learning multiple tasks with kernel methods. J. Machine
Learning Research, 6: 615–637, 2005.
[9] T. Evgeniou, M. Pontil and O. Toubia. A convex optimization approach to modeling consumer hetero-
geneity in conjoint estimation. INSEAD N 2006/62/TOM/DS.
[10] M. Fazel, H. Hindi and S. P. Boyd. A rank minimization heuristic with application to minimum order
system approximation. Proceedings, American Control Conference, 6, 2001.
[11] T. Hastie, R. Tibshirani and J. Friedman. The Elements of Statistical Learning: Data Mining, Inference
and Prediction. Springer Verlag Series in Statistics, New York, 2001.
[12] T. Jebara. Multi-task feature and kernel selection for SVMs. Proc. of ICML 2004.
[13] P.J. Lenk, W.S. DeSarbo, P.E. Green, M.R. Young. Hierarchical Bayes conjoint analysis: recovery of
partworth heterogeneity from reduced experimental designs. Marketing Science, 15(2): 173–191, 1996.
[14] C.A. Micchelli and A. Pinkus. Variational problems arising from balancing several error criteria. Ren-
diconti di Matematica, Serie VII, 14: 37-86, 1994.
[15] C. A. Micchelli and M. Pontil. On learning vector–valued functions. Neural Computation, 17:177–204,
2005.
[16] T. Serre, M. Kouh, C. Cadieu, U. Knoblich, G. Kreiman, T. Poggio. Theory of object recognition:
computations and circuits in the feedforward path of the ventral stream in primate visual cortex. AI
Memo No. 2005-036, MIT, Cambridge, MA, October, 2005.
[17] N. Srebro, J.D.M. Rennie, and T.S. Jaakkola. Maximum-margin matrix factorization. NIPS 2004.
[18] A. Torralba, K. P. Murphy and W. T. Freeman. Sharing features: efﬁcient boosting procedures for
multiclass object detection. Proc. of CVPR’04, pages 762–769, 2004.
[19] K. Yu, V. Tresp and A. Schwaighofer. Learning Gaussian processes from multiple tasks. Proc. of ICML
2005.
[20] J. Zhang, Z. Ghahramani and Y. Yang. Learning Multiple Related Tasks using Latent Independent
Component Analysis. NIPS 2006.

