Information Bottleneck Optimization and
Independent Component Extraction with Spiking
Neurons

Stefan Klampﬂ, Robert Legenstein, Wolfgang Maass
Institute for Theoretical Computer Science
Graz University of Technology
A-8010 Graz, Austria
{klampfl,legi,maass}@igi.tugraz.at

Abstract

The extraction of statistically independent components from high-dimensional
multi-sensory input streams is assumed to be an essential component of sensory
processing in the brain. Such independent component analysis (or blind source
separation) could provide a less redundant representation of information about the
external world. Another powerful processing strategy is to extract preferentially
those components from high-dimensional input streams that are related to other
information sources, such as internal predictions or proprioceptive feedback. This
strategy allows the optimization of internal representation according to the infor-
mation bottleneck method. However, concrete learning rules that implement these
general unsupervised learning principles for spiking neurons are still missing. We
show how both information bottleneck optimization and the extraction of inde-
pendent components can in principle be implemented with stochastically spiking
neurons with refractoriness. The new learning rule that achieves this is derived
from abstract information optimization principles.

1 Introduction

The Information Bottleneck (IB) approach and independent component analysis (ICA) have both
attracted substantial interest as general principles for unsupervised learning [1, 2]. A hope has been,
that they might also help us to understand strategies for unsupervised learning in biological systems.
However it has turned out to be quite difﬁcult to establish links between known learning algorithms
that have been derived from these general principles, and learning rules that could possibly be im-
plemented by synaptic plasticity of a spiking neuron. Fortunately, in a simpler context a direct link
between an abstract information theoretic optimization goal and a rule for synaptic plasticity has
recently been established [3]. The resulting rule for the change of synaptic weights in [3] maxi-
mizes the mutual information between pre- and postsynaptic spike trains, under the constraint that
the postsynaptic ﬁring rate stays close to some target ﬁring rate. We show in this article, that this
approach can be extended to situations where simultaneously the mutual information between the
postsynaptic spike train of the neuron and other signals (such as for example the spike trains of other
neurons) has to be minimized (Figure 1). This opens the door to the exploration of learning rules
for information bottleneck analysis and independent component extraction with spiking neurons that
would be optimal from a theoretical perspective.
We review in section 2 the neuron model and learning rule from [3]. We show in section 3 how this
learning rule can be extended so that it not only maximizes mutual information with some given
spike trains and keeps the output ﬁring rate within a desired range, but simultaneously minimizes
mutual information with other spike trains, or other time-varying signals. Applications to infor-

A

B

Figure 1: Different learning situations analyzed in this article. A In an information bottleneck task
the learning neuron (neuron 1) wants to maximize the mutual information between its output Y K
1
and the activity of one or several target neurons Y K
3 , . . . (which can be functions of the inputs
2 , Y K
X K and/or other external signals), while at the same time keeping the mutual information between
the inputs X K and the output Y K
1 as low as possible (and its ﬁring rate within a desired range). Thus
the neuron should learn to extract from its high-dimensional input those aspects that are related to
these target signals. This setup is discussed in sections 3 and 4. B Two neurons receiving the
same inputs X K from a common set of presynaptic neurons both learn to maximize information
statistically independent. Such
1 and Y K
transmission, and simultaneously to keep their outputs Y K
2
extraction of independent components from the input is described in section 5.

mation bottleneck tasks are discussed in section 4. In section 5 we show that a modiﬁcation of
this learning rule allows a spiking neuron to extract information from its input spike trains that is
independent from the component extracted by another neuron.

2 Neuron model and a basic learning rule

(1)

We use the model from [3], which is a stochastically spiking neuron model with refractoriness,
where the probability of ﬁring in each time step depends on the current membrane potential and the
time since the last output spike. It is convenient to formulate the model in discrete time with step
k(cid:88)
N(cid:88)
size ∆t. The total membrane potential of a neuron i in time step tk = k∆t is given by
wij (tk − tn )xn
ui (tk ) = ur +
j ,
n=1
j=1
where ur = −70mV is the resting potential and wij is the weight of synapse j (j = 1, . . . , N ).
j =
An input spike train at synapse j up to the k-th time step is described by a sequence X k
j = 1)
j ) of zeros (no spike) and ones (spike); each presynaptic spike at time tn (xn
(x1
j , . . . , xk
j , x2
evokes a postsynaptic potential (PSP) with exponentially decaying time course (t − tn ) with time
constant τm = 10ms. The probability ρk
i of ﬁring of neuron i in each time step tk is given by
i = 1 − exp[−g(ui (tk )Ri (tk )∆t] ≈ g(ui (tk ))Ri (tk )∆t,
(2)
ρk
where g(u) = r0 log{1 + exp[(u − u0 )/∆u]} is a smooth increasing function of the membrane
potential u (u0 = −65mV, ∆u = 2mV, r0 = 11Hz). The approximation is valid for sufﬁciently
(t−ˆti−τabs )2
i ¿ 1). The refractory variable Ri (t) =
ref r +(t−ˆti−τabs )2 Θ(t − ˆti − τabs ) assumes
small ∆t (ρk
τ 2
values in [0, 1] and depends on the last ﬁring time ˆti of neuron i (absolute refractory period τabs =
3ms, relative refractory time τref r = 10ms). The Heaviside step function Θ takes a value of 1 for
non-negative arguments and 0 otherwise.
This model from [3] is a special case of the spike-response model, and with a refractory variable
R(t) that depends only on the time since the last postsynaptic event it has renewal properties [4].

i that assumes the value 1 if a
The output of neuron i at the k-th time step is denoted by a variable yk
postsynaptic spike occurred and 0 otherwise. A speciﬁc spike train up to the k-th time step is written
i = (y1
i ).
as Y k
i , . . . , yk
i , y2
(cid:88)
The information transmission between an ensemble of input spike trains XK and the output spike
i can be quantiﬁed by the mutual information1 [5]
train YK
|X K )
i ) log P (Y K
I (XK ; YK
i ) =
P (X K , Y K
i
P (Y K
i )
(cid:80)
XK ,Y K
i
i ) − γDKL (P (Y K
i )|| ˜P (Y K
The idea in [3] was to maximize the quantity I (XK ; YK
i )), where
i )|| ˜P (Y K
i )/ ˜P (Y K
DKL (P (Y K
i ) log(P (Y K
P (Y K
i )) denotes the Kullback-Leibler di-
i )) =
Y K
i
vergence [5], imposing the additional constraint that the ﬁring statistics P (Yi ) of the neuron should
stay as close as possible to a target distribution ˜P (Yi ). This distribution was chosen to be that of a
constant target ﬁring rate ˜g accounting for homeostatic processes. An online learning-rule perform-
ing gradient ascent on this quantity was derived for the weights wij of neuron i, with ∆wk
ij denoting
the weight change during the k-th time step:
∆wk
ij
∆t
which consists of the “correlation term” C k
i [3]. The term C k
ij and the “postsynaptic term” B k
ij
(cid:181)
(cid:182)
measures coincidences between postsynaptic spikes at neuron i and PSPs generated by presynaptic
k(cid:88)
(cid:164)
(cid:163)
action potentials arriving at synapse j ,
g 0 (u1 (tk ))
1 − ∆t
1 − ρk
(tk − tn )xn
1j = C k−1
C k
yk
g(u1 (tk ))
1
j
1j
τC
n=1
(cid:182)γ (cid:184)
(cid:181)
(cid:183)
in an exponential time window with time constant τC = 1s and g 0 (ui (tk )) denoting the derivative
of g with respect to u. The term
(cid:163)
(cid:164)
˜g
g(u1 (tk ))
1 (γ ) = yk
log
1
B k
∆t
¯g1 (tk )
¯g1 (tk )
− (1 − yk
g(u1 (tk )) − (1 + γ )¯g1 (tk ) + γ ˜g
1 )R1 (tk )
(6)
,
compares the current ﬁring rate g(ui (tk )) with its average ﬁring rate2 ¯gi (tk ), and simultaneously
the running average ¯gi (tk ) with the constant target rate ˜g . The argument indicates that this term also
depends on the optimization parameter γ .

= αC k
i (γ ),
ij B k

(4)

,

(5)

.

(3)

+

3 Learning rule for multi-neuron interactions

We extend the learning rule presented in the previous section to a more complex scenario, where the
1 of the learning neuron (neuron 1) and some
mutual information between the output spike train Y K
(l > 1) has to be maximized, while simultaneously minimizing the mutual
target spike trains Y K
l
1 . Obviously, this is the generic IB scenario
information between the inputs X K and the output Y K
applied to spiking neurons (see Figure 1A). A learning rule for extracting independent components
with spiking neurons (see section 5) can be derived in a similar manner.
For simplicity, we consider the case of an IB optimization for only one target spike train Y K
2 , and
derive an update rule for the synaptic weights w1j of neuron 1. The quantity to maximize is therefore
L = −I (XK ; YK
2 ) − γDKL (P (Y K
1 )|| ˜P (Y K
1 ) + β I (YK
1 ; YK
1 )),
(7)
where β and γ are optimization constants. To maximize this objective function, we derive the weight
change ∆wk
1j during the k-th time step by gradient ascent on (7), assuming that the weights w1j can
change between some bounds 0 ≤ w1j ≤ wmax (we assume wmax = 1 throughout this paper).
1We use boldface letters (Xk ) to distinguish random variables from speciﬁc realizations (X k ).
2The rate ¯gi (tk ) = hg(ui (tk ))iXk |Y k−1
denotes an expectation of the ﬁring rate over the input distribution
i
given the postsynaptic history and is implemented as a running average with an exponential time window (with
a time constant of 10ms).

)

−

.

(8)

¯g12 (tk )
¯g1 (tk )

2 log
12 = yk
1 yk
F k

Note that all three terms of (7) implicitly depend on w1j because the output distribution P (Y K
1 )
changes if we modify the weights w1j . Since the ﬁrst and the last term of (7) have already been
considered (up to the sign) in [3], we will concentrate here on the middle term L12 := β I (YK
1 ; YK
2 )
and denote the contribution of the gradient of L12 to the total weight change ∆wk
1j in the k-th time
step by ∆ ˜wk
1j .
(cid:81)K
(cid:81)K
In order to get an expression for the weight change in a speciﬁc time step tk we write the probabilities
2 ) occurring in (7) as products over individual time bins, i.e., P (Y K
i ) and P (Y K
P (Y K
i ) =
1 , Y K
(cid:80)K
2 |Y k−1
i |Y k−1
, Y k−1
k=1 P (yk
) and P (Y K
2 ) =
k=1 P (yk
), according to the chain rule
1 , Y K
1 , yk
1
2
i
(cid:43)
(cid:42)
of information theory [5]. Consequently, we rewrite L12 as a sum over the contributions of the
k=1 ∆Lk
individual time bins, L12 =
12 , with
2 |Y k−1
, Y k−1
β log P (yk
)
1 , yk
12 =
∆Lk
2
1
2 |Y k−1
1 |Y k−1
)P (yk
P (yk
1
2
Xk ,Yk
1 ,Yk
2
(cid:173)
(cid:174)
The weight change ∆ ˜wk
1j is then proportional to the gradient of this expression with respect to the
12 /∂w1j ), with some learning rate α > 0. The evaluation of the
1j = α(∂∆Lk
weights w1j , i.e., ∆ ˜wk
(cid:184)
(cid:183)
gradient yields ∆ ˜wk
1j = α
with a correlation term C k
1j as in (5) and a term
1j βF k
C k
12
1 ,Yk
Xk ,Yk
2
(cid:183)
(cid:184)
¯g12 (tk )
− yk
1 (1 − yk
− ¯g2 (tk )
2 )R2 (tk )∆t
¯g1 (tk )¯g2 (tk )
2 )R1 (tk )R2 (tk )(∆t)2 (cid:163)
(cid:164)
¯g12 (tk )
− (1 − yk
− ¯g1 (tk )
1 )yk
2 R1 (tk )∆t
+
¯g2 (tk )
¯g12 (tk ) − ¯g1 (tk )¯g2 (tk )
+ (1 − yk
1 )(1 − yk
Here, ¯gi (tk ) = hg(ui (tk ))iXk |Y k−1
denotes the average ﬁring rate of neuron i and ¯g12 (tk ) =
hg(u1 (tk ))g(u2 (tk ))iXk |Y k−1
i
denotes the average product of ﬁring rates of both neurons. Both
,Y k−1
2
1
quantities are implemented online as running exponential averages with a time constant of 10s.
Under the assumption of a small learning rate α we can approximate the expectation h·iXk ,Yk
1 ,Yk
2
by averaging over a single long trial. Considering now all three terms in (7) we ﬁnally arrive at an
(cid:164)
(cid:163)
online rule for maximizing (7)
∆wk
1 (−γ ) − β∆tB k
1j
B k
∆t
12
1j sensitive to correlations between the output of the neuron and its
which consists of a term C k
12 that characterize the
1 and B k
presynaptic input at synapse j (“correlation term”) and terms B k
1 is different
postsynaptic state of the neuron (“postsynaptic terms”). Note that the argument of B k
from (4) because some of the terms of the objective function (7) have a different sign. In order to
compensate the effect of a small ∆t, the constant β has to be large enough for the term B k
12 to have
an inﬂuence on the weight change.
1 were described in the previous section.
In addition, our learning rule
The factors C k
1j and B k
(cid:184)
(cid:183)
12 /(∆t)2 that is sensitive to the statistical dependence between
12 = F k
contains an extra term B k
the output spike train of the neuron and the target. It is given by
(cid:183)
(cid:184)
¯g12 (tk )
12 = yk
1 yk
− yk
− ¯g2 (tk )
(1 − yk
(∆t)2 log
2 )R2 (tk )
2
1
B k
¯g1 (tk )¯g2 (tk )
∆t
(cid:163)
(cid:164)
¯g12 (tk )
− yk
− ¯g1 (tk )
(1 − yk
1 )R1 (tk )
2
¯g2 (tk )
∆t
¯g12 (tk ) − ¯g1 (tk )¯g2 (tk )
+ (1 − yk
1 )(1 − yk
2 )R1 (tk )R2 (tk )
(11)
.
This term basically compares the average product of ﬁring rates ¯g12 (which corresponds to the joint
probability of spiking) with the product of average ﬁring rates ¯g1 ¯g2 (representing the probability
of independent spiking). In this way, it measures the momentary mutual information between the
output of the neuron and the target spike train.

¯g12 (tk )
¯g1 (tk )

.

(9)

= −αC k
1j

.

(10)

log

ν k
1
¯ν k
1

¯ν k
1
˜g

f (ν k
1 )

∆wk
1j
∆t

= −αν pre,k
j

For a simpliﬁed neuron model without refractoriness (R(t) = 1), the update rule (4) resembles the
BCM-rule [6] as shown in [3]. With the objective function (7) to maximize, we expect an “anti-
Hebbian BCM” rule with another term accounting for statistical dependencies between Y K
and
1
2 . Since there is no refractoriness, the postsynaptic rate ν1 (tk ) is given directly by the current
Y K
(cid:189)
(cid:183)
(cid:181)
(cid:182)γ (cid:184)
value of g(u(tk )), and the update rule (10) reduces to the rate model3
(cid:184)(cid:182)(cid:190)
(cid:183)
(cid:184)
(cid:183)
(cid:181)
2 log
ν k

¯ν k
¯ν k
(cid:80)k
12
12
1 ¯ν k
¯ν k
1 ¯ν k
¯ν k
2
2
n=1 (tk − tn )xn
where the presynaptic rate at synapse j at time tk is denoted by ν pre,k
= a
j
j
with a in units (Vs)−1 . The values ¯ν k
1 , ¯ν k
2 , and ¯ν k
12 are running averages of the output rate ν k
1 , the
2 , respectively. The function
rate of the target signal ν k
2 and of the product of these values, ν k
1 ν k
1 ) = g 0 (g−1 (ν k
f (ν k
1 ))/a is proportional to the derivative of g with respect to u, evaluated at the
current membrane potential. The ﬁrst term in the curly brackets accounts for the homeostatic process
(similar to the BCM rule, see [3]), whereas the second term reinforces dependencies between Y K
1
and Y K
2 . Note that this term is zero if the rates of the two neurons are independent.
It is interesting to note that if we rewrite the simpliﬁed rate-based learning rule (12) in the following
way,

−β∆t

− ¯ν k
2

,

(12)

− 1

∆wk
= −αν pre,k
1j
Φ(ν k
2 ),
1 , ν k
∆t
j
we can view it as an extension of the classical Bienenstock-Cooper-Munro (BCM) rule [6] with a
2 ). Here, values of Φ > 0 produce LTD
two-dimensional synaptic modiﬁcation function Φ(ν k
1 , ν k
whereas values of Φ < 0 produce LTP. These regimes are separated by a sliding threshold, however,
in contrast to the original BCM rule this threshold does not only depend on the running average of
2 and ¯ν k
the postsynaptic rate ¯ν k
2 .
1 , but also on the current values of ν k

(13)

4 Application to Information Bottleneck Optimization

,

(14)

12 + B k
B k
13

= −αC k
1j

1 of
We use a setup as in Figure 1A where we want to maximize the information which the output Y K
3 . If the target signals are statistically
2 and Y K
a learning neuron conveys about two target signals Y K
independent from each other we can optimize the mutual information to each target signal separately.
(cid:162)(cid:164)
(cid:161)
(cid:163)
This leads to an update rule
∆wk
1 (−γ ) − β∆t
1j
B k
∆t
13 are the postsynaptic terms (11) sensitive to the statistical dependence between
12 and B k
where B k
the output and target signals 1 and 2, respectively. We choose ˜g = 30Hz for the target ﬁring rate,
and we use discrete time with ∆t = 1ms.
In this experiment we demonstrate that it is possible to consider two very different kinds of target
signals: one target spike train has has a similar rate modulation as one part of the input, while the
other target spike train has a high spike-spike correlation with another part of the input. The learning
neuron receives input at 100 synapses, which are divided into 4 groups of 25 inputs each. The ﬁrst
two input groups consist of rate modulated Poisson spike trains4 (Figure 2A). Spike trains from the
remaining groups 3 and 4 are correlated with a coefﬁcient of 0.5 within each group, however, spike
trains from different groups are uncorrelated. Correlated spike trains are generated by the procedure
described in [7].
The ﬁrst target signal is chosen to have the same rate modulation as the inputs from group 1, except
that Gaussian random noise is superimposed with a standard deviation of 2Hz. The second target
spike train is correlated with inputs from group 3 (with a coefﬁcient of 0.5), but uncorrelated to
inputs from group 4. Furthermore, both target signals are silent during random intervals: at each
3 In the absence of refractoriness we use an alternative gain function galt (u) = [1/gmax + 1/g(u)]−1 in
order to pose an upper limit of gmax = 100Hz on the postsynaptic ﬁring rate.

A

D

B

E

C

F

Figure 2: Performance of the spike-based learning rule (10) for the IB task. A Modulation of input
rates to input groups 1 and 2. B Evolution of weights during 60 minutes of learning (bright: strong
synapses, wij ≈ 1, dark: depressed synapses, wij ≈ 0.) Weights are initialized randomly between
0.10 and 0.12, α = 10−4 , β = 2 · 103 , γ = 50. C Output rate and rate of target signal 1 during 5
seconds after learning. D Evolution of the average mutual information per time bin (solid line, left
scale) between input and output and the Kullback-Leibler divergence per time bin (dashed line, right
scale) as a function of time. Averages are calculated over segments of 1 minute. E Evolution of the
average mutual information per time bin between output and both target spike trains as a function
of time. F Trace of the correlation between output rate and rate of target signal 1 (solid line) and
the spike-spike correlation (dashed line) between the output and target spike train 2 during learning.
Correlation coefﬁcients are calculated every 10 seconds.

time step, each target signal is independently set to 0 with a certain probability (10−5 ) and remains
silent for a duration chosen from a Gaussian distribution with mean 5s and SD 1s (minimum duration
is 1s). Hence this experiment tests whether learning works even if the target signals are not available
all of the time.
Figure 2 shows that strong weights evolve for the ﬁrst and third group of synapses, whereas the
efﬁcacies for the remaining inputs are depressed. Both groups with growing weights are correlated
with one of the target signals, therefore the mutual information between output and target spike trains
increases. Since spike-spike correlations convey more information than rate modulations synaptic
efﬁcacies develop more strongly to group 3 (the group with spike-spike correlations). This results in
an initial decrease in correlation with the rate-modulated target to the beneﬁt of higher correlation
with the second target. However, after about 30 minutes when the weights become stable, the
correlations as well as the mutual information quantities stay roughly constant.
An application of the simpliﬁed rule (12) to the same task is shown in Figure 3 where it can be
seen that strong weights close to wmax are developed for the rate-modulated input. To some extent
weights grow also for the inputs with spike-spike correlations in order to reach the constant target
ﬁring rate ˜g . In contrast to the spike-based rule the simpliﬁed rule is not able to detect spike-spike
correlations between output and target spike trains.

4The rate of the ﬁrst 25 inputs is modulated by a Gaussian white-noise signal with mean 20Hz that has been
low pass ﬁltered with a cut-off frequency of 5Hz. Synapses 26 to 50 receive a rate that has a constant value
of 2Hz, except that a burst is initiated at each time step with a probability of 0.0005. Thus there is a burst on
average every 2s. The duration of a burst is chosen from a Gaussian distribution with mean 0.5s and SD 0.2s,
the minimum duration is chosen to be 0.1s. During a burst the rate is set to 50Hz. In the simulations we use
discrete time with ∆t = 1ms.

025005000050input 1 [Hz]025005000050input 2 [Hz]t [ms]t [min]synapse idxevolution of weights  2040602040608010000.51025005000050output [Hz]025005000050target 1 [Hz]t [ms]020406000.0050.01t [min]MI/KLD of neuron 1020406000.020.04020406000.51x 10−3t [min]I(output;targets)020406000.10.20.30.40.5t [min]correlation with targets  target 1target 2A

B

C

Figure 3: Performance of the simpliﬁed update rule (12) for the IB task. A Evolution of weights
during 30 minutes of learning (bright: strong synapses, wij ≈ 1, dark: depressed synapses, wij ≈
0.) Weights are initialized randomly between 0.10 and 0.12, α = 10−3 , β = 104 , γ = 10. B
Evolution of the average mutual information per time bin (solid line, left scale) between input and
output and the Kullback-Leibler divergence per time bin (dashed line, right scale) as a function of
time. Averages are calculated over segments of 1 minute. C Trace of the correlation between output
rate and target rate during learning. Correlation coefﬁcients are calculated every 10 seconds.

5 Extracting Independent Components

With a slight modiﬁcation in the objective function (7) the learning rule allows us to extract statis-
tically independent components from an ensemble of input spike trains. We consider two neurons
receiving the same input at their synapses (see Figure 1B). For both neurons i = 1, 2 we maximize
information transmission under the constraint that their outputs stay as statistically independent from
each other as possible. That is, we maximize
i )|| ˜P (Y K
2 ) − γDKL (P (Y K
i ) − β I (YK
˜Li = I (XK ; YK
i )).
1 ; YK
(15)
Since the same terms (up to the sign) are optimized in (7) and (15) we can derive a gradient ascent
(cid:164)
(cid:163)
rule for the weights of neuron i, wij , analogously to section 3:
∆wk
i (γ ) − β∆tB k
ij
B k
∆t
12

= αC k
ij

.

(16)

Figure 4 shows the results of an experiment where two neurons receive the same Poisson input with a
rate of 20Hz at their 100 synapses. The input is divided into two groups of 40 spike trains each, such
that synapses 1 to 40 and 41 to 80 receive correlated input with a correlation coefﬁcient of 0.5 within
each group, however, any spike trains belonging to different input groups are uncorrelated. The
remaining 20 synapses receive uncorrelated Poisson input. Weights close to the maximal efﬁcacy
wmax = 1 are developed for one of the groups of synapses that receives correlated input (group 2 in
this case) whereas those for the other correlated group (group 1) as well as those for the uncorrelated
group (group 3) stay low. Neuron 2 develops strong weights to the other correlated group of synapses
(group 1) whereas the efﬁcacies of the second correlated group (group 2) remain depressed, thereby
trying to produce a statistically independent output. For both neurons the mutual information is
maximized and the target output distribution of a constant ﬁring rate of 30Hz is approached well.
After an initial increase in the mutual information and in the correlation between the outputs, when
the weights of both neurons start to grow simultaneously, the amounts of information and correlation
drop as both neurons develop strong efﬁcacies to different parts of the input.

6 Discussion

Information Bottleneck (IB) and Independent Component Analysis (ICA) have been proposed as
general principles for unsupervised learning in lower cortical areas, however, learning rules that
can implement these principles with spiking neurons have been missing. In this article we have
derived from information theoretic principles learning rules which enable a stochastically spiking
neuron to solve these tasks. These learning rules are optimal from the perspective of information
theory, but they are not local in the sense that they use only information that is available at a single

t [min]synapse idxevolution of weights  102030204060801000.20.40.60.81010203001234x 10−3t [min]MI/KLD of neuron 1010203000.010.020.030.0401020300.10.20.30.40.5t [min]correlation with target 1A

D

B

E

C

F

Figure 4: Extracting independent components. A,B Evolution of weights during 30 minutes of
learning for both postsynaptic neurons (red: strong synapses, wij ≈ 1, blue: depressed synapses,
wij ≈ 0.) Weights are initialized randomly between 0.10 and 0.12, α = 10−3 , β = 100, γ = 10.
C Evolution of the average mutual information per time bin between both output spike trains as
a function of time. D,E Evolution of the average mutual information per time bin (solid line, left
scale) between input and output and the Kullback-Leibler divergence per time bin for both neurons
(dashed line, right scale) as a function of time. Averages are calculated over segments of 1 minute.
F Trace of the correlation between both output spike trains during learning. Correlation coefﬁcients
are calculated every 10 seconds.

synapse without an auxiliary network of interneurons or other biological processes. Rather, they tell
us what type of information would have to be ideally provided by such auxiliary network, and how
the synapse should change its efﬁcacy in order to approximate a theoretically optimal learning rule.

Acknowledgments

We would like to thank Wulfram Gerstner and Jean-Pascal Pﬁster for helpful discussions. This paper
was written under partial support by the Austrian Science Fund FWF, # S9102-N13 and # P17229-
N04, and was also supported by PASCAL, project # IST2002-506778, and FACETS, project #
15879, of the European Union.

References
[1] N. Tishby, F. C. Pereira, and W. Bialek. The information bottleneck method. In Proceedings of the 37-th
Annual Allerton Conference on Communication, Control and Computing, pages 368–377, 1999.
[2] A. Hyv ¨arinen, J. Karhunen, and E. Oja. Independent Component Analysis. Wiley, New York, 2001.
[3] T. Toyoizumi, J.-P. Pﬁster, K. Aihara, and W. Gerstner. Generalized Bienenstock-Cooper-Munro rule for
spiking neurons that maximizes information transmission. Proc. Natl. Acad. Sci. USA, 102:5239–5244,
2005.
[4] W. Gerstner and W. M. Kistler. Spiking Neuron Models. Cambridge University Press, Cambridge, 2002.
[5] T. M. Cover and J. A. Thomas. Elements of Information Theory. Wiley, New York, 1991.
[6] E. L. Bienenstock, L. N. Cooper, and P. W. Munro. Theory for the development of neuron selectivity:
orientation speciﬁcity and binocular interaction in visual cortex. J. Neurosci., 2(1):32–48, 1982.
[7] R. G ¨utig, R. Aharonov, S. Rotter, and H. Sompolinsky. Learning input correlations through non-linear
temporally asymmetric hebbian plasticity. Journal of Neurosci., 23:3697–3714, 2003.

t [min]synapse idxweights of neuron 1  1020302040608010000.51t [min]synapse idxweights of neuron 2  1020302040608010000.5101020300246x 10−4t [min]I(output 1;output2)010203000.0040.0080.0120.016t [min]010203000.010.020.030.04MI/KLD of neuron 1010203000.0040.0080.0120.016t [min]MI/KLD of neuron 2010203000.010.020.030.04010203000.20.40.6t [min]correlation between outputs