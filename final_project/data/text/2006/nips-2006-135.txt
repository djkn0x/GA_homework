Bayesian Image Super-resolution, Continued

Lyndsey C. Pickup, David P. Capel† , Stephen J. Roberts Andrew Zisserman
Information Engineering Building, Dept. of Eng. Science, Parks Road, Oxford, OX1 3PJ, UK
{elle,sjrob,az}@robots.ox.ac.uk
† 2D3, d.capel@2d3.com

Abstract

This paper develops a multi-frame image super-resolution approach from a
Bayesian view-point by marginalizing over the unknown registration parameters
relating the set of input low-resolution views. In Tipping and Bishop’s Bayesian
image super-resolution approach [16], the marginalization was over the super-
resolution image, necessitating the use of an unfavorable image prior. By inte-
grating over the registration parameters rather than the high-resolution image, our
method allows for more realistic prior distributions, and also reduces the dimen-
sion of the integral considerably, removing the main computational bottleneck of
the other algorithm. In addition to the motion model used by Tipping and Bishop,
illumination components are introduced into the generative model, allowing us
to handle changes in lighting as well as motion. We show results on real and
synthetic datasets to illustrate the efﬁcacy of this approa ch.

1 Introduction

Multi-frame image super-resolution refers to the process by which a group of images of the same
scene are fused to produce an image or images with a higher spatial resolution, or with more visible
detail in the high spatial frequency features [7]. Such problems are common, with everything from
holiday snaps and DVD frames to satellite terrain imagery providing collections of low-resolution
images to be enhanced, for instance to produce a more aesthetic image for media publication [15],
or for higher-level vision tasks such as object recognition or localization [5].

Limits on the resolution of the original imaging device can be improved by exploiting the relative
sub-pixel motion between the scene and the imaging plane. No matter how accurate the registration
estimate, there will be some residual uncertainty associated with the parameters [13]. We propose a
scheme to deal with this uncertainty by integrating over the registration parameters, and demonstrate
improved results on synthetic and real digital image data.

Image registration and super-resolution are often treated as distinct processes, to be considered se-
quentially [1, 3, 7]. Hardie et al. demonstrated that the low-resolution image registration can be
updated using the super-resolution image estimate, and that this improves a Maximum a Posteriori
(MAP) super-resolution image estimate [5]. More recently, Pickup et al. used a similar joint MAP
approach to learn more general geometric and photometric registrations, the super-resolution image,
and values for the prior’s parameters simultaneously [12]. Tipping and Bishop’s Bayesian image
super-resolution work [16] uses a Maximum Likelihood (ML) point estimate of the registration pa-
rameters and the camera imaging blur, found by integrating the high-resolution image out of the
registration problem and optimizing the marginal probability of the observed low-resolution images
directly. This gives an improvement in the accuracy of the recovered registration (measured against
known truth on synthetic data) compared to the MAP approach.

The image-integrating Bayesian super-resolution method [16] is extremely costly in terms of com-
putation time, requiring operations that scale with the cube of the total number of high-resolution

pixels, severely limiting the size of the image patches over which they perform the registration (they
use 9 × 9 pixel patches). The marginalization also requires a form of prior on the super-resolution
image that renders the integral tractable, though priors such as Tipping and Bishop’s chosen Gaus-
sian form are known to be poor for tasks such as edge preservation, and much super-resolution work
has employed other more favorable priors [2, 3, 4, 11, 14].

It is generally more desirable to integrate over the registration parameters rather than the super-
resolution image, because it is the registration that constitutes the “nuisance parameters”, and the
super-resolution image that we wish to estimate. We derive a new view of Bayesian image super-
resolution in which a MAP high-resolution image estimate is found by marginalizing over the
uncertain registration parameters. Memory requirements are considerably lower than the image-
integrating case; while the algorithm is more costly than a simple MAP super-resolution estimate, it
is not infeasible to run on images of several hundred pixels in size.

Sections 2 and 3 develop the model and the proposed objective function. Section 4 evaluates re-
sults on synthetically-generated sequences (with ground truth for comparison), and on a real data
example. A discussion of this approach and concluding remarks can be found in section 5.

2 Generative model

The generative model for multi-frame super-resolution assumes a known scene x (vectorized, size
N × 1), and a given registration vector θ(k) . These are used to generate a vectorized low-resolution
image y(k) with M pixels through a system matrix W(k) . Gaussian i.i.d. noise with precision β is
then added to y(k) ,

α W (cid:16)θ(k) (cid:17) x + λ(k)
β + (k)
y(k) = λ(k)
(k) ∼ N (cid:0)0, β−1 I(cid:1) .
(2)
Photometric parameters λα and λβ provide a global afﬁne correction for the scene illuminatio n, and
λβ is simply an M × 1 vector ﬁlled out with the value of λβ . Each row of W(k) constructs a single
pixel in y(k) , and the row’s entries are the vectorized and point-spread function (PSF) response
for each low-resolution pixel, in the frame of the super-resolution image [2, 3, 16]. The PSF is
usually assumed to be an isotropic Gaussian on the imaging plane, though for some motion models
(e.g. planar projective) this does not necessarily lead to a Gaussian distribution on the frame of x.

(1)

(3)

(4)

(5)

(6)

1

2

θ(k)
λ(k)
α
λ(k)
β

For an individual low-resolution image, given registrations and x, the data likelihood is
M
x, θ(k) , λ(k) (cid:17) = (cid:18) β
2(cid:27) .
2π (cid:19)
exp (cid:26)−
2
β
2
p (cid:16)y(k) (cid:12)(cid:12)(cid:12)
β (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
2 (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
α W (cid:16)θ (k)(cid:17) x − λ(k)
y(k) − λ(k)
When the registration is known approximately, for instance by pre-registering inputs, the uncertainty
(k) for each image’s parameter
can be modeled as a Gaussian perturbation about the mean estimate ¯θ
set, with covariance C, which we restrict to be a diagonal matrix,
(k)


= 

¯θ
(k)
¯λ




α
¯λ(k)
β
δ (k) ∼ N (0, C)
p (cid:16)θ(k) , λ(k)(cid:17) = (cid:18) |C−1 |
(2π)n (cid:19)
δ (k)T C−1δ (k)(cid:27) .
exp (cid:26)−
A Huber prior is assumed for the directional image gradients Dx in the super-resolution image x
(in the horizontal, vertical, and two diagonal directions),
1
ν
exp n−
ρ (Dx, α)o
p (x) =
Zx
2
if |z | < α
ρ(z , α) = (cid:26) z 2
otherwise
2α|z | − α2

+ δ (k)

(7)

(8)

1
2

where α is a parameter of the Huber potential function, and ν is the prior strength parameter. This
belongs to a family of functions often favored over Gaussians for super-resolution image priors [2,
3, 14] because the Huber distribution’s heavy tails mean image edges are penalized less severely.
The difﬁculty in computing the partition function Zx is a consideration when marginalizing over x
as in [16], though for the MAP image estimate, a value for this scale factor is not required.

,

(9)

Regardless of the exact forms of these probability distributions, probabilistic super-resolution algo-
rithms can usually be interpreted in one of the following ways.
The most popular approach to super-resolution is to obtain a MAP estimate, typically using an
iterative scheme to maximize p (cid:0)x (cid:12)(cid:12)(cid:8)y( k), θ(k) , λ(k) (cid:9) (cid:1) with respect to x, where
p (x) QK
k=1 p (cid:0)y(k) (cid:12)(cid:12)x, θ(k) , λ(k) (cid:1)
p (cid:16)x (cid:12)(cid:12)(cid:12)ny(k), θ(k) , λ(k)o (cid:17) =
p (cid:0)(cid:8)y(k) (cid:9) (cid:12)(cid:12)(cid:8)θ(k) , λ(k)(cid:9) (cid:1)
and the denominator is an unknown scaling factor.
Tipping and Bishop’s approach takes an ML estimate of the registration by marginalizing over x,
then calculates the super-resolution estimate as in (9). While Tipping and Bishop did not include a
photometric model, the equivalent expression to be maximized with respect to θ and λ is
K
p (cid:16)ny(y)o (cid:12)(cid:12)(cid:12)nθ (k) , λ(k)o (cid:17) = Z p (x)
p (cid:16)y(y) (cid:12)(cid:12)(cid:12)
x, θ(k) , λ(k) (cid:17) dx.
Yk=1
Note that Tipping and Bishop’s work does employ the same data likelihood expression as in (3),
which forced them to select a Gaussian form for p (x), rather than a more suitable image prior, in
order to keep the integral tractable.
Finally, in this paper we ﬁnd x through marginalizing over θ and λ, so that a MAP estimate of x can
be obtained by maximizing p (cid:0)x (cid:12)(cid:12)(cid:8)y(k)(cid:9) (cid:1) directly with respect to x. This is achieved by ﬁnding
K
p(x)
p (cid:0)(cid:8)y(k) (cid:9)(cid:1) Z
p (cid:16)x (cid:12)(cid:12)(cid:12)ny(k)o (cid:17) =
p (cid:16)θ(k) , λ(k) (cid:17) p (cid:16)y(k) (cid:12)(cid:12)(cid:12)
x, θ(k) , λ(k) (cid:17) d {θ , λ} , (11)
Yk=1
which is developed further in the next section. Note that the integral does not involve the prior, p (x).
3 Marginalizing over registration parameters
In order to obtain an expression for p (cid:0)x| (cid:8)y(k) (cid:9)(cid:1) from expressions (3), (6) and (7) above, the
(k) , ¯λα
parameter variations δ (k) must be integrated out of the problem. Registration estimates ¯θ
and ¯λβ can be obtained using classical registration methods, either intensity-based [8] or estimation
from image points [6], and the diagonal matrix C is constructed to re ﬂect the con ﬁdence in each
parameter estimate. This might mean a standard deviation of a tenth of a low-resolution pixel on
image translation parameters, or a few gray levels’ shift on the illumination model, for instance.

(10)

Kn
2

The integral performed is
KM
2π (cid:19)
2π (cid:19)
2 (cid:18) b
p (cid:0)(cid:8)y(k) (cid:9)(cid:1) (cid:18) β
1
1
ν
p (cid:16)x| ny(k)o(cid:17) =
exp n−
ρ (Dx, α)o
Zx
2
δ (k)C(k)−1 δ (k) (cid:21)) dδ ,
× Z exp (−
K
Xk=1 (cid:20) β
1
2
2 (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
β (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
α W (cid:16)θ (k)(cid:17) x − λ(k)
y(k) − λ(k)
+
2
2
where δT = (cid:2)δ (1)T , δ (2)T , . . . , δ (K )T (cid:3) and all the λ and θ parameters are functions of δ as in
(4). Expanding the data error term in the exponent for each low-resolution image as a second-order
Taylor series about the estimated geometric registration parameter yields
2
β (cid:16)θ (k)(cid:17)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
e(k) (δ ) = (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
y(k) − λα (cid:16)θ(k) (cid:17) W(k) (cid:16)θ(k) (cid:17) x − λ(k)
(13)
2
1
= F (k) + G(k)T δ +
δ (k)T H(k) δ (k) ,
2

(12)

(14)

β
2

1
2

(15)

f =

F (k) −

GT δ −

Values for F , G and H can be found numerically (for geometric registrations) or analytically (for
the photometric parameters) from x and ny(k) , θ(k) , λ(k)
β o. Thus the whole exponent of (12),
α , λ(k)
f , becomes
K
Xk=1 (cid:18)−
H(k) + C−1(cid:21) δ (k)(cid:19)
δ (k)T (cid:20) β
1
β
β
G(k)T δ (k) −
2
2
2
2
δT (cid:20) β
H + V−1(cid:21) δ ,
β
F −
= −
2
2
where the omission of image superscripts indicates stacked matrices, and H is therefore a block-
diagonal nK × nK sparse matrix, and V is comprised of the repeated diagonal of C.
Finally, letting S = β
2 H + V−1 ,
Z exp {f } dδ = exp (cid:26)−
δT Sδ(cid:27) dδ
F (cid:27) Z exp (cid:26)−
1
GT δ −
2
2 exp (cid:26) β 2
= exp (cid:26)−
GT S−1G(cid:27) .
F (cid:27) (2π)
nK
|S|− 1
2
8
The objective function, L, to be minimized with respect to x is obtained by taking the negative log
of (12), using the result from (18), and neglecting the constant terms:

(16)

(18)

β
2

β
2

β
2

(17)

L =

ν
2

ρ (Dx, α) +

β
2

F +

1
2

log |S| −

β 2
8

GT S−1G.

(19)

This can be optimized using Scaled Conjugate Gradients (SCG) [9], noting that the gradient can be
expressed

=

dL
dx

β 2
dF
GT S−1 dG
β
ν
DT d
−
ρ (Dx) +
4
2
2
dx
dx
dx
16 (cid:0)GT S−1 ⊗ GT S−1 (cid:1)(cid:21) dvecH
β 3
+ (cid:20) β
vec (cid:0)S−1 (cid:1)T
4
dx
where derivatives of F , G and H with respect to x can be found analytically for photometric pa-
rameters, and numerically (using the analytic gradient of e(k) (cid:0)δ (k) (cid:1) with respect to x) with respect
to the geometric parameters.
3.1 Implementation notes

(20)

−

,

Notice that the value F from (16) is simply the reprojection error of the current estimate of x at
the mean registration parameter values, and that gradients of this expression with respect to the λ
parameters, and with respect to x can both be found analytically. To ﬁnd the gradient with resp ect to
(k)
, and elements of the Hessian involving it, a central difference
a geometric registration parameter θ
i
scheme involving only the k th image is used.
Mean values for the registration are computed by standard registration techniques, and x is initialized
using around 10 iterations of SCG to ﬁnd the maximum likeliho od solution evaluated at these mean
parameters. Additionally, pixel values are scaled to lie between − 1
2 and 1
2 , and the ML solution is
bounded to lie within these values in order to curb the severe over ﬁtting usually observed in ML
super-resolution results.

In our implementation, the parameters representing the λ values are scaled so that they share the
same standard deviations as the θ parameters, which represent the sub-pixel geometric registration
shifts, which makes the matrix V a multiple of the identity. The scale factors are chosen so that one
standard deviation in λβ gives a 10-gray-level shift, and one standard deviation in λα varies pixel
values by around 10 gray levels at mean image intensity.

4 Results

The ﬁrst experiment takes a sixteen-image synthetic datase t created from an eyechart image. Data is
generated at a zoom factor of 4, using a 2D translation-only motion model, and the two-parameter
global afﬁne illumination model described above, giving a t otal of four registration parameters per
low-resolution image. Gaussian noise with standard deviation equivalent to 5 gray levels is added
to each low-resolution pixel independently. The sub-pixel perturbations are evenly spaced over a
grid up to plus or minus one half of a low-resolution pixel, giving a similar setup to that described
in [10], but with additional lighting variation. The ground truth image and two of the low-resolution
images appear in the ﬁrst row of Figure 1.

Geometric and photometric registration parameters were initialized to the identity, and the images
were registered using an iterative intensity-based scheme. The resulting parameter values were used
to recover two sets of super-resolution images: one using the standard Huber MAP algorithm, and
the second using our extension integrating over the registration uncertainty. The Huber parameter α
was ﬁxed at 0.01 for all runs, and ν was varied over a range of possible values representing ratios
between ν and the image noise precision β .

The images giving lowest RMS error from each set are displayed in the second row of Figure 1.
Visually, the differences between the images are subtle, though the bottom row of letters is better
de ﬁned in the output from the new algorithm. Plotting the RMS E as a function of ν in Figure 2,
we see that the proposed registration-integrating approach achieves a lower error, compared to the
ground truth high-resolution image, than the standard Huber MAP algorithm for any choice of prior
strength, ν in the optimal region.

(a) ground truth high−res

(b) input 1/16

(c) input 16/16

(d) best Huber (err = 15.6)

(e) best int− θ− λ (err = 14.8)

Figure 1: (a) Ground truth image. Only the central recoverable part is shown; (b,c) low-resolution
images. The variation in intensity is clearly visible, and the sub-pixel displacements necessary for
multi-frame image super-resolution are most apparent on the “D ” characters to the right of each im-
age; (d) The best ( ı.e. minimum MSE – see Figure 2) image from t he regular Huber MAP algorithm,
having super-resolved the dataset multiple times with different prior strength settings; (e) The best
result using out approach of integrating over θ and λ. As well as having a lower RMSE, note the
improvement in black-white edge detail on some of the letters on the bottom line.

The second experiment uses real data with a 2D translation motion model and an afﬁne lighting
model exactly as above. The ﬁrst and last images appear on the top row of Figure 3. Image regis-
tration was carried out in the same manner as before, and the geometric parameters agree with the
provided homographies to within a few hundredths of a pixel. Super-resolution images were created

s
l
e
v
e
l
 
y
a
r
g
 
n
i
 
E
S
M
R

23

22

21

20

19

18

17

16

15

14

0

RMSE comparison

Standard Huber MAP
Integrating over registrations and illumination

0.01

0.02
0.08
0.07
0.06
0.05
0.04
0.03
ratio of prior strength parameter, ν, and noise precision, β

0.09

0.1

Figure 2: Plot showing the variation of RMSE with prior strength for the standard Huber-prior MAP
super-resolution method and our approach integrating over θ and λ. The images corresponding to
the minima of the two curves are shown in Figure 1

for a number of ν values, the equivalent values to those quoted in [3] were found subjectively to be
the most suitable.

The covariance of the registration values was chosen to be similar to that used in the synthetic
experiments. Finally, Tipping and Bishop’s method was extended to cover the illumination model
and used to register and super-resolve the dataset, using the same PSF standard deviation (0.4 low-
resolution pixels) as the other methods.

The three sets of results on the real data sequence are shown in the middle and bottom rows of
Figure 3. To facilitate a better comparison, a sub-region of each is expanded to make the letter
details clearer. The Huber prior tends to make the edges unnaturally sharp, though it is very suc-
cessful at regularizing the solution elsewhere. Between the Tipping and Bishop image and the
registration-integrating approach, the text appears more clear in our method, and the regularization
in the constant background regions is slightly more successful.

5 Discussion

It is possible to interpret the extra terms introduced into the objective function in the derivation
of this method as an extra regularizer term or image prior. Considering (19), the ﬁrst two terms
are identical to the standard MAP super-resolution problem using a Huber image prior. The two
additional terms constitute an additional distribution over x in the cases where S is not dominated
by V; as the distribution over θ and λ tightens to a single point, the terms tend to constant values.

The intuition behind the method’s success is that this extra prior resulting from the ﬁnal two terms
of (19) will favor image solutions which are not acutely sensitive to minor adjustments in the image
registration. The images of ﬁgure 4 illustrate the type of so lution which would score poorly. To
create the ﬁgure, one dataset was used to produce two super-r esolved images, using two independent
sets of registration parameters which were randomly perturbed by an i.i.d. Gaussian vector with a
standard deviation of only 0.04 low-resolution pixels. The checker-board pattern typical of ML
super-resolution images can be observed, and the difference image on the right shows the drastic
contrast between the two image estimates.

(a) input 1/10

(b) input 10/10

(c) integrating θ, λ

(d) integrating θ, λ (detailed region)

(e) regular Huber (detailed region)

(f) Tipping & Bishop (detailed region)

Figure 3: (a,b) First and last images from a real data sequence containing 10 images acquired on a
rig which constrained the motion to be pure translation in 2D. (c) The full super-resolution output
from our algorithm. (d) Detailed region of the central letters, again with our algorithm. (e) Detailed
region of the regular Huber MAP super-resolution image, using parameter values suggested in [3],
which are also found to be subjectively good choices. The edges are slightly artiﬁcially crisp, but the
large smooth regions are well regularized. (f) Close-up of letter detail for comparison with Tipping
and Bishop’s method of marginalization. The Gaussian form of their prior leads to a more blurred
output, or one that over- ﬁts to the image noise on the input da ta if the prior’s in ﬂuence is decreased.

5.1 Conclusion

This work has developed an alternative approach for Bayesian image super-resolution with several
advantages over Tipping and Bishop’s original algorithm. These are namely a formal treatment of
registration uncertainty, the use of a much more realistic image prior, and the computational speed
and memory efﬁciency relating to the smaller dimension of th e space over which we integrate.
The results on real and synthetic images with this method show an advantage over the popular
MAP approach, and over the result from Tipping and Bishop’s method, largely owing to our more
favorable prior over the super-resolution image.

It will be a straightforward extension of the current approach to incorporate learning for the point-
spread function covariance, though it will result in a less sparse Hessian matrix H, because each
row and column associated with the PSF parameter(s) has the potential to be full-rank, assuming a
common camera con ﬁguration is shared across all the frames.

Finally, the best way of learning the appropriate covariance values for the distribution over θ given
the observed data, and how to assess the trade-off between its “prior-like ” effects and the need for a
standard Huber-style image prior, are still open questions.

Acknowledgements

The real dataset used in the results section is due to Tomas Pajdla and Daniel Martinec, CMP, Prague,
and is available at http://www.robots.ox.ac.uk/∼vgg/data4.html.

(a) truth

(b) ML image 1

(c) ML image 2

(d) difference

Figure 4: An example of the effect of tiny changes in the registration parameters. (a) Ground truth
image from which a 16-image low-resolution dataset was generated. (b,c) Two ML super-resolution
estimates. In both cases, the same dataset was used, but the registration parameters were perturbed
by an i.i.d. vector with standard deviation of just 0.04 low-resolution pixels. (d) The difference
between the two solutions. In all these images, values outside the valid image intensity range have
been rounded to white or black values.

This work was funded in part by EC Network of Excellence PASCAL.

References

[1] S. Baker and T. Kanade. Limits on super-resolution and how to break them. IEEE Transactions
on Pattern Analysis and Machine Intelligence, 24(9):1167 –1183, 2002.
[2] S. Borman. Topics in Multiframe Superresolution Restoration. PhD thesis, University of Notre
Dame, Notre Dame, Indiana, May 2004.
[3] D. Capel.
Image Mosaicing and Super-resolution (Distinguished Dissertations). Springer,
ISBN: 1852337710, 2004.
[4] S. Farsiu, M. Elad, and P. Milanfar. A practical approach to super-resolution. In Proc. of the
SPIE: Visual Communications and Image Processing, San-Jose, 2006.
[5] R. C. Hardie, K. J. Barnard, and E. A. Armstrong. Joint map registration and high-resolution
image estimation using a sequence of undersampled images.
IEEE Transactions on Image
Processing, 6(12):1621 –1633, 1997.
[6] R. I. Hartley and A. Zisserman. Multiple View Geometry in Computer Vision. Cambridge
University Press, ISBN: 0521540518, second edition, 2004.
[7] M. Irani and S. Peleg. Super resolution from image sequences. ICPR, 2:115 –120, June 1990.
[8] M. Irani and S. Peleg.
Improving resolution by image registration. Graphical Models and
Image Processing, 53:231 –239, 1991.
[9] I. Nabney. Netlab algorithms for pattern recognition. Springer, 2002.
[10] N. Nguyen, P. Milanfar, and G. Golub. Efﬁcient generali zed cross-validation with applications
to parametric image restoration and resolution enhancement.
IEEE Transactions on Image
Processing, 10(9):1299 –1308, September 2001.
[11] L. C. Pickup, S. J. Roberts, and A. Zisserman. A sampled texture prior for image super-
resolution. In Advances in Neural Information Processing Systems, pages 1587 –1594, 2003.
[12] L. C. Pickup, S. J. Roberts, and A. Zisserman. Optimizing and learning for super-resolution.
In Proceedings of the British Machine Vision Conference, 2006. to appear.
[13] D. Robinson and P. Milanfar. Fundamental performance limits in image registration. IEEE
Transactions on Image Processing, 13(9):1185 —1199, September 2004.
[14] R. R. Schultz and R. L. Stevenson. A bayesian approach to image expansion for improved
de ﬁnition.
IEEE Transactions on Image Processing, 3(3):233 –242, 1994.
[15] Salient Stills. http://www.salientstills.com/.
[16] M. E. Tipping and C. M. Bishop. Bayesian imge super-resolution. In S. Thrun, S. Becker, and
K. Obermayer, editors, Advances in Neural Information Processing Systems, volume 15, pages
1279 –1286, Cambridge, MA, 2003. MIT Press.

