Convergence of Laplacian Eigenmaps

Mikhail Belkin
Department of Computer Science
Ohio State University
Columbus, OH 43210
mbelkin@cse.ohio-state.edu

Partha Niyogi
Department of Computer Science
The University of Chicago
Hyde Park, Chicago, IL 60637.
niyogi@cs.uchicago.edu

Abstract

Geometrically based methods for various tasks of machine learning have
attracted considerable attention over the last few years. In this paper we
show convergence of eigenvectors of the point cloud Laplacian to the eigen-
functions of the Laplace-Beltrami operator on the underlying manifold, thus
establishing the ﬁrst convergence results for a spectral dimensionality re-
duction algorithm in the manifold setting.

1 Introduction

The last several years have seen signiﬁcant activity in geometrically motivated approaches
to data analysis and machine learning. The unifying premise behind these methods is
the assumption that many types of high-dimensional natural data lie on or near a low-
dimensional manifold. Collectively this class of learning algorithms is often referred to as
manifold learning algorithms. Some recent manifold algorithms include Isomap [14] and
Locally Linear Embedding (LLE) [13].

In this paper we provide a theoretical analysis for the Laplacian Eigenmaps introduced in [2],
a framework based on eigenvectors of the graph Laplacian associated to the point-cloud data.
More speciﬁcally, we prove that under certain conditions, eigenvectors of the graph Laplacian
converge to eigenfunction of the Laplace-Beltrami operator on the underlying manifold.
We note that in mathematics the manifold Laplacian is a classical ob ject of diﬀerential
geometry with a rich tradition of inquiry. It is one of the key ob jects associated to a general
diﬀerentiable Riemannian manifold. Indeed, several recent manifold learning algorithms are
closely related to the Laplacian. The eigenfunction of the Laplacian are also eigenfunctions
of heat diﬀusions, which is the point of view explored by Coifman and colleagues at Yale
University in a series of recent papers on data analysis (e.g., [6]). Hessian Eigenmaps
approach which uses eigenfunctions of the Hessian operator for data representation was
proposed by Donoho and Grimes in [7]. Laplacian is the trace of the Hessian. Finally, as
observed in [2], the cost function that is minimized to obtain the embedding of LLE is an
approximation to the squared Laplacian.

In the manifold learning setting, the underlying manifold is usually unknown. Therefore
functional maps from the manifold need to be estimated using point cloud data. The com-
mon approximation strategy in these methods is to construct an adjacency graph associated
to a point cloud. The underlying intuition is that since the graph is a proxy for the manifold,
inference based on the structure of the graph corresponds to the desired inference based on
the geometric structure of the manifold. Theoretical results to justify this intuition have
been developed over the last few years. Building on recent results on functional convergence
of approximation for the Laplace-Beltrami operator using heat kernels and results on consis-
tency of eigenfunctions for empirical approximations of such operators, we show convergence
of the Laplacian Eigenmaps algorithm. We note that in order to prove convergence of a

spectral method, one needs to demonstrate convergence of the empirical eigenvalues and
eigenfunctions. To our knowledge this is the ﬁrst complete convergence proof for a spectral
manifold learning method.

1.1 Prior and Related Work

This paper relies on results obtained in [3, 1] for functional convergence of operators. It
turns out, however, that considerably more careful analysis is required to ensure spectral
convergence, which is necessary to guarantee convergence of the corresponding algorithms.
To the best of our knowledge previous results are not suﬃcient to guarantee convergence
for any spectral method in the manifold setting.

Lafon in [10] generalized pointwise convergence results from [1] to the important case of
an arbitrary probability distribution on the manifold. We also note [4], where a similar
result is shown for the case of a domain in Rn . Those results were further generalized and
presented with an empirical pointwise convergence theorem for the manifold case in [9]. We
observe that the arguments in this paper are likely to allow one to use these results to show
convergence of eigenfunctions for a wide class of probability distributions on the manifold.
Empirical convergence of spectral clustering for a ﬁxed kernel parameter t was analyzed
in [11] and is used in this paper. However the geometric case requires t → 0. The results in
this paper as well as in [3, 1] are for the case of a uniform probability distribution on the
manifold. Recently [8] provided deeper probabilistic analysis in that case.

Finally we point out that while the analogies between the geometry of manifolds and the ge-
ometry of graphs are well-known in spectral graph theory and in certain areas of diﬀerential
geometry (see, e.g., [5]) the exact nature of that parallel is usually not made precise.

2 Main Result

The main result of this paper is to show convergence of eigenvectors of graph Laplacian
associated to a point cloud dataset to eigenfunctions of the Laplace-Beltrami operator when
the data is sampled from a uniform probability distribution on an embedded manifold.
In what follows we will assume that the manifold M is a compact inﬁnitely diﬀerentiable
Riemannian submanifold of RN without boundary. Recall now that the Laplace-Beltrami
operator ∆ on M is a diﬀerential operator ∆ : C 2 → L2 deﬁned as
∆f = − div (∇f )
where ∇f is the gradient vector ﬁeld and div denotes divergence.
∆ is a positive semi-deﬁnite self-adjoint operator and has a discrete spectrum on a compact
manifold. We will generally denote its ith smallest eigenvalue by λi and the corresponding
eigenfunction by ei . See [12] for a thorough introduction to the sub ject.
We deﬁne the operator Lt : L2 (M) → L2 (M) as follows (µ is the standard measure):
f (q) dµq (cid:19)
2 (cid:18)ZM
f (p) dµq − ZM
e− kp−qk2
e− kp−qk2
Lt (f )(p) = (4π t)− k+2
4t
4t
If xi are the data points, the corresponding empirical version is given by
 Xi
f (xi )!
(4π t)− k+2
e− kp−xi k2
e− kp−xi k2
2
f (p) − Xi
4t
4t
n
The operator ˆLt
n is (the extension of ) the point cloud Laplacian that forms the basis of
the Laplacian Eigenmaps algorithm for manifold learning. It is easy to see that it acts by
matrix multiplication on functions restricted to the point cloud, with the matrix being the
corresponding graph Laplacian. We will assume that xi are randomly i.i.d. sampled from
M according to the uniform distribution.
Our main theorem shows that that there is a way to choose a sequence tn , such that the
eigenfunctions of the empirical operators ˆLtn
n converge to the eigenfunctions of the Laplace-
Beltrami operator ∆ in probability.

ˆLt
n (f )(p) =

n,i be the ith eigenvalue of ˆLt
n and et
Theorem 2.1 Let λt
n,i be the corresponding eigenfunc-
tion (which, for each ﬁxed i, wil l be shown to exist for t suﬃciently smal l). Let λi and ei
be the corresponding eigenvalue and eigenfunction of ∆ respectively. Then there exists a
sequence tn → 0, such that

λtn
lim
n,i = λi
n→∞
n→∞ ketn
n,i (x) − ei (x)k2 = 0
lim
where the limits are in probability.

3 Overview of the proof

The proof of the main theorem consists of two main parts. One is spectral convergence of
the functional approximation Lt to ∆ as t → 0 and the other is spectral convergence of the
empirical approximation ˆLt
n to Lt as the number of data points n tends to inﬁnity. These
two types of convergence are then put together to obtain the main Theorem 2.1.

Part 1. The more diﬃcult part of the proof is to show convergence of eigenvalues and
eigenfunctions of the functional approximation Lt to those of ∆ as t → 0. To demonstrate
convergence we will take a diﬀerent functional approximation 1−Ht
of ∆, where Ht is the
t
heat operator. While 1−Ht
does not converge uniformly to ∆ they share an eigenbasis and
t
for each ﬁxed i the ith eigenvalue of 1−Ht
converges to the ith eigenvalue of ∆. We will then
t
consider the operator Rt = 1−Ht
t − Lt . A careful analysis of this operator, which constitutes
the bulk of the proof paper, shows that Rt is a small relatively bounded perturbation of 1−Ht
,
t
kRt f k2
in the sense that for any function f we have
f k2 ≪ 1 as t → 0. This will imply spectral
k 1−Ht
t

convergence and lead to the following

Theorem 3.1 Let λi , λt
i , ei , et
i be the ith smal lest eigenvalues and the corresponding eigen-
functions of ∆ and Lt respectively. Then
t→0 |λi − λt
lim
i | = 0
t→0 kei − et
i k2 = 0
lim
Part 2. The second part is to show that the eigenfunctions of the empirical operator ˆLt
n
converge to eigenfunctions of Lt as n → ∞ in probability. That result follows readily from
the previous work in [11] together with the analysis of the essential spectrum of Lt . The
following theorem is obtained:

i be the ith eigenvalue of ˆLt
Theorem 3.2 For a ﬁxed suﬃciently smal l t, let λt
n,i and λt
n
n,i and et
and Lt respectively. Let et
i be the corresponding eigenfunctions. Then
n,i = λt
λt
lim
i
n→∞
n→∞ ket
n,i (x) − et
lim
i (x)k2 = 0
i ≤ 1
assuming that λt
2t . The convergence is almost sure.
Observe that this implies convergence for any ﬁxed i as soon as t is suﬃciently small.

Symbolically these two theorems can be represented by top line of the following diagram:

n → ∞
t → 0
Eig ˆLt
Eig Lt
Eig ∆
............................................................................................................................................................................... ............
............................................................................................................................................................................... ............
............................................................................................................................................................................... ............
............................................................................................................................................................................... ............
n
deterministic
probabilistic
.............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
............
n → ∞ tn → 0

After demonstrating two types of convergence results in the top line of the diagram a simple
argument shows that a sequence tn can be chosen to guarantee convergence as in the ﬁnal
Theorem 2.1 and provides the bottom arrow.

4 Spectral Convergence of Functional Approximations.

4.1 Main Ob jects and the Outline of the Proof

Let M be a compact smooth smoothly embedded k-dimensional manifold in RN with the
induced Riemannian structure and the corresponding induced measure µ.
As above, we deﬁne the operator Lt : L2 (M) → L2 (M) as follows:
2 (cid:18)ZM
f (y) dµy (cid:19)
f (x) dµy − ZM
e− kx−yk2
e− kx−yk2
Lt (f )(x) = (4π t)− k+2
4t
4t
As shown in previous work, this operator serves as a functional approximation to the
Laplace-Beltrami operator on M. The purpose of this paper is to extend the previous results
to the eigenvalues and eigenfunctions, which turn out to need some careful estimates.

We start by reviewing certain properties of the Laplace-Beltrami operator and its connection
to the heat equation. Recall that the heat equation on the manifold M is given by
∂h(x, t)
∆h(x, t) =
∂ t
where h(x, t) is the heat at time t at point x. Let f (x) = h(x, 0) be the initial heat
distribution. We observe that from the deﬁnition of the derivative
1
t

(h(x, t) − f (x))

∆f = lim
t→0

H t (x, y)f (y)dµy

It is well-known (e.g., [12]) that the solution to the heat equation at time t can be written
as
Ht f (x) := h(x, t) = ZM
Here Ht is the heat operator and H t (x, y) is the heat kernel of M. It is also well-known
that the heat operator Ht can be written as Ht = e−t∆ . We immediately see that ∆ =
and that eigenfunctions of Ht and hence eigenfunction of 1−Ht
1−Ht
coincide with
limt→0
t
t
is equal to 1−e−tλi
eigenfunctions of the Laplace operator. The ith eigenvalue of 1−Ht
,
t
t
where λi as usual is the ith eigenvalue of ∆.
It is easy to observe that once the heat kernel H t (x, y) is known, ﬁnding the Laplace operator
poses no diﬃculty:

∆f = lim
t→0

t→0 (cid:18) 1 − Ht
H t (x, y)f (y) dµy (cid:19) = lim
t (cid:18)f (x) − ZM
t (cid:19) f
1
Reconstructing the Laplacian from a point cloud is possible because of the fundamental fact
that the manifold heat kernel H t (x, y) can be approximated by the ambient space Gaussian
and hence Lt is an approximation to 1−Ht
and can be shown to converge for a ﬁxed f to
t
∆. This pointwise operator convergence is discussed in [10, 3, 1].

(1)

To obtain convergence of eigenfunctions, however, one typically needs the stronger uniform
If An is a sequence of operators, we say that An → A uniformly in L2 if
convergence.
supkf k2=1 kAn f − Af k2 → 0. This is suﬃcient for convergence of eigenfunctions and other
spectral properties.

It turns out that this type of convergence does not hold for functional approximation Lt
as t → 0, which presents a serious technical obstruction to proving convergence of spectral
properties. To observe that Lt does not converge uniformly to ∆, observe that while 1−Ht
t

1
t

Indeed,
converges to ∆ for each ﬁxed function f , even this convergence is not uniform.
for a small t, we can always choose a suﬃciently large λi ≫ 1/t and the corresponding
eigenfunction ei of ∆, s.t.
(cid:18) 1 − Ht
(cid:13)(cid:13)(cid:13)(cid:13)
(1 − e−tλi ) − λi (cid:12)(cid:12)(cid:12)(cid:12)
− ∆(cid:19) ei(cid:13)(cid:13)(cid:13)(cid:13)2
t − λi (cid:12)(cid:12)(cid:12)(cid:12)
≈ (cid:12)(cid:12)(cid:12)(cid:12)
= (cid:12)(cid:12)(cid:12)(cid:12)
1
t
Since Lt is an approximation to 1−Ht
, uniform convergence cannot be expected and the
t
standard perturbation theory techniques do not apply. To overcome this obstacle we need
the two following key ingredients:
Observation 1. Eigenfunctions of 1−Ht
t
Observation 2. Lt is a small relatively bounded perturbation of 1−Ht
t
While the ﬁrst of these observations is immediate, the second is the technical core of this
work. The relative boundedness of the perturbation will imply convergence of eigenfunctions
of Lt to those of 1−Ht
and hence, by the Observation 1, to eigenfunctions of ∆.
t
We now deﬁne the perturbation operator

coincide with eigenfunctions of ∆.

≫ 1

.

1 − Ht
− Lt
t
The relative boundedness of the self-adjoint perturbation operator Rt is formalized as fol-
lows:

Rt =

Theorem 4.1 For any 0 < ǫ < 2
k+2 there exists a constant C , such that for al l t suﬃciently
smal l
|hRtf , f i|
2 ǫ(cid:17)
f , f i ≤ C max (cid:16)t
k+2
h 1−Ht
t
hRtf , f i
sup
h 1−Ht
f , f i
kf k2=1
t
on L2 as t tends to 0.

lim
t→0
and hence Rt is dominated by 1−Ht
t

In particular

2
k+2 −ǫ , t

= 0

This result implies that for small values of t, bottom eigenvalues and eigenfunction of Lt
are close to those of 1−Ht
, which in turn implies convergence. To establish this result, we
t
will need two key estimates on the size of the perturbation Rt in two diﬀerent norms.

Proposition 4.2 Let f ∈ L2 . There exists C ∈ R, such that for al l suﬃciently smal l values
of t
kRt f k2 ≤ C kf k2
k
k
+1 , where H
+1 is a Sobolev space. Then there is C ∈ R,
Proposition 4.3 Let f ∈ H
2
2
such that for al l suﬃciently smal l values of t
kRt f k2 ≤ C√tkf kH
In what follows we give the proof of the Theorem 4.1 assuming the two Propositions above.
The proof of the Propositions requires technical estimates of the heat kernel and can be
found the longer version of the paper enclosed.

+1

k
2

4.2 Proof of Theorem 4.1.

Lemma 4.4 Let e be an eigenvector of ∆ with the eigenvalue λ. Then for some universal
constant C

(2)

kekH

k
2

+1 ≤ C λ

k+2
4

The details can be found in the long version. Now we can proceed with the

Proof: [Theorem 4.1]

Let ei (x) be the ith eigenfunction of ∆ and let λi be the corresponding eigenvalue. Recall
that ei form an orthonormal basis of L2 (M). Thus any function f ∈ L2 (M) can be written
uniquely as f (x) = P∞i=0 ai ei (x) where P a2
i < ∞. For technical resons we will assume that
all our functions are perpendicular to the constant and the lowest eigenvalue is nonzero.
Recall also that

Ht f = exp(−t∆)f ,

Ht ei = exp(−tλi )ei ,

1 − Ht
t

ei =

1 − e−λi t
t

ei

(3)

Now let us ﬁx t and consider the function φ(x) = 1−e−xt
t
that φ is a concave and increasing function of x.
Put x0 = 1/√t. We have:

for positive x. It is easy to check

φ(0) = 0

φ(x0 ) =

1 − e−√t
t

φ(x0 )
x0

=

1 − e−√t
√t

Splitting the positive real line in two intervals [0, x0 ], [x0 , ∞) and using concavity and
monotonicity we observe that
φ(x) ≥ min   1 − e−√t
1 − e−√t
!
√t
t
= 1.

x,

1−e−√t
Note that limt→0
√t
Therefore for t suﬃciently small

φ(x) ≥ min (cid:18) 1
2

x,

2√t (cid:19)
1

Thus

1 − e−λi t
(cid:28) 1 − Ht
ei , ei(cid:29) =
min (cid:18)λi ,
√t (cid:19)
1
1
≥
(4)
t
t
2
Now take f ∈ L2 , f (x) = P∞1 ai ei (x). Without a loss of generality we can assume that
kf k2 = 1. Taking α > 0, we split f as a sum of f1 and f2 as following:
f1 = Xλi≤α
f2 = Xλi>α
ai ei ,
ai ei
It is clear that f = f1 + f2 and, since f1 and f2 are orthogonal, kf k2
2 + kf2 k2
2 = kf1 k2
2 . We
will now deal separately with f1 and with f2 .

From the inequality (4) above, we observe that
(cid:28) 1 − Ht
f , f (cid:29) ≥
t
On the other hand, from the inequality (2), we see that if ei is a basis element present in
the basis expansion of f1 ,

1
2

λ1

k
+1
kei k
H ≤ C α
2
+1 ≤ C α
Since ∆ acts by rescaling basis elements, we have kf1 kH
k
2
Therefore by Proposition 4.3 for t suﬃciently small and some constant C ′
kRt f1 k2 ≤ C ′√tα

k+2
4 .

k+2
4

k+2
4

(5)

Hence we see that

k+2
4

(6)

√t α

2C ′
λ1

kRt f1k2
f , f i ≤
h 1−Ht
t
Consider now the second summand f2 . Recalling that f2 only has basis components with
eigenvalues greater than α and using the inequality (4) we see that
f , f (cid:29) ≥ (cid:28) 1 − Ht
(cid:28) 1 − Ht
f2 , f2(cid:29) ≥
min (cid:18)α,
√t (cid:19) kf2 k2
1
1
2
t
t
2
On the other hand, by Proposition 4.2
kRt f2k2 ≤ C1 kf2 k2
2
f , f i ≤ kRt f2k2
|hRtf2 , f2 i|
f2 , f2 i ≤ C ′1 max (cid:18) 1
h 1−Ht
h 1−Ht
α
t
t
Finally, collecting inequalities 6 and 9 we see:
, √t(cid:19) + √t α
f , f i ≤ kRt f1k + kRt f2k
|hRt f , f i|
≤ C (cid:18)max (cid:18) 1
h 1−Ht
h 1−Ht
α
f , f i
t
t
where C is a constant independent of t and α.
Choosing α = t− 2
+ǫ where 0 < ǫ < 2
k+2 yields the desired result.
k+2

, √t(cid:19)

4 (cid:19)
k+2

Thus

(10)

(8)

(9)

(7)

(cid:3)

5 Spectral Convergence of Empirical Approximation

Proposition 5.1 For t suﬃciently smal l
SpecEss (Lt ) ⊂ (cid:18) 1
t−1 , ∞(cid:19)
2
where SpecEss denotes the essential spectrum of the operator.

Proof: As noted before Lt f is a diﬀerence of a multiplication operator and a compact
operator

where

Lt f (p) = g(p)f (p) − K f
2 ZM
e− kp−qk2
g(p) = (4π t)− k+2
4t
and K f is a convolution with a Gaussian. As noted in [11], it is a fact in basic perturbation
theory SpecEss (Lt ) = rg g where rg g is the range of the function g : M → R. To estimate
rg g observe ﬁrst that
2 ZM
e− kp−qk2
(4π t)− k
lim
4t
t→∞
We thus see that for t suﬃciently small
2 ZM
(4π t)− k

e− kp−yk2
4t

dµq = 1

dµy >

(11)

dµq

1
2

(cid:3)

and hence g(t) > 1
2 t−1 .

Lemma 5.2 Let et be an eigenfunction of Lt , Lt et = λt et , λt < 1
2 t−1 . Then et ∈ C∞ .

We see that Theorem 3.2 follows easily:

Proof: [Theorem 3.2] By the Proposition 5.1 we see that the part of the spectrum of Lt
between 0 and 1
2 t−1 is discrete. It is a standard fact of functional analysis that such points
are eigenvalues and there are corresponding eigenspaces of ﬁnite dimension. Consider now
i ∈ [0, 1
2 t−1 ] and the corresponding eigenfunction et
λt
i . The Theorem 4 then follows from
Theorem 23 and Proposition 25 in [11], which show convergence of spectral properties for
the empirical operators.
(cid:3)

6 Main Theorem

We are ﬁnally in position to prove the main Theorem 4.1: Proof: [Theorem 4.1] From
Theorems 3.2 and 3.1 we obtain the following convergence results:

Eig ˆLt
n

n → ∞
..................................................................................................................................... ............

Eig Lt

t → 0
..................................................................................................................................... ............

Eig ∆

where the ﬁrst convergence is almost surely for λi ≤ 1
2 t−1 . Given any i ∈ N and any ǫ > 0,
we can choose t′ < 2λ−1
, s.t. for all t < t′ we have kei − et
i k2 < ǫ
2 . On the other hand, by
i
using the ﬁrst arrow, we see that
ǫ
P nket
2 o = 0
n,i − et
i k2 ≥
lim
n→∞
Thus for any p > 0 and for each t there exists an N , s.t. P {ket
n,i − ei k2 > ǫ} < p Inverting
this relationship, we see that for any N and for any probability p(N ) there exists a tN , s.t.
∀n>N P {ketN
n,i − ei k2 > ǫ} < p(N )
Making p(N ) tend to zero, we obtain convergence in probability.

(cid:3)

References

[1] M. Belkin, Problems of Learning on Manifolds, Univ. of Chicago, Ph.D. Diss., 2003.
[2] M. Belkin, P. Niyogi, Laplacian Eigenmaps and Spectral Techniques for Embedding and
Clustering, NIPS 2001.
[3] M. Belkin, P. Niyogi, Towards a Theoretical Foundation for Laplacian-Based Manifold
Methods, COLT 2005.

[4] O. Bousquet, O. Chapelle, M. Hein, Measure Based Regularization, NIPS 2003.
[5] F. R. K. Chung. (1997). Spectral Graph Theory. Regional Conference Series in Mathe-
matics, number 92.
[6] R.R.Coifman, S. Lafon, A. Lee, M. Maggioni, B. Nadler, F. Warner and S. Zucker,
Geometric diﬀusions as a tool for harmonic analysis and structure deﬁnition of data,
submitted to the Proceedings of the National Academy of Sciences (2004).

[7] D. L. Donoho, C. E. Grimes, Hessian Eigenmaps: new local ly linear embedding tech-
niques for high-dimensional data, PNAS, vol. 100 pp. 5591-5596.

[8] E. Gine, V. Kolchinski, Empirical Graph Laplacian Approximation of Laplace-Beltrami
Operators: Large Sample Results, preprint.
[9] M. Hein, J.-Y. Audibert, U. von Luxburg, From Graphs to Manifolds – Weak and
Strong Pointwise Consistency of Graph Laplacians, COLT 2005.
[10] S. Lafon, Diﬀusion Maps and Geodesic Harmonics, Ph.D.Thesis, Yale University, 2004.

[11] U. von Luxburg, M. Belkin, O. Bousquet, Consistency of Spectral Clustering, Max
Planck Institute for Biological Cybernetics Technical Report TR 134, 2004.

[12] S. Rosenberg, The Laplacian on a Riemannian Manifold, Cambridge Univ. Press, 1997.
[13] Sam T. Roweis, Lawrence K. Saul. (2000). Nonlinear Dimensionality Reduction by
Local ly Linear Embedding, Science, vol 290.
[14] J.B.Tenenbaum, V. de Silva, J. C. Langford. (2000). A Global Geometric Framework
for Nonlinear Dimensionality Reduction, Science, Vol 290.

