Modelling transcriptional regulation using Gaussian
processes

Neil D. Lawrence
School of Computer Science
University of Manchester, U.K.
neill@cs.man.ac.uk

Guido Sanguinetti
Department of Computer Science
University of Shefﬁeld, U.K.
guido@dcs.shef.ac.uk

Magnus Rattray
School of Computer Science
University of Manchester, U.K.
magnus@cs.man.ac.uk

Abstract

Modelling the dynamics of transcriptional processes in the cell requires the knowl-
edge of a number of key biological quantities. While some of them are relatively
easy to measure, such as mRNA decay rates and mRNA abundance levels, it is
still very hard to measure the active concentration levels of the transcription factor
proteins that drive the process and the sensitivity of target genes to these concen-
trations. In this paper we show how these quantities for a given transcription factor
can be inferred from gene expression levels of a set of known target genes. We
treat the protein concentration as a latent function with a Gaussian process prior,
and include the sensitivities, mRNA decay rates and baseline expression levels as
hyperparameters. We apply this procedure to a human leukemia dataset, focusing
on the tumour repressor p53 and obtaining results in good accordance with recent
biological studies.

Introduction

Recent advances in molecular biology have brought about a revolution in our understanding of cellu-
lar processes. Microarray technology now allows measurement of mRNA abundance on a genome-
wide scale, and techniques such as chromatin immunoprecipitation (ChIP) have largely unveiled
the wiring of the cellular transcriptional regulatory network, identifying which genes are bound by
which transcription factors. However, a full quantitative description of the regulatory mechanism of
transcription requires the knowledge of a number of other biological quantities: ﬁrst of all the con-
centration levels of active transcription factor proteins, but also a number of gene-speciﬁc constants
such as the baseline expression level for a gene, the rate of decay of its mRNA and the sensitivity
with which target genes react to a given transcription factor protein concentration. While some of
these quantities can be measured (e.g. mRNA decay rates), most of them are very hard to measure
with current techniques, and have therefore to be inferred from the available data. This is often
done following one of two complementary approaches. One can formulate a large scale simpliﬁed
model of regulation (for example assuming a linear response to protein concentrations) and then
combine network architecture data and gene expression data to infer transcription factors’ protein
concentrations on a genome-wide scale. This line of research was started in [3] and then extended
further to include gene-speciﬁc effects in [10, 11]. Alternatively, one can formulate a realistic model
of a small subnetwork where few transcription factors regulate a small number of established tar-
get genes, trying to include the ﬁner points of the dynamics of transcriptional regulation. In this
paper we follow the second approach, focussing on the simplest subnetwork consisting of one tran-

scription factor regulating its target genes, but using a detailed model of the interaction dynamics
to infer the transcription factor concentrations and the gene speciﬁc constants. This problem was
recently studied by Barenco et al. [1] and by Rogers et al. [9]. In these studies, parametric models
were developed describing the rate of production of certain genes as a function of the concentration
of transcription factor protein at some speciﬁed time points. Markov chain Monte Carlo (MCMC)
methods were then used to carry out Bayesian inference of the protein concentrations, requiring
substantial computational resources and limiting the inference to the discrete time-points where the
data was collected.
We show here how a Gaussian process model provides a simple and computationally efﬁcient
method for Bayesian inference of continuous transcription factor concentration proﬁles and asso-
ciated model parameters. Gaussian processes have been used effectively in a number of machine
learning and statistical applications [8] (see also [2, 6] for the work that is most closely related to
ours). Their use in this context is novel, as far as we know, and leads to several advantages. Firstly,
it allows for the inference of continuous quantities (concentration proﬁles) without discretization,
therefore accounting naturally for the temporal structure of the data. Secondly, it avoids the use of
cumbersome interpolation techniques to estimate mRNA production rates from mRNA abundance
data, and it allows us to deal naturally with the noise inherent in the measurements. Finally, it greatly
outstrips MCMC techniques in terms of computational efﬁciency, which we expect to be crucial in
future extensions to more complex (and realistic) regulatory networks.
The paper is organised as follows: in the ﬁrst section we discuss linear response models. These
are simpliﬁed models in which the mRNA production rate depends linearly on the transcription
factor protein concentration. Although the linear assumption is not veriﬁed in practice, it has the
advantage of giving rise to an exactly tractable inference problem. We then discuss how to extend the
formalism to model cases where the dependence of mRNA production rate on transcription factor
protein concentration is not linear, and propose a MAP-Laplace approach to carry out Bayesian
inference. In the third section we test our model on the leukemia data set studied in [1]. Finally,
we discuss further extensions of our work. MATLAB code to recreate the experiments is available
on-line.

1 Linear Response Model

Let the data set under consideration consist of T measurements of the mRNA abundance of N genes.
We consider a linear differential equation that relates a given gene j ’s expression level xj (t) at time
t to the concentration of the regulating transcription factor protein f (t),

= Bj + Sj f (t) − Dj xj (t) .

dxj
dt
Here, Bj is the basal transcription rate of gene j , Sj is the sensitivity of gene j to the transcription
factor and Dj is the decay rate of the mRNA. Crucially, the dependence of the mRNA transcription
rate on the protein concentration (response) is linear. Assuming a linear response is a crude simpliﬁ-
cation, but it can still lead to interesting results in certain modelling situations. Equation (1) was used
by Barenco et al. [1] to model a simple network consisting of the tumour suppressor transcription
factor p53 and ﬁve of its target genes. We will consider more general models in section 2.
Z t
The equation given in (1) can be solved to recover
0

+ kj exp (−Dj t) + Sj exp (−Dj t)

(1)

xj (t) = Bj
Dj

f (u) exp (Dj u) du

(2)

where kj arises from the initial conditions, and is zero if we assume an initial baseline expression
level xj (0) = Bj /Dj .
We will model the protein concentration f as a latent function drawn from a Gaussian process
prior distribution. It is important to notice that equation (2) involves only linear operations on the
function f (t). This implies immediately that the mRNA abundance levels will also be modelled as
a Gaussian process, and the covariance function of the marginal distribution p (x1 , . . . , xN ) can be
worked out explicitly from the covariance function of the latent function f .

Let us rewrite equation (2) as

f (u) exp (Dj u) du

xj (t) = Bj
+ Lj [f ] (t)
Dj
Z t
where we have set the initial conditions such that kj in equation (2) is equal to zero and
Lj [f ] (t) = Sj exp (−Dj t)
0
is the linear operator relating the latent function f to the mRNA abundance of gene j , xj (t). If the
covariance function associated with f (t) is given by kf f (t, t0 ) then elementary functional analysis
yields that
cov (Lj [f ] (t) , Lk [f ] (t0 )) = Lj ⊗ Lk [kf f ] (t, t0 ) .
Z t
Z t0
Explicitly, this is given by the following formula
kxj xk (t, t0 ) = Sj Sk exp (−Dj t − Dk t0 )
exp (Dk u0 ) kf f (u, u0 ) du0du.
exp (Dj u)
0
0
!
 
If the process prior over f (t) is taken to be a squared exponential kernel,
− (t − t0 )2
l2

kf f (t, t0 ) = exp

(3)

(4)

,

+ γk

+ erf

where

− γk

(cid:19)(cid:21)

(cid:18) t
l

where l controls the width of the basis functions1 , the integrals in equation (4) can be computed
analytically. The resulting covariances are obtained as
√
[hkj (t0 , t) + hjk (t, t0 )]
kxj xk (t, t0 ) = Sj Sk
π l
2
(cid:18) t0 − t
(cid:26)
(cid:19)
(cid:20)
exp (γk )2
(cid:20)
(cid:18) t0
(cid:21)(cid:27)
(cid:19)
exp [−Dk (t0 − t)]
hkj (t0 , t) =
erf
Dj + Dk
l
−exp [− (Dk t0 + Dj )]
− γk
0 exp (cid:0)−y2 (cid:1) dy and γk = Dk l
R x
+ erf (γk )
erf
l
Here erf(x) = 2√
2 . We can therefore compute a likelihood which
π
relates instantiations from all the observed genes, {xj (t)}N
j=1 , through dependencies on the param-
eters {Bj , Sj , Dj }N
j=1 . The effect of f (t) has been marginalised.
To infer the protein concentration levels, one also needs the “cross-covariance” terms between xj (t)
Z t
and f (t0 ), which is obtained as
kxj f (t, t0 ) = Sj exp (−Dj t)
exp (Dj u) kf f (u, t0 ) du.
(cid:19)
(cid:18) t
(cid:19)(cid:21)
(cid:20)
(cid:18) t0 − t
0
Again, this can be obtained explicitly for squared exponential priors on the latent function f as
√
− γj
exp (γj )2 exp [−Dj (t0 − t)]
kxj f (t0 , t) =
erf
l
l

π lSj
2

+ erf

+ γj

.

.

(5)

(6)

Standard Gaussian process regression techniques [see e.g. 8] then yield the mean and covariance
function of the posterior process on f as
hf ipost = Kf xK −1
xx x
f f = Kf f − Kf xK −1
K post
xx Kxf
where x denotes collectively the xj (t) observed variables and capital K denotes the matrix obtained
by evaluating the covariance function of the processes on every pair of observed time points. The

(7)

1The scale of the process is ignored to avoid a parameterisation ambiguity with the sensitivities.

model parameters Bj , Dj and Sj can be estimated by type II maximum likelihood. Alternatively,
they can be assigned vague gamma prior distributions and estimated a posteriori using MCMC
sampling.
In practice, we will allow the mRNA abundance of each gene at each time point to be corrupted by
some noise, so that we can model the observations at times ti for i = 1, . . . , T as,
with j (ti ) ∼ N (cid:0)0, σ2
(cid:1). Estimates of the conﬁdence levels associated with each mRNA mea-
yj (ti ) = xj (ti ) + j (ti )
(8)
Kyy = Σ + Kxx , with Σ = diag (cid:0)σ2
(cid:1).
j i
surement can be obtained for Affymetrix microarrays using probe-level processing techniques
such as the mmgMOS model of [4]. The covariance of the noisy process is simply obtained as
N 1 , . . . , σ2
1T , . . . , σ2
11 , . . . , σ2
N T
2 Non-linear Response Model

While the linear response model presents the advantage of being exactly tractable in the important
squared exponential case, a realistic model of transcription should account for effects such as satu-
ration and ultrasensitivity which cannot be captured by a linear function. Also, all the quantities in
equation (1) are positive, but one cannot constrain samples from a Gaussian process to be positive.
Modelling the response of the transcription rate to protein concentration using a positive nonlinear
function is an elegant way to enforce this constraint.

2.1 Formalism

du g(f (u), θj ) exp (Dj u) ,

Let the response of the mRNA transcription rate to transcription factor protein concentration levels
be modelled by a nonlinear function g with a target-speciﬁc vector θj of parameters, so that,
Z t
= Bj + g(f (t), θj ) − Dj xj
dxj
dt
+ exp (−Dj t)
xj (t) = Bj
Dj
0
where we again set xj (0) = Bj /Dj and assign a Gaussian process prior distribution to f (t). In
this case the induced distribution of xj (t) is no longer a Gaussian process. However, we can derive
the functional gradient of the likelihood and prior, and use this to learn the Maximum a Posteriori
(MAP) solution for f (t) and the parameters by (functional) gradient descent. Given noise-corrupted
"
(cid:1)#
data yj (ti ) as above, the log-likelihood of the data Y = {yj (ti )} is given by
NX
TX
− log (cid:0)σ2
(xj (ti ) − yj (ti ))2
p(Y |f , {Bj , θj , Dj , Ξ}) = − 1
2
j i
σ2
j i
j=1
i=1
where Ξ denotes collectively the parameters of the prior covariance on f (in the squared exponential
= − TX
NX
case, Ξ = l2 ). The functional derivative of the log-likelihood with respect to f is then obtained as
(xj (ti ) − yj (ti ))
δ log p(Y |f )
δf (t)
σ2
j i
j=1
i=1
where Θ(x) is the Heaviside step function and we have omitted the model parameters for brevity.
TX
NX
The negative Hessian of the log-likelihood with respect to f is given by
(xj (ti ) − yj (ti ))
w(t, t0 ) = − δ2 log p(Y |f )
δf (t) δf (t0 )
TX
σ2
j i
j=1
i=1
Θ(ti − t)Θ (ti − t0 )
σ−2
j i g 0 (f (t)) g 0 (f (t0 )) e−Dj (2ti−t−t0 )
i=1

Θ(ti − t)δ (t − t0 )
NX
j=1

g 00 (f (t))e−Dj (ti−t)

g 0 (f (t))e−Dj (ti−t)

(11)

− N T
2

log(2π)

(10)

=

+

(9)

(12)

Θ(ti − t)

where g 0 (f ) = ∂ g/∂ f and g 00 (f ) = ∂ 2 g/∂ f 2 .

2.2

Implementation

(14)

+ ∆2

= δpq∆

g 0 (fp ) e−Dj (ti−tp )

g 00 (fq ) e−Dj (ti−tq )

(xj (ti ) − yj (ti ))
σ2
j i

We discretise in time t and compute the gradient and Hessian on a grid using approximate Riemann
In the simplest case, we choose a uniform grid [tp ]
p = 1, . . . , M so that ∆ =
quadrature.
tp − tp−1 is constant. We write f = [fp ] to be the vector realisation of the function f at the grid
TX
NX
points. The gradient of the log-likelihood is then given by,
∂ log p(Y |f )
(xj (ti ) − yj (ti ))
= − ∆
Θ (ti − tp )
σ2
∂ fp
j i
i=1
j=1
TX
NX
and the negative Hessian of the log-likelihood is,
Wpq = − ∂ 2 log p(Y |f )
Θ (ti − tq )
TX
NX
∂ fp∂ fq
i=1
j=1
Θ (ti − tp ) Θ (ti − tq )
σ−2
j i g 0 (fq ) g 0 (fp ) e−Dj (2ti−tp−tq )
i=1
j=1
where δpq is the Kronecker delta. In these and the following formulae ti is understood to mean the
index of the grid point corresponding to the ith data point, whereas tp and tq correspond to the grid
points themselves.
We can then compute the gradient and Hessian of the (discretised) un-normalised log posterior
Ψ(f ) = log p(Y |f ) + log p(f ) [see 8, chapter 3]
∇Ψ(f ) = ∇ log p(Y |f ) − K −1f
∇∇Ψ(f ) = −(W + K −1 )
where K is the prior covariance matrix evaluated at the grid points. These can be used to ﬁnd the
MAP solution ˆf using Newton’s method. The Laplace approximation to the log-marginal likelihood
is then (ignoring terms that do not involve model parameters)
ˆf T K −1 ˆf − 1
2 log |I + KW |.
log p(Y ) ’ log p(Y | ˆf ) − 1
2
(cid:19)
(cid:18)
We can also optimise the log-marginal with respect to the model and kernel parameters. The gradient
+X
of the log-marginal with respect to the kernel parameters is [8]
∂ log p(Y |Ξ)
∂Ξ K −1 ˆf − 1
ˆf T K −1 ∂K
(I + KW )−1W
∂K
2 tr
∂Ξ
∂Ξ
p
where the ﬁnal term is due to the implicit dependence of ˆf on Ξ.

∂ log p(Y |Ξ)
∂ ˆfp

∂ ˆfp
∂Ξ

= 1
2

(13)

(15)

(16)

(17)

2.3 Example: exponential response

As an example, we consider the case in which
g (f (t) , θj ) = Sj exp (f (t))
(18)
which provides a useful way of constraining the protein concentration to be positive. Substituting
NX
TX
equation (18) in equations (13) and (14) one obtains
(xj (ti ) − yj (ti ))
∂ log p(Y |f )
Θ (ti − tp )
= −∆
TX
σ2
∂ fp
j i
j=1
i=1
∂ log p(Y |f )
Θ (ti − tp ) Θ (ti − tq )
∂ fp
i=1
X
The terms required in equation (17) are,
∂ log p(Y |Ξ)
= −(AW )pp − 1
∂ ˆfp
2
q
where A = (W + K −1 )−1 .

Sj efp−Dj (ti−tp )
NX
j=1

σ−2
j efp+fq −Dj (2ti−tp−tq ) .
j i S 2

= AK −1 ∂K
∂Ξ

∇ log p(Y | ˆf ) ,

Wpq = −δpq

∂ ˆf
∂Ξ

AqqWqp

+ ∆2

3 Results

To test the efﬁcacy of our method, we used a recently published biological data set which was stud-
ied using a linear response model by Barenco et al. [1]. This study focused on the tumour suppressor
protein p53. mRNA abundance was measured at regular intervals in three independent human cell
lines using Affymetrix U133A oligonucleotide microarrays. The authors then restricted their in-
terest to ﬁve known target genes of p53: DDB2, p21, SESN1/hPA26, BIK and TNFRSF10b. They
estimated the mRNA production rates by using quadratic interpolation between any three consecu-
tive time points. They then discretised the model and used MCMC sampling (assuming a log-normal
noise model) to obtain estimates of the model parameters Bj , Sj , Dj and f (t). To make the model
identiﬁable, the value of the mRNA decay of one of the target genes, p21, was measured experimen-
tally. Also, the scale of the sensitivities was ﬁxed by choosing p21’s sensitivity to be equal to one,
and f (0) was constrained to be zero. Their predictions were then validated by doing explicit protein
concentration measurements and growing mutant cell lines where the p53 gene had been knocked
out.

3.1 Linear response analysis

We ﬁrst analysed the data using the simple linear response model used by Barenco et al. [1]. Raw
data was processed using the mmgMOS model of [4], which also provides estimates of the credibil-
ity associated with each measurement. Data from the different cell lines were treated as independent
instantiations of f but sharing the model parameters {Bj , Sj , Dj , Ξ}. We used a squared exponen-
tial covariance function for the prior distribution on the latent function f . The inferred posterior
mean function for f , together with 95% conﬁdence intervals, is shown in Figure 1(a). The pointwise
estimates inferred by Barenco et al. are shown as crosses in the plot. The posterior mean function
matches well the prediction obtained by Barenco et al.2 Notice that the right hand tail of the in-
ferred mean function shows an oscillatory behaviour. We believe that this is an artifact caused by
the squared exponential covariance; the steep rise between time zero and time two forces the length
scale of the function to be small, hence giving rise to wavy functions [see page 123 in 8]. To avoid
this, we repeated the experiment using the “MLP” covariance function for the prior distribution over
f [12]. Posterior estimation cannot be obtained analytically in this case so we resorted to the MAP-
Laplace approximation described in section 2. The MLP covariance is obtained as the limiting case
 
!
of an inﬁnite number of sigmoidal neural networks and has the following covariance function
p(wt2 + b + 1) (wt02 + b + 1)
wtt0 + b
where w and b are parameters known as the weight and the bias variance. The results using this
covariance function are shown in Figure 1(b). The resulting proﬁle does not show the unexpected
oscillatory behaviour and has tighter credibility intervals.
Figure 2 shows the results of inference on the values of the hyperparameters Bj , Sj and Dj . The
columns on the left, shaded grey, show results from our model and the white columns are the
estimates obtained in [1]. The hyperparameters were assigned a vague gamma prior distribution
(a = b = 0.1, corresponding to a mean of 1 and a variance of 10). Samples from the posterior dis-
tribution were obtained using Hybrid Monte Carlo [see e.g. 7]. The results are in good accordance
with the results obtained by Barenco et al. Differences in the estimates of the basal transcription
rates are probably due to the different methods used for probe-level processing of the microarray
data.

k (t, t0 ) = arcsin

(19)

3.2 Non-linear response analysis

We then used the non-linear response model of section 2 in order to constrain the protein concentra-
tions inferred to be positive. We achieved this by using an exponential response of the transcription
rate to the logged protein concentration. The inferred MAP solutions for the latent function f are
plotted in Figure 3 for the squared exponential prior (a) and for the MLP prior (b).

2Barenco et al. also constrained the latent function to be zero at time zero.

(a)

(b)

Figure 1: Predicted protein concentration for p53 using a linear response model: (a) squared exponential
prior on f ; (b) MLP prior on f . Solid line is mean prediction, dashed lines are 95% credibility intervals. The
prediction of Barenco et al. was pointwise and is shown as crosses.

(c)
(b)
(a)
Figure 2: Results of inference on the hyperparameters for p53 data studied in [1]. The bar charts show (a)
Basal transcription rates from our model and that of Barenco et al.. Grey are estimates obtained with our model,
white are the estimates obtained by Barenco et al. (b) Similar for sensitivities. (c) Similar for decay rates.

4 Discussion

In this paper we showed how Gaussian processes can be used effectively in modelling the dynam-
ics of a very simple regulatory network motif. This approach has many advantages over standard
parametric approaches: ﬁrst of all, there is no need to restrict the inference to the observed time
points, and the temporal continuity of the inferred functions is accounted for naturally. Secondly,
Gaussian processes allow noise information to be accounted for in a natural way. It is well known
that biological data exhibits a large variability, partly because of technical noise (due to the difﬁculty
to measure mRNA abundance for low expressed genes, for example), and partly because of the dif-
ference between different cell lines. Accounting for these sources of noise in a parametric model can
be difﬁcult (particularly when estimates of the derivatives of the measured quantities are required),
while Gaussian Processes can incorporate this information naturally. Finally, MCMC parameter
estimation in a discretised model can be computationally expensive due to the high correlations be-
tween variables. This is a consequence of treating the protein concentrations as parameters, and
results in many MCMC iterations to obtain reliable samples. Parameter estimation can be achieved
easily in our framework by type II maximum likelihood or by using efﬁcient Monte Carlo sampling
techniques only on the model hyperparameters.
While the results shown in the paper are encouraging, this is still a very simple modelling situation.
For example, it is well known that transcriptional delays can play a signiﬁcant role in determining
the dynamics of many cellular processes [5]. These effects can be introduced naturally in a Gaussian
process model; however, the data must be sampled at a reasonably high frequency in order for delays
to become identiﬁable in a stochastic model, which is often not the case with microarray data sets.
Another natural extension of our work would be to consider more biologically meaningful nonlin-
earities, such as the popular Michaelis-Menten model of transcription used in [9]. Finally, networks
consisting of a single transcription factor are very useful to study small systems of particular interest
such as p53. However, our ultimate goal would be to describe regulatory pathways consisting of

0510−2−1012340510−2−101234DDB2hPA26TNFRSF20bp21BIK00.050.10.150.20.25DDB2hPA26TNFRSF20bp21BIK00.511.522.5DDB2hPA26TNFRSF20bp21BIK00.10.20.30.40.50.60.70.80.9(a)

(b)

Figure 3: Predicted protein concentration for p53 using an exponential response: (a) shows results of using a
squared exponential prior covariance on f ; (b) shows results of using an MLP prior covariance on f . Solid line
is mean prediction, dashed lines show 95% credibility intervals. The results shown are for exp(f ), hence the
asymmetry of the credibility intervals. The prediction of Barenco et al. was pointwise and is shown as crosses.

more genes. These can be dealt with in the general framework described in this paper, but careful
thought will be needed to overcome the greater computational difﬁculties.

Acknowledgements

We thank Martino Barenco for useful discussions and for providing the data. We gratefully acknowl-
edge support from BBSRC Grant No BBS/B/0076X “Improved processing of microarray data with
probabilistic models”.

References
[1] M. Barenco, D. Tomescu, D. Brewer, R. Callard, J. Stark, and M. Hubank. Ranked prediction of p53
targets using hidden variable dynamic modeling. Genome Biology, 7(3):R25, 2006.
[2] T. Graepel. Solving noisy linear operator equations by Gaussian processes: Application to ordinary and
In T. Fawcett and N. Mishra, editors, Proceedings of the International
partial differential equations.
Conference in Machine Learning, volume 20, pages 234–241. AAAI Press, 2003.
[3] J. C. Liao, R. Boscolo, Y.-L. Yang, L. M. Tran, C. Sabatti, and V. P. Roychowdhury. Network compo-
nent analysis: Reconstruction of regulatory signals in biological systems. Proceedings of the National
Academy of Sciences USA, 100(26):15522–15527, 2003.
[4] X. Liu, M. Milo, N. D. Lawrence, and M. Rattray. A tractable probabilistic model for affymetrix probe-
level analysis across multiple chips. Bioinformatics, 21(18):3637–3644, 2005.
[5] N. A. Monk. Unravelling nature’s networks. Biochemical Society Transactions, 31:1457–1461, 2003.
[6] R. Murray-Smith and B. A. Pearlmutter. Transformations of Gaussian process priors. In J. Winkler, N. D.
Lawrence, and M. Niranjan, editors, Deterministic and Statistical Methods in Machine Learning, volume
3635 of Lecture Notes in Artiﬁcial Intelligence, pages 110–123, Berlin, 2005. Springer-Verlag.
[7] R. M. Neal. Bayesian Learning for Neural Networks. Springer, 1996. Lecture Notes in Statistics 118.
[8] C. E. Rasmussen and C. K. Williams. Gaussian Processes for Machine Learning. MIT press, 2005.
[9] S. Rogers, R. Khanin, and M. Girolami. Model based identiﬁcation of transcription factor activity from
microarray data. In Probabilistic Modeling and Machine Learning in Structural and Systems Biology,
Tuusula, Finland, 17-18th June 2006.
[10] C. Sabatti and G. M. James. Bayesian sparse hidden components analysis for transcription regulation
networks. Bioinformatics, 22(6):739–746, 2006.
[11] G. Sanguinetti, M. Rattray, and N. D. Lawrence. A probabilistic dynamical model for quantitative infer-
ence of the regulatory mechanism of transcription. Bioinformatics, 22(14):1753–1759, 2006.
[12] C. K. I. Williams. Computation with inﬁnite neural networks. Neural Computation, 10(5):1203–1216,
1998.

0510012345605100123456