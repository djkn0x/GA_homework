A Probabilistic Algorithm Integrating Source
Localization and Noise Suppression of MEG and
EEG Data

Johanna M. Zumer
Biomagnetic Imaging Lab
Department of Radiology
Joint Graduate Group in Bioengineering
University of California, San Francisco
San Francisco, CA 94143-0628
johannaz@mrsc.ucsf.edu

Kensuke Sekihara
Dept. of Systems Design and Engineering
Tokyo Metropolitan, University
Tokyo, 191-0065 Japan
ksekiha@cc.tmit.ac.jp

Hagai T. Attias
Golden Metallic, Inc.
San Francisco, CA
htattias@goldenmetallic.com

Srikantan S. Nagarajan
Biomagnetic Imaging Lab
Department of Radiology
Joint Graduate Group in Bioengineering
University of California, San Francisco
San Francisco, CA 94143-0628
sri@mrsc.ucsf.edu

Abstract

We have developed a novel algorithm for integrating source localization and
noise suppression based on a probabilistic graphical model of stimulus-evoked
MEG/EEG data. Our algorithm localizes multiple dipoles while suppressing noise
sources with the computational complexity equivalent to a single dipole scan,
and is therefore more ef(cid:2)cient than traditional multidipole (cid:2)tting procedures. In
simulation, the algorithm can accurately localize and estimate the time course of
several simultaneously-active dipoles, with rotating or (cid:2)xed orientation, at noise
levels typical for averaged MEG data. Furthermore, the algorithm is superior to
beamforming techniques, which we show to be an approximation to our graphical
model, in estimation of temporally correlated sources. Success of this algorithm
for localizing auditory cortex in a tumor patient and for localizing an epileptic
spike source are also demonstrated.

1 Introduction

Mapping functional brain activity is an important problem in basic neuroscience research as well as
clinical use. Clinically, such brain mapping procedures are useful to guide neurosurgical planning,
navigation, and tumor and epileptic spike removal, as well as guiding the surgeon as to which areas
of the brain are still relevant for cognitive and motor function in each patient.
Many non-invasive techniques have emerged for functional brain mapping, such as functional mag-
netic resonance imaging (fMRI) and electromagnetic source imaging (ESI). Although fMRI is the
most popular method for functional brain imaging with high spatial resolution, it suffers from poor
temporal resolution since it measures blood oxygenation level signals with (cid:3)uctuations in the order
of seconds. However, dynamic neuronal activity has (cid:3)uctuations in the sub-millisecond time-scale
that can only be directly measured with electromagnetic source imaging (ESI). ESI refers to imag-
ing of neuronal activity using magnetoencephalography (MEG) and electroencephalography (EEG)

data. MEG refers to measurement of tiny magnetic (cid:2)elds surrounding the head and EEG refers to
measurement of voltage potentials using an electrode array placed on the scalp.
The past decade has shown rapid development of whole-head MEG/EEG sensor arrays and of al-
gorithms for reconstruction of brain source activity from MEG and EEG data. Source localization
algorithms, which can be broadly classi(cid:2)ed as parametric or tomographic, make assumptions to
overcome the ill-posed inverse problem. Parametric methods, including equivalent current dipole
(ECD) (cid:2)tting techniques, assume knowledge about the number of sources and their approximate lo-
cations. A single dipolar source can be localized well, but ECD techniques poorly describe multiple
sources or sources with large spatial extent. Alternatively, tomographic methods reconstruct an esti-
mate of source activity at every grid point across the whole brain. Of many tomographic algorithms,
the adaptive beamformer has been shown to have the best spatial resolution and zero localization
bias [1, 2].
All existing methods for brain source localization are hampered by the many types of noise present
in MEG/EEG data. The magnitude of the stimulus-evoked neural sources are on the order of noise on
a single trial, and so typically 50-200 trials are needed to average in order to distinguish the sources
above noise. This can be time-consuming and dif(cid:2)cult for a subject or patient to hold still or pay
attention through the duration of the experiment. Gaussian thermal noise is present at the sensors
themselves. Background room interference such as from powerlines and electronic equipment can
be problematic. Biological noise such as heartbeat, eyeblink or other muscle artifact can also be
present. Ongoing brain activity itself, including the drowsy-state alpha ((cid:24)10Hz) rhythm can drown
out evoked brain sources. Finally, most localization algorithms have dif(cid:2)culty in separating neural
sources of interest that have temporally overlapping activity.
Noise in MEG and EEG data is typically reduced by a variety of preprocessing algorithms before
being used by source localization algorithms. Simple forms of preprocessing include (cid:2)ltering out
frequency bands not containing a brain signal of interest. Additionally and more recently, ICA
algorithms have been used to remove artefactual components, such as eyeblinks. More sophisticated
techniques have also recently been developed using graphical models for preprocessing prior to
source localization [3, 4].
This paper presents a probabilistic modeling framework for MEG/EEG source localization that is
robust to interference and noise. The framework uses a probabilistic hidden variable model that de-
scribes the observed sensor data in terms of activity from unobserved brain and interference sources.
The unobserved source activities and model parameters are inferred from the data by a Variational-
Bayes Expectation-Maximization algorithm. The algorithm then creates a spatiotemporal image of
brain activity by scanning the brain, inferring the model parameters and variables from sensor data,
and using them to compute the likelihood of a dipole at each grid location in the brain. We also
show that an established source localization method, the minimum variance adaptive beamformer
(MVAB), is an approximation of our framework.

2 Probabilistic model integrating source localization and noise suppression

This section describes the generative model for the data. We assume that the MEG/EEG data has
been collected such that stimulus onset or some other experimental marker indicated the ’zero’ time
point. Ongoing brain activity, biological noise, background environmental noise, and sensor noise
are present in both pre-stimulus and post-stimulus periods; however, the evoked neural sources of
interest are only present in the post-stimulus time period. We therefore assume that the sensor data
can be described as coming from four types of sources: (1) evoked source at a particular voxel (grid
point), (2) all other evoked sources not at that voxel, (3) all background noise sources with spatial
covariance at the sensors (including brain, biological, or environmental sources), and (4) sensor
noise. We (cid:2)rst infer the model describing source types (3) and (4) from the pre-stimulus data, then
(cid:2)x certain quantities (described in section 2.2) and infer the full model describing the remaining
source types (1) and (2) from the post-stimulus data (described in section 2.1). After inference of
the model, a map of the source activity is created as well as a map of the likelihood of activity across
voxels.
Let yn denote the K (cid:2) 1 vector of sensor data for time point n, where K is the number of sensors
(typically 200). Time ranges from (cid:0)Npre : 0 : Npost (cid:0) 1 where Npre (Npost ) indicates the number

a

A

F

s

b

B

l

u

x

y

Figure 1: (Left) Graphical model for proposed algorithm. Variables are inside dotted box, param-
eters outside dotted box. Values in circles unknown and learned from the model, and values in
squares known. (Right) Representation of factors in(cid:3)uencing the data recorded at the sensors. In
orange, a post-stimulus source at the voxel of interest, focused on by the lead (cid:2)eld F. In red, other
post-stimulus sources not at that particular voxel. In green, all background sources, including on-
going brain activity, eyeblinks, heartbeat, and electrical noise. In blue, thermal noise present in each
sensor.

(1)

of time samples in the pre-(post-)stimulus period. The generative model for data yn is
yn = (cid:26) Bun + vn
n = (cid:0)Npre ; : : : ; (cid:0)1
n + Ar xr
F r sr
n = 0; : : : ; Npost (cid:0) 1
n + Bun + vn
The K (cid:2) 3 forward lead (cid:2)eld matrix F r represents the physical (and linear) relationship between
a dipole source at voxel r for each orientation, and its in(cid:3)uence on sensor k = 1 : K [5]. The
lead (cid:2)eld F r is calculated from knowing the geometry of the source location to the sensor location,
as well as the conducting medium in which the source lies: the human head is most commonly
n is a 3 (cid:2) 1 vector
approximated as a single-shell sphere volume conductor. The source activity sr
of dipole strength in each of the three orientations at time n for the voxel r . The K (cid:2) L matrix A
and the L (cid:2) 1 vector xn represent the post-stimulus mixing matrix and evoked non-localized factors,
respectively, corresponding to source type (2) discussed above. The K (cid:2) M matrix B and the M (cid:2) 1
vector un represent the background mixing matrix and background factors, respectively. The K (cid:2) 1
vector vn represents the sensor-level noise. All quantities depend on r in the post-stimulus period
except for B ; un and (cid:21) (the sensor precision), which will be learned from the pre-stimulus data and
(cid:2)xed as the other quantities are learned for each voxel. Note however the posterior update for (cid:22)un
does depend on the voxel r . The graphical model is shown in Fig. 1. This generative model becomes
a probabilistic model when we specify prior distributions, as described in the next two sections.

2.1 Localization of evoked sources learned from post-stimulus data

In the stimulus-evoked paradigm, the source strength at each voxel is learned from the post-stimulus
data. The background mixing matrix B and sensor noise precision (cid:21) are (cid:2)xed, after having been
learned from the pre-stimulus data, described in section 2.2. We assume those quantities remain con-
stant through the post-stimulus period and are independent of source location. We assume Gaussian
prior distributions on the source factors and interference factors. We further make the assumption
that the signals are independent and identically distributed (i.i.d.) across time. The source factors
have prior precision given by the 3 (cid:2) 3 matrix (cid:8), which relates to the strength of the dipole in each
of 3 orientations. All Normal distributions speci(cid:2)ed in this paper are de(cid:2)ned by their mean and
precision (inverse covariance).
3
p(s) = Yn
Yj=1
p(sjn ) = N (0; (cid:8))
The interference and background factors are assumed to have identity precision. To complete spec-
i(cid:2)cation of this model, we need to specify prior distributions on the model parameters. We use a

p(sn ) =

p(sn );

(2)

p(xn ); p(xn ) =

(3)

conjugate prior for the interference mixing matrix A, where the (cid:11)j is a hyperparameter over the j th
column of A and (cid:21)i is the precision of the ith sensor. The hyperparameter (cid:11) (a diagonal matrix)
provides a robust mechanism for automatic model order selection, so that the optimal size of A is
inferred from the data through (cid:11).
p(x) = Yn
p(u) = Yn

L
Yj=1
p(xjn ) = N (0; I );
M
Yj=1
N (Aij j0; (cid:21)i(cid:11)j )

p(A) = Yij
We now specify the full model:
p(y js; x; u; A; B ) = Yn
(4)
p(yn jsn ; xn ; un ; A; B ; (cid:21)) = N (yn jF sn + Axn + Bun ; (cid:21))
Exact inference on this model is intractable using the joint posterior over the interference factors and
interference mixing matrix; thus the following variational-Bayesian approximation for the posteriors
is used:

p(yn jsn ; xn ; un ; A; B );

p(ujn ) = N (0; I )

p(un ); p(un ) =

(5)
p(s; x; Ajy) (cid:25) q(s; x; Ajy) = q(s; xjy)q(Ajy)
We learn the hidden variables and parameters from the post-stimulus data, iterating through each
voxel in the brain, using a variational-Bayesian Expectation-Maximization (EM) algorithm. All
variables, parameters and hyperparameters are hidden and are learned from the data. In place of
maximizing the logp(y), which would be mathematically intractable, we maximize a lower bound
to logp(y) de(cid:2)ned by F in the following equation
F = Z dx ds dA q(s; x; Ajy) [logp(y; s; x; A) (cid:0) logq(s; x; Ajy)]
(6)
= log p(y) (cid:0) KL[q(s; x; Ajy)jjp(s; x; Ajy)]
where K L(q jjp) is the Kullback-Leibler divergence between distributions q and p. F is equal to
logp(y) when the approximation in Eq. 5 is true, thus making the K L-distance zero. We use a
variational-Bayesian EM algorithm which alternately maximizes the function F with respect to the
posteriors q(s; xjy) and q(Ajy). In the E-step, F is maximized w.r.t. q(s; xjy), keeping q(Ajy)
constant, and the suf(cid:2)cient statistics of the hidden variables are computed.
In the M-step, F is
maximized w.r.t. q(Ajy), keeping q(s; xjy) constant, and the MAP estimate of the parameters and
hyperparameters are computed. In the E-step, the posterior distribution of the background factors
given the data is computed:

n jyn ) = N ( (cid:22)x0
q(x0
n ; (cid:0));
(cid:0) = (cid:22)A0T (cid:21) (cid:22)A0 + K(cid:9) + I 0
n = (cid:0)(cid:0)1 (cid:22)A0T (cid:21)yn ;
(cid:22)x0
where we de(cid:2)ne:
I ! ; (cid:9) =   0
0
0
(cid:22)A0 = (cid:0) F (cid:22)A (cid:22)B (cid:1) ; I 0 =   (cid:8) 0
0
n =   (cid:22)sn
0 ! (8)
(cid:22)un ! ;
(cid:22)x0
0 (cid:9)AA 0
0
0
(cid:22)xn
I
0
0
0
0
In the M-step, we maximize the function F w.r.t. q(Ajy) holding q(s; xjy) (cid:2)xed. We update the
posterior distribution of the interference mixing matrix A including its precision (cid:9)AA . Note that the
lead (cid:2)eld F is (cid:2)xed based on the geometry of the sensors relative to the head, and (cid:22)B was learned
and (cid:2)xed from the pre-stimulus data. The sensor noise precision (cid:21) is also kept (cid:2)xed from the pre-
stimulus period. The MAP values of the hyperparameter (cid:11) and source factor precision (cid:8) are learned
here from the post-stimulus data.

(7)

(cid:22)A = (Ryx (cid:0) F Rsx (cid:0) (cid:22)BRux )(cid:9)AA ; (cid:9)AA = (Rxx + (cid:11))(cid:0)1 ;
1
1
K
N

(cid:22)AT(cid:21) (cid:22)A + (cid:9)AA )

(cid:11)(cid:0)1 = diag(

(cid:8)(cid:0)1 =

Rss ;

(9)

The matrices, such as Ryx , represent the posterior covariance between the two subscripts and explicit
de(cid:2)nitions are omitted for space.
In each iteration of EM, the marginal likelihood is increased.
The variational likelihood function (the lower bound on the exact marginal likelihood) is given as
follows:

N
2

log

K
2

(cid:0)

1
2

(10)

Lr =

0 T r
n (cid:0)r (cid:22)x

logj(cid:11)r jj(cid:9)r j

j(cid:21)jj(cid:8)r j
j(cid:0)r j

N
n (cid:17) +
Xn=1 (cid:16)yT
0 r
n (cid:21)yn (cid:0) (cid:22)x
This likelihood function is dependent on the source voxel r and thus a map of the likelihood across
the brain can be displayed. Furthermore, we can also plot an image of the source power estimates
and the time course of activity at each voxel.
We note that the computational complexity of the proposed
algorithm is on the order O(K LN S ), roughly equivalent to
a single dipole scan, which is of order O(N (K 2 + S )). These
are much smaller than the complexity of a multi-dipole scan
which is order O(N S P ) where P is the number of dipoles,
and if S represents roughly several thousand voxels. We fur-
ther note that the number of hidden variables to be estimated
is less than the number of data points observed, thus not pos-
ing signi(cid:2)cant problems for estimation accuracy.

Algortihm, sim. interference
Algorithm, real brain noise
MVAB, sim. inteference
MVAB, real brain noise

Localization error of proposed model (blue) 
relative to beamforming (green)

)
m
m
(
 
r
o
r
r
E

20
20

15
15

10
10

5
5

2.2 Separation
of background sources learned from pre-stimulus data

0
0

-10
-10

-5
-5

0
0

5
5

SNIR (dB)

Figure 2: Performance of algorithm
relative to beamforming for simu-
lated datasets. See text for details.

We learn the background mixing matrix and sensor noise pre-
cision from the pre-stimulus data using a variational-Bayes
factor analysis model. We assume Gaussian prior distribu-
tions on the background factors and sensor noise, with zero
mean and identity precision; we assume a (cid:3)at prior on the
sensor precision. We again use a conjugate prior for the back-
ground mixing matrix B , where (cid:12)j is a hyperparameter, similar to the expression for the interference
mixing matrix. All variables, parameters and hyperparameters are hidden and are learned from the
pre-stimulus data. We make the variational-Bayesian approximation for the background mixing ma-
trix and background factors p(u; B jy) (cid:25) q(u; B jy) = q(ujy)q(B jy). In the E-step, we maximize
the function F w.r.t. q(ujy) holding q(B jy) (cid:2)xed. We update the posterior distribution of the factors:
q(ujy) = Yn
(cid:22)un = (cid:13)(cid:0)1B T (cid:21)yn ; (cid:13) = (cid:22)B T (cid:21) (cid:22)B + K  (cid:0)1 + I

q(un jyn ); q(un jyn ) = N ( (cid:22)un ; (cid:13) )

In the M-step, we compute the full posterior distribution of the background mixing matrix B , includ-
ing its precision matrix   , and the MAP estimates of the noise precision (cid:21) and the hyperparameter
(cid:12) . We assume the noise precision is diagonal.
(cid:22)B = Ryu  ;
1
K

  = (Ruu + (cid:12) )(cid:0)1
1
N

diag(Ryy (cid:0) (cid:22)BRT
yu )

(cid:22)BT(cid:21) (cid:22)B +  );

(cid:12)(cid:0)1 = diag(

(cid:21)(cid:0)1 =

(11)

2.3 Relationship to minimum-variance adaptive beamforming

Minimum variance adaptive beamforming (MVAB) is one of the best performing source local-
ization techniques. MVAB estimates the dipole source time series by ^sn = WM V AB yn , where
yy and Ryy is the measured data covariance matrix. Thus, MVAB
WM V AB = (F T R(cid:0)1
yy F )(cid:0)1F T R(cid:0)1
also has computational complexity equivalent to a single-dipole scan, on the order O(K 2 + S ).
MVAB attempts to suppress interference, but recent studies have shown the MVAB is ineffective in
cancellation of interference from other brain sources, especially if there are many such sources. In
this section, we derive that MVAB is an approximation to inference on our model.

)
m
m
(
 
z

40

20

0

-20

)
m
m
(
 
z

40

20

0

-20

-50

0
x (mm)

50

-50

0
x (mm)

50

1

0

-1
-600
1
0.5

-0.5

-600
1

0

-1
-600

-200

200

600

1000

-200

200

600

1000

-200

200

600

1000

Figure 3: Example of algorithm and MVAB for correlated source simulation. See text for details

We start by rewriting Eq. (1) as yn = F sn + zn , where zn is termed the total noise and is given
by zn = Axn + Bun + vn . It has mean zero and precision matrix (cid:7) = (AAT + BB T + (cid:21)(cid:0)1 )(cid:0)1 .
Assuming we have estimated the model parameters A; B ; (cid:21); (cid:8), the MAP estimate of the dipole
source time series is (cid:22)sn = W yn , where W = (cid:0)(cid:0)1F T (cid:7) and (cid:0) = F T (cid:7)F + (cid:8). It can be shown that
this expression is equivalent to Eq. 8.
In the in(cid:2)nite data limit, the data covariance satis(cid:2)es Ryy = F (cid:8)(cid:0)1F T + (cid:7)(cid:0)1 . Its inverse is found,
using the matrix inversion lemma, to be R(cid:0)1
yy = (cid:7) (cid:0) (cid:7)F (cid:0)(cid:0)1F T (cid:7). Hence, we obtain

(12)
F T R(cid:0)1
yy = (I (cid:0) F T (cid:7)F (cid:0)(cid:0)1 )F T (cid:7) = (cid:8)(cid:0)(cid:0)1F T (cid:7)
where the last step used the expression for (cid:0). Next, we approximate (cid:0) (cid:25) F T (cid:7)F . We then use Eq.
(12) to obtain:
yy F )(cid:0)1F T R(cid:0)1
W (cid:25) (F T (cid:7)F )(cid:0)1F T (cid:7) = (F T (cid:7)F )(cid:0)1(cid:0)(cid:8)(cid:0)1(cid:8)(cid:0)(cid:0)1F T (cid:7) = (F T R(cid:0)1
yy = WM V AB

3 Results

3.1 Simulations

Performance of SAKETINI (blue) relative to 
beamforming (green) in ability to estimate source time course 
NA
IN

RE

1

1

1

0.8

0.6

0.4

0.2

0.8

0.6

0.4

0.2

0.8

0.6

0.4

0.2

e
c
r
u
o
s
 
e
u
r
t
 
h
t
i
w
 
d
e
t
a
m
i
t
s
e
 
f
o
 
n
o
i
t
a
l
e
r
r
o
C

The proposed method was tested in a variety of real-
istic source con(cid:2)gurations reconstructed on a 5mm
voxel grid. A single-shell spherical volume conduc-
tor model was used to calculate the forward lead
(cid:2)eld [5]. Simulated datasets were constructed by
placing Gaussian-damped sinusoidal time courses at
speci(cid:2)c locations inside a voxel grid based on real-
istic head geometry. Sources were assumed to be
present in the post-stimulus period with 437 samples
along with a pre-stimulus period of 263 samples.
In the (cid:148)noise-alone (NA)(cid:148) cases, Gaussian noise
only was added to all time points at the sensors. In
the (cid:148)interference (IN)(cid:148) cases, Gaussian noise time
courses occurring in both pre- and post-stimulus
periods, representing simulated (cid:148)ongoing(cid:148) activity,
were placed at 50 random locations throughout the
brain voxel grid, and their activity was projected
Figure 4: Performance of algorithm relative
onto the sensors and added to both the sensor noise
to beamforming for simulated datasets. See
and source activity. Finally, in the (cid:148)real (RE)(cid:148) cases,
text for details.
700 samples of real MEG sensor data averaged over
100 trials collected while a human subject was alert but not performing tasks or receiving stimuli.
This real background data thus includes real sensor noise plus real (cid:148)ongoing(cid:148) brain activity that
could interfere with evoked sources and adds spatial correlation to the sensor data. We varied the
Signal-to-Noise Ratio (SNR) and the corresponding Signal to Noise-plus-Interference Ratio (SNIR).
SNIR is calculated from the ratio of the sensor data resulting from sources only to sensor data from
noise plus interference. The (cid:2)rst performance (cid:2)gure (Fig. 2) shows the localization error of the
proposed method relative to the MVAB. For this data, a single dipole was placed randomly within

Algorithm, uncorrelated sources
MVAB, uncorrelated sources
Algorithm, correlated sources
MVAB, correlated sources

5
0
SNIR (dB)

0
SNIR (dB)

5

5
0
SNIR (dB)

0
-5

0
-5

0
-5

)
0
0
0
 1
o
t
 
0
0
0
1
-
 (
y
t
si
n
e
t
n
I
 
d
e
z
i
al
m
r
o
N

1000

500

0

-500

-1000
-100

0

100

200
Time (ms)

300

400

Figure 5: Algorithm applied to auditory MEG dataset in patient with temporal lobe tumor.
the voxel grid space. The largest peak in the likelihood map was found and the distance from this
point to the true source was recorded. Each datapoint is an average of 20 realizations of the source
con(cid:2)guration, with error bars showing standard error. This simulation was performed for a variety
of SNIR’s and for all three cases of noise described above. The results from NA were omitted since
both the proposed method and MVAB performed perfectly (zero error). This (cid:2)gure clearly shows
that the error in localization is smaller for the proposed method (black) than for MVAB (green).
The next set of simulations examines the proposed method’s ability to estimate the source time
course sn . Three sources were placed in the brain voxel grid. The locations of these sources were
(cid:2)xed, but the orientation and time courses were allowed to vary across realizations of the simula-
tions. In half the cases, two of the three sources were forced to be perfectly correlated in time (a
scenario where the MVAB is known to fail), while the time course of the third source was random
relative to the other two. An example of the likelihood map and estimated time courses are shown in
Fig. 3. The likelihood map from the proposed method (on the left) has peaks near all three sources,
including the two that were perfectly correlated (depicted by squares). However, the MVAB (middle
plot) largely misses the source on the left. On the right plot, the estimated time courses from the
proposed method (dashes) and MVAB (dots) are plotted relative to the true time course (solid). The
top and middle plots correspond to the (square) correlated sources. While both methods estimate
the time courses well, MVAB underestimates the overall strength of the source on the top plot, and
exhibits extra noise in the pre-stimulus period for the middle plot.
The performance of the proposed model on the same set of simulations of correlated sources, com-
pared to beamforming, are shown in Fig. 4. This (cid:2)gure shows the correlation of the estimated
with the true time course, for three cases of NA, IN, and RE, and for both correlated and uncorre-
lated sources, as a function of SNIR. The proposed method consistently out-performs the MVAB
whether the simulated sources are highly correlated with each other (dashed lines), or uncorrelated
(solid), and especially in the RE case. Each datapoint represents an average of 10 realizations of the
simulation, with standard errors on the order of 0.05 (not shown).

3.2 Real data

Stimulus-evoked data was collected in a 275-channel CTF System MEG device from a patient with
temporal lobe tumor near auditory cortex. The stimulus was a noise burst presented binaurally in
120 trials. A large peak is typically seen around 100ms after presentation of an auditory stimulus,
termed the M100 peak. Figure 5 shows the results of the proposed method applied to this dataset.
On the right, the likelihood map show a spatial peak in auditory cortex near the tumor. At that peak
voxel, the time course was extracted and plotted on the left, showing the clear M100 peak. This
information can be useful to the neurosurgical team for guiding the location of surgical lesion and
for providing knowledge of the patient’s auditory processing abilities.
We next tested the proposed method on its ability to localize interictal spikes obtained from a patient
with epilepsy. No sensory stimuli were presented to this patient in this dataset, which was collected
in the same MEG device described above. A Registered EEG/Evoked Potential Technologist marked
segments of the continuously-collected dataset which contained spontaneous spikes, as well as seg-
ments that clearly contained no spikes. One segment of data with a spike marked at 400ms was used
here as the (cid:148)post-stimulus(cid:148) period and a separate, spike-free, segment of equal length was used as
the (cid:148)pre-stimulus(cid:148) period. Figure 6 shows the proposed method’s performance on this dataset. The
top left subplot shows the raw sensor data for the segment containing the marked spike. The bottom
left shows the location of the equivalent-current dipole (ECD) (cid:2)t to several spikes from this patient;
this location from the ECD (cid:2)t would normally be used clinically. The middle bottom (cid:2)gure shows
the likelihood map from the proposed model; the peak is in clear agreement with the standard ECD
localization. The middle top (cid:2)gure shows the time course estimated for the likelihood spatial peak.

x 10  12

RMS = 311.2 fT

T)
(
 
d
l
e
i
F
 
c
i
t
e
n
g
a
M
 

1

0.8

0.6

0.4

0.2

0

0. 2

0. 4

0. 6

0. 8

1

0

100

200

300

400
Time (ms)

500

600

700

1000

500

0

-500

-1000
0

)
0
0
0
 1
o
t
 
0
0
0
1
-
 (
y
t
si
n
e
t
n
I
 
d
e
z
i
al
m
r
o
N

200

400
Time (ms)

600

1000

500

0

-500

-1000
0

)
0
0
0
 1
o
t
 
0
0
0
1
-
 (
y
t
si
n
e
t
n
I
 
d
e
z
i
al
m
r
o
N

200

400
Time (ms)

600

1000

900

800

700

600

500

400

300

200

100

0

1000

800

600

400

200

0

200

400

600

800

1000

Figure 6: Performance of algorithm applied to data from an epileptic patient. See text for details.

The spike at 400ms is clearly seen; this cleaned waveform could be of use to the clinician in ana-
lyzing peak shape. Finally, the top right plot shows a source time course from a randomly selected
location far from the epileptic spike source (shown with cross-hairs on bottom right plot), in order
to show the low noise level and to show lack of cross-talk onto source estimates elsewhere.

4 Extensions

We have described a novel probabilistic algorithm which performs source localization while robust
to interference and demonstrated its superior performance over a standard method in a variety of
simulations and real datasets. The model takes advantage of knowledge of when sources of interest
are not occurring (such as in the pre-stimulus period of a evoked response paradigm). This model
currently assumes averaged data from an evoked response paradigm, but could be extended to exam-
ine variations from the average in individual trials, only involving a few extra parameters to estimate.
Furthermore, the model could be extended to take advantage of temporal smoothness in the data as
well as frequency content. Additionally, spatial smoothness or spatial priors from other modalities,
such as structural or functional MRI, could be incorporated. Furthermore, one is not limited to sn
in a single voxel; the above formulation holds for any P arbitrarily chosen dipole components, no
matter which voxels they belong to, and for any value of P . Of course, as P increases the inferred
value of (cid:8) becomes less accurate, and one might choose to restrict it to a diagonal or block-diagonal
form.

References
[1] K. Sekihara, M. Sahani, and S.S. Nagarajan, (cid:147)Localization bias and spatial resolution of adaptive
and non-adaptive spatial (cid:2)lters for MEG source reconstruction,(cid:148) NeuroImage, vol. 25, pp. 1056(cid:150)
1067, 2005.
[2] K. Sekihara, S.S. Nagarajan, D. Poeppel, and A. Marantz, (cid:147)Performance of an MEG adaptive-
beamformer technique in the presence of correlated neural activities: Effects on signal intensity
and time-course estimates,(cid:148) IEEE Trans Biomed Eng, vol. 49, pp. 1534(cid:150)1546, 2002.
[3] Srikantan S. Nagarajan, Hagai T. Attias, Kenneth E. Hild, and Kensuke Sekihara, (cid:147)A graphical
model for estimating stimulus-evoked brain responses from magnetoencephalography data with
large background brain activity,(cid:148) Neuroimage, vol. 30, pp. 400(cid:150)416, 2006.
[4] S.S. Nagarajan, H.T. Attias, K.E. Hild, and K. Sekihara, (cid:147)Stimulus evoked independent factor
analysis of MEG data with large background activity,(cid:148) in Adv. Neur. Info. Proc. Sys., 2005.
[5] J. Sarvas, (cid:147)Basic mathematical and electromagnetic concepts of the biomagnetic inverse prob-
lem,(cid:148) Phys Med Biol, vol. 32, pp. 11(cid:150)22, 1987.

