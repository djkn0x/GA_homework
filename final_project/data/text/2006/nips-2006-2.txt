Online Classiﬁcation for Complex Problems Using
Simultaneous Projections

Yonatan Amit1
Shai Shalev-Shwartz1 Yoram Singer1,2
1 School of Computer Sci. & Eng., The Hebrew University, Jerusalem 91904, Israel
2 Google Inc. 1600 Amphitheatre Pkwy, Mountain View, CA 94043, USA
{mitmit,shais,singer}@cs.huji.ac.il

Abstract
We describe and analyze an algorithmic framework for online classiﬁcation where
each online trial consists of multiple prediction tasks that are tied together. We
tackle the problem of updating the online hypothesis by deﬁning a projection
problem in which each prediction task corresponds to a single linear constraint.
These constraints are tied together through a single slack parameter. We then in-
troduce a general method for approximately solving the problem by projecting
simultaneously and independently on each constraint which corresponds to a pre-
diction sub-problem, and then averaging the individual solutions. We show that
this approach constitutes a feasible, albeit not necessarily optimal, solution for the
original projection problem. We derive concrete simultaneous projection schemes
and analyze them in the mistake bound model. We demonstrate the power of
the proposed algorithm in experiments with online multiclass text categorization.
Our experiments indicate that a combination of class-dependent features with the
simultaneous projection method outperforms previously studied algorithms.

1 Introduction

In this paper we discuss and analyze a framework for devising efﬁcient online learning algorithms
for complex prediction problems such as multiclass categorization. In the settings we cover, a com-
plex prediction problem is cast as the task of simultaneously coping with multiple simpliﬁed sub-
problems which are nonetheless tied together. For example, in multiclass categorization, the task is
to predict a single label out of k possible outcomes. Our simultaneous projection approach is based
on the fact that we can retrospectively (after making a prediction) cast the problem as the task of
making k − 1 binary decisions each of which involves the correct label and one of the competing
labels. The performance of the k − 1 predictions is measured through a single loss. Our approach
stands in contrast to previously studied methods which can be roughly be partitioned into three
paradigms. The ﬁrst and probably the simplest previously studied approach is to break the problem
into multiple decoupled problems that are solved independently. Such an approach was used for
instance by Weston and Watkins [1] for batch learning of multiclass support vector machines. The
simplicity of this approach also underscores its deﬁciency as it is detached from the original loss of
the complex decision problem. The second approach maintains the original structure of the problem
but focuses on a single, worst performing, derived sub-problem (see for instance [2]). While this
approach adheres with the original structure of the problem, the resulting update mechanism is by
construction sub-optimal as it oversees almost all of the constraints imposed by the complex pre-
diction problem. (See also [6] for analysis and explanation of the sub-optimality of this approach.)
The third approach for dealing with complex problems is to tailor a speciﬁc efﬁcient solution for
the problem on hand. While this approach yielded efﬁcient learning algorithms for multiclass cate-
gorization problems [2] and aesthetic solutions for structured output problems [3, 4], devising these
algorithms required dedicated efforts. Moreover, tailored solutions typically impose rather restric-
tive assumptions on the representation of the data in order to yield efﬁcient algorithmic solutions.

In contrast to previously studied approaches, we propose a simple, general, and efﬁcient framework
for online learning of a wide variety of complex problems. We do so by casting the online update
task as an optimization problem in which the newly devised hypothesis is required to be similar to
the current hypothesis while attaining a small loss on multiple binary prediction problems. Casting
the online learning task as a sequence of instantaneous optimization problems was ﬁrst suggested
and analyzed by Kivinen and Warmuth [12] for binary classiﬁcation and regression problems. In
our optimization-based approach, the complex decision problem is cast as an optimization problem
that consists of multiple linear constraints each of which represents a simpliﬁed sub-problem. These
constraints are tied through a single slack variable whose role is to asses the overall prediction
quality for the complex problem. We describe and analyze a family of two-phase algorithms. In the
ﬁrst phase, the algorithms solve simultaneously multiple sub-problems. Each sub-problem distills
to an optimization problem with a single linear constraint from the original multiple-constraints
problem. The simple structure of each single-constraint problem results in an analytical solution
which is efﬁciently computable. In the second phase, the algorithms take a convex combination of
the independent solutions to obtain a solution for the multiple-constraints problem. The end result is
an approach whose time complexity and mistake bounds are equivalent to approaches which solely
deal with the worst-violating constraint [9]. In practice, though, the performance of the simultaneous
projection framework is much better than single-constraint update schemes.

2 Problem Setting

In this section we introduce the notation used throughout the paper and formally describe our prob-
lem setting. We denote vectors by lower case bold face letters (e.g. x and ω ) where the j ’th element
of x is denoted by xj . We denote matrices by upper case bold face letters (e.g. X), where the j ’th
row of X is denoted by xj . The set of integers {1, . . . , k} is denoted by [k ]. Finally, we use the
hinge function [a]+ = max{0, a}.
Online learning is performed in a sequence of trials. At trial t the algorithm receives a matrix Xt
of size kt × n, where each row of Xt is an instance, and is required to make a prediction on the
label associated with each instance. We denote the vector of predicted labels by ˆyt . We allow ˆy t
j
j ) and | ˆy t
j | is the conﬁdence
to take any value in R, where the actual label being predicted is sign( ˆy t
in the prediction. After making a prediction ˆyt the algorithm receives the correct labels yt where
j ∈ {−1, 1} for all j ∈ [kt ]. In this paper we assume that the predictions in each trial are formed
y t
by calculating the inner product between a weight vector ω t ∈ Rn with each instance in Xt , thus
ˆyt = Xt ω t . Our goal is to perfectly predict the entire vector yt . We thus say that the vector ˆyt
j 6= sign( ˆy t
j ). That is, we suffer a
was imperfectly predicted if there exists an outcome j such that y t
(cid:3)
(cid:2)1 − y t
j ) 6= y t
unit loss on trial t if there exists j , such that sign( ˆy t
j . Directly minimizing this combinatorial
error is a computationally difﬁcult task. Therefore, we use an adaptation of the hinge-loss, deﬁned
‘ ( ˆyt , yt ) = maxj∈[kt ]
j ˆy t
j ˆy t
, as a proxy for the combinatorial error. The quantity y t
j is
j
+
often referred to as the (signed) margin of the prediction and ties the correctness and the conﬁdence
in the prediction. We use ‘ (ω ; (Xt , yt )) to denote ‘ ( ˆyt , yt ) where ˆyt = Xt ω . We also denote the
j ) 6= y t
set of instances whose labels were predicted incorrectly by Mt = {j | sign( ˆy t
j }, and similarly
the set of instances whose hinge-losses are greater than zero by Γt = {j | [1 − y t
j ]+ > 0}.
j ˆy t

3 Derived Problems

In this section we further explore the motivation for our problem setting by describing two different
complex decision tasks and showing how they can be cast as special cases of our setting. We also
would like to note that our approach can be employed in other prediction problems (see Sec. 7).
Multilabel Categorization In the multilabel categorization task each instance is associated with
a set of relevant labels from the set [k ]. The multilabel categorization task can be cast as a
special case of a ranking task in which the goal is to rank the relevant labels above the irrel-
evant ones. Many learning algorithms for this task employ class-dependant features (for ex-
ample, see [7]). For simplicity, assume that each class is associated with n features and de-
note by φ(x, r) the feature vector for class r . We would like to note that features obtained
for different classes typically relay different information and are often substantially different.

ω t

ω t+1

3 (ω · xt
3 ) ≥ 1
y t

1 (ω · xt
1 ) ≥ 1
y t

2 (ω · xt
2 ) ≥ 1
y t

A categorizer, or label ranker, is based on a weight vector
ω . A vector ω induces a score for each class ω · φ(x, r)
which, in turn, deﬁnes an ordering of the classes. A learner is
required to build a vector ω that successfully ranks the labels
according to their relevance, namely for each pair of classes
(r, s) such that r is relevant while s is not, the class r should
be ranked higher than the class s. Thus we require that ω ·
φ(x, r) > ω · φ(x, s) for every such pair (r, s). We say that a
label ranking is imperfect if there exists any pair (r, s) which
violates this requirement. The loss associated with each such
violation is [1 − (ω · φ(x, r) − ω · φ(x, s))]+ and the loss
of the categorizer is deﬁned as the maximum over the losses
induced by the violated pairs. In order to map the problem to
our setting, we deﬁne a virtual instance for every pair (r, s)
such that r is relevant and s is not. The new instance is the
n dimensional vector deﬁned by φ(x, r) − φ(x, s). The label
associated with all of the instances is set to 1. It is clear that
an imperfect categorizer makes a prediction mistake on at
least one of the instances, and that the losses deﬁned by both
problems are the same.
Ordinal Regression In the problem of ordinal regression an instance x is a vector of n features
that is associated with a target rank y ∈ [k ]. A learning algorithm is required to ﬁnd a vector ω
and k thresholds b1 ≤ · · · ≤ bk−1 ≤ bk = ∞. The value of ω · x provides a score from which the
prediction value can be deﬁned as the smallest index i for which ω · x < bi , ˆy = min {i|ω · x < bi }.
In order to obtain a correct prediction, an ordinal regressor is required to ensure that ω · x ≥ bi for all
i < y and that ω · x < bi for i ≥ y . It is considered a prediction mistake if any of these constraints
is violated. In order to map the ordinal regression task to our setting, we introduce k − 1 instances.
Each instance is a vector in Rn+k−1 . The ﬁrst n entries of the vector are set to be the elements of
x, the remaining k − 1 entries are set to −δi,j . That is, the i’th entry in the j ’th vector is set to −1
if i = j and to 0 otherwise. The label of the ﬁrst y − 1 instances is 1, while the remaining k − y
instances are labeled as −1. Once we learned an expanded vector in Rn+k−1 , the regressor ω is
obtained by taking the ﬁrst n components of the expanded vector and the thresholds b1 , . . . , bk−1
are set to be the last k − 1 elements. A prediction mistake of any of the instances corresponds to an
incorrect rank in the original problem.

Figure 1: Illustration of the simultane-
ous projections algorithm: each instance
casts a constraint on ω and each such
constraint deﬁnes a halfspace of feasi-
ble solutions. We project on each half-
space in parallel and the new vector is a
weighted average of these projections

4 Simultaneous Projection Algorithms
(cid:0)ω t · xt
(cid:1) ≥ 1. If all the constraints are satisﬁed
Recall that on trial t the algorithm receives a matrix, Xt , of kt instances, and predicts ˆyt = Xt ω t .
After performing its prediction, the algorithm receives the corresponding labels yt . Each such
instance-label pair casts a constraint on ω t , y t
j
j
by ω t then ω t+1 is set to be ω t and the algorithm proceeds to the next trial. Otherwise, we would
like to set ω t+1 as close as possible to ω t while satisfying all constraints.
Such an aggressive approach may be sensitive to outliers and over-ﬁtting. Thus, we allow some
of the constraints to remain violated by introducing a tradeoff between the change to ω t and the
loss attained on (Xt , yt ). Formally, we would like to set ω t+1 to be the solution of the following
2 kω − ω tk2 + C ‘(ω ; (Xt , yt )), where C is a tradeoff parameter.
optimization problem, minω∈Rn
1
As we discuss below, this formalism effectively translates to a cap on the maximal change to ω t .
(cid:13)(cid:13)ω − ω t(cid:13)(cid:13)2 + C ξ s.t. ∀j ∈ [kt ] : y t
(cid:1) ≥ 1 − ξ , ξ ≥ 0 .
(cid:0)ω · xt
We rewrite the above optimization by introducing a single slack variable as follows:
1
min
(1)
ω∈Rn ,ξ≥0
2
j
j
We denote the objective function of Eq. (1) by P t and refer to it as the instantaneous primal problem
to be solved on trial t. The dual optimization problem of P t is the maximization problem
(cid:13)(cid:13)(cid:13)2
(cid:13)(cid:13)(cid:13)ω t +
ktX
ktX
ktX
j − 1
αt
2
j=1
j=1
j=1

j ≤ C , ∀j : αt
j ≥ 0 .
αt

max
1 ,..,αt
αt
kt

j xt
j y t
αt
j

s.t.

(2)

max
αt
j

(3)

j ∈ [0, C ] .
s.t. αt

primal problem is calculated from the optimal dual solution as follows, ω t+1 = ω t +Pkt
Each dual variable corresponds to a single constraint of the primal problem. The minimizer of the
j xt
j .
j y t
j=1 αt
Unfortunately, in the common case, where each xt
j is in an arbitrary orientation, there does not exist
an analytic solution for the dual problem (Eq. (2)). We tackle the problem by breaking it down
into kt reduced problems, each of which focuses on a single dual variable. Formally, for the j ’th
j 0 = 0 for all j 0 6= j . Each reduced
variable, the j ’th reduced problem solves Eq. (2) while ﬁxing αt
(cid:13)(cid:13)2
(cid:13)(cid:13)ω t + αt
optimization problem amounts to the following problem
j − 1
j xt
j y t
αt
2
j
P
We next obtain an exact or approximate solution for each reduced problem as if it were inde-
pendent of the rest. We then choose a distribution µt ∈ ∆kt , where ∆kt = {µ ∈ Rkt
:
j µj = 1, µj ≥ 0} is the probability simplex, and multiply each αt
j ≤ C implies that Pkt
j by the corresponding
j . Since µt ∈ ∆kt , this yields a feasible solution to the dual problem deﬁned in Eq.
(2) for
µt
Finally, the algorithm uses the combined solution and sets ω t+1 = ω t + Pkt
j ≤ C .
j ≥ 0 and the fact that αt
the following reason. Each µt
j αt
j=1 µt
j αt
j xt
j .
j y t
j αt
j=1 µt
Input:
We next present three schemes to obtain a solu-
tion for the reduced problem (Eq. (3)) and then
Aggressiveness parameter C > 0
combine the solution into a single update.
Initialize:
ω1 = (0, . . . , 0)
Simultaneous Perceptron: The simplest of the
For t = 1, 2, . . . , T :
update forms generalizes the famous Perceptron
Receive instance matrix X t ∈ Rkt×n
algorithm from [8] by setting αt
j to C if the j ’th
Predict ˆyt = Xt ω t
instance is incorrectly labeled, and to 0 otherwise.
Receive correct labels yt
We similarly set the weight µt
j to be
1|Mt | for
Suffer loss ‘ (ω t ; (Xt , yt ))
j ∈ Mt and to 0 otherwise. We abbreviate this
If ‘ > 0:
Choose importance weights µt ∈ ∆kt
scheme as the SimPerc algorithm.
Update ω t+1 = ω t + Pkt
Choose individual dual solutions αt
Soft Simultaneous Projections: The soft simul-
j
(cid:13)(cid:13)2 (cid:9). We
j )(cid:1) / (cid:13)(cid:13)xt
j = min (cid:8)C, ‘ (cid:0)ω t ; (xt
taneous projections scheme uses the fact that each
j xt
j y t
j=1 µt
j αt
j
reduced problem has an analytic solution, yield-
ing αt
j , y t
Figure 2: Simultaneous projections algorithm.
j
independently assign each αt
j this optimal solu-
j to be 1|Γt | for j ∈ Γt and to 0 otherwise. We would like to comment that this
tion. We next set µt
solution may update αt
j also for instances which were correctly classiﬁed as long as the margin they
attain is not sufﬁciently large. We abbreviate this scheme as the SimProj algorithm.
Conservative Simultaneous Projections: Combining ideas from both methods, the conservative
simultaneous projections scheme optimally sets αt
j according to the analytic solution. The difference
with the SimProj algorithm lies in the selection of µt . In the conservative scheme only the instances
which were incorrectly predicted (j ∈ Mt ) are assigned a positive weight. Put differently, µt
j is set
1|Mt | for j ∈ Mt and to 0 otherwise. We abbreviate this scheme as the ConProj algorithm.
to
To recap, on each trial t we obtain a feasible solution for the instantaneous dual given in Eq. (2).
j , according to a weight vector µt ∈ ∆kt . While
This solution combines independently calculated αt
this solution may not be optimal, it does constitutes an infrastructure for obtaining a mistake bound
and, as we demonstrate in Sec. 6, performs well in practice.

5 Analysis

The algorithms described in the previous section perform updates in order to increase the instanta-
neous dual problem deﬁned in Eq. (2). We now use the mistake bound model to derive an upper
bound on the number of trials on which the predictions of SimPerc and ConProj algorithms are
imperfect. Following [6], the ﬁrst step in the analysis is to tie the instantaneous dual problems to

2 kωk2 + C PT
a global loss function. To do so, we introduce a primal optimization problem deﬁned over the en-
tire sequence of examples as follows, minω∈Rn
t=1 ‘ (ω ; (X t , Y t )) . We rewrite the
1
TX
(cid:0)ω · xt
(cid:1) ≥ 1 − ξt ∀t : ξt ≥ 0. (4)
optimization problem as the following equivalent constrained optimization problem,
1
kωk2 + C
s.t. ∀t ∈ [T ], ∀j ∈ [kt ] : y t
min
ξt
ω∈Rn ,ξ∈RT
2
j
j
t=1
We denote the value of the objective function at (ω , ξ) for this optimization problem by P (ω , ξ).
A competitor who may see the entire sequence of examples in advance may in particular set (ω , ξ)
to be the minimizer of the problem which we denote by (ω? , ξ? ). Standard usage of Lagrange
(cid:13)(cid:13)(cid:13)2
(cid:13)(cid:13)(cid:13) TX
ktX
ktX
ktX
TX
multipliers yields that the dual of Eq. (4) is,
λt,j − 1
λt,j ≤ C ∀t, j : λt,j ≥ 0 .
s.t. ∀t :
max
j xt
(5)
λt,j y t
2
j
λ
t=0
t=1
j=1
j=1
j=1
We denote the value of the objective function of Eq. (5) by D(λ1 , · · · , λT ), where each λt is a
deﬁnes a feasible solution ω = PT
Pkt
vector in Rkt . Through our derivation we use the fact that any set of dual variables λ1 , · · · , λT
j xt
j with a corresponding assignment of the slack
j=1 λt,j y t
t=1
variables.
Clearly, the optimization problem given by Eq. (5) depends on all the examples from the ﬁrst trial
through time step T and thus can only be solved in hindsight. We note however, that if we ensure
that λs,j = 0 for all s > t then the dual function no longer depends on instances occurring on rounds
proceeding round t. As we show next, we use this primal-dual view to derive the skeleton algorithm
from Fig. 2 by ﬁnding a new feasible solution for the dual problem on every trial. Formally, the
instantaneous dual problem, given by Eq. (2), is equivalent (after omitting an additive constant) to
ktX
the following constrained optimization problem,
λj ≤ C .
D(λ1 , · · · , λt−1 , λ, 0, · · · , 0) s.t. λ ≥ 0 ,
max
(6)
λ
j=1
That is, the instantaneous dual problem is obtained from D(λ1 , · · · , λT ) by ﬁxing λ1 , . . . , λt−1
the prediction vector used on trial t is ω t = Pt−1
P
to the values set in previous rounds, forcing λt+1 through λT to the zero vectors, and choosing a
feasible vector for λt . Given the set of dual variables λ1 , . . . , λt−1 it is straightforward to show that
(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)ω t +
(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)2
j xs
j . Equipped with these relations and
j λs,j ys
s=1
ktX
ktX
ktX
omitting constants which do not depend on λt Eq. (6) can be rewritten as,
λj − 1
2
j=1
j=1
j=1
The problems deﬁned by Eq.
(7) and Eq.
(2) are equivalent. Thus, weighing the variables
by µt
also yields a feasible solution for the problem deﬁned in Eq. (6), namely
1 , . . . , αt
αt
1 , . . . , µt
kt
kt
Theorem 1. Let (cid:0)X1 , y1 (cid:1) , . . . , (cid:0)XT , yT (cid:1) be a sequence of examples where Xt is a matrix of kt
λt,j = µt
j . We now tie all of these observations together by using the weak-duality theorem. Our
j αt
ﬁrst bound is given for the SimPerc algorithm.
examples and yt are the associated labels. Assume that for all t and j the norm of an instance xt
is at most R. Then, for any ω? ∈ Rn the number of trials on which the prediction of SimPerc is
2 kω? k2 + C PT
j
imperfect is at most,
t=1 ‘ (ω? ; (Xt , yt ))
1
C − 1
2 C 2R2

s.t. ∀j : λj ≥ 0,

max
λ1 ,...,λkt

.

j xt
λj y t
j

λj ≤ C .

(7)

Proof. To prove the theorem we make use of the weak-duality theorem. Recall that any dual feasible
solution induces a value for the dual’s objective function which is upper bounded by the optimum
value of the primal problem, P (ω? , ξ? ). In particular, the solution obtained at the end of trial T
is dual feasible, and thus D(λ1 , . . . , λT ) ≤ P (ω? , ξ? ) . We now rewrite the left hand-side of the
TX
(cid:2)D(λ1 , . . . , λt , 0, . . . , 0) − D(λ1 , . . . , λt−1 , 0, . . . , 0)(cid:3) .
above equation as the following sum,
D(0, . . . , 0) +
t=1

(8)

+

(9)

+

.

.

.

∆t =

j xt
j y t
j αt
µt
j

objective values, D(λ1 , . . . , λt , 0, . . . , 0) − D(λ1 , . . . , λt−1 , 0, . . . , 0), we get that PT
Note that D(0, . . . , 0) equals 0. Therefore, denoting by ∆t the difference in two consecutive dual
t=1 ∆t ≤
P (ω? , ξ? ). We now turn to bounding ∆t from below. First, note that if the prediction on trial t is
perfect (Mt = ∅) then SimPerc sets λt to the zero vector and thus ∆t = 0. We can thus focus on
update of ω t we get that ω t = P
Pks
trials for which the algorithm’s prediction is imperfect. We remind the reader that by unraveling the
(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)2
(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)ω t +
j . We now rewrite ∆t as follows,
j xs
j=1 λs,j ys
ktX
ktX
(cid:13)(cid:13)ω t(cid:13)(cid:13)2
s<t
1
λt,j − 1
∆t =
j xt
λt,j y t
j and Pkt
.
2
2
j
j=1
j=1
(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)2
(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)ω t +
j = 1, which lets us further expand Eq. (9) and write,
By construction, λt,j = µt
j=1 µt
j αt
ktX
ktX
ktX
(cid:13)(cid:13)ω t(cid:13)(cid:13)2
1
j − 1
µt
j αt
µt
2
2
j
j=1
j=1
j=1
The squared norm, k·k2 is a convex function in its vector argument and thus ∆t is concave, which
(cid:20)
(cid:13)(cid:13)ω t(cid:13)(cid:13)2(cid:21)
∆t ≥ ktX
(cid:13)(cid:13)2 +
(cid:13)(cid:13)ω t + αt
yields the following lower bound on ∆t ,
j − 1
1
j xt
(10)
αt
µt
j y t
2
2
j
j
j=1
j to be 1/|Mt | for all j ∈ Mt and to be 0 otherwise. Furthermore,
The SimPerc algorithm sets µt
(cid:13)(cid:13)ω t(cid:13)(cid:13)2(cid:21)
(cid:20)
for all j ∈ Mt , αt
∆t ≥ X
(cid:13)(cid:13)ω t + C y t
(cid:13)(cid:13)2 +
j is set to C . Thus, the right hand-side of Eq. (10) can be further simpliﬁed and
written as,
1
C − 1
j xt
µt
2
2
j
j
(cid:20)
(cid:13)(cid:13)ω t(cid:13)(cid:13)2(cid:21)
j∈Mt
∆t ≥ X
(cid:13)(cid:13)ω t(cid:13)(cid:13)2 − C y t
(cid:13)(cid:13)2 +
2 C 2 (cid:13)(cid:13)y t
We expand the norm in the above equation and obtain that,
C − 1
1
j − 1
j ω t · xt
j xt
µt
2
2
j
j
j∈Mt
The set Mt consists of indices of instances which were incorrectly classiﬁed. Thus, y t
j (ω t · xt
j ) ≤ 0
(cid:20)
(cid:21)
(cid:13)(cid:13)2(cid:21)
(cid:20)
∆t ≥ X
≥ X
2 C 2 (cid:13)(cid:13)y t
for every j ∈ Mt . Therefore, ∆t can further be bounded from below as follows,
C − 1
= C − 1
C − 1
j xt
2 C 2R2
2 C 2R2 ,
j
j∈Mt
j∈Mt
where for the second inequality we used the fact that the norm of all the instances is bounded by
R. To recap, we have shown that on trials for which the prediction is imperfect ∆t ≥ C − 1
2 C 2R2 ,
while in perfect trials where no mistake is made ∆t = 0. Putting all the inequalities together we
(cid:19)
(cid:18)
 ≤ TX
obtain the following bound,
C − 1
∆t = D(λ1 , . . . , λT ) ≤ P (ω? , ξ? ) ,
(13)
2 C 2R2
C PT
t=1
rewriting P (ω? , ξ? ) as 1
2 kω? k2 +
where  is the number of imperfect
trials.
Finally,
t=1 ‘(ω? ; (Xt , yt ) yields the bound stated in the theorem.
The ConProj algorithm updates the same set of dual variables as the SimPerc algorithm, but selects
j to be the optimal solution of Eq. (3). Thus, the value of ∆t attained by the ConProj algorithm
αt
is never lower than the value attained by the SimPerc algorithm. The following corollary is a direct
consequence of this observation.
Corollary 1. Under the same conditions of Thm. 1 and for any ω? ∈ Rn , the number of trials on
2 kω? k2 + C PT
which the prediction of ConProj is imperfect is at most,
t=1 ‘ (ω? ; (Xt , yt ))
1
C − 1
2 C 2R2

.

(11)

.

µt
j

µt
j

(12)

username
beck-s
farmer-d
kaminski-v
kitchen-l
lokay-m
sanders-r
williams-w3

k
101
25
41
47
11
30
18

m
1973
3674
4479
4017
2491
1190
2771

SimProj ConProj
50.0
55.2
30.3
27.4
47.8
43.1
47.0
42.9
18.8
25.3
25.6
20.7
4.2
5.0

SimPerc Max-SP Max-MP Mira
55.9
56.6
63.8
63.7
31.8
28.6
30.0
30.7
47.3
49.6
49.5
47.0
52.6
54.9
48.0
49.0
25.3
23.0
25.4
25.3
34.1
36.3
23.8
23.2
5.4
4.2
5.8
5.9

Table 1: The percentage of online mistakes of the three variants compared to Max-Update (Single
prototype (SP) and Multi prototype (MP)) and the Mira algorithm. Experiments were performed on
seven users of the Enron data set.
Note that the predictions of the SimPerc algorithm do not depend on the speciﬁc value of C , thus
pkω? k4 + kω? k2 ‘ (ω? ; (Xt , yt )) .
‘ (cid:0)ω? ; (Xt , yt )(cid:1) +
for R = 1 and an optimal choice of C the bound attained in Thm. 1 now becomes.
1
1
kω? k2 +
2
2
We omit the proof for lack of space, see [6] for a closely related analysis.
We conclude this section with a few closing words about the SimProj variant. The SimPerc and
ConProj algorithms ensure a minimal increase in the dual by focusing solely on classiﬁcation errors
and ignoring margin errors. While this approach ensures a sufﬁcient increase of the dual, in practice
it appears to be a double edged sword as the SimProj algorithm performs empirically better. This
superior empirical performance can be motivated by a reﬁned derivation of the optimal choice for
µ. This derivation will be provided in a long version of this manuscript.

6 Experiments

In this section we describe experimental results in order to demonstrate some of the mer-
4
its of our algorithms. We tested performance of the three variants described in Sec.
on a multiclass categorization task and compared them to previously studied algorithms for
multiclass categorization. We compared our algorithms to the single-prototype and multi-
prototype Max-Update algorithms from [9] and to the Mira algorithm [2]. The experiments
were performed on the task of email classiﬁcation using the Enron email dataset (Available at
http://www.cs.cmu.edu/∼enron/enron_mail_030204.tar.gz). The learning goal was to correctly classify
email messages into user deﬁned folders. Thus, the instances in this dataset are email messages,
while the set of classes are the user deﬁned folders denoted by {1, . . . , k}. We ran the experiments
on the sequence of email messages from 7 different users.
Since each user employs different criteria for email classiﬁcation, we treated each person as a sep-
arate online learning problem. We represented each email message as a vector with a component
for every word in the corpus. On each trial, and for each class r , we constructed class-dependent
vectors as follows. We set φj (xt , r) to twice the number of time the j ’th word appeared in the
message if it had also appeared in a ﬁfth of the messages previously assigned to folder r . Similarly,
we set φj (xt , r) to minus the number of appearances of the word appeared if it had appeared in less
than 2 percent of previous messages. In all other cases, we set φj (xt , r) to 0. This class-dependent
construction is closely related to the construction given in [10]. Next, we employed the mapping
described in Sec. 3, and deﬁned a set of k − 1 instances for each message as follows. Denote the rel-
evant class by r , then for every irrelevant class s 6= r , we deﬁne an instance xt
s = φ(xt , r) − φ(xt , s)
and set its label to 1. All these instances were combined into a single matrix Xt and were provided
to the algorithm in trial t.
The results of the experiments are summarized in Table 1. It is apparent that the SimProj algo-
rithm outperforms all other algorithms. The performances of SimPerc and ConProj are comparable
with no obvious winner. It is worth noting that the Mira algorithm ﬁnds the optimum of a projec-
tion problem on each trial while our algorithms only ﬁnd an approximate solution. However, Mira
employs a different approach in which there is a single input instance (instead of the set Xt ) and
constructs multiple predictors (instead of a single vector ω ). Thus, Mira employs a larger hypothesis
space which is more difﬁcult to learn in online settings. In addition, by employing a single vector

Figure 3: The cumulative number of mistakes as a function of the number of trials.

representation of the email message, Mira cannot beneﬁt from feature selection which yields class-
dependent features. It is also obvious that the simultaneous projection variants, while remaining
simple to implement, consistently outperform the Max-Update technique which is commonly used
in online multiclass classiﬁcation. In Fig. 3 we plot the cumulative number of mistakes as a function
of the trial number for 3 of the 7 users. The graphs clearly indicate the high correlation between the
S imP erc and C onP roj variants, while indicating the superiority of the S imP roj variant.

7 Extensions and discussion
We presented a new approach for online categorization with complex output structure. Our algo-
global constraint on all the dual variables, namely P
rithms decouple the complex optimization task into multiple sub-tasks, each of which is simple
enough to be solved analytically. While the dual representation of the online problem imposes a
j ≤ C , our framework of simultaneous
j αt
with multiple constraints of the more general form P
projections which are followed by averaging the solutions automatically adheres with this constraint
and hence constitute a feasible solution. It is worthwhile noting that our approach can also cope
j νj αj ≤ C , where νj ≥ 0 for all j . The
box constraint implied for each individual projection problem distils to 0 ≤ αj ≤ C/νj and thus
the simultaneous projection algorithm can be used verbatim. We are currently exploring the usage
of this extension in complex decision problems with multiple structural constraints. Another pos-
sible extension is to replace the squared norm regularization with other twice differentiable penalty
functions. Algorithms of this more general framework still attain similar mistake bounds and are
easy to implement so long as the induced individual problems are efﬁciently solvable. A particu-
larly interesting case is obtained when setting the penalty to the relative entropy. In this case we
obtain a generalization of the Winnow and the EG algorithms [11, 12] for complex classiﬁcation
problems. Another interesting direction is the usage of simultaneous projections for problems with
more constrained structured output such as max-margin networks [3].

References
[1] J. Weston and C. Watkins. Support vector machines for multi-class pattern recognition. In Proc. of the Seventh European Symposium on
Artiﬁcial Neural Networks, April 1999.
[2] K. Crammer and Y. Singer. Ultraconservative online algorithms for multiclass problems. J. of Machine Learning Res., 3:951–991, 2003.
[3] B. Taskar, C. Guestrin, and D. Koller. Max-margin markov networks. In Advances in Neural Information Processing Systems 17, 2003.
I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun. Support vector machine learning for interdependent and structured output
[4]
spaces. In Proc. of the 21st Intl. Conference on Machine Learning, 2004.
[5] Yoav Freund and Robert E. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. Journal of
Computer and System Sciences, 55(1):119–139, August 1997.
[6] S. Shalev-Shwartz and Y. Singer. Online learning meets optimization in the dual. In Proc. of the Nineteenth Annual Conference on
Computational Learning Theory, 2006.
[7] R.E. Schapire and Y. Singer. BoosTexter: A boosting-based system for text categorization. Machine Learning, 32(2/3), 2000.
[8] F. Rosenblatt. The perceptron: A probabilistic model for information storage and organization in the brain. Psychological Review,
65:386–407, 1958. (Reprinted in Neurocomputing (MIT Press, 1988).).
[9] K. Crammer, O. Dekel, J. Keshet, S. Shalev-Shwartz, and Y. Singer. Online passive aggressive algorithms. Journal of Machine Learning
Research, 7, Mar 2006.
[10] M. Fink, S. Shalev-Shwartz, Y. Singer, and S. Ullman. Online multiclass learning by interclass hypothesis sharing. In Proc. of the 23rd
International Conference on Machine Learning, 2006.
[11] N. Littlestone. Learning when irrelevant attributes abound: A new linear-threshold algorithm. Machine Learning, 2:285–318, 1988.
Information and Computation,
[12] J. Kivinen and M. Warmuth. Exponentiated gradient versus gradient descent for linear predictors.
132(1):1–64, January 1997.

01000200030002004006008001000farmer−d  SimProjConProjSimPercMira0500100015002000100200300400500600lokay−m  0200400600800100050100150200250300350400sanders−r  