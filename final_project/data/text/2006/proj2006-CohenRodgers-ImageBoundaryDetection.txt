”Combination of Experts ” Approach to Image Boundary Detect

ion

David Cohen and Jim Rodgers
{dscohen,jimkr}@cs.stanford.edu

December 13, 2006

1 Introduction and Background

Boundary detection in two-dimensional images is an im-
portant problem in computer vision. There are a wide va-
riety of algorithms to accomplish this task, but none have
come close to human pro ﬁciency. We explore a variety of
ways to use machine learning algorithms to combine ex-
isting boundary detection algorithms with the goal of ex-
ceeding the performance of any particular algorithm. We
present methods using Adaboost and linear regression and
show favorable results produced by them.
Boundary detection is a classiﬁcation problem which
entails labeling a subset of pixels in an image as part of
an edge that separates two objects. However, there is
no clear de ﬁnition for which objects should be separated.
The most common approach is to attempt to ﬁnd a set of
edges which a human being would consider reasonable.
Nonetheless, for any given image, there may be disagree-
ment among human beings as to what set of edges best
captures the image. Additionally, while some boundary
detection algorithms impose hard boundaries, others in-
stead provide probabilities that each pixel in an image is
part of an edge.
Boundary detection, an active research area within the
artiﬁcial intelligence ﬁeld of computer vision, has a va-
riety of applications to higher-level vision tasks. Many
object-recognition algorithms use image boundaries as in-
puts. Furthermore, boundary detection algorithms help
show the precise orientation of an object in space, which
is useful for robotic manipulation tasks. This approach to
boundary detection is particularly interesting to us, since
we are working on an MRF-based image segmentation
algorithm that takes the output from a boundary detec-
tion algorithm as its input. Thus, this project could pro-

1

vide better inputs for image segmentation. Alternatively,
it may allow us to combine the image segmentation al-
gorithm’s boundary output with other boundary detection
algorithms’ outputs for even better results.

2 Methodology

Our goal is to predict which pixels in an image fall are
edges between objects in that image. Unfortunately, as
noted above, there is no clear de ﬁnition of an edge in an
image. Further, even when human beings agree on edges,
they often disagree on precisely which pixels in an im-
age correspond to them. To account for this, we use soft
boundary maps computed from the edges selected by a
number of human subjects as our ground truth. Similarly,
we use our algorithms to produce soft edge maps, which
we evaluate by applying various threshold values, thin-
ning wide edges, and measuring the quality of each of the
resulting thin hard edge maps. We evaluate these edge
maps using precision, recall, and f-score, where:

precision =
P (point is an edge in the ground truth image|
point is predicted as edge)

recall = P (point is predicted as edge|
point is an edge in the ground truth image)

(1)

(2)

f-score =

2 ∗ precision ∗ recall
precision + recall
Plotting precision and recall for each threshold value
produces a curve which characterizes an algorithm’s be-
havior, and the maximum f-score of the data points plotted

(3)

yields a single number which summarizes the algorithm’s
success.

3 Experts and Features

We combine the results of currently existing boundary de-
tection algorithms to produce our edge predictions. We
assemble a large number of boundary detection algo-
rithms and experiment with methods of combining them
to produce a single boundary map. Our set of boundary
detection algorithms currently includes six hard-threshold
classiﬁers which produce logical boundary maps, and
ﬁve probabilistic classiﬁers which produce soft boundary
maps, associating each pixel with the probability it is an
edge. Some of the soft edge maps are drawn from [1].
Five of the hard-threshold methods and all of the soft-
threshold methods approximate gradients in the image
and predict edges at points which correspond to local
maxima of the gradient. The two remaining detection
methods are a Laplacian of Gaussian algorithm which se-
lects points where the Laplacian of the image changes
its sign, and Felzenszwalb’s graph-based image segmen-
tation algorithm [2] which merges regions of an image
based on their variations in intensity. By varying the pa-
rameters of these algorithms, such as threshold values and
ﬁlter sizes, and by varying the image channel on which
these algorithms are run (red, green, blue, or grayscale),
we produce 91 different edge maps for each original im-
age. We call each parameterization of a boundary detector
on each image channel an expert.
In order to learn from our experts, we consider the
problem of classifying a single pixel as an edge or non-
edge point based on its treatment in the experts’ edge
maps. Since each expert produces one edge map per im-
age, it contributes exactly one feature for each pixel. We
experimented with three different methods for extract-
ing features from experts’ edge maps. Let fa (x, y , e)
be the feature extracted by algorithm a from expert e
for pixel (x, y ), and let Me be the edge map produced
by expert e.
In our ﬁrst feature extraction method, di-
rect extraction, fdirect(x, y , e) takes the value Me (x, y ).
For Euclidean distance extraction, fdist (x, y , e) has the
value of the Euclidean distance in Me between (x, y )
and the nearest edge pixel in the edge map.
In Gaus-
sian distance extraction, fgaussian (x, y , e) takes the value

exp(−fdist (x, y , e)2 /v) where v is the variance of our
Gaussian distribution. We experiment with several such
variances.
In constructing training sets, we vary the ratio of edge
pixels to non-edge pixels in our training set. We create
non-balanced training sets by randomly sampling pixels
from our training images, and we label a pixel as an edge
if it falls within a one pixel radius of any pixel with a
non-zero value in the ground truth edge map. These train-
ing sets are composed of approximately 200 edge pixels
and 800 non-edge pixels for each image. We also create
balanced data sets by sampling 500 edge pixels and 500
non-edge pixels from each image.

4 Learning algorithms

We explore several learning algorithms to combine the
predictions of our experts. The two most successful
of these was real-valued Adaboost, followed by least-
squares linear regression. Real-valued Adaboost is an it-
erative algorithm that converts features into classiﬁers b y
choosing the speciﬁc feature and threshold with maximal
performance on a weighted version of the training set. For
example, one such classiﬁer might be:
if feature k > threshold t
prediction = (cid:26) edge
non-edge otherwise
At each iteration, Adaboost reweights the training set to
increase the importance of data instances misclassiﬁed by
the newly chosen classiﬁer. The result of running Ad-
aboost for n iterations is a linear combination of n classi-
ﬁers, with coefﬁcients determined by the accuracy of each
classiﬁer on the weighted data set. This linear combina-
tion of classiﬁers is then applied to test data.
The other successful algorithm we ﬁnd is least-squares
linear regression, which ﬁnds the linear combination of
the features that minimizes the squared error of feature-
value predictions. Unlike Adaboost, which attempts to
directly classify data instances, linear regression estimates
an arbitrary real-valued function with a line through d-
dimensional space, where d is the number of features. We
use linear regression to estimate the same features in the
test data that we calculate in the training data: raw pixel
value, Euclidean distance, or Gaussian distance.

2

Original image

Ground truth

Adaboost result

Linear regression 
result

Figure 1: Sample results of running Adaboost and linear regression on the original image, and a comparison with the
human-generated ground truth.

5 Results

We train and test our algorithms on twenty images from
the training set and test set, respectively, provided by the
Berkeley Segmentation Dataset [4]. Figure 1 shows a
sample of our results on some of the images. We ﬁnd
that Adaboost performs the best of all the algorithms, both
visually and according to the f-score. When trained on
a balanced data set based on Gaussian distance features
with a standard deviation of 2 pixels, Adaboost achieved
an f-score of 0.67. We note that this exceeds the f-score of
our best expert by 0.04, but also that this particular expert
achieved that score when tested on a 100 image test set.
This indicates a small performance gain over the baseline.
We ﬁnd that the most signiﬁcant factor in our success
with Adaboost was the use of a balanced training set, ob-
serving that all of our experiments with different features

over balanced datasets scored at or above 0.60, and all
Adaboost runs with non-balanced training sets scored at
or below 0.56. We believe that this result arises from the
ratio of edge points to non-edge points, rather than the ab-
solute numbers of edge or non-edge points. As evidence,
we note that our f-score on a balanced Gaussian distance
dataset (with standard deviation of 4 pixels) only dropped
by 0.01 when we halved the number of training exam-
ples used. This highlights the distinction between our ob-
jective function, the accuracy, and our evaluation mecha-
nism, the f-score. The distinguishing characteristic of the
f-score is that it completely ignores true negatives: the
number of non-edge points correctly classiﬁed by an al-
gorithm does not affect its f-score, though misclassifying
non-edge points as edge-points does lower an algorithm’s
f-score. The f-score captures the intuition that edges are

3

more important than non-edges in an edge map, and ac-
counts for the fact that the number of edge points in an
image varies linearly with its scale, whereas the number
of non-edge points varies quadratically. Adaboost yields
similar accuracy on both types of training sets, but both
the f-scores and the visual appearance of the results on
non-balanced sets are inferior.

Least-squares linear regression produces results that
are not as good as those we obtain with Adaboost (see
Figure 2), but are nonetheless reasonable. The composi-
tion of the training set has little impact on the results. We
believe that this is consistent with the non-classiﬁcation
nature of linear regression. The idea of balancing the
training set between edges and non-edges is less meaning-
ful when dealing with an algorithm that does not attempt
to match edge/non-edge labels, but rather match the real-
valued feature that corresponds to any given ground truth
pixel. Linear regression performs similarly with Gaussian
distance and direct pixel values as features. It performs
very poorly with Euclidean distance as a feature, yield-
ing edge maps that predict edges almost everywhere. We
achieve the best results, 0.61, with Gaussian features and
standard deviation of 4 pixels. Figure 3 shows Precision-
Recall curves for Adaboost and linear regression using
different training sets and feature composition.

In addition to Adaboost and linear regression, we
explore support vector machines (SVMs) and locally
weighted linear regression. Neither produce acceptable
results. We train SVMs, using the SVMlight package [3],
on balanced and unbalanced data sets using pixel values
and Euclidean distance features and obtain very poor re-
call scores. Furthermore, we ﬁnd a large number of sup-
port vectors during SVM training, which hurts SVM per-
formance. Locally weighted linear regression yields no
obvious visual differences from standard linear regression
when run with a wide variety of bandwidth values, while
massively increasing runtime. Whereas standard linear
regression produces only one set of parameters, locally
weighted linear regression learns new parameters for ev-
ery pixel in the test set, and thus appears intractable in the
context of edge detection.

 

1

0.75

n
o
i
s
i
c
e
r
P

0.5

0.25

F=0.67 Adaboost, Gaussian dist, balanced set

F=0.60 Linear reg, Gaussian dist, balanced set

0

 
0

0.25

0.5
Recall

0.75

1

Figure 2: Precision and recall curves for best Adaboost
and linear regression results. Adaboost performs better
than linear regression

6 Conclusion and Future Work

We conclude that Adaboost is a suitable method for com-
bining expert predictions for the image boundary detec-
tion problem. Not only does it appear that our current
Adaboost classiﬁer may perform better than all of its com-
ponent experts (we have yet to con ﬁrm this by testing on
the full Berkeley test set), our ﬁndings also offer several
avenues for further improvement. First, we achieved a
large improvement by changing the composition of our
training set, but have not attempted to ﬁnd the optimal
training set edge to non-edge ratio. Further exploration
of training set composition may continue to improve our
results. Second, we found signiﬁcant f-score differences
based on the variance used for Gaussian distance features,
and would like to ﬁnd the optimal variance using cross-
validation. Furthermore, we currently optimize the accu-
racy and evaluate performance on the f-score, but boost-
ing may allow us to optimize the f-score directly, and thus
improve our results. Also, we wish to incorporate knowl-
edge of the softness of our ground truth edge maps by

4

1

0.75

n
o
i
s
i
c
e
r
P

0.5

0.25

F=0.67

F=0.61

F=0.64

F=0.61

 

1

 

1

 

1

 

1

F=0.59

 

0.75

n
o
i
s
i
c
e
r
P

0.5

0.25

0.75

n
o
i
s
i
c
e
r
P

0.5

0.25

0.75

n
o
i
s
i
c
e
r
P

0.5

0.25

0.75

n
o
i
s
i
c
e
r
P

0.5

0.25

F=0.67 @(0.66,0.67) t=0.97

F=0.61 @(0.58,0.65) t=0.97

F=0.64 @(0.83,0.51) t=0.97

F=0.61 @(0.69,0.55) t=0.68

F=0.59 @(0.66,0.53) t=0.29

0
 
0

0.25

0.5
Recall

0.75

1

0
 
0

0.25

0.5
Recall

0.75

1

0
 
0

0.25

0.5
Recall

0.75

1

0
 
0

0.25

0.5
Recall

0.75

1

0
 
0

0.25

0.5
Recall

0.75

1

(a) Adaboost, Gaussian dis-
tance, balanced set (F=0.67)

Euclidean
(b) Adaboost,
balanced
distance,
set
(F=0.61)

(c) Adaboost, direct pixel
value, balanced set (F=0.64)

(d) Linear regression, Gaus-
sian distance, balanced set
(F=0.61)

(e) Linear
regression, di-
rect pixel value, balanced set
(F=0.59)

1

0.75

n
o
i
s
i
c
e
r
P

0.5

0.25

F=0.56

F=0.45

F=0.50

F=0.60

 

1

 

1

 

1

 

1

F=0.59

 

0.75

n
o
i
s
i
c
e
r
P

0.5

0.25

0.75

n
o
i
s
i
c
e
r
P

0.5

0.25

0.75

n
o
i
s
i
c
e
r
P

0.5

0.25

0.75

n
o
i
s
i
c
e
r
P

0.5

0.25

F=0.56 @(0.62,0.50) t=0.49

F=0.45 @(0.64,0.34) t=0.16

F=0.50 @(0.40,0.69) t=0.03

F=0.60 @(0.68,0.53) t=0.39

F=0.59 @(0.67,0.52) t=0.09

0
 
0

0.25

0.5
Recall

0.75

1

0
 
0

0.25

0.5
Recall

0.75

1

0
 
0

0.25

0.5
Recall

0.75

1

0
 
0

0.25

0.5
Recall

0.75

1

0
 
0

0.25

0.5
Recall

0.75

1

Gaussian
(f) Adaboost,
distance,
unbalanced
set
(F=0.56)

Euclidean
(g) Adaboost,
distance,
unbalanced
set
(F=0.45)

(h) Adaboost, direct pixel
value,
unbalanced
set
(F=0.50)

(i) Linear regression, Gaus-
sian distance, unbalanced set
(F=0.60)

(j) Linear regression, direct
pixel value, unbalanced set
(F=0.59)

Figure 3: Precision-Recall curves and their maximum F-score for different combinations of features and training set
composition. Best performance is with Adaboost, Gaussian distance, and a balanced training set.

weighting edge pixels by their ground truth pixel values,
and thus force our algorithm to favor correct predictions
on the stronger edges. Finally, we wish to gather more ex-
perts for use in Adaboost and explore more methods for
extracting features. Adding more experts and features, es-
pecially ones signiﬁcantly different from those currently
used, may improve the resulting edge maps.

7 Acknowledgements

Thanks to Steve Gould, Gal Elidan, and Ben Packer for
providing helpful feedback and suggestions.

References

[1] D.Martin, C. Fowlkes, and J. Malik. Learning to de-
tect natural image boundaries using local brightness,
color, and texture cues.
IEEE Transactions on Pat-

tern Analysis and Machine Intelligence, 26(5):530 –
549, 2004.

[2] P. Felzenszwalb and D. Huttenlocher. Efﬁcient graph-
based image segmentation. International Journal of
Computer Vision, 59(2), 2004.

[3] T. Joachims. Making large-scale support vector ma-
chine learning practical. In A. Smola B. Sch ¨olkopf,
C. Burges, editor, Advances in Kernel Methods: Sup-
port Vector Machines. MIT Press, Cambridge, MA,
1998.

[4] D. Martin, C. Fowlkes, D. Tal, and J. Malik. A
database of human segmented natural images and
its application to evaluating segmentation algorithms
and measuring ecological statistics. In Proc. 8th Int’l
Conf. Computer Vision, volume 2, pages 416 –423,
July 2001.

5

