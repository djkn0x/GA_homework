A Theory of Retinal Population Coding

Eizaburo Doi
Center for the Neural Basis of Cognition
Carnegie Mellon University
Pittsburgh, PA 15213
edoi@cnbc.cmu.edu

Michael S. Lewicki
Center for the Neural Basis of Cognition
Carnegie Mellon University
Pittsburgh, PA 15213
lewicki@cnbc.cmu.edu

Abstract

Efﬁcient coding models predict that the optimal code for natural images is a popu-
lation of oriented Gabor receptive ﬁelds. These results match response properties
of neurons in primary visual cortex, but not those in the retina. Does the retina
use an optimal code, and if so, what is it optimized for? Previous theories of
retinal coding have assumed that the goal is to encode the maximal amount of
information about the sensory signal. However, the image sampled by retinal
photoreceptors is degraded both by the optics of the eye and by the photoreceptor
noise. Therefore, de-blurring and de-noising of the retinal signal should be impor-
tant aspects of retinal coding. Furthermore, the ideal retinal code should be robust
to neural noise and make optimal use of all available neurons. Here we present
a theoretical framework to derive codes that simultaneously satisfy all of these
desiderata. When optimized for natural images, the model yields ﬁlters that show
strong similarities to retinal ganglion cell (RGC) receptive ﬁelds. Importantly, the
characteristics of receptive ﬁelds vary with retinal eccentricities where the optical
blur and the number of RGCs are signiﬁcantly different. The proposed model pro-
vides a uniﬁed account of retinal coding, and more generally, it may be viewed as
an extension of the Wiener ﬁlter with an arbitrary number of noisy units.

1 Introduction

What are the computational goals of the retina? The retina has numerous specialized classes of
retinal ganglion cells (RGCs) that are likely to subserve a variety of different tasks [1]. An important
class directly subserving visual perception is the midget RGCs (mRGCs) which constitute 70% of
RGCs with an even greater proportion at the fovea [1]. The problem that mRGCs face should be
to maximally preserve signal information in spite of the limited representational capacity, which
is imposed both by neural noise and the population size. This problem was recently addressed
(although not speciﬁcally as a model of mRGCs) in [2], which derived the theoretically optimal
linear coding method for a noisy neural population. This model is not appropriate, however, for
the mRGCs, because it does not take into account the noise in the retinal image (Fig. 1). Before
being projected on the retina, the visual stimulus is distorted by the optics of the eye in a manner
that depends on eccentricity [3]. This retinal image is then sampled by cone photoreceptors whose
sampling density also varies with eccentricity [1]. Finally, the sampled image is noisier in the
dimmer illumination condition [4]. We conjecture that the computational goal of mRGCs is to
represent the maximum amount of information about the underlying, non-degraded image signal
subject to limited coding precision and neural population size.
Here we propose a theoretical model that achieves this goal. This may be viewed as a generalization
of both Wiener ﬁltering [5] and robust coding [2]. One signiﬁcant characteristic of the proposed
model is that it can make optimal use of an arbitrary number of neurons in order to preserve the
maximum amount of signal information. This allows the model to predict theoretically optimal
representations at any retinal eccentricity in contrast to the earlier studies [4, 6, 7, 8].

Figure 1: Simulation of retinal images at different retinal eccentricities.
(a) Undistorted image
signal. (b) The convolution kernel at the fovea [3] superimposed on the photoreceptor array indicated
by triangles under the x-axis [1]. (c) The same as in (b) but at 40 degrees of retinal eccentricity.

2 The model

First let us deﬁne the problem (Fig. 2). We assume that data sampled by photoreceptors (referred
to as the observation) x ∈ RN are blurred versions of the underlying image signal s ∈ RN with
additive white noise ν ∼ N (0, σ2
ν IN ),

x = Hs + ν
(1)
where H ∈ RN ×N implements the optical blur. To encode the image, we assume that the obser-
vation is linearly transformed into an M -dimensional representation. To model limited neural pre-
cision, it is assumed that the representation is subject to additive channel noise, δ ∼ N (0, σ2
δ IM ).
The noisy neural representation is therefore expressed as
r = W(Hs + ν ) + δ
(2)
where each row of W ∈ RM ×N corresponds to a receptive ﬁeld. To evaluate the amount of signal
information preserved in the representation, we consider a linear reconstruciton ˆs = Ar where
A ∈ RN ×M . The residual is given by
 = (IN − AWH)s − AWν − Aδ ,
where IN is the N -dimensional identity matrix, and the mean squared error (MSE) is
E = tr[Σs ] − 2 tr[AWHΣs ] + tr[AW(HΣsHT + σ2
ν IN )WT AT ] + σ2
δ tr[AAT ]
(4)
with E = trhT i by deﬁnition, h·i the average over samples, and Σs the covariance matrix of the
image signal s. The problem is to ﬁnd W and A that minimize E .
To model limited neural capacity, the representation r must have limited SNR. This constraint is
equivalent to ﬁxing the variance of ﬁlter output hwT
j xi = σ2
u , where wj is the j -th row of W (here
we assume all neurons have the same capacity). It is expressed in the matrix form as
diag[WΣxWT ] = σ2
u1M
(5)
where Σx = HΣsHT + σ2
ν IN is the covariance of the observation. It can further be simpliﬁed to
diag[VVT ] = 1M ,
(6)
W = σuVS−1
x ET ,
(7)

(3)

Figure 2: The model diagram. If there is no degradation of the image (H = I and σ2
ν = 0), the
δ = 0),
model is reduced to the original robust coding model [2]. If channel noise is zero as well (σ2
it boils down to conventional block coding such as PCA, ICA, or wavelet transforms.

Visual angle [arc min]Intensity04-404-4(b) Fovearetinal image(c) 40 degrees eccentricity(a) Undistorted imagesensory noisechannel noiseobservationreconstructionencoderdecoderoptical blurrepresentationimageνδHsˆsAxWrν , · · · , pαN λN + σ2
where Sx = diag(pα1λ1 + σ2
√
ν ) (the square root of Σx ’s eigenvalues),
αk
√
and λk are respectively the eigenvalues of H and Σs , and the columns of E are their common
eigenvectors1 . Note that
αk deﬁnes the modulation transfer function of the optical blur H, i.e., the
attenuation of the amplitude of the signal along the k-th eigenvector.
Now, the problem is to ﬁnd V and A that minimize E . The optimal A should satisfy ∂ E /∂A = O,
which yields

(8)

δ IM ]−1
A = ΣsHT WT [W(HΣsHT + σ2
ν IN )WT + σ2
= γ 2
ESsP[IN + γ 2VT V]−1VT
σu
√
√
√
√
φ1 , · · · ,
λ1 , · · · ,
φN ), and
λN ), P = diag(
δ (neural SNR), Ss = diag(
where γ 2 = σ2
u /σ2
φk = αk λk /(αk λk + σ2
ν ) (the power ratio between the attenuated signal and that signal plus sensory
noise; as we will see below, φk characterizes the generalized solutions of robust coding, and if there
is neither sensory noise nor optical blur, φk becomes 1 that reduces the solutions of the current model
to those in the original robust coding model [2]). This implies that the optimal A is determined once
the optimal V is found.
With eqn. 7 and 9, E becomes
NX
k=1
Finally, the problem is reduced to ﬁnding V that minimizes eqn. 10.

2P2 (IN + γ 2VT V)−1 ].

λk (1 − φk ) + tr[Ss

E =

(10)

(9)

Solutions for 2-D data

(11)

In this section we present the explicit characterization of the optimal solutions for two-dimensional
data. It entails under-complete, complete, and over-complete representations, and provides precise
insights into the numerical solutions for the high-dimensional image data (Section 3). This is a
generalization of the analysis in [2] with the addition of optical blur and additive sensory noise.
 cos θ1

From eqn. 6 we can parameterize V with
sin θ1
...
...
V =
cos θM sin θM
(ψ1 + ψ2 ) (cid:0) M
2 γ 2 + 1(cid:1) − γ 2
where θj ∈ [0, 2π), j = 1, · · · , M , which yields
2X
(cid:0) M
2 γ 2 + 1(cid:1)2 − 1
2 (ψ1 − ψ2 ) Re(Z )
λk (1 − φk ) +
E =
with ψk ≡ φk λk and Z ≡ P
4 γ 4 |Z |2
k=1
j (cos 2θj + i sin 2θj ). In the following we analyze the cases when
ψ1 = ψ2 and when ψ1 6= ψ2 . Without loss of generality we consider ψ1 > ψ2 for the latter case. (In
the previous analysis of robust coding [2], these cases depend only on the ratio between λ1 and λ2 ,
i.e., the isotropy of the data. In the current, general model, these also depend on the isotropy of the
optical blur (α1 and α2 ) and the variance of sensory noise (σ2
ν ), and no simple meaning is attatched
to the individual cases.)
2 γ 2 + 1(cid:1)
2ψ (cid:0) M
1). If ψ1 = ψ2 (≡ ψ): E in eqn. 10 becomes
2X
2 γ 2 + 1(cid:1)2 − 1
(cid:0) M
4 γ 4 |Z |2
k=1
Therefore, E is minimized when |Z |2 is minimized.
1The eigenvectors of Σs and H are both Fourier basis functions because we assume that s are natural images
[9] and H is a circulant matrix [10].

λk (1 − φk ) +

E =

(12)

(13)

,

.

ET .

(16)

(14)

(15)

W = σu ( cos θ1

sin θ1 )

(cid:20)
(cid:21)
(cid:20)
(cid:21)
1-a). If M = 1 (single neuron case): By deﬁnition |Z |2 = 1, implying that E is constant for any θ1 ,
(cid:18) 1/pα1λ1 + σ2
(cid:19)
λ1 (1 − φ1 ) + ψ1
E =
λ2 (1 − φ2 ) + ψ2
+ λ1 ,
+ λ2 =
1/pα2λ2 + σ2
γ 2 + 1
γ 2 + 1
0
ν
0
ν
Because there is only one neuron, only one direction in the two dimensional space can be recon-
structed, and eqn. 15 implies that any direction can be equally good. The ﬁrst equality in eqn. 14
can be interpreted as the case when W represents the direction along the ﬁrst eigenvector, and
consequently, the whole data variance along the second eigenvector λ2 is left in the error E .
1-b). If M ≥ 2 (multiple neuron case): There always exists Z that satisﬁes |Z | = 0 if M ≥ 2, with
"
#
2X
which E is minimized [2]. Accordingly,
E =
λk (1 − φk ) +
ψk
(cid:18) 1/pα1λ1 + σ2
(cid:19)
,
2 γ 2 + 1
M
1/pα2λ2 + σ2
k=1
0
W = σuV
ET ,
(17)
ν
0
ν
where V is arbitrary as long as it satisﬁes |Z | = 0. Note that W takes the same form as in M = 1
except that there are more than two neurons. Also, eqn.16 shares the second term with eqn. 14
except that the SNR of the representation γ 2 is multiplied by M /2. It implies that having n times the
neurons is equivalent to increasing the representation SNR by the factor of n (this relation generally
holds in the multiple neuron cases below).
2). If ψ1 > ψ2 : Eqn. 12 is minimized when Z = Re(Z ) ≥ 0 for a ﬁxed value of |Z |2 . Therefore,
(ψ1 + ψ2 ) (cid:0) M
2 γ 2 + 1(cid:1) − γ 2
the problem is reduced to seeking a real value Z = y ∈ [0, M ] that minimizes
2X
2 γ 2 + 1(cid:1)2 − 1
(cid:0) M
2 (ψ1 − ψ2 ) y
λk (1 − φk ) +
E =
4 γ 4 y2
k=1
(cid:20)
(cid:21)
2-a). If M = 1 (single neuron case): Z = Re(Z ) holds iff θ1 = 0. Accordingly,
λ1 (1 − φ1 ) + ψ1
E =
σupα1λ1 + σ2
γ 2 + 1
eT
1 .
ν
These take the same form as in the case of ψ1 = ψ2 and M = 1 (eqn. 14-15) except that the direction
of the representation is speciﬁed along the ﬁrst eigenvector e1 , indicating that all the representational
resources (namely, one neuron) are devoted to the largest data variance direction.
2-b). If M ≥ 2 (multiple neuron case): From eqn. 18, the necessary condition for the minimun
(cid:21)
(cid:19)
(cid:18)
(cid:21)(cid:20) √
(cid:19)
(cid:18)
(cid:20) √
dE /dy = 0 yields
√
ψ1 − √
2
ψ1 +
2
√
√
√
ψ1 − √
ψ2
ψ2
ψ1 +
γ 2
γ 2
ψ2
ψ2
"s
#
The existence of a root y in the domain [0, M ] depends on how γ 2 compares to the next quantity,
which is a generalized form of the critical point of neural precision [2]:
− 1

1
ψ1
c =
γ 2
M
ψ2
c : dE /dy = 0 does not have a root within the domain. Since dE /dy is always
(cid:20)
(cid:21)
2-b-i). If γ 2 < γ 2
negative, E is minimized when y = M . Accordingly,
E =
λ1 (1 − φ1 ) +
σupα1λ1 + σ2
ν

ψ1
M γ 2 + 1
1M eT
1 .

(19)

(20)

(23)

(24)

− y

= 0.

M +

− y

.

(18)

(21)

(22)

W =

W =

+ λ2 ,

M +

.

+ λ2 ,

,

These solutions are the same as in M = 1 (eqn. 19-20) except that the neural SNR γ 2 is multiplied
by M to yield smaller MSE.
(cid:19)
(cid:18) 2
2-b-ii). If γ 2 ≥ γ 2
c : Eqn. 21 has a root within [0, M ],
ψ1 − √
√
√
√
ψ2
y =
γ 2 + M
ψ1 +
ψ2
2X
with y = M if γ 2 = γ 2
c . The optimal solutions are
√
√
ψ2 )2
ψ1 +
(
1
E =
λk (1 − φk ) +
(cid:18) 1/pα1λ1 + σ2
(cid:19)
,
2
2 γ 2 + 1
M
1/pα2λ2 + σ2
k=1
0
ν
0
ν
where V is arbitrary up to satisfying eqn. 25.
In Fig. 3 we illustrate some examples of explicit solutions for 2-D data with two neurons. The gen-
eral strategy of the proposed model is to represent the principal axis of the signal s more accurately
as the signal is more degraded (by optical blur and/or sensory noise). Speciﬁcally, the two neurons
come to represent the identical dimension when the degradation is sufﬁciently large.

W = σuV

(25)

(26)

(27)

ET ,

Figure 3: Sensory noise changes the optimal linear ﬁlter. The gray (outside) and blue (inside)
contours show the variance of the target and reconstructed signal, respectively, and the red (thick)
bars the optimal linear ﬁlters when there are two neurons. The SNR of the observation is varied
from 20 to −10 dB (column-wise). The bottom row is the case where the power of the signal’s
minor component is attenuated as in the optical blur (i.e., low pass ﬁltering): (α1 , α2 ) = (1, 0.1);
while the top is without the blur: (α1 , α2 ) = (1, 1). The neural SNR is ﬁxed at 10 dB.

3 Optimal receptive ﬁeld populations

We applied the proposed model to a natural images data set [11] to obtain the theoretically optimal
population coding for mRGCs. The optimal solutions were derived under the following biological
constraints on the observation, or the photoreceptor response, x (Fig. 2). To model the retinal images
at different retinal eccentricities, we used modulation transfer functions of the human eye [3] and
cone photoreceptor densities of the human retina [1] (Fig. 1). The retinal image is further corrupted
by the additive Gaussian noise to model the photon transduction noise by which the SNR of the
observartion becomes smaller under dimmer illumination level [4]. This yields the observation
at different retinal eccentricities. In the following, we present the optimal solutions for the fovea
(where the most accurate visual information is represented while the receptive ﬁeld characteristics
are difﬁcult to measure experimentally) and those at 40 degrees retinal eccentricity (where we can
compare the model to recent physiological measurements in the primate retina [12]).

20dB10dB0dB-10dBno-blurblurThe information capacity of neural representations is limited by both the number of neurons and the
precision of neural codes. The ratio of cone photoreceptors to mRGCs in the human retina is 1 : 2
at the fovea and 23 : 2 at 40 degrees [13]. We did not model neural rectiﬁcation (separate on and off
channels) and thus assumed the effective cell ratios as 1 : 1 and 23 : 1, respectively. We also ﬁxed
the neural SNR at 10 dB, equivalent to assuming ∼ 1.7 bits coding precision as in real neurons [14].
The optimal W can be derived with the gradient descent on E , and A can be derived from W using
 
!
eqn. 8. As explained in Section 2, the solution must satisfy the variance constraint (eqn. 6). We
formulate this as a constrained optimization problem [15]. The update rule for W is given by
ln[diag(WΣxWT )/σ2
u ]
∆W ∝ −AT (AWH − IN )ΣsHT − σ2
ν AT AW − κ diag
diag(WΣxWT )
where κ is a positive constant that controls the strength of the variance constraint. Our initial results
a receptive ﬁeld: the constraint for the k-th neuron is deﬁned by P
indicated that the optimal solutions are not unique and these solutions are equivalent in terms of
MSE. We then imposed an additional neural resource constraint that penalizes the spatial extent of
j |Wkj |(ρ d 2
kj + 1) where dkj
is the spatial distance between the j -th weight and the center of mass of all weights, and ρ is a
positive constant deﬁning the strength of the spatial constraint. This assumption is consistent with
the spatially restricted computation in the retina. If ρ = 0, it imposes sparse weights [16], though
not necessarily spatially localized. In our simulations we ﬁxed ρ = 0.5.
For the fovea, we examined 15×15 pixel image patches sampled from a large set of natural im-
ages, where each pixel corresponds to a cone photoreceptor. Since the cell ratio is assumed to be
1 : 1, there were 225 model neurons in the population. As shown in Fig. 4, the optimal ﬁlters
show concentric center-surround organization that is well ﬁt with a difference-of-Gaussian function
(which is one major characteristic of mRGCs). The precise organization of the model receptive ﬁeld
changes according to the SNR of the observation: as the SNR decreases, the surround inhibition
gradually disappears and the center becomes larger, which serves to remove sensory noise by aver-
aging. As a population, this yields a signiﬁcant overlap among adjacent receptive ﬁelds. In terms of
spatial-frequency, this change corresponds to a shift from band-pass to low-pass ﬁltering, which is
consistent with psychophysical measurements of the human and the macaque [17].

WΣx , (28)

Figure 4: The model receptive ﬁelds at the fovea under different SNRs of the observation. (a) A
cross-section of the two-dimensional receptive ﬁeld. (b) Six examples of receptive ﬁelds. (c) The
tiling of a population of receptive ﬁelds in the visual ﬁeld. The ellipses show the contour of receptive
ﬁelds at half the maximum. One pair of adjacent ﬁlters are highlighted for clarity. The scale bar
indicates an interval of three photoreceptors.
(d) Spatial-frequency proﬁles (modulation transfer
functions) of the receptive ﬁelds at different SNRs.
For 40 degrees retinal eccentricity, we examined 35×35 photoreceptor array that are projected to
53 model neurons (so that the cell ratio is 23 : 1). The general trend of the results is the same as
in the fovea except that the receptive ﬁelds are much larger. This allows the fewer neurons in the
population to completely tile the visual ﬁeld. Furthermore, the change of the receptive ﬁeld with the
sensory noise level is not as signiﬁcant as that predicted for the fovea, suggesting that the SNR is a

Spatial freq.Magnitude20dB20dB10dB0dB-10dB-10dB(a)(d)(b)(c)less signiﬁcant factor when neural number is severely limited. We also note that the elliptical shape
of the extent of the receptive ﬁelds matches experimental observations [12].

Figure 5: The theoretically-derived receptive ﬁelds for 40 degrees of the retinal eccentricity. Cap-
tions as in Fig. 4.

Finally, we demonstrate the performance of de-blurring, de-noising, and information preservation
by these receptive ﬁelds (Fig. 6). The original image is well recovered in spite of both the noisy
representation (10% of the code’s variation is noise because of the 10 dB precision) and the noisy,
degraded observation. Note that the 40 degrees eccentricity is subject to an additional, signiﬁcant
dimensionality reduction, which is why the reconstruction error (e.g., 34.8% at 20 dB) can be greater
than the distortion in the observation (30.5%).

Figure 6: Reconstruction example. For both the fovea and 40 degrees retinal eccentricity, two
sensory noise conditions are shown (20 and −10 dB). The percentages indicate the average distortion
in the observation or the reconstruction error, respectively, over 60,000 samples. The blocking effect
is caused by the implementation of the optical blur on each image patch using a matrix H instead of
convolving the whole image.

4 Discussion

The proposed model is a generalization of the robust coding model [2] and allows a complete char-
acterization of the optimal representation as a function of both image degradation (optical blur and
additive sensory noise) and limited neural capacity (neural precision and population size). If there
ν = 0 and no optical blur H = IN , then φk = 1 for all k , which reduces all the
is no sensory noise σ2
optimal solutions above to those reported in [2].
The proposed model may also be viewed as a generalization of the Wiener ﬁlter:
if there is no
δ = 0 and the cell ratio is 1 : 1, and by assuming A ≡ IN without loss of generality,
channel noise σ2
the problem is reformulated as ﬁnding W ∈ RN ×N that provides the best estimate of the original
(cid:21)
(cid:20) √
signal ˆs = W(Hs + ν ) in terms of the MSE. The optimal solution is given by the Wiener ﬁlter:
√
, · · · ,
αN λN
α1λ1
ν IN ]−1 = E diag
W = ΣsHT [HΣsHT + σ2
αN λN + σ2
α1λ1 + σ2
ν
ν

ET , (29)

20dB-10dBoriginalfovea20 dB-10 dB20 dB-10 dBobservationreconstruction40 deg.1024.7% 30.5% 25.7% 1029.5% 34.8% 57.5% 10.1% 53.5% E = tr[Σs ] − tr[WHΣs ] = PN
k=1 λk (1 − φk ),
(30)
(note that the diagonal matrix in eqn. 29 corresponds to the Wiener ﬁlter formula in the frequency
domain [5]). This also implies that the Wiener ﬁlter is optimal only in the limiting case in our setting.
Here, we have treated the model primarily as a theory of retinal coding, but its generality would
allow it to be applied to a wide range of problems in signal processing. We should also note several
limitations. The model assumes Gaussian signal structure. Modeling non-Gaussian signal distribu-
tions might account for coding efﬁciency constraints on the retinal population. The model is linear,
but the framework allows for the incorporation of non-linear encoding and decoding methods, at the
expense of analytic tractability.
There have been earlier approaches to theoretically characterizing the retinal code [4, 6, 7, 8]. Our
approach differs from these in several respects. First, it is not restricted to the so-called complete
representation (M = N ) and can predict properties of mRGCs at any retinal eccentricity. Second,
we do not assume a single, translation invariant ﬁlter and can derive the optimal receptive ﬁelds
for a neural population. Third, we accurately model optical blur, retinal sampling, cell ratio, and
neural precision. Finally, we assumed that, as in [4, 8], the objective of the retinal coding is to
form the neural code that yields the minimum MSE with linear decoding, while others assumed it
to form the neural code that maximally preserves information about signal [6, 7]. To the best of our
knowledge, we don’t know a priori which objective should be appropriate for the retinal coding. As
suggested earlier [8], this issue could be resolved by comparing different theoretical predictions to
physiological data.

References
[1] R. W. Rodieck. The First Steps in Seeing. Sinauer, MA, 1998.
[2] E. Doi, D. C. Balcan, and M. S. Lewicki. A theoretical analysis of robust coding over noisy overcomplete
channels. In Advances in Neural Information Processing Systems, volume 18. MIT Press, 2006.
[3] R. Navarro, P. Artal, and D. R. Williams. Modulation transfer of the human eye as a function of retinal
eccentricity. Journal of Optical Society of America A, 10:201–212, 1993.
[4] M. V. Srinivasan, S. B. Laughlin, and A. Dubs. Predictive coding: a fresh view of inhibition in the retina.
Proc. R. Soc. Lond. B, 216:427–459, 1982.
[5] R. C. Gonzalez and R. E. Woods. Digital image processing. Prentice Hall, 2nd edition, 2002.
[6] J. J. Atick and A. N. Redlich. Towards a theory of early visual processing. Neural Computation, 2:308–
320, 1990.
[7] J. H. van Hateren. Theoretical predictions of spatiotemporal receptive ﬁelds of ﬂy LMCs, and experimen-
tal validation. J. Comp. Physiol. A, 171:157–170, 1992.
[8] D. L. Ruderman. Designing receptive ﬁelds for highest ﬁdelity. Network, 5:147–155, 1994.
[9] D. J. Field. Relations between the statistics of natural images and the response properties of cortical cells.
J. Opt. Soc. Am. A, 4:2379–2394, 1987.
[10] R. M. Gray. Toeplitz and circulant matrices: A review. Foundations and Trends in Communications and
Information Theory, 2:155–239, 2006.
[11] E. Doi, T. Inui, T.-W. Lee, T. Wachtler, and T. J. Sejnowski. Spatiochromatic receptive ﬁeld properties
derived from information-theoretic analyses of cone mosaic responses to natural scenes. Neural Compu-
tation, 15:397–417, 2003.
[12] E. S. Frechette, A. Sher, M. I. Grivich, D. Petrusca, A. M. Litke, and E. J. Chichilnisky. Fidelity of the
ensemble code for visual motion in primate retina. Journal of Neurophysiology, 94:119–135, 2005.
[13] C. A. Curcio and K. A. Allen. Topography of ganglion cells in human retina. Journal of Comparative
Neurology, 300:5–25, 1990.
[14] A. Borst and F. E. Theunissen. Information theory and neural coding. Nature Neuroscience, 2:947–957,
1999.
[15] E. Doi and M. S. Lewicki. Sparse coding of natural images using an overcomplete set of limited capacity
units. In Advances in Neural Information Processing Systems, volume 17. MIT Press, 2005.
[16] B. T. Vincent and R. J. Baddeley. Synaptic energy efﬁciency in retinal processing. Vision Research,
43:1283–1290, 2003.
[17] R. L. De Valois, H. Morgan, and D. M. Snodderly. Psychophysical studies of monkey vision - III. Spatial
luminance contrast sensitivity test of macaque and human observers. Vision Research, 14:75–81, 1974.

