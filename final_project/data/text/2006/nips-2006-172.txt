Logistic Regression for Single Trial EEG
Classiﬁcation

Kazuyuki Aihara†
Ryota Tomioka∗
Dept. of Mathematical Informatics,
IST, The University of Tokyo,
113-8656 Tokyo, Japan.
ryotat@first.fhg.de
aihara@sat.t.u-tokyo.ac.jp

Klaus-Robert M¨uller∗
Dept. of Computer Science,
Technical University of Berlin,
Franklinstr. 28/29,
10587 Berlin, Germany.
klaus@first.fhg.de

Abstract

We propose a novel framework for the classiﬁcation of single trial ElectroEn-
cephaloGraphy (EEG), based on regularized logistic regression. Framed in
this robust statistical framework no prior feature extraction or outlier re-
moval is required. We present two variations of parameterizing the regres-
sion function: (a) with a full rank symmetric matrix coeﬃcient and (b) as a
diﬀerence of two rank=1 matrices. In the ﬁrst case, the problem is convex
and the logistic regression is optimal under a generative model. The latter
case is shown to be related to the Common Spatial Pattern (CSP) algo-
rithm, which is a popular technique in Brain Computer Interfacing. The
regression coeﬃcients can also be topographically mapped onto the scalp
similarly to CSP pro jections, which allows neuro-physiological interpreta-
tion. Simulations on 162 BCI datasets demonstrate that classiﬁcation ac-
curacy and robustness compares favorably against conventional CSP based
classiﬁers.

1 Introduction

The goal of Brain-Computer Interface (BCI) research [1, 2, 3, 4, 5, 6, 7] is to provide a
direct control pathway from human intentions reﬂected in brain signals to computers. Such
a system will not only provide disabled people more direct and natural control over a neuro-
prosthesis or over a computer application (e.g. [2]) but also opens up a further channel of
man machine interaction for healthy people to communicate solely by their intentions.
Machine learning approaches to BCI have proven to be eﬀective by requiring less sub ject
training and by compensating for the high inter-sub ject variability. In this ﬁeld, a number
of studies have focused on constructing better low dimensional representations that combine
various features of brain activities [3, 4], because the problem of classifying EEG signals is
intrinsically high dimensional. In particular, eﬀorts have been made to reduce the number
of electrodes by eliminating electrodes recursively [8] or by decomposition techniques e.g.,
ICA, which only uses the marginal distribution, or Common Spatial Patterns (CSP) [9]
which additionally takes the labels into account. In practice, often a BCI system has been
constructed by combining a feature extraction step and a classiﬁcation step.
Our contribution is a logistic regression classiﬁer that integrates both steps under the roof
of a single minimization problem and uses well controlled regularization. Moreover, the
classiﬁer output has a probabilistic interpretation. We study a BCI based on the motor
∗Fraunhofer FIRST.IDA, Kekul´estr. 7, 12489 Berlin, Germany.
†ERATO Aihara Complexity Modeling Pro ject, JST, 153-8505 Tokyo, Japan

imagination paradigm. Motor imagination can be captured through spatially localized band-
power modulation in the µ- (10-15Hz) or β - (20-30Hz) band characterized by the second-
order statistics of the signal; the underlying neuro-physiology is well known as Event Related
Desynchronization (ERD) [10].

1.1 Problem setting
Let us denote by X ∈ Rd×T the EEG signal of a single trial of an imaginary motor move-
ment1 , where d is the number of electrodes and T is the number of sampled time-points in
a trial. We consider a binary classiﬁcation problem where each class, e.g. right or left hand
imaginary movement, is called positive (+) or negative (−) class. Let y ∈ {+1, −1} be the
class label. Given a set of trials and labels {Xi , yi }n
i=1 , the task is to predict the class label
y for an unobserved trial X .

1.2 Conventional method: classifying with CSP features

In the motor-imagery EEG signal classiﬁcation, Common Spatial Pattern (CSP) based clas-
siﬁers have proven to be powerful [11, 3, 6]. CSP is a decomposition method proposed
by Koles [9] that ﬁnds a set of pro jections that simultaneously diagonalize the covariance
(cid:88)
matrices corresponding to two brain states. Formally, the covariance matrices2 are deﬁned
as:
1
(c ∈ {+, −}),
XiX (cid:62)
|Ic |
i
i∈Ic
where Ic is the set of indices belonging to a class c ∈ {+, −}; thus I+ ∪ I− = {1, . . . , n}.
Then, the simultaneous diagonalization is achieved by solving the following generalized
eigenvalue problem:

Σc =

(1)

(2)

Σ+w = λΣ−w .
Note that for each pair of eigenvector and eigenvalue (wj , λj ), the equality λj = w(cid:62)
j Σ+wj
w(cid:62)
j Σ−wj
holds. Therefore, the eigenvector with the largest eigenvalue corresponds to the pro jection
with the maximum ratio of power for the “+” class and the “−” class, and the other-
way-around for the eigenvector with the smallest eigenvalue. In this paper, we call these
eigenvectors ﬁlters3 ; we call the eigenvector of an eigenvalue smaller (or larger) than one a
ﬁlter for the “+” class (or the “−” class), respectively, because the signal pro jected with
them optimally (in the spirit of eigenvalues) captures the task related de-synchronization in
each class. It is common practice that only the ﬁrst nof largest eigenvectors and the last nof
smallest eigenvectors are used to construct a low dimensional feature representation. The
feature vector consists of logarithms of the pro jected signal powers and a Linear Discriminant
Analysis (LDA) classiﬁer is trained on the resulting feature vector. To summarize, the
conventional CSP based classiﬁer can be constructed as follows:

How to build a CSP based classiﬁer:
1. Solve the generalized eigenvalue problem Eq. (2).
(cid:170)J
(cid:169)
2. Take the nof largest and smallest eigenvectors {wj }J
j=1
j XiX (cid:62)
log w(cid:62)
3. xi :=
(i = 1, . . . , n).
i wj
j=1
4. Train an LDA classiﬁer on {xi , yi }n
i=1 .
`
T 11(cid:62) ´
1For simplicity, we assume that the signal is already band-pass ﬁltered and each trial is centered
IT − 1
and scaled as X = 1√
Xoriginal
.
T
2Although it is convenient to call Eq. (1) a covariance matrix, calling it an averaged cross power
matrix gives better insight into the nature of the problem, because we are focusing on the task
related modulation of rhythmic activities.
3 according to the convention by [12].

(J = 2nof ).

2 Theory

2.1 The model

We consider the following discriminative model; we model the symmetric logit transform
W XX (cid:62) (cid:164)
(cid:163)
of the posterior class probability to be a linear function with respect to the second order
statistics of the EEG signal:
log P (y = +1|X )
+ b,
= f (X ; θ) := tr
P (y = −1|X )
where θ := (W, b) ∈ Sym(d) × R, W is a symmetric d × d matrix and b is the bias term.
(cid:163)(cid:161)−Σ+
−1 + Σ−−1 (cid:162)
XX (cid:62) (cid:164)
The model (3) can be derived by assuming a zero-mean Gaussian distribution with no
temporal correlation with a covariance matrix Σ± for each class as follows:
log P (y = +1|X )
1
P (y = −1|X )
2
However training of a discriminative model is robust to misspeciﬁcation of the marginal
In another words, the marginal distribution P (X ) is a nuisance
distribution P (X ) [13].
parameter; we maximize the joint log-likelihood, which is decomposed as log P (y , X |θ) =
log P (y |X, θ) + log P (X ), only with respect to θ [14]. Therefore, no assumption about the
generative model is necessary. Note that from Eq. (4) normally the optimal W has both
positive and negative eigenvalues.

+ const..

(3)

(4)

=

tr

2.2 Logistic regression

.

(5)

log

min
W ∈Sym(d),b∈R

2.2.1 Linear logistic regression
(cid:180)
(cid:179)
n(cid:88)
(cid:161)
trΣP W ΣP W + b2 (cid:162)
We minimize the negative log-likelihood of Eq. (3) with an additional regularization term,
which is written as follows:
1 + e−yi f (Xi ; θ)
1
(cid:80)n
+ C
2n
n
i=1
i=1 XiX (cid:62)
is introduced in the regularization
Here, the pooled covariance matrix ΣP := 1
i
n
term in order to make the regularization invariant to linear transformation of the data; if
we rewrite W as W := Σ−1/2
˜W Σ−1/2
, one can easily see that the regularization term is
P
P
(cid:81)n
simply the Frobenius norm of a symmetric matrix ˜W ; the transformation corresponds to the
whitening of the signal ˜X = Σ−1/2
P X . By simple calculation, one can see that the loss term
i=1 1/(1 + e−yi f (Xi ;θ ) ), in another
is the negative logarithm of the conditional likelihood
words the probability of observing head (yi = +1) or tail (yi = −1) by tossing n coins with
probability P (y = +1|X = Xi , θ) (i = 1, . . . , n) for the head. From a general point of view,
the loss term of Eq. (5) converges asymptotically to the true loss where the empirical average
is replaced by the expectation over X and y , whose minimum over functions in L2 (PX ) is
achieved by the symmetric logit transform of P (y = +1|X ) [15].
Note that the problem Eq. (5) is convex. The problem of classifying motor imagery EEG
signals is now addressed under a single loss function. Based on the criterion (Eq. (5)) we
can say how good a solution is and we know how to properly regularize it.

2.2.2 Rank=2 approximation of the linear logistic regression

Here we present a rank=2 approximation of the regression function (3). Using this approx-
imation we can greatly reduce the number of parameters to be estimated from a symmetric
matrix coeﬃcient to a pair of pro jection coeﬃcients and additionally gain insight into the
relevant feature the classiﬁer has found.
(cid:163)(cid:161)−w1w(cid:62)
XX (cid:62) (cid:164)
(cid:162)
The rank=2 approximation of the regression function (3) is written as follows:
1
1 + w2w(cid:62)
¯f (X ; ¯θ) :=
2
2

+ b,

(6)

tr

min
w1 ,w2∈Rd ,b∈R

where ¯θ := (w1 , w2 , b) ∈ Rd × Rd × R. The rationale for choosing this special form of
function is that the Bayes optimal regression coeﬃcients in Eq. (4) is the diﬀerence of two
positive deﬁnite matrices; therefore two bases with opposite signs are at least necessary in
capturing the nature of Eq. (4) (incorporating more bases goes beyond the scope of this
contribution).
The rank=2 parameterized logistic regression can be obtained by minimizing the sum of the
(cid:179)
(cid:180)
n(cid:88)
2 ΣP w2 + b2 (cid:162)
(cid:161)
logistic regression loss and regularization terms similarly to Eq. (5):
1 + e−yi
w(cid:62)
1 ΣP w1 + w(cid:62)
i=1
Here, again the pooled covariance matrix ΣP is used as a metric in order to ensure the
invariance to linear transformations. Note that the bases {w1 , w2 } give pro jections of the
signal into a two dimensional feature space in a similar manner as CSP (see Sec. 1.2). We call
w1 and w2 ﬁlters corresponding to “+” and “−” classes, respectively, similarly to CSP. The
ﬁlters can be topographically mapped onto the scalp, from which insight into the classiﬁer
can be obtained. However, the ma jor diﬀerence between CSP and the rank=2 parameterized
logistic regression (Eq. (7)) is that in our new approach, there is no distinction between the
feature extraction step and the classiﬁer training step. The coeﬃcient that linearly combines
the features (i.e., the norm of w1 and w2 ) is optimized in the same optimization problem
(Eq. (7)).

¯f (Xi ; ¯θ)

+ C
2n

1
n

log

.

(7)

3 Results

3.1 Experimental settings

We compare the logistic regression classiﬁers (Eqs. (3) and (6)) against CSP based classiﬁers
with nof = 1 (total 2 ﬁlters) and nof = 3 (total 6 ﬁlters). The comparison is a chronological
validation. All methods are trained on the ﬁrst half of the samples and applied on the second
half. We use 60 BCI experiments [6] from 29 sub jects where the sub jects performed three
imaginary movements, namely “right hand” (R), “left hand” (L) and “foot” (F) according
to the visual cue presented on the screen, except 9 experiments where only two classes
were performed. Since we focus on binary classiﬁcation, all the pairwise combination of
the performed classes produced 162 (= 51 · 3 + 9) datasets. Each dataset contains 70 to 600
trials (at median 280) of imaginary movements. All the recordings come from the calibration
measurements, i.e. no feedback was presented to the sub jects. The signal was recorded from
the scalp with multi-channel EEG ampliﬁers using 32, 64 or 128 channels. The signal was
sampled at 1000Hz and down-sampled to 100Hz before the processing.
The signal is band-pass ﬁltered at 7-30Hz and the interval 500-3500ms after the appearance
of visual cue is cut out from the continuous EEG signal as a trial X . The training data is
whitened before minimizing Eqs. (5) and (7) because both problems become considerably
simpler when ΣP is an identity matrix. For the prediction of test data, coeﬃcients including
the whitening operation W = Σ−1/2
for Eq. (3) and wj = Σ−1/2
˜W Σ−1/2
˜wj (j = 1, 2) for
P
P
P
Eq. (6) are used, where ˜W and ˜wj denote the minimizer of Eqs. (5) and (7) for the whitened
data. Note that we did not whitened the training and test data jointly, which could have
improved the performance. The regularization constant C for the proposed method is chosen
by 5×10 cross-validation on the training set.

3.2 Classiﬁcation performance

In Fig. 1, logistic regression (LR) classiﬁers with the full rank parameterization (Eq. (3);
left column) and the rank=2 parameterization (Eq. (6); right column) are compared against
CSP based classiﬁers with 6 ﬁlters (top row) and 2 ﬁlters (bottom row). Each plot
shows the bit-rates achieved by CSP (horizontal) and LR (vertical) for each dataset as
a circle. Here the bit-rate (per decision) is deﬁned based on the classiﬁcation test er-
ror perr as the capacity of a binary symmetric channel with the same error probability:

Figure 1: Comparison of bit-rates achieved by the CSP based classiﬁers and the logistic
regression (LR) classiﬁers. The bit-rates achieved by the conventional CSP based classiﬁer
and the proposed LR classiﬁer are shown as a circle for each dataset. The proportion of
datasets lying above/below the diagonal is shown at top-left/bottom-right corners of each
plot, respectively. Only the diﬀerence between CSP with 2 ﬁlters and rank=2 approximated
(cid:179)
(cid:180)
LR (lower right) is signiﬁcant based on Fisher sign test at 5% level.
1 −
+ (1 − perr ) log2
perr log2
. The proposed method improves upon the con-
1
1
1−perr
perr
ventional method for datasets lying above the diagonal. Note that our proposed logistic
regression ansatz is signiﬁcantly better only in the lower right plot.
Figure 2 shows examples of spatial ﬁlter coeﬃcients obtained by CSP (6 ﬁlters) and rank=2
parameterized logistic regression. The CSP ﬁlters for sub ject A (see Fig. 2(a)) include
typical cases (the ﬁrst ﬁlter for the “left hand” class and the ﬁrst two ﬁlters for the “right
hand” class) of ﬁlters corrupted by artifacts, e.g., muscle movements. The CSP ﬁlters for
the “foot” class in sub ject B (see Fig. 2(b)) are corrupted by strong occipital α-activity,
which might have been weakly correlated to the labels by chance. Note that CSP with 2
ﬁlters only use the ﬁrst ﬁlter for each class, which corresponds to the ﬁrst row in Figs. 2(a)
and 2(b). On the other hand the ﬁlter coeﬃcients obtained by the logistic regression are
clearly focused on the area physiologically corresponding to ERD in the motor cortex (see
Figs. 2(c) and (d)).

4 Discussion

4.1 Relation to CSP

Here, we show that at the optimum of Eq. (7) the regression coeﬃcients w1 and w2 are
generalized eigenvectors of two uncertainty weighted covariance matrices corresponding to
two motor imagery classes, which are weighted by the uncertainty of the decision 1 − P (y =
yi |X = Xi ) for each sample. Samples that are easily explained by the regression function
are weighed low whereas those lying close to the decision boundary or those lying on the
wrong side of the boundary are highly weighted. Although, both CSP and the rank=2
approximated logistic regression can be understood as generalized eigenvalue decomposition,
the classiﬁcation-optimized weighting in the logistic regression yields ﬁlters that focus on

00.20.40.60.8100.20.40.60.81CSP (6 filters)LR (full rank)43%48%00.20.40.60.800.20.40.60.8CSP (6 filters)LR (rank=2)52%38%00.20.40.60.8100.20.40.60.81CSP (2 filters)LR (full rank)52%43%00.20.40.60.800.20.40.60.8CSP (2 filters)LR (rank=2)64%28%the task related modulation of rhythmic activities more clearly when compared to CSP, as
shown in Fig. 2.
± n(cid:88)
Diﬀerentiating Eq. (7) with either w1 or w2 , we obtain the following equality which holds
at the optimum.
e−zi
j + CΣP w∗
yiXiX (cid:62)
i w∗
j = 0
1 + e−zi
i=1
∗
) and ± denotes + and − for j = 1, 2,
¯f (Xi ; ¯θ
where we deﬁne the short hand zi := yi
respectively. Moreover, Eq. (8) can be rewritten as follows:
∗
∗
, C )w∗
, 0)w∗
Σ−(¯θ
1 = Σ+(¯θ
1 ,
∗
∗
, 0)w∗
, C )w∗
Σ+(¯θ
2 = Σ−(¯θ
2 ,
(cid:88)
n(cid:88)
where we deﬁne the uncertainty weighted covariance matrix as:
e−zi
∗
XiX (cid:62)
i + C
Σ± (¯θ
1 + e−zi
n
i∈I±
i=1
Note that increasing the regularization constant C biases the uncertainty weighted covari-
ance matrix to the pooled covariance matrix ΣP ; the regularization only aﬀects the right-
hand side of Eqs. (9) and (10). If C > 0, the optimal ﬁlter coeﬃcients w∗
j (j = 1, 2) are the
generalized eigenvectors of Eqs. (9) and (10), respectively.

XiX (cid:62)
i .

(9)
(10)

(j = 1, 2),

(8)

, C ) =

4.2 CSP is not optimal

When ﬁrst proposed, CSP was rather a decomposition technique than a classiﬁcation tech-
nique (see [9]). After being introduced to the BCI community by [11], it has proved to be
also powerful in classifying imaginary motor movements [3, 6]. However, since it is not op-
timized for the classiﬁcation problem, there are two ma jor drawbacks. Firstly, the selection
of “good” CSP components is usually done somewhat arbitrarily. A widely used heuristic is
to choose several generalized eigenvectors from both ends of the eigenvalue spectrum. How-
ever, as in sub ject B in Fig. 2, it is often observed that ﬁlters corresponding to overwhelming
strong power come to the top of the spectrum though they are not correlated to the label
so strongly. In practice, an experienced investigator can choose good ﬁlters by looking at
them, however the validity of the selection cannot be assessed because the manual selection
cannot be done inside the cross-validation. Secondly, simultaneous diagonalization of co-
variance matrices can suﬀer greatly from a few outlier trials as seen in sub ject A in Fig. 2.
Again, in practice one can inspect the EEG signals to detect outliers, however a manual
outlier detection is also a somewhat arbitrary, non-reproducible process, which cannot be
validated.

5 Conclusion

In this paper, we have proposed an uniﬁed framework for single trial classiﬁcation of motor-
imagery EEG signals. The problem is addressed as a single minimization problem without
any prior feature extraction or outlier removal steps. The task is to minimize a logistic
regression loss with a regularization term. The regression function is a linear function with
respect to the second order statistics of the EEG signal.
We have tested the proposed method on 162 BCI datasets. By parameterizing the whole
regression coeﬃcients directly, we have obtained comparable classiﬁcation accuracy with
CSP based classiﬁers. By parameterizing the regression coeﬃcients as the diﬀerence of two
rank-one matrices, improvement against CSP based classiﬁers was obtained.
We have shown that in the rank=2 parameterization of the logistic regression function,
the optimal ﬁlter coeﬃcients has an interpretation as a solution to a generalized eigenvalue
problem similarly to CSP. However, the diﬀerence is that in the case of logistic regression
every sample is weighted according to the importance to the overall classiﬁcation problem
whereas in CSP all the samples have uniform importance.

The proposed framework provides a basis for various future directions. For example, in-
corporating more than two ﬁlters will connect the two parameterizations of the regression
function shown in this paper and it may allow us to investigate how many ﬁlters are suf-
ﬁcient for good classiﬁcation. Since the classiﬁer output is the logit transform of the class
probability, it is straightforward to generalize the method to multi-class problems. Also
non-stationarities, e.g. caused by a covariate shift (see [16, 17]) in the density P (X ) from
one session to another, could be corrected by adapting the likelihood model.
Acknowledgments: This research was partially supported by MEXT, Grant-in-Aid for
JSPS fellows, 17-11866 and Grant-in-Aid for Scientiﬁc Research on Priority Areas, 17022012,
by BMBF-grant FKZ 01IBE01A, and by the IST Programme of the European Community,
under the PASCAL Network of Excellence, IST-2002-506778. This publication only reﬂects
the authors’ views.

References

[1] J. R. Wolpaw, N. Birbaumer, D. J. McFarland, G. Pfurtscheller, and T. M. Vaughan, “Brain-
computer interfaces for communication and control”, Clin. Neurophysiol., 113: 767–791, 2002.
[2] N. Birbaumer, N. Ghanayim, T. Hinterberger, I. Iversen, B. Kotchoubey, A. K¨ubler, J. Perel-
mouter, E. Taub, and H. Flor, “A spelling device for the paralysed”, Nature, 398: 297–298,
1999.
[3] G. Pfurtscheller, C. Neuper, C. Guger, W. Harkam, R. Ramoser, A. Schl¨ogl, B. Obermaier,
and M. Pregenzer, “Current Trends in Graz Brain-computer Interface (BCI)”, IEEE Trans.
Rehab. Eng., 8(2): 216–219, 2000.
[4] B. Blankertz, G. Curio, and K.-R. M¨uller, “Classifying Single Trial EEG: Towards Brain
Computer Interfacing”, in: T. G. Diettrich, S. Becker, and Z. Ghahramani, eds., Advances in
Neural Inf. Proc. Systems (NIPS 01), vol. 14, 157–164, 2002.
[5] B. Blankertz, G. Dornhege, C. Sch¨afer, R. Krepki, J. Kohlmorgen, K.-R. M¨uller, V. Kunzmann,
F. Losch, and G. Curio, “Boosting Bit Rates and Error Detection for the Classiﬁcation of
Fast-Paced Motor Commands Based on Single-Trial EEG Analysis”, IEEE Trans. Neural Sys.
Rehab. Eng., 11(2): 127–131, 2003.
[6] B. Blankertz, G. Dornhege, M. Krauledat, K.-R. M¨uller, V. Kunzmann, F. Losch, and G. Cu-
rio, “The Berlin Brain-Computer Interface: EEG-based communication without sub ject train-
ing”, IEEE Trans. Neural Sys. Rehab. Eng., 14(2): 147–152, 2006.
[7] G. Dornhege, J. del R. Mill´an, T. Hinterberger, D. McFarland, and K.-R. M¨uller, eds., Towards
Brain-Computer Interfacing, MIT Press, 2006, in press.
[8] T. N. Lal, M. Schr¨oder, T. Hinterberger, J. Weston, M. Bogdan, N. Birbaumer, and
B. Sch¨olkopf, “Support Vector Channel Selection in BCI”, IEEE Transactions Biomedical
Engineering, 51(6): 1003–1010, 2004.
[9] Z. J. Koles, “The quantitative extraction and topographic mapping of the abnormal compo-
nents in the clinical EEG”, Electroencephalogr. Clin. Neurophysiol., 79: 440–447, 1991.
[10] G. Pfurtscheller and F. H. L. da Silva, “Event-related EEG/MEG synchronization and desyn-
chronization: basic principles”, Clin. Neurophysiol., 110(11): 1842–1857, 1999.
[11] H. Ramoser, J. M¨uller-Gerking, and G. Pfurtscheller, “Optimal spatial ﬁltering of single trial
EEG during imagined hand movement”, IEEE Trans. Rehab. Eng., 8(4): 441–446, 2000.
[12] N. J. Hill, J. Farquhar, T. N. Lal, and B. Sch¨olkopf, “Time-dependent demixing of task-relevant
EEG sources”, in: Proceedings of the 3rd International Brain-Computer Interface Workshop
and Training Course 2006, Verlag der Technischen Universit¨at Graz, 2006.
[13] B. Efron, “The Eﬃciency of Logistic Regression Compared to Normal Discriminant Analysis”,
J. Am. Stat. Assoc., 70(352): 892–898, 1975.
[14] T. Minka, “Discriminative models, not discriminative training”, Tech. Rep. TR-2005-144,
Microsoft Research Cambridge, 2005.
[15] T. Hastie, R. Tibshirani, and J. Friedman, The Elements of Statistical Learning, Springer-
Verlag, 2001.
[16] H. Shimodaira, “Improving predictive inference under covariate shift by weighting the log-
likelihood function”, Journal of Statistical Planning and Inference, 90: 227–244, 2000.
[17] S. Sugiyama and K.-R. M¨uller, “Input-Dependent Estimation of Generalization Error under
Covariate Shift”, Statistics and Decisions, 23(4): 249–279, 2005.

(a) Sub ject A. CSP ﬁlter coeﬃcients

(b) Sub ject B. CSP ﬁlter coeﬃcients

(c) Sub ject A. Logistic regression (rank=2)
ﬁlter coeﬃcients

(d) Sub ject B. Logistic regression (rank=2)
ﬁlter coeﬃcients

Figure 2: Examples of spatial ﬁlter coeﬃcients obtained by CSP and the rank=2 parame-
terized logistic regression. (a) Sub ject A. Some CSP ﬁlters are corrupted by artifacts. (b)
Sub ject B. Some CSP ﬁlters are corrupted by strong occipital α-activity. (c) Sub ject A.
Logistic regression coeﬃcients are focusing on the physiologically expected “left hand” and
“right hand” areas. (d) Sub ject B. Logistic regression coeﬃcients are focusing on the “left
hand” and “foot” areas. Electrode positions are marked with crosses in every plot. For CSP
ﬁlters, the generalized eigenvalues (Eq. (2)) are shown inside brackets.

[2.40]left hand[2.04][1.88][0.33]right hand[0.41][0.59][7.11]left hand[4.74][3.19][0.61]foot[0.67][0.70]left handright handleft handfoot