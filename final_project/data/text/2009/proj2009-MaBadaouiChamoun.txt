A Generalized Method to Solve Text-Based CAPTCHAs

Jason Ma, Bilal Badaoui, Emile Chamoun

December 11, 2009

1 Abstract

4 Segmentation

We present work in progress on the automated solv-
ing of text-based CAPTCHAs. Our method consists
of two large components: ﬁrstly, we segment the text
from the background. Afterwards, in order to iden-
tify the text, we extract features and use learning
algorithms to classify each character. In particular,
we developed a weighted k -means algorithm, which
is largely able to segment the text portion of the
CAPTCHA image. Additionally, we developed an
algorithm to separate the individual characters. Fi-
nally, we explored classifying the separated charac-
ters using several methods, including through sup-
port vector machines and optical character recogni-
tion algorithms. We also present some current chal-
lenges we face in this algorithm, and some ideas we
plan on exploring to overcome them.

2 Background information

A completely automated public Turing test for telling
computers and humans apart, or CAPTCHA, is used
in many web-based applications. The most preva-
lent CAPTCHAs consist of an image of a sequence of
distorted letters, which is purportedly diﬃcult for a
computer to solve, but easy for humans. CAPTCHAs
are used to prevent the automation of certain tasks;
for instance, they are often found on website registra-
tion forms, which helps ensure that each registration
is from a human. Previous research has been tra-
ditionally focused on solving single speciﬁc types of
CAPTCHAs.

3 Data retreival

We began by obtaining 1000 CAPTCHAs from the
ICQ registration site, 400 CAPTCHAs from Gmail,
400 CAPTCHAs from Yahoo!, and 400 CAPTCHAs
from Kongregate. In addition, we used a small num-
ber of CAPTCHAs from other generators, in order to
ensure that our algorithm is general.

We explored ﬁve main areas, comprising the segmen-
tation portion of our method.

4.1 Weighted k -means

4.1.1 k -means

We began by exploring k -means clustering of the col-
ors (treating each pixel as a vector in R3 ). By com-
pressing the colorspace of the image, we hope to seg-
ment the text from the background. It is likely that
the text has diﬀerent color values, as otherwise hu-
mans will not be able to identify the text easily. Nat-
urally, then, if we were able to cluster the pixels so as
to place the text and the background into separate
clusters, we would be able to more easily recognize
the text.
Unfortunately, simple k -means does not perform
well in certain cases, especially when the both the
background and text vary in color. Moreover, simple
k -means performs poorly when the text consists of
progressively diﬀering colors, as the diﬀerent parts of
characters will be placed in diﬀerent clusters. Other
weaknesses include when the text is obscured by lines
that extend across the text, as the lines themselves
will be clustered with the text.

4.1.2 Weighted k -means

To surmount these challenges in simple k -means, we
investigated an enhanced algorithm in which we con-
sider both the color and the location of the pixel.
Speciﬁcally, for each pixel, the distance to the cen-
troid is deﬁned as a weighted combination of the Eu-
clidean distance between the respective colors, and
the Euclidean distance between the geometric loca-
tions of the pixels within the image. By adjusting
the weight of the two components, we hope to strike
a balance and cluster pixels that are of a similar color
and location.
Whereas simple k -means performed poorly on cer-
tain CAPTCHAs, with the proper weights and the

1

proper k, weighted k -means performs signiﬁcantly
better.
Below, we show three ﬁgures comparing the per-
formance of weighted and unweighted k -means. Fig-
ure 1 shows the original CAPTCHA, which is dif-
ﬁcult to segment due to the background. Figure 2
shows the result when simple k -means is used; Fig-
ure 3 shows the corresponding result for weighted k -
means. Both algorithms used k = 15 clusters; the
weighted k -means algorithm weighted the proximity
with a factor of w = 4. By weighting the k -means
algorithm, we are able to cluster the text into a small
number of clusters, with each character completely
within one cluster.

To ﬁnd the orientation of the text, we compute the
ﬁrst principal component of all the points in the text.
Subsequently, to simplify the discretization step, we
rotate the image so that this principal component is
horizontal. Next, we pro ject the image on the prin-
cipal component, and ﬁnd the points with highest
diﬀerences in intensity. We calculate the mean and
standard deviation of the changes in intensity and,
for all points that lie c standard deviations above the
mean, we make a vertical cut to divide the cluster
into two parts. With a continuous region of high dif-
ference, we make the cut at the region’s median to
minimize information loss.

Figure 1: A CAPTCHA from ICQ

Figure 2: Unweighted k-means

4.3 Minimum spanning tree

One of the approaches we tried was using the min-
imum spanning tree to segment the CAPTCHAs.
In essence, minimum spanning tree clustering tech-
niques resemble k -means, with the extra advantage
of constructively building the clusters.
Each pixel corresponds to a vertex in the graph.
Neighboring pixels within a predetermined window
size will be connected by edges, the weight of each
edge being a weighted average between the color
intensity and proximity (similarly to weighted k -
means). We can build the minimum spanning tree
resulting from this graph.
First, let us lay out the theoretical foundations of
our MST clustering algorithm.
Deﬁnition 1.1 For a data set D, C ⊆ D forms a
cluster in D only if for any arbitrary partition C =
C1 ∪ C2 , the closest data point d to C 1, d ∈ D − C1 ,
is from C2 .
In essence, by this deﬁnition, we are trying to cap-
ture our intuition about a cluster; that is: distances
between neighbors within a cluster should be smaller
than any inter-cluster distances.

Figure 3: Weighted k-means

4.3.1 Fundamental results

4.2 Vertical cuts segmentation
As can be seen in Figure 3, weighted k -means can
cluster multiple characters into the same cluster. As
classiﬁcation requires individual letters, separation of
clusters is necessary. To accomplish this, we ﬁrst de-
termine the orientation of the text. Then, we dis-
cretize the image space into lines that are perpen-
dicular to the dominant orientation. Characters are
separated by lines whose change in pixel density is
greatest.

Property 1.2 Expansion Property. If c1 and c2 are
two points of a cluster C , then all data points in the
tree path, P , connecting c1 and c2 in the minimum
spanning tree, must be from C .
The proof of this result can be found in [4].
Property 1.3 Let c1 and c2 be such that c2 is the
closest point to c1 . Then either c1 deﬁnes a cluster
alone, or c1 and c2 are in the same cluster.
The proof of this result can be found easily by ap-
plying the deﬁnition 1.1.

2

4.3.2 Corollaries

We can get from the ﬁrst fundamental result that
a cluster is a connected component of the minimum
spanning tree. Hence, clustering is only a matter of
pruning certain edges from the minimum spanning
tree. The resulting graph will have a number of con-
nected components, deﬁning the clusters.

close colors), and the clusters will not necessarily con-
sist of characters only (namely because of the nature
of a CAPTCHA: characters and noise nearby might
be clustered in the same cluster). For example, af-
ter running weighted k -means on the CAPTCHA in
Figure 1, one of the clusters obtained is shown in
Figure 4.

4.3.3 Exploration clustering algorithm

The algorithm consists of two steps.

1. Mandatory components. To avoid singleton
clusters, the algorithm ﬁrst uses the second fun-
damental result to build agglomerative manda-
tory components. We start ﬁrst with each vertex
considered as a component. For each point A in
a component C , we consider the component D of
A’s closest neighbor. If C 6= D, C := C ∪ D. We
apply iteratively this rule to every component as
long as merging is occurring. We stop when the
process stabilizes.

2. Exploration.
In the exploration phase, we
take every mandatory component M C . For each
point B on the border of M C , we get its closest
neighbor N in M C . If the distance between B
and N is less than m + s × d (where m is the
mean of distances in M C , d the standard devia-
tion and s is a parameter we will call sensitivity)
we merge M C and the mandatory component
containing B . After doing this for every point
that was on the border, we update the mean and
the standard deviation and reiterate.

4.3.4 Results

Unfortunately, the results were not satisfactory at all.
The Mandatory Component phase in the algorithm
produces a huge initial number of mandatory compo-
nents (typically in a 100 x 240 picture, the number of
Mandatory Components is around 4000). This made
the exploration phase very ineﬃcient with mandatory
components being merged (due to similar small size)
and resulting in creating one very big cluster that
would contain more than 99% of the image.

4.4 Weighted k -means noise removal

As discussed earlier, the weighted k -means segmenta-
tion manages to create successfully clusters contain-
ing text. However, one cluster might contain more
than one character (possibly if the k used is small
or if the characters are close enough and have very

Figure 4: One cluster from weighted k-means

Our noise removal algorithm tackles these chal-
lenges. The algorithm is based upon the observation
that a cluster found by weighted k-means consists of
a set of “continuous” components. The idea is then
to break a cluster into these continuous components.
Each of these components would be considered a sep-
arate cluster provided it is not “too small”. To ﬁnd
continuous clusters, we use again a graph structure
to connect neighboring cluster pixels. Finding the
“continuous” components is equivalent to ﬁnding the
connected components of the graph. By applying the
algorithm on the cluster in Figure 4, we get the fol-
lowing clusters:

Figure 5: Separated cluster, after noise removal

Figure 6: Separated cluster, after noise removal

4.5 Normalized Cuts
The apparent dissimilarities between the text and the
background in CAPTCHAS suggested the use of nor-
malized cuts as a potential segmentation method [1].

3

Eﬀectively, in addition to measuring the total similar-
ity within each cluster, the normalized criterion takes
into account the total dissimilarity between diﬀerent
groups.
Essentially, the algorithm models the image as a
weighted undirected graph. Each pixel is a node in
the graph and is connected by edges to the other pix-
els in the image. Moreover, a weight indicating the
degree of similarity between two pixels is assigned to
each edge.
Thus, segments are formed by removing edges from
the graph. The normalized cut ratio is deﬁned by
the weight of the cut to the weight of the edges in
a given segment. The normalized cut segmentation
algorithm seeks to minimize the normalized cut ratio,
in accordance with the overall goal of minimizing the
weight of the edges removed.
Unfortunately, this algorithm did not perform too
well on our dataset since the text in the CAPTCHAs
often progressively changes intensity which makes it
very hard to segment individual letters properly. Ef-
fectively, it turns out that this algorithm often splits
the same letter into two or more clusters if the dif-
ferent parts of the character share more similarities
with the background that with each other.

4.6 Fuzzy c-means Clusterization
We applied fuzzy clustering to the segmented text
parts to try to further separate characters in the same
cluster. The fuzzy clustering algorithm can be de-
scribed in the following steps:

Chose a number of clusters.

Assign randomly to each point coefficients
that represent their degree of belonging in
a cluster.

Repeat until convergence {
Compute the centroid of each cluster,
which is defined as the mean of all
points in the cluster weighted by their
degree of belonging to the cluster.

Update the coefficients to reflect the
new degree of belonging to the cluster.

}

Although this algorithm performed well in separat-
ing spaced out characters, it did not succeed in seg-
menting connected characters as is the case in google
CAPTCHAs. In particular, we found the assignment
of clusters in this algorithm to heavily depend on the
physical location of points in the image. Thus, in

the case of connected characters, the algorithm might
assign two halves of the same character to the two
neighboring clusters if the distance of each half to
the neighboring cluster is smaller than the distance
that separate them.

5 Classiﬁcation

We tried a variety of methods to classify the individ-
ual segmented characters. This comprises part two
of our method. Our training data consisted of the
CAPTCHAs collected, as described in the data re-
trieval section.

5.1 Support vector machines

Our ﬁrst attempt was to try to classify characters us-
ing SVM. We started ﬁrst by generating a training set
consisting of all alphanumeric characters in diﬀerent
shapes, fonts and sizes. Using SURF, we extracted
the features from each element in the training set.
For each training element, we ran k -means over the
features (k was heuristically ﬁxed at 15). We then
trained a one-versus-one multi-classiﬁer SVM using
the SURF features of the centroids as inputs. The
aim was to use the trained SVM on the segmented
clusters from the previous section. However, the ac-
curacy of the trained SVM was very low: the SVM
had 10% accuracy. Conceptually, this was not very
surprising. Consider for examples the characters E
and F. Any interest point in F will be in E. However,
E should contain at least one more interest point (the
bottom right edge). Running k -means could only be
harmful to the classiﬁcation of either E or F. If k
is big enough for E, the classiﬁcation of F will be
harmed by added irrelevant features. The converse
would happen if k were small.

5.2 Optical character recognition

Another classiﬁcation method we considered was op-
tical character recognition. Optical character recog-
nition (OCR) is the electronic translation of text-
based images into a computer editable form. Given
the success of OCR technology in advanced identify
the segmented characters.
Tesseract, which is widely considered as one of
most accurate open source OCR engines available,
was run on the segmented characters in an attempt
to recognize them.
Although Tesseract succeeded in identifying some
characters, it turned out to not be suitable for our
classiﬁcation problem for the two following reasons:

4

1. Tesseract learns the font of the characters in
its training set, which consists of scanned elec-
tronic documents. Therefore, Tesseract will not
succeed in identifying characters whose font dif-
fers signiﬁcantly from that training set. More-
over, training Tesseract on a customized dataset
is not feasible since the engine will not be able
to learn the font given that diﬀerent types of
CAPTCHAs do not have the same font.

2. Tesseract uses a dictionary to identify whole set
of words, as opposed to individual characters. In
that sense, Tesseract does poorly when it comes
to identifying individual characters.
In some
cases, it even tries to match a character to a full
word in its dictionary if such match is possible.

6 Work in progress

Given the low success rate achieved by out-of-the-
box character recognition packages and our intent to
continue work on the pro ject, we are currently con-
sidering other classiﬁcation methods outlined in the
next sections.

6.1 Back propagation

One idea worth exploring is back propagation.
Brieﬂy, similar to the way humans reason about
CAPTCHAs, a high conﬁdence classiﬁcation of a cer-
tain segment in a CAPTCHA provides us with valu-
able information about the “structure” of the text,
such as orientation. This information could be prop-
agated back to the segmentation in order to obtain
better quality clusters, which will provide better re-
sults in general.

6.2 LeNet

Indentifying individual characters from segmented
text-based CAPTCHAs requires robustness to font
selection and image transformations.
In that con-
text, we are currently exploring using convolutional
neural networks to try to recognize images with min-
imal preprocessing. Convolution Neural networks are
a form of multi-layer neural networks designed to rec-
ognize visual patterns from images. They are robust
to distortions and geometric transformations and can
recognize patterns with a high degree of variability
such as CAPTCHAs.
One such convolutional network is LeNet-5 [3]
which is originally designed to identify handwritten
and machine-printed character recognition. The fact

that LeNet-5 is successfully able to recognize hand-
written characters leads us to believe that it might
perform very well on CAPTCHAs if trained on a good
dataset. Eﬀectively, handwritten characters present
features that are very similar to CAPTCHAs such as
a high degree of variability in font, distortion as well
as the spacing between individual characters.

6.3 Shape context features

Shape context features reﬂects the distribution of a
pixel’s neighboring points relative to it[2]. Thus, cor-
responding points on two related shapes will have
similar shape context features. In particular, letters
are deﬁned by the relative locations of each pixel’s
neighbors, and thus shape context features are highly
robust to distortions in text, as capturing the de-
pendencies between neighboring pixels is key to suc-
cessful identiﬁcation. For this reason, shape context
features will likely perform signiﬁcantly better than
SURF in a support vector machine.

7 Conclusion

The key step in solving CAPTCHAs, segmentation to
extract individual letters, has been reasonably suc-
cessful. Through using a variety of algorithms, we
reduce color variations in the image, separate clus-
ters, and reduce the noise in each cluster. From our
algorithms, we can retrieve with reasonable success
a set of binary images that represents each character
in the CAPTCHA. Additionally, more work remains
to be done in classiﬁcation. Several ideas have sig-
niﬁcant potential in this area. These results show
promise for a generalized CAPTCHA solver, which
would render them ineﬀective and promote the need
of a improved system.

References

[1] Jianbo Shi and Jitendra Malik. Normalized Cuts
and Image Segmentation. IEEE Transactions on
Pattern Analysis and Machine Intel ligence, 2000.

[2] Jitendra Malik Serge Belongie and Jan Puzicha.
Shape Matching and Ob ject Recognition Using
Shape Contexts. IEEE Transactions on Pattern
Analysis and Machine Intel ligence, 2002.

[3] Y. Bengio Y. LeCun, L. Bottou and P. Haﬀner.
Gradient-based learning applied to document
recognition. Proceedings of the IEEE, 1998.

5

[4] Victor Olman Ying Xu and Dong Xu. Minimum
Spanning Trees for Gene Expression Data Clus-
tering. Genome Informatics, 2001.

6

