Estimating image bases for visual image
reconstruction from human brain activity

Yusuke Fujiwara1 Yoichi Miyawaki2;1 Yukiyasu Kamitani1
1ATR Computational Neuroscience Laboratories
2National Institute of Information and Communications Technology
2-2-2 Hikaridai, Seika-cho, Kyoto, Japan
yureisoul@gmail.com yoichi m@atr.jp kmtn@atr.jp

Abstract

Image representation based on image bases provides a framework for understand-
ing neural representation of visual perception. A recent fMRI study has shown
that arbitrary contrast-deﬁned visual images can be reconstructed from fMRI ac-
tivity patterns using a combination of multi-scale local image bases. In the recon-
struction model, the mapping from an fMRI activity pattern to the contrasts of the
image bases was learned from measured fMRI responses to visual images. But the
shapes of the images bases were ﬁxed, and thus may not be optimal for reconstruc-
tion. Here, we propose a method to build a reconstruction model in which image
bases are automatically extracted from the measured data. We constructed a prob-
abilistic model that relates the fMRI activity space to the visual image space via a
set of latent variables. The mapping from the latent variables to the visual image
space can be regarded as a set of image bases. We found that spatially localized,
multi-scale image bases were estimated near the fovea, and that the model using
the estimated image bases was able to accurately reconstruct novel visual images.
The proposed method provides a means to discover a novel functional mapping
between stimuli and brain activity patterns.

1 Introduction

The image basis is a key concept for understanding neural representation of visual images. Using
image bases, we can consider natural scenes as a combination of simple elements corresponding
to neural units. Previous works have shown that image bases similar to receptive ﬁelds of simple
cells are learned from natural scenes by the sparse coding algorithm [4, 9]. A recent fMRI study
has shown that visual images can be reconstructed using a linear combination of multi-scale image
bases (1x1, 1x2, 2x1, and 2x2 pixels covering an entire image), whose contrasts were predicted
from the fMRI activity pattern [6]. The multi-scale bases produced more accurate reconstruction
than the pixel-by-pixel prediction, and each scale contributed to reconstruction in a way consistent
with known visual cortical representation. However, the predeﬁned shapes of image bases may not
be optimal for image reconstruction.
Here, we developed a method to automatically extract image bases from measured fMRI responses
to visual stimuli, and used them for image reconstruction. We employed the framework of canonical
correlation analysis (CCA), in which two multi-dimensional observations are related via a common
coordinate system. CCA ﬁnds multiple correspondences between a weighted sum of voxels and
a weighted sum of pixels. These correspondences provide an efﬁcient mapping between the two
observations. The pixel weights for each correspondence can be thought to deﬁne an image basis.
As the early visual cortex is known to be organized in a retinotopic manner, one can assume that
a small set of pixels corresponds to a small set of voxels. To facilitate the mapping between small

1

Figure 1: Model for estimating image bases. (a) Illustration of the model framework. The visual
image I (pixels) and an fMRI activity pattern r (voxels) is linked by latent variables z. The links
from each latent variable to image pixels deﬁne an image basis WI , and the links from each latent
variable to fMRI voxels is called a weight vector Wr . (b) Graphical representation of the model.
Circles indicate model parameters to be estimated and squares indicate observations. The matrices
WI and Wr , the common latent variable z, and the inverse variances (cid:11)I and (cid:11)r are simultaneously
estimated using the variational Bayesian method. Using the estimated parameters, the predictive
distribution for a visual image given a new brain activity pattern is constructed (dashed line).

sets of pixels and voxels, we extended CCA to Bayesian CCA [10] with sparseness priors. Bayesian
CCA treats the multiple correspondences as latent variables with two transformation matrices to two
sets of observations. The transformation matrix to the visual image can be regarded as a set of image
bases. The matrices are assumed to be random variables with hyper-parameters. We introduced a
sparseness prior into each element of the matrices, such that only small subsets of voxels and pixels
are related with non-zero matrix elements.
The Bayesian CCA model was applied to the data set of Miyawaki et al. [6]. We show that spa-
tially localized image bases were extracted, especially around the foveal region, whose shapes were
similar to those used in the previous work. We also demonstrate that the model using the estimated
image bases produced accurate visual image reconstruction.

2 Method

We constructed a model in which a visual image is related with an fMRI activity pattern via latent
variables (Figure 1). Each latent variable has links to a set of pixels, which can be regarded as
an image basis because links from a single latent variable construct an element of a visual image.
The latent variable also has multiple links to a set of fMRI voxels, which we call a weight vector.
This model is equivalent to CCA: each latent variable corresponds to a canonical coefﬁcient [3] that
bundles a subset of fMRI voxels responding to a speciﬁc visual stimulus. We then extended the CCA
model to the Bayesian CCA model that can conduct a sparse selection of these links automatically.

2.1 Canonical Correlation Analysis

We ﬁrst consider the standard CCA for estimating image bases given visual images I and fMRI
activity patterns r. Let I be an N (cid:2) 1 vector and r be a K (cid:2) 1 vector where N is the number
of image pixels, K is the number of fMRI voxels and t is a sample index. Both data sets are
(cid:1) I(t)
independent identically distributed (i.i.d.) samples. CCA ﬁnds linear combinations u1 (t) = a0
(cid:1) r(t) such that the correlation between u1 and v1 is maximized. The variables u1
and v1 (t) = b0
1
1
and v1 are called the ﬁrst canonical variables and the vectors a1 and b1 are called the canonical
(cid:1) I(t) and v2 (t) = b0
(cid:1) r(t) are sought
coefﬁcients. Then, the second canonical variables u2 (t) = a0
2
2
by maximizing the correlation of u2 and v2 while the second canonical variables are orthogonalized
to the ﬁrst canonical variables. This procedure is continued up to a pre-deﬁned number of times M .
The number M is conventionally set to the smaller dimension of the two sets of observations: in
our case, M = N because the number of visual-image pixels is much smaller than that of the fMRI

2

(a)(b)voxels (N < K ). The M sets of canonical variables are summarized as
u(t) = A (cid:1) I(t);
(1)
v(t) = B (cid:1) r(t);
(2)
where u(t) and v(t) are M (cid:2) 1 vectors, A is an M (cid:2) N matrix, and B is a M (cid:2) K matrix. The
matrices A and B are obtained by solving the eigen problem of the covariance matrix between I
and r [1]. The visual image can be reconstructed by
(cid:0)1 (cid:1) B (cid:1) r(t);
I(t) = A
where each column vector of the inverse matrix A(cid:0)1 is an image basis.

(3)

2.2 Bayesian CCA

jjI(t) (cid:0) WI (cid:1) z(t)jj2

Bayesian CCA introduces common latent variables that relate a visual image I and the fMRI ac-
tivity pattern r with image basis set WI and weight vector set Wr (Figure 1 (b)). These variables
are treated as random variables and prior distributions are assumed for each variable. Hyper-prior
distributions are also assumed for an inverse variance of each element of the image bases and the
weight vectors. The image bases and the weight vectors are estimated as a posterior distribution by
the variational Bayesian method [2]. After the parameters are determined, a predictive distribution
for the visual image can be calculated.
We assume two likelihood functions. One is for visual images that are generated from latent vari-
ables. The other is for fMRI activity patterns that are generated from the same latent variables.
When observation noises for visual images and fMRI voxels are assumed to follow a Gaussian dis-
[
]
T∑
tribution with zero mean and spherical covariance, the likelihood functions of the visual image I and
the fMRI activity pattern r are
P (IjWI ; z) / exp
(cid:0) 1
[
]
T∑
2 (cid:12)I
;
t=1
(cid:0) 1
P (rjWr ; z) / exp
jjr(t) (cid:0) Wr (cid:1) z(t)jj2
(5)
2 (cid:12)r
;
t=1
where WI is an N (cid:2) M matrix representing M image bases, each of which consists of N pixels,
Wr is a K (cid:2)M matrix representing M weight vectors, each of which consist of K voxels, z(t) is an
M (cid:2) 1 vector representing latent variables, (cid:12)
(cid:0)1
(cid:0)1
and (cid:12)
are scalar variables representing unknown
r
I
noise variances of the visual image and fMRI activity pattern, and T is the number of observations.
]
[
T∑
The latent variables are treated as the following Gaussian prior distribution,
jjz(t)jj2
P0 (z) / exp
(cid:0) 1
:
2
t=1
]
[
N∑
M∑
(
)2
The image bases and weight vectors are regarded as random variables, and the prior distributions of
them are assumed as,
P0 (WI j(cid:11)I ) / exp
(cid:0) 1
[
]
M∑
K∑
)2
(
WI(n;m)
;
2
m=1
n=1
(cid:0) 1
P0 (Wr j(cid:11)r ) / exp
;
2
m=1
k=1
where (cid:11)I(n;m) and (cid:11)r(k;m) are the inverse variances of the elements in WI and Wr , respectively,
∏
∏
which are assumed to be mutually independent.
We also assume hyper-prior distributions for the inverse variances (cid:11)I(n;m) and (cid:11)r(k;m) ,
∏
∏
G ((cid:11)I(n;m) j (cid:22)(cid:11)I(n;m) ; (cid:13) I(n;m) );
P0 ((cid:11)I ) =
m
n
G ((cid:11)I(k;m) j (cid:22)(cid:11)r(k;m) ; (cid:13) r(k;m) );
m
k

P0 ((cid:11)r ) =

(cid:11)r(k;m)

Wr(k;m)

(7)

(8)

(9)

(10)

(4)

(6)

(cid:11)I(n;m)

3

where G ((cid:11)j (cid:22)(cid:11); (cid:13) ) represents the Gamma distribution with mean (cid:22)(cid:11) and conﬁdence parameter (cid:13) . For
our analysis, all the means (cid:22)(cid:11)I(n;m) and (cid:22)(cid:11)r(k;m) were set to 1 and all the conﬁdence parameters
(cid:13) I(n;m) and (cid:13) r(k;m) were set to 0.
This conﬁguration of the prior and hyper-prior settings is known as the automatic relevance deter-
mination (ARD), where non-effective parameters are automatically driven to zero [7]. In the current
case, these priors and hyper-priors lead to a sparse selection of links from each latent variable to
pixels and voxels.
Prior distributions of observation noise are assumed as non-informative priors, which are described
by the observation noise,

P0 ((cid:12)I ) =

P0 ((cid:12)r ) =

1
(cid:12)I
1
(cid:12)r

;

:

(11)

(12)

2.3 Parameter estimation by the variational Bayesian method
The image bases and weight vectors are estimated as a posterior distribution P (WI ; Wr jI; r), given
the likelihood functions (Eqs. (4) and (5)), the prior distributions (Eqs. (6) - (8), (11) and (12)), and
the hyper-prior distributions (Eqs. (9) and (10)). This posterior distribution is obtained by marginal-
izing the joint posterior distribution P (WI ; Wr ; z; (cid:11)I ; (cid:11)r ; (cid:12)I ; (cid:12)r jI; r) with respect to latent vari-
∫
ables and variance parameters,
P (WI ; Wr jI; r) =

dzd(cid:11)Id(cid:11)rd(cid:12)Id(cid:12)rP (WI ; Wr ; z; (cid:11)I ; (cid:11)r ; (cid:12)I ; (cid:12)r jI; r):

(13)

Since the joint posterior distribution cannot be calculated analytically, we approximate it using a
trial distribution based on the variational Bayesian (VB) method [2].
In the VB method, a trial
distribution Q(WI ; Wr ; z; (cid:11)I ; (cid:11)r ; (cid:12)I ; (cid:12)r ) with the following factorization is assumed,
Q(WI ; Wr ; z; (cid:11)I ; (cid:11)r ; (cid:12)I ; (cid:12)r ) = Qw (WI )Qw (Wr )Qz (z)Q(cid:11) ((cid:11)I ; (cid:11)r ; (cid:12)I ; (cid:12)r ):
(14)
The joint posterior distribution P (WI ; Wr ; z; (cid:11)I ; (cid:11)r ; (cid:12)I ; (cid:12)r jI; r) is approximated by the factorized
distribution (Eq. (14)). According to the standard calculation of the VB method, the trial distribution
N∏
M∏
of the image bases Qw (WI ) is derived as
Qw (WI ) =
n=1
m=1

(cid:0)1
I(n;m) );

(15)

where

N (WI(n;m) jWI(n;m) ; (cid:27)
T∑
t=1

In (t)zm (t);

)

(16)

(17)

+ (cid:11)I(n;m) ;

(cid:27) I(n;m) = (cid:22)(cid:12)I

( T∑
(cid:0)1
WI(n;m) = (cid:22)(cid:12)I(cid:27)
I(n;m)
(cid:0)1
m (t) + T (cid:6)
z2
z(m;m)
t=1
and N (xj (cid:22)x; (cid:27)
(cid:0)1 . The trial distri-
(cid:0)1 ) represents a Gaussian distribution with mean (cid:22)x and variance (cid:27)
bution of the weight vectors Qw (Wr ) is obtained in a similar way, by replacing I with r, n with k ,
T∏
and N with K in Eqs. (15-17). The trial distribution of the latent variables Qz (z) is obtained by
N (z(t)jz(t); (cid:6)
Qz (z) =
(cid:0)1
z );
)
(
t=1
(
(
)
0
0
(cid:0)1
I I(t) + (cid:22)(cid:12)rW
(cid:22)(cid:12)IW
r r(t)
z(t) = (cid:6)
;
z
0
0
(cid:0)1
(cid:0)1
(cid:6)z = (cid:22)(cid:12)I
+ (cid:22)(cid:12)r
rWr + (cid:6)
IWI + (cid:6)
W
W
wI
wr

(19)
(20)

where

(18)

)

+ E:

4

(21)

;

1
2

(cid:6)wI = diag

([ N∑
])
N∑
In Eq. (20), E is an identity matrix, and (cid:6)wI and (cid:6)wr are deﬁned as
([ K∑
])
(cid:27) I(n;1) ; (cid:1) (cid:1) (cid:1) ;
K∑
(cid:27) I(n;M )
;
n=1
n=1
(cid:27)r(k;1) ; (cid:1) (cid:1) (cid:1) ;
(cid:6)wr = diag
(22)
(cid:27)r(k;M )
:
k=1
k=1
Finally, the distribution of the inverse variances Q(cid:11) ((cid:11)I ; (cid:11)r ; (cid:12)I ; (cid:12)r ) is further factorized into
Q(cid:11) ((cid:11)I )Q(cid:11) ((cid:11)r )Q(cid:11) ((cid:12)I )Q(cid:11) ((cid:12)r ), each having a function form equivalent to a gamma distribution.
)(
)(cid:0)1
(
The expectation of (cid:11)I(n;m) is given by

(cid:0)1
(cid:0)1
I(n;m) + (cid:13) I0(n;m)(cid:11)
I0(n;m)
)

1
(cid:22)(cid:11)I(n;m) =
(WI(n;m) )2 +
2
{
( T∑
[
T∑
and that of (cid:12)I is given by
jjI(t) (cid:0) WI (cid:22)z(t)jj2 + Tr
(cid:6)
t=1
t=1
(24)
The expectations of Q(cid:11) ((cid:11)r ) and Q(cid:11) ((cid:12)r ) are obtained in a similar way, by replacing I with r, n
with k , and N with K in Eq. (23) and Eq. (24), respectively. The expectations of these distributions
are used in the calculation of Qw (WI ), Qw (Wr ) and Qz (z) (Eqs. (15) - (20)). The algorithm
estimates the joint posterior by successive calculations of 1) Qw (WI ) and Qw (Wr ), 2) Qz (z), and
3) Q(cid:11) ((cid:11)I ; (cid:11)r ; (cid:12)I ; (cid:12)r ). After the algorithm converges, image bases WI are calculated by taking the
expectation of Q(WI ).

(23)
]}(cid:0)1

(cid:0)1
0 (t) + T (cid:6)
z

(cid:0)1
+ T (cid:6)
z W

+ (cid:13) I0(n;m)

(cid:22)(cid:12)I = N T

1
2 (cid:27)

0
IWI

:

(cid:0)1
wI

z(t)z

2.4 Predictive distribution for visual image reconstruction

(25)

Using the estimated parameters, we can derive the predictive distribution for a visual image Inew
given a new brain activity rnew (Figure 1 (b), dashed line). Note that Inew and rnew were taken
from the data set reserved for testing the model, independent of the data set to estimate the model
parameters. The predictive distribution P (Inew jrnew ) is constructed from the likelihood of the visual
image (Eq. (4)), the estimated distribution of image bases Q(WI ) (Eqs. (15) - (17)), and a posterior
∫
distribution of latent variables P (znew jrnew ) as follows,
dWIdznewP (Inew jWI ; znew )Q(WI )P (znew jrnew ):
P (Inew jrnew ) =
Because the multiple integral over the random variable WI and znew is intractable, we replace the
∫
random variable WI with the estimated image bases WI to vanish the integral over WI . Then the
predictive distribution becomes
P (Inew jrnew ) ’

dznewP (Inew jznew )P (znew jrnew );
]
[
where
(cid:22)(cid:12)I jjInew (cid:0) WIznew jj2
(cid:0) 1
P (Inew jznew ) / exp
(27)
:
2
distribution Q(z) (Eqs. (18) - (20)). We construct an approximate distribution eQz (znew ), by omit-
Since P (znew jrnew ) is an unknown distribution, we approximate P (znew jrnew ) based on the trial
eQz (znew ) = N (zj(cid:22)znew ; (cid:6)
ting the terms related to the visual image in Eqs. (18) - (20),
(cid:0)1
znew );
(28)
(
)
0
(cid:0)1
(cid:22)znew = (cid:22)(cid:12)r(cid:6)
znewW
r rnew ;
0
(cid:6)znew = (cid:22)(cid:12)r
rWr + (cid:6)
W

(29)
(30)

where

+ E:

(26)

(cid:0)1
wr

5

∫
dznewP (Inew jznew ) eQz (znew )
Finally, the predictive distribution is obtained by
P (Inew jrnew ) ’
= N (Inew j(cid:22)Inew ; (cid:6)
(cid:0)1
Inew );

where

0
(cid:0)1
(cid:22)Inew = (cid:22)(cid:12)rWI(cid:6)
znewW
r rnew ;
0
(cid:0)1
(cid:0)1
I + (cid:22)(cid:12)
(cid:6)Inew = WI(cid:6)
znewW
I E:

(31)

(32)
(33)

The reconstructed visual image is calculated by taking the expectation of the predictive distribution.

2.5

fMRI data

We used the data set from Miyawaki et al. [6], in which fMRI signals were measured while subjects
viewed visual images consisting of contrast-deﬁned 10 (cid:2) 10 patches. The data set contained two
independent sessions. One is a “random image session”, in which spatially random patterns were
sequentially presented for 6 s followed by a 6 s rest period. A total of 440 different random patterns
were presented for each subject. The other is a “ﬁgure image session”, in which alphabetical letters
and simple geometric shapes were sequentially presented for 12 s followed by a 12 s rest period.
Five alphabetical letters and ﬁve geometric shapes were presented six or eight times per subject. We
used fMRI data from V1 for the analyses. See Miyawaki et al. [6] for details.

3 Results

We estimated image bases and weight vectors using the data from the “random image session”.
Then, reconstruction performance was evaluated with the data from the “ﬁgure image session”.

3.1 Estimated image bases

Figure 2 (a) shows representative image bases estimated by Bayesian CCA (weight values are in-
dicated by a gray scale). The estimation algorithm extracted spatially localized image bases whose
shapes were consistent with those used in the previous study [6] (1 (cid:2) 1, 1 (cid:2) 2, and 2 (cid:2) 1 shown
in 1st and 2nd row of Figure 2 (a)). We also found image bases with other shapes (e.g., L-shape,
3 (cid:2) 1 and 1 (cid:2) 3, 3rd row of Figure 2 (a)) that were not assumed in the previous study. We repeated
the estimation using data resampled from the random image session, and calculated the distribution
of the image bases (deﬁned by a pixel cluster with magnitudes over 3 SD of all pixel values) over
eccentricity for different sizes (Figure 2 (a), right). The image bases of the smallest size (1 (cid:2) 1)
were distributed over the visual ﬁeld, and most of them were within three degrees of eccentricity.
The size of the image basis tended to increase with eccentricity. For comparison, we also performed
the image basis estimation using CCA, but it did not produce spatially localized image bases (Fig-
ure 2 (b)). Estimated weight vectors for fMRI voxels had high values around the retinotopic region
corresponding the location of the estimated basis (data not shown).

3.2 Visual image reconstruction using estimated image bases

The reconstruction model with the estimated image bases was tested on ﬁve alphabet letters and ﬁve
geometric shapes (Figure 3 (a), 1st row). The images reconstructed by Bayesian CCA captured the
essential features of the presented images (Figure 3 (a), 2nd row). In particular, they showed ﬁne
reconstruction for ﬁgures consisting of thin lines such as small frames and alphabet letters. However,
the peripheral reconstruction was poor and often lacked shapes of the presented images. This may
be due to the lack of estimated image bases in the peripheral regions (Figure 2 (a), right). The
standard CCA produced poorer reconstruction with noise scattered over the entire image (Figure
3 (a), 3rd row), as expected from the non-local image bases estimated by CCA (Figure 2 (b)).
Reconstruction using ﬁxed image bases [6] showed moderate accuracy for all image types (Figure
3 (a), 4th row). To evaluate the reconstruction performance quantitatively, we calculated the spatial
correlation between the presented and reconstructed images (Figure 3 (b)). The correlation values

6

Figure 2: Image basis estimation: (a) Representative bases estimated by Bayesian CCA (left,
sorted by the number of pixels), and their frequency as a function of eccentricity (right). 3-pixel
bases (L-shape, 3x1 and 1x3) were not assumed in Miyawaki et al. [6]. Negative (dark) bases were
often associated with negative voxel weights, thus equivalent to positive bases with positive voxel
weights. (b) Examples of image bases estimated by the standard CCA.

were not signiﬁcantly different between Bayesian CCA and the ﬁxed basis method when the alphabet
letters and the geometric shapes were analyzed together. However, Bayesian CCA outperformed the
ﬁxed basis method for the alphabet letters, while the ﬁxed basis method outperformed Bayesian
CCA for the geometric shapes (p < :05). This is presumably because the alphabet letters consist
of more foveal pixels, which overlap the region covered by the image bases estimated by Bayesian
CCA. The reconstruction performance of CCA was lowest in all cases.

4 Discussion

We have proposed a new method to estimate image bases from fMRI data and presented visual
stimuli. Our model consists of the latent variables and two matrices relating the two sets of obser-
vations. The previous work used ﬁxed image bases and estimated the weights between the image
bases and fMRI voxels. This estimation was conducted by the sparse logistic regression that as-
sumed sparsenes in the weight values, which effectively removed irrelevant voxels [8]. The proposed
method introduced sparseness priors not only for fMRI voxels but also for image pixels. These pri-
ors lead to automatic extraction of images bases, and the mappings between a small number of fMRI
voxels and a small number of image pixels. Using this model, we successfully extracted spatially
localized image bases including those not used in the previous work [6]. Using the set of image
bases, we were able to accurately reconstruct arbitrary contrast-deﬁned visual images from fMRI
activity patterns. The sparseness priors played an important role to estimate spatially localized im-
age bases, and to improve reconstruction performance, as demonstrated by the comparison with the
results from standard CCA (Figure 2 and 3).
Our method has several limitations. First, as the latent variables were assumed to have an orthogo-
nal Gaussian distribution, it may be difﬁcult to obtain non-orthogonal image bases, which have been

7

(a) Estimated image bases by Bayesian CCA040123456FrequencyEccentricity [deg]3x11x2L-shape00.5-0.5(b) Estimated image bases by CCA1x22x11x33-pixel basis1-pixel basis2-pixel basis040040Figure 3: Visual image reconstruction: (a) Presented images (1st row, alphabet letters and geo-
metric shapes) and the reconstructed images obtained from Bayesian CCA, the standard CCA, and
the ﬁxed basis model (2nd - 4th rows). (b) Spatial correlation between presented and reconstructed
images.

shown to provide an effective image representation in the framework of sparse coding [4, 9]. Differ-
ent types of image bases could be generated by introducing non-orthogonality and/or non-lineality
in the model. The shape of estimated image bases may also depend on the visual stimuli used for
the training of the reconstruction model. Although we used random images as visual stimuli, other
types of images including natural scenes may lead to more effective image bases that allow for ac-
curate reconstruction. Finally, our method failed to estimate peripheral image bases, and as a result,
only poor reconstruction was achieved for peripheral pixels. The cortical magniﬁcation factor of the
visual cortex [5] suggests that a small number of voxels represent a large number of image pixels in
the periphery. Elaborate assumptions about the degree of sparseness depending on eccentricity may
help to improve basis estimation and image reconstruction in the periphery.

Acknowledgments

This study was supported by the Nissan Science Foundation, SCOPE (SOUMU) and SRPBS
(MEXT).

8

Spatial CorrelationFixed bases (Miyawaki et al.)Bayesian CCA00.40.8PresentedReconstructedAllGeometricshapesAlphabetLettersGeometric shapesAlphabet letters(a)(b)CCA Bayesian CCAFixed bases (Miyawaki et al.)CCAReferences
[1] Anderson, T.W. (2003). An Introduction to Multivariate Statistical Analysis. 3rd ed. Wiley
Interscience.
[2] Attias, H. (1999). Inferring parameters and structure of latent variable models by variational
Bayes. Proc. 15th Conference on Uncertainty in Artiﬁcial Intelligence, 21-30.
[3] Bach, F.R. and Jordan, M.I. (2005). A probabilistic interpretation of canonical correlation anal-
ysis. Dept. Statist., Univ. California, Berkeley, CA, Tech. Repo. 688.
[4] Bell, A.J. and Sejnowski, T.J. (1997) The independent components of natural scenes are edge
ﬁlter. Vision Res. 27(23), 3327-3338.
[5] Engel, S.A., Glover, G.H. and Wandell, B.A. (1997) Retinotopic organization in human visual
cortex and the spatial precision of functional MRI. Cereb. Cortex 7, 181-192.
[6] Miyawaki, Y., Uchida, H., Yamashita, O., Sato, MA., Morito, Y., Tanabe, HC., Sadato, N. and
Kamitani, Y. (2008). Visual image reconstruction from human brain activity using a combina-
tion of multiscale local image decoders. Neuron 60(5), 915-929.
[7] Neal, R.M. (1996). Bayesian learning for Neural Networks. Springer-Verlag.
[8] Yamashita, O., Sato, MA., Yoshioka, T., Tong, F., Kamitani, Y. (2008) Sparse estimation au-
tomatically selects voxels relevant for the decoding of fMRI activity patterns. Neuroimage.
42(4), 1414-29.
[9] Olshausen ,B.A. and Field, D.J. (1996). Emergence of simple-cell receptive ﬁeld properties by
learning a sparse code for natural images. Nature 381, 607-609.
[10] Wang, C. (2007). Variatonal Bayesian Approach to Canonical Correlation Analysis. IEEE
Trans Neural Netw. 18(3), 905-910.

9

