Fast subtree kernels on graphs

Nino Shervashidze, Karsten M. Borgwardt
Interdepartmental Bioinformatics Group
Max Planck Institutes T ¨ubingen, Germany
{nino.shervashidze,karsten.borgwardt}@tuebingen.mpg.de

Abstract

In this article, we propose fast subtree kernels on graphs. On graphs with n nodes
and m edges and maximum degree d, these kernels comparing subtrees of height
h can be computed in O(mh), whereas the classic subtree kernel by Ramon &
G ¨artner scales as O(n2 4dh). Key to this efﬁciency is the observation that the
Weisfeiler-Lehman test of isomorphism from graph theory elegantly computes a
subtree kernel as a byproduct. Our fast subtree kernels can deal with labeled
graphs, scale up easily to large graphs and outperform state-of-the-art graph ker-
nels on several classiﬁcation benchmark datasets in terms of accuracy and runtime.

1

Introduction

Graph kernels have recently evolved into a branch of kernel machines that reaches deep into graph
mining. Several different graph kernels have been deﬁned in machine learning which can be catego-
rized into three classes: graph kernels based on walks [5, 7] and paths [2], graph kernels based on
limited-size subgraphs [6, 11], and graph kernels based on subtree patterns [9, 10].
While fast computation techniques have been developed for graph kernels based on walks [12]
and on limited-size subgraphs [11], it is unclear how to compute subtree kernels efﬁciently. As a
consequence, they have been applied to relatively small graphs representing chemical compounds [9]
or handwritten digits [1], with approximately twenty nodes on average. But could one speed up
subtree kernels to make them usable on graphs with hundreds of nodes, as they arise in protein
structure models or in program ﬂow graphs?
It is a general limitation of graph kernels that they scale poorly to large, labeled graphs with more
than 100 nodes. While the efﬁcient kernel computation strategies from [11, 12] are able to compare
unlabeled graphs efﬁciently, the efﬁcient comparison of large, labeled graphs remains an unsolved
challenge. Could one speed up subtree kernels to make them the kernel of choice for comparing
large, labeled graphs?
The goal of this article is to address both of the aforementioned questions, that is, to develop a fast
subtree kernel that scales up to large, labeled graphs.
The remainder of this article is structured as follows. In Section 2, we review the subtree kernel from
the literature and its runtime complexity. In Section 3, we describe an alternative subtree kernel and
its efﬁcient computation based on the Weisfeiler-Lehman test of isomorphism. In Section 4, we
compare these two subtree kernels to each other, as well as to a set of four other state-of-the-art
graph kernels and report results on kernel computation runtime and classiﬁcation accuracy on graph
benchmark datasets.

1

2 The Ramon-G ¨artner subtree kernel
Terminology We deﬁne a graph G as a triplet (V , E , L), where V is the set of vertices, E the set
of undirected edges, and L : V → Σ a function that assigns labels from an alphabet Σ to nodes in
the graph1 . The neighbourhood N (v) of a node v is the set of nodes to which v is connected by an
edge, that is N (v) = {v (cid:48) |(v , v (cid:48) ) ∈ E }. For simplicity, we assume that every graph has n nodes, m
edges, a maximum degree of d, and that there are N graphs in our given set of graphs.
A walk is a sequence of nodes in a graph, in which consecutive nodes are connected by an edge. A
path is a walk that consists of distinct nodes only. A (rooted) subtree is a subgraph of a graph, which
has no cycles, but a designated root node. A subtree of G can thus be seen as a connected subset
of distinct nodes of G with an underlying tree structure. The height of a subtree is the maximum
distance between the root and any other node in the graph plus one. The notion of walk is extending
the notion of path by allowing nodes to be equal. Similarly, the notion of subtrees can be extended to
subtree patterns (also called ‘tree-walks’ [1]), which can have nodes that are equal. These repetitions
of the same node are then treated as distinct nodes, such that the pattern is still a cycle-free tree. Note
that all subtree kernels compare subtree patterns in two graphs, not (strict) subtrees. Let S (G) refer
to the set of all subtree patterns in graph G.
Deﬁnition The ﬁrst subtree kernel on graphs was deﬁned by [10]. It compares all pairs of nodes
Ramon (G, G(cid:48) ) = (cid:88)
(cid:88)
from graphs G = (V , E , L) and G(cid:48) = (V (cid:48) , E (cid:48) , L(cid:48) ) by iteratively comparing their neighbourhoods:
kh (v , v (cid:48) ),
k (h)
v (cid:48)∈V (cid:48)
v∈V
(cid:81)
(cid:80)
δ(L(v), L(cid:48) (v (cid:48) )),
(w,w(cid:48) )∈R kh−1 (w, w (cid:48) ),

kh (v , v (cid:48) ) =

if h = 1
if h > 1

λr λs

R∈M(v ,v (cid:48) )

(1)

(2)

where

(cid:26)

and

M(v , v (cid:48) ) = {R ⊆ N (v) × N (v (cid:48) )|(∀(u, u(cid:48) ), (w, w (cid:48) ) ∈ R : u = w ⇔ u(cid:48) = w (cid:48) )
∧(∀(u, u(cid:48) ) ∈ R : L(u) = L(cid:48) (u(cid:48) ))}.

(3)

Intuitively, kRamon iteratively compares all matchings M(v , v (cid:48) ) between neighbours of two nodes
v from G and v (cid:48) from G(cid:48) .

Complexity The runtime complexity of the subtree kernel for a pair of graphs is O(n2h4d ), in-
cluding a comparison of all pairs of nodes (n2 ), and a pairwise comparison of all matchings in
their neighbourhoods in O(4d ), which is repeated in h iterations. h is a multiplicative factor, not an
exponent, as one can implement the subtree kernel recursively, starting with k1 and recursively com-
puting kh from kh−1 . For a dataset of N graphs, the resulting runtime complexity is then obviously
in O(N 2n2h4d ).

Related work The subtree kernels in [9] and [1] reﬁne the above deﬁnition for applications in
chemoinformatics and hand-written digit recognition. Mah ´e and Vert [9] deﬁne extensions of the
classic subtree kernel that avoid tottering [8] and consider unbalanced subtrees. Both [9] and [1]
propose to consider α-ary subtrees with at most α children per node. This restricts the set of match-
ings to matchings of up to α nodes, but the runtime complexity is still exponential in this parameter
α, which both papers describe as feasible on small graphs (with approximately 20 nodes) with many
distinct node labels. We present a subtree kernel that is efﬁcient to compute on graphs with hundreds
and thousands of nodes next.

1The extension of this deﬁnition and our results to graphs with edge labels is straightforward, but omitted
for clarity of presentation.

2

3 Fast subtree kernels

3.1 The Weisfeiler-Lehman test of isomorphism

Our algorithm for computing a fast subtree kernel builds upon the Weisfeiler-Lehman test of isomor-
phism [14], more speciﬁcally its 1-dimensional variant, also known as “naive vertex reﬁnement”,
which we describe in the following.
Assume we are given two graphs G and G(cid:48) and we would like to test whether they are isomorphic.
The 1-dimensional Weisfeiler-Lehman test proceeds in iterations, which we index by h and which
comprise the following steps:

Algorithm 1 One iteration of the 1-dimensional Weisfeiler-Lehman test of graph isomorphism
1: Multiset-label determination
• For h = 1, set Mh (v) := l0 (v) = L(v) for labeled graphs, and Mh (v) := l0 (v) =
| N (v)| for unlabeled graphs.
• For h > 1, assign a multiset-label Mh (v) to each node v in G and G(cid:48) which consists of
the multiset {lh−1 (u)|u ∈ N (v)}.
2: Sorting each multiset
• Sort elements in Mh (v) in ascending order and concatenate them into a string sh (v).
• Add lh−1 (v) as a preﬁx to sh (v).
3: Sorting the set of multisets
• Sort all of the strings sh (v) for all v from G and G(cid:48) in ascending order.
4: Label compression
• Map each string sh (v) to a new compressed label, using a function f : Σ∗ → Σ such
that f (sh (v)) = f (sh (w)) if and only if sh (v) = sh (w).
5: Relabeling
• Set lh (v) := f (sh (v)) for all nodes in G and G(cid:48) .

The sorting step 3 allows for a straightforward deﬁnition and implementation of f for the compres-
sion step 4: one keeps a counter variable for f that records the number of distinct strings that f has
compressed before. f assigns the current value of this counter to a string if an identical string has
been compressed before, but when one encounters a new string, one increments the counter by one
and f assigns its value to the new string. The sorted order from step 3 guarantees that all identical
strings are mapped to the same number, because they occur in a consecutive block.
The Weisfeiler-Lehman algorithm terminates after step 5 of iteration h if {lh (v)|v ∈ V } (cid:54)=
{lh (v (cid:48) )|v (cid:48) ∈ V (cid:48)}, that is, if the sets of newly created labels are not identical in G and G(cid:48) . The
graphs are then not isomorphic. If the sets are identical after n iterations, the algorithm stops with-
out giving an answer.

Complexity The runtime complexity of Weisfeiler-Lehman algorithm with h iterations is O(hm).
Deﬁning the multisets in step 1 for all nodes is an O(m) operation. Sorting each multiset is an
O(m) operation for all nodes. This efﬁciency can be achieved by using Counting Sort, which is an
instance of Bucket Sort, due to the limited range that the elements of the multiset are from. The
elements of each multiset are a subset of {f (sh (v))|v ∈ V }. For a ﬁxed h, the cardinality of this
set is upper-bounded by n, which means that we can sort all multisets in O(m) by the following
procedure: We assign the elements of all multisets to their corresponding buckets, recording which
multiset they came from. By reading through all buckets in ascending order, we can then extract
the sorted multisets for all nodes in a graph. The runtime is O(m) as there are O(m) elements in
the multisets of a graph in iteration h. Sorting the resulting strings is of time complexity O(m) via
the Radix Sort. The label compression requires one pass over all strings and their characters, that is
O(m). Hence all these steps result in a total runtime of O(hm) for h iterations.

3.2 The Weisfeiler-Lehman kernel on pairs of graphs

Based on the Weisfeiler-Lehman algorithm, we deﬁne the following kernel function.

3

Deﬁnition 1 The Weisfeiler-Lehman kernel on two graphs G and G(cid:48) is deﬁned as:
W L (G, G(cid:48) ) = |{(si (v), si (v (cid:48) ))|f (si (v)) = f (si (v (cid:48) )), i ∈ {1, . . . , h}, v ∈ V , v (cid:48) ∈ V (cid:48)}|,
k (h)
(4)
where f is injective and the sets {f (si (v))|v ∈ V ∪ V (cid:48)} and {f (sj (v))|v ∈ V ∪ V (cid:48)} are disjoint
for all i (cid:54)= j .

That is, the Weisfeiler-Lehman kernel counts common multiset strings in two graphs.

Theorem 2 The Weisfeiler-Lehman kernel is positive deﬁnite.

Proof Intuitively, k (h)
W L is a kernel because it counts matching subtree patterns of up to height h in
two graphs. More formally, let us deﬁne a mapping φ that counts the occurrences of a particular
label sequence s in G (generated in h iterations of Weisfeiler-Lehman). Let φ(h)
s (G) denote the
s (G(cid:48) ) for G(cid:48) . Then
number of occurrences of s in G, and analogously φ(h)
(G, G(cid:48) ) = φ(h)
s (G(cid:48) ) =
s (G)φ(h)
k (h)
s
= |{(si (v), si (v (cid:48) ))|si (v) = si (v (cid:48) ), i ∈ {1, . . . , h}, v ∈ V , v (cid:48) ∈ V (cid:48) }|,
(G, G(cid:48) ) = (cid:88)
W L (G, G(cid:48) ) = (cid:88)
and if we sum over all s from Σ∗ , we obtain
s (G(cid:48) ) =
k (h)
s (G)φ(h)
φ(h)
k (h)
s
s∈Σ∗
s∈Σ∗
= |{(si (v), si (v (cid:48) ))|si (v) = si (v (cid:48) ), i ∈ {1, . . . , h}, v ∈ V , v (cid:48) ∈ V (cid:48)}| =
= |{(si (v), si (v (cid:48) ))|f (si (v)) = f (si (v (cid:48) )), i ∈ {1, . . . , h}, v ∈ V , v (cid:48) ∈ V (cid:48)}|,
where the last equality follows from the fact that f is injective.
As f (s) (cid:54)= s and hence each string s corresponds to exactly one subtree pattern t, k (h)
W L deﬁnes a
kernel with corresponding feature map φ(h)
W L , such that
s (G))s∈Σ∗ = (φ(h)
φ(h)
W L (G) = (φ(h)
t

(G))t∈S (G) .

(5)

(6)

(7)

Theorem 3 The Weisfeiler-Lehman kernel on a pair of graphs G and G(cid:48) can be computed in
O(hm).

Proof This follows directly from the deﬁnition of the Weisfeiler-Lehman kernel and the runtime
complexity of the Weisfeiler-Lehman test, as described in Section 3.1. The number of match-
ing multiset strings can be counted as part of step 3, as they occur consecutively in the sorted order.

3.3 The Weisfeiler-Lehman kernel on N graphs

For computing the Weisfeiler-Lehman kernel on N graphs we propose the following algorithm
which improves over the naive, N 2 -fold application of the kernel from (4). We now process all
N graphs simultaneously and conduct the steps given in the Algorithm 2 in each of h iterations on
each graph G.
The hash function g can be implemented efﬁciently: it again keeps a counter variable x which counts
the number of distinct strings that g has mapped to compressed labels so far. If g is applied to a string
that is different from all previous ones, then the string is mapped to x + 1, and x increments. As
before, g is required to keep sets of compressed labels from different iterations disjoint.
Theorem 4 For N graphs, the Weisfeiler-Lehman kernel on all pairs of these graphs can be com-
puted in O(N hm + N 2hn).
Proof Naive application of the kernel from deﬁnition (4) for computing an N × N kernel matrix
would require a runtime of O(N 2hm). One can improve upon this runtime complexity by comput-
ing φ(h)
W L explicitly. This can be achieved by replacing the compression mapping f in the classic
Weisfeiler-Lehman algorithm by a hash function g that is applied to all N graphs simultaneously.

4

Algorithm 2 One iteration of the Weisfeiler-Lehman kernel on N graphs
1: Multiset-label determination
• Assign a multiset-label Mh (v) to each node v in G which consists of the multiset
{lh−1 (u)|u ∈ N (v)}.
2: Sorting each multiset
• Sort elements in Mh (v) in ascending order and concatenate them into a string sh (v).
• Add lh−1 (v) as a preﬁx to sh (v).
3: Label compression
• Map each string sh (v) to a compressed label using a hash function g : Σ∗ → Σ such
that g(sh (v)) = g(sh (w)) if and only if sh (v) = sh (w).
4: Relabeling
• Set lh (v) := g(sh (v)) for all nodes in G.

This has the following effects on the runtime of Weisfeiler-Lehman: Step 1, the multiset-label de-
termination, still requires O(N m). Step 2, the sorting of the elements in each multiset can be done
via a joint Bucket Sort (Counting Sort) of all strings, requiring O(N n + N m) time. The use of the
hash function g renders the sorting of all strings unnecessary (Step 3 from Section 3.1), as identical
strings will be mapped to the same (compressed) label anyway. Step 4 and Step 5 remain unchanged.
The effort of computing φ(h)
W L on all N graphs in h iterations is then O(N hm), assuming that
m > n. To get all pairwise kernel values we have to multiply all feature vectors, which requires a
runtime of O(N 2hn), as each graph G has at most hn non-zero entries in φ(h)
W L (G).

3.4 Link to the Ramon-G ¨artner kernel

ki (v , v (cid:48) ),

and

(8)

(9)

ki−1 (v , v (cid:48) ) maxR∈M(v ,v (cid:48) )

where
ki (v , v (cid:48) ) =

if i = 1
if i > 1 and M (cid:54)= ∅
if i > 1 and M = ∅

The Weisfeiler-Lehman kernel can be deﬁned in a recursive fashion which elucidates its relation to
the Ramon-G ¨artner kernel.
(cid:88)
(cid:88)
h(cid:88)
Theorem 5 The kernel k (h)
recursive deﬁned as
recursive (G, G(cid:48) ) =
k (h)

v∈V
v (cid:48)∈V (cid:48)
i=1
(cid:81)
δ(L(v), L(cid:48) (v (cid:48) )),
(w,w(cid:48) )∈R ki−1 (w, w (cid:48) ),
0,
M(v , v (cid:48) ) = {R ⊆ N (v) × N (v (cid:48) )|(∀(u, u(cid:48) ), (w, w (cid:48) ) ∈ R : u = w ⇔ u(cid:48) = w (cid:48) )
∧(∀(u, u(cid:48) ) ∈ R : L(u) = L(cid:48) (u(cid:48) ) ∧ |R| = | N (v)| = | N (v (cid:48) )|)}
is equivalent to the Weisfeiler-Lehman kernel k (h)
W L .
Proof We prove this theorem by induction over h. Induction initialisation: h = 1:
= (cid:88)
(cid:88)
W L = |{(s1 (v), s1 (v (cid:48) ))|f (s1 (v)) = f (s1 (v (cid:48) )), v ∈ V , v (cid:48) ∈ V (cid:48)}| =
k (1)
δ(L(v), L(cid:48) (v (cid:48) )) = k (1)
recursive .
v (cid:48)∈V (cid:48)
v∈V
The equality follows from the deﬁnition of M(v , v (cid:48) ).
(cid:88)
recursive = (cid:88)
(cid:88)
(cid:88)
h(cid:88)
Induction step h → h + 1: Assume that k (h)
W L = k (h)
recursive . Then
kh+1 (v , v (cid:48) ) +
k (h+1)
v∈V
v (cid:48)∈V (cid:48)
v∈V
v (cid:48)∈V (cid:48)
i=1
= |{(sh+1 (v), sh+1 (v (cid:48) ))|f (sh+1 (v)) = f (sh+1 (v (cid:48) )), v ∈ V , v (cid:48) ∈ V (cid:48)}| + k (h)
W L = k (h+1)
W L ,

ki (v , v (cid:48) ) =

(10)

(11)
(12)

(13)

(14)

5

Figure 1: Runtime in seconds for kernel matrix computation on synthetic graphs using the pairwise
(red, dashed) and the global (green) Weisfeiler-Lehman kernel (Default values: dataset size N = 10,
graph size n = 100, subtree height h = 5, graph density c = 0.4).

where the equality of (13) and (14) follows from the fact that kh+1 (v , v (cid:48) ) = 1 if and only if the
neigborhoods of v and v (cid:48) are identical, that is if f (sh+1 (v)) = f (sh+1 (v (cid:48) )).
Theorem 5 highlights the following differences between the Weisfeiler-Lehman and the Ramon-
G ¨artner kernel: In (8), Weisfeiler-Lehman considers all subtrees up to height h and the Ramon-
G ¨artner kernel the subtrees of exactly height h. In (9) and (10), the Weisfeiler-Lehman kernel checks
whether the neighbourhoods of v and v (cid:48) match exactly, whereas the Ramon-G ¨artner kernel considers
all pairs of matching subsets of the neighbourhoods of v and v (cid:48) in (3). In our experiments, we next
examine the empirical differences between these two kernels in terms of runtime and prediction
accuracy on classiﬁcation benchmark datasets.

4 Experiments

4.1 Runtime behaviour of Weisfeiler-Lehman kernel

Methods We empirically compared the runtime behaviour of our two variants of the Weisfeiler-
Lehman (WL) kernel. The ﬁrst variant computes kernel values pairwise in O(N 2hm). The second
variant computes the kernel values in O(N hm + N 2hn) on the dataset simultaneously. We will
refer to the former variant as the ‘pairwise’ WL, and the latter as ‘global’ WL.

Experimental setup We assessed the behaviour on randomly generated graphs with respect to
four parameters: dataset size N , graph size n, subtree height h and graph density c. The density
of an undirected graph of n nodes without self-loops is deﬁned as the number of its edges divided
by n(n − 1)/2, the maximal number of edges. We kept 3 out of 4 parameters ﬁxed at their default
values and varied the fourth parameter. The default values we used were 10 for N , 100 for n, 5 for
h and 0.4 for the graph density c. In more detail, we varied N and n in range {10, 100, 1000}, h in
{2, 4, 8} and c in {0.1, 0.2, . . . , 0.9}.
For each individual experiment, we generated N graphs with n nodes, and inserted edges randomly
until the number of edges reached (cid:98)cn(n − 1)/2(cid:99). We then computed the pairwise and the global

6

10110210310!1100101102103104105Number of graphs NRuntime in seconds02004006008001000050100150200250300350400Graph size nRuntime in seconds  234567805101520Subtree height hRuntime in seconds0.10.20.30.40.50.60.70.80.905101520Graph density cRuntime in secondspairwiseglobalWL kernel on these synthetic graphs. We report CPU runtimes in seconds in Figure 1, as measured
in Matlab R2008a on an Apple MacPro with 3.0GHz Intel 8-Core with 16GB RAM.

Results Empirically, we observe that the pairwise kernel scales quadratically with dataset size N .
Interestingly, the global kernel scales linearly with N . The N 2 sparse vector multiplications that
have to be performed for kernel computation with global WL do not dominate runtime here. This
result on synthetic data indicates that the global WL kernel has attractive scalability properties for
large datasets.
When varying the number of nodes n per graph, we observe that the runtime of global WL scales
linearly with n, and is much faster than the pairwise WL for large graphs.
We observe the same picture for the height h of the subtree patterns. The runtime of both kernels
grows linearly with h, but the global WL is more efﬁcient in terms of runtime in seconds.
Varying the graph density c, both methods show again a linearly increasing runtime, although the
runtime of the global WL kernel is close to constant. The density c seems to be a graph property
that affects the runtime of the pairwise kernel more severely than that of global WL.
Across all different graph properties, the global WL kernel from Section 3.3 requires less runtime
than the pairwise WL kernel from Section 3.2. Hence the global WL kernel is the variant of our
Weisfeiler-Lehman kernel that we use in the following graph classiﬁcation tasks.

4.2 Graph classiﬁcation

Datasets We employed the following datasets in our experiments: MUTAG, NCI1, NCI109, and
D&D. MUTAG [3] is a dataset of 188 mutagenic aromatic and heteroaromatic nitro compounds
labeled according to whether or not they have a mutagenic effect on the Gram-negative bacterium
Salmonella typhimurium. We also conducted experiments on two balanced subsets of NCI1 and
NCI109, which classify compounds based on whether or not they are active in an anti-cancer screen
([13] and http://pubchem.ncbi.nlm.nih.gov). D&D is a dataset of 1178 protein struc-
tures [4]. Each protein is represented by a graph, in which the nodes are amino acids and two nodes
are connected by an edge if they are less than 6 Angstroms apart. The prediction task is to classify
the protein structures into enzymes and non-enzymes.

Experimental setup On these datasets, we compared our Weisfeiler-Lehman kernel to the Ramon-
G ¨artner kernel (λr = λs = 1), as well as to several state-of-the-art graph kernels for large graphs:
the fast geometric random walk kernel from [12] that counts common labeled walks (with λ chosen
from the set {10−2 , 10−3 , . . . , 10−6} by cross-validation on the training set), the graphlet kernel
from [11] that counts common induced labeled connected subgraphs of size 3, and the shortest path
kernel from [2] that counts pairs of labeled nodes with identical shortest path distance.
We performed 10-fold cross-validation of C-Support Vector Machine Classiﬁcation, using 9 folds
for training and 1 for testing. All parameters of the SVM were optimised on the training dataset
only. To exclude random effects of fold assignments, we repeated the whole experiment 10 times.
We report average prediction accuracies and standard errors in Tables 1 and 2.
We choose h for our Weisfeiler-Lehman kernel by cross-validation on the training dataset for h ∈
{1, . . . , 10}, which means that we computed 10 different WL kernel matrices in each experiment.
We report the total runtime of this computation (not the average per kernel matrix).

Results
In terms of runtime the Weisfeiler-Lehman kernel can easily scale up even to graphs with
thousands of nodes. On D&D, subtree-patterns of height up to 10 were computed in 11 minutes,
while no other comparison method could handle this dataset in less than half an hour. The shortest
path kernel is competitive to the WL kernel on smaller graphs (MUTAG, NCI1, NCI109), but on
D&D its runtime degenerates to more than 23 hours. The Ramon and G ¨artner kernel was computable
on MUTAG in approximately 40 minutes, but for the large NCI datasets it only ﬁnished computation
on a subsample of 100 graphs within two days. On D&D, it did not even ﬁnish on a subsample of
100 graphs within two days. The random walk kernel is competitive on MUTAG, but as the Ramon-
G ¨artner kernel, does not ﬁnish computation on the full NCI datasets and on D&D within two days.
The graphlet kernel is faster than our WL kernel on MUTAG and the NCI datasets, and about a

7

NCI1
Method/Dataset MUTAG
82.19 (± 0.18)
82.05 (±0.36)
Weisfeiler-Lehman
85.72 (±0.49) —-
Ramon & G ¨artner
75.61 (±0.49)
66.00 (±0.07)
Graphlet count
80.72 (±0.38) —-
Random walk
73.47 (±0.11)
87.28 (±0.55)
Shortest path

D & D
NCI109
79.78 (±0.36)
82.46 (±0.24)
—-
—-
78.59 (±0.12)
66.59 (±0.08)
—-
—-
73.07 (±0.11)
78.45 (±0.26)
—-: did not ﬁnish in 2 days.
Table 1: Prediction accuracy (± standard error) on graph classiﬁcation benchmark datasets

Dataset MUTAG
28
Maximum # nodes
17.93
Average # nodes
# labels
7
188
Number of graphs
6”
Weisfeiler-Lehman
Ramon & G ¨artner
40’6”
3”
Graphlet count
Random walk
12”
2”
Shortest path

NCI1
111
29.87
37

100
5”
25’9”
2”
58’30”
3”

NCI109
111
29.68
54

D & D
5748
284.32
89

1178
100
4127
100
11’
58”
7’21”
5”
31 days∗
—-
—-
26’40”
30’21”
2’40”
1’27”
2”
153 days∗
—-
—-
2h 9’41”
3”
23h 17’2”
58’45”
4’39”
—-: did not ﬁnish in 2 days, * = extrapolated.
Table 2: CPU runtime for kernel computation on graph classiﬁcation benchmark datasets

4110
7’20”
29 days∗
1’27”
68 days∗
4’38”

factor of 3 slower on D&D. However, this efﬁciency comes at a price, as the kernel based on size-3
graphlets turns out to lead to poor accuracy levels on three datasets. Using larger graphlets with 4
or 5 nodes that might have been more expressive led to infeasible runtime requirements in initial
experiments (not shown here).
On NCI1, NCI109 and D&D, the Weisfeiler-Lehman kernel reached the highest accuracy. On D&D
the shortest path and graphlet kernels yielded similarly good results, while on NCI1 and NCI109 the
Weisfeiler-Lehman kernel improves by more than 8% the best accuracy attained by other methods.
On MUTAG, it reaches the third best accuracy among all methods considered. We could not assess
the performance of the Ramon & G ¨artner kernel and the random walk kernel on larger datasets,
as their computation did not ﬁnish in 48 hours. The labeled size-3 graphlet kernel achieves low
accuracy levels, except on D&D.
To summarize, the WL kernel turns out to be competitive in terms of runtime on all smaller datasets,
fastest on the large protein dataset, and its accuracy levels are highest on three out of four datasets.

5 Conclusions

We have deﬁned a fast subtree kernel on graphs that combines scalability with the ability to deal
with node labels. It is competitive with state-of-the-art kernels on several classiﬁcation benchmark
datasets in terms of accuracy, even reaching the highest accuracy level on three out of four datasets,
and outperforms them signiﬁcantly in terms of runtime on large graphs, even the efﬁcient computa-
tion schemes for random walk kernels [12] and graphlet kernels [11] that were recently deﬁned.
This new kernel opens the door to applications of graph kernels on large graphs in bioinformatics, for
instance, protein function prediction via detailed graph models of protein structure on the amino acid
level, or on gene networks for phenotype prediction. An exciting algorithmic question for further
studies will be to consider kernels on graphs with continuous or high-dimensional node labels and
their efﬁcient computation.

Acknowledgements

The authors would like to thank Kurt Mehlhorn, Pascal Schweitzer, and Erik Jan van Leeuwen for
fruitful discussions.

8

References
[1] F. R. Bach. Graph kernels between point clouds. In ICML, pages 25–32, 2008.
[2] K. M. Borgwardt and H.-P. Kriegel. Shortest-path kernels on graphs. In Proc. Intl. Conf. Data
Mining, pages 74–81, 2005.
[3] A. K. Debnath, R. L. Lopez de Compadre, G. Debnath, A. J. Shusterman, and C. Hansch.
Structure-activity relationship of mutagenic aromatic and heteroaromatic nitro compounds.
correlation with molecular orbital energies and hydrophobicity. J Med Chem, 34:786–797,
1991.
[4] P. D. Dobson and A. J. Doig. Distinguishing enzyme structures from non-enzymes without
alignments. J Mol Biol, 330(4):771–783, Jul 2003.
[5] T. G ¨artner, P.A. Flach, and S. Wrobel. On graph kernels: Hardness results and efﬁcient alter-
natives. In B. Sch ¨olkopf and M. Warmuth, editors, Sixteenth Annual Conference on Computa-
tional Learning Theory and Seventh Kernel Workshop, COLT. Springer, 2003.
[6] T. Horvath, T. G ¨artner, and S. Wrobel. Cyclic pattern kernels for predictive graph mining. In
Proceedings of the International Conference on Knowledge Discovery and Data Mining, 2004.
[7] H. Kashima, K. Tsuda, and A. Inokuchi. Marginalized kernels between labeled graphs. In
Proceedings of the 20th International Conference on Machine Learning (ICML), Washington,
DC, United States, 2003.
[8] P. Mah ´e, N. Ueda, T. Akutsu, J.-L. Perret, and J.-P. Vert. Extensions of marginalized graph
kernels. In Proceedings of the Twenty-First International Conference on Machine Learning,
2004.
[9] P. Mah ´e and J.-P. Vert. Graph kernels based on tree patterns for molecules. q-bio/0609024,
September 2006.
[10] J. Ramon and T. G ¨artner. Expressivity versus efﬁciency of graph kernels. Technical report, First
International Workshop on Mining Graphs, Trees and Sequences (held with ECML/PKDD’03),
2003.
[11] N. Shervashidze, S.V.N. Vishwanathan, T. Petri, K. Mehlhorn, and K. M. Borgwardt. Efﬁcient
graphlet kernels for large graph comparison. In Artiﬁcial Intelligence and Statistics, 2009.
[12] S. V. N. Vishwanathan, Karsten Borgwardt, and Nicol N. Schraudolph. Fast computation
In B. Sch ¨olkopf, J. Platt, and T. Hofmann, editors, Advances in Neural
of graph kernels.
Information Processing Systems 19, Cambridge MA, 2007. MIT Press.
[13] N. Wale and G. Karypis. Comparison of descriptor spaces for chemical compound retrieval
and classiﬁcation. In Proc. of ICDM, pages 678–689, Hong Kong, 2006.
[14] B. Weisfeiler and A. A. Lehman. A reduction of a graph to a canonical form and an algebra
arising during this reduction. Nauchno-Technicheskaya Informatsia, Ser. 2, 9, 1968.

9

