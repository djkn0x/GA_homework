DUOL: A Double Updating Approach for
Online Learning

Rong Jin
Dept. of Comp. Sci. & Eng.
Michigan State University
East Lansing, MI, 48824
rongjin@cse.msu.edu

Peilin Zhao
School of Comp. Eng.
Nanyang Tech. University
Singapore 639798
zhao0106@ntu.edu.sg

Steven C.H. Hoi
School of Comp. Eng.
Nanyang Tech. University
Singapore 639798
chhoi@ntu.edu.sg
Abstract
In most online learning algorithms, the weights assigned to the misclassiﬁed ex-
amples (or support vectors) remain unchanged during the entire learning process.
This is clearly insufﬁcient since when a new misclassiﬁed example is added to
the pool of support vectors, we generally expect it to affect the weights for the
existing support vectors. In this paper, we propose a new online learning method,
termed Double Updating Online Learning, or DUOL for short. Instead of only
assigning a ﬁxed weight to the misclassiﬁed example received in current trial, the
proposed online learning algorithm also tries to update the weight for one of the
existing support vectors. We show that the mistake bound can be signiﬁcantly im-
proved by the proposed online learning method. Encouraging experimental results
show that the proposed technique is in general considerably more effective than
the state-of-the-art online learning algorithms.
1 Introduction

Online learning has been extensively studied in the machine learning community (Rosenblatt, 1958;
Freund & Schapire, 1999; Kivinen et al., 2001a; Crammer et al., 2006). Most online learning
algorithms work by assigning a ﬁxed weight to a new example when it is misclassiﬁed. As a result,
the weights assigned to the misclassiﬁed examples, or support vectors, remain unchanged during the
entire process of learning. This is clearly insufﬁcient because when a new example is added to the
pool of support vectors, we expect it to affect the weights assigned to the existing support vectors
received in previous trials.
Although several online algorithms are capable of updating the example weights as the learning
process goes, most of them are designed for the purposes other than improving the classiﬁcation
accuracy and reducing the mistake bound. For instance, in (Orabona et al., 2008; Crammer et al.,
2003; Dekel et al., 2005), online learning algorithms are proposed to adjust the example weights
in order to ﬁt in the constraint of ﬁxed number of support vectors; in (Cesa-Bianchi & Gentile,
2006), example weights are adjusted to track the drifting concepts. In this paper, we propose a new
formulation for online learning that aims to dynamically update the example weights in order to
improve the classiﬁcation accuracy as well as the mistake bound. Instead of only assigning a weight
to the misclassiﬁed example that is received in current trial, the proposed online learning algorithm
also updates the weight for one of the existing support vectors. As a result, the example weights
are dynamically updated as learning goes. We refer to the proposed approach as Double Updating
Online Learning, or DUOL for short.
The key question in the proposed online learning approach is which one of the existing support vec-
tors should be selected for weight updating. To this end, we employ an analysis for double updating
online learning that is based on the recent work of online convex programming by incremental dual
ascent (Shalev-Shwartz & Singer, 2006). Our analysis shows that under certain conditions, the pro-
posed online learning algorithm can signiﬁcantly reduce the mistake bound of the existing online
algorithms. This result is further veriﬁed empirically by extensive experiments and comparison to
the state-of-the-art algorithms for online learning.

1

The rest of this paper is organized as follows. Section 2 reviews the related work for online learning.
Section 3 presents the proposed “double updating” approach to online learning. Section 4 gives our
experimental results. Section 5 sets out the conclusion and addresses some future work.
2 Related Work
Online learning has been extensively studied in machine learning (Rosenblatt, 1958; Crammer &
Singer, 2003; Cesa-Bianchi et al., 2004; Crammer et al., 2006; Fink et al., 2006; Yang et al., 2009).
One of the most well-known online approaches is the Perceptron algorithm (Rosenblatt, 1958; Fre-
und & Schapire, 1999), which updates the learning function by adding a new example with a constant
weight into the current set of support vectors when it is misclassiﬁed. Recently a number of online
learning algorithms have been developed based on the criterion of maximum margin (Crammer &
Singer, 2003; Gentile, 2001; Kivinen et al., 2001b; Crammer et al., 2006; Li & Long, 1999). One
example is the Relaxed Online Maximum Margin algorithm (ROMMA) (Li & Long, 1999), which
repeatedly chooses the hyper-planes that correctly classify the existing training examples with the
maximum margin. Another representative example is the Passive-Aggressive (PA) method (Cram-
mer et al., 2006). It updates the classiﬁcation function when a new example is misclassiﬁed or its
classiﬁcation score does not exceed some predeﬁned margin. Empirical studies showed that the
maximum margin based online learning algorithms are generally more effective than the Perceptron
algorithm. However, despite the difference, most online learning algorithms only update the weight
of the newly added support vector, and keep the weights of the existing support vectors unchanged.
This constraint could signiﬁcantly limit the effect of online learning.
Besides the studies for regular online learning, several algorithms are proposed for online learning
with ﬁxed budget. In these studies, the total number of support vectors is required to be bounded
either by a theoretical bound or by a manually ﬁxed budget. Example algorithms for ﬁxed budget
online learning include (Weston & Bordes, 2005; Crammer et al., 2003; Cavallanti et al., 2007;
Dekel et al., 2008). The key idea of these algorithms is to dynamically update the weights of the
existing support vectors as a new support vector is added, and the support vector with the least weight
will be discarded when the number of support vectors exceeds the budget. The idea of discarding
support vectors is also used in studies (Kivinen et al., 2001b) and (Cheng et al., 2006). In a very
recently proposed method (Orabona et al., 2008), a new “projection” approach is proposed for online
learning that ensures the number of support vectors is bounded. Besides, in (Cesa-Bianchi & Gentile,
2006), an online learning algorithm is proposed to handle the drifting concept, in which the weights
of the existing support vectors are reduced whenever a new support vector is added. Although these
online learning algorithms are capable of dynamically adjusting the weights of support vectors, they
are designed to either ﬁt in the budget of the number of support vectors or to handle drifting concepts,
not to improve the classiﬁcation accuracy and the mistake bound.
The proposed online learning algorithm is closely related to the recent work of online convex pro-
gramming by incremental dual ascent (Shalev-Shwartz & Singer, 2006). Although the idea of si-
multaneously updating the weights of multiple support vectors was mentioned in (Shalev-Shwartz
& Singer, 2006), no efﬁcient updating algorithm was explicitly proposed. As will be shown later, the
online algorithm proposed in this work shares the same computational cost as that of conventional
online learning algorithms, despite the need of updating weights of two support vectors.
3 Double Updating to Online Learning
3.1 Motivation
We consider an online learning trial t with an incoming example that is misclassiﬁed. Let κ(·, ·) :
Rd × Rd → R be the kernel function used in our classiﬁer. Let D = {(xi , yi ), i = 1, . . . , n}
be the collection of n misclassiﬁed examples received before the trial t, where xi ∈ Rd and yi ∈
{−1, +1}. We also refer to these misclassiﬁed training examples as “support vectors”. We denote
by α = (α1 , . . . , αn ) ∈ [0, C ]n the weights assigned to the support vectors in D , where C is a
n(cid:88)
predeﬁned constant. The resulting classiﬁer, denoted by f (x), is expressed as
i=1
Let (xa , ya ) be the misclassiﬁed example received in the trial t, i.e., ya f (xa ) ≤ 0. In the conven-
tional approach for online learning, we simply assign a constant weight, denoted by β , to (xa , ya ),

αi yiκ(x, xi )

f (x) =

(1)

2

αi yiκ(x, xi ) = β yaκ(x, xa ) + f (x)

(2)

and the resulting classiﬁer becomes
f (cid:48) (x) = β yaκ(x, xa ) +

n(cid:88)
i=1
The shortcoming with the conventional online learning approach is that the introduction of the new
support vector (xa , ya ) may harm the classiﬁcation of existing support vectors in D , which is re-
(cid:80)n
vealed by the following proposition.
Proposition 1. Let (xa , ya ) be an example misclassiﬁed by the current classiﬁer f (x) =
i=1 αi yiκ(x, xi ), i.e., ya f (xa ) < 0. Let f (cid:48) (x) = β yaκ(x, xa ) + f (x) be the updated classi-
ﬁer with β > 0. There exists at least one support vector xi ∈ D such that yi f (xi ) > yi f (cid:48) (xi ).
Proof. It follows from the fact that: ∃xi ∈ D , yi yaκ(xi , xa ) < 0 when ya f (xa ) < 0.

As indicated by the above proposition, when a new misclassiﬁed example is added to the classi-
ﬁer, the classiﬁcation conﬁdence of at least one support vector will be reduced. In the case when
ya f (xa ) ≤ −γ , it is easy to verify that there exists some support vector (xb , yb ) who satisﬁes
β ya ybk(xa , xb ) ≤ −γ /n; at the meantime, it can be shown that when the classiﬁcation conﬁdence
of (xb , yb ) is less than γ /n, i.e., yb f (xb ) ≤ γ /n, such support vector will be misclassiﬁed after
the classiﬁer is updated with the example (xa , ya ). In order to alleviate this problem, we propose
to update the weight for the existing support vector whose classiﬁcation conﬁdence is signiﬁcantly
affected by the new misclassiﬁed example. In particular, we consider a support vector (xb , yb ) ∈ D
for weight updating if it satisﬁes the following two conditions
• yb f (xb ) ≤ 0, i.e., support vector (xb , yb ) is misclassiﬁed by the current classiﬁer f (x)
• k(xb , xa )ya yb ≤ −ρ where ρ ≥ 0 is a predeﬁned threshold, i.e., support vector (xb , yb )
“conﬂicts” with the new misclassiﬁed example (xa , ya ).
We refer to the support vector satisfying the above conditions as auxiliary example. It is clear that
by adding the misclassiﬁed example (xa , ya ) to classiﬁer f (x) with weight β , the classiﬁcation score
of (xb , yb ) will be reduced by at least β ρ, which could lead to the misclassiﬁcation of the auxiliary
example (xb , yb ). To avoid such a mistake, we propose to update the weights for both (xa , ya ) and
(xb , yb ) simultaneously. In the next section, we show the details of the double updating algorithm
for online learning, and the analysis for mistake bound.
Our analysis follows closely the previous work on the relationship between online learning and
the dual formulation of SVM (Shalev-Shwartz & Singer, 2006), in which the online learning is
interpreted as an efﬁcient updating rule for maximizing the objective function in the dual form of
SVM. We denote by ∆t the improvement of the objective function in dual SVM when adding a new
misclassiﬁed example to the classiﬁcation function in the t-th trial. If an online learning algorithm A
(cid:195)
(cid:33)
is designed to ensure that all ∆t is bounded from the below by a positive constant ∆, then the number
T(cid:88)
of mistakes made by A when trained over a sequence of trials (x1 , y1 ), . . . , (xT , yT ), denoted by
M , is upper bounded by:
M ≤ 1
1
(cid:107)f (cid:107)2Hκ + C
min
(cid:96)(yi f (xi ))
(3)
f ∈Hκ
∆
2
i=1
where (cid:96)(yi f (xi )) = max(0, 1 − yi f (xi )) is the hinge loss function. In our analysis, we will show
that ∆, which is referred to as the bounding constant for the improvement in the objective function,
could be signiﬁcantly improved when updating the weight for both the newly misclassiﬁed example
and the auxiliary example.
For the remaining part of this paper, we denote by (xb , yb ) an auxiliary example that satisﬁes the two
conditions speciﬁed before. We slightly abuse the notation by using α = (α1 , . . . , αn−1 )) ∈ Rn−1
to denote the weights assigned to all the support vectors in D except (xb , yb ). Similarly, we denote
by y = (y1 , . . . , yn−1 ) ∈ [−1, 1]n−1 the class labels assigned to all the examples in D except for
(xb , yb ). We deﬁne
note by (cid:98)γb the weight for the auxiliary example (xb , yb ) that is used in the current classiﬁer f (x), and
sa = κ(xa , xa ), sb = κ(xb , xb ), sab = κ(xa , xb ), wab = ya yb sab .
(4)
According to the assumption of auxiliary example, we have wab = sab ya yb ≤ −ρ. Finally, we de-
by γa and γb the updated weights for (xa , ya ) and (xb , yb ), respectively. Throughout the analysis,
we assume κ(x, x) ≤ 1 for any example x.

3

(6)

(7)

+

1
2

(cid:107)ft (cid:107)2
Hκ

+C

3.2 Double Updating Online Learning
Recall an auxiliary example (xb , yb ) should satisfy two conditions (I) yb f (xb ) ≤ 0, and (II) wab ≤
−ρ. In addition, the new example (xa , ya ) received in the current iteration t is misclassiﬁed, i.e.,
ya f (xa ) ≤ 0. Following the framework of dual formulation for online learning, the following
lemma shows how to compute ∆t , i.e., the improvement in the objective function of dual SVM by
adjusting weights for (xa , ya ) and (xb , yb ).
Lemma 1. The maximal improvement in the objective function of dual SVM by adjusting weights
{h(γa , ∆γb ) : 0 ≤ γa ≤ C, 0 ≤ ∆γb ≤ C − (cid:98)γb }
for (xa , ya ) and (xb , yb ), denoted by ∆t , is computed by solving the following optimization problem:
∆t = max
(5)
γa ,∆γb
where
b − wabγa∆γb
a − sb
h(γa , ∆γb ) = γa (1 − ya f (xa )) + ∆γb (1 − yb f (xb )) − sa
(cid:80)t
∆γ 2
2 γ 2
2
2 (cid:107)ft(cid:107)2Hκ
i=1 (cid:96)(yi ft (xi )),
1

Proof. It is straightforward to verify that the dual function of min
ft∈Hκ
γi − t(cid:88)
t(cid:88)
denoted by Dt (γ1 , . . . , γt ), is computed as follows,
1
(cid:80)t
(cid:107)ft(cid:107)2
γi yi ft (xi ) +
Dt (γ1 , . . . , γt ) =
2
Hκ
h(γa , ∆γb ) = Dt (γ1 , . . . , (cid:98)γb + ∆γb , . . . , γt−1 , γa ) − Dt−1 (γ1 , . . . , (cid:98)γb , . . . , γt−1 )
i=1
i=1
where 0 ≤ γi ≤ C, i = 1, . . . , t and ft (·) =
i=1 γi yiκ(·, xi ) is the current classiﬁer. Thus,
(cid:33)
(cid:195)
t−1(cid:88)
t−1(cid:88)
(cid:33)
(cid:195)
γi + ∆γb + γa −
=
γi yi ft (xi ) + ∆γb yb ft (xb ) + γa ya ft (xa )
γi − t−1(cid:88)
t−1(cid:88)
i=1
i=1
−
i=1
i=1
Using the relation ft (x) = ft−1 (x) + ∆γb ybκ(x, xb ) + γa yaκ(x, xa ), we have
h(γa , ∆γb ) = γa (1 − ya ft−1 (xa )) + ∆γb (1 − yb ft−1 (xb )) − sa
b − wabγa∆γb
a − sb
∆γ 2
2 γ 2
constraint that the weight for example (xb , yb ) is in the range [0, C ], i.e., (cid:98)γb + ∆γb ∈ [0, C ]. To this
2
Finally, we need to show ∆γb ≥ 0. Note that this constraint does not come directly from the box
end, we consider the part of h(γa , ∆γb ) that is related to ∆γb , i.e.,
g(∆γb ) = ∆γb (1 − yb ft−1 (xb ) − wabγa ) − sb
∆γ 2
2
b
Since wab ≤ −ρ and yb ft−1 (xb ) ≤ 0, it is clear that ∆γb ≥ 0 when maximizing g(∆γb ), which
results in the constraint ∆γb ≥ 0.
Theorem 1. Assume C > (cid:98)γb + 1/(1 − ρ) for the selected auxiliary example (xb , yb ). We have the
The following theorem shows the bound for ∆ when C is sufﬁciently large.
following bound for ∆
∆ ≥ 1
(8)
1 − ρ
Proof. Using the fact sa , sb ≤ 1, γa , ∆γb ≥ 0, ya f (xa ) ≤ 0, yb f (xb ) ≤ 0, and wa,b ≤ −ρ, we
have
a − 1
h(γa , ∆γb ) ≥ γa + ∆γb − 1
2 γ 2
2
Thus, ∆ is bounded as
γb∈[0,C ],∆γb∈[0,C−(cid:98)γ ]
γa + ∆γb − 1
∆ ≥
a + ∆γ 2
(γ 2
max
b ) + ργa∆γb
2
Under the condition that C > ˆγb + 1/(1 − ρ), it is easy to verify that the optimal solution for the
above problem is γa = ∆γb = 1/(1 − ρ), which leads to the result in the theorem.

∆γ 2
b + ργa∆γb

γi yi ft−1 (xi ) +

(cid:107)ft−1 (cid:107)2
Hκ

1
2

4

We now consider the general case, where we only assume C ≥ 1. The following theorem shows the
bound for ∆ in the general case.
Theorem 2. Assume C ≥ 1. We have the following bound for ∆, when updating the weights for the
(1 + ρ)2 , (C − (cid:98)γ )2 (cid:162)
(cid:161)
new example (xa , ya ) and the auxiliary example (xb , yb )
1
∆ ≥ 1
2
2
Proof. By setting γa = 1, we have h(γa , ∆γb ) computed as
+ (1 + ρ)∆γb − 1
h(γa = 1, ∆γb ) ≥ 1
(cid:181)
(cid:182)
2
2
Hence, ∆ is lower bounded by
∆γb∈[0,C−(cid:98)γ ]
(1 + ρ)∆γb − 1
∆ ≥ 1
max
2
2

∆γ 2
b
(1 + ρ)2 , (C − (cid:98)γ )2 (cid:162)
(cid:161)

≥ 1
2

∆γ 2
b

min

min

1
2

+

+

+

Since we only have ∆ ≥ 1/2 if we only update the weight for the new misclassiﬁed example
(xa , ya ), the result in theorem 2 indicates an increase in ∆ when updating the weight for both
(xa , ya ) and the auxiliary example (xb , yb ). Furthermore, when C is sufﬁciently large, as indicated
by Theorem 1, the improvement in ∆ can be very signiﬁcant.
The ﬁnal remaining question is how to identify the auxiliary example (xb , yb ) efﬁciently, which
requires efﬁciently updating the classiﬁcation score yi f (xi ) for all the support vectors. To this
end, we introduce a variable for each support vector, denoted by f i
t , to keep track the classiﬁ-
cation score. When a new support vector (xa , ya ) with weight γa is added to the classiﬁer, we
t ← f i
t−1 + yiγa yaκ(xi , xa ), and when the weight of
t−1 by f i
update the classiﬁcation score f i
an auxiliary example (xb , yb ) is updated from ˆγb to γb , we update the classiﬁcation score f i
t−1 by
t−1 + yi (γb − ˆγb )ybκ(xi , xb ).This updating procedure ensures that the computational cost of
t ← f i
f i
double updating online learning is O(n), where n is the number of support vectors, similar to that
of the kernel online learning algorithm. Figure 1 shows the details of the DUOL algorithm.
Finally, we show a bound on the number of mistakes by assuming C is sufﬁciently large.
Theorem 3. Let (x1 , y1 ), . . . , (xT , yT ) be a sequence of examples, where xt ∈ Rn , yt ∈ {−1, +1}
and κ(xt , xt ) ≤ 1 for all t. And assume C is sufﬁciently large. Then for any function f in Hκ , the
(cid:195)
(cid:33)
T(cid:88)
number of prediction mistakes M made by DUOL on this sequence of examples is bounded by:
− 1 + ρ
(cid:107)f (cid:107)2Hκ + C
min
1 − ρ
f ∈Hκ
i=1
where Md (ρ) is the number of mistakes when there is an auxiliary example, which depends on the
threshold ρ and the dataset (Md (ρ) is actually a decreasing function with ρ).
(cid:33)
(cid:195)
Proof. We denote by Ms the number of mistakes when we made a single update without ﬁnding
T(cid:88)
appropriate auxiliary example. Using Theorem 1, we have the following inequality,
1
1
1
(cid:107)f (cid:107)2Hκ + C
2 Ms +
min
1 − ρ
f ∈Hκ
2
(cid:195)
(cid:33)
i=1
T(cid:88)
Plugging M = Ms + Md into the equation above, we can get
(cid:107)f (cid:107)2Hκ + C
min
f ∈Hκ
i=1

− 1 + ρ
1 − ρ

Md (ρ) ≤

(cid:96)(yi f (xi ))

(cid:96)(yi f (xi ))

(cid:96)(yi f (xi ))

M ≤ 2

M ≤ 2

Md (ρ)

Md (ρ)

1
2

1
2

(9)

(10)

(11)

It is worthwhile pointing out that although according to Theorem 3, it seems that the larger the value
of ρ the smaller the mistake bound will be. This however is not true since Md (ρ) is in general a
monotonically decreasing function in ρ. As a result, it is unclear if Md (ρ) × (1 + ρ)/(1 − ρ) will
increase when ρ is increased.
5

24:
25:
26:
27:
28:
29:
30:
31:
32:
33:
ft = ft−1 ; St = St−1 ;
34:
for ∀i ∈ St do
35:
t ← f i
f i
t−1 ;
36:
end for
37:
end if
38:
39: end for

else

20:
21:
22:
23:

1
1−ρ );
γt = min(C,
γb = min(C, ˆγb + 1
1−ρ );
for ∀i ∈ St do
t ← f i
f i
t−1 + yi γt yt k(xi , xt )
+ yi (γb − ˆγb )yb k(xi , xb );
end for
ft = ft−1 + γt yt k(xt , ·) + (γb − ˆγb )yb k(xb , ·);
else /* no auxiliary example found */
γt = min(C, 1);
for ∀i ∈ St do
t ← f i
f i
t−1 + yi γt yt k(xi , xt );
end for
ft = ft−1 + γt yt k(xt , ·);
end if

Algorithm 1 The DUOL Algorithm (DUOL)
PROC EDUR E
Initialize S0 = ∅, f0 = 0;
1:
for t=1,2,. . . ,T do
2:
Receive new instance xt
3:
Predict ˆyt = sign(ft−1 (xt ));
4:
5:
Receive label yt ;
lt = max{0, 1 − yt ft−1 (xt )}
6:
if lt > 0 then
7:
8:
wmin = 0
for ∀i ∈ St−1 do
9:
t−1 ≤ 0) then
if (f i
10:
if (yi yt k(xi , xt ) < wmin ) then
11:
12:
wmin = yi yt k(xi , xt );
(xb , yb ) = (xi , yi );/*auxiliary example*/
13:
end if
14:
end if
15:
end for
16:
f t
t−1 = yt ft−1 (xt );
17:
St = St−1 ∪ {t};
18:
if (wmin ≤ −ρ) then
19:
Figure 1: The Algorithm of Double Updating Online Learning (DUOL).
4 Experimental Results
4.1 Experimental Testbed and Setup
We now evaluate the empirical performance of the proposed double updating online learning
(DUOL) algorithm. We compare DUOL with a number of state-of-the-art techniques, including
Perceptron (Rosenblatt, 1958; Freund & Schapire, 1999), the “ROMMA” algorithm and its aggres-
sive version “agg-ROMMA” (Li & Long, 1999), the ALMAp (α) algorithm (Gentile, 2001), and the
Passive-Aggressive algorithms (“PA”) (Crammer et al., 2006). The original Perceptron algorithm
was proposed for learning linear models. In our experiments, we follow (Kivinen et al., 2001b) by
adapting it to the kernel case. Two versions of PA algorithms (PA-I and PA-II) were implemented as
described in (Crammer et al., 2006). Finally, as an ideal yardstick, we also implement a full online
SVM algorithm (“Online-SVM”) (Shalev-Shwartz & Singer, 2006), which updates all the support
vectors in each trial, and is thus computationally extremely intensive as will be revealed in our study.
To extensively examine the performance, we test all the algorithms on a number of benchmark
datasets from web machine learning repositories. All of the datasets can be downloaded from LIB-
SVM website 1 , UCI machine learning repository 2 and MIT CBCL face datasets 3 . Due to space
limitation, we randomly choose six of them in our discussions, including “german”, “splice”, “spam-
base”, “MITFace”, “a7a”, and “w7a”.
To make a fair comparison, all algorithms adopt the same experimental setup. In particular, for all
the compared algorithms, we set the penalty parameter C = 5, and employ the same Gaussian kernel
with σ = 8. For the ALMAp (α) algorithm, parameter p and α are set to be 2 and 0.9, respectively,
based on our experience. For the proposed DUOL algorithm, we ﬁx ρ to be 0.2 for all cases.
All the experiments were conducted over 20 random permutations for each dataset. All the results
were reported by averaging over these 20 runs. We evaluate the online learning performance by mea-
suring mistake rate, i.e., the ratio of the number of mistakes made by the online learning algorithm
over the total number of examples received for predictions. In addition, to examine the sparsity of
the resulting classiﬁers, we also evaluate the number of support vectors produced by each online
learning algorithm. Finally, we also evaluate computational efﬁciency of all the algorithms by their
running time (in seconds). All experiments were run in Matlab over a machine of 2.3GHz CPU.
4.2 Performance Evaluation
Table 1 to 6 summarize the performance of all the compared algorithms over the six datasets4 ,
respectively. Figure 2 to 6 show the mistake rates of all online learning algorithms in comparison
over trials. We observe that Online-SVM yields considerably better performance than the other
online learning algorithms for dataset “german”, “splice”, “spambase”, and “MITFace”, however,
at the price of extremely high computational cost. For most cases, the running time of Online-SVM
is two order, sometimes three order, higher than the other online learning algorithms, making it

1http://www.csie.ntu.edu.tw/˜cjlin/libsvmtools/datasets/
2http://www.ics.uci.edu/˜mlearn/MLRepository.html
3http://cbcl.mit.edu/software-datasets
4Due to huge computational cost, we are unable to obtain the results of Online-SVM on two large datasets.

6

unsuitable for online learning. For the remaining part of this section, we restrict our discussion to
the other six baseline online learning algorithms.
First, among the six baseline algorithms in comparison, we observe that the agg-ROMMA and two
PA algorithms (PA-I and PA-II) perform considerably better than the other three algorithms (i.e.,
Perceptron, ROMMA, and ALMA) in most cases. We also notice that the agg-ROMMA and the
two PA algorithms consume considerably larger numbers of support vectors than the other three
algorithms. We believe this is because the agg-ROMMA and the two PA algorithms adopt more
aggressive strategies than the other three algorithms, resulting more updates and better classiﬁcation
performance. For the convenience of discussion, we refer to agg-ROMMA and two PA algorithms
as aggressive algorithms, and the three algorithms as non-aggressive ones.
Second, comparing with all six competing algorithms, we observe that DUOL achieves signiﬁcantly
smaller mistake rates than the other single-updating algorithms in all cases. This shows that the
proposed double updating approach is effective in improving the online prediction performance.
By examining the sparsity of resulting classiﬁers, we observed that DUOL results in sparser clas-
siﬁers than the three aggressive online learning algorithms, and denser classiﬁers than the three
non-aggressive algorithms.
Third, according to the results of running time, we observe that DUOL is overall efﬁcient compared
to the state-of-the-art online learning algorithms. Among all the compared algorithms, Percep-
tron, for its simplicity, is clearly the most efﬁcient algorithm, and the agg-ROMMA algorithm is
signiﬁcantly slower than the others (except for “Online-SVM”). Although DUOL requires double
updating, its efﬁciency is comparable to the PA and ROMMA algorithms.
Table 2: Evaluation on splice (n=1000, d=6).
Table 1: Evaluation on german (n=1000, d=24).
Time (s)
Support Vectors (#)
Mistakes (%)
Algorithm
Time (s)
Support Vectors (#)
Mistake (%)
Algorithm
271.20 ± 9.75
27.120 ± 0.975
353.05 ± 15.10
35.305 ± 1.510
0.016
Perceptron
0.018
Perceptron
255.60 ± 8.14
25.560 ± 0.814
351.05 ± 11.89
35.105 ± 1.189
0.055
ROMMA
0.154
ROMMA
33.350 ± 1.287
643.25 ± 12.31
22.980 ± 0.780
602.95 ± 7.43
0.803
agg-ROMMA
1.068
agg-ROMMA
34.025 ± 0.910
402.00 ± 7.33
26.040 ± 0.965
314.95 ± 9.41
0.075
ALMA2 (0.9)
0.225
ALMA2 (0.9)
33.670 ± 1.278
732.60 ± 9.74
23.815 ± 1.042
665.60 ± 5.60
PA-I
0.029
PA-I
0.028
689.00 ± 7.85
23.515 ± 1.005
757.00 ± 10.02
33.175 ± 1.229
0.028
PA-II
0.030
PA-II
28.860 ± 0.651
646.10 ± 5.00
17.455 ± 0.518
614.90 ± 2.92
12.243
Online-SVM
16.097
Online-SVM
29.990 ± 1.033
682.50 ± 12.87
20.560 ± 0.566
577.85 ± 8.93
DUOL
DUOL
0.089
0.076
Table 3: Evaluation on spambase (n=4601, d=57).
Table 4: Evaluation on MITFace (n=6977, d=361).
Algorithm
Mistake (%)
Support Vectors (#)
Time (s)
Algorithm
Mistake (%)
Support Vectors (#)
Time (s)
325.50 ± 13.37
4.665 ± 0.192
1149.65 ± 24.17
24.987 ± 0.525
0.164
Perceptron
0.204
Perceptron
287.05 ± 10.84
4.114 ± 0.155
1102.10 ± 23.44
23.953 ± 0.510
0.362
ROMMA
10.128
ROMMA
1121.15 ± 24.18
3.137 ± 0.093
2550.60 ± 27.32
21.242 ± 0.384
11.074
agg-ROMMA
95.028
agg-ROMMA
400.10 ± 10.53
4.467 ± 0.169
1550.15 ± 15.65
23.579 ± 0.411
0.675
ALMA2 (0.9)
25.294
ALMA2 (0.9)
1155.45 ± 14.53
3.190 ± 0.128
2861.50 ± 24.36
22.112 ± 0.374
0.356
PA-I
0.490
PA-I
21.907 ± 0.340
3029.10 ± 24.69
3.108 ± 0.112
1222.05 ± 13.73
0.370
PA-II
0.505
PA-II
17.138 ± 0.321
2396.95 ± 10.57
1.142 ± 0.073
520.05 ± 4.55
Online-SVM
Online-SVM
2521.665
7238.105
19.438 ± 0.432
2528.55 ± 20.57
2.409 ± 0.161
768.65 ± 16.18
DUOL
0.985
DUOL
0.384
Table 6: Results on w7a (n=24292, d=300).
Table 5: Evaluation on a7a (n=16100, d=123).
Time (s)
Support Vectors (#)
Mistake (%)
Algorithm
Time (s)
Support Vectors (#)
Mistake (%)
Algorithm
994.40 ± 23.57
4.027 ± 0.095
3545.50 ± 32.49
22.022 ± 0.202
1.233
Perceptron
2.043
Perceptron
21.297 ± 0.272
3428.85 ± 43.77
4.158 ± 0.087
1026.75 ± 21.51
13.860
ROMMA
306.793
ROMMA
20.832 ± 0.234
4541.30 ± 109.39
3.500 ± 0.061
2317.70 ± 58.92
137.975
661.632
agg-ROMMA
agg-ROMMA
20.096 ± 0.214
3571.05 ± 40.38
3.518 ± 0.071
1031.05 ± 15.33
ALMA2 (0.9)
ALMA2 (0.9)
338.609
13.245
2839.60 ± 41.57
3.701 ± 0.057
6760.70 ± 47.89
21.826 ± 0.239
3.732
PA-I
4.296
PA-I
21.478 ± 0.237
7068.40 ± 51.32
3.571 ± 0.053
3391.50 ± 51.94
4.719
PA-II
4.536
PA-II
19.389 ± 0.227
7089.85 ± 38.93
2.771 ± 0.041
1699.80 ± 22.78
DUOL
10.122
DUOL
2.677
5 Conclusions
This paper presented a novel “double updating” approach to online learning named as “DUOL”,
which not only updates the weight of the newly added support vector, but also adjusts the weight
of one existing support vector that seriously conﬂicts with the new support vector. We show that
the mistake bound for an online classiﬁcation task can be signiﬁcantly reduced by the proposed
DUOL algorithms. We have conducted an extensive set of experiments by comparing with a number
of competing algorithms. Promising empirical results validate the effectiveness of our technique.
Future work will address issues of multi-class double updating online learning.
Acknowledgements
This work was supported in part by MOE tier-1 Grant (RG67/07), NRF IDM Grant (NRF2008IDM-IDM-004-
018), National Science Foundation (IIS-0643494), and US Navy Research Ofﬁce (N00014-09-1-0663).

7

(a) average rate of mistakes
(b) average number of support vectors
(c) average time cost (log10 t)
Figure 2: Evaluation on the german dataset. The data size is 1000 and the dimensionality is 24.

(a) average rate of mistakes

(c) average time cost (log10 t)
Figure 3: Evaluation on the splice dataset. The data size is 1000 and the dimensionality is 60.

(b) average number of support vectors

(a) average rate of mistakes

(c) average time cost (log10 t)
Figure 4: Evaluation on the spambase dataset. The data size is 4601 and the dimensionality is 57.

(b) average number of support vectors

(a) average rate of mistakes

(c) average time cost (log10 t)
Figure 5: Evaluation on the a7a dataset. The data size is 16100 and the dimensionality is 123.

(b) average number of support vectors

(a) average rate of mistakes

(c) average time cost (log10 t)
Figure 6: Evaluation on the w7a dataset. The data size is 24292 and the dimensionality is 300.

(b) average number of support vectors

8

020040060080010000.250.30.350.40.450.5Number of samplesOnline average rate of mistakes  PerceptronROMMAagg−ROMMAALMA2(0.9)PA−IPA−IIOnline−SVMDUOL020040060080010000100200300400500600700800Number of samplesOnline average number of support vectors  PerceptronROMMAagg−ROMMAALMA2(0.9)PA−IPA−IIOnline−SVMDUOL02004006008001000−3−2−10123Number of samplesaverage time cost (log10 t)  PerceptronROMMAagg−ROMMAALMA2(0.9)PA−IPA−IIOnline−SVMDUOL020040060080010000.20.250.30.350.40.450.5Number of samplesOnline average rate of mistakes  PerceptronROMMAagg−ROMMAALMA2(0.9)PA−IPA−IIOnline−SVMDUOL020040060080010000100200300400500600700Number of samplesOnline average number of support vectors  PerceptronROMMAagg−ROMMAALMA2(0.9)PA−IPA−IIOnline−SVMDUOL02004006008001000−3−2−10123Number of samplesaverage time cost (log10 t)  PerceptronROMMAagg−ROMMAALMA2(0.9)PA−IPA−IIOnline−SVMDUOL0100020003000400050000.160.180.20.220.240.260.280.30.320.340.36Number of samplesOnline average rate of mistakes  PerceptronROMMAagg−ROMMAALMA2(0.9)PA−IPA−IIOnline−SVMDUOL0100020003000400050000500100015002000250030003500Number of samplesOnline average number of support vectors  PerceptronROMMAagg−ROMMAALMA2(0.9)PA−IPA−IIOnline−SVMDUOL010002000300040005000−3−2−1012345678Number of samplesaverage time cost (log10 t)  PerceptronROMMAagg−ROMMAALMA2(0.9)PA−IPA−IIOnline−SVMDUOL02000400060008000100001200014000160000.190.20.210.220.230.240.250.260.270.28Number of samplesOnline average rate of mistakes  PerceptronROMMAagg−ROMMAALMA2(0.9)PA−IPA−IIDUOL0200040006000800010000120001400016000010002000300040005000600070008000Number of samplesOnline average number of support vectors  PerceptronROMMAagg−ROMMAALMA2(0.9)PA−IPA−IIDUOL0200040006000800010000120001400016000−2−101234Number of samplesaverage time cost (log10 t)  PerceptronROMMAagg−ROMMAALMA2(0.9)PA−IPA−IIDUOL00.511.522.5x 1040.0250.030.0350.040.0450.050.0550.06Number of samplesOnline average rate of mistakes  PerceptronROMMAagg−ROMMAALMA2(0.9)PA−IPA−IIDUOL00.511.522.5x 1040500100015002000250030003500Number of samplesOnline average number of support vectors  PerceptronROMMAagg−ROMMAALMA2(0.9)PA−IPA−IIDUOL00.511.522.5x 104−2−1.5−1−0.500.511.522.533.5Number of samplesaverage time cost (log10 t)  PerceptronROMMAagg−ROMMAALMA2(0.9)PA−IPA−IIDUOLReferences
Cavallanti, G., Cesa-Bianchi, N., & Gentile, C. (2007). Tracking the best hyperplane with a simple
budget perceptron. Machine Learning, 69, 143–167.
Cesa-Bianchi, N., Conconi, A., & Gentile, C. (2004). On the generalization ability of on-line learn-
ing algorithms. IEEE Trans. on Inf. Theory, 50, 2050–2057.
Cesa-Bianchi, N., & Gentile, C. (2006). Tracking the best hyperplane with a simple budget percep-
tron. COLT (pp. 483–498).
Cheng, L., Vishwanathan, S. V. N., Schuurmans, D., Wang, S., & Caelli, T. (2006). Implicit online
learning with kernels. NIPS (pp. 249–256).
Crammer, K., Dekel, O., Keshet, J., Shalev-Shwartz, S., & Singer, Y. (2006). Online passive-
aggressive algorithms. JMLR, 7, 551–585.
Crammer, K., Kandola, J. S., & Singer, Y. (2003). Online classiﬁcation on a budget. NIPS.
Crammer, K., & Singer, Y. (2003). Ultraconservative online algorithms for multiclass problems.
JMLR, 3, 951–991.
Dekel, O., Shalev-Shwartz, S., & Singer, Y. (2005). The forgetron: A kernel-based perceptron on a
ﬁxed budget. NIPS.
Dekel, O., Shalev-Shwartz, S., & Singer, Y. (2008). The forgetron: A kernel-based perceptron on a
budget. SIAM J. Comput., 37, 1342–1372.
Fink, M., Shalev-Shwartz, S., Singer, Y., & Ullman, S. (2006). Online multiclass learning by inter-
class hypothesis sharing. ICML (pp. 313–320).
Freund, Y., & Schapire, R. E. (1999). Large margin classiﬁcation using the perceptron algorithm.
Mach. Learn., 37, 277–296.
Gentile, C. (2001). A new approximate maximal margin classiﬁcation algorithm. JMLR, 2, 213–242.
Kivinen, J., Smola, A. J., & Williamson, R. C. (2001a). Online learning with kernels. NIPS (pp.
785–792).
Kivinen, J., Smola, A. J., & Williamson, R. C. (2001b). Online learning with kernels. NIPS (pp.
785–792).
Li, Y., & Long, P. M. (1999). The relaxed online maximum margin algorithm. NIPS (pp. 498–504).
Orabona, F., Keshet, J., & Caputo, B. (2008). The projectron: a bounded kernel-based perceptron.
ICML (pp. 720–727).
Rosenblatt, F. (1958). The perceptron: A probabilistic model for information storage and organiza-
tion in the brain. Psychological Review, 65, 386–407.
Shalev-Shwartz, S., & Singer, Y. (2006). Online learning meets optimization in the dual. COLT (pp.
423–437).
Weston, J., & Bordes, A. (2005). Online (and ofﬂine) on an even tighter budget. AISTATS (pp.
413–420).
Yang, L., Jin, R., & Ye, J. (2009). Online learning by ellipsoid method. ICML (p. 145).

9

