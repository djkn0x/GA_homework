Bilinear classiﬁers for visual recognition

Hamed Pirsiavash
Charless Fowlkes
Deva Ramanan
Department of Computer Science
University of California at Irvine
{hpirsiav,dramanan,fowlkes}@ics.uci.edu

Abstract

We describe an algorithm for learning bilinear SVMs. Bilinear classiﬁers are a
discriminative variant of bilinear models, which capture the dependence of data
on multiple factors. Such models are particularly appropriate for visual data that
is better represented as a matrix or tensor, rather than a vector. Matrix encod-
ings allow for more natural regularization through rank restriction. For example,
a rank-one scanning-window classiﬁer yields a separable ﬁlter. Low-rank mod-
els have fewer parameters and so are easier to regularize and faster to score at
run-time. We learn low-rank models with bilinear classiﬁers. We also use bi-
linear classiﬁers for transfer learning by sharing linear factors between different
classiﬁcation tasks. Bilinear classiﬁers are trained with biconvex programs. Such
programs are optimized with coordinate descent, where each coordinate step re-
quires solving a convex program - in our case, we use a standard off-the-shelf
SVM solver. We demonstrate bilinear SVMs on difﬁcult problems of people de-
tection in video sequences and action classiﬁcation of video sequences, achieving
state-of-the-art results in both.

1

Introduction

Linear classiﬁers (i.e., wT x > 0) are the basic building block of statistical prediction. Though quite
standard, they produce many competitive approaches for various prediction tasks. We focus here
on the task of visual recognition in video - “does this spatiotemporal window contain an object”?
In this domain, scanning-window templates trained with linear classiﬁcation yield state of the art
performance on many benchmark datasets [6, 10, 7].
Bilinear models, introduced into the vision community by [23], provide an interesting generalization
of linear models. Here, data points are modelled as the conﬂuence of a pair of factors. Typical ex-
amples include digits affected by style and content factors or faces affected by pose and illumination
factors. Conditioned on one factor, the model is linear in the other. More generally, one can deﬁne
multilinear models [25] that are linear in one factor conditioned on the others.
Inspired by the success of bilinear models in data modeling, we introduce discriminative bilinear
models for classiﬁcation. We describe a method for training bilinear (multilinear) SVMs with bi-
convex (multiconvex) programs. A function f : X × Y → R is called biconvex if f (x, y) is convex
in y for ﬁxed x ∈ X and is convex in x for ﬁxed y ∈ Y . Such functions are well-studied in
the optimization literature [1, 14]. While not convex, they admit efﬁcient coordinate descent algo-
rithms that solve a convex program at each step. We show bilinear SVM classiﬁers can be optimized
with an off-the-shelf linear SVM solver. This is advantageous because we can leverage large-scale,
highly-tuned solvers (we use [13]) to learn bilinear classiﬁers with tens of thousands of features with
hundreds of millions of examples.
While bilinear models are often motivated from the perspective of increasing the ﬂexibility of a
linear model, our motivation is reversed - we use them to reduce the number of parameters of a

1

Figure 1: Many approaches for visual recognition employ linear classiﬁers on scanned windows.
Here we illustrate windows processed into gradient-based features [6, 12]. We show an image
window (left) and a visualization of the extracted HOG descriptor (middle), which itself is better
represented as gradient features extracted from different orientation channels (right). Most learning
formulations ignore this natural representation of visual data as matrices or tensors. Wolf et al. [26]
show that one can produce more meaningful schemes for regularization and parameter reduction
through low-rank approximations of a tensor model. Our contribution involves casting the resulting
learning problem as a biconvex optimization. Such formulations can leverage off-the-shelf solvers
in an efﬁcient two-stage optimization. We also demonstrate that bilinear models have additional
advantages for transfer learning and run-time efﬁciency.

weight vector that is naturally represented as a matrix or tensor W . We reduce parameters by
factorizing W into a product of low-rank factors. This parameter reduction can reduce over-ﬁtting
and improve run-time efﬁciency because fewer operations are needed to score an example. These are
important considerations when training large-scale spatial or spatiotemporal template-classiﬁers. In
our case, the state-of-the-art features we use to detect pedestrians are based on histograms of gradient
(HOG) features [6] or spatio-temporal generalizations [7] as shown in Fig.1. The extracted feature
set of both gradient and optical ﬂow histogram is quite large, motivating the need for dimensionality
reduction.
Finally, by sharing factors across different classiﬁcation problems, we introduce a novel formulation
of transfer learning. We believe that transfer through shared factors is an important beneﬁt of
multilinear classiﬁers which can help ameliorate overﬁtting.
We begin with a discussion of related work in Sec.2. We then explicitly deﬁne our bilinear classiﬁer
in Sec. 3. We illustrate several applications and motivations for the bilinear framework in Sec. 4.
In Sec. 5, We describe extensions to our model for the multilinear and multiclass case. We provide
several experiments on visual recognition in the video domain in Sec. 6, signiﬁcantly improving on
the state-of-the-art system for ﬁnding people in video sequences [7] both in performance and speed.
We also illustrate our approach on the task of action recognition, showing that transfer learning can
ameliorate the small-sample problem that plagues current benchmark datasets [18, 19].

2 Related Work

Tenenbaum and Freeman [23] introduced bilinear models into the vision community to model data
generated from multiple linear factors. Such methods have been extended to the multilinear set-
ting, e.g. by [25], but such models were generally used as a factor analysis or density estimation
technique. Recent work has explored extensions of tensor models to discriminant analysis [22, 27],
while our work focuses on an efﬁcient max-margin formulation of multilinear models.
There is also a body of related work on learning low-rank matrices from the collaborative ﬁlter-
√
ing literature [21, 17, 16]. Such approaches typically deﬁne a convex objective by replacing the
Tr(W T W ) regularization term in our objective (6) with the trace norm Tr(
W T W ). This can be
seen as an alternate “soft” rank restriction on W that retains convexity. This is because the trace
norm of a matrix is equivalent to the sum of its singular values rather than the number of nonzero
eigenvalues (the rank) [3]. Such a formulation would be interesting to pursue in our scenario, but as
[17, 16] note, the resulting SDP is difﬁcult to solve. Our approach, though non-convex, leverages
existing SVM solvers in the inner loop of a coordinate descent optimization that enforces a hard
low-rank condition.

2

Our bilinear-SVM formulation is closely related to the low-rank SVM formulation of [26]. Wolf
et. al. convincingly argue that many forms of visual data are better modeled as matrices rather than
vectors - an important motivation for our work (see Fig.1). They analyze the VC dimension of rank
constrained linear classiﬁers and demonstrate an iterative weighting algorithm for approximately
solving an SVM problem in which the rank of W acts as a regularizer. They also outline an algo-
rithm similar to the one we propose here which has a hard constraint on the rank, but they include an
additional orthogonality constraint on the columns of the factors that compose W . This requires cy-
cling through each column separately during the optimization which is presumably slower and may
introduce additional local minima. This in turn may explain why they did not present experimental
results for their hard-rank formulation.
Our work also stands apart from Wolf et. al. in our focus on the multi-task learning, which dates
back at least to the work of Caruna [4]. Our formulation is most similar to that of Ando and Zhang
[2]. They describe a procedure for learning linear prediction models for multiple tasks with the
assumption that all models share a component living in a common low-dimensional subspace. While
this formulation allows for sharing, it does not reduce the number of model parameters as does our
approach of sharing factors.

3 Model deﬁnition

Linear predictors are of the form

fw (x) = wT x.
(1)
Existing formulations of linear classiﬁcation typically treat x as a vector. We argue for many prob-
lems, particularly in visual recognition, x is more naturally represented as a matrix or tensor. For
example, many state-of-the-art window scanning approaches train a classiﬁer deﬁned over local
feature vectors extracted over a spatial neighborhood. The Dalal and Triggs detector [6] is a partic-
ularly popular pedestrian detector where x is naturally represented as a concatenation of histogram
of gradient (HOG) feature vectors extracted from a spatial grid of ny × nx , where each local HOG
descriptor is itself composed of nf features. In this case, it is natural to represent an example x
as a tensor X ∈ Rny ×nx×nf . For ease of exposition, we develop the mathematics for a simpler
matrix representation, ﬁxing nf = 1. This holds, for example, when learning templates deﬁned on
grayscale pixel values.
We generalize (1) for a matrix X with

fW (X ) = Tr(W T X ).
(2)
where both X and W are ny × nx matrices. One advantage of the matrix representation is that it
is more natural to regularize W and restrict the number of parameters. For example, one natural
mechanism for reducing the degrees of freedom in a matrix is to reduce its rank. We show that one
can obtain a biconvex objective function by enforcing a hard restriction on the rank. Speciﬁcally,
we enforce the rank of W to be at most d ≤ min(ny , nx ). This restriction can be implemented by
writing
Wy ∈ Rny ×d , Wx ∈ Rnx×d .
W = WyW T
where
x
This allows us to write the ﬁnal predictor explicitly as the following bilinear function:
x X ) = Tr(W T
(X ) = Tr(WyW T
y XWx ).
fWy ,Wx

(3)

(4)

3.1 Learning
Assume we are given a set of training data and label pairs {xn , yn}. We would like to learn a model
with low error on the training data. One successful approach is a support vector machine (SVM).
We can rewrite the linear SVM formulation for w and xn with matrices W and Xn using the trace
(cid:88)
operator.
max(0, 1 − ynwT xn ).
(cid:88)
n
Tr(W T W ) + C
n

1
2 wT w + C
1
2

max(0, 1 − yn Tr(W T Xn )).

L(W ) =

(5)

(6)

L(w) =

3

The above formulations are identical when w and xn are the vectorized elements of matrices W and
Xn . Note that (6) is convex. We wish to restrict the rank of W to be d. Plugging in W = WyW T
x ,
(cid:88)
we obtain our biconvex objective function:
1
L(Wy , Wx ) =
Tr(WxW T
y WyW T
2
x
n

max(0, 1 − yn Tr(WxW T
y Xn )).

) + C

(7)

In the next section, we show that optimizing (7) over one matrix holding the other ﬁxed is a convex
program - speciﬁcally, a QP equivalent to a standard SVM. This makes (7) biconvex.

3.2 Coordinate descent

L(Wy , Wx ) =

We can optimize (7) with a coordinate descent algorithm that solves for one set of parameters holding
the other ﬁxed. Each step in this descent is a convex optimization that can be solved with a standard
SVM solver. Speciﬁcally, consider
(cid:88)
max(0, 1 − yn Tr(W T
min
y XnWx )).
Wy
n
The above optimization is convex in Wy but does not directly translate into the trace-based SVM
(cid:88)
formulation from (6). To do so, let us reparametrize Wy as ˜Wy :
1
max(0, 1 − yn Tr( ˜W T
L( ˜Wy , Wx ) =
Tr( ˜W T
˜Wy ) + C
min
2
y
y
˜Wy
n
˜Xn = XnWxA− 1
˜Wy = Wy A
2

Tr(Wy AW T
y

A = W T
x Wx .

1
2

and

˜Xn ))

(9)

1
2

) + C

(8)

where

and

One can see that (9) is structurally equivalent to (6) and hence (5). Hence it can be solved with
a standard off-the-shelf SVM solver. Given a solution, we can recover the original parameters by
x Wx is matrix of size d × d that is in general invertible for
Wy = ˜Wy A− 1
2 . Recall that A = W T
small d. Using a similar derivation, one can show that minWx L(Wy , Wx ) is also equivalent to a
standard convex SVM formulation.

4 Motivation

We outline here a number of motivations for the biconvex objective function deﬁned above.

4.1 Regularization

Bilinear models allow a natural way of restricting the number of parameters in a linear model. From
this perspective, they are similar to approaches that apply PCA for dimensionality reduction prior
to learning. Felzenszwalb et al.
[11] ﬁnd that PCA can reduce the size of HOG features by a
factor of 4 without a loss in performance. Image windows are naturally represented as a 3D tensor
X ∈ Rny ×nx×nf , where nf is the dimensionality of a HOG feature. Let us “reshape” X into a 2D
matrix X ∈ Rnxy ×nf where nxy = nxny . We can restrict the rank of the corresponding model
f . Wxy ∈ Rnxy ×d is equivalent to a vectorized spatial template
to d by deﬁning W = WxyW T
deﬁned over d features at each spatial location, while Wf ∈ Rnf ×d deﬁnes a set of d basis vectors
spanning Rnf . This basis can be loosely interpreted as the PCA-basis estimated in [11]. In our
biconvex formulation, the basis vectors are not constrained to be orthogonal, but they are learned
discriminatively and jointly with the template Wxy . We show in Sec. 6 this often signiﬁcantly
outperforms PCA-based dimensionality reduction.

4.2 Efﬁciency

Scanning window classiﬁers are often implemented using convolutions [6, 12]. For example, the
product Tr(W T X ) can be computed for all image windows X with nf convolutions. By restricting
W to be WxyW T
f , we project features into a d dimensional subspace spanned by Wf , and com-
pute the ﬁnal score with d convolutions. One can further improve efﬁciency by using the same

4

d-dimensional feature space for a large number of different object templates - this is precisely the
basis of our transfer approach in Sec.4.3. This can result in signiﬁcant savings in computation. For
example, spatio-temporal templates for ﬁnding objects in video tend to have large nf since multiple
features are extracted from each time-slice.
Consider a rank-1 restriction of Wx and Wy . This corresponds to a separable ﬁlter Wxy . Hence, our
formulation can be used to learn separable scanning-window classiﬁers. Separable ﬁlters can be
evaluated efﬁciently with two one-dimensional convolutions. This can result in signiﬁcant savings
because computing the score at the window is now O(nx + ny ) rather than O(nxny ).

Cm

)).

(10)

4.3 Transfer
Assume we wish to train M predictors and are given {xm
n } training data pairs for each prediction
W m ) + (cid:88)
(cid:88)
(cid:88)
n , ym
problem 1 ≤ m ≤ M . One can write all M learning problems with a single optimization:
1
max(0, 1 − ym
L(W 1 , . . . , W M ) =
Tr(W mT
Tr(W mT
X m
2
n
n
m
m
n
As written, the problem above can be optimized over each W m independently. We can introduce
n . To transfer
a rank constraint on W m that induces a low-dimensional subspace projection of X m
knowledge between the classiﬁcation tasks, we require all tasks to use the same low-dimensional
subspace projection by sharing the same feature matrix:
W m = W m
xyW T
f
Note that the leading dimension of W m
xy can depend on m. This fact allows for X m
n from different
tasks to be of varying sizes. In our motivating application, we can learn a family of HOG templates
of varying spatial dimension that share a common HOG feature subspace. The coordinate descent
algorithm from Sec.3.2 naturally applies to the multi-task setting. Given a ﬁxed Wf , it is straightfor-
xy by deﬁning A = W T
xy , a single
f Wf . Given a ﬁxed set of W m
ward to independently optimize W m
˜Wf ) + (cid:88)
(cid:88)
matrix Wf is learned for all classes by computing:
1
max(0, 1 − ym
L( ˜Wf , W 1
Tr( ˜W T
Tr( ˜W T
A = (cid:88)
min
) =
xy , . . . , W M
Cm
2
xy
f
n
f
˜Wf
m
n
xy A− 1
˜X m
˜Wf = Wf A
= X m
W mT
n W m
xy W m
xy .
2
n
m
If all problems share the same slack penalty (Cm = C ), the above can be optimized with an off-the-
shelf SVM solver. In the general case, a minor modiﬁcation is needed to allow for slack-rescaling
[24].
In practice, nf can be large for spatio-temporal features extracted from multiple temporal windows.
The above formulation is convenient in that we can use data examples from many classiﬁcation tasks
to learn a good subspace for spatiotemporal features.

˜X m
n

where

and

1
2

and

))

5 Extensions

5.1 Multilinear

In many cases, a data point x is more natural represented as a multidimensional matrix or a high-
order tensor. For example, spatio-temporal templates are naturally represented as a 4th -order tensor
capturing the width, height, temporal extent, and the feature dimension of a spatio-temporal window.
For ease of exposition let us assume the feature dimension is 1 and so we write a feature vector x as
X ∈ Rnx×ny ×nt . We denote the element of a tensor X as xijk . Following [15], we deﬁne a scalar
(cid:104)W, X (cid:105) = (cid:88)
product of two tensors W and X as the sum of their element-wise products:
ijk
(cid:88)
With the above deﬁnition, we can generalize our trace-based objective function (6) to higher-order
tensors:
1
max(0, 1 − yn (cid:104)W, Xn (cid:105)).
2 (cid:104)W, W (cid:105) + C
n

L(W ) =

wijk xijk .

(11)

(12)

5

We wish to impose a rank restriction on the tensor W . The notion of rank for tensors of order
greater than two is subtle - for example, there are alternate approaches for deﬁning a high-order
SVD [25, 15]. For our purposes, we follow [20] and deﬁne W as a rank d tensor by writing it as
product of matrices W y ∈ Rny ×d , W x ∈ Rnx×d , W t ∈ Rnt×d :
d(cid:88)
s=1
Combining (11) - (13), it is straightforward to show that L(W y , W x , W t ) is convex in one matrix
given the others. This means our coordinate descent algorithm from Sec.3.2 still applies. As an
example, consider the case when d = 1. This rank restriction forces the spatio-temporal template
W to be separable in along the x, y , and t axes, allowing for window-scan scoring by three one-
dimensional convolutions. This greatly increases run-time efﬁciency for spatio-temporal templates.

wy
j swt
iswx
ks .

wijk =

(13)

5.2 Bilinear structural SVMs

We outline here an extension of our formalism to structural SVMs [24]. Structural SVMs learn
models that predict a structured label yn given a data point xn . Given training data of the form
{xn , yn}, the learning problem is:
(cid:88)
1
(l(yn , y) − wT ∆φ(xn , yn , y))
L(w) =
2 wT w + C
max
y
n
where ∆φ(xn , yn , y) = φ(xn , yn ) − φ(xn , y),

(14)

and where l(yn , y) is the loss of assigning example i with label y given that its true label is yn . The
above optimization problem is convex in w . As a concrete example, consider the task of learning a
w = (cid:2)wT
(cid:3) ,
multiclass SVM for nc classes using the formalism of Crammer and Singer [5]. Here,
. . . wT
nc
1
where each wi ∈ Rnx can be interpreted as a classiﬁer for class i. The corresponding φ(x, y) will
be a sparse vector with nx nonzero values at those indices associated with the y th class. It is natural
to model the relevant vectors as matrices W, Xn , ∆Φ that lie in Rnc×nx . We can enforce W to be
x where Wc ∈ Rnc×d and Wx ∈ Rnx×d . For
of rank d < min(nc , nx ) by deﬁning W = WcW T
example, one may expect template classiﬁers that classify nc different human actions to reside in a
(cid:88)
d dimensional subspace. The resulting biconvex objective function is
1
(l(yn , y) − Tr(WxW T
max
2
c
y
n

Tr(WxW T
c WcW T
x

Φ(Xn , yn , y)).

L(Wc , Wx ) =

) + C

(15)

Using our previous arguments, it is straightforward to show that the above objective is biconvex and
that each step of the coordinate descent algorithm reduces to a standard structural SVM problem.

6 Experiments

We focus our experiments on the task of visual recognition using spatio-temporal templates. This
problem domain has large feature sets obtained by histograms of gradients and histograms of optical
ﬂow computing from a frame pair. We illustrate our method on two challenging tasks using two
benchmark datasets - detecting pedestrians in video sequences from the INRIA-Motion database [7]
and classifying human actions in UCF-Sports dataset [18].
We model features computed from frame pairs x as matrices X ∈ Rnxy ×nf , where nxy = nxny
is the vectorized spatial template and nf is the dimensionality of our combined gradient and ﬂow
feature space. We use the histogram of gradient and ﬂow feature set from [7]. Our bilinear model
f where Wxy ∈ Rnxy ×d and Wf ∈ Rnf ×d . Typical values
learns a classiﬁer of the form WxyW T
include ny = 14, nx = 6, nf = 84, and d = 5 or 10.

6

6.1 Spatiotemporal pedestrian detection

Scoring a detector: Template classiﬁers are often scored using missed detections versus false-
positives-per-window statistics. However, recent analysis suggests such measurements can be mis-
leading [9]. We opt for the scoring criteria outlined by the widely-acknowledged PASCAL com-
petition [10], which looks at average precision (AP) results obtained after running the detector on
cluttered video sequences and suppressing overlapping detections.
Baseline: We compare with the linear spatiotemporal-template classiﬁer from [7]. The static-image
detector counterpart is a well-known state-of-the-art system for ﬁnding pedestrians [6]. Surprisingly,
when scoring AP for person detection in the INRIA-motion dataset, we ﬁnd the spatiotemporal
model performed worse than the static-image model. This is corroborated by personal communi-
cation with the authors as well as Dalal’s thesis [8]. We found that aggressive SVM cutting-plane
optimization algorithms [13] were needed for the spatiotemporal model to outperform the spatial
model. This suggests our linear baseline is the true state-of-the-art system for ﬁnding people in
video sequences. We also compare results with an additional rank-reduced baseline obtained by set-
ting wf to the basis returned by a PCA projection of the feature space from nf to d dimensions. We
use this PCA basis to initialize our coordinate descent algorithm when training our bilinear models.
We show precision-recall curves in Fig.2. We refer the reader to the caption for a detailed analysis,
but our bilinear optimization seems to produce the state-of-the-art system for ﬁnding people in video
sequences, while being an order-of-magnitude faster than previous approaches.

6.2 Human action classiﬁcation

Action classiﬁcation requires labeling a video sequence with one of nc action labels. We do this
by training nc 1-vs-all action templates. Template detections from a video sequence are pooled
together to output a ﬁnal action label. We experimented with different voting schemes and found
that a second-layer SVM classiﬁer deﬁned over the maximum score (over the entire video) for each
template performed well. Our future plan is to integrate the video class directly into the training
procedure using our bilinear structural SVM formulation.
Action recognition datasets tend to be quite small and limited. For example, up until recently, the
norm consisted of scripted activities on controlled, simplistic backgrounds. We focus our results
on the relatively new UCF Sports Action dataset, consisting of non-scripted sequences of cluttered
sports videos. Unfortunately, there has been few published results on this dataset, and the initial
work [18] uses a slightly different set of classes than those which are available online. The published
average class confusion is 69.2%, obtained with leave-one-out cross validation. Using 2-fold cross
validation (and hence signiﬁcantly less training data), our bilinear template achieves a score of
64.8% (Fig. 3). Again, we see a large improvement over linear and PCA-based approaches. While
not directly comparable, these results suggest our model is competitive with the state of the art.
Transfer: We use the UCF dataset to evaluate transfer-learning in Fig.4. We consider a small-
sample scenario when one has only two example video sequences of each action class. Under this
scenario, we train one bilinear model in which the feature basis Wf is optimized independently for
each action class, and another where the basis is shared across all classes. The independently-trained
model tends to overﬁt to the training data for multiple values of C , the slack penalty from (6). The
joint model clearly outperforms the independently-trained models.

7 Conclusion

We have introduced a generic framework for multilinear classiﬁers that are efﬁcient to train with
existing linear solvers. Multilinear classiﬁers exploit the natural matrix and/or tensor representation
of spatiotemporal data. For example, this allows one to learn separable spatio-temporal templates
for ﬁnding objects in video. Multilinear classiﬁers also allow for factors to be shared across clas-
siﬁcation tasks, providing a novel form of transfer learning. In our future experiments, we wish to
demonstrate transfer between domains such as pedestrian detection and action classiﬁcation.

7

Figure 2: Our results on the INRIA-motion database [7]. We evaluate results using average preci-
sion, using the well-established protocol outlined in [10]. The baseline curve is our implementation
of the HOG+ﬂow template from [7]. The size of the feature vector is over 7,000 dimensions. Using
PCA to reduce the dimensionality by 10X results in a signiﬁcant performance hit. Using our bilin-
ear formulation with the same low-dimensional restriction, we obtain better performance than the
original detector while being 10X faster. We show example detections on video clips on the right.

Figure 3: Our results on the UCF Sports Action dataset [18]. We show classiﬁcation results obtained
from 2-fold cross validation. Our bilinear model provides a strong improvement over both the linear
and PCA baselines. We show class confusion matrices, where light values correspond to correct
classiﬁcation. We label each matrix with the average classiﬁcation rate over all classes.

Figure 4: We show results for transfer learning on the UCF action recognition dataset with limited
training data - 2 training videos for each of 12 action classes. In the top table row, we show results
for independently learning a subspace for each action class. In the bottom table row, we show
results for jointly learning a single subspace that is transfered across classes. In both cases, the
regularization parameter C was set on held-out data. The jointly-trained model is able to leverage
training data from across all classes to learn the feature space Wf , resulting in overall better perfor-
mance. On the right, We show low-rank models W = WxyW T
f during iterations of the coordinate
descent. Note that the head and shoulders of the model are blurred out in iteration 1 which uses
PCA, but after the biconvex training procedure discriminatively updates the basis, the ﬁnal model is
sharper at the head and shoulders.

References
[1] F.A. Al-Khayyal and J.E. Falk. Jointly constrained biconvex programming. Mathematics of Operations
Research, pages 273–286, 1983.

8

00.20.40.60.8100.20.40.60.81RecallPrecisionPrec/Rec curve  Bilinear AP = 0.795Baseline AP = 0.765PCA AP = 0.698Dive−SideGolf−BackGolf−FrontGolf−SideKick−FrontKick−SideRide−HorseRun−SideSkate−FrontSwing−BenchSwing−SideWalk−FrontDive−SideGolf−BackGolf−FrontGolf−SideKick−FrontKick−SideRide−HorseRun−SideSkate−FrontSwing−BenchSwing−SideWalk−FrontDive−SideGolf−BackGolf−FrontGolf−SideKick−FrontKick−SideRide−HorseRun−SideSkate−FrontSwing−BenchSwing−SideWalk−FrontDive−SideGolf−BackGolf−FrontGolf−SideKick−FrontKick−SideRide−HorseRun−SideSkate−FrontSwing−BenchSwing−SideWalk−FrontDive−SideGolf−BackGolf−FrontGolf−SideKick−FrontKick−SideRide−HorseRun−SideSkate−FrontSwing−BenchSwing−SideWalk−FrontDive−SideGolf−BackGolf−FrontGolf−SideKick−FrontKick−SideRide−HorseRun−SideSkate−FrontSwing−BenchSwing−SideWalk−FrontBilinear (.648)Linear (.518)PCA (.444)Iter1Iter2Ind(C=.01).222.289Joint(C=.1).267.356Walk−Iter2Walk−Iter1(2 training videos per class)UCF Sport Action DatasetcloseupWalk−Iter2closeupWalk−Iter1[2] R.K. Ando and T. Zhang. A framework for learning predictive structures from multiple tasks and unla-
beled data. The Journal of Machine Learning Research, 6:1817–1853, 2005.
[3] S.P. Boyd and L. Vandenberghe. Convex optimization. Cambridge university press, 2004.
[4] R. Caruana. Multitask learning. Machine Learning, 28(1):41–75, 1997.
[5] K. Crammer and Y. Singer. On the algorithmic implementation of multiclass kernel-based vector ma-
chines. The Journal of Machine Learning Research, 2:265–292, 2002.
[6] N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In IEEE Computer Society
Conference on Computer Vision and Pattern Recognition, 2005. CVPR 2005, volume 1, 2005.
[7] N. Dalal, B. Triggs, and C. Schmid. Human detection using oriented histograms of ﬂow and appearance.
Lecture Notes in Computer Science, 3952:428, 2006.
[8] Navneet Dalal. Finding People in Images and Video. PhD thesis, Institut National Polytechnique de
Grenoble / INRIA Grenoble, July 2006.
[9] P. Doll ´ar, C. Wojek, B. Schiele, and P. Perona. Pedestrian detection: A benchmark. In CVPR, June 2009.
and A. Zisserman.
[10] M. Everingham, L. Van Gool, C. K.
The
J. Winn,
I. Williams,
PASCAL Visual Object Classes Challenge 2008 (VOC2008) Results.
http://www.pascal-
network.org/challenges/VOC/voc2008/workshop/index.html.
[11] P. Felzenszwalb, R. Girshick, D. McAllester, and D. Ramanan. Object detection with discriminatively
trained part based models. PAMI, In submission.
[12] P. Felzenszwalb, D. McAllester, and D. Ramanan. A discriminatively trained, multiscale, deformable part
model. Computer Vision and Pattern Recognition, Anchorage, USA, June, 2008.
[13] V. Franc and S. Sonnenburg. Optimized cutting plane algorithm for support vector machines. In Proceed-
ings of the 25th international conference on Machine learning, pages 320–327. ACM New York, NY,
USA, 2008.
[14] J. Gorski, F. Pfeuffer, and K. Klamroth. Biconvex sets and optimization with biconvex functions: a survey
and extensions. Mathematical Methods of Operations Research, 66(3):373–407, 2007.
[15] L.D. Lathauwer, B.D. Moor, and J. Vandewalle. A multilinear singular value decomposition. SIAM J.
Matrix Anal. Appl, 1995.
[16] N. Loeff and A. Farhadi. Scene Discovery by Matrix Factorization. In Proceedings of the 10th European
Conference on Computer Vision: Part IV, pages 451–464. Springer-Verlag Berlin, Heidelberg, 2008.
[17] J.D.M. Rennie and N. Srebro. Fast maximum margin matrix factorization for collaborative prediction. In
International Conference on Machine Learning, volume 22, page 713, 2005.
[18] M.D. Rodriguez, J. Ahmed, and M. Shah. Action MACH a spatio-temporal Maximum Average Correla-
tion Height ﬁlter for action recognition. In IEEE Conference on Computer Vision and Pattern Recognition,
2008. CVPR 2008, pages 1–8, 2008.
[19] C. Schuldt, I. Laptev, and B. Caputo. Recognizing human actions: A local SVM approach. In Pattern
Recognition, 2004. ICPR 2004. Proceedings of th e17th International Conference on, volume 3, 2004.
[20] A. Shashua and T. Hazan. Non-negative tensor factorization with applications to statistics and computer
vision. In International Conference on Machine Learning, volume 22, page 793, 2005.
[21] N. Srebro, J.D.M. Rennie, and T.S. Jaakkola. Maximum-margin matrix factorization. Advances in Neural
Information Processing Systems, 17:1329–1336, 2005.
[22] D. Tao, X. Li, X. Wu, and S.J. Maybank. General tensor discriminant analysis and Gabor features for gait
recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, 29(10):1700, 2007.
[23] J.B. Tenenbaum and W.T. Freeman. Separating style and content with bilinear models. Neural Computa-
tion, 12(6):1247–1283, 2000.
[24] I. Tsochantaridis, T. Joachims, T. Hofmann, and Y. Altun. Large margin methods for structured and
interdependent output variables. Journal of Machine Learning Research, 6(2):1453, 2006.
[25] M.A.O. Vasilescu and D. Terzopoulos. Multilinear analysis of image ensembles: Tensorfaces. Lecture
Notes in Computer Science, pages 447–460, 2002.
[26] L. Wolf, H. Jhuang, and T. Hazan. Modeling appearances with low-rank SVM. In IEEE Conference on
Computer Vision and Pattern Recognition (CVPR), pages 1–6. Citeseer, 2007.
[27] S. Yan, D. Xu, Q. Yang, L. Zhang, X. Tang, and H.J. Zhang. Discriminant analysis with tensor represen-
tation. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition, volume 1,
page 526. Citeseer, 2005.

9

