Learning Stereo Features with Stacked Autoencoders

Daniel Jin Hao Chia, Pang Wei Koh, Zhenghao Chen
CS229 Final Pro ject

1 Introduction

Single-layer stacked autoencoders have been shown to be successful in training artiﬁcial neurons with re-
ceptive ﬁelds that are similar to those found in the V1 cortex, but on monocular data. In this pro ject we
investigate extending a single-layer stacked autoencoder network to learn receptive ﬁelds on stereo data, and
evaluate them with respect to their eﬀectiveness as features for ob ject classiﬁcation and their similarity to
neuronal receptive ﬁelds characterized in physiological experiments.

The primary motivation for using stacked autoencoders is their intrinsic non-linearity, which allow us to
obtain higher-level features by stacking more levels and iterating the same algorithm multiple times.
In
contrast, stacking linear transformations such as those obtained from ICA does not yield any meaningful
results. This higher-level representation would be useful both as a tool for performing image and depth
recognition with stereo data, as well as a model for how the brain processes visual information.

2 Methodology

We generate 14x28 receptive ﬁelds from a training set of 291,600 14x28 images, sampled from the ﬁrst
training dataset of the NORB dataset [1]. For each of the 29,160 stereo pairs of 108x108 images in the
NORB training set, we ﬁrst whiten the data and then sample 10 pairs of 14x14 images around a 80x80
bounding box centered on the middle of the image, concatenating each pair of corresponding 14x14 images
to form a 14x28 image. Within each 14x28 image, the 14 columns on the left represent the image that the
left eye sees, while the 14 columns on the right represent the image that the right eye sees.

Training of the stacked autoencoder network is done with the Stanford Deep Learning Network Library,
with each of the 200 neurons characterized by a 14x28 receptive ﬁeld. The network uses a sum-of-squares
reconstruction error as the ob jective term, coupled with sparsity regularization on the bias term and L2
weight decay. Optimal coeﬃcients of the sparsity regularization term and the weight decay term are found
with a grid search.

We evaluate the learnt 14x28 receptive ﬁelds through supervised training on the original set of 29,160 pairs
of 108x108 images and classiﬁcation on a distinct but similar set. Each 108x108 image is whitened and then
cropped to 98x98 to eliminate border eﬀects. Feature vectors are generated by convolution: we extract 8x8
overlapping stereo patches, each of size 14x28 (half from the left image and half from the right image), from
each pair of 98x98 images, and run each of these 14x28 patches through the network with the learnt receptive
ﬁelds, taking the hidden layer activations as our features. Through concatenation, each pair of 98x98 images
therefore translates into a feature vector of length 64*200 = 12800.

The stereo receptive ﬁelds are contrasted against mono receptive ﬁelds learnt on the same dataset. We
generate the latter by treating left and right pairs of images as independent, essentially learning receptive
ﬁelds on 291,600*2 = 583,200 14x14 images, and doing supervised training and classiﬁcation on sets of 58,320
98x98 images.

We also present results obtained from running the FastICA algorithm [3] on the same set of 291,600 sampled
14x28 images. No dimensionality reduction was done, resulting in 14*28=392 independent components, each
of size 14x28, found. Classiﬁcation results run on the whitened raw data, as well as on the convolution of
whitened raw data pro jected upon the ICA bases, are also shown.

1

Disparity tuning curves are calculated using the method described by Hyv¨arinen et al.[2]. Each curve
plots response against horizontal disparity. To calculate the response of a neuron at a particular horizontal
disparity, we use the left side of the receptive ﬁeld of the neuron itself as the stimulus, translate it horizontally
by the required amount, and ﬁnd the maximum over all vertical translations of the activation of the neuron
when presented with that stimulus. We then repeat this process with the right side of the receptive ﬁeld.
The response is taken to be the average of the activations when presented with the stimulus from the left
and the right side.

3 Results - Receptive Fields and Classi(cid:12)cation

Figure 1: Representative receptive ﬁelds from diﬀerent areas of search space

(a) NS - Stereo

(b) NS - Mono

(c) LR - Stereo

(d) LR - Mono

Figure 2: Images of receptive ﬁelds

Figure 3: ICA bases obtained from the training set

We ﬁnd that the most neurologically accurate learnt stereo receptive ﬁelds lie in the area of moderate weight
decay and sparsity (Fig. 1). These learnt patches resemble, for the most part, a pair of Gabor ﬁlters that are
phase and/or positionally shifted from each other (Fig. 2a, 2b). We compare these to the ’receptive ﬁelds’

2

(a) Original image patch

(b) Reconstruction by NS

(c) Reconstruction by LR

Figure 4: Reconstructed patches

that result in the lowest reconstruction error. These correspond to networks that have not been constrained
much by sparsity. We term these sets of receptive ﬁelds NS and LR respectively. In comparison, Fig. 3
shows the results of running ICA on the same training set.

Fig. 4 shows an example of the reconstructed images obtained using the NS and LR stereo receptive ﬁelds.

Type
Stereo NS
Stereo LR
Mono NS
Mono LR
Raw pixels
ICA

Classiﬁcation Accuracy (%)
41.58
43.51
34.06
37.11
31.27
31.09

Table 1: Classiﬁcation results on 29,160 pairs of 98x98 images

Table 1 displays the results of classiﬁcation through the various methods described.

4 Results - Neurological Comparisons

(a) Far (Autoencoders)

(b) Near (Autoencoders)

(c) Tuned excitatory (Autoen-
coders)

(d) Tuned inhibitory (ICA)

Figure 5: Characteristic disparity tuning curves

Traditionally, binocular neurons have been classiﬁed into four diﬀerent categories: far, near, tuned excitatory,
and tuned inhibitory, based on characteristic disparity responses for each category. The receptive ﬁelds that
the single-layer stacked autoencoder learn show disparity tuning curves from the ﬁrst three categories (Fig.
5a, 5b, 5c). However, none of our current receptive ﬁelds match the response of a tuned inhibitory neuron
(Fig. 5d).

In accordance with biological data [4], phase (Fig. 6b) and positional (Fig. 6a) shifts are visible. We also
report the presence of ocular dominance (in both the autoencoder (Fig. 6c, Fig. 6d) as well as the ICA
receptive ﬁelds, though to a signiﬁcantly greater extent in the latter. To the best of our knowledge, this
phenomenon is not well understood within the neurological literature.

3

(a) Positional shift

(b) Phase shift

(c) Left ocular dominance

(d) Right ocular dominance

Figure 6: Disparity and ocular dominance in autoencoder receptive ﬁelds

5 Discussion and Future Directions

We have obtained some encouraging preliminary results as to how stacked autoencoders can produce receptive
ﬁelds with properties that resemble neuronal receptive ﬁelds, in particular when sparsity constraints are set
on the network. This supports sparse coding hypotheses of the workings of the visual cortex. However,
there are types of receptive ﬁelds found in the real neurons that are currently lacking in those that the
autoencoders produce, for example, those that result in tuned inhibitory disparity tuning curves. This could
be due to the diﬀerence in the workings on the human visual system as compared to the system we are
implementing: in particular, our eyes are able to vary their focal lengths, and tuned excitatory and tuned
inhibitory neurons are thought to be related to this change in ﬁxation length [5].

Also, stacked autoencoders can be used to produce stereo feature sets that achieve better linear classiﬁcation
accuracy with a smaller number of features as compared to using raw pixel data, or linear transformations
thereof. However, the neurologically similar features that we ﬁnd are not those that result in the highest
classiﬁcation accuracy. We can think of three possible reasons for this: ﬁrstly, the NORB dataset is not
perfectly stereo in that the images chosen for background noise are placed at a ﬁxed disparity between the left
and right patches, which is not a totally realistic representation of natural images. Secondly, the advantage
of the neurologically similar features might lie not so much in achieving the greatest classiﬁcation accuracy,
but rather in optimizing a tradeoﬀ between the amount of data required versus the classiﬁcation accuracy. In
this sense, the sparser feature set would be more amenable to compression via thresholding of each neuron’s
activity, for example. Thirdly, it could be that the neurologically similar features lend themselves better to
the ﬁnding of higher-level features through the stacking of additional autoencoders.

With these in mind, we propose the following future directions:
(cid:15) Quantitative comparison to biological data.
The methods used to generate disparity tuning curves vary from paper to paper, and we have not yet
found a way to statistically and non-qualitatively measure how similar the disparity responses of our
neurons are to those of real, biological neurons. For example, the comparison in Hyv¨arinenet al.[2] is
done by eye. There is also a lack of clear statistics on factors such as the degree of ocular dominance
present within a set of receptive ﬁelds. We would like to investigate how we might quantitatively
measure such similarity, in order to make more conﬁdent claims about the usefulness of the stacked
autoencoders as a biological model.
(cid:15) Learning and evaluating on a diﬀerent dataset.
We would like to see if other datasets give us similar results. In particular, the next step would be to
run the same algorithm on a dataset comprising true stereo images, with pictures taken at diﬀering
focal lengths. We would also like to see if the stacked autoencoders, particularly the NS feature set,
perform comparatively better on classiﬁcation tasks with a greater number of classes (NORB has
5).
(cid:15) Using non-linear classiﬁers.
Our current restriction to linear classiﬁers is a likely cause of the low classiﬁcation accuracy that we
are seeing across the diﬀerent feature sets, and might impede proper analysis of the eﬀectiveness of
the features generated by the stacked autoencoders. Memory and time restrictions due to the large
size of the feature sets prohibits more complex methods, but we would like to explore alternative
methods for classiﬁcation that might result in better classiﬁcation accuracy.
(cid:15) Extension to multi-layered stacked autoencoders and addition of stochastic elements.

4

The learnt features can also be improved, and higher-level features obtained, by stacking more
autoencoders on top of our single layer. This is the main long-term aim of our work. Additionally,
improvements to the learnt features can also be made through the addition of random elements into
the neural network, either through using denoising autoencoders, or by making the activation of
each neuron binary and probabilistic, instead of continuous and deterministic as it is now.
(cid:15) Modifying the ob jective function.
The current ob jective of sum-of-squares reconstruction error might not be optimal in terms of pro-
ducing receptive ﬁelds that compare favorably with neuronal receptive ﬁelds. In particular, the best
receptive ﬁelds are not the ones with the lowest reconstruction error, and we are currently judg-
ing the quality of a receptive ﬁeld by eye. We would like to investigate how a modiﬁed ob jective
function, perhaps involving kurtosis or a similar convex function to encourage sparsity, would aﬀect
the results we get. In particular, we would like to see if a modiﬁed ob jective function could help in
the automation of hyperparameter tuning, as well as in the driving of the learnt receptive ﬁelds to
match the ICA bases and the neurological data.
(cid:15) Using ICA to train the neural network.
Another possible and related way to obtain receptive ﬁelds closer to the ICA bases is to ﬁx the
decoder weights as the ICA bases, and then train encoder weights using the autoencoder algorithm.
This should have the eﬀect of indirectly modifying the ob jective function to result in learnt receptive
ﬁelds that resemble the ICA bases more closely. Coming up with a non-linear approximation to the
linear ICA bases in this manner might allow for higher-level features to be learnt by repeating the
algorithm.

6 Acknowledgements

We would like to thank our TAs, Andrew, Ian and Quoc for the huge amount of help that they have given
us in this pro ject.

References

[1] Y. LeCun, F.J. Huang, L. Bottou, Learning Methods for Generic Ob ject Recognition with Invariance
to Pose and Lighting , CVPR (2004).
[2] A. Hyv¨arinen, J. Hurri, P. O. Hoyer, Natural Image Statistics, Springer (2009).

[3] A. Hyv¨arinen, Fast and Robust Fixed-Point Algorithms for Independent Component Analysis, IEEE
Transactions on Neural Networks 10(3):626-634 (1999).
[4] A. Anzai, I. Ohzawa, R. D. Freeman, Neural Mechanisms For Encoding Binocular Disparity: Receptive
Field Position vs. Phase, Journal of Neurophysiology 82(2):874890 (1999).
[5] B. Fischer, J Kruger, Disparity Tuning and Binocularity of Single Neurons in Cat Visual Cortex, Exp.
Brain Res. 35, 1-8 (1979).

5

