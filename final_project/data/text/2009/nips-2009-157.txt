STDP enables spiking neurons to
detect hidden causes of their inputs

Bernhard Nessler, Michael Pfeiffer, and Wolfgang Maass
Institute for Theoretical Computer Science, Graz Universi ty of Technology
A-8010 Graz, Austria
{nessler,pfeiffer,maass}@igi.tugraz.at

Abstract

The principles by which spiking neurons contribute to the as tounding computa-
tional power of generic cortical microcircuits, and how spi ke-timing-dependent
plasticity (STDP) of synaptic weights could generate and maintain this compu-
tational function, are unknown. We show here that STDP, in conjunction with
a stochastic soft winner-take-all (WTA) circuit, induces spiking neurons to gen-
erate through their synaptic weights implicit internal models for subclasses (or
“causes ”) of the high-dimensional spike patterns of hundre ds of pre-synaptic neu-
rons. Hence these neurons will ﬁre after learning whenever t he current input best
matches their internal model. The resulting computational function of soft WTA
circuits, a common network motif of cortical microcircuits , could therefore be
a drastic dimensionality reduction of information streams , together with the au-
tonomous creation of internal models for the probability di stributions of their in-
put patterns. We show that the autonomous generation and maintenance of this
computational function can be explained on the basis of rigorous mathematical
principles. In particular, we show that STDP is able to approximate a stochastic
online Expectation-Maximization (EM) algorithm for modeling the input data. A
corresponding result is shown for Hebbian learning in arti ﬁ cial neural networks.

1

Introduction

It is well-known that synapses change their synaptic efﬁcac y ( “weight ”) w in dependence of the
difference tpost − tpre of the ﬁring times of the post- and presynaptic neuron accord ing to variations
of a generic STDP rule (see [1] for a recent review). However, the computational beneﬁt of this
learning rule is largely unknown [2, 3]. It has also been observed that local WTA-circuits form a
common network-motif in cortical microcircuits [4]. However, it is not clear how this network-motif
contributes to the computational power and adaptive capabilities of laminar cortical microcircuits,
out of which the cortex is composed. Finally, it has been conjectured for quite some while, on the
basis of theoretical considerations, that the discovery and representation of hidden causes of their
high-dimensional afferent spike inputs is a generic computational operation of cortical networks of
neurons [5]. One reason for this belief is that the underlying mathematical framework, Expectation-
Maximization (EM), arguably provides the most powerful approach to unsupervised learning that
we know of. But one has so far not been able to combine these three potential pieces (STDP, WTA-
circuits, EM) of the puzzle into a theory that could help us to unravel the organization of computation
and learning in cortical networks of neurons.

We show in this extended abstract that STDP in WTA-circuits approximates EM for discovering
hidden causes of large numbers of input spike trains. We ﬁrst demonstrate this in section 2 in an
application to a standard benchmark dataset for the discovery of hidden causes. In section 3 we
show that the functioning of this demonstration can be explained on the basis of EM for simpler
non-spiking approximations to the spiking network considered in section 2.

1

2 Discovery of hidden causes for a benchmark dataset

We applied the network architecture shown in Fig. 1A to handwritten digits from the MNIST dataset
[6].1 This dataset consists of 70, 000 28 × 28-pixel images of handwritten digits2 , from which we
picked the subset of 20, 868 images containing only the digits 0, 3 and 4. Training examples were
randomly sampled from this subset with a uniform distribution of digit classes.

i
k
w
 
∆

0

 

Simple STDP curve
Complex STDP curve

 

c · e
−wki -1

σ

-1

0
t
 − t
post

pre

B

A

Figure 1: A) Architecture for learning with STDP in a WTA-network of spiking neurons. B) Learn-
ing curve for the two STDP rules that were used (with σ = 10ms). The synaptic weight wki is
changed in dependence of the ﬁring times
tpre of the presynaptic neuron yi and tpost of the post-
synaptic neuron zk . If zk ﬁres at time t without a ﬁring of yi in the interval [t − σ, t + 2σ ], wki is
reduced by 1. The resulting weight change is in any case multiplied with the current learning rate η ,
which was chosen in the simulations according to the variance tracking rule7 .

Pixel values xj were encoded through population coding by binary variables yi (spikes were pro-
duced for each variable yi by a Poisson process with a rate of 40 Hz for yi = 1, and 0 Hz for yi = 0,
at a simulation time step of 1ms, see Fig. 2A). Every training example x was presented for 50ms.
Every neuron yi was connected to all K = 10 output neurons z1 , . . . , z10 . A Poisson process caused
ﬁring of one of the neurons zk on average every 5ms (see [8] for a more realistic ﬁring mechanism).
The WTA-mechanism ensured that only one of the output neurons could ﬁre at any time step. The
winning neuron at time step t was chosen from the soft-max distribution

p(zk ﬁres at time t|y) =

euk (t)
PK
l=1 eul (t)
where uk (t) = Pn
i=1 wki ˜yi (t) + wk0 represents the current membrane potential of neuron zk (with
[t − 10ms, t], else ˜yi (t) = 0).3
˜yi (t) = 1 if yi ﬁred within the time interval
STDP with the learning curves shown in Fig. 1B was applied to all synapses wki for an input consist-
ing of a continuous sequence of spike encodings of handwritten digits, each presented for 50ms (see

,

(1)

1A similar network of spiking neurons had been applied successfully in [7] to learn with STDP the classi-
ﬁcation of symbolic (i.e., not handwritten) characters. Possibly our the oretical analysis could also be used to
explain their simulation result.
2Pixels were binarized to black/white. All pixels that were black in less than 5% of the training examples
were removed, leaving m = 429 external variables xj , that were encoded by n = 858 spiking neurons yi . Our
approach works just as well for external variables xj that assume any ﬁnite number of values, provided that
they are presented to the network through population coding with one variab le yi for every possible value of
xj . In fact, the approach appears to work also for the commonly considered population coding of continuous
external variables.
3This amounts to a representation of the EPSP caused by a ﬁring of neuron yi by a step function, which facil-
itates the theoretical analysis in section 3. Learning with the spiking network wo rks just as well for biologically
realistic EPSP forms.

2

s
n
o
r
u
e
N
 
t
u
p
n
I

100

200

300

400

500

600

700

800

0

Input Spike Trains

Output before Learning

Output after Learning

1

2

3

4

5

6

7

8

9

s
n
o
r
u
e
N
 
t
u
p
t
u
O

1

2

3

4

5

6

7

8

9

s
n
o
r
u
e
N
 
t
u
p
t
u
O

50

100
Time [ms]
A

150

10

0

150

10

0

50

100
Time [ms]
B

50

100
Time [ms]
C

150

Figure 2: Unsupervised classi ﬁcation learning and sparsi ﬁ
cation of ﬁring of output neurons after
training. For testing we presented three examples from an in dependent test set of handwritten digits
0, 3, 4 from the MNIST dataset, and compared the ﬁring of the output- neurons before and after
learning. A) Representation of the three handwritten digits 0, 3, 4 for 50ms each by 858 spiking
neurons yi . B) Response of the output neurons before training. C) Response of the output neurons
after STDP (according to Fig. 1B) was applied to their weights wki for a continuous sequence of
spike encodings of 4000 randomly drawn examples of handwritten digits 0, 3, 4, each represented
for 50ms (like in panel A). The three output neurons z4 , z9 , z6 that respond have generated internal
models for the three shown handwritten digits according to F ig. 3C.

Fig. 2A).4 The learning rate η was chosen locally according to the variance tracking rule 7 . Fig. 2C
shows that for subsequent representations of new handwritten samples of the same digits only one
neuron responds during each of the 50ms while a handwritten digit is shown. The implicit internal
models which the output neurons z1 , . . . , z10 had created in their weights after applying STDP are
made explicit in Fig. 3B and C. Since there were more output neurons than digits, several output
neurons created internal models for different ways of writi ng the same digit. When after applying
STDP to 2000 random examples of handwritten digits 0 and 3 also examples of handwritten digit
4 were included in the next 2000 examples, the internal models of the 10 output neurons reorga-
nized autonomously, to include now also two internal models for different ways of writing the digit
4. The adaptation of the spiking network to the examples shown so far is measured in Fig. 3A by
the normalized conditional entropy H (L|Z )/H (L, Z ), where L denotes the correct classi ﬁcation of
each handwritten digit y, and Z is the random variable which denotes the cluster assignment with
p(Z = k |y) = p(zk = 1|y), the ﬁring probabilities at the presentation of digit y, see (1).
Since after training by STDP each of the output neurons ﬁre pr eferentially for one digit, we can
measure the emergent classi ﬁcation capability of the netwo rk. The resulting weight-settings achieve
a classi ﬁcation error of 2.19% on the digits 0 and 3 after 2000 training steps and 3.68% on all three
digits after 4000 training steps on independent test sets of 10,000 new samples each.

3 Underlying theoretical principles

We show in this section that one can analyze the learning dynamics of the spiking network con-
sidered in the preceding section (with the simple STDP curve of Fig. 1B with the help of Hebbian
learning (using rule (12)) in a corresponding non-spiking neural network Nw . Nw is a stochastic
arti ﬁcial neural network with the architecture shown in Fig . 1A, and with a parameter vector w con-
sisting of thresholds wk0 (k = 1, . . . , K ) for the K output units z1 , . . . , zK and weights wki for the
connection from the ith input node yi (i = 1, . . . , n) to the k th output unit zk . We assume that this
network receives at each discrete time step a binary input vector y ∈ {0, 1}n and outputs a binary
vector z ∈ {0, 1}K with PK
k=1 zk = 1, where the k such that zk = 1 is drawn from the distribution
4Whereas the weights in the theoretical analysis of section 3 will approximate logs of probabilities (see (6)),
one can easily make all weights non-negative by restricting the range of these log -probabilities to [−5, 0], and
then adding a constant 5 to all weight values. This transformation gives rise to the factor c = e5 in Fig. 1B.

3

Spiking Network (simple STDP curve)
Spiking Network (complex STDP curve)
Non−spiking Network (no missing attributes)
Non−spiking Network (35% missing attributes)

 

0.5

0.45

0.4

0.35

0.3

0.25

0.2

0.15

0.1

0.05

y
p
o
r
t
n
E
 
l
a
n
o
i
t
i
d
n
o
C

0
 
0

500

1000

1500
2500
2000
Training Examples
A

3000

3500

4000

B

C

Figure 3: Analysis of the learning progress of the spiking ne twork for the MNIST dataset. A)
Normalized conditional entropy (see text) for the spiking network with the two variants of STDP
learning rules illustrated in Fig. 1B (red solid and blue dashed lines), as well as two non-spiking
approximations of the network with learning rule (12) that a re analyzed in section 3. According to
this analysis the non-spiking network with 35% missing attributes (dash-dotted line) is expected to
have a very similar learning behavior to the spiking network . 2000 random examples of handwritten
digits 0 and 3 were presented (for 50ms each) to the spiking network as the ﬁrst 2000 examples.
Then for the next 2000 examples also samples of handwritten digit 4 were included. B) The implicit
internal models created by the neurons after 2000 training examples are made explicit by drawing
for each pixel the difference wki − wk(i+1) of the weights for input yi and yi+1 that encode the two
possible values (black/white) of the variable xj that encodes this pixel value. One can clearly see
that neurons created separate internal models for differen t ways of writing the two digits 0 and 3. C)
Re-organized internal models after 2000 further training examples that included digit 4. Two output
neurons had created internal models for the newly introduce d digit 4.

over {1, . . . , K } deﬁned by

eul

with uk =

wki yi + wk0 .

p(zk = 1|y, w) =

n
euk
Xi=1
K
Pl=1
We consider the case where there are arbitrary discrete exte rnal variables x1 , . . . , xm , each ranging
over {1, . . . , M } (we had M = 2 in section 2), and assume that these are encoded through binary
variables y1 , . . . , yn for n = m · M with Pn
i=1 yi = m according to the rule
for j = 1, . . . , m and r = 1, . . . , M .
y(j−1)·M +r = 1 ⇐⇒ xj = r ,
In other words: the group Gj of variables y(j−1)·M +1 , . . . , y(j−1)·M +M provides a population cod-
ing for the discrete variable xj .
We now consider a class of probability distributions that is particularly relevant for our analysis:
mixtures of multinomial distributions [9], a generalization of mixtures of Bernoulli distributions
(see section 9.3.3 of [10]). This is a standard model for latent class analysis [11] in the case of
discrete variables. Mixtures of multinomial distributions are arbitrary mixtures of K distributions
p1 (x), . . . , pK (x) that factorize, i.e.,

(2)

(3)

pkj (xj )

pk (x) =

m
Yj=1
for arbitrary distributions pkj (xj ) over the range {1, . . . , M } of possible values for xj . In other
words: there exists some distribution over hidden binary va riables zk with PK
k=1 zk = 1, where the
k with zk = 1 is usually referred to as a hidden “cause” in the generation o f x, such that
K
Xk=1
p(zk = 1) · pk (x).
p(x) =

(4)

4

We ﬁrst observe that any such distribution p(x) can be represented with some suitable weight vector
w by the neural network Nw , after recoding of the multinomial variables xj by binary variables yi
as deﬁned before:

for

eu∗
k

p(y|w) =

K
Xk=1
w∗
ki := log p(yi = 1|zk = 1)

with

and

u∗
k :=

ki yi + w∗
w∗
k0

n
Xi=1
w∗
k0 := log p(zk = 1) .

,

(5)

(6)

In addition, Nw deﬁnes for any weight vector w whose components are normalized, i.e.
K
Xk=1
ewk0 = 1 and Xi∈Gj
a mixture of multinomials of the type (4).
The problem of learning a generative model for some arbitrar ily given input distribution p∗ (x) (or
p∗ (y) after recoding according to (3)), by the neural network Nw is to ﬁnd a weight vector w such
that p(y|w) deﬁned by (5) models p∗ (y) as accurately as possible. As usual, we quantify this goal
by demanding that

for j = 1, . . . , m; k = 1, . . . , K,

ewki = 1 ,

(7)

Ep∗ [log p(y|w)]

(8)

is maximized.

Note that the architecture Nw is very useful from a functional point of view, because if (7) holds,
then the weighted sum uk at its unit zk has according to (2) the value log p(zk = 1|y, w), and the
stochastic WTA rule of Nw picks the “winner”
k with zk = 1 from this internally generated model
p(zk = 1|y, w) for the actual distribution p∗ (zk = 1|y) of hidden causes. We will not enforce the
normalization (7) explicitly during the subsequently considered learning process, but rather use a
learning rule (12) that turns out to automatically approximate such normalization in the limit.
Expectation Maximization (EM) is the standard method for maximizing Ep∗ [log p(y|w)]. We will
show that the simple STDP-rule of Fig. 1B for the spiking network of section 2 can be viewed as
an approximation to an online version of this EM method. We will ﬁrst consider in section 3.1 the
standard EM-approach, and show that the Hebbian learning ru le (12) provides a stochastic approxi-
mation to the maximization step.

3.1 Reduction to EM

The standard method for maximizing the expected log-likelihood Ep∗ [log p(y|w)] with a dis-
tribution p of the form p(y|w) = Pz p(y, z|w) with hidden variables z, is to observe that
Ep∗ [log p(y|w)] can be written for arbitrary distributions q(z|y) in the form
(9)
Ep∗ [log p(y|w)] = L(q , w) + Ep∗ [KL(q(z|y)||p(z|y, w))]
L(q , w) = Ep∗ "Xz
q(z|y) # ,
p(y, z|w)
where KL(.) denotes the Kullback-Leibler divergence.
old ) for the current parameter values w = w
In the E -step one sets q(z|y) = p(z|y, w
old , thereby
achieving Ep∗ [KL(q(z|y)||p(z|y, w
old by new parameters
old ))] = 0. In the M -step one replaces w
w that maximize L(q , w) for this distribution q(z|y). One can easily show that this is achieved by
setting

q(z|y) log

(10)

and
(11)
w∗
w∗
ki = log p∗ (yi = 1|zk = 1),
k0 = log p∗ (zk = 1),
with values for the variables zk generated by q(z|y) = p(z|y, w
old ), while the values for the vari-
ables y are generated by the external distribution p∗ . Note that this distribution of z is exactly the
distribution (2) of the output of the neural network Nw for inputs y generated by p∗ .5 In the fol-
lowing section we will show that this M -step can be approximated by applying iteratively a simple
Hebbian learning rule to the weights w of the neural network Nw .
5Hence one can extend p∗ (y) for each ﬁxed w to a joint distribution p∗ (y, z), where the z are generated
for each y by Nw .

5

3.2 A Hebbian learning rule for the M-step

We show here that the target weight values (11) are the only equilibrium points of the following
Hebbian learning rule:
∆wki= (η (e−wki − 1),
∆wk0= (cid:26)η (e−wk0 − 1),
−η ,
−η ,
0,
It is obvious (using for the second equivalence the fact that yi is a binary variable) that

if yi=1 and zk=1
if yi=0 and zk=1
if zk = 0,

if zk=1
if zk=0

(12)

E[∆wki ] = 0 ⇔
⇔

⇔
⇔

p∗ (yi=1|zk=1)η(e−wki − 1) − p∗ (yi=0|zk=1)η = 0
p∗ (yi=1|zk=1)(e−wki − 1) + p∗ (yi=1|zk=1) − 1 = 0
p∗ (yi=1|zk=1)e−wki = 1
wki = log p∗ (yi=1|zk=1) .

(13)

Analogously one can show that E[∆wk0 ] = 0 ⇔ wk0 = log p∗ (zk=1). With similar elementary
calculations one can show that E[∆wki ] has for any w a value that moves wki in the direction of
ki (in fact, exponentially fast).
w∗
One can actually show that one single step of (12) is a linear approximation of the ideal incremental
update of wki = log aki
, with aki and Nk representing the values of the corresponding sufﬁcient
Nk
statistics, as log aki+1
Nk+1 = wki + log(1 + ηe−wk i ) − log(1 + η) for η = 1
. This also reveals the
Nk
role of the learning rate η as the reciprocal of the equivalent sample size6 .
In order to guarantee the stochastic convergence (see [12]) of the learning rule one has to use a
t=1 (η (t) )2 = 0.7
decaying learning rate η (t) such that P∞
t=1 η (t) = ∞ and P∞
The learning rule (12) is similar to a rule that had been intro duced in [13] in the context of supervised
learning and reinforcement learning. That rule had satis ﬁe d an equilibrium condition similar to (13).
But to the best of our knowledge, such type of rule has so far not been considered in the context of
unsupervised learning.
One can easily see the correspondence between the update of wki in (12) and in the simple STDP
rule of Fig. 1B. In fact, if each time where neuron zk ﬁres in the spiking network, each presynaptic
neuron yi that currently has a high ﬁring rate has ﬁred within the last
σ = 10ms before the ﬁring
of zk , the two learning rules become equivalent. However since the latter condition could only be
achieved with biologically unrealistic high ﬁring rates, w e need to consider in section 3.4 the case
for the non-spiking network where some attributes are missi ng (i.e., yi = 0 for all i ∈ Gj ; for some
group Gj that encodes an external variable xj via population coding).
We ﬁrst show that the Hebbian learning rule (12) is also meani ngful in the case of online learning of
Nw , which better matches the online learning process for the sp iking network.

3.3 Stochastic online EM

The preceding arguments justify an application of learning rule (12) for a number of steps within
p [log p(y|w)]. We now show that it is also
each M-step of a batch EM approach for maximizing E∗
meaningful to apply the same rule (12) in an online stochastic EM approach (similarly as in [14]),
where at each combined EM-step only one example y is generated by p∗ , and the learning rule (12)

6The equilibrium condition (13) only sets a necessary constraint for the the quotient of the two directions of
the update in (12). The actual formulation of (12) is motivated by the goal of updating a sufﬁcient statistics.
7 In our experiments we used an adaptation of the variance tracking heuris tic from [13]. If we assume that
the consecutive values of the weights represent independent samples of their true stochastic distribution at the
current learning rate, then this observed distribution is the log of a beta-dis tribution of the above mentioned
t and second moments E[wki ] ≈
parameters of the sufﬁcient statistics. Analytically this distribution has the ﬁrs
= E[w2
ki ]−E [wki ]2
log aki
ki ] ≈ E[wki ]2 + 1
and E[w2
ki = 1
+ 1
, leading to the estimate ηnew
. The
e−E[wki ]+1
Ni
aki
Ni
Ni
empirical estimates of these ﬁrst two moments can be gathered online by ex ponentially decaying averages
using the same learning rate ηki .

6

ewk0 ! −

is applied just once (for zk resulting from p(z|y, w) for the current weights w, or simpler: for the
zk that is output by Nw for the current input y).
Our strategy for showing that a single application of learning rule (12) is expected to provide
progress in an online EM-setting is the following. We consider the Lagrangian F for maximiz-
ing Ep∗ [log p(y|w)] under the constraints (7), and show that an application of ru le (12) is expected
to increase the value of F . We set
F (w, λ) = Ep∗ [log p(y|w)] − λ0  1 −

ewki 
λkj 
m
K
K
1 − Xi∈Gj
Xj=1
Xk=1
Xk=1
 .
k=1 euk for uk = PK
According to (5) one can write p(y|w) = PK
i=1 wki yi + wk0 . Hence one
arrives at the following conditions for the Lagrange multip liers λ:
] − λ0 ewk0 ! = 0
Xk=1  Ep∗ [
K
K
euk
Xk=1
=
PK
l=1 eul
= Xi∈Gj  Ep∗ [yi
] − λkj ewki ! = 0,
euk
Xi∈Gj
PK
l=1 eul
euk
which yield λ0 = 1 and λkj = Ep∗ [
l=1 eul ].
PK
Plugging these values for λ into ∇wF · E∗
p [∆w] with ∆w deﬁned by (12) shows that this vector
product is always positive. Hence even a single application of learning rule (12) to a single new
example y, drawn according to p∗ , is expected to increase Ep∗ [log p(y|w)] under the constraints
(7).

∂F
∂wk0

∂F
∂wki

(14)

(15)

(16)

3.4

Impact of missing attributes

We had shown at the end of 3.2 that learning in the spiking network corresponds to learning in the
non-spiking network Nw with missing attributes. A profound analysis of the correct handling of
missing attribute values in EM can be found in [15]. Their analysis implies that the correct learning
action is then not to change the weights wki for i ∈ Gj . However the STDP rule of Fig. 1B, as
well as (12), reduce also these weights by η if zk ﬁres. This yields a modi ﬁcation of the equilibrium
analysis (13):
E[∆wki ] = 0 ⇔ (1 − r) (cid:0)p∗ (yi=1|zk=1)η(e−wki − 1) − p∗ (yi=0|zk=1)η(cid:1) − rη = 0
wki = log p∗ (yi=1|zk=1) + log(1 − r) ,
⇔
where r is the probability that i belongs to a group Gj where the value of xj is missing. Since
this probability r is independent of the neuron zk and also independent of the current value of the
external variable xi , this offset of log(1 − r) is expected to be the same for all weights. It can easily
be veri ﬁed, that such an offset does not change the resulting probabilities of the competition in the
E-step according to (2).

(17)

3.5 Relationship between the spiking and the non-spiking network

As indicated at the end of section 3.2, the learning process for the spiking network from section 2
with the simple STDP curve from Fig. 1B (and external variables xj encoded by input spike trains
from neurons yi ) is equivalent to a somewhat modi ﬁed learning process of the non-spiking network
Nw with the Hebbian learning rule (12) and external variables xj encoded by binary variables yi .
Each ﬁring of a neuron zk at some time t corresponds to a discrete time step in Nw with an ap-
plication of the Hebbian learning rule (12). Each neuron yi that had ﬁred during the time interval
[t − 10ms, t] contributes a value ˜yi (t) = 1 to the membrane potential uk (t) of the neuron zk at time
t, and a value ˜yi (0) = 0 if it did not ﬁre during [t − 10ms, t]. Hence the weight updates at time t
according to the simple STDP curve are exactly equal to those of (12) in the non-spiking network.
However (12) will in general be applied to a corresponding input y where it may occur that for some

7

j ∈ {1, . . . , m} one has yi = 0 for all i ∈ Gj (since none of the neurons yi with i ∈ Gj ﬁred in the
spiking network during [t − 10ms, t]). Hence we arrive at an application of (12) to an input y with
missing attributes, as discussed in section 3.4.
Since several neurons zk are likely to ﬁre during the presentation of an external inpu t x (each hand-
written digit was presented for 50ms in section 2; but a much shorter presentation time of 10ms also
works quite well), this external input x gives in general rise to several applications of the STDP rule.
This corresponds to several applications of rule (12) to the same input (but with different choices
of missing attributes) in the non-spiking network. In the experiments in section 2, every example
in the non-spiking network with missing attributes was therefore presented for 10 steps, such that
the average number of learning steps is the same as in the spik ing case. The learning process of
the spiking network corresponds to a slight variation of the stochastic online EM algorithm that is
implemented through (12) according to the analysis of section 3.3.

4 Discussion

The model for discovering hidden causes of inputs that is proposed in this extended abstract presents
an interesting shortcut for implementing and learning gene rative models for input data in networks
of neurons. Rather than building and adapting an explicit model for re-generating internally the dis-
tribution of input data, our approach creates an implicit model of the input distribution (see Fig. 3B)
that is encoded in the weights of neurons in a simple WTA-circuit. One might call it a Vapnik-style
[16] approach towards generative modeling, since it focuses directly on the task to represent the
most likely hidden causes of the inputs through neuronal ﬁri ng. As the theoretical analysis via non-
spiking networks in section 3 has shown, this approach also offers a new perspective for generating
self-adapting networks on the basis of traditional arti ﬁci al neural networks. One just needs to add
the stochastic and non-feedforward parts required for impl ementing stochastic WTA circuits to a
1-layer feedforward network, and apply the Hebbian learning rule (12) to the feedforward weights.
One interesting aspect of the “implicit generative learnin g” approach that we consider in this ex-
tended abstract is that it retains important advantages of the generative learning approach, faster
learning and better generalization [17], while retaining the algorithmic simplicity of the discrimina-
tive learning approach.

Our approach also provides a new method for analyzing detail s of STDP learning rules. The sim-
ulation results of section 2 show that a simpli ﬁed STDP rule t hat can be understood clearly from
the perspective of stochastic online EM with a suitable Hebbian learning rule, provides good perfor-
mance in discovering hidden causes for a standard benchmark dataset. A more complex STDP rule,
whose learning curve better matches experimentally record ed average changes of synaptic weights,
provides almost the same performance. For a comparison of th e STDP curves in Fig. 1B with ex-
perimentally observed STDP curves one should keep in mind, that most experimental data on STDP
curves are for very low ﬁring rates. The STDP curve of Fig. 7C i n [18] for a ﬁring rate of 20Hz has,
similarly as the STDP curves in Fig. 1B of this extended abstract, no pronounced negative dip, and
instead an almost constant negative part.

In our upcoming paper [8] we will provide full proofs for the r esults announced in this extended
abstract, as well as further applications and extensions of the learning result. We will also demon-
strate, that the learning rules that we have proposed are robust to noise, and that they are matched
quite well by experimental data.

Acknowledgments

We would like to thank the anonymous reviewer for a hint in the notational formalism. Written under
partial support by the Austrian Science Fund FWF, project # P17229-N04, project # S9102-N04,
and project # FP6-015879 (FACETS) as well as # FP7-216593 (SECO) of the European Union.

8

References

[1] Y. Dan and M. Poo. Spike timing-dependent plasticity of neural circuits. Neuron, 44:23–30, 2004.
[2] L. F. Abbott and S. B. Nelson. Synaptic plasticity: taming the beast. Nature Neuroscience, 3:1178–1183,
2000.
[3] A. Morrison, A. Aertsen, and M. Diesmann. Spike-timing-dependent plasticity in balanced random net-
works. Neural Computation, 19:1437–1467, 2007.
[4] R. J. Douglas and K. A. Martin. Neuronal circuits of the neocortex. Annu Rev Neurosci, 27:419–451,
2004.
[5] G. E. Hinton and Z. Ghahramani. Generative models for discovering sparse distributed representations.
Philos Trans R Soc Lond B Biol Sci., 352(1358):1177–1190, 1997.
[6] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition.
Proceedings of the IEEE, 86(11):2278–2324, 1998.
[7] A. Gupta and L. N. Long. Character recognition using spiking neura l networks. IJCNN, pages 53–58,
2007.
[8] B. Nessler, M. Pfeiffer, and W. Maass. Spike-timing dependent plasticity performs stochastic expectation
maximization to reveal the hidden causes of complex spike inputs. (in preparation).
[9] M. Meil ˘a and D. Heckerman. An experimental comparison of model-based clustering methods. Machine
Learning, 42(1):9–29, 2001.
[10] C. M. Bishop. Pattern Recognition and Machine Learning. Springer, New York, 2006.
[11] G. McLachlan and D. Peel. Finite mixture models. Wiley, 2000.
[12] J.H. Kushner and G.G. Yin. Stochastic approximation algorithms and applications. Springer, 1997.
[13] B. Nessler, M. Pfeiffer, and W. Maass. Hebbian learning of bayes optimal decisions. In Advances in
Neural Information Processing Systems 21, pages 1169–1176. MIT Press, 2009.
[14] M. Sato. Fast learning of on-line EM algorithm. Rapport Technique, ATR Human Information Processing
Research Laboratories, 1999.
[15] Z. Ghahramani and M.I. Jordan. Mixture models for learning from incomplete data. Computational
Learning Theory and Natural Learning Systems, 4:67–85, 1997.
[16] V. Vapnik. Universal learning technology: Support vector machines. NEC Journal of Advanced Technol-
ogy, 2:137–144, 2005.
[17] A. Y. Ng and M. I. Jordan. On discriminative vs. generative classiﬁers: A comparison of logistic regression
and naive Bayes. Advances in Neural Information Processing Systems (NIPS), 14:841–848, 2002.
[18] P. J. Sj ¨ostr ¨om, G. G. Turrigiano, and S. B. Nelson. Rate, timing, and cooperativity jointly determine
cortical synaptic plasticity. Neuron, 32:1149–1164, 2001.

9

