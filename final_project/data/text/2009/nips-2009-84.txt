On Stochastic and Worst-case Models for Investing

Elad Hazan
IBM Almaden Research Center
650 Harry Rd, San Jose, CA 95120
ehazan@cs.princeton.edu

Satyen Kale
Yahoo! Research
4301 Great America Parkway, Santa Clara, CA 95054
skale@yahoo-inc.com

Abstract

In practice, most investing is done assuming a probabilistic model of stock price
returns known as the Geometric Brownian Motion (GBM). While often an ac-
ceptable approximation, the GBM model is not always valid empirically. This
motivates a worst-case approach to investing, called universal portfolio manage-
ment, where the objective is to maximize wealth relative to the wealth earned by
the best ﬁxed portfolio in hindsight.
In this paper we tie the two approaches, and design an investment strategy which
is universal in the worst-case, and yet capable of exploiting the mostly valid GBM
model. Our method is based on new and improved regret bounds for online convex
optimization with exp-concave loss functions.

1 Introduction

“Average-case” Investing: Much of mathematical ﬁnance theory is devoted to the modeling of
stock prices and devising investment strategies that maximize wealth gain, minimize risk while doing
so, and so on. Typically, this is done by estimating the parameters in a probabilistic model of stock
prices. Investment strategies are thus geared to such average case models (in the formal computer
science sense), and are naturally susceptible to drastic deviations from the model, as witnessed in
the recent stock market crash.
Even so, empirically the Geometric Brownian Motion (GBM) ([Osb59, Bac00]) has enjoyed great
predictive success and every year trillions of dollars are traded assuming this model. Black and
Scholes [BS73] used this same model in their Nobel prize winning work on pricing options on
stocks.
“Worst-case” Investing: The fragility of average-case models in the face of rare but dramatic de-
viations led Cover [Cov91] to take a worst-case approach to investing in stocks. The performance
of an online investment algorithm for arbitrary sequences of stock price returns is measured with
respect to the best CRP (constant rebalanced portfolio, see [Cov91]) in hindsight. A universal port-
folio selection algorithm is one that obtains sublinear (in the number of trading periods T ) regret,
which is the difference in the logarithms of the ﬁnal wealths obtained by the two.
Cover [Cov91] gave the ﬁrst universal portfolio selection algorithm with regret bounded by
O(log T ). There has been much follow-up work after Cover’s seminal work, such as [HSSW96,
MF92, KV03, BK97, HKKA06], which focused on either obtaining alternate universal algorithms
or improving the efﬁciency of Cover’s algorithm. However, the best regret bound is still O(log T ).
This dependence of the regret on the number of trading periods is not entirely satisfactory for two
main reasons. First, a priori it is not clear why the online algorithm should have high regret (growing
with the number of iterations) in an unchanging environment. As an extreme example, consider a
setting with two stocks where one has an “upward drift” of 1% daily, whereas the second stock
remains at the same price. One would expect to “ﬁgure out” this pattern quickly and focus on the

1

ﬁrst stock, thus attaining a constant fraction of the wealth of the best CRP in the long run, i.e.
constant regret, unlike the worst-case bound of O(log T ).
The second problem arises from trading frequency. Suppose we need to invest over a ﬁxed period of
time, say a year. Trading more frequently potentially leads to higher wealth gain, by capitalizing on
short term stock movements. However, increasing trading frequency increases T , and thus one may
expect more regret. The problem is actually even worse: since we measure regret as a difference of
logarithms of the ﬁnal wealths, a regret bound of O(log T ) implies a poly(T ) factor ratio between the
ﬁnal wealths. In reality, however, experiments [AHKS06] show that some known online algorithms
actually improve with increasing trading frequency.
Bridging Worst-case and Average-case Investing: Both these issues are resolved if one can show
that the regret of a “good” online algorithm depends on total variation in the sequence of stock
returns, rather than purely on the number of iterations. If the stock return sequence has low variation,
we expect our algorithm to be able to perform better. If we trade more frequently, then the per
iteration variation should go down correspondingly, so the total variation stays the same.
We analyze a portfolio selection algorithm and prove that its regret is bounded by O(log Q), where
Q (formally deﬁned in Section 1.2) is the sum of squared deviations of the returns from their mean.
Since Q ≤ T (after appropriate normalization), we improve over previous regret bounds and retain
the worst-case robustness. Furthermore, in an average-case model such as GBM, the variation can
be tied very nicely to the volatility parameter, which explains the experimental observation the regret
doesn’t increase with increasing trading frequency. Our algorithm is efﬁcient, and its implementa-
tion requires constant time per iteration (independent of the number of game iterations).

1.1 New Techniques and Comparison to Related Work

Cesa-Bianchi, Mansour and Stoltz [CBMS07] initiated work on relating worst case regret to the
variation in the data for the related learning problem of prediction from expert advice, and conjec-
√
tured that the optimal regret bounds should depend on the observed variation of the cost sequence.
Recently, this conjectured was proved and regret bounds of ˜O(
Q) were obtained in the full infor-
mation and bandit linear optimization settings [HK08, HK09], where Q is the variation in the cost
sequence. In this paper we give an exponential improvement in regret, viz. O(log Q), for the case
of online exp-concave optimization, which includes portfolio selection as a special case.
Another approach to connecting worst-case to average-case investing was taken by Jamshidian
[Jam92] and Cross and Barron [CB03]. They considered a model of “continuous trading”, where
there are T “trading intervals”, and in each the online investor chooses a ﬁxed portfolio which is
rebalanced k times with k → ∞. They prove familiar regret bounds of O(log T ) (independent of
k) in this model w.r.t. the best ﬁxed portfolio which is rebalanced T × k times. In this model our
algorithm attains the tighter regret bounds of O(log Q), although our algorithm has more ﬂexibility.
Furthermore their algorithms, being extensions of Cover’s algorithm, may require exponential time
in general1 .
√
Our bounds of O(log Q) regret require completely different techniques compared to the ˜O(
Q)
regret bounds of [HK08, HK09]. These previous bounds are based on ﬁrst-order gradient descent
methods which are too weak to obtain O(log Q) regret. Instead we have to use the second-order
Newton step ideas based on [HKKA06] (in particular, the Hessian of the cost functions).
The second-order techniques of [HKKA06] are, however, not sensitive enough to obtain O(log Q)
bounds. This is because progress was measured in terms of the distance between successive portfo-
lios in the usual Euclidean norm, which is insensitive to variation in the cost sequence. In this paper,
we introduce a different analysis technique, based on analyzing the distance between successive
predictions using norms that keep changing from iteration to iteration and are actually sensitive to
the variation.
A key technical step in the analysis is a lemma (Lemma 6) which bounds the sum of differences of
successive Cesaro means of a sequence of vectors by the logarithm of its variation. This lemma,

1Cross and Barron give an efﬁcient implementation for some interesting special cases, under assumptions
on the variation in returns and bounds on the magnitude of the returns, and assuming k → ∞. A truly efﬁcient
implementation of their algorithm can probably be obtained using the techniques of Kalai and Vempala.

2

which may be useful in other contexts when variation bounds on the regret are desired, is proved
using the Kahn-Karush-Tucker conditions, and also improves the regret bounds in previous papers.

1.2 The model and statement of results
Portfolio management. In the universal portfolio management model [Cov91], an online investor
∆n = {(cid:80)
iteratively distributes her wealth over n assets before observing the change in asset price. In each
iteration t = 1, 2, . . . the investor commits to an n-dimensional distribution of her wealth, xt ∈
i xi = 1 , x ≥ 0}. She then observes a price relatives vector rt ∈ Rn
+ , where rt (i) is
(cid:81)
the ratio between the closing price of the ith asset on trading period t and the opening price. In the
(cid:81)
(cid:80)
tth trading period, the wealth of the investor changes by a factor of (rt · xt ). The overall change in
t (rt · xt ). Since in a typical market wealth grows at an exponential rate, we measure
wealth is thus
(cid:81)
t (rt · xt ) =
t log(rt · xt ). A constant
performance by the exponential growth rate, which is log
rebalanced portfolio (CRP) is an investment strategy which rebalances the wealth in every iteration
to keep a ﬁxed distribution. Thus, for a CRP x ∈ ∆n , the change in wealth is
t (rt · x).
(cid:88)
(cid:88)
The regret of the investor is deﬁned to be the difference between the exponential growth rate of her
investment strategy and that of the best CRP strategy in hindsight, i.e.
log(rt · xt )
log(rt · x∗ ) −
t
t

Regret := max
x∗∈∆n

ft (x).

ft (xt ) − min
x∈K

Note that the regret doesn’t change if we scale all the returns in any particular period by the same
amount. So we assume w.l.o.g. that in all periods t, maxi rt (i) = 1. We assume that there is known
parameter r > 0, such that for all periods t, mint,i rt (i) ≥ r . We call r the market variability
parameter. This is the only restriction we put on the stock price returns; they could be chosen
adversarially as long as they respect the market variability bound.
Online convex optimization. In the online convex optimization problem [Zin03], which generalizes
universal portfolio management, the decision space is a closed, bounded, convex set K ∈ Rn , and
we are sequentially given a series of convex cost2 functions ft : K → R for t = 1, 2, . . .. The
algorithm iteratively produces a point xt ∈ K in every round t, without knowledge of ft (but using
T(cid:88)
T(cid:88)
the past sequence of cost functions), and incurs the cost ft (xt ). The regret at time T is deﬁned to be
(cid:80)T
(cid:80)
Regret :=
t=1
t=1
t=1 . In this paper, we restrict our attention to convex cost functions
t denote
Usually, we will let
which can be written as ft (x) = g(vt · x) for some univariate convex function g and a parameter
vector vt ∈ Rn (for example, in the portfolio management problem, K = ∆n , ft (x) = − log(rt · x),
g = − log, and vt = rt ).
Thus, the cost functions are parametrized by the vectors v1 , v2 , . . . , vT . Our bounds will be ex-
T(cid:88)
pressed as a function of the quadratic variability of the parameter vectors v1 , v2 , . . . , vT , deﬁned
as
(cid:107)vt − µ(cid:107)2 .
(cid:80)T
Q(v1 , ..., vT ) := min
µ
t=1
t=1 vt , and thus the quadratic variation is just T − 1 times
This expression is minimized at µ = 1
the sample variance of the sequence of vectors {v1 , ..., vt }. Note however that the sequence can be
T
generated adversarially rather than by some stochastic process. We shall refer to this as simply Q if
the vectors are clear from the context.
Main theorem. In the setup of the online convex optimization problem above, we have the following
algorithmic result:
Theorem 1. Let the cost functions be of the form ft (x) = g(vt ·x). Assume that there are parameters
R, D , a, b > 0 such that the following conditions hold:

2Note the difference from the portfolio selection problem: here we have convex cost functions, rather than
concave payoff functions. The portfolio selection problem is obtained by using − log as the cost function.

3

1. for all t, (cid:107)vt (cid:107) ≤ R,
2. for all x ∈ K , we have (cid:107)x(cid:107) ≤ D ,
3. for all x ∈ K , and for all t, either g (cid:48) (vt · x) ∈ [0, a] or g (cid:48) (vt · x) ∈ [−a, 0], and
4. for all x ∈ K , and for all t, g (cid:48)(cid:48) (vt · x) ≥ b.
Then there is an algorithm that guarantees the following regret bound:
Regret = O((a2n/b) log(1 + bQ + bR2 ) + aRD log(2 + Q/R2 ) + D2 ).
eters. We have (cid:107)rt (cid:107) ≤ √
√
Now we apply Theorem 1 to the portfolio selection problem. First, we estimate the relevant param-
n. For any x ∈ ∆n , (cid:107)x(cid:107) ≤ 1, so D = 1.
n since all rt (i) ≤ 1, thus R =
g (cid:48) (vt · x) = − 1
(vt ·x) , and thus g (cid:48) (vt · x) ∈ [− 1
r . Finally, g (cid:48)(cid:48) (vt · x) = 1
(vt ·x)2 ≥ 1, so
r , 0], so a = 1
b = 1. Applying Theorem 1 we get the following corollary:
(cid:179) n
(cid:180)
Corollary 2. For the portfolio selection problem over n assets, there is an algorithm that attains
the following regret bound:
r2 log(Q + n)
2 Bounding the Regret by the Observed Variation in Returns

Regret = O

.

2.1 Preliminaries
All matrices are assumed be real symmetric matrices in Rn×n , where n is the number of stocks. We
use the notation A (cid:186) B to say that A − B is positive semideﬁnite. We require the notion of a norm
√
of a vector x induced by a positive deﬁnite matrix M , deﬁned as (cid:107)x(cid:107)M =
x(cid:62)M x. The following
simple generalization of the Cauchy-Schwartz inequality is used in the analysis:
(cid:80)
x · y ≤ (cid:107)x(cid:107)M (cid:107)y(cid:107)M −1 .
∀x, y ∈ Rn :
We denote by |A| the determinant of a matrix A, and by A • B = Tr(AB ) =
ij Aij Bij . As
we are concerned with logarithmic regret bounds, potential functions which behave like harmonic
series come into play. A generalization of harmonic series to high dimensions is the vector-harmonic
series, which is a series of quadratic forms that can be expressed as (here A (cid:194) 0 is a positive deﬁnite
(cid:80)t
matrix, and v1 , v2 , . . . are vectors in Rn ):
τ =1 vτ v(cid:62)
τ )−1 vt , . . .
v(cid:62)
2 )−1 v2 , . . . , v(cid:62)
1 + v2 v(cid:62)
1 (A + v1 v(cid:62)
1 )−1 v1 , v(cid:62)
2 (A + v1 v(cid:62)
t (A +
The following lemma is from [HKKA06]:
(cid:34)
(cid:35)
(cid:80)T
T(cid:88)
(cid:80)t
Lemma 3. For a vector harmonic series given by an initial matrix A and vectors v1 , v2 , . . . , vT , we
have
τ |
|A +
τ =1 vτ v(cid:62)
τ )−1 vt ≤ log
τ =1 vτ v(cid:62)
|A|
t=1
The reader can note that in one dimension, if all vectors vt = 1 and A = 1, then the series above
reduces exactly to the regular harmonic series whose sum is bounded, of course, by log(T + 1).

v(cid:62)
t (A +

.

2.2 Algorithm and analysis

We analyze the following algorithm and prove that it attains logarithmic regret with respect to the
observed variation (rather than number of iterations). The algorithm follows the generic algorithmic
scheme of “Follow-The-Regularized-Leader” (FTRL) with squared Euclidean regularization.
(cid:195)
(cid:33)
t−1(cid:88)
Algorithm Exp-Concave-FTL. In iteration t, use the point xt deﬁned as:
τ =1

xt (cid:44) arg min
x∈∆n

fτ (x) +

(1)

(cid:107)x(cid:107)2

1
2

Note the mathematical program which the algorithm solves is convex, and can be solved in time
polynomial in the dimension and number of iterations. The running time, however, for solving this

4

convex program can be quite high.
In the full version of the paper, for the speciﬁc problem of
portfolio selection, where ft (x) = − log(rt · x), we give a faster implementation whose per itera-
tion running time is independent of the number of iterations, using the more sophisticated “online
Newton method” of [HKKA06]. In particular, we have the following result:
(cid:179) n
(cid:180)
Theorem 4. For the portfolio selection problem, there is an algorithm that runs in O(n3 ) time per
iteration whose regret is bounded by
r3 log(Q + n)
In this paper, we retain the simpler algorithm and analysis for an easier exposition. We now proceed
to prove the Theorem 1.

Regret = O

.

Proof. [Theorem 1] First, we note that the algorithm is running a “Follow-the-leader” procedure
2 (cid:107)x(cid:107)2 is a ﬁctitious period 0 cost function. In
on the cost functions f0 , f1 , f2 , . . . where f0 (x) = 1
other words, in each iteration, it chooses the point that would have minimized the total cost under
all the observed functions so far (and, additionally, a ﬁctitious initial cost function f0 ). This point is
referred to as the leader in that round.
The ﬁrst step in analyzing such an algorithm is to use a stability lemma from [KV05], which bounds
the regret of any Follow-the-leader algorithm by the difference in costs (under ft ) of the current pre-
Regret ≤ (cid:80)
diction xt and the next one xt+1 , plus an additional error term which comes from the regularization.
Thus, we have
≤ (cid:80)
1
t ft (xt ) − ft (xt+1 ) +
((cid:107)x∗ (cid:107)2 − (cid:107)x0 (cid:107)2 )
2
(cid:80)
1
t∇ft (xt ) · (xt − xt+1 ) +
2 D2
1
t g (cid:48) (vt · xt )[vt · (xt − xt+1 )] +
=
(2)
2 D2
(cid:80)t−1
The second inequality is because ft is convex. The last equality follows because ∇ft (xt ) = g (cid:48) (xt ·
vt )vt . Now, we need a handle on xt − xt+1 . For this, deﬁne Ft =
(cid:80)t
τ =0 fτ , and note that xt
minimizes Ft over K . Consider the difference in the gradients of Ft+1 evaluated at xt+1 and xt :
(cid:80)t
τ =0∇fτ (xt+1 ) − ∇fτ (xt )
∇Ft+1 (xt+1 ) − ∇Ft+1 (xt ) =
(cid:80)t
τ (vτ · xt+1 ) − g (cid:48)
τ (vτ · xt )]vτ + (xt+1 − xt )
τ =1 [g (cid:48)
=
(cid:80)t
τ ) · (xt+1 − xt )]vτ + (xt+1 − xt )
τ (vτ · ζ t
τ =1 [∇g (cid:48)
=
(3)
τ (xt+1 − xt ) + (xt+1 − xt ).
τ (vτ · ζ t
τ )vτ v(cid:62)
τ =1 g (cid:48)(cid:48)
=
(4)
τ (vτ · x) at
Equation 3 follows by applying the Taylor expansion of the (multi-variate) function g (cid:48)
(cid:80)t
point xt , for some point ζ t
τ on the line segment joining xt and xt+1 . The equation (4) follows from
τ (vτ · x)vτ .
τ (vτ · x) = g (cid:48)(cid:48)
the observation that ∇g (cid:48)
τ =1 g (cid:48)(cid:48) (vt · ζ t
t + I , where I is the identity matrix, and ∆xt = xt+1 − xt . Then
τ )vt v(cid:62)
Deﬁne At =
equation (4) can be re-written as:
∇Ft+1 (xt+1 ) − ∇Ft (xt ) − g (cid:48) (vt · xt )vt = At∆xt .
(5)
Now, since xt minimizes the convex function Ft over the convex set K , a standard inequality of
convex optimization (see [BV04]) states that for any point y ∈ K , we have ∇Ft (xt ) · (y − xt ) ≥ 0.
Thus, for y = xt+1 , we get that ∇Ft (xt ) · (xt+1 − xt ) ≥ 0. Similarly, we get that ∇Ft+1 (xt+1 ) ·
(xt − xt+1 ) ≥ 0. Putting these two inequalities together, we get that
(∇Ft+1 (xt+1 ) − ∇Ft (xt )) · ∆xt ≤ 0.
Thus, using the expression for At∆xt from (5) we have
At = At∆xt · ∆xt
(cid:107)∆xt (cid:107)2
= (∇Ft+1 (xt+1 ) − ∇Ft (xt ) − g (cid:48) (vt · xt )vt ) · ∆xt
≤ g (cid:48) (vt · xt )[vt · (xt − xt+1 )]

(from (6))

(6)

(7)

5

≤

·

−1
t

(11)

Assume that g (cid:48) (vt · x) ∈ [−a, 0] for all x ∈ K and all t. The other case is handled similarly.
Inequality (7) implies that g (cid:48) (vt · xt ) and vt · (xt − xt+1 ) have the same sign. Thus, we can upper
(cid:80)t
bound
g (cid:48) (vt · xt )[vt · (xt − xt+1 )] ≤ a(vt · ∆xt ).
(8)
(cid:80)
(cid:80)
(cid:80)T
Deﬁne ˜vt = vt − µt , µt = 1
τ =1 vτ . Then, we have
(cid:80)t
(cid:80)T −1
t+1
t=2xt (µt−1 − µt ) − x1µ1 + xT +1µT ,
t ˜vt · ∆xt +
t vt · ∆xt =
(9)
t=2xt (µt−1 − µt ) − x1µ1 + xT +1µT ≤ (cid:80)T
(cid:80)T
t=1 (cid:107)µt+1 − µt (cid:107).
where ˜vt = vt − µt , µt = 1
τ =1 vt . Now, deﬁne ρ = ρ(v1 , . . . , vT ) =
t+1
Then we bound
t=2 (cid:107)xt(cid:107)(cid:107)µt−1 − µt (cid:107) + (cid:107)x1 (cid:107)(cid:107)µ1 (cid:107) + (cid:107)xT +1 (cid:107)(cid:107)µT (cid:107)
≤ Dρ + 2DR.
(10)
We will bound ρ momentarily. For now, we turn to bounding the ﬁrst term of (9) using the Cauchy-
Schwartz generalization as follows:
˜vt · ∆xt ≤ (cid:107)˜vt (cid:107)A
(cid:107)∆xt (cid:107)At .
(cid:113)(cid:80)
(cid:113)(cid:80)
(cid:113)(cid:80)
(cid:113)(cid:80)
−1
(cid:80)
t
By the usual Cauchy-Schwartz inequality,
t (cid:107)∆xt (cid:107)2
t (cid:107)˜vt (cid:107)2
(cid:107)∆xt (cid:107)At ≤
t (cid:107)˜vt (cid:107)A
ta(vt · ∆xt )
t (cid:107)˜vt(cid:107)2
·
(cid:113)(cid:80)
(cid:113)(cid:80)
−1
−1
(cid:80)
At
A
A
t
t
from (7) and (8). We conclude, using (9), (10) and (11), that
·
t (cid:107)˜vt(cid:107)2
ta(vt · ∆xt ) ≤ a
ta(vt · ∆xt ) + aDρ + 2aDR.
ta(vt · ∆xt ) ≤ a2(cid:80)
(cid:80)
−1
A
t
This implies (using the AM-GM inequality applied to the ﬁrst term on the RHS) that
t (cid:107)˜vt(cid:107)2
+ 2aDρ + 4aDR.
−1
Regret ≤ a2(cid:80)
A
t
Plugging this into the regret bound (2) we obtain, via (8),
1
t (cid:107)˜vt (cid:107)2
+ 2aDρ + 4aDR +
2 D2 .
A
The proof is completed by the following two lemmas (Lemmas 5 and 6) which bound the RHS. The
(cid:164)
(cid:163)
(cid:80)
ﬁrst term is a vector harmonic series, and the second term can be bounded by a (regular) harmonic
series.
≤ 3n
t (cid:107)˜vt(cid:107)2
(cid:80)
(cid:80)t
Lemma 5.
b log
1 + bQ + bR2
−1
A
(cid:80)
t
τ =1 g (cid:48)(cid:48) (vt · ζ t
t + I . Since g (cid:48)(cid:48) (vt · ζ t
τ ) ≥ b, we have At (cid:186) I + b
t vt v(cid:62)
τ )vt v(cid:62)
(cid:33)
(cid:33)
(cid:195)
(cid:195)
Proof. We have At =
t .
t(cid:88)
(cid:88)
t(cid:88)
t(cid:88)
t(cid:88)
t(cid:88)
Using the fact that ˜vt = vt − µt and µt = 1
τ ≤t vτ , we get that
t+1
(τ +1)2 ≤ (cid:82) t+1
(cid:80)t
− 1
s + vs v(cid:62)
[vr v(cid:62)
vs v(cid:62)
˜vτ ˜v(cid:62)
r ].
s +
1 +
τ =
s +
1
1
(τ +1)2
(τ +1)2
r<s
τ =s
τ =s
s=1
τ =1
s=1
s − 1
t+1 . Since (vr + vs )(vr + vs )(cid:62) (cid:186) 0, we get that
x2 dx = 1
Now,
1
1
τ (cid:185) t(cid:88)
t(cid:88)
s ] (cid:185) t(cid:88)
t(cid:88)
(cid:88)
t(cid:88)
(cid:161)
(cid:162)
(cid:161)
(cid:162)
τ =s
s
s (cid:186) −[vr v(cid:62)
s + vs v(cid:62)
vr v(cid:62)
r + vs v(cid:62)
r ], and hence we have
(cid:80)
s (cid:185) 3
˜vτ ˜v(cid:62)
vs v(cid:62)
vs v(cid:62)
r + vs v(cid:62)
t+1 [vr v(cid:62)
vs v(cid:62)
1 + 1
2 + 1
s +
1
s .
s
s
r<s
τ =1
s=1
s=1
s=1
s=1
(cid:104) | ˜AT |
(cid:105)
(cid:88)
(cid:88)
3, we get (cid:88)
t . Note that the inequality above shows that 3 ˜At (cid:186) At . Thus, using Lemma
t ˜vt ˜v(cid:62)
Let ˜At = 1
3 I + b
√
√
t ˜vt ≤ 3
(cid:107)˜vt(cid:107)2
˜vtA−1
b˜vt ](cid:62) ˜A−1
[
[
=
−1
| ˜A0 |
t
b
A
(cid:80)
(cid:80)
t
t
t
t
To bound the latter quantity note that | ˜A0 | = |I | = 1, and that
(cid:80)
(cid:80)
| ˜AT | = |I + b
t(cid:107)˜vt (cid:107)2
t | ≤ (1 + b
t ˜vt ˜v(cid:62)
2 )n = (1 + b ˜Q)n
t (cid:107)˜vt (cid:107)2 =
t (cid:107)˜vt − µt (cid:107)2 . Lemma 7 (proved in the full version of the paper), we
where ˜Q =
show that ˜Q ≤ Q + R2 . This implies that | ˜AT | ≤ (1 + bQ + bR2 )n and the proof is completed by
substituting this bound into (12).

b˜vt ] ≤ 3
b log

(12)

.

−1
t

.

6

Furthermore,

Lemma 6. ρ(v1 , . . . , vT ) ≤ 2R[log(2 + Q/R2 ) + 1].
(cid:80)T
(cid:80)T
Proof. Deﬁne, for τ ≥ 0, the vector uτ = vτ − µT +1 . Note that by convention, we have v0 = 0.
We have
τ =1 (cid:107)vτ − µT +1 (cid:107)2 = R2 + Q.
τ =0 (cid:107)uτ (cid:107)2 = (cid:107)µT +1 (cid:107)2 +
(cid:176)(cid:176)(cid:176) 1
(cid:176)(cid:176)(cid:176)
(cid:80)t
(cid:80)t+1
(cid:176)(cid:176)(cid:176)
(cid:176)(cid:176)(cid:176) 1
(cid:80)t
(cid:80)t+1
(cid:107)µt+1 − µt(cid:107) =
τ =0 vτ − 1
τ =0 vτ
t+2
t+1
(cid:80)t
τ =0uτ − 1
=
τ =0uτ
t+2
t+1
≤ 1
t+1 (cid:107)ut+1 (cid:107)
τ =0 (cid:107)uτ (cid:107) + 1
(cid:180)
(cid:179)
(t+1)2
≤ (cid:80)
(cid:80)t
t (cid:107)µt+1−µt (cid:107) ≤ (cid:80)
(cid:80)
Summing up over all iterations,
t (cid:107)ut−1(cid:107) ≤ 2R[log(2+Q/R2 )+1].
τ =0 (cid:107)uτ (cid:107) + 1
t+1 (cid:107)ut+1 (cid:107)
2
1
(t+1)2
t
t
The last inequality follows from Lemma 8 (proved in the full version) below by setting xt =
(cid:107)ut−1(cid:107)/R, for t ≥ 1.
(cid:80)T
(cid:80)
Lemma 7. ˜Q ≤ Q + R2 .
t=1 xt/t ≤ log(1 + Q) + 1.
Lemma 8. Suppose that 0 ≤ xt ≤ 1 and
t ≤ Q. Then
t x2
3 Implications in the Geometric Brownian Motion Model

We begin with a brief description of the model. The model assumes that stocks can be traded con-
tinuously, and that at any time, the fractional change in the stock price within an inﬁnitesimal time
interval is normally distributed, with mean and variance proportional to the length of the interval.
The randomness is due to many inﬁnitesimal trades that jar the price, much like particles in a physi-
cal medium are jarred about by other particles, leading to the classical Brownian motion.
Formally, the model is parameterized by two quantities, the drift µ, which is the long term trend
of the stock prices, and volatility σ , which characterizes deviations from the long term trend. The
parameter σ is typically speciﬁed as annualized volatility, i.e. the standard deviation of the stock’s
logarithmic returns in one year. Thus, a trading interval of [0, 1] speciﬁes 1 year. The model pos-
tulates that the stock price at time t, St , follows a geometric Brownian motion with drift µ and
volatility σ :

dSt = µStdt + σStdWt ,
where Wt is a continuous-time stochastic process known as the Wiener process or simply Brownian
motion. The Wiener process is characterized by three facts:

1. W0 = 0,
2. Wt is almost surely continuous, and
3. for any two disjoint time intervals [s1 , t1 ] and [s2 , t2 ], the random variables Wt1 − Ws1 and
Wt2 − Ws2 are independent zero mean Gaussian random variables with variance t1 − s1
and t2 − s2 respectively.
Using It ¯o’s lemma (see, for example, [KS04]), it can be shown that the stock price at time t is given
by
St = S0 exp((µ − σ2/2)t + σWt ).
Now, we consider a situation where we have n stocks in the GBM model. Let µ = (µ1 , µ2 , . . . , µn )
be the vector of drifts, and σ = (σ1 , σ2 , . . . , σn ) be the vector of (annualized) volatilities. Suppose
we trade for one year. We now study the effect of trading frequency on the quadratic variation
of the stock price returns. For this, assume that the year-long trading interval is sub-divided into
T equally sized intervals of length 1/T , and we trade at the end of each such interval. Let rt =
(rt (1), rt (2), . . . , rt (n)) be the vector of stock returns in the tth trading period. We assume that T is
“large enough”, which is taken to mean that it is larger than µ(i), σ(i), ( µ(i)
σ(i) )2 for any i.

(13)

7

Then using the facts of the Wiener process stated above, we can prove the following lemma, which
shows that the expected quadratic variation, and its variance, is the essentially the same regardless
of trading frequency. The proof is a straightforward calculation and deferred to the full version of
this paper.
(cid:105)
(cid:104)(cid:80)T
Lemma 9. In the setup of trading n stocks in the GBM model over one year with T trading periods,
there is a vector v such that
(cid:104)(cid:80)T
(cid:105)
≤ (cid:107)σ(cid:107)2 (1 + O( 1
t=1 (cid:107)rt − v(cid:107)2
T ))
t=1 (cid:107)rt − v(cid:107)2
VAR
regardless of how the stocks are correlated.

≤ 6(cid:107)σ(cid:107)2 (1 + O( 1
T )),

and

E

Applying this bound in our algorithm, we obtain the following regret bound from Corollary 2.
Theorem 10. In the setup of Lemma 9, for any δ > 0, with probability at least 1 − 2e−δ , we have
Regret ≤ O(n(log((cid:107)σ(cid:107)2 + n) + δ)).
Theorem 10 shows that one expects to achieve constant regret independent of the trading frequency,
as long as the total trading period is ﬁxed. This result is only useful if increasing trading frequency
improves the performance of the best constant rebalanced portfolio. Indeed, this has been observed
empirically (see e.g. [AHKS06], and more empirical evidence is given in the full version of this
paper.).
To obtain a theoretical justiﬁcation for increasing trading frequency, we consider an example where
we have two stocks that follow independent Black-Scholes models with the same drifts, but different
volatilities σ1 , σ2 . The same drift assumption is necessary because in the long run, the best CRP is
the one that puts all its wealth on the stock with the greater drift. We normalize the drifts to be equal
to 0, this doesn’t change the performance in any qualitative manner.
Since the drift is 0, the expected return of either stock in any trading period is 1; and since the
returns in each period are independent, the expected ﬁnal change in wealth, which is the product
of the returns, is also 1. Thus, in expectation, any CRP (indeed, any portfolio selection strategy)
has overall return 1. We therefore turn to a different criterion for selecting a CRP. The risk of an
investment strategy is measured by the variance of its payoff; thus, if different investment strategies
have the same expected payoff, then the one to choose is the one with minimum variance. We
therefore choose the CRP with the least variance. We prove the following lemma in the full version
of the paper:
Lemma 11. In the setup where we trade two stocks with zero drift and volatilities σ1 , σ2 , the vari-
ance of the minimum variance CRP decreases as the trading frequency increases.

Thus, increasing the trading frequency decreases the variance of the minimum variance CRP, which
implies that it gets less risky to trade more frequently; in other words, the more frequently we trade,
the more likely the payoff will be close to the expected value. On the other hand, as we show
in Theorem 10, the regret does not change even if we trade more often; thus, one expects to see
improving performance of our algorithm as the trading frequency increases.

4 Conclusions and Future Work

We have presented an efﬁcient algorithm for regret minimization with exp-concave loss functions
whose regret strictly improves upon the state of the art. For the problem of portfolio selection,
the regret is bounded in terms of the observed variation in stock returns rather than the number of
iterations.
Recently, DeMarzo, Kremer and Mansour [DKM06] presented a novel game-theoretic framework
for option pricing. Their method prices options using low regret algorithms, and it is possible that
our analysis can be applied to options pricing via their method (although that would require a much
tighter optimization of the constants involved).
Increasing trading frequency in practice means increasing transaction costs. We have assumed no
transaction costs in this paper. It would be very interesting to extend our portfolio selection algorithm
to take into account transaction costs as in the work of Blum and Kalai [BK97].

8

[BK97]

[BS73]

[KS04]

[BV04]

[CB03]

[Bac00]

References
[AHKS06] Amit Agarwal, Elad Hazan, Satyen Kale, and Robert E. Schapire. Algorithms for port-
folio management based on the newton method. In ICML, pages 9–16, 2006.
L. Bachelier. Th ´eorie de la sp ´eculation. Annales Scientiﬁques de l’ ´Ecole Normale
Sup ´erieure, 3(17):21–86, 1900.
Avrim Blum and Adam Kalai. Universal portfolios with and without transaction costs.
In COLT, pages 309–313, New York, NY, USA, 1997. ACM.
Fischer Black and Myron Scholes. The pricing of options and corporate liabilities.
Journal of Political Economy, 81(3):637–654, 1973.
Stephen Boyd and Lieven Vandenberghe. Convex Optimization. Cambridge University
Press, New York, NY, USA, 2004.
Jason E Cross and Andrew R Barron. Efﬁcient universal portfolios for past dependent
target classes. Mathematical Finance, 13(2):245–276, 2003.
[CBMS07] Nicol `o Cesa-Bianchi, Yishay Mansour, and Gilles Stoltz.
Improved second-order
bounds for prediction with expert advice. Mach. Learn., 66(2-3):321–352, 2007.
[Cov91]
T. Cover. Universal portfolios. Math. Finance, 1:1–19, 1991.
[DKM06] Peter DeMarzo, Ilan Kremer, and Yishay Mansour. Online trading algorithms and ro-
bust option pricing. In STOC ’06: Proceedings of the thirty-eighth annual ACM sym-
posium on Theory of computing, pages 477–486, New York, NY, USA, 2006. ACM.
Elad Hazan and Satyen Kale. Extracting certainty from uncertainty: Regret bounded
by variation in costs. In Proceedings of 21st COLT, 2008.
Elad Hazan and Satyen Kale. Better algorithms for benign bandits. In SODA, pages
38–47, Philadelphia, PA, USA, 2009. Society for Industrial and Applied Mathematics.
[HKKA06] Elad Hazan, Adam Kalai, Satyen Kale, and Amit Agarwal. Logarithmic regret algo-
rithms for online convex optimization. In COLT, pages 499–513, 2006.
[HSSW96] David P. Helmbold, Robert E. Schapire, Yoram Singer, and Manfred K. Warmuth. On-
line portfolio selection using multiplicative updates. In ICML, pages 243–251, 1996.
F. Jamshidian. Asymptotically optimal portfolios. Mathematical Finance, 2:131–150,
1992.
Ioannis Karatzas and Steven E. Shreve. Brownian Motion and Stochastic Calculus.
Springer Verlag, New York, NY, USA, 2004.
Adam Kalai and Santosh Vempala. Efﬁcient algorithms for universal portfolios. J.
Mach. Learn. Res., 3:423–440, 2003.
Adam Kalai and Santosh Vempala. Efﬁcient algorithms for online decision problems.
Journal of Computer and System Sciences, 71(3):291–307, 2005.
Neri Merhav and Meir Feder. Universal sequential learning and decision from individ-
ual data sequences. In COLT, pages 413–427, 1992.
[Osb59] M. F. M. Osborne. Brownian motion in the stock market. Operations Research, 2:145–
173, 1959.
Martin Zinkevich. Online convex programming and generalized inﬁnitesimal gradient
ascent. In ICML, pages 928–936, 2003.

[Jam92]

[HK08]

[HK09]

[Zin03]

[KV03]

[KV05]

[MF92]

9

