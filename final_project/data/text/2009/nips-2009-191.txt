Neural Implementation of Hierarchical Bayesian
Inference by Importance Sampling

Lei Shi
Helen Wills Neuroscience Institute
University of California, Berkeley
Berkeley, CA 94720
lshi@berkeley.edu

Thomas L. Grifﬁths
Department of Psychology
University of California, Berkeley
Berkeley, CA 94720
tom griffiths@berkeley.edu

Abstract

The goal of perception is to infer the hidden states in the hierarchical process by
which sensory data are generated. Human behavior is consistent with the opti-
mal statistical solution to this problem in many tasks, including cue combination
and orientation detection. Understanding the neural mechanisms underlying this
behavior is of particular importance, since probabilistic computations are notori-
ously challenging. Here we propose a simple mechanism for Bayesian inference
which involves averaging over a few feature detection neurons which ﬁre at a rate
determined by their similarity to a sensory stimulus. This mechanism is based
on a Monte Carlo method known as importance sampling, commonly used in
computer science and statistics. Moreover, a simple extension to recursive im-
portance sampling can be used to perform hierarchical Bayesian inference. We
identify a scheme for implementing importance sampling with spiking neurons,
and show that this scheme can account for human behavior in cue combination
and the oblique effect.

1

Introduction

Living creatures occupy an environment full of uncertainty due to noisy sensory inputs, incomplete
observations, and hidden variables. One of the goals of the nervous system is to infer the states of the
world given these limited data and make decisions accordingly. This task involves combining prior
knowledge with current data [1], and integrating cues from multiple sensory modalities [2]. Studies
of human psychophysics and animal behavior suggest that the brain is capable of solving these
problems in a way that is consistent with optimal Bayesian statistical inference [1, 2, 3, 4]. Moreover,
complex brain functions such as visual information processing involves multiple brain areas [5].
Hierarchical Bayesian inference has been proposed as a computational framework for modeling such
processes [6]. Identifying neural mechanisms that could support hierarchical Bayesian inference is
important, since probabilistic computations can be extremely challenging. Just representing and
updating distributions over large numbers of hypotheses is computationally expensive.
Much effort has recently been devoted towards proposing possible mechanisms based on known
neuronal properties. One prominent approach to explaining how the brain uses population activities
for probabilistic computations has been done in the “Bayesian decoding” framework [7]. In this
framework, it is assumed that the ﬁring rate of a population of neurons, r , can be converted to a
probability distribution over stimuli, p(s|r), by applying Bayesian inference, where the likelihood
p(r|s) reﬂects the probability of that ﬁring pattern given the stimulus s. A ﬁring pattern thus encodes
a distribution over stimuli, which can be recovered through Bayesian decoding. The problem of
performing probabilistic computations then reduces to identifying a set of operations on ﬁring rates
r that result in probabilistically correct operations on the resulting distributions p(s|r). For example,

1

[8] showed that when the likelihood p(r|s) is an exponential family distribution with linear sufﬁcient
statistics, adding two sets of ﬁring rates is equivalent to multiplying probability distributions.
In this paper, we take a different approach, allowing a population of neurons to encode a probability
distribution directly. Rather than relying on a separate decoding operation, we assume that the activ-
ity of each neuron translates directly to the weight given to the optimal stimulus for that neuron in the
corresponding probability distribution. We show how this scheme can be used to perform Bayesian
inference, and how simple extensions of this basic idea make it possible to combine sources of in-
formation and to propagate uncertainty through multiple layers of random variables. In particular,
we focus on one Monte Carlo method, namely importance sampling with the prior as a surrogate,
and show how recursive importance sampling approximates hierarchical Bayesian inference.

2 Bayesian inference and importance sampling
Given a noisy observation x, we can recover the true stimulus x∗ by using Bayes’ rule to compute
(cid:82)
the posterior distribution
p(x∗ )p(x|x∗ )
p(x∗ |x) =
(1)
x∗ p(x∗ )p(x|x∗ )dx∗
where p(x∗ ) is the prior distribution over stimulus values, and p(x|x∗ ) is the likelihood, indicating
the probability of the observation x if the true stimulus value is x∗ . A good guess for the value of
x∗ is the expectation of x∗ given x. In general, we are often interested in the expectation of some
function f (x∗ ) over the posterior distribution p(x∗ |x), E [f (x∗ )|x]. The choice of f (x∗ ) depends
on the task. For example, in noise reduction where x∗ itself is of interest, we can take f (x∗ ) = x∗ .
However, evaluating expectations over the posterior distribution can be challenging: it requires com-
puting a posterior distribution and often a multidimensional integration. The expectation E [f (x∗ )|x]
can be approximated using a Monte Carlo method known as importance sampling. In its general
form, importance sampling approximates the expectation by using a set of samples from some surro-
(cid:90)
M(cid:88)
gate distribution q(x∗ ) and assigning those samples weights proportional to the ratio p(x∗ |x)/q(x∗ ).
f (x∗ ) p(x∗ |x)
i |x)
i ) p(x∗
q(x∗ ) q(x∗ )dx∗ (cid:39) 1
E [f (x∗ )|x] =
i ∼ q(x∗ )
f (x∗
x∗
q(x∗
i )
M
i=1
M(cid:88)
M(cid:88)
M(cid:88)
If we choose q(x∗ ) to be the prior p(x∗ ), the weights reduce to the likelihood p(x|x∗ ), giving
i ) p(x|x∗
i |x)
i ) p(x∗
i ) p(x, x∗
1
1
E [f (x∗ )|x] (cid:39) 1
i )
i )
f (x∗
f (x∗
f (x∗
(cid:80)M
=
p(x∗
p(x∗
(cid:82) p(x|x∗ )p(x∗ )dx∗ (cid:39) (cid:88)
i )
i )p(x)
p(x)
M
M
M
(cid:80)
i=1
i=1
i=1
i )p(x|x∗
p(x|x∗
i=1 f (x∗
i )
i )
1
f (x∗
i )
M
p(x|x∗
i )
x∗
x∗
i
i
Thus, importance sampling provides a simple and efﬁcient way to perform Bayesian inference,
approximating the posterior distribution with samples from the prior weighted by the likelihood.
Recent work also has suggested that importance sampling might provide a psychological mechanism
for performing probabilistic inference, drawing on its connection to exemplar models [9].

i ∼ p(x∗ )
x∗

=

=

(2)

(3)

3 Possible neural implementations of importance sampling

The key components of an importance sampler can be realized in the brain if: 1) there are feature
detection neurons with preferred stimulus tuning curves proportional to the likelihood p(x|x∗
i ); 2)
the frequency of these feature detection neurons is determined by the prior p(x∗ ); and 3) divisive
normalization can be realized by some biological mechanism. In this section, we ﬁrst describe a
radial basis function network implementing importance sampling, then discuss the feasibility of
three assumptions mentioned above. The model is then extended to networks of spiking neurons.

3.1 Radial basis function (RBF) networks

Radial basis function (RBF) networks are a multi-layer neural network architecture in which the
hidden units are parameterized by locations in a latent space x∗
i . On presentation of a stimulus x,

2

Figure 1: Importance sampler realized by radial basis function network. For details see Section 3.1.

these hidden units are activated according to a function that depends only on the distance ||x − x∗
i ||,
e.g., exp(−|x − x∗
i |2/2σ2 ), similar to the tuning curve of a neuron. RBF networks are popular
because they have a simple structure with a clear interpretation and are easy to train. Using RBF
networks to model the brain is not a new idea – similar models have been proposed for pattern
recognition [10] and as psychological accounts of human category learning [11].
Implementing importance sampling with RBF networks is straightforward. A RBF neuron is re-
cruited for a stimulus value x∗
i drawn from the prior (Fig. 1). The neuron’s synapses are organized
so that its tuning curve is proportional to p(x|x∗
i ). For a Gaussian likelihood, the peak ﬁring rate
i and diminishes as ||x − x∗
i || increases. The ith RBF
would be reached at preferred stimulus x = x∗
neuron makes a synaptic connection to output neuron j with strength fj (x∗
i ), where fj is a function
of interest. The output units also receive input from an inhibitory neuron that sums over all RBF
neurons’ activities. Such an RBF network produces output exactly in the form of Eq. 3, with the
activation of the output units corresponding to E [fj (x∗ )|x].
Training RBF networks is practical for neural implementation. Unlike the multi-layer perceptron
that usually requires global training of the weights, RBF networks are typically trained in two stages.
First, the radial basis functions are determined using unsupervised learning, and then, weights to the
outputs are learned using supervised methods. The ﬁrst stage is even easier in our formulation,
because RBF neurons simply represent samples from the prior, independent of the second stage
later in development. Moreover, the performance of RBF networks is relatively insensitive to the
precise form of the radial basis functions [12], providing some robustness to differences between the
Bayesian likelihood p(x|x∗
i ) and the activation function in the network. RBF networks also produce
sparse coding, because localized radial basis likelihood functions mean only a few units will be
signiﬁcantly activated for a given input x.

3.2 Tuning curves, priors and divisive normalization

We now examine the neural correlates of the three components in RBF model. First, responses
of cortical neurons to stimuli are often characterized by receptive ﬁelds and tuning curves, where
receptive ﬁelds specify the domain within a stimulus feature space that modify neuron’s response
and tuning curves detail how neuron’s responses change with different feature values. A typical
tuning curve (like orientation tuning in V1 simple cells) has a bell-shape that peaks at the neuron’s
preferred stimulus parameter and diminishes as parameter diverges. These neurons are effectively
measure the likelihood p(x|x∗
i ), where x∗
i is the preferred stimulus.
Second, importance sampling requires neurons with preferred stimuli x∗
i to appear with frequency
proportional to the prior distribution p(x∗ ). This can be realized if the number of neurons represent-
ing x∗ is roughly proportional to p(x∗ ). While systematic study of distribution of neurons over their
preferred stimuli is technically challenging, there are cases where this assumption seems to hold.
For example, research on the ”oblique effect” supports the idea that the distribution of orientation
tuning curves in V1 is proportional to the prior. Electrophysiology [13], optical imaging [14] and

3

SXp(Sx|xi*)p(Sx|xn*)p(Sx|x1*)∑∑∑E[f1(x)|Sx]≈f1(x1*)f2(x1*)f1(xi*)f1(xn*)f2(xi*)f2(xn*)lateralnormalization∑  f1(xi*)p(Sx|xi*)∑ ∑ p(Sx|xi*)∑  f2(xi*)p(Sx|xi*)∑ ∑  p(Sx|xi*)stimulusRBFneuronsoutputneuronsinhibitoryneuronxi* ~ p(x)E[f2(x)|)|Sx]≈]≈fMRI studies [15] have found that there are more V1 neurons tuned to cardinal orientations than
to oblique orientations. These ﬁndings are in agreement with the prior distribution of orientations
of lines in the visual environment. Other evidence comes from motor areas. Repetitive stimulation
of a ﬁnger expands its corresponding cortical representation in somatosensory area [16], suggesting
more neurons are recruited to represent this stimulus. Alternatively, recruiting neurons x∗
i according
to the prior distribution can be implemented by modulating feature detection neurons’ ﬁring rates.
This strategy also seems to be used by the brain: studies in parietal cortex [17] and superior col-
liculus [18] show that increased prior probability at a particular location results in stronger ﬁring for
neurons with receptive ﬁelds at that location.
Third, divisive normalization is a critical component in many neural models, notably in the study of
attention modulation [19, 20]. It has been suggested that biophysical mechanisms such as shunting
inhibition and synaptic depression might account for normalization and gain control [10, 21, 22].
Moreover, local interneurons [23] act as modulator for pooled inhibitory inputs and are good can-
didates for performing normalization. Our study makes no speciﬁc claims about the underlying
biophysical processes, but gains support from the literature suggesting that there are plausible neu-
ral mechanisms for performing divisive normalization.

3.3

Importance sampling by Poisson spiking neurons

Neurons communicate mostly by spikes rather than continuous membrane potential signals. Poisson
spiking neurons play an important role in other analyses of systems for representing probabilities [8].
To show this we need a property of Poisson distributions: if yi ∼ Poisson(λi ) and Y = (cid:80)
Poisson spiking neurons can also be used to perform importance sampling if we have an ensemble
then Y ∼ Poisson((cid:80)
i λi ) and (y1 , y2 , . . . , ym |Y = n) ∼ Multinomial(n, λi / (cid:80)
of neurons with ﬁring rates λi proportional to p(x|x∗
i ), with the values of x∗
i drawn from the prior.
implies that E (yi/Y |Y = n) = λi / (cid:80)
i yi ,
i λi ). This further
the number of spikes produced by the corresponding neurons yields (cid:80)
i )ri / (cid:80)
i λi . Assume a neuron tuned to stimulus x∗
i emits spikes
ri ∼ Poisson(c · p(x|x∗
i )), where c is any positive constant. An average of a function f (x∗
i ) using
i f (x∗
i ri , whose
(cid:34)(cid:88)
(cid:35)
(cid:34)
(cid:35)
(cid:80)
= (cid:88)
= (cid:88)
expectation is
ri(cid:80)
ri(cid:80)
cλi(cid:80)
(cid:80)
i )p(x|x∗
i f (x∗
i )
f (x∗
f (x∗
f (x∗
i )
i )E
i )
=
i p(x|x∗
E
i )
j cλj
j rj
j rj
pectation. The variance of this estimator decreases as population activity n = (cid:80)
i
i
i
which is thus an unbiased estimator of the importance sampling approximation to the posterior ex-
i ri increases
because var[ri /n] ∼ 1/n. Thus, Poisson spiking neurons, if plugged into an RBF network, can per-
form importance sampling and give similar results to “neurons” with analog output, as we conﬁrm
later in the paper through simulations.

(4)

4 Hierarchical Bayesian inference and multi-layer importance sampling

Inference tasks solved by the brain often involve more than one random variable, with complex
dependency structures between those variables. For example, visual information process in pri-
mates involves dozens of subcortical areas that interconnect in a hierarchical structure containing
two major pathways [5]. Hierarchical Bayesian inference has been proposed as a solution to this
problem, with particle ﬁltering and belief propagation as possible algorithms implemented by the
brain [6]. However, few studies have proposed neural models that are capable of performing hier-
archical Bayesian inference (although see [24]). We show how a multi-layer neural network can
perform such computations using importance samplers (Fig. 1) as building blocks.

4.1 Generative models and Hierarchical Bayesian inference

Generative models describe the causal process by which data are generated, assigning a probability
distribution to each step in that process. To understand brain function, it is often helpful to identify
the generative model that determines how stimuli to the brain Sx are generated. The brain then has
to reverse the generative model to recover the latent variables expressed in the data (see Fig. 2). The
direction of inference is thus the opposite of the direction in which the data are generated.

4

Figure 2: A hierarchical Bayesian model. The generative model speciﬁes how each variable is
generated (in circles), while inference reverses this process (in boxes). Sx is the stimulus presented
to the nervous system, while X , Y , and Z are latent variables at increasing levels of abstraction.
E [f (z )|Sx ] = (cid:82) f (z )p(z |Sx ) dz . After repeatedly using the importance sampling trick (see Eq. 5),
In the case of a hierarchical Bayesian model, as shown in Fig. 2, the quantity of interest is the
posterior expectation of some function f (z ) of a high-level latent variable Z given stimulus Sx ,
this hierarchical Bayesian inference problem can decomposed into three importance samplers with
values x∗
i ,y∗
j and z ∗
k drawn from the prior.

(5)

This result relies on recursively applying importance sampling to the integral, with each recursion
resulting in an approximation to the posterior distribution of another random variable. This recursive
importance sampling scheme can be used in a variety of graphical models. For example, tracking a
stimulus over time is a natural extension where an additional observation is added at each level of
the generative model. We evaluate this scheme in several generative models in Section 5.

4.2 Neural implementation of the multi-layer importance sampler

The decomposition of hierarchical inference into recursive importance sampling (Eq. 5) gives rise
to a multi-layer neural network implementation (see Fig. 3a). The input layer X is similar to that in
Fig. 1, composed of feature detection neurons with output proportional to the likelihood p(Sx |x∗
i ).
Their output, after presynaptic normalization, is fed into a layer corresponding to the Y variables,
(cid:80)
i |y∗
p(x∗
j ) . The response of neuron y∗
j )
with synaptic weights
j , summing over synaptic inputs, ap-
i |y∗
j p(x∗
k |Sx ), and the activities of these neurons
j |Sx ). Similarly, the response of z ∗
k ≈ p(z ∗
proximates p(y∗
are pooled to compute E [f (z )|Sx ]. Note that, at each level, x∗
i ,y∗
j and z ∗
k are sampled from prior
distributions. Posterior expectations involving any random variable can be computed because the
neuron activities at each level approximate the posterior density. A single pool of neurons can also
feed activation to multiple higher levels. Using the visual system as an example (Fig. 3b), such
a multi-layer importance sampling scheme could be used to account for hierarchical inference in
divergent pathways by projecting a set of V2 cells to both MT and V4 areas with corresponding
synaptic weights.

5

ZYXSxgenerative   modelZYXSxinference  processp(yj|zk)p(xi|yj)p(Sx|xi)pp(zk|y|yj)p(yj|x|xi)p(xi|S|Sx)E[f(z)|S  ]x =f(z)p(z|y)[p(y|x)p(x|Sx)dx]dydz≈f(z)p(z|y)ip(y|x*i)p(Sx|x*i)ip(Sx|x*i)dy dz=f(z)ip(z|y)p(y|x*i)dyp(Sx|x*i)ip(Sx|x*i)dz≈f(z)ijp(z|y*j)p(x*i|y*j)jp(x*i|y*j)p(Sx|x*i)ip(Sx|x*i)dz=j[f(z)p(z|y*j)dz]ip(x*i|y*j)jp(x*i|y*j)p(Sx|x*i)ip(Sx|x*i)≈jkf(z*k)p(y*j|z*k)kp(y*j|z*k)ip(x*i|y*j)jp(x*i|y*j)p(Sx|x*i)ip(Sx|x*i)=kf(z*k)jp(y*j|z*k)kp(y*j|z*k)ip(x*i|y*j)jp(x*i|y*j)p(Sx|x*i)ip(Sx|x*i)importancesamplingimportancesamplingimportancesampling zk                    yj               xix*i~ p(x)y*j~ p(y)z*k~ p(z)Figure 3: a) Multi-layer importance sampler for hierarchical Bayesian inference. b) Possible imple-
mentation in dorsal-ventral visual inference pathways, with multiple higher levels receiving input
from one lower level. Note that the arrow directions in the ﬁgure are direction of inference, which
is opposite to that of its generative model.

5 Simulations

In this section we examine how well the mechanisms introduced in the previous sections account
for human behavioral data for two perceptual phenomena: cue combination and the oblique effect.

5.1 Haptic-visual cue combination

When sensory cues come from multiple modalities, the nervous system is able to combine those cues
optimally in the way dictated by Bayesian statistics [2]. Fig. 4a shows the setup of an experiment
where a subject measures the height of a bar through haptic and visual inputs. The object’s visual
input is manipulated so that the visual cues can be inconsistent with haptic cues and visual noise
can be adjusted to different levels, i.e. visual cue follows xV ∼ N (SV , σ2
V ) and haptic cue follows
xH ∼ N (SH , σ2
H ), where SV , SH , σ2
V are controlled parameters. The upper panel of Fig. 4d shows
the percentage of trials that participants report the comparison stimulus (consistent visual/haptic cues
from 45-65mm) is larger than the standard stimulus (inconsistent visual/haptic cues, SV = 60mm
and SH = 50mm). With the increase of visual noise, haptic input accounts for larger weights in
decision making and the percentage curve is shifted towards SH , consistent with Bayesian statistics.
Several studies have suggested that this form of cue combination could be implemented by popula-
tion coding [2, 8]. In particular, [8] made an interesting observation that, for Poisson-like spiking
neurons, summing ﬁring activities of two populations is the optimal strategy. This model is under
the Bayesian decoding framework and requires construction of the network so that these two pop-
ulations of neurons have exactly the same number of neurons and precise one-to-one connection
between two populations, with the connected pair of neurons having exactly the same tuning curves.
We present an alternative solution based on importance sampling that encodes the probability distri-
bution by a population of neurons directly.
The importance sampling solution approximates the posterior expectation of the bar’s height x∗
C
given SV and SH . Sensory inputs are channeled in through xV and xH (Fig.4b). Because sensory
input varies in a small range (45-65mm in [2]), we assume priors p(xC ), p(xV ) and p(xH ) are
uniform. It is straightforward to approximate posterior p(xV |SV ) using importance sampling:
(cid:80)
≈ rV(cid:80)
V )|SV ] ≈ p(SV |x∗
V )
V |SV ) = E [1(xV = x∗
p(xV = x∗
i p(SV |x∗
V ,i )
i rV ,i
where rV ,i ∼ Poisson[c · p(SV |x∗
V ,i )] is the number of spikes emitted by neuron x∗
V ,i . A similar strat-
egy applies to p(xH |SH ). The posterior p(xC |SV , SH ), however, is not trivial since multiplication

V ,i ∼ p(xV )
x∗

(6)

6

x2*∑lateralnormalizationGRBF neuronsxi*~p(x)∑∑∑xn*y1*=∑i∑∑x1*yj*=∑iym*=∑ixi*z1*=∑jzk*=∑jzN*=∑j∑yj*~p(y)zk*~p(z)synaptic weight:activity of yj:activity of xi:p(Sx|x*i)ip(Sx|x*i)ip(x*i|y*j)jp(x*i|y*j)p(Sx|x*i)ip(Sx|x*i)activity of zk:jp(y*j|z*k)kp(y*j|z*k)ip(x*i|y*j)jp(x*i|y*j)p(Sx|x*i)ip(Sx|x*i)synaptic weight:pp(y*j|z*k)kp(y*j|z*k)p(x*i|y*j)jp(x*i|y*j)∑f( Z1*)f( Zk*)f( ZN*)(a)(b)V1MTV4V2E[f(z)|Sx]synaptic weight:p(V*1,i|V*2,j)jsynaptic weight:p(x*i|y*j)jp(x*i|y*j)p(V*1,i|V*2,j)p(V*2,j|V*4,k)jp(V*2,j|V*4,k)p(V*2,j|MT*  m)(V*2,j|MT*  m)p)‘Where’ pathway‘What’ pathwayFigure 4: (a) Experimental setup [2]. (b) Generative model. SV and SH are the sensory stimuli,
XV and XH the values along the visual and haptic dimensions, and XC the combined estimate of
H,j }. The
object height. (c) Illustration of importance sampling using two sensory arrays {x∗
V ,i}, {x∗
transparent ellipses indicate the tuning curves of high level neurons centered on values x∗
C,k over
xV and xH . The big ellipse represents the manipulated input with inconsistent sensory input and
different variance structure. Bars at the center of opaque ellipses indicate the relative ﬁring rates of
C,k |SV , SH ). (d) Human data and simulation results.
xC neurons, proportional to p(x∗
(cid:90)
of spike trains is needed.
(cid:90)
C |SV , SH ) =
C )p(xC |xV , xH )p(xV |SV )p(xH |SH ) dxV dxH
1(xC = x∗
p(xC = x∗
≈ (cid:88)
(cid:88)
C )p(xC |xV , xH ) rV ,i(cid:80)
rH,j(cid:80)
1(xC = x∗
j rH,j
i rV ,i
j
i
Fortunately, the experiment gives an important constraint, namely subjects were not aware of the
manipulation of visual input. Thus, the values x∗
C,k employed in the computation are sampled from
normal perceptual conditions, namely consistent visual and haptic inputs (xV = xH ) and normal
variance structure (transparent ellipses in Fig.4c, on the diagonal). Therefore, the random variables
{xV , xH } effectively become one variable xV ,H and values of x∗
V ,H,i are composed of samples
C )rV ,i + (cid:80)
(cid:80)
drawn from xV and xH independently. Applying importance sampling,
(cid:80)
i rV ,i + (cid:80)
H,j |x∗
V ,i |x∗
j p(x∗
i p(x∗
C )rH,j
C |SV , SH ) ≈
C |SV , SH ] ≈ (cid:88)
(cid:88)
p(xC = x∗
j rH,j
x∗
E [x∗
rC,k
C,k rC,k /
k
k
where rC,k ∼ Poisson(c · p(x∗
C,k ∼ p(xC ). Compared with Eq. 6, inputs x∗
C,k |SV , SH )) and x∗
V ,i
and x∗
H,j are treaded as from one population in Eq 8. rV ,i and rH,j are weighted differently only
because of different observation noise. Eq. 9 is applicable for manipulated sensory input (in Fig. 4c,
the ellipse off the diagonal). The simulation results (for an average of 500 trials) are shown in the
lower panel of Fig.4d, compared with human data in the upper panel. There are two parameters,
noise levels σV and σH , are optimized to ﬁt within-modality discrimination data (see [2] Fig. 3a).
{x∗
V ,i},{x∗
H,j } and {x∗
C,k } consist of 20 independently drawn examples each, and the total ﬁring rate
of each set of neurons is limited to 30. The simulations produce a close match to human behavior.

(9)

(7)

(8)

5.2 The oblique effect

The oblique effect describes the phenomenon that people show greater sensitivity to bars with hor-
izontal or vertical (0o /90o ) orientations than “oblique” orientations. Fig. 5a shows an experimental
setup where subjects exhibited higher sensitivity in detecting the direction of rotation of a bar when
the reference bar to which it was compared was in one of these cardinal orientations. Fig. 5b shows
the generative model for this detection problem. The top-level binary variable D randomly chooses a
direction of rotation. Conditioning on D , the amplitude of rotation ∆θ is generated from a truncated

7

CRTStereoglassesOpaquemirrorForce-feedbackdevicesVisual and hapticsceneNoise:3 cm equals 100%Visual heightHaptic heightWidth3-cm depth stepM.O. Ernst and M.S. Banks Nature (2002)(a) Experiment setting(d) Visual–haptic discriminationSVSHNormalized comparison height (mm)00.250.500.751.000%67%133%200%545556Noise levelVisual–hapticProportion of trials perceived as 'taller'human behavior (Ernst et. al. 2002)00.250.500.751.00SVSH545556simulation(b) Generative model of      cue combinationxCxVxHSVSH(c) Importance sampling from       visual−haptic examples505560Visual input (mm)505560Haptic input (mm)p(xV,xH|xC,k*){xC,k*}p(xxV,xH){xV,i*}{xH, j*}Figure 5: (a) Orientation detection experiment. The oblique effect is shown in lower panel, being
greater sensitivity to orientation near the cardinal directions. (b) Generative model. (c) The oblique
effect emerges from our model, but depends on having the correct prior p(θ).

normal distribution (NT (D) , being restricted to ∆θ > 0 if D = 1 and ∆θ < 0 otherwise). When
combined with the angle of the reference bar r (shaded in the graphical model, since it is known),
∆θ generates the orientation of a test bar θ , and θ further generates the observation Sθ , both with
normal distributions with variance σθ and σSθ respectively.
The oblique effect has been shown to be closely related to the number of V1 neurons that tuned to
different orientations [25]. Many studies have found more V1 neurons tuned to cardinal orientations
than other orientations [13, 14, 15]. Moreover, the uneven distribution of feature detection neurons
is consistent with the idea that these neurons might be sampled proportional to the prior: more
horizontal and vertical segments exist in the natural visual environment of humans.
Importance sampling provides a direct test of the hypothesis that preferential distribution of V1
neurons around 0o /90o can cause the oblique effect, which becomes a question of whether the
p(D = 1|Sθ , r) ≈ (cid:88)
(cid:88)
oblique effect depends on the use of a prior p(θ) with this distribution. The quantity of interest is:
(cid:80)
(cid:80)
i |∆θ∗
p(θ∗
p(Sθ |θ∗
j (cid:48) , r)
i )
(10)
i p(Sθ |θ∗
i |∆θ∗
j p(θ∗
j , r)
i )
j (cid:48)
i
where j (cid:48) indexes all ∆θ∗ > 0. If p(D = 1|Sθ , r) > 0.5, then we should assign D = 1. Fig. 5c
shows that detection sensitivity is uncorrelated with orientations if we take a uniform prior p(θ), but
exhibits the oblique effect under a prior that prefers cardinal directions. In both cases, 40 neurons
are used to represent each of ∆θ∗
i and θ∗
i , and results are averaged over 100 trials. Sensitivity is
measured by percentage correct in inference. Due to the qualitative nature of this simulation, model
parameters are not tuned to ﬁt experiment data.

6 Conclusion

Understanding how the brain solves the problem of Bayesian inference is a signiﬁcant challenge for
computational neuroscience. In this paper, we have explored the potential of a class of solutions
that draw on ideas from computer science, statistics, and psychology. We have shown that a small
number of feature detection neurons whose tuning curves represent a small set of typical examples
from sensory experience is sufﬁcient to perform some basic forms of Bayesian inference. Moreover,
our theoretical analysis shows that this mechanism corresponds to a Monte Carlo sampling method,
i.e. importance sampling. The basic idea behind this approach – storing examples and activating
them based on similarity – is at the heart of a variety of psychological models, and straightforward
to implement either in traditional neural network architectures like radial basis function networks,
circuits of Poisson spiking neurons, or associative memory models. The nervous system is con-
stantly reorganizing to capture the ever-changing structure of our environment. Components of the
importance sampler, such as the tuning curves and their synaptic strengths, need to be updated to
match the distributions in the environment. Understanding how the brain might solve this daunting
problem is a key question for future research.
Acknowledgments. Supported by the Air Force Ofﬁce of Scientiﬁc Research (grant FA9550-07-1-0351).

8

45901351800124590135180012(b) Generative model0o90o180op(clockwise)?reference bartest bar(a) Oblique effectRelative detection sensitivityadopted from Furmanski & Engel (2000)D∆θθrSθp(D=1) = p(D=-1) = 0.5Clockwise or counterclockwise?∆θ | D ~ NT(D) (0,σ∆θ)2∆θ ~ N (0,σ∆θ)2θ | ∆θ, r ~ N (∆θ+r ,σθ )2θ ~ {Sθ | θ ~ N (θ ,σS )2∆θUni([0, pi]) or(1-k)/2[N(0, σθ )+N(pi/2, σθ )]+k Uni([0, pi])(c) Oblique effect and prior090180prior090180priorOrientationRelative detection sensitivityIn

J.Opt.Soc.Am.A

References
[1] K. K ¨ording and D. M. Wolpert. Bayesian integration in sensorimotor learning. Nature, 427:244–247,
2004.
[2] M. O. Ernst and M. S. Banks. Humans integrate visual and haptic information in a statistically optimal
fashion. Nature, 415(6870):429–433, 2002.
[3] A. Stocker and E. Simoncelli. A bayesian model of conditioned perception.
In J.C. Platt, D. Koller,
Y. Singer, and S. Roweis, editors, Advances in Neural Information Processing Systems 20, pages 1409–
1416. MIT Press, Cambridge, MA, 2008.
[4] A. P. Blaisdell, K. Sawa, K. J. Leising, and M. R. Waldmann. Causal reasoning in rats. Science,
311(5763):1020–1022, 2006.
[5] D. C. Van Essen, C. H. Anderson, and D. J. Felleman.
Information processing in the primate visual
system: an integrated systems perspective. Science, 255(5043):419–423, 1992 Jan 24.
[6] T. S. Lee and D. Mumford. Hierarchical bayesian inference in the visual cortex.
Opt.Image Sci.Vis., 20(7):1434–1448, 2003.
[7] R. S. Zemel, P. Dayan, and A. Pouget. Probabilistic interpretation of population codes. Neural Comput,
10(2):403–430, 1998.
[8] W. J. Ma, J. M. Beck, P. E. Latham, and A. Pouget. Bayesian inference with probabilistic population
codes. Nat.Neurosci., 9(11):1432–1438, 2006.
[9] L. Shi, N. H. Feldman, and T. L. Grifﬁths. Performing bayesian inference with exemplar models.
Proceedings of the 30th Annual Conference of the Cognitive Science Society, 2008.
[10] M. Kouh and T. Poggio. A canonical neural circuit for cortical nonlinear operations. Neural Comput,
20(6):1427–1451, 2008.
[11] J. K. Kruschke. Alcove: An exemplar-based connectionist model of category learning. Psychological
Review, 99:22–44, 1992.
[12] M. J. D. Powell. Radial basis functions for multivariable interpolation: a review. Clarendon Press, New
York, NY, USA, 1987.
[13] R. L. De Valois, E. W. Yund, and N. Hepler. The orientation and direction selectivity of cells in macaque
visual cortex. Vision Res, 22(5):531–544, 1982.
[14] D. M. Coppola, L. E. White, D. Fitzpatrick, and D. Purves. Unequal representation of cardinal and oblique
contours in ferret visual cortex. Proc Natl Acad Sci U S A, 95(5):2621–2623, 1998 Mar 3.
[15] C. S. Furmanski and S. A. Engel. An oblique effect in human primary visual cortex. Nat Neurosci,
3(6):535–536, 2000.
[16] A. Hodzic, R. Veit, A. A. Karim, M. Erb, and B. Godde. Improvement and decline in tactile discrimination
behavior after cortical plasticity induced by passive tactile coactivation. J Neurosci, 24(2):442–446, 2004.
[17] M. L. Platt and P. W. Glimcher. Neural correlates of decision variables in parietal cortex. Nature, 400:233–
238, 1999.
[18] M. A. Basso and R. H. Wurtz. Modulation of neuronal activity by target uncertainty. Nature,
389(6646):66–69, 1997.
[19] J. H. Reynolds and D. J. Heeger. The normalization model of attention. Neuron, 61(2):168–185, 2009
Jan 29.
[20] J. Lee and J. H. R. Maunsell. A normalization model of attentional modulation of single unit responses.
PLoS ONE, 4(2):e4651, 2009.
[21] S. J. Mitchell and R. A. Silver. Shunting inhibition modulates neuronal gain during synaptic excitation.
Neuron, 38(3):433–445, 2003.
[22] J. S. Rothman, L. Cathala, V. Steuber, and R A. Silver. Synaptic depression enables neuronal gain control.
Nature, 457(7232):1015–1018, 2009 Feb 19.
[23] H. Markram, M. Toledo-Rodriguez, Y. Wang, A. Gupta, G. Silberberg, and C. Wu. Interneurons of the
neocortical inhibitory system. Nat Rev Neurosci, 5(10):793–807, 2004 Oct.
[24] K. Friston. Hierarchical models in the brain. PLoS Comput Biol, 4(11):e1000211, 2008 Nov.
[25] G. A. Orban, E. Vandenbussche, and R. Vogels. Human orientation discrimination tested with long stim-
uli. Vision Res, 24(2):121–128, 1984.

9

