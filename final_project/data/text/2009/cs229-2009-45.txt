Feature selection methods for SVM classiﬁcation of microarray data

Mike Love

December 11, 2009

SVMs for microarray classiﬁcation tasks

Linear support vector machines have been used in microarray experiments to predict a certain class
of a sample tissue (e.g. healthy or tumor) using the mRNA expression of diﬀerent genes. In mea-
suring tens of thousands of genes, a microarray dataset includes many genes that are uninformative
with respect to the classes. Finding subsets of genes for the SVM to train on could help improve
the generalization of the algorithm and reveal a small set of relevant genes that could be used to
build a cheaper diagnostic test.

Feature selection algorithms

I compare three methods of feature selection against running a linear SVM on the full dataset, on
simulated data and an open microarray dataset.
Golub (1999) describes a weighted voting method with ﬁlter feature selection. The algorithm takes
a certain number of genes that show the most extreme measure of a weight representing correlation
between genes and the class labels. The measure of weight for gene i is:

i − µ−
ci = µ+
i
i + σ−
σ+
i
where µ+
is the standard
is the mean of gene i for the positive class in the training data and σ+
i
i
deviation of gene i for the negative class in the training data. A certain number of genes with the
highest |ci | then contribute a vote to the total:

i + µ−
(µ+
i ))

vi = ci (xi − 1
2
Here vi is the vote from gene i and xi is the value of gene i for a test case. The votes are then
summed and if the total is positive then a positive class label is predicted. This method is similar
to but not the same as a SVM algorithm.
Guyon (2002) and Zhang (2006) describe methods of backward search feature selection. Both
methods involve starting with the full set of genes, picking a set of decreasing feature subset sizes,
and eliminating batches of genes at each iteration by ranking their contribution. The measure of
contribution in Guyon is w2
i , the squared value of the weight vector for gene i from running SVM.

1

i − µ−
The measure in Zhang is wi (µ+
i ). The ﬁnal subset size is chosen by k-fold cross-validation,
which includes the feature selection steps as well as training the SVM. If multiple sizes tied for
minimum CV error, I choose the one with more features, as choosing too few features can increase
the error much more steeply than choosing too many. The ﬁnal set of genes is chosen by the most
frequently used genes at the step with the smallest CV error.

Simulated microarray data

I construct various sets of simulated data, using methods described in Zhang (2006). A set of infor-
mative genes are sampled from N (±0.25, 1) with the sign depending on which class the observation
is from. A set of uninformative genes are sampled from N (0, 1). To simulate outliers, some percent
of the expression values for each sample are drawn from a Gaussian with the appropriate mean
and 10 times the standard deviation. A training set with 100 observations and a test set with 1000
observations were created using this same procedure. 20 simulations were run for each setting of
the parameters to assess variance. I varied the ratio of informative to uninformative genes, and the
ratio of positive to negative classes in the training data.

Simulation results

I use the SMO algorithm presented in class with C=1, tolerance = 0.001 and max passes = 10. For
the method presented in Golub, I set the number of features to ﬁlter to 500. For the two backward
search methods, I stepped through the subset sizes: [2000, 1500, 1000, 750, 500, 400, 300, 200, 100].
Here are results for diﬀerent parameter settings. The ﬁnal column indicates if the feature selection
methods had test error with mean signiﬁcantly diﬀerent than the mean test error of the full SVM
(two-tailed t-test at level α = .05).

100 informative genes, 1900 uninformative genes, 1% outliers, balanced classes:
method CV error (%)
features kept number of SV signiﬁcant
test error (%)
22.9 ± 5.2
23.8 ± 1.9
80
2000
full SVM
NA
20.4 ± 5.8
23.1 ± 1.9
Golub
500
NA
20.5 ± 2.9
18.0 ± 4.8
44
100
Guyon
18.2 ± 5.1
20.8 ± 2.8
Zhang
200
63

*
*

200 informative genes, 1800 uninformative genes, 1% outliers, balanced classes:
features kept number of SV signiﬁcant
test error (%)
method CV error (%)
7.1 ± 2.9
9.6 ± 0.7
full SVM
2000
80
NA
9.7 ± 1.4
5.5 ± 2.6
NA
500
Golub
8.7 ± 1.2
5.4 ± 2.7
78
500
Guyon
5.2 ± 2.4
8.8 ± 1.0
Zhang
400
78

*
*

2

300 informative genes, 1700 uninformative genes, 1% outliers, balanced classes:
method CV error (%)
test error (%)
features kept number of SV signiﬁcant
2.1 ± 1.2
3.4 ± 0.7
80
2000
full SVM
NA
2.3 ± 1.5
3.3 ± 0.6
Golub
500
NA
3.3 ± 0.6
1.5 ± 1.5
77
500
Guyon
1.7 ± 1.4
3.5 ± 1.1
Zhang
500
77

200 informative genes, 1800 uninformative genes, 1% outliers, unbalanced classes (25% positive,
75% negative):
method CV error (%)
22.9 ± 1.5
full SVM
18.5 ± 3.1
Golub
16.7 ± 3.1
Guyon
16.8 ± 3.1
Zhang

features kept number of SV signiﬁcant
NA
80
2000
*
NA
500
*
37
100
100
36
*

test error (%)
21.0 ± 1.0
19.5 ± 2.2
14.9 ± 2.3
14.9 ± 2.7

Microarray data

To test the methods on real microarray data, I used an openly available dataset published by Alon
(1999). The data include 2000 of the genes with the largest minimal intensity across 40 tumor
and 22 normal colon samples. The number of samples is not large enough to have a training set
and a separate test set, so instead I compared the methods using out-of-bootstrap error. For each
method, I trained the SVM on a bootstrap sample from the 62 observations, and tested on the
observations that did not appear in the bootstrap sample. This was repeated for 20 bootstrap
samples. As with cross-validation in the simulations, the feature selection loops were embedded
within the bootstrapping loop.

method
full SVM
Golub
Golub
Guyon
Zhang

out-of-boot error (%)
19.5 ± 5.8
33.8 ± 14.7
21.1 ± 11.1
18.3 ± 6.7
18.3 ± 7.9

features kept number of SV signiﬁcant
NA
39
2000
NA
500
* (worse)
NA
20
1500
41
33
400

Conclusions

For the simulation data, the backwards search feature selection methods have statistically signiﬁcant
reduction in cross-validation and test error when there are few informative genes, although the
diﬀerences are not large for the balanced class data. This agrees with the conclusion from Nilsson
(2006) that the SVM performs well even with many uninformative features, making large decreases
in predictive error through feature selection hard to achieve. All three feature selection algorithms
gave signiﬁcant improvements with the unbalanced simulated data, and the reduction in error was
large for backwards search methods (29% decrease in test error).
The two backwards search methods performed very similarly (both better than the method from

3

Golub) on the simulated datasets. The number of support vectors always decreased as the number
of features was reduced in the backwards search methods, which might imply better generalization
results.
For the actual microarray data, the two backwards search methods had similar error to the full
SVM, but in this case the Golub method performed worse. I set the Golub method to pick only 20
genes after trying on 500 genes and having high prediction error. The minimum number selected
for the Guyon and Zhang methods can be arbitrary in cases like this when the error curve is fairly
ﬂat over the various subset sizes.
The plots of cross-validation error indicate that the predictive errors often increase more steeply
with the loss of any informative features than they do with the gain of uninformative features.
These plots might provide, for empirical data, a rough sense of the number of “relevant” genes for
a certain contrast of sample classes.

Figures

Plots of CV error from the simulated data are the averages over 20 simulations.

Plot of out-of-bootstrap error for the Alon (1999) data is the average over 20 bootstrap samples.

4

References

1. Alon, U., Barkai, N., Notterman, D.A., Gish, K., Ybarra, S., Mack, D., Levine, A.J.: Broad pat-
terns of gene expression revealed by clustering analysis of tumor and normal colon tissues probed by
oligonucleotide arrays. Procedings of the National Academy of Sciences 96 (1999) 6745-6750
2. Golub, T.R., Slonim, D.K., Tamayo, P., Huard, C., Gaasenbeek, M., Mesirov, J., Coller, H., Loh,
M., Downing, J., Caligiuri, M., Bloomﬁeld, C., Lander, E.S.: Molecular classiﬁation of cancer: class
discovery and class prediction by gene expression monitoring. Science 286 (1999) 531-537
3. Guyon, I., Weston, J., Barnhill, S., Vapnik, V.: Gene selection for cancer classiﬁcation using support
vector machines. Machine Learning 46 (2002) 389-422
4. Nilsson, R., Pena, J.M., Bjorkegren, J., Tegner, J.: Evaluating Feature Selection for SVMs in High
Dimensions. Springer Berlin / Heidelberg (2006)
5. Zhang, X., Lu, X., Shi, Q., Xu, X., Leung, H.E., Harris, L.N., Iglehart, J.D., Miron, A., Liu, J.S.,
Wong, W.H.: Recursive SVM feature selection and sample classiﬁcation for mass-spectrometry and
microarray data. BMC Bioinformatics 7 (2006)

5

