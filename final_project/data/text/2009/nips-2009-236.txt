Robust Principal Component Analysis: Exact Recovery of
Corrupted Low-Rank Matrices via Convex Optimization

Correction

John Wright

December 21, 2009

The supplementary material to the NIPS version of this paper [4] contains a critical error, which
was discovered several days before the conference. Unfortunately, it was too late to withdraw
the paper from the proceedings. Fortunately, since that time, a correct analysis of the proposed
convex programming relaxation has been developed by Emmanuel Candes of Stanford University.
That analysis is reported in a joint paper, Robust Principal Component Analysis? by Emmanuel
Candes, Xiaodong Li, Yi Ma and John Wright, http://arxiv.org/abs/0912.3599. That work not
only removes the error in our NIPS submission, but yields signiﬁcantly stronger results than those
claimed in the NIPS conference version. Below, we ﬁrst brieﬂy describe the error, and then describe
how this aﬀects the claims of the paper.

In Equation (63) of the supplementary material, we state a tail bound
Description of the error.
for a function of the “sign matrix” ˜U ˜V ∗ . This bound is obtained by introducing a random rotation
R ]. However, the tail bound for the quantity in (63) is not correct, since the expectation ER [·]
[ I
of this quantity with respect to the auxiliary rotation R is not necessarily zero. This error was
discovered by Emmanuel Candes.

Implication on the results. Theorem 2, regarding the completion of random matrices with
uniformly distributed singular vectors, depends strongly on the above incorrect argument, and hence
should be regarded as a conjecture.
Theorem 1, the main result of the paper, has been signiﬁcantly strengthened. The paper asserted
that the convex programming heuristic successfully recovers certain random matrices of rank r <
Cm/ log m from errors aﬀecting ρm2 of the m2 entries. New results in [1] remove the necessity to
assume any random model on the matrix to be recovered. All that needs to be assumed is that the
singular vectors are incoherent with the standard basis, in the sense of [2, 3]. The correct result
states that rank-r matrices with incoherence parameter µ can be recovered from ρm2 errors, as long
as r < Cm/µ log2 m.
[1] also generalizes the result to the non-
Please see [1] for more discussion of this result.
square case, and to matrix completion with corrupted entries, and further gives a faster-converging
algorithm than the proximal gradient approach discussed in the NIPS version.

1

References

[1] E. Candes, X. Li, Y. Ma, and J. Wright. Robust principal component analysis? http: // arxiv.
org/ abs/ 0912. 3599 , 2009.

[2] E. Candes and B. Recht. Exact matrix completion via convex optimzation. Foundatoins of
Computational Mathematics, 9:717–772, 2008.

[3] E. Candes and T. Tao. The power of convex relaxation: Near-optimal matrix completion. IEEE
Transactions on Information Theory, to appear, 2009.

[4] J. Wright, A. Ganesh, S. Rao, Y. Peng, and Y. Ma. Robust principal component analysis: Exact
recovery of corrupted low-rank matrices via convex optimization. In Y. Bengio, D. Schuurmans,
J. Laﬀerty, and C. Williams, editors, Advances in Neural Information Processing Systems 22,
2009.

2

