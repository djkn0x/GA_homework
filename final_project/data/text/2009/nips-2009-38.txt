Ranking Measures and Loss Functions
in Learning to Rank

Wei Chen∗
Chinese Academy of sciences
chenwei@amss.ac.cn

Tie-Yan Liu
Microsoft Research Asia
tyliu@micorsoft.com

Yanyan Lan
Chinese Academy of sciences
lanyanyan@amss.ac.cn

Zhiming Ma
Chinese Academy of sciences
mazm@amt.ac.cn

Hang Li
Microsoft Research Asia
hangli@micorsoft.com

Abstract

Learning to rank has become an important research topic in machine learning.
While most learning-to-rank methods learn the ranking functions by minimizing
loss functions, it is the ranking measures (such as NDCG and MAP) that are used
to evaluate the performance of the learned ranking functions. In this work, we
reveal the relationship between ranking measures and loss functions in learning-
to-rank methods, such as Ranking SVM, RankBoost, RankNet, and ListMLE. We
show that the loss functions of these methods are upper bounds of the measure-
based ranking errors. As a result, the minimization of these loss functions will lead
to the maximization of the ranking measures. The key to obtaining this result is to
model ranking as a sequence of classi ﬁcation tasks, and deﬁn
e a so-called essen-
tial loss for ranking as the weighted sum of the classi ﬁcation errors o f individual
tasks in the sequence. We have proved that the essential loss is both an upper
bound of the measure-based ranking errors, and a lower bound of the loss func-
tions in the aforementioned methods. Our proof technique also suggests a way to
modify existing loss functions to make them tighter bounds of the measure-based
ranking errors. Experimental results on benchmark datasets show that the modi ﬁ-
cations can lead to better ranking performances, demonstrating the correctness of
our theoretical analysis.

1

Introduction

Learning to rank has become an important research topic in many ﬁelds, such as machine learning
and information retrieval. The process of learning to rank is as follows. In training, a number of
sets are given, each set consisting of objects and labels representing their rankings (e.g., in terms of
multi-level ratings1 ). Then a ranking function is constructed by minimizing a certain loss function
on the training data. In testing, given a new set of objects, the ranking function is applied to produce
a ranked list of the objects.

Many learning-to-rank methods have been proposed in the literature, with different motivations and
formulations. In general, these methods can be divided into three categories [3]. The pointwise
approach, such as subset regression [5] and McRank [10], views each single object as the learn-
ing instance. The pairwise approach, such as Ranking SVM [7], RankBoost [6], and RankNet [2],
regards a pair of objects as the learning instance. The listwise approach, such as ListNet [3] and

∗The work was performed when the ﬁrst and the third authors were intern s at Microsoft Research Asia.
1 In information retrieval, such a label represents the relevance of a document to the given query.

1

ListMLE [16], takes the entire ranked list of objects as the learning instance. Almost all these
methods learn their ranking functions by minimizing certain loss functions, namely the pointwise,
pairwise, and listwise losses. On the other hand, however, it is the ranking measures that are used
to evaluate the performance of the learned ranking functions. Taking information retrieval as an ex-
ample, measures such as Normalized Discounted Cumulative Gain (NDCG) [8] and Mean Average
Precision (MAP) [1] are widely used, which obviously differ from the loss functions used in the
aforementioned methods. In such a situation, a natural question to ask is whether the minimization
of the loss functions can really lead to the optimization of the ranking measures.2
Actually people have tried to answer this question. It has been proved in [5] and [10] that the regres-
sion and classi ﬁcation based losses used in the pointwise ap proach are upper bounds of (1−NDCG).
However, for the pairwise and listwise approaches, which are regarded as the state-of-the-art of
learning to rank [3, 11], limited results have been obtained. The motivation of this work is to reveal
the relationship between ranking measures and the pairwise/listwise losses.

The problem is non-trivial to solve, however. Note that ranking measures like NDCG and MAP
are deﬁned with the labels of objects (i.e., in terms of multi -level ratings). Therefore it is relatively
easy to establish the connection between the pointwise losses and the ranking measures, since the
pointwise losses are also deﬁned with the labels of objects.
In contrast, the pairwise and listwise
losses are deﬁned with the partial or total order relations a mong objects, rather than their individual
labels. As a result, it is much more difﬁcult to bridge the gap between the pairwise/listwise losses
and the ranking measures.

To tackle the challenge, we propose making a transformation of the labels on objects to a permutation
set. All the permutations in the set are consistent with the labels, in the sense that an object with a
higher rating is ranked before another object with a lower rating in the permutation. We then deﬁne
an essential loss for ranking on the permutation set as follows. First, for each permutation, we
construct a sequence of classi ﬁcation tasks, with the goal o f each task being to distinguish an object
from the objects ranked below it in the permutation. Second, the weighted sum of the classi ﬁcation
errors of individual tasks in the sequence is computed. Third, the essential loss is deﬁned as the
minimum value of the weighted sum over all the permutations in the set.

Our study shows that the essential loss has several nice properties, which help us reveal the rela-
tionship between ranking measures and the pairwise/listwise losses. First, it can be proved that the
essential loss is an upper bound of measure-based ranking errors such as (1−NDCG) and (1−MAP).
Furthermore, the zero value of the essential loss is a sufﬁcient and necessary condition for the zero
values of (1−NDCG) and (1−MAP). Second, it can be proved that the pairwise losses in Ranking
SVM, RankBoost, and RankNet, and the listwise loss in ListMLE are all upper bounds of the essen-
tial loss. As a consequence, we come to the conclusion that the loss functions used in these methods
can bound (1−NDCG) and (1−MAP) from above. In other words, the minimization of these loss
functions can effectively maximize NDCG and MAP.

The proofs of the above results suggest a way to modify existing pairwise/listwise losses so as
to make them tighter bounds of (1−NDCG). We hypothesize that tighter bounds will lead to better
ranking performances; we tested this hypothesis using benchmark datasets. The experimental results
show that the methods minimizing the modi ﬁed losses can outp erform the original methods, as well
as many other baseline methods. This validates the correctness of our theoretical analysis.

2 Related work

In this section, we review the widely-used loss functions in learning to rank, ranking measures in
information retrieval, and previous work on the relationship between loss functions and ranking
measures.

2Note that recently people try to directly optimize ranking measures [17, 12, 14, 18]. The relationship
between ranking measures and the loss functions in such work is explicitly known. However, for other methods,
the relationship is unclear.

2

2.1 Loss functions in learning to rank

Let x = {x1 , · · · , xn } be the objects be to ranked.3 Suppose the labels of the objects are given
as multi-level ratings L = {l(1), ..., l(n)}, where l(i) ∈ {r1 , ..., rK } denotes the label of xi [11].
Without loss of generality, we assume l(i) ∈ {0, 1, ..., K − 1} and name the corresponding labels
as K -level ratings. If l(i) > l(j ), then xi should be ranked before xj . Let F be the function class
and f ∈ F be a ranking function. The optimal ranking function is learned from the training data
by minimizing a certain loss function deﬁned on the objects,
their labels, and the ranking function.
Several approaches have been proposed to learn the optimal ranking function.
In the pointwise approach, the loss function is deﬁned on the basis of single objects. F or example,
in subset regression [5], the loss function is as follows,
n
Xi=1 (cid:0)f (xi ) − l(i)(cid:1)2
Lr (f ; x, L) =
In the pairwise approach, the loss function is deﬁned on the basis of pairs of objects w hose labels
are different. For example, the loss functions of Ranking SVM [7], RankBoost [6], and RankNet [2]
all have the following form,

(1)

.

n−1
n
Xi=1,l(i)<l(s)
Xs=1
Lp (f ; x, L) =
φ(cid:0)f (xs ) − f (xi )(cid:1),
where the φ functions are hinge function (φ(z ) = (1 − z )+ ), exponential function (φ(z ) = e−z ),
and logistic function (φ(z ) = log(1 + e−z )) respectively, for the three algorithms.
In the listwise approach, the loss function is deﬁned on the basis of all the n objects. For example,
in ListMLE [16], the following loss function is used,
n−1
n
Xs=1 (cid:16) − f (xy(s) ) + ln (cid:0)
exp(f (xy(i) ))(cid:1)(cid:17),
Xi=s
where y is a randomly selected permutation (i.e., ranked list) that satis ﬁes the following condition:
for any two objects xi and xj , if l(i) > l(j ), then xi is ranked before xj in y . Notation y(i)
represents the index of the object ranked at the i-th position in y .

Ll (f ; x, y) =

(2)

(3)

2.2 Ranking measures

Several ranking measures have been proposed in the literature to evaluate the performance of a
ranking function. Here we introduce two of them, NDCG [8] and MAP[1], which are popularly
used in information retrieval.
NDCG is deﬁned with respect to K -level ratings L,
n
1
Xr=1
G(cid:0)l(πf (r))(cid:1)D(r),
N DCG(f ; x, L) =
Nn
where πf is the ranked list produced by ranking function f , G is an increasing function (named
the gain function), D is a decreasing function (named the position discount function), and Nn =
maxπ Pn
1
log2 (1+z) if
r=1 G(cid:0)l(π(r))(cid:1)D(r). In practice, one usually sets G(z ) = 2z − 1; D(z ) =
z ≤ C , and D(z ) = 0 if z > C (C is a ﬁxed integer).
MAP is deﬁned with respect to 2-level ratings as follows,
Pi≤s I{l(πf (i))=1}
1
n1 Xs:l(πf (s))=1
M AP (f ; x, L) =
s
where I{·} is the indicator function, and n1 is the number of objects with label 1. When the labels
are given in terms of K -level ratings (K > 2), a common practice of using MAP is to ﬁx a level
k∗ , and regard all the objects whose levels are lower than k∗ as having label 0, and regard the other
objects as having label 1 [11].
From the deﬁnitions of NDCG and MAP, we can see that their maxi mum values are both one.
Therefore, we can consider (1−NDCG) and (1−MAP) as ranking errors. For ease of reference, we
call them measure-based ranking errors.

(4)

.

3For example, for information retrieval, x represents the documents associated with a query.

3

2.3 Previous bounds

1 − N DCG(f ; x, L) ≤

For the pointwise approach, the following results have been obtained in [5] and [10].4
The regression based pointwise loss is an upper bound of (1−NDCG),
n
1
D(i)2(cid:17)1/2
Nn (cid:16)2
Xi=1
Lr (f ; x, L)1/2 .
The classi ﬁcation based pointwise loss is also an upper boun d of (1−NDCG),
15√2
n
n
n
D(i)2/n(cid:17)1/2(cid:16)
I{ˆl(i) 6=l(i)}(cid:17)1/2
Nn (cid:16)
Xi=1
Yi=1
Xi=1
D(i)2 − n
1 − N DCG(f ; x, L) ≤
where ˆl(i) is the label of object xi predicted by the classi ﬁer, in the setting of 5-level rating s.
For the pairwise approach, the following result has been obtained [9],
n1
1
Xi=1
n1+1 )−1 (
(Lp (f ; x, L) + C 2
1 − M AP (f ; x, L) ≤ 1 −
n1
According to the above results, minimizing the regression and classi ﬁcation based pointwise losses
will minimize (1−NDCG). Note that the zero values of these two losses are sufﬁc ient but not nec-
essary conditions for the zero value of (1−NDCG). That is, when (1−NDCG) is zero, the loss
functions may still be very large [10]. For the pairwise losses, the result is even weaker: their zero
values are even not sufﬁcient for the zero value of (1-MAP).

,

√i)2 .

To the best of our knowledge, there was no other theoretical result for the pairwise/listwise losses.
Given that the pairwise and listwise approaches are regarded as the state-of-the-art in learning to
rank [3, 11], it is very meaningful and important to perform more comprehensive analysis on these
two approaches.

3 Main results

In this section, we present our main results on the relationship between ranking measures and the
pairwise/listwise losses. The basic conclusion is that many pairwise and listwise losses are upper
bounds of a quantity which we call the essential loss, and the essential loss is an upper bound of
both (1−NDCG) and (1−MAP). Furthermore, the zero value of the essential loss is a sufﬁcient and
necessary condition for the zero values of (1−NDCG) and (1−MAP).

3.1 Essential loss: ranking as a sequence of classi ﬁcations

In this subsection, we describe the essential loss for ranking.

First, we propose an alternative representation of the labels of objects (i.e., multi-level ratings). The
basic idea is to construct a permutation set, with all the permutations in the set being consistent with
the labels. The deﬁnition that a permutation is consistent with multi-level ratings is given as below.
Deﬁnition 1. Given multi-level ratings L and permutation y , we say y is consistent with L, if
∀i, s ∈ {1, ..., n} satisfying i < s, we always have l(y(i)) ≥ l(y(s)), where y(i) represents the index
of the object that is ranked at the i-th position in y . We denote YL = {y |y is consistent with L}.

According to the deﬁnition, it is clear that the NDCG and MAP o f a ranking function equal one, if
and only if the ranked list (permutation) given by the ranking function is consistent with the labels.
Second, given each permutation y ∈ YL , we decompose the ranking of objects x into several se-
quential steps. For each step s, we distinguish xy(s) , the object ranked at the s-th position in y , from
all the other objects ranked below the s-th position in y , using ranking function f .5 Speci ﬁcally, we
denote x(s) = {xy(s) , · · · , xy(n) } and deﬁne a classi ﬁer based on
f , whose target output is y(s),
Tf (x(s) ) = arg
max
f (xj ).
j∈{y(s),··· ,y(n)}

(5)

4Note that the bounds given in the original papers of [5] and [10] are with respect to DCG. Here we give their
equivalent forms in terms of NDCG, and set P (·|xi , S ) = δl(i) (·) in the bound of [5], for ease of comparison.
5For simplicity and clarity, we assume f (xi ) 6= f (xj ) ∀i 6= j , such that the classiﬁer will have a unique
output. It can be proved (see [4]) that the main results in this paper still hold without this assumption.

4

It is clear that there are n − s possible outputs of this classi ﬁer, i.e., {y(s), · · · , y(n)}. The 0-1
loss for this classi ﬁcation task can be written as follows, w here the second equality is based on the
deﬁnition of Tf ,

n
Yi=s+1
ls (cid:0)f ; x(s) , y(s)(cid:1) = I{Tf (x(s) ) 6=y(s)} = 1 −
We give a simple example in Figure 1 to illustrate the aforementioned process of decomposition.

I{f (xy(s) )>f (xy(i) )} .

y
A
B
C










π
B
A
C

y
π
C (cid:19)
C (cid:19) (cid:18) B
(cid:18) B

incorrect
======⇒
remove A


(cid:0) C (cid:1)

Figure 1: Modeling ranking as a sequence of classi ﬁcations

correct
=======⇒
remove B

y

π

(cid:0) C (cid:1)

Suppose there are three objects, A, B , and C , and a permutation y = (A, B , C ). Suppose the output
of the ranking function for these objects is (2, 3, 1), and accordingly the predicted ranked list is
π = (B , A, C ). At step one of the decomposition, the ranking function predicts object B to be on
the top of the list. However, A should be on the top according to y . Therefore, a prediction error
occurs. For step two, we remove A from both y and π . Then the ranking function predicts object B
to be on the top of the remaining list. This is in accordance with y and there is no prediction error.
After that, we further remove object B , and it is easy to verify there is no prediction error in step
three either. Overall, the ranking function makes one error in this sequence of classi ﬁcation tasks.
Third, we assign a non-negative weight β (s)(s = 1, · · · , n − 1) to the classi ﬁcation task at the
s-th step, representing its importance to the entire sequence. We compute the weighted sum of the
classi ﬁcation errors of all individual tasks,

n−1
n
Yi=s+1
Xs=1
β (s)(cid:0)1 −
I{f (xy(s) )>f (xy(i) )} (cid:1),
and then deﬁne the minimum value of the weighted sum over all t he permutations in YL as the
essential loss for ranking.

Lβ (f ; x, y) ,

(6)

Lβ (f ; x, L) = min
y∈YL

Lβ (f ; x, y).

(7)

According to the above deﬁnition of the essential loss, we ca n obtain its following nice property.
Denote the ranked list produced by f as πf . Then it is easy to verify that,
Lβ (f ; x, L) = 0 ⇐⇒ ∃y ∈ YL satisfying Lβ (f ; x, y) = 0 ⇐⇒ πf = y ∈ YL .
In other words, the essential loss is zero if and only if the permutation given by the ranking function
is consistent with the labels. Further considering the discussions on the consistent permutation at
the begining of this subsection, we can come to the conclusion that the zero value of the essential
loss is a sufﬁcient and necessary condition for the zero valu es of (1-NDCG) and (1-MAP).

3.2 Essential loss: upper bound of measure-based ranking errors

In this subsection, we show that the essential loss is an upper bound of (1−NDCG) and (1−MAP),
when speci ﬁc weights β (s) are used.
Theorem 1. Given K -level rating data (x, L) with nk objects having label k and PK
i=k∗ ni > 0,
then ∀f , the following inequalities hold,
1
Lβ1 (f ; x, L), where β1 (s) = G(cid:0)l(y(s))(cid:1)D(s), ∀y ∈ YL ;
1 − N DCG(f ; x, L) ≤
(1)
Nn
1
Lβ2 (f ; x, L), where β2 (s) ≡ 1.
1 − M AP (f ; x, L) ≤
PK
i=k∗ ni
Proof. (1) We now prove the inequality for (1−NDCG). First, we reformulate NDCG using the
permutation set YL . This can be done by changing the index of the sum in NDCG from the rank

(2)

5

position r in πf to the rank position s in ∀y ∈ YL . Considering that s = y−1 (cid:0)πf (r)(cid:1) and r =
π−1
f (cid:0)y(s)(cid:1), it is easy to verify,
n
n
1
1
G(cid:16)l(cid:0)πf (π−1
f y(s))(cid:1)(cid:17)D(cid:0)π−1
Xs=1
Xs=1
f (y(s))(cid:1) =
N DCG(f ; x, L) =
Nn
Nn
Second, we consider the essential loss case by case. Note that

G(cid:0)l(y(s))(cid:1)D(cid:0)π−1
f (y(s))(cid:1).

n−1
n
Yi=s+1
Xs=1
G(cid:0)l(y(s))(cid:1)D(s)(cid:0)1 −
f (y(i))} (cid:1).
Lβ1 (f ; x, L) = min
I{π−1
f (y(s))<π−1
y∈YL
Then ∀y ∈ YL , if position s satis ﬁes Qn
f (y(i))} = 1 (i.e., ∀i > s, π−1
f (y(s)) <
i=s+1 I{π−1
f (y(s))<π−1
f (y(s)) ≤ s. As a consequence, D(s) Qn
f (y(i))), we have π−1
π−1
f (y(i))} =
i=s+1 I{π−1
f (y(s))<π−1
f (y(s))(cid:1). Otherwise, if Qn
D(s) ≤ D(cid:0)π−1
f (y(i))} = 0, it is easy to see that
i=s+1 I{π−1
f (y(s))<π−1
D(s) Qn
f (y(i))} = 0 ≤ D(cid:0)π−1
f (y(s))(cid:1). To sum up, ∀s ∈ {1, 2, ..., n − 1},
i=s+1 I{π−1
f (y(s))<π−1
D(s) Qn
f (y(s))(cid:1). Further considering π−1
f (y(i))} ≤ D(cid:0)π−1
f (y(n)) ≤ n and
i=s+1 I{π−1
f (y(s))<π−1
D(·) is a decreasing function, we have D(n) ≤ D(cid:0)π−1
f (y(n))(cid:1). As a result, we obtain,
n
1
1
G(cid:0)l(y(s))(cid:1)(cid:16)D(s) − D(cid:0)π−1
f (y(s))(cid:1)(cid:17) ≤
Xs=1
1 − N DCG(f ; x, L) =
Lβ1 (f ; x, L).
Nn
Nn
(2) We then prove the inequality for (1−MAP). First, we prove the result for 2-level ratings. Given
2-level rating data (x, L), it can be proved (see Lemma 1 in [4]) that Lβ2 (f ; x, L) = n1 − i0 + 1,
where i0 denotes the position of the ﬁrst object with label 0 in πf , and i0 ≤ n1 + 1. We then consider
n1 (cid:0)1 − M AP (f ; x, L)(cid:1) = n1 − Ps: l(πf (s))=1 P i≤s I{l(πf (i))=1}
case by case. If i0 > n1 (i.e., the
s
ﬁrst object with label 0 is ranked after position n1 in πf ), then all the objects with label 1 are ranked
before the objects with label 0. Thus n1 (1 − M AP (f ; x, L)) = n1 − n1 = 0 = Lβ2 (f ; x, L).
If i0 (πf ) ≤ n1 , there are i0 (πf ) − 1 objects with label 1 ranked before all the objects with label
0. Thus n1 (1 − M AP (f ; x, L)) ≤ n1 − i0 (πf ) + 1 = Lβ2 (f ; x, L). This proves the theorem for
2-level ratings.
Second, given K -level rating data (x, L), we denote the 2-level ratings induced by L as L0 . Then it
is easy to verify YL ⊆ YL0 . As a result, we have,
Lβ2 (f ; x, L0 ) = min
Lβ2 (f ; x, y) ≤ min
y∈YL
y∈YL0
Using the result for 2-level ratings, we obtain

Lβ2 (f ; x, y) = Lβ2 (f ; x, L).

1 − M AP (f ; x, L) = 1 − M AP (f ; x, L0 ) ≤

1
PK−1
i=k∗ ni

Lβ2 (f ; x, L0 ) ≤

1
PK−1
i=k∗ ni

Lβ2 (f ; x, L).

3.3 Essential loss: lower bound of loss functions

In this section, we show that many pairwise/listwise losses are upper bounds of the essential loss.
Theorem 2. The pairwise losses in Ranking SVM, RankBoost, and RankNet, and the listwise loss
in ListMLE are all upper bounds of the essential loss, i.e.,
β (s)(cid:1)Lp (f ; x, L);
(1) Lβ (f ; x, L) ≤ (cid:0) max
1≤s≤n−1
1
β (s)(cid:1)Ll (f ; x, y), ∀y ∈ YL .
ln 2 (cid:0) max
(2) Lβ (f ; x, L) ≤
1≤s≤n−1
Proof. (1) We now prove the inequality for the pairwise losses. First, we reformulate the pairwise
losses using permutation set YL ,

Lp (f ; x, L) =

n−1
Xs=1

n
Xi=s+1,
l(y(s)) 6=l(y(i))

φ(cid:0)f (xy(s) ) − f (xy(i) )(cid:1) =

n−1
Xs=1

n
Xi=s+1

a(cid:0)y(i), y(s)(cid:1)φ(cid:0)f (xy(s) ) − f (xy(i) )(cid:1),

6

where y is an arbitrary permutation in YL , a(i, j ) = 1 if l(i) 6= l(j ); a(i, j ) = 0 otherwise. Note that
only those pairs whose ﬁrst object has a larger label than the second one are counted in the pairwise
loss. Thus, the value of the pairwise loss is equal ∀y ∈ YL .
Second, we consider the value of a(cid:0)Tf (x(s) ), y(s)(cid:1) case by case. ∀y and ∀s ∈ {1, 2, ..., n − 1},
if a(cid:0)Tf (x(s) ), y(s)(cid:1) = 1 (i.e., ∃i0 > s, satisfying l(y(i0 )) 6= l(y(s)) and f (xy(i0 ) ) > f (xy(s) )),
considering that function φ in Ranking SVM, RankBoost and RankNet are all non-negative, non-
increasing, and φ(0) = 1, we have,
n
Xi=s+1
a(cid:0)y(i), y(s)(cid:1)φ(cid:0)f (xy(s) ) − f (xy(i) )(cid:1)
≥ a(cid:0)y(i0 ), y(s)(cid:1)φ(cid:0)f (xy(s) ) − f (xy(i0 ) )(cid:1) = φ(cid:0)f (xy(s) ) − f (xy(i0 ) )(cid:1) > 1 = a(cid:0)Tf (x(s) ), y(s)(cid:1).
If a(cid:0)Tf (x(s) ), y(s)(cid:1) = 0, it is clear that Pn
i=s+1 a(cid:0)y(i), y(s)(cid:1)φ(cid:0)f (xy(s) ) − f (xy(i) )(cid:1) ≥ 0 =
a(cid:0)Tf (x(s) ), y(s)(cid:1). Therefore,
n−1
n−1
n
Xi=s+1
Xs=1
Xs=1
β (s)a(cid:0)Tf (x(s) ), y(s)(cid:1).
a(cid:0)y(i), y(s)(cid:1)φ(cid:0)f (xy(s) ) − f (xy(i) )(cid:1) ≥
β (s)
Third, it can be proved (see Lemma 2 in [4]) that the following inequality holds,
n−1
Xs=1
β (s)a(cid:0)Tf (x(s) ), y(s)(cid:1).
Lβ (f ; x, L) ≤ max
y∈YL
Considering inequality (8) and noticing that the pairwise losses are equal ∀y ∈ YL , we have
n−1
n
Xi=s+1
Xs=1
β (s)(cid:1)Lp (f ; x, L).
a(cid:0)y(i), y(s)(cid:1)φ(cid:0)f (xy(s) ) − f (xy(i) )(cid:1) ≤ (cid:0) max
1≤s≤n−1
(2) We then prove the inequality for the loss function of ListMLE. Again, we prove the result case by
case. Consider the loss of ListMLE in Eq.(3). ∀y and ∀s ∈ {1, 2, ..., n − 1}, if I{Tf (x(s) ) 6=y(s)} = 1
2 Pn
(i.e., ∃i0 > s satisfying f (xy(i0 ) ) > f (xy(s) )), then ef (xy(s) ) < 1
i=s ef (xy(s) ) . Therefore, we
f (xy(s) )
have − ln
f (xy(i) ) > ln 2 = ln 2 I{Tf (x(s) ) 6=y(s)} . If I{Tf (x(s) ) 6=y(s)} = 0, then it is clear
e
P n
i=s e
f (xy(s) )
f (xy(i) ) > 0 = ln 2 I{Tf (x(s) ) 6=y(s)} . To sum up, we have,
e
P n
i=s e
n−1
n−1
ef (xy(s) )
β (s)(cid:16) − ln
i=s ef (xy(i) ) (cid:17) >
Xs=1
Xs=1
β (s) ln 2 I{Tf (x(s) ) 6=y(s)} ≥ ln 2 min
Pn
y∈YL
By further relaxing the inequality, we obtain the following result,
1
β (s)(cid:1)Ll (f ; x, y), ∀y ∈ YL .
ln 2 (cid:0) max
1≤s≤n−1

Lβ (f ; x, L) ≤ max
y∈YL

Lβ (πf , y) = ln 2 Lβ (πf , L).

(8)

− ln

β (s)

Lβ (f ; x, L) ≤

3.4 Summary

We have the following inequalities by combining the results obtained in the previous subsections.
(1) The pairwise losses in Ranking SVM, RankBoost, and RankNet are upper bounds of (1−NDCG)
and (1−MAP).

G(K − 1)D(1)
Lp (f ; x, L);
1 − N DCG(f ; x, L) ≤
Nn
1
Lp (f ; x, L).
1 − M AP (f ; x, L) ≤
PK
i=k∗ ni
(2) The listwise loss in ListMLE is an upper bound of (1−NDCG) and (1−MAP).
G(K − 1)D(1)
Ll (f ; x, y), ∀y ∈ YL ;
Nn ln 2
1
Ll (f ; x, y), ∀y ∈ YL .
ln 2 PK
i=k∗ ni

1 − N DCG(f ; x, L) ≤
1 − M AP (f ; x, L) ≤

7

Table 1: Ranking accuracy on OHSUMED

Methods
NDCG@5
NDCG@10

RankNet W-RankNet
0.4868
0.4568
0.4604
0.4414

ListMLE W-ListMLE
0.4588
0.4471
0.4453
0.4347

Methods
NDCG@5
NDCG@10

Regression Ranking SVM RankBoost
0.4494
0.4164
0.4278
0.4110
0.414
0.4302

FRank
0.4588
0.4433

ListNet
0.4432
0.441

SVMMAP
0.4516
0.4319

4 Discussion

The proofs of Theorems 1 and 2 actually suggest a way to improve existing loss functions. The key
idea is to introduce weights related to β1 (s) to the loss functions so as to make them tighter bounds
of (1−NDCG).
Speci ﬁcally, we introduce weights to the pairwise and listw ise losses in the following way,

˜Ll (f ; x, y) =

˜Lp (f ; x, L) =

n−1
K−1
n
G(cid:0)l(y(s))(cid:1)D(cid:16)1 +
nk (cid:17)
Xs=1
Xi=s+1
Xk=l(y(s))+1
a(cid:0)y(i), y(s)(cid:1)φ(cid:0)f (xy(s) ) − f (xy(i) )(cid:1), ∀y ∈ YL ;
n−1
n
G(cid:0)l(y(s))(cid:1)D(s)(cid:16) − f (xy(s) ) + ln (cid:0)
exp(f (xy(i) ))(cid:1)(cid:17).
Xi=s
Xs=1
It can be proved (see Proposition 1 in [4]) that the above weighted losses are still upper bounds of
(1−NDCG) and they are lower bounds of the original pairwise and listwise losses. In other words,
the above weighted loss functions are tighter bounds of (1−NDCG) than existing loss functions.
We tested the effectiveness of the weighted loss functions on the OHSUMED dataset in LETOR 3.0.6
We took RankNet and ListMLE as example algorithms. The methods that minimize the weighted
loss functions are referred to as W-RankNet and W-ListMLE. From Table 1, we can see that (1)
W-RankNet and W-ListMLE signi ﬁcantly outperform RankNet a nd ListMLE. (2) W-RankNet and
W-ListMLE also outperform other baselines on LETOR such as Regression, Ranking SVM, Rank-
Boost, FRank [15], ListNet and SVMMAP [18]. These experimental results seem to indicate that
optimizing tighter bounds of the ranking measures can lead to better ranking performances.

5 Conclusion and future work

In this work, we have proved that many pairwise/listwise losses in learning to rank are actually upper
bounds of measure-based ranking errors. We have also shown a way to improve existing methods
by introducing appropriate weights to their loss functions. Experimental results have validated our
theoretical analysis. As future work, we plan to investigate the following issues.

(1) We have modeled ranking as a sequence of classi ﬁcations, when deﬁning the essential loss. We
believe this modeling has its general implication for ranking, and will explore its other usages.

(2) We have taken NDCG and MAP as two examples in this work. We will study whether the
essential loss is an upper bound of other measure-based ranking errors.

(3) We have taken the loss functions in Ranking SVM, RankBoost, RankNet and ListMLE as ex-
amples in this study. We plan to investigate the loss functions in other pairwise and listwise ranking
methods, such as RankCosine [13], ListNet [3], FRank [15] and QBRank [19].

(4) While we have mainly discussed the upper-bound relationship in this work, we will study
whether loss functions in existing learning-to-rank methods are statistically consistent with the es-
sential loss and the measure-based ranking errors.

6http://research.microsoft.com/ ˜ letor

8

References
[1] R. Baeza-Yates and B. Ribeiro-Neto. Modern Information Retrieval. Addison Wesley, May
1999.
[2] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.
Learning to rank using gradient descent. In ICML ’05: Proceedings of the 22nd International
Conference on Machine learning, pages 89–96, New York, NY, USA, 2005. ACM.
[3] Z. Cao, T. Qin, T.-Y. Liu, M.-F. Tsai, and H. Li. Learning to rank: from pairwise approach to
listwise approach. In ICML ’07: Proceedings of the 24th International Conference on Machine
learning, pages 129–136, New York, NY, USA, 2007. ACM.
[4] W. Chen, T.-Y. Liu, Y. Lan, Z. Ma, and H. Li. Essential loss: Bridge the gap between ranking
measures and loss functions in learning to rank. Technical report, Microsoft Research, MSR-
TR-2009-141, 2009.
[5] D. Cossock and T. Zhang. Statistical analysis of bayes optimal subset ranking. Information
Theory, 54:5140–5154, 2008.
[6] Y. Freund, R. Iyer, R. E. Schapire, and Y. Singer. An efﬁci ent boosting algorithm for combining
preferences. Journal of Machine Learning Research, 4:933–969, 2003.
[7] R. Herbrich, K. Obermayer, and T. Graepel. Large margin rank boundaries for ordinal re-
gression. In Advances in Large Margin Classi ﬁers , pages 115–132, Cambridge, MA, 1999.
MIT.
[8] K. J ¨arvelin and J. Kek ¨al ¨ainen. Cumulated gain-based evaluation of ir techniques. ACM Trans-
actions on Information Systems, 20(4):422–446, 2002.
[9] T. Joachims. Optimizing search engines using clickthrough data. In KDD ’02: Proceedings
of the 8th ACM SIGKDD international conference on Knowledge discovery and data mining,
pages 133–142, New York, NY, USA, 2002. ACM.
[10] P. Li, C. Burges, and Q. Wu. Mcrank: Learning to rank using multiple classi ﬁcation and
gradient boosting. In NIPS ’07: Advances in Neural Information Processing Systems 20, pages
897–904, Cambridge, MA, 2008. MIT.
[11] T.-Y. Liu, J. Xu, T. Qin, W.-Y. Xiong, and H. Li. Letor: Benchmark dataset for research
on learning to rank for information retrieval. In SIGIR ’07 Workshop, San Francisco, 2007.
Morgan Kaufmann.
[12] Q. L. Olivier Chapelle and A. Smola. Large margin optimization of ranking measures. In NIPS
workshop on Machine Learning for Web Search 2007, 2007.
[13] T. Qin, X.-D. Zhang, M.-F. Tsai, D.-S. Wang, T.-Y. Liu, , and H. Li. Query-level loss functions
for information retrieval. Information Processing and Management, 44(2):838–855, 2008.
[14] M. Taylor, J. Guiver, S. Robertson, and T. Minka. Softrank: optimizing non-smooth rank
metrics. In Proceedings of the International Conference on Web search and web data mining,
pages 77–86, Palo Alto, California, USA, 2008. ACM.
[15] M.-F. Tsai, T.-Y. Liu, T. Qin, H.-H. Chen, and W.-Y. Ma. Frank: a ranking method with ﬁdelity
loss. In SIGIR ’07: Proceedings of the 30th annual ACM SIGIR conference, pages 383–390,
Amsterdam, The Netherlands, 2007. ACM.
[16] F. Xia, T.-Y. Liu, J. Wang, W. Zhang, and H. Li. Listwise approach to learning to rank - theory
and algorithm. In ICML ’08: Proceedings of the 25th International Conference on Machine
learning, pages 1192–1199. Omnipress, 2008.
[17] J. Xu and H. Li. Adarank: a boosting algorithm for information retrieval.
In SIGIR ’07:
Proceedings of the 30th annual international ACM SIGIR conference on Research and devel-
opment in information retrieval, pages 391–398, 2007.
[18] Y. Yue, T. Finley, F. Radlinski, and T. Joachims. A support vector method for optimizing
average precision. In SIGIR ’07: Proceedings of the 30th annual international ACM SIGIR
conference on Research and development in information retrieval, pages 271–278, New York,
NY, USA, 2007. ACM.
[19] Z. Zheng, H. Zha, T. Zhang, O. Chapelle, K. Chen, and G. Sun. A general boosting method
and its application to learning ranking functions for web search. In NIPS ’07: Advances in
Neural Information Processing Systems 20, pages 1697–1704. MIT, Cambridge, MA, 2008.

9

