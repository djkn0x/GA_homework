Machine Learning in Modern
Well Testing

Yang Liu and Yinfeng Qin

December 11, 2009

1

Introduction

Well testing is a crucial stage in the decision of
setting up new wells on oil ﬁeld. Decision makers
rely on the metrics to evaluate the candidate wells’
potential. One important metric is permeability,
measuring the ability of porous material to trans-
mit ﬂuids. High permeability often leads to high
yielding.
In a conventional well test, the well is controlled
to produce at a constant ﬂow rate, and the pres-
sure is measured for a couple of hours (Figure 1).
This pressure curve will be used to interpret the
reservoir parameters, including the permeability k
and initial pressure Pi . To interpret the pressure
curve, a radial ﬂow with inﬁnite boundary model is
utilized, whose mathematical solution may be sim-
ply written in the Equation 1. Key parameters in
Equation 1 are: pwf , the measured bottom hole
pressure, Pi , the initial pressure; q , the constant
ﬂow rate; k , the reservoir permeability. Tradition-
ally the permeability may be interpreted by com-
paring the observed pressure curve with the calcu-
lated overlay template (Figure 2).

(log t + C )

(1)

pwf = Pi −

qBµ
k
Nowadays, newly introduced Permanent Down-
hole Gauge (PDG), is widely used. PDG can mea-
sure both the pressure and varied ﬂow rate for a
long duration (Figure 3). However, current well
test remains the conventional approach, interpret-
ing only on a piece of pressure curve corresponding
to a constant ﬂow rate. Obviously, this method
wastes most data and the resulting interpretation
is not convincing.
This study tries to use machine learning ap-
proach to develop a method that is able to make
an interpretation on a modern well test by tak-
ing all measurements into account. We would like
to proceed in two steps. First, all the measured

)
i
s
p
(
 
e
r
u
s
s
e
r
P

3600

3400

3200

3000

2800

 
0

)
d
/
B
T
S
(
 
e
t
a
R
 
w
o
l
F

71

70.5

70

69.5

69

 
0

5

5

 

Noisy P
True P

25

 

True Q

10
15
time(hous)

20

10
15
time(hous)

20

25

Figure 1: Pressure and ﬂow rate signals from sub-
surface in a conventional well test.

 

k=18
k=20
k=22

3800

3600

3400

3200

3000

2800

)
i
s
p
(
 
e
r
u
s
s
e
r
P

2600
 
0

5

10
15
time(hous)

20

25

Figure 2: Pressure curves with diﬀerent reservoir
permeabilities.

noisy data are used to train a machine learning
model, which gives a good prediction given any ﬂow
rate history. Upon the completion of this step, the
reservoir parameters, which are the goal of the well
test, are actually stored in the machine learning
model. Secondly, we try to interpret the well test
result by extracting the reservoir parameters from
the learning model. Two diﬃculties lie in the pro-
cess: ﬁrst, the current physical model is designed
for constant ﬂow rate, which is not the case in a
modern well test; second, while in traditional well
test the ﬂow rate is accurate, in our problem both
the ﬂow rate and pressure are noisy.
Section 2 ﬁrst discusses learning the data set by
Locally Weighted Pro jection Regression (LWPR)
algorithm. Section 3 discuss applying the maximize
likelihood method in a Hilbert space by deﬁning a
transformation φ(x). Finally, Section 4 summarizes
the whole pro ject.

1

)
i
s
p
(
 
e
r
u
s
s
e
r
P

5000

4500

4000

3500

3000

2500

2000

 
0

)
d
/
B
T
S
(
 
e
t
a
R
 
w
o
l
F

100

50

0

−50

 
0

 

Noisy P
True P

10

20

30

40
time(hous)

50

60

70

80

 

Noisy Q
True Q

10

20

30

40
time(hous)

50

60

70

80

Figure 3: Pressure curves with diﬀerent reservoir
permeabilities in a modern well test.

2 Locally Weighted Pro jec-
tion Regression

2.1 Locally Weighted Pro jection Re-
gression Algorithm

Locally Weighted Pro jection Regression (LWPR)
is an algorithm that achieves nonlinear function
approximation in high-dimensional spaces with lo-
cally weighted linear regression in each dimension
(Atkeson, Moore, & Schaal, 1997). The LWPR
algorithm is improved over the Locally Weighted
Regression (LWR) algorithm by use of a pro jection
process.
The workﬂow of LWPR is as following:
(1)
Pro ject the training data into higher-dimensional
spaces. A subset pro jected on each pro jection di-
rection will be obtained. (2) Solve a LWR system
on each subset. A linear hypothesis will be trained
on each pro jection direction. (3) Sum up all hy-
pothesis on all dimensions to reconstruct the hy-
pothesis in the original one-dimensional space.

2.2 LWPR in Real Time Space

First the LWPR algorithm was applied to a
synthetic pressure generated from constant ﬂow
rate without noise.
In cases with constant ﬂow
rates(Figure 4 & 5), LWPR works very well.
When the ﬂow rate is not constant, the pres-
sure transient is no longer increasing or decreasing
monotonically. The incorrect predictions will be
more prevalent(Figure 6). The LWPR algorithm
fails when the ﬂow rate changes quickly (Figure 7).

Locally Weighted Projection Regression

e
r
u
s
s
e
r
P

 16

 14

 12

 10

 8

 6

 4

 2

 0

True Data
Prediction

 0

 4000
 8000
Time(samples)

 12000

Figure 4: Synthetic pressure generated from con-
stant ﬂow rate without noise.

Locally Weighted Projection Regression

e
r
u
s
s
e
r
P

 16

 14

 12

 10

 8

 6

 4

 2

 0

True Data
Noisy Data
Prediction

 0

 4000
 8000
Time(samples)

 12000

Figure 5: Synthetic pressure generated from con-
stant ﬂow rate with noise.

(2)

q ′ (τ ) [p (t − τ ) + S ] dτ

pwf = Z t
0
Currently we suspect this suﬀers from two rea-
sons: ﬁrst is the relatively slow learning rate of the
algorithm, second is that the pressure is a result of
convolution of previous ﬂow rates (Horne, 1995),
as described in Equation 2. To solve this problem,
one choice is to convert the data set into a space
where the pressures are independent of each other.
There actually is such a space where the pressures
are deconvolved, namely the Laplace space.

2.3 LWPR in Laplace Space

To apply the machine learning algorithm in Laplace
space, the workﬂow is natural and straight-forward:
(1) Transform the data set into Laplace space nu-
merically. (2) Apply the machine learning method
(LWPR) in Laplace space. Obtain the prediction

2

Locally Weighted Projection Regression

LWPR in Laplace Space

e
r
u
s
s
e
r
P

 1200

 1000

 800

 600

 400

 200

 0

 0

True Data
Noisy Data
Prediction

 5000

 10000
Time(samples)

 15000

 20000

}
e
r
u
s
s
e
r
P
 
e
c
a
l
p
a
L
{
e
R

 200

 150

 100

 50

 0

-50

-100

-150

True Data
Noisy Data
Prediction

 1

 1.2

 1.4

 1.6
 Im{s}

 1.8

 2

 2.2

Figure 6:
Synthetic pressure generated from
changed ﬂow rate with noise.

Figure 8: Synthetic pressure with noise in Laplace
space.

Locally Weighted Projection Regression

Prediction from LWPR in Laplace Space

 1500

 1000

 500

 0

e
r
u
s
s
e
r
P

True Data
Prediction

 0

 4000
 8000
Time(samples)

 12000

e
r
u
s
s
e
r
P

 800

 700

 600

 500

 400

 300

 200

 100

 0

 0

True Data
Noisy Data
Prediction

 100

 200

 300
Time(samples)

 400

 500

 600

Figure 7: Synthetic pressure generated from fast
changing ﬂow rate without noise.

Figure 9: Synthetic pressure with noise in real time
space.

in Laplace space. (3) Invert the prediction numeri-
cally from Laplace space back into time space. Fig-
ure 8 shows the result in Laplace space. From the
ﬁgure, it is clear that the method works well in
Laplace space.
The prediction in the Laplace space was then
converted into real time space, as shown in Fig-
ure 9. The overall trend is captured well. Two
zoom-in views are also provided in Figure 10 and
Figure 11.
Although the LWPR regression obtains good
prediction in the Laplace space, the performance
is slow. There is heavy computation in the process
of transforming and inverting the data between the
real time space and the Laplace time space, which
cost more than 95% CPU time. Therefore, a roll-
back is required: how can we train the machine
learning algorithm in the real time space but void
the problem of data dependency? Section 3 will
proposes another learning algorithm to answer this

question.

Likelihood
3 Maximize
Hilbert Space

in

3.1 Super Position

First we need to understand the physical essence
of the pressure transient when the ﬂow rates are
varied. When the ﬂow rates are varied, the pres-
sure transients are formed by a physical process
named Super Position. The pressure transients
caused by varied ﬂow rates are actually a combina-
tion of multiple pressure transients each of which
is corresponding to a constant ﬂow rate. Figure 12
demonstrates this process.
The super position enables us to re-write the con-
trol equation of the pressure transient in a modern
well test, as shown in Equation 3.

3

Prediction from LWPR in Laplace Space

True Data
Noisy Data
Prediction

 600

 550

 500

 450

e
r
u
s
s
e
r
P

 400
 30

 35

 40

 45
 55
 50
Time(samples)

 60

 65

 70

Figure 10: Synthetic pressure with noise in real
time space: zoom-in view 1.

Prediction from LWPR in Laplace Space

True Data
Noisy Data
Prediction

 680

 660

 640

 620

 600

 580

 560

 540

 520

e
r
u
s
s
e
r
P

 500
 120

 130

 140
 150
Time(samples)

 160

 170

Figure 11: Synthetic pressure with noise in real
time space: zoom-in view 2.

(5)

Equation 3 may be written as
wf = θT φ (cid:16)x(i) (cid:17)
P (i)
So instead of
feeding the learning algorithm
hθ (x) = θT x with data x(i) , we will feed the with
vector φ (cid:0)x(i) (cid:1). In this selected Hilbert space, the
learning hypothesis becomes
hθ (cid:16)φ (cid:16)x(i) (cid:17)(cid:17) = θT φ (cid:16)x(i) (cid:17)
(6)
So to train the learning algorithm, we just
need to estimate θ by stochastic gradient descent
method. After the hypothesis θ is obtained, we may
give a pressure transient prediction with any given
ﬂow rate history by Equation 5. Besides accurate
prediction, we would also like to interpret the reser-
voir parameters like Pi and k . It is actually very
straight forward after θ is obtained. Comparing
with Equation 3, we can get


After training the learning hypothesis with all
φ (cid:0)x(i) (cid:1), the reservoir parameters obtained are
listed in Table 1. The results are very close to the
true values of the reservoir parameters (Figure 14).
The trend of the prediction is very good, but the
curve is oscillating because the ﬂow rate history is
noisy. Section 3.3 improves the training process by
imposing a pre-processing on the noisy ﬂow rates.

Pi = θ0
C = θ1
θ2
k = Bµ
θ2

(7)

p(i)
wf = Pi −

(qj − qj−1 ) Bµ
k

i−1
Xj=1
(3)
With Equation 3, Section 3.2 solves the problem
by learning in a selected Hilbert space.

(log (ti − tj ) + C )

3.2 Application in Hilbert Space

With Equation 3, we may map each input vector
x(i) = [1; q (i) ; t(i) ]T by a function φ, shown in Equa-
tion 4.

φ (cid:16)x(i) (cid:17) = 
1
Pi−1
j=1 (cid:0)q (j) − q (j−1) (cid:1)
(4)

Pi−1
j=1 (cid:0)q (j) − q (j−1) (cid:1) log (cid:0)t(i) − t(j) (cid:1)
With this mapping, the pressure transient Pwf ,

4

Table 1: Parameter Interpretation from Machine

Learning

Parameters True Value Learning Value

Pi

k

5000

20

4989

20.89

3.3 Smooth Flow Rate by Edge Pre-
serving Filter

We would like to smooth the ﬂow rate, because the
prediction would be corrupted by the noise in ﬂow
rate. However, simple smoothing techniques can
blur the edges at transition positions, and intro-
duce error in all the data that follows. As a result,
we come up with the idea to use edge-preserving

ﬁlters widely used in computer vision community.
Speciﬁcally, we choose to use bi-lateral ﬁlter, which
in essence is described by
W (x; xi ) = exp "−   (f (x) − f (xi ))2
σ2
f

kx − xi k2
σ2
x

+

!#
(8)

The weight of data x to xi combines both magni-
tude and spatial diﬀerences, in contrast to normal
ﬁlters taking into account only spatial information.
By smoothing the ﬂow rate with Edge Preserving
Filter ﬁrst and then applying the machine learning
algorithm discussed in Section 3.2, the results are
much better, shown in Figure 15 and Table 2.

Table 2: Parameter Interpretation from Machine

Learning with Pre-processing on ﬂow rates

Parameters True Value Learning Value

Pi

k

5000

20

4997

20.07

4 Summary

In this work, we ﬁrst tried LWPR in real time and
Laplace space to learn the underlying model of well-
testing data. The prohibitive computation cost
lead us to re-consider the problem, and come up
with the idea to apply superposition to re-organize
the data and put them into a uniﬁed linear model.
Based on this model, gradient descent is used to
learn the model parameters, which reveals the de-
sired physical metrics of the well. Finally we uti-
lize edge-preserving ﬁlter to smooth ﬂow rate and
achieve further improved accuracy.

References

[1] R. N. Horne. Modern Well Test Analysis.
Petroway Inc., 1995.

[2] C. Atkeson, A. Moore, and S. Schaal. Locally
Weighted Learning. Artiﬁcial Intel ligence Re-
view, Vol. 11(4), pp 76-113, 1997.

[3] A. Ng. Machine Learning Lecture Notes. Stan-
ford University, 2009.

5000

P
 
∆

0

−5000

 
0

)
d
/
B
T
S
(
 
e
t
a
R
 
w
o
l
F

100

50

0

−50

−100

 
0

3000

2000

1000

P
 
∆

0

 
0

80

60

40

20

0

 

)
d
/
B
T
S
(
 
e
t
a
R
 
w
o
l
F

)
i
s
p
(
 
e
r
u
s
s
e
r
P

5000

4000

3000

2000

 
0

)
d
/
B
T
S
(
 
e
t
a
R
 
w
o
l
F

80

60

40

20

0

 

∆ p1
∆ p2

10

q1
q2

10

 

50

 

20
30
time(hous)

40

40

50

20
30
time(hous)

(a)

 

50

 

 

50

 

∆ p1+∆ p2

10

20
30
time(hous)

40

q1+q2

5

10

15

20
30
25
time(hous)

35

40

45

(b)

10

20
30
time(hous)

40

p1+p2

q1+q2

5

10

15

20
30
25
time(hous)

35

40

45

(c)

Figure 12: A demonstration of super position:
(a) two separated constant ﬂow and their pressure
drop, (b) the combination of the two constant ﬂow
forms a varied ﬂow and its corresponding pressure
drop, and (c) the varied ﬂow rate and the corre-
sponding pressure transient when the initial pres-
sure is considered.

5

)
i
s
p
(
 
e
r
u
s
s
e
r
P

5000

4500

4000

3500

3000

2500

2000

 
0

)
d
/
B
T
S
(
 
e
t
a
R
 
w
o
l
F

100

50

0

−50

 
0

 

Noisy P
True P

10

20

30

40
time(hous)

50

60

70

80

 

Noisy Q
True Q

10

20

30

40
time(hous)

50

60

70

80

Figure 13: Noisy pressure transient and noisy var-
ied ﬂow rates from a modern well test.

 

Prediction
True Data

5000

4500

4000

3500

3000

)
i
s
p
(
 
e
r
u
s
s
e
r
P

2500

 
0

10

20

30
50
40
time(hous)

60

70

80

Figure 14: Pressure prediction after machine learn-
ing with noisy varied ﬂow rates.

5000

4500

4000

3500

3000

)
i
s
p
(
 
e
r
u
s
s
e
r
P

 

Prediction
True Data

2500

 
0

10

20

30

40
time(hous)

50

60

70

80

)
d
/
B
T
S
(
 
e
t
a
R
 
w
o
l
F

80

60

40

20

0

 

True Q
Processed Q

−20

 
0

10

20

30
40
time (hours)

50

60

70

80

Figure 15: Pressure prediction after machine learn-
ing with smoothed varied ﬂow rates.

6

