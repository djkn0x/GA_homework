Matrix Completion from Power-Law Distributed
Samples

Raghu Meka, Prateek Jain, and Inderjit S. Dhillon
Department of Computer Sciences
University of Texas at Austin
Austin, TX 78712
{raghu,pjain,inderjit}@cs.utexas.edu

Abstract

The low-rank matrix completion problem is a fundamental problem with many
important applications. Recently, [4],[13] and [5] obtained the ﬁrst non-trivial
theoretical results for the problem assuming that the observed entries are sampled
uniformly at random. Unfortunately, most real-world datasets do not satisfy this
assumption, but instead exhibit power-law distributed samples. In this paper, we
propose a graph theoretic approach to matrix completion that solves the problem
for more realistic sampling models. Our method is simpler to analyze than previ-
ous methods with the analysis reducing to computing the threshold for complete
cascades in random graphs, a problem of independent interest. By analyzing the
graph theoretic problem, we show that our method achieves exact recovery when
the observed entries are sampled from the Chung-Lu-Vu model, which can gener-
ate power-law distributed graphs. We also hypothesize that our algorithm solves
the matrix completion problem from an optimal number of entries for the popu-
lar preferential attachment model and provide strong empirical evidence for the
claim. Furthermore, our method is easy to implement and is substantially faster
than existing methods. We demonstrate the effectiveness of our method on ran-
dom instances where the low-rank matrix is sampled according to the prevalent
random graph models for complex networks and present promising preliminary
results on the Net ﬂix challenge dataset.

1

Introduction

Completing a matrix from a few given entries is a fundamental problem with many applications in
machine learning, statistics, and compressed sensing. Since completion of arbitrary matrices is not
a well-posed problem, it is often assumed that the underlying matrix comes from a restricted class.
Here we address the matrix completion problem under the natural assumption that the underlying
matrix is low-rank.
Formally, for an unknown matrix M ∈ Rm×n of rank at most k , given Ω ⊆ [m] × [n], PΩ (M )1 and
k , the low-rank matrix completion problem is to ﬁnd a matrix X ∈ Rm×n such that

rank(X ) ≤ k

and PΩ (X ) = PΩ (M ).

(1.1)

Recently Candes and Recht [4], Keshavan et.al [13], Candes and Tao [5] obtained the ﬁrst non-trivial
guarantees for the above problem under a few additional assumptions on the matrix M and the set of
known entries Ω. At a high level, the assumptions made in the above papers can be stated as follows.
A1 M is incoherent, in the sense that the singular vectors of M are not correlated with the
standard basis vectors.
1Throughout this paper PΩ : Rm×n → Rm×n will denote the projection of a matrix onto the pairs of
indices in Ω: (PΩ (X ))ij = Xij for (i, j ) ∈ Ω and (PΩ (X ))ij = 0 otherwise.

1

A2 The observed entries are sampled uniformly at random.
In this work we address some of the issues with assumption [A2]. For Ω ⊆ [m]×[n], let the sampling
graph GΩ = (U, V , Ω) be the bipartite graph with vertices U = {u1 , . . . , um}, V = {v1 , . . . , vn }
and edges given by the ordered pairs in Ω 2 . Then, assumption [A2] can be reformulated as follows:
A3 The sampling graph GΩ is an Erd ˝os-R ´enyi random graph3 .
A prominent feature of Erd ˝os-R ´enyi graphs is that the degrees of vertices are Poisson distributed and
are sharply concentrated about their mean. The techniques of [4, 5], [13], as will be explained later,
crucially rely on these properties of Erd ˝os-R ´enyi graphs. However, for most large real-world graphs
such as the World Wide Web ([1]), the degree distribution deviates signi ﬁcantly from the Poisson
distribution and has high variance. In particular, most large matrix-completion datasets such as the
much publicized Net ﬂix prize dataset and the Yahoo Music dat aset exhibit power-law distributed
degrees, i.e., the number of vertices of degree d is proportional to d−β for a constant β (Figure 1).
In this paper, we overcome some of the shortcomings of assumption [A3] above by considering
more realistic random graph models for the sampling graph GΩ . We propose a natural graph theo-
retic approach for matrix completion (referred to as ICMC for informationcascadingmatrixcomple-
tion) that we prove can handle sampling graphs with power-law distributed degrees. Our approach
is motivated by the models for information cascading in social networks proposed by Kempe et
al. [11, 12]. Moreover, the analysis of ICMC reduces to the problem of ﬁnding density thresholds
for complete cascades in random graphs - a problem of independent interest.

By analyzing the threshold for complete cascades in the random graph model of Chung, Lu & Vu
[6] (CLV model), we show that ICMC solves the matrix completion problem for sampling graphs
drawn from the CLV model. The bounds we obtain for matrix-completion on the CLV model are
incomparable to the main results of [4, 5, 13]. The methods of the latter papers do not apply to
models such as the CLV model that generate graphs with skewed degrees. On the other hand, for
Erdos-Renyi graphs the density requirements for ICMC are stronger than those of the above papers.

We also empirically investigate the threshold for complete cascading in other popular random graph
models such as the preferential attachment model [1], the forest- ﬁre model [17] and the afﬁliation
networks model [16]. The empirical estimates we obtain for the threshold for complete cascading
in the preferential attachment model strongly suggest that ICMC solves the exact matrix-completion
problem from an optimal number of entries for sampling procedures with preferential attachment.

Our experiments demonstrate that for sampling graphs drawn from more realistic models such as
the preferential attachment, forest- ﬁre and afﬁliation ne
twork models, ICMC outperforms - both in
accuracy and time - the methods of [4, 5, 3, 13] by an order of magnitude.

In summary, our main contributions are:
• We formulate the sampling process in matrix completion as generating random graphs (GΩ ) and
demonstrate that the sampling assumption [A3] does not hold for real-world datasets.
• We propose a novel graph theoretic approach to matrix completion (ICMC) that extensively uses
the link structure of the sampling graph. We emphasize that previously none of the methods
exploited the structure of the sampling graph.
• We prove that our method solves the matrix completion problem exactly for sampling graphs
generated from the CLV model which can generate power-law distributed graphs.
• We empirically evaluate our method on more complex random graph models and on the Net ﬂix
Challenge dataset demonstrating the effectiveness of our method over those of [4, 5, 3, 13].

2 Previous Work and Preliminaries

The Net ﬂix challenge has recently drawn much attention to th e low-rank matrix completion prob-
lem. Most methods for matrix completion and the more general rank minimization problem with
afﬁne constraints are based on either relaxing the non-conv ex rank function to a convex function
or assuming a factorization of the matrix and optimizing the resulting non-convex problem using
alternating minimization and its variants [2, 15, 18].

2We will often abuse notation and identify edges (ui , vj ) with ordered pairs (i, j ).
3We consider the Erd ˝os-R ´enyi model, where edges (ui , vj ) ∈ E independently with probability for p for
(i, j ) ∈ [m] × [n] and p is the density parameter.

2

Until recently, most methods for rank minimization subject to afﬁne constraints were heuristic in
nature with few known rigorous guarantees. In a recent breakthrough, Recht et.al [20] extend the
techniques of compressed sensing to rank minimization with afﬁne constraints. However, the results
of Recht et.al do not apply to the case of matrix completion as the constraints in matrix completion
do not satisfy the restricted isoperimetryproperty they assume.

Building on the work of Recht et al. [20], Candes and Recht [4] and Candes and Tao [5] showed that
minimizing the trace-norm recovers the unknown low-rank matrix exactly under certain conditions.
However, these approaches require the observed entries to be sampled uniformly at random and as
suggested by our experiments, do not work well when the observed entries are not drawn uniformly.

Independent of [4, 5], Keshavan et al. [13] also obtained similar results for matrix completion using
different techniques that generalize the works of Friedman et al. [9], Feige and Ofek [8] on the
spectrum of random graphs. However, the results of [13], crucially rely on the regularity of Erd ˝os-
R ´enyi graphs and do not extend to sampling graphs with skewed degree distributions even for rank
one matrices. This is mainly because the results of Friedman et al. and Feige and Ofek on the
spectralgap of Erd ˝os-R ´enyi graphs do not hold for graph models with skewed expected degrees (see
[6, 19]).

We also remark that several natural variants of the trimming phase of [8] and [13] did not improve
the performance in our experiments. A similar observation was made in [19], [10] who address the
problem of re-weighting the edges of graphs with skewed degrees in the context of LSA.

2.1 Random Graph Models
We focus on four popular models of random graphs all of which can generate graphs with power-law
distributed degrees. In contrast to the common descriptions of the models, we need to work with
bipartite graphs; however, the models we consider generalize naturally to bipartite graphs. Due to
space limitations we only give a (brief) description of the Chung et.al [6], and refer to the original
papers for the preferential attachment [1], forest- ﬁre [17 ] and afﬁliation networks [16] models.
[6] generates graphs with arbitrary expected degree sequences, p1 , . . . , pm ,
The CLV model
q1 , . . . , qn with p1 + . . . + pm = q1 + . . . + qn = w . In the model, a bipartite graph G = (U, V , E )
with U = {u1 , . . . , um}, V = {v1 , . . . , vn } is generated by independently placing an edge between
vertices ui , vj with probability pi qj /w for all i ∈ [m], j ∈ [n]. We deﬁne the density of an instance
of CLV model to be the expected average degree (p1 + . . . + pm )/(mn) = w/mn.
The CLV model is more general than the standard Erd ˝os-R ´enyi model with the case pi = np, qi =
mp corresponding to the standard Erd ˝os-R ´enyi model with density p for bipartite random graphs.
Further, by choosing weights that are power-law distributed, the CLV model can generate graphs
with power-law distributed degrees, a prominent feature of real-world graphs.

3 Matrix Completion from Information Cascading
We now present our algorithm ICMC. Consider the following standard formulation of the low-rank
matrix completion problem: Given k , Ω, PΩ (M ) for a rank k matrix M , ﬁnd X, Y such that
PΩ (X Y T ) = PΩ (M ), X ∈ Rm×k , Y ∈ Rn×k .
(3.1)
Note that given X we can ﬁnd Y and vice versa by solving a linear least squares regression prob-
lem. This observation is the basis for the popular alternate minimization heuristic and its variants
which outperform most methods in practice. However, analyzing the performance of alternate min-
imization is a notoriously hard problem. Our algorithm can be seen as a more reﬁned version of the
alternate minimization heuristic that is more amenable to analysis. We assume that the target matrix
M is non-degenerate in the following sense.
Deﬁnition 3.1 A rank k matrix Z is non-degenerate if there exist X ∈ Rm×k , Y ∈ Rn×k ,
Z = X Y T such that any k rows of X are linearly independent and any k rows of Y are linearly
independent.
Though reminiscent of the incoherence property used by Candes and Recht, Keshavan et al., non-
degeneracy appears to be incomparable to the incoherence property used in the above works. Ob-
serve that a random low-rank matrix is almost surely non-degenerate.
Our method progressively computes rows of X and Y so that Equation (3.1) is satis ﬁed. Call a
vertex ui ∈ U as infected if the i’th row of X has been computed (the term infected is used to reﬂect

3

that infection spreads by contact as in an epidemic). Similarly, call a vertex vj ∈ V as infected if
the j ’th row of Y has been computed. Suppose that at an intermediate iteration, vertices L ⊆ U and
R ⊆ V are marked as infected. That is, the rows of X with indices in L and rows of Y with indices
in R have been computed exactly.
Now, for an uninfected j ∈ [n], to compute the corresponding row of Y , y
j ∈ Rk , we only need k
T
independent linear equations. Thus, if M is non-degenerate, to compute y
j we only need k entries
T
of the j ’th column of M with row indices in L. Casting the condition in terms of the sampling graph
j can be computed and vertex vj ∈ V be marked as infected if there are at least k edges from
GΩ , y
T
vj to infected vertices in L. Analogously, x
i can be computed and the vertex ui ∈ U be marked as
T
infected if there are at least k edges from ui to previously infected vertices R.
Observe that M = X Y T = XW W −1Y T , for any invertible matrix W ∈ Rk×k . Thus for non-
degenerate M , without loss of generality, a set of k rows of X can be ﬁxed to be the k × k identity
matrix Ik . This suggests the following cascading procedure for infecting vertices in GΩ and pro-
gressively computing the rows of X, Y . Here L0 ⊆ U with |L0 | = k .

ICMC(GΩ , PΩ (M ), L0 ):
1 Start with initially infected sets L = L0 ⊆ U , R = ∅. Set the k × k sub-matrix of X with rows
in L0 to be Ik .
2 Repeat until convergence:
(a) Mark as infected all uninfected vertices in V that have at least k edges to previously infected
vertices L and add the newly infected vertices to R.
(b) For each newly infected vertex vj ∈ R, compute the j ’th row of Y using the observed
entries of M corresponding to edges from vj to L.
(c) Mark as infected all uninfected vertices in U that have at least k edges to previously infected
vertices R and add the newly infected vertices to L.
(d) For each newly infected vertex ui ∈ L, compute the i’th row of X using the observed
entries of M corresponding to edges from ui to R
3 Output M ′ = X Y T .

We abstract the cascading procedure from above using the framework of Kempe et al. [11] for
information cascades in social networks. Let G = (W, E ) be an undirected graph and ﬁx A ⊆ W ,
k > 0. Deﬁne σG,k (A, 0) = A and for t > 0 deﬁne σG,k (A, t + 1) inductively by

σG,k (A, t + 1) = σG,k (A, t) ∪ {u ∈ W : u has at least k edges to σG,k (A, t) }.

Deﬁnition 3.2 The inﬂuence of a set A ⊆ W , σG,k (A), is the number of vertices infected by the
cascading process upon termination when starting at A. That is, σG,k (A) = | ∪t σG,k (A, t)|. We
say A is completely cascading of order k if σG,k (A) = |W |.

We remark that using a variant of the standard depth- ﬁrst sea rch algorithm, the cascading process
above can be computed in linear time for any set A. From the discussion preceding ICMC it follows
that ICMC recovers M exactly if the cascading process starting at L0 infects all vertices of GΩ and
we get the following theorem.

Theorem 3.1 Let M be a non-degenerate matrix of rank k . Then, given GΩ = (U, V , Ω), PΩ (M )
and L0 ⊆ U with |L0 | = k , ICMC(GΩ , PΩ (M ), L0 ) recovers the matrix M exactly if L0 is a
completely cascading set of order k in GΩ .

Thus, we have reduced the matrix-completion problem to the graph-theoretic problem of ﬁnding
a completely cascading set (if it exists) in a graph. A more general case of the problem –
ﬁnding
a set of vertices that maximize inﬂuence, was studied by Kemp e et al. [11] for more general cas-
cading processes. They show the general problem of maximizing inﬂuence to be NP-hard and give
approximation algorithms for several classes of instances.

However, it appears that for most reasonable random graph models, the highest degree vertices have
large inﬂuence with high probability.
In the following we in vestigate completely cascading sets
in random graphs and show that for CLV graphs, the k highest degree vertices form a completely
cascading set with high probability.

4

Information Cascading in Random Graphs
4
We now show that for sufﬁciently dense CLV graphs and ﬁxed
a completely cascading set with high probability.

k , the k highest degree vertices form

Theorem 4.1 For every γ > 0, there exists a constant c(γ ) such that the following holds. Con-
sider an instance of the CLV model given by weights p1 , . . . , pm , q1 , . . . , qn with density p and
min(pi , qj ) ≥ c(γ )k log n/pk . Then, for G = (U, V , E ) generated from the model, the k highest
degree vertices of U form a completely cascading set of order k with probability at least 1 − n−γ .

(4.1)

qk+1
j

Proof sketch We will show that the highest weight vertices L0 = {u1 , . . . , uk } form a completely
cascading set with high probability; the theorem follows from the above statement and the observa-
tion that the highest degree vertices of G will almost surely correspond to vertices with large weights
in the model; we omit these details for lack of space. Let w = Pi pi = Pj qj = mnp and m ≤ n.
Fix a vertex ui /∈ L0 and consider an arbitrary vertex vj ∈ V . Let P i
j be the indicator variable
that is 1 if (ui , vj ) ∈ E and vj is connected to all vertices of L0 . Note that vertex ui will be
infected after two rounds by the cascading process starting at L0 if Pj P i
j ≥ k . Now, Pr[P i
j = 1] =
(pi qj /w) Q1≤l≤k (pl qj /w) and
n
n
pi qj
pi
pl qj
Xj=1
Xj=1
wk+1 · ( Y1≤l≤k
w Yl≤k
E[P i
1 + . . . + P i
n ] =
w
Observe that Pi pi = w ≤ nk + pk (m − k). Thus, pk ≥ (w − nk)/(m − k). Now, using the
power-mean inequality we get,
¶k+1
n ≥ n µ q1 + . . . + qn
n ´k+1
= n · ³ w
1 + qk+1
qk+1
2 + . . . + qk+1
(4.2)
n
with equality occurring only if qj = w/n for all j . From Equations (4.1), (4.2) we have
m − k ¶k
n ] ≥ pi · µ w − nk
1
1 + . . . + P i
E[P i
nk
m ¶−k
w ¶k
= pi · µ1 −
· µ1 −
mn ´k
nk
· ³ w
k
It is easy to check that under our assumptions, w ≥ nk2 and m ≥ k2 . Thus, (1 − nk/w)k ≥ 1/e
and (1 − k/m)−k ≥ 1/2e. From Equation (4.3) and our assumption pi ≥ c(γ )k log n/pk , we get
n ] ≥ c(γ )k log n/4e2 .
1 + . . . + P i
E[P i
n are independent of each other, using the above lower
Now, since the indicator variables P i
1 , . . . , P i
bound for the expectation of their sum and Chernoff bounds we get Pr[P i
1 + . . . + P i
n ≤ k ] ≤
exp(−Ω(c(γ ) log n)). Thus, for a sufﬁciently large constant c(γ ), the probability that the vertex ui
is uninfected after two rounds Pr[P1 + . . . + Pn ≤ k ] ≤ 1/2mγ+1 . By taking a union bound over
all vertices uk+1 , . . . , um , the probability that there is an uninfected vertex in the left partition after
two steps of cascading starting from L0 is at most 1/2mγ . The theorem now follows by observing
that if the left partition is completely infected, for a suitably large constant c(γ ), all vertices in the
right will be infected with probability at least 1 − 1/2mγ as qj ≥ c(γ )k log n.¤

.

,

.

(4.3)

=

pl ) ·

·

Combining the above with Theorem 3.1 we obtain exact matrix-completion for sampling graphs
drawn from the CLV model.

Theorem 4.2 Let M be a non-degenerate matrix of rank k . Then, for sampling graphs GΩ gen-
erated from a CLV model satisfying the conditions of Theorem 4.1, ICMC recovers the matrix M
exactly with high probability.

Remark: The above results show exact-recovery for CLV graphs with densities up to n−1/k = o(1).
As mentioned in the introduction, the above result is incomparable to the main results of [4, 5], [13].

The main bottleneck for the density requirements in the proof of Theorem 4.1 is Equation (4.2)
relating Pj qk+1
to (Pj qj )k+1 , where we used the power-mean inequality. However, when the
j
5

expected degrees qj are skewed, say with a power-law distribution, it should be possible to obtain
much better bounds than those of Equation (4.2), hence also improving the density requirements.
Thus, in a sense the Erd ˝os-R ´enyi graphs are the worst-case examples for our analysis.

Our empirical simulations also suggest that completely cascading sets are more likely to exist in
random graph models with power-law distributed expected degrees as compared to Erd ˝os-R ´enyi
graphs. Intuitively, this is because of the following reasons.
• In graphs with power-law distributed degrees, the high degree vertices have much higher degrees
than the average degree of the graph. So, infecting the highest degree vertices is more likely to
infect more vertices in the ﬁrst step.
• More importantly, as observed in the seminal work of Kleinberg [14] in most real-world graphs
there are a small number of vertices (hubs) that have much higher connectivity than most ver-
tices. Thus, infecting the hubs is likely to infect a large fraction of vertices.
Thus, we expect ICMC to perform better on models that are closer to real-world graphs and have
power-law distributed degrees. In particular, as strongly supported by experiments (see Figure 3),
we hypothesize that ICMC solves exact matrix completion from an almost optimal number of entries
for sampling graphs drawn from the preferential attachment model.
Conjecture 4.3 There exists a universal constant C such that for all k ≥ 1, k1 , k2 ≥ C k the fol-
lowing holds. For G = (U, V , E ) generated from the preferential attachment model with parameters
m, n, k1 , k2 , the k highest degree vertices of U form a completely cascading set of order k with high
probability.
If true, the above combined with Theorem 3.1 would imply the following.
Conjecture 4.4 Let M be a non-degenerate matrix of rank k . Then, for sampling graphs GΩ gen-
erated from a PA model with parameters k1 , k2 ≥ C k , ICMC recovers the matrix M exactly with
high probability.
Remark: To solve the matrix completion problem we need to sample at least (m + n)k entries.
Thus, the bounds above are optimal up to a constant factor. Moreover, the bounds above are stronger
than those obtainable - even information theoretically - for Erd ˝os-R ´enyi graphs, as for Erd ˝os-R ´enyi
graphs we need to sample Ω(n log n) entries even for k = 1.

5 Experimental Results
We ﬁrst demonstrate that for many real-world matrix complet
ion datasets, the observed entries are
far from being sampled uniformly with the sampling graph having power-law distributed degrees.
We then use various random graph models to compare our method against the trace-norm based
singular value thresholding algorithm of [3], the spectral matrix completion algorithm (SMC) of
[13] and the regularized alternating least squares minimization (ALS) heuristic. Finally, we present
empirical results on the Net ﬂix challenge dataset. For comp aring with SVT and SMC, we use the
code provided by the respective authors; while we use our own implementation for ALS. Below we
provide a few implementation details for our algorithm ICMC.
Implementation Details
Consider step 2(b) of our algorithm ICMC. Let Lj be the set of vertices in L that have an edge to
vj , Lk
j be any size k subset of Lj , and let X (Lk
j , :) be the sub-matrix of X containing rows corre-
sponding to vertices in Lk
j . If the underlying matrix is indeed low-rank and there is no noise in the
observed entries, then for a newly infected vertex vj , the corresponding row of Y , y
j , can be com-
T
puted by solving the following linear system of equations: M (Lk
j , :)yj . To account for
j , j ) = X (Lk
noise in measurements, we compute yj by solving the following regularized least squares problem:
2 , where λ is a regularization parameter. Similarly,
yj = argminy kM (Lj , j ) − X (Lj , :)yk2
2 + λkyk2
2 .
i by solving: xi = argminx kM (i, Ri )T − Y (Ri , :)xk2
we compute x
T
2 + λkxk2
Note that if ICMC fails to infect all the vertices, i.e. L ( U or R ( V , then rows of X and Y
will not be computed for vertices in U \L and V \R. Let X = [XL , X ˜L ], where XL is the set of
computed rows of X (for vertices in L) and X ˜L denotes the remaining rows of X . Similarly, let
Y = [YR , Y ˜R ]. We estimate X ˜L and Y ˜R using an alternating least squares based heuristic that solves
the following:
2
¯¯¯¯
˜R ]¶¯¯¯¯
X ˜L ,Y ˜R ¯¯¯¯
¯¯¯¯
PΩ µM − ·XL
X ˜L¸ [Y T
R Y T
min
6

F + µkY ˜R k2
+ µkX ˜L k2
F ,

F

