CS229 Pro ject: A Machine Learning Approach to Stroke Risk
Prediction

Yu Cao
Hsu-Kuang Chiu
Aditya Khosla
Cliﬀ Chiung Yu Lin

Abstract

In this paper, we consider the prediction
of stroke using the Cardiovascular Health
Study (CHS) dataset. Missing data impu-
tation, feature selection and feature aggre-
gation were conducted before training and
making prediction with the dataset. Then
we used a mixture of support vector ma-
chine (SVM) and stratiﬁed Cox proportional
hazards model to predict the occurrence of
stroke. Diﬀerent methods and variations of
models were evaluated and compared to ﬁnd
the best algorithm.

1. INTRODUCTION

Currently home-monitored chronic health condition
data is used in health-risk assessment systems. Ac-
cording to the data, the systems make predictions on
the possibility that a a patient might need medical
help in the next few years due to the onset of disease
or other conditions. The prediction result is helpful
for prevention or early treatment. However, many cur-
rent systems use relatively simple hand-coded rules to
build the prediction models. Applying machine learn-
ing techniques to the health-risk assessment problem
will be a possible approach to have more accurate
predictions.
In this pro ject, our ob jective is to im-
prove the accuracy of stroke prediction using the CHS
dataset. It is a challenging task for three main reasons:
(1) The CHS dataset suﬀers from problems such as a
large fraction of missing data ( 25%), sets of correlated
features, while some of the features are not highly re-
lated to stroke, and (2) the stroke prediction problem
itself involves the survival time of individuals that are
not captured well by typical machine learning meth-

yufcao@stanford.edu
hkchiu@stanford.edu
aditya86@stanford.edu
chiungyu@stanford.edu

ods (3) the dataset is extremely skewed as only 5%
of the patients had a stroke over the period of consid-
eration. Therefore, missing data imputation, feature
selection and aggregation, and the Cox proportional
hazard models are integrated to overcome problems (1)
and (2). To overcome problem (3), we use the area un-
der the receiver operating characteristic (ROC) curve
instead of the usual measures of accuracy as we can
achieve 95% accuracy simply by classifying all the pa-
tients as not having a stroke, which is clearly not a
useful prediction.

1.1. The Cardiovascular Health Study (CHS)
Dataset

The CHS [8] is a study of risk factors for cardiovascu-
lar diseases in people above 65 years old. More than
5,000 patients were examined yearly from 1989 to 1999,
with about 2,700 attributes collected annually through
medical tests and a set of questionnaires. Events such
as stroke and hospitalization were also recorded for
each patient. However, in a longitudinal study like
CHS, it is unlikely that all patients return each year
and provide data for all the required attributes.
In
the CHS dataset, some attributes are missing inter-
mittently for certain years, while some attributes have
missing data for a contiguous series of years. Further-
more, the attributes collected per patient change from
year to year and there is no easy way to determine the
change over time for a single feature.

1.2. Our Contributions

We compared more than 8 diﬀerent data imputation
methods to ﬁnd the best method for the given dataset.
We also used forward search feature selection to pick a
smaller set with 132 features. A prediction model us-
ing SVM and Cox is then built to determine whether a
patient has a high risk of stroke in the next 5 years. We
tried a variety of other methods including EM based
algorithms and Gaussian Process regression, but we
have not described those as they did not produce sat-

A Machine Learning Approach to Stroke Risk Prediction

isfactory results. Using data imputation, combined
with feature selection, we achieved 0.72 for area un-
der the ROC curve. We also tried to incorporate the
data from multiple years to make a better prediction.
The rest of the paper is organized as follows. Section 2
provides an overview of the problems that we consider,
and reviews the related previous works in the litera-
ture. Section 3 describes the approaches to tackle the
issues and improve the results. Then, experimental
results are shown and discussed in Section 4. Finally,
conclusions are in Section 5 and future research direc-
tions are given in Section 6.

2. PROBLEM OVERVIEW AND
PREVIOUS WORK

The problem we consider can be roughly divided into
three parts: (1) imputation of the missing entries in
the dataset, (2) selection of strong features and aggre-
gation of weak features, and (3) stroke prediction with
the selected ﬁlled-in features.

2.1. Missing Data Imputation

The ﬁrst part of the problem is to ﬁll in the missing
entries in the dataset. In [1] several methods were dis-
cussed, including ﬁlling missing features with column
mean, column median and hot-deck imputation. They
are commonly used in statistics and serve as the base-
line methods against which we would like to test the
other algorithms that we develop or use.

We evaluated the missing data imputation results with
the following two sets of metrics.

1. Data imputation accuracy: The primary target
of missing data imputation is to achieve accurate
imputation of the missing entries, evaluated by
the following 4 metrics as described in [1].

(a) Root-Mean-Square Deviation (RMSD)

(b) Mean Absolute Deviation (MAD)

(c) Bias: the diﬀerence between mean of the im-
puted results and mean of the ground-truth
values.

(d) Proportionate Variance (PV): the proportion
of variance of the imputed results to variance
of the ground-truth values.

2.2. Feature Selection and Aggregation

The CHS dataset has a large number of attributes
ranging from demographic information, clinical his-
tory, to biomedical and physical measurements [10].
However, only a small subset of attributes is highly
relevant to stroke prediction. In addition, some indi-
vidual attributes can be weak but correlated, and the
aggregated feature may serve as a good indicator to
stroke occurrence.
[3] has shown that SVM is one of
the best methods for feature selection. Other papers
such as [10] also use manually selected features accord-
ing to risk factors analyzed by medical and clinical
study. The subset of features selected can be com-
bined with stroke prediction models to evaluate the
performance of feature selection and aggregation.

2.3. Stroke Prediction

After ﬁlling the missing data entries and selecting the
most representative features, we can use those prepro-
cessed data to build the stroke prediction model. In [3],
several machine learning algorithms were applied in a
stroke risk assessment problem: support vector ma-
chines (SVM), decision trees, nearest neighbors, and
multilayer perception. According to [3], SVM is the
most promising algorithm with high sensitivity and
speciﬁcity. Therefore SVM was chosen to build our
stroke risk prediction model. The evaluation metric in
medical diagnosis is better chosen as the area under
ROC curve in order to assess both the sensitivity and
speciﬁcity performance of the model.

The Cox proportional hazards model is one of the
most important statistical models used in medical
research[9]. This model has been extensively studied[6,
9], and has been applied in various medical applica-
tions for the prediction of various diseases[10, 5] and
analysis of medical data[7]. The paper by Lumley et
al(2002), which makes use of the Cox proportional haz-
ards model is the paper that we used as our baseline
result as it contained the best stroke prediction scores
as compared to the other papers relating to this appli-
cation. We followed the method described in [10] to
attempt to achieve the same results and to use that
as our comparison metric to gauge the success of our
models.

3. ALGORITHMS

2. Overall stroke prediction quality: The ultimate
goal of the missing data imputation is to collab-
orate with stroke prediction algorithm. Imputa-
tion results were fed to the prediction methods to
evaluate the overall stroke prediction quality.

3.1. Missing Data Imputation Methods

For missing data imputation, two main observations
on the CHS dataset aﬀect our strategies: (1) only a
small subset of the features is highly related to the
occurrence of stroke, and (2) many of the features are

A Machine Learning Approach to Stroke Risk Prediction

discrete instead of continuous. Due to observation (1),
we focus our prediction and evaluation on a set of 132
features selected by forward search using SVM. And
due to observation (2), for most algorithms that we
implement, we also evaluate extra versions that align
each imputed value to its closest discrete label.

Besides the baseline methods, the following imputa-
tion algorithms were implemented and evaluated.

so it will be computationally expensive to complete
the entire forward search process with all the features.
Thus, L1 regularized logistic regression was executed
ﬁrst to choose 200 features with highest signiﬁcance
ranking as the domain of our forward search process.
The forward search was performed with linear kernel
SVM and 5-fold cross validation. The value of param-
eter C was also tuned to achieve the best results.

1. Column mean with alignment to the closest dis-
crete value
2. Linear regression
3. Linear regression with alignment to the closest
discrete value
4. Singular Value Decomposition (SVD)
5. Singular Value Thresholding (SVT) from [4]

3.2. Feature Aggregation

In the set of questionnaires answered by each patient,
there are several groups of contiguous questions de-
signed to evaluate a similar quality. For example, how
often the patient does various sports or whether the
patient can spell some words correctly. The answer
options also have the same pattern for these questions.
These features are highly correlated. Therefore we
looked through the descriptions for each feature and
decided to aggregate a group of contiguous features if
they are targeted at the same type of assessment and
share the same set of values in the choice of answer.
In the end, 13 groups were selected. Since the fea-
tures within a group have the same answer values, we
could use the mean of these values as an indicator for
the aggregated feature. However there can be missing
value in any of the features for a patient. Therefore we
should check whether missing values of features exist
for each patient, and exclude the missing values when
computing the mean for that patient. In addition, the
aggregated features should be computed before stan-
dardizing all the feature values and removal of features
with lots of missing data to ensure that the aggregated
features capture the property of the original data.

3.3. Feature Selection

Firstly, features with missing data rate higher than a
threshold value were removed. Even though we have
missing data imputation algorithms, features with too
many missing entries still may not give us accurate in-
formation after imputation. Therefore, those features
were ﬁltered out.

3.4. Stroke Prediction with Support Vector
Machine

Our stroke prediction model has ﬁve steps:

1. Feature aggregation: average weak but correlated
features
2. Data preprocessing: remove features and train-
ing examples with missing data rate higher than
threshold values.
3. Features selection: select the best subset of fea-
tures.
4. Missing data imputation: ﬁll in values of missing
entries.
5. SVM training and testing: With the feature set
obtained from previous step, train an SVM model
with linear kernel due to computation eﬃciency.
In testing, we used 10-fold cross validation to ob-
tain an average generalization performance.

(1)

βiXi )

3.5. Cox proportional hazards model
n(cid:88)
The proportional hazards regression model is given by
h(t|X) = h0 (t)exp(
i=1
where h(t|X) is the hazard value at time t given the
feature set X for an individual, X1 , . . . , Xn are the
features, h0 (t) is an arbitrary baseline hazard function,
and β1 , . . . , βn are the parameters that we are trying
to estimate for the model. This model is known as
a semiparametric model because the baseline hazard
function is treated nonparametrically. Thus, we can
see that the parameters have a multiplicative eﬀect
on the hazard value which makes it diﬀerent from the
linear regression models and these models have been
shown to correspond better to biological data[2].
Given the attributes of two individuals, X(1) and X(2) ,
n(cid:88)
we can obtain their hazards ratio as
h(t|X(1) )
i − X (2)
βi (X (1)
= exp(
h(t|X(2) )
i
i=1

))

(2)

Then forward search technique was applied to select
the subset of most representative features. However,
the number of features was 800 after preprocessing,

Thus, we observe that the hazard ratio is independent
of the time t, and by comparing these hazard ratios,
we can ﬁnd a threshold to classify the individuals.

A Machine Learning Approach to Stroke Risk Prediction

The same steps as described in the previous section
were used with this model to make predictions to be
able to compare the two models.

3.6. Cox proportional hazards model with
SVM

The SVM and Cox models described in the previous
sections only allowed us to make predictions using the
baseline data, or data from a single year. To incorpo-
rate the eﬀect of the data from multiple years, the two
models were combined using the following algorithm.
For each of the years that we want to consider:

1. Perform feature selection using forward search
2. Get a hazards value by applying the Cox propor-
tional hazards model
3. Combine the hazards value by using them as fea-
tures for a SVM

This model allowed us to incorporate the fact that the
features from each year aﬀected the prediction score
in a multiplicative way, and the relative importance of
each year could be estimated by ﬁnding the parame-
ters corresponding to the hazards ratio from each year.
The regular model that allows for time dependence in
the Cox model could not be used as features do not
remain consistent from year to year. This model al-
lowed us to incorporate any set of features from mul-
tiple years.

4. EXPERIMENTAL ESTIMATION

ble 3. Here column mean was used for missing data
imputation. We chose a linear kernel with a ﬁxed C
value equal to 0.0003 for SVM model. We can see
that using only the feature set by forward search has
better performance than using manually selected fea-
tures [10] and using all CHS features. Forward search
technique has successfully selected the most represen-
tative features in the stroke risk prediction problem.
Moreover, we also tried the feature set obtained by
forward search beginning with Lumley’s features [10].
The result is slightly lower than pure forward search.
Feature aggregation combined with the 132 selected
features yields similar performance as well.

The various methods of data imputation were com-
bined with the SVM model for verifying the impor-
tance of good data imputation. The list of data im-
putation methods, and their results are listed in Table
2. We found that the diﬀerent methods of data impu-
tation did not aﬀect the outcome of the model signif-
icantly. Furthermore, the RMSD values obtained for
the various data imputation methods were not exactly
correlated to the stroke prediction outcome. Instead,
we found that the data imputation models that gave us
the lowest RMSD values such as linear regression and
linear regression with discretization produced worse re-
sults for area under the ROC curve than simple impu-
tation methods such as discretized column mean and
column median. The reason for this may be the fact
that the initial feature selection algorithm was run us-
ing data that used column mean as the method for
data imputation.

4.1. Missing Data Imputation Quality

4.4. Cox Proportional Hazards Model

The missing data imputation results with baseline
methods and our proposed algorithms are shown in
Table 1, 5 and 6 respectively.
In general, linear re-
gression achieves the least RMSD and MAD values
with reasonable bias and PV values, and alignment
to discrete values further lowers the MAD value but
increases RMSD and Bias values.

4.2. Feature Selection and Feature
Aggregation Results

Using forward search and 5-fold cross validation with
linear kernel SVM, the area under ROC curve achieves
the largest value 0.759 when 132 features are selected.
The properties of the 13 aggregated features are sum-
marized in Table 7.

4.3. Stroke Prediction Precision with SVM

The average performance of stroke prediction models
with SVM and diﬀerent feature sets is shown in Ta-

We implemented the Cox proportional hazards regres-
sion model using the same set of features as described
in [10], and found the coeﬃcients by ﬁtting the data
using Matlab in a similar fashion as described in the
paper. However, we were not able to obtain the same
coeﬃcients as described in the paper, and found that
the area under the ROC curve was only 0.7021 using
the features given in the paper, and 0.7064 using the
132 features found using forward search.

Furthermore, to try to emulate the [10], we followed
the method for processing the data exactly as de-
scribed in the paper and tried to use the same co-
eﬃcients for the generated data, and found a an area
under the ROC curve of 0.5681. This was very low as
compared to the reported area of 0.73 in the paper.
We were not able to verify this value despite follow-
ing through the details provided in the paper multiple
times. Also, we requested Professor Lumley for his
data set to be able to verify his result but we have not

A Machine Learning Approach to Stroke Risk Prediction

heard back from him for the last 5 weeks.

4.5. SVM combined with the Cox Model

The results of the model combined for two years is
given in Table 6. The results from using data for mul-
tiple years proved to be the best as we managed to
achieve area under the ROC curve values close to 0.73.
The area under the ROC curve was averaged over 10
independent training and test data sets. This model
was only tried for data from two years due to the lack
of time and is possibly a promising direction to achieve
better overall results by combining the data in this way
for more years.

5. CONCLUSIONS

This pro ject has shown that machine learning algo-
rithms can be a powerful tool to achieve good results
even in diﬃcult data sets like the one presented in
this paper. We managed to match the values achieved
by hand selected features through automatic feature
selection. Furthermore, we found that the machine
learning tools provide a strong mechanism to handle a
variety of tasks involving both imputation of missing
data and stroke classiﬁcation.

6. FUTURE WORK

Due to the shortage of time, we were unable to im-
plement some of the suggestions that were brought up
during the course of the pro ject. We would like to
suggest these as possible directions for future work.
Firstly, for data imputation, an ensemble of methods
could be tried that encompass various machine learn-
ing methods that are selected from a variety of meth-
ods such as SVM, linear regression, logistic regression,
EM based methods, etc. Each of the methods could be
tested for each feature, and depending on the results,
we could use the best method found for each of the
features.

Furthermore, upon looking more closely at the data,
we found that the data contained values for certain
features that could lead to poor classiﬁcation as well
as data imputation. For some of the features that
were ’Yes/No’ questions, these answers were assigned
a value of 1/0, but sometimes there was another value
’Unknown’ which was written in the data as 9. Re-
moving these values and applying better data imputa-
tion techniques could lead to an overall increase in the
stroke prediction quality although the initial tests did
not suggest that data imputation improved prediction
scores.

Secondly, for stroke prediction, we could try increas-
ing the number of years considered for the Cox-SVM
model to potentially increase the prediction score.
Also, we could attempt using other methods for ex-
ploiting the time series property of the data which was
not completely used in our current pro ject. This time-
series property could also be used to improve data im-
putation, but this problem is a diﬃcult one given the
nature of the data. The features in the data vary from
year to year and even the same features do not have
the same names. Thus, it would be a cumbersome
task to ﬁnd commonality between features from mul-
tiple years.

ACKNOWLEDGEMENTS

We thank Honglak Lee for his guidance and support
throughout the pro ject. He provided us with direction
and various useful tools to carry out the data analysis
that we needed. Also, we thank Professor Ng for giving
us an opportunity to work on such interesting topics
by oﬀering this class and for his invaluable teachings
throughout the quarter. Lastly, we thank Anand Iyer
for partaking in discussions about the pro ject during
its inception.

References

[1] J. M. Engels and P. Diehr. Imputation of miss-
ing longitudinal data: a comparison of methods.
Journal of Clinical Epidemiology, 56(10):968 976,
2003.
[2] Klein J. and Moeschberger M. Survival Analy-
sis: Techniques for Censored and Truncated Data.
Springer, 2003.
[3] J.C. Sanchez J. Prados, A. Kalousis. Mining
mass spectra for diagnosis and biomarker discov-
ery of cerebral accidents. Proteomics, 4:2320–
2332, 2004.
[4] E. J. Candes J.F. Cai and Z. Shen. A singular
value thresholding algorithm for matrix comple-
tion. arXiv, 2008.
[5] Satoshi Saitoh Kenji Ikeda, Hiromitsu Kumada.
Eﬀect of repeated transcatheter arterial emboliza-
tion on the survival time in patients with hepato-
cellular carcinoma. Cancer, 2006.
[6] Tsuyoshi Nakamura Kouhei Akazawa. Simulation
program for estimating statistical power of cox’s
proportional hazards model assuming no speciﬁc
distribution for the survival time. Elseview Ire-
land, 1991.
[7] Steven G. Self Kung-Yee Liang and Xinhua Liu.
The cox proportional hazards model with change
point: An epidemiologic application. Biometrics,

A Machine Learning Approach to Stroke Risk Prediction

46:783–793, 1990.
[8] P. Enright L.P. Fried, N.O. Borhani. The cardio-
vascular health study: design and rationale. Ann
Epidemiol, 1(3):263–276, 1991.
[9] Thomas Augustin Ralf Bender and Maria Blet-
tner. Generating survival times to simulate
cox proportional hazards models. Statistics in
Medicine, 24:1713–1723, 2005.
[10] R. A. Kronmal T. Lumley. A stroke prediction
score in the elderly: validation and web-based
application.
Journal of Clinical Epidemiology,
55(2):129–136, 2002.

Model
Cox model(year 1 with feature selection)
Cox model(year 2 without feature selec-
tion)
Cox-SVM model on above data sets
Cox-SVM model with feature selection for
both years

AUC ROCˆ
0.7064
0.6403

0.7240
0.7296

Table 4. Cox proportional hazards model with SVM

Column Mean
Avg.
Max.
0.2259
Training RMSD 0.4997
Test RMSD
0.5002
0.2265
0.1631
0.4994
Training MAD
0.1641
0.4999
Test MAD
0
0.0008
Training Bias
-0.0005
0.0406
Test Bias
Training PV
0.2311
0.0084
0.0002
0.0116
Test PV

Min.
0.04
0.0033
0.0061
0.0033
-0.0013
-0.0454
0
0

Column Median
Avg.
Max.
0.2479
0.695
0.705
0.2487
0.1302
0.483
0.1317
0.497
0.0399
0.471
0.0394
0.4851
0.0814
0.0054
0.0229
1

Min.
0.0406
0
0.003
0
-0.483
-0.497
0
0

Hot Deck
Max.
0.7022
0.7069
0.4975
0.5025
0.0135
0.042
1.172
7460

Avg.
0.3152
0.3158
0.1838
0.1854
0
-0.0009
0.9445
57.5

Min.
0.0548
0.0004
0.0061
0.0001
-0.0128
-0.0599
0.3375
0.2761

Table 1. Data imputation quality with baseline methods

Algorithm
Hot deck
Column mean
Column mean discretized
Column media
Linear regression
Linear regression discretized
SVD

AUC ROCˆ
0.7165
0.7113
0.7199
0.7188
0.7141
0.7159
0.6995

Table 2. Stroke prediction quality for a variety of data im-
putation methods.

Training Accu-
racy
Testing Accu-
racy
AUC ROCˆ

All
(800)*
0.5593

Lumley’s [10] Forward
search
0.5707

0.5701

Forward search begin
with Lumley’s [10]
0.5598

Forward search with ag-
gregated features
0.5717

0.5465

0.5696

0.5635

0.5557

0.6478 0.6306

0.6998

0.6887

0.5673

0.6986

Table 3. Results of stroke prediction models with SVM us-
ing diﬀerent feature sets
*The number in parenthesis is the size of feature set.
ˆAUC ROC: area under ROC curve

A Machine Learning Approach to Stroke Risk Prediction

Column Mean and Align-
ment
Max.
Training RMSD 0.695
0.705
Test RMSD
Training MAD
0.483
0.497
Test MAD
0.471
Training Bias
0.4851
Test Bias
Training PV
0.152
1
Test PV

Avg.
0.2443
0.2449
0.1342
0.1355
0.0298
0.0293
0.0054
0.0224

Min.
0.04
0
0.003
0
-0.483
-0.497
0
0

Linear Regression

Max.
0.3752
0.6998
0.317
0.4395
0.0191
0.0598
1
5.08

Avg.
0.1289
0.1762
0.0926
0.1212
-0.0001
-0.0009
0.5866
0.0541

Min.
0
0
2.21E-07
2.93E-07
-0.0188
-0.0837
0.1895
0.0001

Linear Regression and
Alignment
Max.
0.4333
0.5843
0.2552
0.3414
0.1076
0.1222
1.0177
1.7028

Avg.
0.1354
0.1758
0.0571
0.0836
0.0061
0.0051
0.6432
0.6571

Min.
0
0
0
0
-0.1273
-0.1689
0
0.0001

Table 5. Data imputation quality with non-baseline algo-
rithms

Fill-In with SVD
Avg.
Max.
Training RMSD 7.0258
1.4448
1.4334
6.8523
Test RMSD
1.0635
5.2127
Training MAD
1.0518
5.2009
Test MAD
Training Bias
0.1342
-0.0005
0.005
0.278
Test Bias
41.398
198.543
Training PV
Test PV
2.43E+05
2995

Min.
0
0
0
0
-0.1432
-0.3097
1
0.9993

Fill-In with SVT
Avg.
Max.
0.9984
0.4229
0.4223
1
0.3181
0.9967
0.3176
1
0.9967
0.3181
0.3176
1
0
0
0
0

Min.
0.0541
0
0.003
0
0.003
0
0
0

Table 6. Data imputation quality with other non-baseline
algorithms

1
3
5
7
9
11
13

Ability to walk without diﬃculty
Recent exercise or physical work
General trend of mood
Awareness of time and venue
Ability to spell simple words
Perform simple tasks with hands
Frequency of eating various beans

Table 7. Properties of aggregated features

2
4
6
8
10
12

Optimistic or pessimistic
Diﬀerence in physical stamina
Sleep problems
Simple mathematical ability
Ability to repeat words
Frequency of taking fruits/fruit juices

