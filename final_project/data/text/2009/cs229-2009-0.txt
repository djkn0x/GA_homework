A Framework for Stock Prediction

Hung Pham, Andrew Chien, Youngwhan Lim

December 11, 2009

1

Introduction

1.1 Motivation

Stock price prediction is a classic and important prob-
lem. With a successful model for stock prediction, we
can gain insight about market behavior over time,
spotting trends that would otherwise not have been
noticed. With the increasingly computational power
of the computer, machine learning will be an eﬃcient
method to solve this problem. However, the public
stock dataset is too limited for many machine learn-
ing algorithms to work with, while asking for more
features may cost thousands of dollars everyday.
In this paper, we will introduce a framework in
which we integrate user predictions into the cur-
rent machine learning algorithm using public his-
torical data to improve our results. The motivated
idea is that, if we know all information about todays
stock trading (of all speciﬁc traders), the price is pre-
dictable. Thus, if we can obtain just a partial informa-
tion, we can expect to improve the current prediction
lot.
With the growth of the Internet, social networks,
and online social interactions, getting daily user pre-
dictions is feasible job1 . Thus, our motivation is to
design a public service incorporating historical data
and users predictions to make a stronger model that
will beneﬁt everyone.

1.2 Framework description

In addition to using historical data, our framework
also uses daily predictions made by users of the stock
market. The framework will build two mechanisms,

1Certainly, it may take time to build such a system. The
hard part is obtaining “serious predictions” instead of random
predictions from users.

one which learns from historical data, and the other
which learns from the user data, then combine these
mechanisms into a single prediction. In particular, the
framework needs to maintain the following natural
requirements:

1. It must provide predictions on a daily basis and
return this prediction to the users.

2. It must have comparable performance as the best
users.

3. It must be stable. In particular, there is no dic-
tator or a group of dictators.

From a high-level viewpoint, the framework will com-
bine an ob jective prediction (from historical data)
and sub jective prediction (from user predictions).
The ﬁrst requirement means that the framework must
employ online and adaptive algorithms and run as
fast as possible to respond to a large-scale market.
The second requirement means that the best users
should not perform better than the algorithm, which
uses data from these users. The last requirement
means that the predictions are consistent over time
even more information is discovered. On the other
hand, it implies that there is no group of users who
can decide the prediction of the whole framework
(who we call “dictators”), or otherwise, the frame-
work will become unstable as users’ predictions are
not stable at all. Thus, we have to control how much
we want to reply on ob jective predictions and sub-
jective predictions, so that the overall predictions are
good, but not too sub jective.
In the next section, we will describe in details our
framework that can satisfy those three requirements.

1

2 Prediction using historical
stock information

2.1 The dataset
To make predictions, we use standard OHLCV (open,
high, low, close, and volume) data that can be down-
loaded from ﬁnancial websites2 . We focus primarily
on technology companies (Google, Yahoo, Microsoft,
etc) to test our model.

2.2 Problem description
We formall formulate the stock prediction problem as
follows:

Given n + 1 feature vectors x1 , x2 , . . . , xn+1
and observed labels y1 , . . . , yn for the ﬁrst n
days, predict the label yn+1 for day n + 1.
In our particular formulation, xi ∈ Rk are the fea-
tures on day i, and yi is the actual price, making this
a regression problem.

2.3 Ob jective function
Since we are basing our predictions oﬀ a feature
vector, linear regression is a reasonable method to
(cid:0)θT xi − yi
(cid:1)2 , and makes the prediction
regret (cid:80)n
solve this problem. Using the standard linear regres-
sion method, we ﬁnd a vector θ that minimizes the
i=1
yn+1 = θT xn+1 . However, this algorithm does not
capture the temporal correlation inside the data (for
example, stock behavior one year ago is diﬀerent from
stock behavior now). Thus, we do not expect this al-
gorithm to turn out well in practice, and empirical ev-
idence conﬁrms this. Nevertheless, we can still apply
the idea of empirical risk minimization while trying
to capture the temporal correlation.
We modify the linear regression model by allowing
the vector θ to change with time. We introduce the
n(cid:88)
n(cid:88)
following ob jective function
i=2
i=1

α−i (cid:96)(θi , xi , yi ) + β

Fn =

α−i s(θi , θi−1 ).

Here, α is the discount factor representing how cur-
rent data relates to past data, (cid:96) is the loss function,

2For example, as http://www.nasdaq.com.

2

and s(c, d) is a distance measure between c and d. In
this paper, we will consider3 (cid:96)(θ , x, y) = (θT x − y)2
and s(c, d) = (cid:107)c − d(cid:107)2 . The function s is introduced
to gain stability by making θi slowly change. Next,
we will apply this idea for both regression and classi-
ﬁcation models.

2.4 The classiﬁcation model
Often, we care less about the actual price than we
do about the change in the price from one day to
the next. The algorithm above describes a regres-
sion problem, but we can perform classiﬁcation by
comparing tomorrow’s predicted value with today’s
price.4

2.4.1 Deep Correlation Algorithm

In order to make a prediction, we minimize the ob jec-
tive function with some θ1 , . . . , θn . This allows us to
make the prediciton yn+1 = θT
n xn . To solve this opti-
mization function, we introduce a method we call the
Deep Correlation (DC) Algorithm.
Experimentally, gradient descent performs too
poorly to optimize the ob jective function due to slow
convergence. Instead, the following algorithm (Deep
Correlation) uses coordinate descent to solve the op-
timization problem much more quickly.

Choose parameters α and β .
Choose d, the depth of correlation in the data.
α + β .
Set λ = β
Repeat until convergence:
For each i from n down to n − d + 1:
α xi+1 + βxi−1 + xi yi .
Set z = β
Set θi = (M −1 )T z , M = xixT
i + λIk .
Set θn+1 = θn .
Output (θ1 , θ2 , · · · , θn+1 ).
The above update rule follows by setting partial
derivatives to be zero

i θi + (β + αβ )θi = β θi+1 + αβ θi−1 + αxi yi .
αxixT
3This assumes a linear correlation between x and y . We can
certainly make polynomial extension on the dataset to intro-
duce more complicated correlation.
4We expect regression methods to work better than classi-
ﬁcation, because by changing all actual prices to 0-1 labels, we
lose too much information. Since any regression algorithm can
be converted into a classiﬁcation algorithm, it’s ﬁne to only
consider regression.

In practice, the DC algorithm is incredibly fast. It
takes no more than one second before converging if
we set d = 50 and initialize θ from previous results.
This satisﬁes the ﬁrst requirement of our framework.
Moreover, after each update all θi , 1 ≤ i ≤ n fully
satisfy the identity θT
i xi = yi . So, the movement of
θi does somehow represent the movement and corre-
lation of the data.

Stock
GOOG
YHOO
MSFT
AAPL
AMZN
BIDU

Decidable Days
64.47%
63.83%
48.17%
72.67%
68.50%
79.80%

Lin. Ext Quad. Ext
71.17% 72.21%
62.40% 65.01%
51.21% 51.21%
65.37% 65.60%
66.42% 67.25%
63.66% 66.42%

Figure 2. DC algorithm on 600 2-days blocks, threshold 1%

2.4.2 Testing results

In testing mode, we introduce a threshold constant
and the concept of “decidable day”. A decidable day
is a day whose price changes signiﬁcantly compared
previous day’s price. For example, if we set a thresh-
old of 1%, the decidable days are the ones where the
price changes by at least 1% compared to the previ-
ous day’s price. Although a good algorithm5 should
perform well on all days, the analysis of algorithms on
only decidable days is also meaningful, because these
are the days wehre being correct is more important.
We also preprocess the data by dividing it into dis-
crete blocks of multiple days. The price of a block of
days is the average price on those days. Thus, we aim
for a long-term prediction, which is more important
than a short-term one.
The following table shows the result of some basic
learning algorithms. In our experiments, dividing the
data into blocks does not improve these results by
very much.

Stock
GOOG
YHOO
MSFT
AAPL
BIDU

Decidable Days
51.00%
52.25%
30.00%
61.75%
71.63%

Lin. Reg.
50.37%
53.17%
46.44%
49.29%
51.40%

Log. Reg.
43.87%
53.39%
50.42%
55.87%
50.44%

Figure 1. Classical methods on 800 single days, threshold
1%

The DC algorithm does not work any better than
these algorithms with single-day prediction. However,
when dividing data into block, we see an incredible
improvement.

5Empirically, any algorithm consistently getting > 50% cor-
rectness can be considered good.

Stock
GOOG
YHOO
MSFT
AAPL
AMZN
BIDU

Decidable Days
80.00%
75.00%
62.67%
81.30%
81.00%
86.40%

Lin. Ext Quad. Ext
84.58% 82.50%
65.33% 67.11%
52.13% 53.19%
81.97% 81.15%
80.66% 79.84%
78.24% 79.19%

Figure 3. DC algorithm on 300 4-days blocks, threshold 1%

The DC algorithm performs well with many stock in-
dexes, reaching nearly 80% when analyzing 4-days
blocks with Google, Apple, Amazon, and Baidu.
In contrast, it still performs poorly with Microsoft.
Looking at the data, this is because Microsoft’s stock
price very stable. Finally, note that using quadratic
expansion slightly improves linear expansion, espe-
cially with data where we have lower success rates.

2.5 The regression model
Although the classiﬁcaiton model we use is based oﬀ
the regression model, the success of DC in the clas-
siﬁcation model does not carry over to the regres-
sion model, and DC performs about as well as other
methods (such as linear regression) for performing ac-
tual stock price. This is because stock prices tend to
change very little on a daily basis, so even the sim-
plest algorithms (assuming the price does not change)
can reach 97% to 99% correctness. In this section, we
will introduce a more general version of the DC algo-
rithm that outperforms linear regression in the long
term.

2.5.1 Generalized DC algorithm
In the DC algorithm, we assume that yi ∼ N (µi , σ),
where µi = θT
i xi . Although the DC algorithm cap-
tures temporal correlation, it assumes a strong rela-
tion: the price of a day is a linear function of the
feature on that day. Even when we use a quadratic

3

xT
j θjMij

λi (θi − θi−1 )2 .

expansion, the results are not improved signiﬁcantly.
µi = (cid:80)n
In the general model, we modify this assumption
to a more reasonable one: yi ∼ N (µi , σi ), where
j θjMij and σi is some determined by
j=1 xT
some ﬁxed function of our choice.
Under this model, the price of a day depends on all
observered data (in contrast, under the standard DC
algorithm the price of each day is determined by the
features of that day). A reasonable choice for Mij is
Mij = αi−j if i ≥ j and Mij = β j−i if j > i, i.e. α and
β are respectively the backward and forward correla-
tion factor. By maximizing the log-likelihood func-
tion and adding the stability requirement, we want
2
yi − n(cid:88)
to minimize the following ob jective function:
n(cid:88)
n(cid:88)
i=2
j=1
i=1
As before, we ﬁnd the gradient descent does not work
well for this algorithm, while coordinate descent does.
After some math, we get the update rules for this
coordinate descent.
Let N be a matrix such that Nij = Mij
. Let δij = 1 if
σi
i = j and 0 otherwise. Let S = N T N , and let D be a
matrix such that Dij = (1 − δij )Sij , then we update
Rj := (cid:0)λj Ik + λj+1 Ik + xj xT
(cid:1)
Cj := λj θT
j−1 + λj+1 θT
j+1
(cid:32)
(cid:33)
n−1(cid:88)
j − n(cid:88)
j Sj j
yi
Cj +
p xpxT
Dpj θT
Nij xT
j
σi
p=1
i=1
It is not hard to see that this model generalizes DC,
linear regression, and weighted linear regression with
appropriate choices of α, β , σ and λ. In contrast, lin-
ear regression can be considered as a greedy version
of both DC algorithm and generalized DC algorithm
when the θs are ﬁxed.

R−1
j

.

1
σ2
i

+

θj :=

2.5.2 Testing results

We test our algorithm with Google, using diﬀerent
α and β and compare to the standard linear regres-
sion method. We choose σi = (n − i)2 to allow more
variances on past data. The evaluation is based on
the average linear absolute error made by each algo-
rithm. To predict the price in the next d days, we
simply shift the features back d days.

4

Method
Tomorrow
3 days
7 days
14 days
1 months

Lin. Reg. Gen. DC 1 Gen. DC 2
7.037
7.412
11.021
16.003
13.505
13.778
25.840
22.076
24.762
37.474
33.862
43.654
98.269
67.779
54.406

Figure 4. Error of long-term predictions on 150 days
with Google6

The above table suggests that Generalized DC is not
better than linear regression (actually worse) when
predicting tomorrow price. However, Generalized DC
performs much better in long-term predictions, even
when linear regression does poorly. Experiments sug-
gest that quadratic expansion does not help General-
ized DC perform better at all.

3 Prediction using user feed-
backs

This section will present a method of predicting based
on user’s prediction so that it can satisfy requirement
2: the prediction should be relatively good compared
to the best users. Although regression is more desir-
able, we have to restrict our framework to classiﬁca-
tion only due to time constraint. The algorithm to
be presented is proved to be good (in the worst case)
without any assumption about the dataset, thus we
can expect that it may performed better eventually
when the real dataset is ﬁt in.

3.1 Problem Description

Assume that we have a group of n people. On day i,
each person j makes a prediction pij ∈ {1, 0} indicat-
ing whether the stock is up or down. We have to make
prediction each day before the actual price is released at
the end of the day. How to make predictions each day?
This is a typical example for boosting algorithm. We
will apply the Weight Ma jority algorithm. Adaboost
is under our consideration, but we won’t really em-
ploy it until a real user dataset is obtained.

6The Generalized DC 1 & 2 correspond to diﬀerent choice
of α, β : (0.95, 0.01) and (0.8, 0.01)

3.2 The Weighted Ma jority algorithm
Weighted Ma jority (WM) works by assigning weights
for each user wj . On day i, the prediction is made
P0 = (cid:88)
wj ; P1 = (cid:88)
comparing P0 , P1 , in which
j :pij =1
j :pij =0
At the end of the day, if person j predicts wrongly,
we will update his weight: wj = wj
c ; otherwise, the
weight is kept the same. It is shown that, if mi is the
total number of mistakes made by user i, and m =
mini mi , then the total number of mistakes made by
the WM algorithm is no more than

wj .

log n + m log 1
c
log 2
1+c

.

Most importantly, this upper bound is true on daily
basis with any dataset. Therefore, we can make sure
that the requirement 2 is always satisﬁed: the predic-
tion is as good as the best user’s prediction up to a
constant factor.

3.3 Test with sampled datasets
Although it is not a convincing evidence about the
performance of WM algorithm in practice, we want
to at least see how it works under some reasonable
sampled dataset. Because we do not have any ac-
tual datasets of user data, we generated our own
data sets from the actual prices. We created a data
set such that predictions are never more than 62.4%
correctness and the average correctness is ∼ 50%,
then the result made by WM algorithm is roughly
57.5% − 65.6%.

4 Combine predictions

The previous sections present two methods of predic-
tions: ob jective prediction by learning historical stock
features, and sub jective prediction by learning user
predictions. Both methods are online and adaptive,
thus satisfy requirement 1. However, requirement 3
is not always satisﬁed with sub jective prediction, as
the WM algorithm will give the best users very high
weight and making them into dictators. This section
will introduce how those methods can be combined

together to satisfy the third requirement. Again, we
restrict our model to the classiﬁcation problem only.
The natural idea is to ﬁnd the probabilities p1 , p2
for the classiﬁcations made by the two algorithms,
and base our ﬁnal prediction on cp1 + (1 − c)p2 for
some constant c of our choice (or we can learn it).
The probability obtained by the WM algorithm can
. The hard part is to ﬁnd
be assumed to be
P0
P0+P1
a probability by Generalized DC. Notice that in the
Generalized DC algorithm, we assume yi ∼ N (µi , σi ).
Thus, when yn−1 is observed, the probability that
(cid:18) −1
(cid:19)
(cid:90) yn−1
yn < yn−1 is given by
1(cid:112)2πσ2
2σ2
−∞
i
i
Unfortunately, this integral has no closed form. In-
(cid:19)(cid:19)
(cid:18) x − µi
(cid:18)
stead, it is represented as as
√
2
σi
Here erf, the error function, is an odd function and
(cid:115)
(cid:19)
(cid:18) −(ax2 + b)x2
approximated by
erf(x) ∼ ±
1 + x2

(x − µi )2

f (yn−1 ) =

1 − exp

exp

.

1
2

1 + erf

.

where

.

a =

8(π − 3)
4
3(4 − π) , b =
π
This last formulation explicitly show how the proba-
bility the price goes down is computed. Consequently,
the combined probability can be computed easily.
Moreover, if we choose c greater than 0.5 so that
ob jective prediction contributes mainly to the ﬁnal
prediction, we can assure that there is no dictator in
the framework.

5 Conclusion

This paper proposes a relatively good framework for
stock prediction which can satisfy three natural re-
quirements (with any dataset). However, this may not
be the best framework in practice. Such a better one
should be built when a real dataset is obtained. Nev-
ertheless, the most important idea of the paper is to

5

lecting and analysing historical stock data, detailed
explanation on the structure of the stock market and
suggestion on designing the platform since the last
summer. We also thank Prof. Ng and Quoc Le for
their help on machine learning methods and the mo-
tivation of the temporal correlation.

References

[1] Roger Lowenstein, Eﬃcient Market Hypothesis,
Wikipedia.org

[2] Nick Littlestone, Manfred K. Warmuth, The
weighted majority algorithm,
Information and
Computation, Volume 108, issue 2, 1994.

connect classical (ob jective) machine learning algo-
rithms to (sub jective) user feedbacks to learn com-
plicated social structures. In the time being, no ma-
chine can really get the intelligence level of the hu-
man; therefore it is better to ask the human to learn
about them and their game (unless there are ma-
chines who are more intelligent than them and can
simulate them).
In the context of stock prediction, we believe that
the lack of data is the ma jor issue, while machine
learners do not spend too much eﬀort on this sub ject.
Hedge funds and other trading cooporations should
have much better datasets, but they never want to
disclose it in fear that it will aﬀect their business. In
contrast, user predictions may be the best dataset for
stock prediction, and if it is publicly distributed, it
may encourage machine learners to attack this prob-
lem more in depth.

6 Future works

Following are a list of works that we intend to do.
1. Obtain the real user predictions. Hung has de-
signed an online system for that purpose (see
http://www.stocknet.us).

2. Make a better mechanism to combine two meth-
ods together. For example,
if the prediction
based on historical data suggests the price goes
up, but user mechanism suggests that it goes
down, should we make update on θ or the weights
of users before announcing the ﬁnal prediction?
In the proposed framework, two methods do not
really interact with each other before ﬁnal pre-
dictions.

3. Develop a regression model for user mechanism.

4. Develope a better regression model for historical
data prediction. Generalized DC is not totally
satisﬁable.

7 Acknowledgment

We would like to thank Prof. Nguyen Dinh Tho7 and
Ms. Ha Viet Phuong for their dedicated job of col-

7He is currently the Director of Financial Department, For-
eign Trade University, Vietnam

6

