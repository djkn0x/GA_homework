Optimizing Multi-class Spatio-Spectral Filters via
Bayes Error Estimation for EEG Classiﬁcation

Wenming Zheng
Research Center for Learning Science
Southeast University
Nanjing, Jiangsu 210096, P.R. China
wenming zheng@seu.edu.cn

Zhouchen Lin
Microsoft Research Asia
Beijing 100190, P.R. China
zhoulin@microsoft.com

Abstract

The method of common spatio-spectral patterns (CSSPs) is an extension of com-
mon spatial patterns (CSPs) by utilizing the technique of delay embedding to al-
leviate the adverse effects of noises and artifacts on the electroencephalogram
(EEG) classiﬁcation. Although the CSSPs method has shown to be more power-
ful than the CSPs method in the EEG classiﬁcation, this method is only suitable for
two-class EEG classiﬁcation problems. In this paper, we generalize the two-class
CSSPs method to multi-class cases. To this end, we ﬁrst develop a novel theory of
multi-class Bayes error estimation and then present the multi-class CSSPs (MC-
SSPs) method based on this Bayes error theoretical framework. By minimizing the
estimated closed-form Bayes error, we obtain the optimal spatio-spectral ﬁlters of
MCSSPs. To demonstrate the effectiveness of the proposed method, we conduct
extensive experiments on the BCI competition 2005 data set. The experimental
results show that our method signiﬁcantly outperforms the previous multi-class
CSPs (MCSPs) methods in the EEG classiﬁcation.

1 Introduction

The development of non-invasive brain computer interface (BCI) using the electroencephalogram
(EEG) signal has become a very hot research topic in the BCI community [1]. During the last sev-
eral years, a large number of signal processing and machine learning methods have been proposed
for EEG classiﬁcation [6]. It is challenging to extract the discriminant features from the EEG signal
for EEG classi ﬁcation. This is because in most cases the EEG data are centered at zero and thus
many traditional discriminant feature extraction methods, e.g., Fisher’s linear discriminant analysis
(FLDA) [7], cannot be successfully used. Among the various EEG feature extraction methods, the
common spatial patterns (CSPs) method [2] is one of the most popular. Given two classes of EEG
signal, the basic idea of CSPs is to ﬁnd some projection directions such that the projections of the
EEG signal onto these directions will maximize the variance of one class and simultaneously mini-
mize the variance of the other class. Although CSPs have achieved great success in EEG classiﬁca-
tion, this method only utilizes the spatial information of the EEG signal. To utilize both the spatial
and the temporal information of the EEG signal for classiﬁcation, Lemm et al. [3] proposed a new
EEG feature extraction method, called common spatio-spectral patterns (CSSPs), which extended
the CSPs method by concatenating the original EEG data and a time-delayed one to form a longer
vector sample, and then performed EEG feature extraction, which is similar to the CSPs method,
from these padded samples. The experiments in [3] showed that the CSSPs method outperforms the
CSPs method.

A multi-class extension of the two-class CSPs method (MCSPs) was proposed by Dornhege et al.
[4] who adopted a joint approximate diagonalization (JAD) technique to ﬁnd the optimal spatial
ﬁlters. Grosse-Wentrup and Buss [5] recently pointed out that the MCSPs method has two major

1

drawbacks. The ﬁrst drawback is that this method lacks solid theoretical foundation with respect to
its classi ﬁcation error. The second one is that the selection of the optimal spatial ﬁlters of MCSPs
is based on heuristics. To overcome these drawbacks, they proposed a method based on mutual
information to select the optimal spatial ﬁlters from the original MCSPs result. Nevertheless, it
should be noted that both the MCSPs methods are based on the JAD technique, where a closed-form
solution is unavailable, making the theoretical analysis difﬁcult.

In this paper, we generalize the two-class CSSPs method to multi-class cases, hereafter called the
MCSSPs method. However, we do not adopt the same JAD technique used in the MCSPs method
to derive our MCSSPs method. Instead, we derive our MCSSPs method directly based on the Bayes
error estimation, and thus provide a solid theoretic foundation. To this end, we ﬁrst develop a novel
theory of multi-class Bayes error estimation, which has a closed-form solution to ﬁnd the optimal
discriminant vectors. Based on this new theoretic framework, we propose our MCSSPs method for
EEG feature extraction and recognition.

2 Brief Review of CSPs and CSSPs
i = {xt
i,j ∈ IRd |j = 1, · · · , mi,t } (t = 1, · · · , ni ; i = 1, · · · , c) denote the EEG data set from
Let Xt
the tth trial of the ith class, where d, c, ni , and mi,t denote the number of channels (i.e., recording
electrodes), the number of classes, the number of trials of the ith class, and the number of samples
(i.e., recording points) in the tth trial of the ith class, respectively. Assume that the EEG data
conditioned on each class follows a Gaussian distribution with a zero mean, i.e., pi (x) = N (0, Σi )
(i = 1, · · · , c)1 . Then the main task of EEG feature extraction is to ﬁnd a linear transformation
W ∈ IRd×k (k < d), such that for ﬁnite training data using the projected vectors yt
i,j = WT xt
i,j to
classify the EEG signal may lead to better classiﬁcation accuracy than using xt
i,j .

2.1 The CSPs Method

For the two-class EEG classiﬁcation problem, the basic idea of CSPs is to ﬁnd a transformation
matrix W that simultaneously diagonalizes both class covariance matrices Σ1 and Σ2 [2], i.e.,
WT ΣiW = Λi , (i = 1, 2),
(1)
where Λi = diag{λi,1 , · · · , λi,d } (i = 1, 2) are diagonal matrices. The spatial ﬁlters can be chosen
(j = 1, · · · , d). Parra et
(cid:189)
(cid:190)
as the columns of W associated with the maximal or minimal ratio of λ1,j
λ2,j
al. [6] proved that the CSPs method can be formulated as the following optimization problem:
ωT Σ1ω
ωT Σ2ω
ω = arg max
ωT Σ2ω
ωT Σ1ω
ω
and this optimization problem boils down to solving the following generalized eigenvalue decom-
position problem:

max

(2)

,

,

Σ1ω = λΣ2ω .
(3)
Let ω1 , · · · , ωd and λ1 , · · · , λd be the eigenvectors and the corresponding eigenvalues of equation
(3), then the spatial ﬁlters ωi1 , · · · , ωik can be chosen from the eigenvectors ω1 , · · · , ωd associated
with the largest and the smallest eigenvalues.
Then W = [ωi1 , · · · , ωik ] and the projection of Xt
i with W can be expressed as:
i = WT Xt
Yt
i .

(4)

2.2 The CSSPs Method

The CSSPs method is an extension of CSPs by concatenating the original EEG data and a time-
delayed one to form a longer vector sample, and then performing EEG feature extraction, which
δ τ denote the
is similar to the CSPs method, from these padded samples. More speciﬁcally, let
time-delay operator with the delayed time τ , i.e.,
i,j ) = xt
δ τ (xt
i,j−τ .
1This model is often assumed in the literature, e.g., [5].

(5)

2

Then, equation (4) can be re-written as the following:
ˆYt
(τ ) δ τ (Xt
i = WT
i + WT
i ),
(0)Xt
(6)
where W(0) and W(τ ) are the transformation matrices on the EEG data Xt and δ τ (Xt ), respec-
(cid:181)
(cid:182)
tively.
To express the above equation in a similar form as CSPs, we de ﬁne
Xt
i
δ τ (Xt
i )
In this way, solving the CSSPs problem boils down to solving a similar generalized eigenvalue
ˆΣ1 and ˆΣ2 to
(cid:88)
problem as deﬁned in equation (3), if we use the new class covariance matrices
replace the original class covariance matrices Σ1 and Σ2 , where
˜Σi
trace( ˜Σi )
t

i ( ˆXt
ˆXt
i )T .

ˆXt
i =

˜Σi =

ˆΣi =

and

(7)

(8)

.

,

3 MCSSPs Based on Multi-class Bayes Error Estimation

In this section, we extend the CSSPs method to the multi-class case. To begin with, we develop a
novel theory of multi-class Bayes error estimation. Then we present our MCSSPs method based on
this Bayes error framework.

(9)

ε =

min(Pipi (x), Pj pj (x))dx,

3.1 Multi-class Bayes Error Estimation
(cid:90)
It is well known that the Bayes error regarding classes i and j can be expressed as [7]:
(cid:82) (cid:112)
where Pi and pi (x) are the apriori probability and the probability density function of the ith class,
respectively. Let εij =
PiPj pi (x)pj (x)dx. By applying the following inequality:
√
∀a, b ≥ 0,
min(a, b) ≤
(10)
ab,
(cid:33)− 1
(cid:33)
(cid:195)
(cid:195)
and the assumption pi (x) = N (0, Σi ), we obtain the following upper bound of the Bayes error:
(cid:112)
(cid:112)
(cid:112)|Σi ||Σj |
(cid:112)|Σi ||Σj |
| ¯Σij |
| ¯Σij |
2
− 1
ε ≤ εij =
=
PiPj exp
ln
(11)
PiPj
,
2
2 (Σi + Σj ). The expression in exp(·) is the simpliﬁed Bhattacharyya distance [7]. If
where ¯Σij = 1
(cid:33)− 1
(cid:195)
(cid:112)
we project the samples to 1D by a vector ω , then the upper bound εij becomes:
(cid:112)
ωT ¯Σij ω
2
εij =
(12)
.
PiPj
(ωT Σiω)(ωT Σj ω)
(cid:182)− 1
(cid:181)
(cid:182) 1
(cid:181)
(cid:181)
(cid:182)
(cid:179) v
(cid:179) v
(cid:180)2
(cid:180)2
4 ≤ (cid:112)
(cid:112)
(cid:112)
2 (Σi − Σj ). Then εij can be written as
Deﬁne u = ωT ¯Σij ω and v = ωT ∆Σij ω , where ∆Σij = 1
1 − 1
u√
1 −
2
=
εij =
PiPj
PiPj
PiPj
estimated as ε ≤ (cid:80)c−1
(cid:80)c
u2 − v2
4
u
u
(cid:33)
(cid:195)
For the c classes problem, the upper bound of the Bayes error in the reduced feature space can be
(cid:181)
(cid:182)2
ε ≤ c−1(cid:88)
c(cid:88)
εij ≤ c−1(cid:88)
c(cid:88)
(cid:112)
j=i+1 εij [8]. Then, from equation (13), we obtain that
i=1
ωT ∆Σij ω
1 − 1
(cid:181)
(cid:182)2
c(cid:88)
c−1(cid:88)
c(cid:88)
c(cid:88)
PiPj
(cid:112)
(cid:112)
ωT ¯Σij ω
4
i=1
j=i+1
i=1
j=i+1
PiPj − 1
PiPj
8
i=1
i=1
j=1
j=i+1

ωT (∆Σij )ω
ωT ¯Σij ω

(13)

(14)

=

.

.

3

(cid:179)

(cid:180)2

.

(15)

a+c
b+d

Let ¯Σ =

, ∀a, c ≥ 0; b, d > 0 to the
(cid:33)2

(cid:162)2 +
(cid:162)2 ≥
(cid:161)
(cid:161)
(cid:195) (cid:80)c
(cid:80)c
c
a
Recursively applying the following inequality
ε ≤ c−1(cid:88)
c(cid:88)
(cid:112)
d
b
(cid:80)c
(cid:80)c
error bound in equation (14), we have
4 |ωT ∆Σij ω |
j=1 (PiPj ) 5
PiPj − 1
(cid:80)c
i=1
j=1 PiPj ωT ¯Σij ω
8
i=1
c(cid:88)
c(cid:88)
c(cid:88)
c(cid:88)
i=1
j=i+1
i=1 PiΣi be the global covariance matrix. Then we have
1
PiPj ¯Σij =
PiPj (Σi + Σj ) = ¯Σ.
2
(cid:195) (cid:80)c
(cid:80)c
i=1
j=1
j=1
i=1
ε ≤ c−1(cid:88)
c(cid:88)
(cid:112)
Combining equations (15) and (16), we have
4 |ωT ∆Σij ω |
j=1 (PiPj ) 5
PiPj − 1
i=1
ωT ¯Σω
8
j=i+1
i=1
(cid:195)
(cid:33)2
(cid:80)c
(cid:80)c
Assume that the prior probabilities of the classes are the same, i.e., Pi = Pj = P , which holds for
c(cid:88)
ε ≤ c−1(cid:88)
most EEG experiments. Then equation (17) becomes
j=1 |ωT (Σi − Σj )ω |
5
P − 1
(cid:80)c
(cid:80)c
P
2
i=1
.
2ωT ¯Σω
8
(cid:175)(cid:175)(cid:175)(cid:175)(cid:175)(cid:175) = |ωT (Σi − ¯Σ)ω |.
(cid:175)(cid:175)(cid:175)(cid:175)(cid:175)(cid:175) c(cid:88)
j=i+1
i=1
c(cid:88)
On the other hand, from ¯Σ =
i=1 PiΣi =
i=1 P Σi , we obtain that
P ωT (Σi − Σj )ω
|ωT (Σi − Σj )ω | ≥
(cid:33)2
(cid:195)
(cid:80)c
i=1
j=1
c(cid:88)
ε ≤ c−1(cid:88)
Combining equations (19) and (18), we obtain that
i=1 |ωT (Σi − ¯Σ)ω |
3
P − 1
2
.
2ωT ¯Σω
8
j=i+1
i=1

(cid:33)2

(19)

(16)

(17)

(18)

(20)

P

P

.

.

J (ω) =

3.2 MCSSPs Based on Multi-class Bayes Error Estimation
Let ˆΣi (k = 1, · · · , c) denote the new class covariance matrices computed via equation (8). Then
(cid:80)c
to minimize the Bayes error, we should minimize its upper bound, which boils down to maximizing
the following discriminant criterion
i=1 |ωT ( ˆΣi − ˆ¯Σ)ω |
(21)
ωT ˆ¯Σω
(cid:80)c
where ˆ¯Σ is the global covariance matrix. Based on this criterion, we deﬁne the k optimal spatial
ﬁlters of MCSSPs as follows:
i=1 |ωT ( ˆΣi − ˆ¯Σ)ω |
(cid:80)c
ωT ˆ¯Σω
i=1 |ωT ( ˆΣi − ˆ¯Σ)ω |
ωT ˆ¯Σω

max
ωT ˆ¯Σωj = 0,
j = 1, · · · , k − 1
− 1
− 1
Let ˆˆΣi = ˆ¯Σ
2 (i = 1, · · · , c) and α = ˆ¯Σ
ˆ¯Σ
(cid:80)c
2 ˆΣi
ω . Then solving the optimization problem of
equation (22) is equivalent to solving the following optimization problem
i=1 |αT ( ˆˆΣi − I)α|
(cid:80)c
αT α
i=1 |αT ( ˆˆΣi − I)α|
αT α

α1 = arg max
α
· · ·

ω1 = arg max
ω
· · ·

αk = arg

ωk = arg

max
αT Uk−1 = 0

(22)

(23)

1
2

.

,

,

,

4

,

.

(24)

α1 = arg max
α
· · ·

where Uk−1 = [α1 , · · · , αk−1 ] and I is the identity matrix. Suppose that si ∈ {+1, −1} denotes
the positive or negative sign of αT ( ˆˆΣi − I)α. Then
|αT ( ˆΣi − I)α| = αT si ( ˆΣi − I)α.
αT (cid:80)c
So equation (23) can be expressed as
i=1 si ( ˆˆΣi − I)α
αT (cid:80)c
αT α
i=1 si ( ˆˆΣi − I)α
(cid:80)c
max
αk = arg
αT α
αT Uk−1 = 0
i=1 si ( ˆˆΣi − I), where s = [s1 , s2 , · · · , sc ]T and si ∈ {+1, −1}. Then the ﬁrst vector
Let T(s) =
α1 deﬁned in equation (25) is the principal eigenvector associated with the largest eigenvalue of the
matrix T(s). Suppose that we have obtained the ﬁrst k vectors α1 , · · · , αk . To solve the (k + 1)-th
vector αk+1 , we introduce Theorems 1 and 2 below. The similar proofs of both theorems can be
found in [9].
Theorem 1. Let QkRk be the QR decomposition of Uk . Then αk+1 de ﬁned in (25) is the principal
eigenvector corresponding to the largest eigenvalue of the following matrix
(Id − QkQT
k )T(s)(Id − QkQT
k ).
(cid:179)
(cid:180)
Theorem 2. Suppose that QkRk is the QR decomposition of Uk . Let Uk+1 = (Uk αk+1 ),
(cid:181)
(cid:182)
q = αk+1 − Qk (QT
k αk+1 ), and Qk+1 =
q(cid:107)q(cid:107)
Qk
. Then
Rk QT
k αk+1
(cid:107)q(cid:107)
0

Qk+1

(25)

is the QR decomposition of Uk+1 .
The above two theorems are crucial to design our fast algorithm for solving MCSSPs: Theorem 1
makes it possible to use the power method to solve MCSSPs, while Theorem 2 makes it possible to
k(cid:89)
update Qk+1 from Qk by adding a single column. Moreover, it is notable that
k−1 )(Id − qk qT
Id − QkQT
(Id − qiqT
i ) = (Id − Qk−1QT
k =
k ),
(26)
i=1
where qi is the i-th column of Qk . Equation (26) makes it possible to update the matrix (Id −
k )T(s)(Id − QkQT
k ) from (Id − Qk−1QT
k−1 )T(s)(Id − Qk−1QT
k−1 ) by the rank-one update
QkQT
technique.
Let S = {s|s ∈ {+1, −1}c} denote the parameter vector set, whose cardinality is 2c . Then we have
c(cid:88)
that
max
max
(cid:107)α(cid:107)=1
(cid:107)α(cid:107)=1
i=1
If c is not too large, a full search on S similar to that proposed in [9] is affordable. We present the
pseudo-code of our MCSSPs method using the full search on S in Algorithm 1. However, if c is a
bit large, we may adopt a similar approach as proposed in [10], which is based on a greedy search,
to ﬁnd the suboptimal solution. The pseudo-code based on the greedy search is given in Algorithm
2.

|αT ( ˆˆΣi − I)α| = max
s∈S

αT T(s)α.

(27)

4 EEG Feature Extraction Based on the MCSSPs

(cid:181)
(cid:182)
Let Xt
i be the EEG sample points from the tth trial under the ith condition (i.e., the ith class). Let ωj
Xt
be the j th optimal spatial ﬁlter of the MCSSPs method. Construct the new data ˆXt
i =
i
,
δ τ (Xt
i )
and let

(28)

ˆXt
i

ˆpt
i,j = ωT
j

5

= UΛ−1UT ;

Algorithm 1: The MCSSPs Algorithm Based on the Full Search Strategy
Input:• Input data matrix X and the class label vector l.
Initialization:
1. Compute the average covariance matrices ˆΣi (i = 1, · · · , c) and ˆ¯Σ;
− 1
−1
2 = UΛ− 1
2. Perform SVD of ˆ¯Σ: ˆ¯Σ = UΛUT , compute ˆ¯Σ
2 UT and ˆ¯Σ
− 1
− 1
2 and ∆ ˆˆΣi = ˆˆΣi − I (i = 1, · · · , c);
3. Compute ˆˆΣi = ˆ¯Σ
ˆ¯Σ
2 ˆΣi
4. Enumerate all the elements of S and denote them by S = {s1 , s2 , · · · , s2c };
For i = 1, 2, · · · , k , Do
1. For j =1 to 2c
• Compute T(si );
• Solve the principal eigenvector of T(si )α(j ) = λ(j )α(j ) via the power iteration
method;
2. Select the eigenvector α with the largest eigenvalue maxj=1,···,2c {λ(j ) };
3. If i = 1, then qi ← α, qi ← qi /(cid:107)qi (cid:107), and Q1 ← qi ;
i−1α), qi ← qi /(cid:107)qi (cid:107), and Qi ← (Qi−1 qi );
else qi ← α − Qi−1 (QT
i ∆ ˆˆΣpqi )qT
4. Compute ∆ ˆˆΣp ← ∆ ˆˆΣp − (∆ ˆˆΣpqi )qT
i ∆ ˆˆΣp ) + qi (qT
i − qi (qT
i (p = 1, · · · , c);
− 1
αi , i = 1, · · · , k .
Output: ωi = ˆ¯Σ
2

= UΛ−1UT ;

Algorithm 2: The MCSSPs Algorithm Based on the Greedy Search Strategy
Input:• Input data matrix X and the class label vector l.
Initialization:
1. Compute the average covariance matrices ˆΣi (i = 1, · · · , c) and ˆ¯Σ;
− 1
−1
2 = UΛ− 1
2. Perform SVD of ˆ¯Σ: ˆ¯Σ = UΛUT , compute ˆ¯Σ
2 UT and ˆ¯Σ
− 1
− 1
3. Compute ˆˆΣi = ˆ¯Σ
2 and ∆ ˆˆΣi = ˆˆΣi − I (i = 1, · · · , c);
ˆ¯Σ
2 ˆΣi
For i = 1, 2, · · · , k , Do
1. Set s ← (1, · · · , 1)T , s1 ← −s, and compute T(s);
2. Solve the principal eigenvector of T(s)α = λα associated with the largest absolute eigen-
value |λ| via the power iteration method. Set λ0 ← |λ|;
While s (cid:54)= s1 , Do
(a) Set s1 ← s;
(b) For j = 1, 2, · · · , c, Do
• Set sj ← −sj , where sj denotes the j th element of s. Compute T(s);
• Solve the principal eigenvector of T(s)α = λα associated with the largest abso-
lute eigenvalue |λ| via the power iteration method, and set λ1 ← |λ|;
• If λ1 ≤ λ0 , then sj ← −sj , else λ0 ← λ1 ;
(c) Compute T(s) and solve the principal eigenvector αi of T(s)αi = λαi associated
with the largest absolute eigenvalue |λ| via the power iteration method;
3. If i = 1, then qi ← αi , qi ← qi /(cid:107)qi (cid:107), and Q1 ← qi ;
else qi ← αi − Qi−1 (QT
i−1αi ), qi ← qi /(cid:107)qi (cid:107), and Qi ← (Qi−1 qi );
4. Compute ∆ ˆˆΣp ← ∆ ˆˆΣp − (∆ ˆˆΣpqi )qT
i ∆ ˆˆΣp ) + qi (qT
i ∆ ˆˆΣpqi )qT
i − qi (qT
i (p = 1, · · · , c);
− 1
αi , i = 1, · · · , k .
Output: ωi = ˆ¯Σ
2

6

(29)

,

be the projections of the EEG data ˆXt onto the projection vector ωj . Then the covariance of the
elements in the projections ˆpt
i,j can be expressed as
ˆXt
ˆΣt
i ) = ωT
i,j = var(ωT
v t
i ωj .
j
j
where ˆΣt
i denotes the covariance matrix of the EEG data in the tth trial of the ith class.
For all the k spatio-spectral ﬁlters ω1 , · · · , ωk , we obtain the k features v t
i,j (j = 1, · · · , k) from the
i,1 , · · · , v t
i = [v t
i,k ]T be the feature vector associated with the tth
tth trial of EEG data. Now let vt
(cid:33)
(cid:195)
trial of the ith class. Similar to the method used in [2], the following log-transformation form is
i(cid:80)
used as the ﬁnal feature vector of the EEG signal:
vt
k v t
i,k
where the log function is applied to each element of the vector independently.
(cid:181)
(cid:182)
transformation serves to approximate the normal distribution of the data [2].
For the given unknown EEG data Z, we use the same procedures to extract the corresponding fea-
Z
tures, i.e., we ﬁrst construct the new data ˆZ =
(cid:181)
(cid:182)
, and then adopt the above method to
δ τ (Z)
vz(cid:80)
extract the corresponding discriminant feature vector f z , where
1 , · · · , vz
j = ωT
k ]T , and vz
, vz = [vz
j
k vz
k
in which ˆΣz denotes the covariance matrix of ˆZ.
i (i = 1, · · · , c; t = 1, 2 · · · , ni ) and f z , we can
After obtaining the discriminant feature vectors f t
classify the unknown EEG data into one of the c classes by using a classiﬁer, e.g., the K-nearest
neighbor (K-NN) classiﬁer [7].

i = log
f t

f z = log

(30)

The log-

ˆΣz ωj ,

(31)

5 Experiments

To test the performance of our MCSSPs method, we use the real world EEG data set to conduct
experiments. The data set used here is from “BCI competition 2005” - data set IIIa [11]. This data set
consists of recordings from three subjects (k3b, k6b, and l1b), which performed four different motor
imagery tasks (left/right hand, one foot, or tongue) according to a cue. During the experiments, the
EEG signal is recorded in 60 channels, using the left mastoid as reference and the right mastoid as
ground. The EEG was sampled at 250 Hz and was ﬁltered between 1 and 50 Hz with the notch ﬁlter
on. Each trial lasted for 7 s, with the motor imagery performed during the last 4 s of each trial. For
subjects k6b and l1b, a total of 60 trials per condition were recorded. For subject k3b, a total of 90
trials per condition were recorded. Similar to the method in [5], we discard the four trials of subject
k6b with missing data. For each trial of the EEG raw data, we only use part of the sample points,
i.e., from No.1001 to No.1750, as the experiment data since they carry most of the information in
the EEG signal. Consequently, each trial contains 750 data points. We adopt the two-fold cross
validation strategy to perform the experiment, i.e., for all the trials of each condition per subject, we
divide them into two groups. Each group is used as training data and testing data once. We conduct
ﬁve rounds of experiments in total, with different divisions of the training and testing data sets, to
obtain ten recognition rates, which are averaged as the ﬁnal recognition rate. For comparison, we
also conduct the same experiment using both MCSPs methods proposed by [4] and [5], respectively.
To better identify the effect of using different EEG ﬁlters, a simple classiﬁer, K-NN classiﬁer with
the Euclidean distance and 7 nearest neighbors, is used for ﬁnal classiﬁcation.

Table 1 shows the average classiﬁcation rates (%) versus the standard deviations (%) of the three
methods2 , while ﬁgure 1 shows the average recognition rates of our MCSSPs method with different
choices of the delayed time τ . From table 1, we can see that the MCSSPs method achieves much
better classi ﬁcation performance than the MCSPs methods.

2The results using the MCSPs method proposed in [5] are inferior to those reported in [5] because we did
not pre-ﬁlter the EEG signals with a Butterworth ﬁlter and did not use the logistic regression classiﬁers for
classiﬁcation either, as we are more interested in comparing the effect of different EEG ﬁlters.

7

Table 1: Comparison of the classiﬁcation rates (%) versus standard deviations (%) between MCSPs
and MCSSPs.

Subject MCSPs [4] MCSPs [5] MCSSPs/Bayes
85.83 (2.23)
k3b
46.17 (6.15)
84.89 (2.74)
56.28 (3.87)
50.09 (2.59)
33.54 (4.27)
k6b
68.58 (6.16)
l1b
35.17 (3.92)
62.08 (3.99)

Figure 1: The classiﬁcation rates (%) of our MCSSPs method with different choices of τ .

6 Conclusions

In this paper, we extended the two-class CSSPs method to the multi-class cases via the Bayes error
estimation. We ﬁrst proposed a novel theory on multi-class Bayes error estimation, which has a
closed-form solution to ﬁnd the optimal discriminant vectors for feature extraction. Then we applied
the multi-class Bayes error estimation theory to generalize the two-class CSSPs method to multi-
class cases. The experiments on the data set IIIa from BCI competition 2005 have shown that
our MCSSPs method is superior to the MCSPS methods. With more elaborate treatments, e.g.,
preprocessing the EEG signal and adopting a more advanced classiﬁer, even higher classiﬁcation
rates are possible. These will be reported in our forthcoming papers.

Acknowledgment

This work was partly supported by National Natural Science Foundation of China under Grants
60503023 and 60872160.

References

[1] B. Blankertz, G. Curio, & K.-R. M ¨uller (2002) Classifying single trial EEG: towards brain computer
interfacing. In: T.G. Dietterich, S. Bechker, Z. Ghaharamani (Eds.), Advances in Neural Information
Processing Systems14, pp.157-164. Cambridge, MA:MIT Press.

[2] H. Ramoser, J. Mueller-Gerking, & G. Pfurtscheller (2000) Optimal spatial ﬁltering of single trial EEG
during imaged hand movement. IEEE Transactions on Rehabilitation Engineering. 8(4):441-446.

8

12345678910505560657075808590tClassification rates (%)  k3bk6bl1b[3] S. Lemm, B. Blanketz, G. Curio, & K.-R. M ¨uller (2005) Spatio-spectral ﬁlters for improved classiﬁcation
of single trial EEG. IEEE Transactions on Biomedical Engineering. 52(9):1541-1548.
[4] G. Dornhege, B. Blankertz, G. Curio, & K.-R. M ¨uller (2004) Boosting bit rates in noninvasive EEG single-
trial classiﬁcations by feature combination and multiclass paradigms.
IEEE Transactions on Biomedical
Engineering. 51(6):993-1002.
[5] M. Grosse-Wentrup, & M. Buss (2008) Multiclass Common Spatial Patterns and Information Theoretic
Feature Extraction. IEEE Transactions on Biomedical Engineering. 55:1991-2000.
[6] L. C. Parra, C. D. Spence, A. D. Gerson, & P. Sajda (2005) Recipes for linear analysis of EEG. Neuroim-
age, 28:326-341.
[7] K. Fukunaga (1990) Introduction to Statistical Pattern Recognition (Second Edition). New York: Aca-
demic Press.
[8] J.T. Chu & J.C. Chuen (1967) Error Probability in Decision Functions for Character Recognition. Journal
of the Association for Computing Machinery. 14(2):273-280.
[9] W. Zheng (2009) Heteroscedastic Feature Extraction for Texture Classiﬁcation.
Letters, 16(9):766-769.
[10] W. Zheng, H. Tang, Z. Lin, & T.S. Huang (2009) A Novel Approach to Expression Recognition from
Non-frontal Face Images. Proceedings of 2009 IEEE International Conference on Computer Vision
(ICCV2009), pp.1901-1908.
[11] G. Blankertz, K.R. Mueller, D. Krusienski, G. Schalk, J.R. Wolpaw, A. Schloegl, G. Pfurtscheller, J. R.
Millan, M. Schroeder, & N. Birbaumer (2006) The BCI competition III: Validating alternative approaches
to actual BCI problems. IEEE Transactions on Rehabilitation Engineering 14:153-159.

IEEE Signal Processing

9

