Conditional Random Fields with High-Order
Features for Sequence Labeling

Hai Leong Chieu
Nan Ye
Wee Sun Lee
DSO National Laboratories
Department of Computer Science
National University of Singapore
chaileon@dso.org.sg
{yenan,leews}@comp.nus.edu.sg

Dan Wu
Singapore MIT Alliance
National University of Singapore
dwu@nus.edu.sg

Abstract

Dependencies among neighbouring labels in a sequence is an important source
of information for sequence labeling problems. However, only dependencies be-
tween adjacent labels are commonly exploited in practice because of the high
computational complexity of typical inference algorithms when longer distance
dependencies are taken into account. In this paper, we show that it is possible to
design efﬁcient inference algorithms for a conditional random ﬁeld using features
that depend on long consecutive label sequences (high-order features), as long as
the number of distinct label sequences used in the features is small. This leads
to efﬁcient learning algorithms for these conditional random ﬁelds. We show ex-
perimentally that exploiting dependencies using high-order features can lead to
substantial performance improvements for some problems and discuss conditions
under which high-order features can be effective.

1

Introduction

In a sequence labeling problem, we are given an input sequence x and need to label each component
of x with its class to produce a label sequence y. Examples of sequence labeling problems include
labeling words in sentences with its type in named-entity recognition problems [16], handwriting
recognition problems [15], and deciding whether each DNA base in a DNA sequence is part of a
gene in gene prediction problems [2].
Conditional random ﬁelds (CRF) [8] has been successfully applied in many sequence labeling prob-
lems. Its chief advantage lies in the fact that it models the conditional distribution P (y|x) rather
than the joint distribution P (y, x). In addition, it can effectively encode arbitrary dependencies of y
on x as the learning cost mainly depends on the parts of y involved in the dependencies. However,
the use of high-order features, where a feature of order k is a feature that encodes the dependency
between x and (k + 1) consecutive elements in y, can potentially lead to an exponential blowup in
the computational complexity of inference. Hence, dependencies are usually assumed to exist only
between adjacent components of y, giving rise to linear-chain CRFs which limits the order of the
features to one.
In this paper, we show that it is possible to learn and predict CRFs with high-order features efﬁ-
ciently under the following pattern sparsity assumption (which is often observed in real problems):
the number of observed label sequences of length, say k , that the features depend on, is much smaller
than nk , where n is the number of possible labels. We give an algorithm for computing the marginals
and the CRF log likelihood gradient that runs in time polynomial in the number and length of the
label sequences that the features depend on. The gradient can be used with quasi-newton methods
to efﬁciently solve the convex log likelihood optimization problem [14]. We also provide an efﬁ-
cient decoding algorithm for ﬁnding the most probable label sequence in the presence of long label
sequence features. This can be used with cutting plane methods to train max-margin solutions for
sequence labeling problems in polynomial time [18].

We show experimentally that using high-order features can improve performance in sequence la-
beling problems. We show that in handwriting recognition, using even simple high-order indicator
features improves performance over using linear-chain CRFs, and impressive performance improve-
ment is observed when the maximum order of the indicator features is increased. We also use a
synthetic data set to discuss the conditions under which higher order features can be helpful. We
further show that higher order label features can sometimes be more stable under change of data
distribution using a named entity data set.

2 Related Work

Conditional random ﬁelds [8] are discriminately trained, undirected Markov models, which has
been shown to perform well in various sequence labeling problems. Although a CRF can be used
to capture arbitrary dependencies among components of x and y, in practice, this ﬂexibility of the
CRF is not fully exploited as inference in Markov models is NP-hard in general (see e.g. [1]), and
can only be performed efﬁciently for special cases such as linear chains. As such, most applications
involving CRFs are limited to some tractable Markov models. This observation also applies to other
structured prediction methods such as structured support vector machines [15, 18].
A commonly used inference algorithm for CRF is the clique tree algorithm [5]. Deﬁning a feature
depending on k (not necessarily consecutive) labels will require forming a clique of size k , resulting
in a clique-tree with tree-width greater or equal to k . Inference on such a clique tree will be exponen-
tial in k . For sequence models, a feature of order k can be incorporated into a k-order Markov chain,
but the complexity of inference is again exponential in k . Under the pattern sparsity assumption, our
algorithm achieves efﬁciency by maintaining only information related to a few occurred patterns,
while previous algorithms maintain information about all (exponentially many) possible patterns.
In the special case of a semi-Markov random ﬁelds, where high-order features depend on segments
of identical labels, the complexity of inference is linear in the maximum length of the segments
[13]. The semi-Markov assumption can be seen as deﬁning a sparse feature representation: though
the number of length k label patterns is exponential in k , the semi-Markov assumption effectively
allows only n2 of them (n is the cardinality of the label set), as the features are deﬁned on a sequence
of identical labels that can only depend on the label of the preceding segment. Compared to this
approach, our algorithm has the advantage of being able to efﬁciently handle high-order features
having arbitrary label patterns.
Long distance dependencies can also be captured using hierarchical models such as Hierarchical
Hidden Markov Model (HHMM) [4] or Probabilistic Context Free Grammar (PCFG) [6]. The time
complexity of inference in an HHMM is O(min{nl3 , n2 l}) [4, 10], where n is the number of states
and l is the length of the sequence. Discriminative versions such as hierarchical CRF has also
been studied [17]. Inference in PCFG and its discriminative version can also be efﬁciently done
in O(ml3 ) where m is the number of productions in the grammar [6]. These methods are able to
capture dependencies of arbitrary lengths, unlike k-order Markov chains. However, to do efﬁcient
learning with these methods, the hierarchical structure of the examples need to be provided. For
example, if we use PCFG to do named entity recognition, we need to provide the parse trees for
efﬁcient learning; providing the named entity labels for each word is not sufﬁcient. Hence, a training
set that has not been labeled with hierarchical labels will need to be relabeled before it can be trained
efﬁciently. Alternatively, methods that employ hidden variables can be used (e.g. to infer the hidden
parse tree) but the optimization problem is no longer convex and local optima can sometimes be a
problem. Using high-order features captures less expressive form of dependencies than these models
but allows efﬁcient learning without relabeling the training set with hierarchical labels.
Similar work on using higher order features for CRFs was independently done in [11]. Their work
apply to a larger class of CRFs, including those requiring exponential time for inference, and they
did not identify subclasses for which inference is guaranteed to be efﬁcient.

3 CRF with High-order Features

Throughout the remainder of this paper, x, y, z (with or without decorations) respectively denote
an observation sequence of length T , a label sequence of length T , and an arbitrary label sequence.
The function | · | denotes the length of any sequence. The set of labels is Y = {1, . . . , n}.
If

fi (x, y, t) =

z = (y1 , . . . , yt ), then zi:j denotes (yi , . . . , yj ). When j < i, zi:j is the empty sequence (denoted
by ). Let the features being considered be f1 , . . . , fm . Each feature fi is associated with a label
(cid:26)gi (x, t),
sequence zi , called fi ’s label pattern, and fi has the form
if yt−|zi |+1:t = zi
0,
otherwise.
We call fi a feature of order |zi |−1. Consider, for example, the problem of named entity recognition.
The observations x = (x1 , . . . , xT ) may be a word sequence; gi (x, t) may be an indicator function
for whether xt is capitalized or may output a precomputed term weight if xt matches a particular
word; and zi may be a sequence of two labels, such as (person, organization) for the named entity
recognition task, giving a feature of order one.
exp((cid:80)m
t=|zi | λi fi (x, y, t)), and Zx = (cid:80)
(cid:80)T
A CRF deﬁnes conditional probability distributions P (y|x) = Zx (y)/Zx , where Zx (y) =
partition function. In this paper, we will use the notation (cid:80)
y Zx (y). The normalization factor Zx is called the
i=1
x:P red(x) f (x) to denote the summation
of f (x) over all elements of x satisfying the predicate P red(x).

3.1

Inference for High-order CRF

In this section, we describe the algorithms for computing the partition function, the marginals and the
most likely label sequence for high-order CRFs. We give rough polynomial time complexity bounds
to give an idea of the effectiveness of the algorithms. These bounds are pessimistic compared to
practical performance of the algorithms. It can also be veriﬁed that the algorithms for linear chain
CRF [8] are special cases of our algorithms when only zero-th and ﬁrst order features are considered.
We show a work example illustrating the computations in the supplementary material.

3.1.1 Basic Notations

As in the case of hidden Markov models (HMM) [12], our algorithm uses a forward and backward
pass. First, we describe the equivalent of states used in the forward and backward computation. We
shall work with three sets: the pattern set Z , the forward-state set P and the backward-state set
S . The pattern set, Z , is the set of distinct label patterns used in the m features. For notational
simplicity, assume Z = {z1 , . . . , zM }. The forward-state set, P = {p1 , . . . p|P |}, consists of
distinct elements in Y ∪ {zj
1:k }0≤k≤|zj |−1,1≤j≤M ; that is, P consists of all labels and all proper
preﬁxes (including ) of label patterns, with duplicates removed. Similarly, S = {s1 , . . . s|S | }
consists of the labels and proper sufﬁxes: distinct elements in Y ∪ {zj
1:k }1≤k≤|zj |,1≤j≤M .
The transitions between states are based on the preﬁx and sufﬁx relationships deﬁned below. Let
z1 ≤p z2 denote that z1 is a preﬁx of z2 and let z1 ≤s z2 denote that z1 is a sufﬁx of z2 . We deﬁne
the longest preﬁx and sufﬁx relations with respect to the sets P and S as follows
(z1 ∈ S ) and (z1 ≤p z2 ) and (∀z ∈ S , z ≤p z2 ⇒ z ≤p z1 )
z1 ≤pS z2
z1 ≤sP z2
(z1 ∈ P ) and (z1 ≤s z2 ) and (∀z ∈ P , z ≤s z2 ⇒ z ≤s z1 ).
Finally, the subsequence relationship deﬁned below are used when combining forward and backward
variables to compute marginals. Let z ⊆ z(cid:48) denote that z is a subsequence of z(cid:48) , z ⊂ z(cid:48) denote that
2:|z(cid:48) |−1 . The addition of subscript j in ⊆j and ⊂j indicates that the condition
z is a subsequence of z(cid:48)
z ≤s z(cid:48)
1:j is satisﬁed as well (that is, z ends at position j in z(cid:48) ).
We shall give rough time bounds in terms of m (the total number of features), n (the number of
labels), T (the length of the sequence), M (the number of distinct label patterns in Z ), and the
maximum order K = max{|z1 | − 1, . . . , |zM | − 1}.
3.1.2 The Forward and Backward Variables
(cid:80)|z|
x (z) = exp((cid:80)m
We now deﬁne forward vector αx and backward vector βx . Suppose z ≤p y, then deﬁne y’s preﬁx
t=|zi | λi fi (x, y, t)). Similarly, if z ≤s y, then deﬁne y’s sufﬁx score
score Z p
i=1

if and only if
if and only if

x (z)
Z p

x (z).
Z s

x (z) = exp((cid:80)m
Z s
i=1

(cid:80)T
αx (t, pi ) = (cid:88)
t=T −|z|+|zi | λi fi (x, y, t)). Z p
x (z) and Z s
x (z) only depend on z. Let
(cid:88)
z:|z|=t,pi≤sP z
βx (t, si ) =
z:|z|=T +1−t,si≤pS z
The variable αx (t, pi ) computes for x1:t the sum of the scores of all its label sequences z having
pi as the longest sufﬁx. Similarly, the variable βx (t, si ) computes for xt:T the sum of scores of all
its label sequence z having si as the longest preﬁx. Each vector αx (t, ·) is of dimension |P |, while
x (t, p) = exp((cid:80)
βx (t, ·) has dimension |S |. We shall compute the αx and βx vectors with dynamic programming.
i:zi≤sp λi gi (x, t)). For y with p ≤s y1:t , this function counts the contribu-
Let Ψp
tion towards Zx (y) by all features fi with their label patterns ending at position t and being sufﬁxes
of p. Let pi y be the concatenation of pi with a label y . The following proposition is immediate.
(a) For any z, there is a unique pi such that pi ≤sP z.
Proposition 1
(b) For any z, y , if pi ≤sP z and pk ≤sP pi y , then pk ≤sP zy and Z p
x (z).
x (t, pi y)Z p
x (zy) = Ψp
Proposition 1(a) means that we can induce partitions of label sequences using the forward states.
and Proposition 1(b) shows how to make well-deﬁned transition from one forward state at a time
slice to another forward state at the next time slice. By deﬁnition, αx (0, ) = 1, and αx (0, pi ) = 0
(cid:88)
for all pi (cid:54)= . Using Proposition 1(b), the recurrence for αx is
x (t, pi y)αx (t − 1, pi ), for 1 ≤ t ≤ T .
αx (t, pk ) =
Ψp
x (t, s) = exp((cid:80)
(pi ,y):pk≤sP pi y
i:zi≤p s λi gi (x, t + |zi | − 1)). By
Similarly, for the backward vectors βx , let Ψs
(cid:88)
deﬁnition, βx (T + 1, ) = 1, and βx (T + 1, si ) = 0 for all si (cid:54)= . The recurrence for βx is
for 1 ≤ t ≤ T .
Ψs
βx (t, sk ) =
x (t, ysi )βx (t + 1, si ),
(si ,y):sk≤pS ysi
|S |(cid:88)
|P |(cid:88)
Once αx or βx is computed, then using Proposition 1(a), Zx can be easily obtained:
i=1
i=1
Time Complexity: We assume that each evaluation of the function gi (·, ·) can be performed in unit
x that are used can hence be computed in O(mn|P |T ) (thus
time for all i. All relevant values of Ψp
O(mnM K T )) time. In practice, this is pessimistic, and the computation can be done more quickly.
For all following analyses, we assume that Ψp
x has already been computed and stored in an array.
Now all values of αx can be computed in Θ(n|P |T ), thus O(nM K T ) time. Similar bounds for Ψs
x
and βx hold.

Zx =

αx (T , pi ) =

βx (1, si ).

3.1.3 Computing the Most Likely Label Sequence
As in the case of HMM [12], Viterbi decoding (calculating the most likely label sequence) is ob-
tained by replacing the sum operator in the forward backward algorithm with the max operator.
Formally, let δx (t, pi ) = maxz:|z|=t,pi≤sP z Z p
x (z). By deﬁnition, δx (0, ) = 1, and δx (0, pi ) = 0
for all pi (cid:54)= , and using Proposition 1, we have
x (t, pi y)δx (t − 1, pi ), for 1 ≤ t ≤ T .
δx (t, pk ) =
max
Ψp
(pi ,y):pk≤sP pi y
We use Φx (t, pk ) to record the pair (pi , y) chosen to obtain δx (t, pk ),
x (t, pi y)δx (t − 1, pi ).
Φx (t, pk ) = arg max(pi ,y):pk≤sP pi yΨp

Let p∗
T ) has y∗
1 , . . . , y∗
T = arg maxpi δx (T , pi ), then the most likely path y∗ = (y∗
T as the last label
T , and the full sequence can be traced backwards using Φx (·, ·) as follows
in p∗
t+1 ), for 1 ≤ t < T .
(p∗
t , y∗
t ) = Φx (t + 1, p∗
Time Complexity: Either Ψp
x or Ψs
x can be used for decoding; hence decoding can be done in
Θ(n min{|P |, |S |}T ) time.

3.1.4 Computing the Marginals
We need to compute marginals of label sequences and single variables, that is, compute P (yt−|z|:t =
z|x) for z ∈ Z ∪ Y . Unlike in the traditional HMM, additional care need to be taken regarding
Wx (t, z) = exp( (cid:88)
features having label patterns that are super or sub sequences of z. We deﬁne
λi gi (x, t − |z| + j )).
(i,j ):zi⊂j z
This function computes the sum of all features that may activate strictly within z.
(cid:88)
If z1:|z|−1 ≤s pi and z2:|z| ≤p sj , deﬁne [pi , z, sj ] as the sequence pi
1:|pi |−(|z|−1)zsj|z|−1:|sj | , and
λk gk (x, t − |pi | + k (cid:48) − 1)).
Ox (t, pi , sj , z) = exp(
(k,k(cid:48) ):z⊆zk ,zk⊆k(cid:48) [pi ,z,sj ]
Ox (t, pi , sj , z) counts the contribution of features with their label patterns properly containing z but
within [pi , z, sj ].
Proposition 2 Let z ∈ Z ∪ Y . For any y with yt−|z|+1:t = z, there exists unique pi , sj such
that z1:|z|−1 ≤s pi , z2:|z| ≤p sj , pi ≤sP y1:t−1 , and sj ≤pS yt−|z|+2:T . In addition, Zx (y) =
x (T + 1 − (t − |z| + 2), yt−|z|+2:T )Ox (t, pi , sj , z).
x (t − 1, y1:t−1 )Z s
1
Wx (t,z) Z p

.

P (yt−|z|+1:t = z|x) =

Multiplying by Ox counts features that are not counted in Z p
x while division by Wx removes
xZ s
features that are double-counted. By Proposition 2, we have
(cid:80)
(i,j ):z1:|z|−1≤spi ,z2:|z|≤p sj αx (t − 1, pi )βx (t − |z| + 2, sj )Ox (t, pi , sj , z)
ZxWx (t, z)
Time Complexity: Both Wx (t, z) and Ox (t, pi , sj , z) can be computed in O(|pi ||sj |) =
O(K 2 ) time (with some precomputation). Thus a very pessimistic time bound for computing
P (yt−|z|+1:t = z|x) is O(K 2 |P ||S |) = O(M 2K 4 ).
3.2 Training
log-likelihood LT = log Π(x,y)∈T P (y|x) − (cid:80)m
Given a training set T , the model parameters λi ’s can be chosen by maximizing the regularized
λ2
, where σreg is a parameter that controls
i
2σ2
i=1
the degree of regularization. Note that LT is a concave function of λ1 , . . . , λm , and its maximum is
reg
achieved when
∂LT
= ˜E (fi ) − E (fi ) − λk
where ˜E (fi ) = (cid:80)
(x,y)∈T (cid:80)|x|
σ2
∂λi
reg
(x,y)∈T (cid:80)|y(cid:48) |=|x| P (y(cid:48) |x) (cid:80)|x|
data, and E (fi ) = (cid:80)
t=|zi | fi (x, y, t) is the empirical sum of the feature fi in the observed
t=|zi | fi (x, y(cid:48) , t) is the expected sum of fi .
Given the gradient and value of LT , we use the L-BFGS optimization method [14] for maximiz-
ing the regularized log-likelihood.
The function LT can now be computed because we have shown how to compute Zx , and computing
the value of Zx (y) is straightforward, for all (x, y) ∈ T . For the gradient, computing ˜E (fi ) is

= 0

|x|(cid:88)
E (fi ) = (cid:88)
straightforward, and E (fi ) can be computed using marginals computed in previous section:
t−|zi |+1:t = zi |x)gi (x, t).
P (y(cid:48)
(x,y)∈T
t=|zi |
just consider the time needed to compute the gradient. Let X = (cid:80)
Time Complexity: Computing the gradient is clearly more time-consuming than LT , thus we shall
(x,y)∈T |x|. We need to compute
at most M X marginals, thus total time needed to compute all the marginals has O(M 3K 4X ) as
an upper bound. Given the marginals, we can compute the gradient in O(mX ) time. If the total
number of gradient computations needed in maximization is I , then the total running time in training
is bounded by O((M 3K 4 + m)X I ) (very pessimistic).

4 Experiments

The practical feasibility of making use of high-order features based on our algorithm lies in the
observation that the pattern sparsity assumption often holds. Our algorithm can be applied to take
those high-order features into consideration; high-order features now form a component that one can
play with in feature engineering.
Now, the question is whether high-order features are practically signiﬁcant. We ﬁrst use a synthetic
data set to explore conditions under which high-order features can be expected to help. We then use
a handwritten character recognition problem to demonstrate that even incorporating simple high-
order features can lead to impressive performance improvement on a naturally occurring dataset.
Finally, we use a named entity data set to show that for some data sets, higher order label features
may be more robust to changes in data distributions than observation features.

4.1 Synthetic Data Generated Using k-Order Markov Model

We randomly generate an order k Markov model with n states s1 , . . . , sn as follows. To increase
pattern sparsity, we allow at most r randomly chosen possible next state given the previous k states.
This limits the number of possible label sequences in each length k + 1 segment from nk+1 to
nk r . The conditional probabilities of these r next states is generated by randomly selecting a vector
from uniform distribution over [0, 1]r and normalizing them. Each state si generates an observation
(a1 , . . . , am ) such that aj follows a Gaussian distribution with mean µij and standard deviation
σ . Each µi,j is independently randomly generated from the uniform distribution over [0, 1]. In the
experiments, we use values of n = 5, r = 2 and m = 3.
The standard deviation, σ , has an important role in determining the characteristics of the data gener-
ated by this Markov model. If σ is very small as compared to most µij ’s, then using the observations
alone as features is likely to be good enough to obtain a good classiﬁer of the states; the label cor-
relations becomes less important for classiﬁcation. However, if σ is large, then it is difﬁcult to
distinguish the states based on the observations alone and the label correlations, particularly those
captured by higher order features are likely to be helpful. In short, the standard deviation, σ , is used
to to control how much information the observations reveal about the states.
We use the current, previous and next observations, rather than just the current observation as fea-
tures, exploiting the conditional probability modeling strength of CRFs. For higher order features,
we simply use all indicator features that appeared in the training data up to a maximum order. We
considered the case k = 2 and k = 3, and varied σ and the maximum order. The training set and
test set each contains 500 sequences of length 20; each sequence was initialized with a random se-
quence of length k and generated using the randomly generated order k Markov model. Training
was done by maximizing the regularized log likelihood with regularization parameter σreg = 1 in all
experiments in this paper. The experimental results are shown in Figure 1.
Figure 1 shows that the high-order indicator features are useful in this case. In particular, we can
see that it is beneﬁcial to increase the order of the high-order features when the underlying model
has longer distance correlations. As expected, increasing the order of the features beyond the order
of the underlying model is not helpful. The results also suggests that in general, if the observations
are closely coupled with the states (in the sense that different states correspond to very different
observations), then feature engineering on the observations is generally enough to perform well, and

Figure 1: Accuracy as a function of maximum order on the synthetic data set.

Figure 2: Accuracy (left) and running time (right) as a function of maximum order for the handwrit-
ing recognition data set.

it is less important to use high-order features to capture label correlations. On the other hand, when
such coupling is not clear, it becomes important to capture the label correlations, and high-order
features can be useful.

4.2 Handwriting Recognition

We used the handwriting recognition data set from [15], consisting of around 6100 handwritten
words with an average length of around 8 characters. The data was originally collected by Kassel
[7] from around 150 human subjects. The words were segmented into characters, and each character
was converted into an image of 16 by 8 binary pixels. In this labeling problem, each xi is the image
of a character, and each yi is a lower-case letter. The experimental setup is the same as that used in
[15]: the data set was divided into 10 folds with each fold having approximately 600 training and
5500 test examples and the zero-th order features for a character are the pixel values.
For higher order features, we again used all indicator features that appeared in the training data up
to a maximum order. The average accuracy over the 10 folds are shown in Figure 2, where strong
improvements are observed as the maximum order increases. Figure 2 also shows the total training
time and the running time per iteration of the L-BFGS algorithm (which requires computation of the
gradient and value of the function at each iteration). The running time appears to grow no more than
linearly with the maximum order of the features for this data set.

4.3 Named Entity Recognition with Distribution Change

The Named Entity Recognition (NER) problem asks for identiﬁcation of named entities from texts.
With carefully engineered observation features, there does not appear to be very much to be gained
from using higher order features. However, in some situations, the training data does not come from
the same distribution as the test data. In such cases, we hypothesize that higher order label features
may be more stable than observation features and can sometimes offer performance gain.
In our experiment, we used the Automatic Content Extraction (ACE) data [9], which is labeled with
seven classes: Organization, Geo-political, Location, Facility, Vehicle, and Weapon. The ACE data

Generated by 2nd-Order Markov Model8284868890929496981234Maximum Order of FeaturesAccuracySigma = 0.01Sigma = 0.05Sigma = 0.10Generated by 3rd-Order Markov Model7981838587899193951234Maximum Order of FeaturesAccuracySigma = 0.01Sigma = 0.05Sigma = 0.10Handwritten Character Recognition747678808284868812345Maximum Order of FeaturesAccuracyRuntimes for Character Recognition Training01020304050607080902345Maximum Order of FeaturesTime (s)0500100015002000250030003500Time (s)Per Iteration Time (Left Axis)Total Time (Right Axis)comes from several genres and we use the following in our experiment: Broadcast conversation
(BC), Newswire (NW), Weblog (WL) and Usenet (UN).
We use all pairs of genres as training and test
data. Scoring was done with the F1 score [16].
The features used are previous word, next word,
current word, case patterns for these words, and
all indicator label features of order up to k . The
results for the case k = 1 and k = 2 are shown
in Figure 3. Introducing second order indicator
features shows improvement in 10 out of the 12
combinations and degrades performance in two
of the combinations. However, the overall effect
is small, with an average improvement of 0.62 in
F1 score.

4.4 Discussion

Figure 3: Named entity recognition results.

In our experiments, we used indicator features of all label patterns that appear in the training data.
For real applications, if the pattern sparsity assumption is not satisﬁed, but certain patterns do not
appear frequently enough and are not really important, then it is useful to see how we can select a
subset of features with few distinct label patterns automatically. One possible approach would be to
use boosting type methods [3] to sequentially select useful features.
An alternate approach to feature selection is to use all possible features and maximize the margin
of the solution instead. Generalization error bounds [15] show that it is possible to obtain good
generalization with a relatively small training set size despite having a very large number of features
if the margin is large. This indicates that feature selection may not be critical in some cases. Theo-
retically, it is also interesting to note that minimizing the regularized training cost when all possible
high-order features of arbitrary length are used is computationally tractable. This is because the
representer theorem [19] tells us that the optimum solution for minimizing quadratically regularized
cost functions lies on the span of the training examples. Hence, even when we are learning with
arbitrary sets of high-order features, we only need to use the features that appear in the training set
to obtain the optimal solution. Given a training set of N sequences of length l, only O(l2N ) long
label sequences of all orders are observed. Using cutting plane techniques [18] the computational
complexity of optimization is polynomial in inverse accuracy parameter, the training set size and
maximum length of the sequences.
It should also be possible to use kernels within the approach here. On the handwritten character
problem, [15] reports substantial improvement in performance with the use of kernels. Use of ker-
nels together with high-order features may lead to further improvements. However, we note that the
advantage of the higher order features may become less substantial as the observations become more
powerful in distinguishing the classes. Whether the use of higher order features together with ker-
nels brings substantial improvement in performance is likely to be problem dependent. Similarly,
observation features that are more distribution invariant such as comprehensive name lists can be
used for the NER task we experimented with and may reduce the improvements offered by higher
order features.

5 Conclusion

The pattern sparsity assumption often holds in real applications, and we give efﬁcient inference al-
gorithms for CRF with high-order features when the pattern sparsity assumption is satisﬁed. This
allows high-order features to be explored in feature engineering for real applications. We studied the
conditions that are favourable for using high-order features using a synthetic data set, and demon-
strated that using simple high-order features can lead to performance improvement on a handwriting
recognition problem and a named entity recognition problem.

Acknowledgements
This work is supported by DSO grant R-252-000-390-592 and AcRF grant R-252-000-327-112.

Named Entity Recognition (Domain Adaptation)Average Improvement = 0.6225303540455055606570bc:nwbc:unbc:wlnw:bcnw:unnw:wlun:bcun:nwun:wlwl:bcwl:nwwl:unTraining Domain : Test DomainF1 ScoreLinear ChainSecond OrderReferences
[1] B. A. Cipra, “The Ising model is NP-complete,” SIAM News, vol. 33, no. 6, 2000.
[2] A. Culotta, D. Kulp, and A. McCallum, “Gene prediction with conditional random ﬁelds,”
University of Massachusetts, Amherst, Tech. Rep. UM-CS-2005-028, 2005.
[3] T. G. Dietterich, A. Ashenfelter, and Y. Bulatov, “Training conditional random ﬁelds via gra-
dient tree boosting,” in Proceedings of the Twenty-First International Conference on Machine
Learning, 2004.
[4] S. Fine, Y. Singer, and N. Tishby, “The hierarchical hidden markov model: Analysis and ap-
plications,” Machine Learning, vol. 32, no. 1, pp. 41–62, 1998.
[5] C. Huang and A. Darwiche, “Inference in belief networks: A procedural guide,” International
Journal of Approximate Reasoning, vol. 15, no. 3, pp. 225–263, 1996.
[6] F. Jelinek, J. D. Lafferty, and R. L. Mercer, “Basic methods of probabilistic context free gram-
mars,” in Speech Recognition and Understanding. Recent Advances, Trends, and Applications.
Springer Verlag, 1992.
[7] R. H. Kassel, “A comparison of approaches to on-line handwritten character recognition,”
Ph.D. dissertation, Massachusetts Institute of Technology, Cambridge, MA, USA, 1995.
[8] J. Lafferty, A. McCallum, and F. Pereira, “Conditional random ﬁelds: Probabilistic models
for segmenting and labeling sequence data,” in Proceedings of the Eighteenth International
Conference on Machine Learning, 2001, pp. 282–289.
[9] Linguistic Data Consortium, “ACE (Automatic Content Extraction) English Annotation
Guidelines for Entities,” 2005.
[10] K. P. Murphy and M. A. Paskin, “Linear-time inference in hierarchical HMMs,” in Advances
in Neural Information Processing Systems 14, vol. 14, 2002.
[11] X. Qian, X. Jiang, Q. Zhang, X. Huang, and L. Wu, “Sparse higher order conditional random
ﬁelds for improved sequence labeling,” in ICML, 2009, p. 107.
[12] L. R. Rabiner, A tutorial on hidden Markov models and selected applications in speech recog-
nition. San Francisco, CA, USA: Morgan Kaufmann Publishers Inc., 1990.
[13] S. Sarawagi and W. W. Cohen, “Semi-Markov conditional random ﬁelds for information ex-
traction,” in Advances in Neural Information Processing Systems 17. Cambridge, MA: MIT
Press, 2005, pp. 1185–1192.
[14] F. Sha and F. Pereira, “Shallow parsing with conditional random ﬁelds,” in Proceedings of the
Twentieth International Conference on Machine Learning, 2003, pp. 282–289.
[15] B. Taskar, C. Guestrin, and D. Koller, “Max-margin Markov networks,” in Advances in Neural
Information Processing Systems 16. Cambridge, MA: MIT Press, 2004.
[16] E. Tjong and F. D. Meulder, “Introduction to the CoNLL-2003 shared task: Language-
independent named entity recognition,” in Proceedings of Conference on Computational Nat-
ural Language Learning, 2003.
[17] T. T. Tran, D. Phung, H. Bui, and S. Venkatesh, “Hierarchical semi-Markov conditional random
ﬁelds for recursive sequential data,” in NIPS’08: Advances in Neural Information Processing
Systems 20. Cambridge, MA: MIT Press, 2008, pp. 1657–1664.
[18] I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun, “Support vector machine learning for
interdependent and structured output spaces,” in Proceedings of the Twenty-First international
conference on Machine learning, 2004, pp. 104–112.
[19] G. Wahba, Spline models for observational data, ser. CBMS-NSF Regional Conference Series
in Applied Mathematics. Philadelphia, PA: Society for Industrial and Applied Mathematics
(SIAM), 1990, vol. 59.

