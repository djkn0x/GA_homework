Stress, noradrenaline, and realistic prediction of
mouse behaviour using reinforcement learning

Gediminas Lukˇsys1,2 , Carmen Sandi2 , Wulfram Gerstner1
1Laboratory of Computational Neuroscience
2Laboratory of Behavioural Genetics
Ecole Polytechnique F ´ed ´erale de Lausanne (EPFL)
Lausanne, CH-1015, Switzerland
{gediminas.luksys,carmen.sandi,wulfram.gerstner}@epfl.ch

Abstract

Suppose we train an animal in a conditioning experiment. Can one predict how
a given animal, under given experimental conditions, would perform the task?
Since various factors such as stress, motivation, genetic background, and previous
errors in task performance can inﬂuence animal behaviour, this appears to be a
very challenging aim. Reinforcement learning (RL) models have been success-
ful in modeling animal (and human) behaviour, but their success has been limited
because of uncertainty as to how to set meta-parameters (such as learning rate,
exploitation-exploration balance and future reward discount factor) that strongly
inﬂuence model performance. We show that a simple RL model whose meta-
parameters are controlled by an artiﬁcial neural network, fed with inputs such as
stress, affective phenotype, previous task performance, and even neuromodula-
tory manipulations, can successfully predict mouse behaviour in the ”hole-box”
- a simple conditioning task. Our results also provide important insights on how
stress and anxiety affect animal learning, performance accuracy, and discounting
of future rewards, and on how noradrenergic systems can interact with these pro-
cesses.

1 Introduction

Animal behaviour is guided by rewards that can be received in different situations and by modulatory
factors, such as stress and motivation. It is known that acute stress can affect learning and memory by
modulating plasticity through stress hormones and neuromodulators [1, 2, 3], but their role in high-
level processes such as learning, memory, and action selection is not well understood. A number
of interesting conceptual and computational models have been proposed relating neuromodulatory
systems, cognitive processes, and abstract statistical quantities characterizing the environment [4, 5].
While such models provide great mechanistic insights, they alone are often unable to accurately
predict animal behaviour in a realistic situation due to a great number of diverse modulatory factors.
Stress [2], genotype [6], affective traits such as anxiety and impulsivity [7], motivation [8], and
evaluation of performance errors [9] can all inﬂuence individual performance in any single task, yet
it may prove difﬁcult and inefﬁcient to explicitly model each factor in order to accurately predict
animal behaviour. Instead, we propose a method which could account for the inﬂuence of arbitrary
modulatory factors on behaviour as control parameters of a general behavioural model.
In modeling reward-based behavioural learning, approaches based on the formal theory of reinforce-
ment learning (RL) have been the most successful. The basic idea of RL is that animals (or artiﬁcial
agents) select their actions based on predicted future rewards that could be acquired upon taking
these actions. The expected values of future rewards for different actions (Q-values) can be gradu-
ally learned by observing rewards received under different state-action combinations. An efﬁcient

1

way to do this is temporal difference (TD) learning [10], which uses an error signal that correlates
with the activity of dopaminergic neurons in the Substantia Nigra [11]. TD models have been suc-
cessfully applied to explain a wide range of experimental data, including animal conditioning [8],
human decision-making [12], and even addiction [13].
Learning and action selection in TD models can be strongly inﬂuenced by the choice of model meta-
parameters such as the learning rate, the future reward discounting, and the exploitation-exploration
balance. While in most modeling studies they have received relatively little attention, it has been pro-
posed that RL meta-parameters are related to speciﬁc neuromodulators - noradrenaline, serotonin,
acetylcholine [14], and to neural activity occurring in different brain regions - notably amygdala,
striatum, and anterior cingulate [15]. Modulatory factors such as stress, anxiety, and impulsivity
often act through the same brain systems, which suggests that in RL models their effects could be
expressed through changes in meta-parameter values.
In the present study, we tested mouse behaviour in a simple conditioning task - the hole-box, and
showed how various modulatory factors could control a simple RL model to accurately predict ani-
mal behaviour. We used food deprived mice of two genetic strains - ’calm’ C57BL/6 and ’anxious’
DBA/2 [6], half of which were exposed to an additional stressor - sitting on an elevated platform -
before each experimental session. We formalized animal behaviour using a simple RL model, and
trained an artiﬁcial neural network that could control RL meta-parameters using information about
stress, motivation, individual affective traits, and previous learning success. We demonstrate that
such model can successfully predict mouse behaviour in the hole-box task and that the resulting
model meta-parameters provide useful insights into how animals adjust their performance through-
out the course of a learning experience, and how they respond to stressors and motivational demands.
Finally, using systemic manipulations of the noradrenergic system we show how noradrenaline in-
teracts with stress and anxiety in regulating performance accuracy and temporal discounting.

2 Description of the hole-box experiment

In our hole-box experiments, we used 64 male mice (32 of C57BL/6 strain and 32 of DBA/2 strain)
that were 10-week old at the beginning of the experiment. During an experimental session, each
animal was placed into the hole-box (Figure 1a). The mice had to learn to make a nose poke into
the hole upon the onset of lights and not to make it under the condition of no light. After a response
to light, the animals (which were food deprived to 87.3+/-1.0% of their initial weight) received a
reward in form of a food pellet (Figure 1b). The inter-trial interval (ITI) between subsequent trials
was varying: the probability of a new trial during each 0.5 sec long time step was 1/30, resulting in
the average ITI of 15 sec. The total session duration was 500 sec, equivalent to 1000 time steps.

Figure 1: a. Scheme of the hole-box. b. Protocol of the hole-box experiment. c. Hole-box state-
action chart. Rectangles are states, thin arrows are actions.

During 2 days of habituation (when the food delivery was not paired with light) the mice learned that
food could be delivered from the boxes. After this, they were trained for 8 consecutive days, during

2

which half of the mice were exposed to extrinsic stress (30min on the elevated platform) before
each training session. On training days 3, 6, and 8, animals have been injected i.p. (5 ml/kg, 30
min before the experimental session) with either saline (1/2 of mice), or adrenergic alpha-2 agonist
clonidine (1/4 of mice, 0.05 mg/kg) that reduces brain noradrenaline levels, or adrenergic alpha-2
antagonist yohimbine (1/4 of mice, 1 mg/kg) that increases brain noradrenaline levels. Mice of each
strain were treated equivalently with respect to pharmacological and stress conditions. Stress and
pharmacological treatment groups were the same during all training days.

3 Challenges of behavioural analysis

To quantify animal performance in the hole-box experiment, we used 7 different performance mea-
sures (PMs). These were behavioural statistics, calculated for each daily session: number of trials
(within 500 sec), number of ITI pokes, mean response time (after light onset), mean nose poke
duration, number of uneaten food pellets, ”TimePreference”1 , and ”DurationPreference”2 . Differ-
ent PMs reﬂected different aspects of behaviour - learning to respond, associating responses with
light, overcoming anxiety to make sufﬁciently long nose pokes, etc. For this reason, during the pro-
cess of learning PMs exhibited a variety of dynamics: slowly increasing numbers of trials, rapidly
decreasing mean response times, ﬁrst increasing and later decreasing numbers of ITI pokes.

Figure 2: a. Development of selected PMs with learning for C57BL/6 mice. b. Results of the PCA
applied for all PMs: eigenvalues and loadings for the ﬁrst 3 components.

When comparing the PMs between different experimental groups (Figure 2a), it is often hard to
interpret the differences, as each PM describes an unknown mixture of cognitive processes such
as learning, memory, performance intensity and accuracy. In some cases, performing a principal
component analysis (PCA) or similar tools may be suitable for reducing the behavioural measures
to few main components that could be easily interpreted [16]. However, more often that is not
the case - for instance, in our experiment, the 3 principal components are not sufﬁcient to explain
even 75% of the variation, and the composition of the components is not easy to interpret (Figure
2b). As an alternative to conventional behavioural analysis, we propose that a computational model
of behaviour, based on reinforcement learning, could be sufﬁciently ﬂexible to ﬁt a wide range of
behavioural effects, and in contrast to the PMs, RL meta-parameters could be easily interpreted in
cognitive terms.

4 Modeling the hole-box using reinforcement learning

We used a simple temporal difference RL model to formalize the behaviour. Conceptually, the
model had 4 states: [ITI, trial] x [animal outside, making a nose poke], and 2 actions: move (in
or out) and stay. However, to make model’s performance realistic several extensions had to be
introduced (Figure 1c). First of all, the state animal outside was divided into 6 states corresponding

1TimePreference = (average time between adjacent ITI pokes) / (average response time)
2DurationPreference = (average trial response poke duration) / (average ITI poke duration)

3

to different places in the box which the animal could occupy, adding additional actions for the
transitions between these new states (moving around the box). Secondly, we observed that when
our animals made too short trial responses (with nose poke duration under 0.5 sec), they often could
not pick up the delivered food. Conversely, when the nose pokes were longer than 1.5 sec, animals
nearly always managed to pick up the delivered food immediately. To account for this, the state
making a nose poke was divided into 5 states, representing different nose poke durations, with the
increasing probability of picking up the reward (to keep things simple, we chose a linear increase:
from p = 0.2 for the ﬁrst state to p = 1.0 for the ﬁfth). Note that a food pellet is delivered at the
start of each trial response, irrespectively of whether the animal picks it up during that nose poke or
not. Unconsumed pellets could be eaten during later (sufﬁciently long) ITI nose pokes.
The Q-values, deﬁned as Q(st , at ) = E [r(t) + γ r(t + 1) + γ 2 r(t + 2) + ...|st , at ], were updated
based on the temporal difference error:
∆Q(st , at ) = α[r(t) + γQ(st+1 , at+1 ) − Q(st , at )],
(1)
where r(t) is the reward at time t, st the state, at the action, α the learning rate, and γ the future
reward discount factor. High γ values (close to 1) signiﬁed that future rewards were given high
(cid:88)
weight, while low γ values (0-0.5) meant that immediate rewards were preferred. Actions were
chosen probabilistically, based on Q-values and the exploitation factor β , as follows:
p(ai |s) = exp(βQ(s, ai ))/
k∈A(s)
where A(s) are actions available at state s. Low β values implied that the actions were being chosen
more or less randomly (exploration), while high β values strongly biased the choice towards the
action(s) with the highest Q-value (exploitation). Q-values were initialized as zeros before the ﬁrst
training day, and the starting state was always ITI / outside, near the hole.

exp(βQ(s, ak )))

(2)

5 Predicting mouse behaviour using dynamic control of model
meta-parameters
NPM(cid:88)
To compare the model with animal behaviour we used the following goodness-of-ﬁt function [17]:
k=1

k − PMmod
(PMexp
k

(α, β , γ ))2 /(σ exp
k

χ2 =

)2 ,

(3)

where PMexp
and PMmod
are the PMs calculated for each animal and the model, respectively, and
k
k
NPM = 7 is the number of the PMs. PMmod
(α, β , γ ) were calculated after simulation of one
k
session (averaged over multiple runs) with ﬁxed values of the meta-parameters. To evaluate whether
our model is sufﬁciently ﬂexible to ﬁt a wide range of animal behaviours (including effects of stress,
strain, and noradrenaline), we performed an estimation procedure of daily meta-parameters. Using
stochastic gradient ascent from multiple starting points, we minimized (3) with respect to α, β , γ
for each session separately by systematically varying the meta-parameters in the following ranges:
α, γ ∈ [0.03, 0.99] and β ∈ [10−1 , 101.5 ]. To evaluate how well the model ﬁts the experimental data
we used χ2 -test with ν = NPM − 3 degrees of freedom (since our model has 3 free parameters).
The P (χ2 , ν ) value, deﬁned as the probability that a realization of a chi-square-distributed random
variable would exceed χ2 by chance, was calculated for each session separately. Generally, values
of P (χ2 , ν ) > 0.01 correspond to a fairly good model [17].
Even if our RL model with estimated meta-parameters is capable of reproducing behaviour of differ-
ent experimental groups in the hole-box, this does not tell us how, given a new animal in an arbitrary
experimental condition, we should set daily meta-parameters to predict its behaviour. However,
information about animal’s affective phenotype, its experimental condition, and recent task perfor-
mance may be helpful in determining these meta-parameter settings, and thus, predicting behaviour.
For this purpose, we trained an artiﬁcial neural network (NN) model (Figure 3b), whose outputs
would be the predicted values of α, β , and γ . The inputs of the model included the following infor-
mation: animal’s genetic strain (0 for C57BL/6, 1 for DBA/2), its anxiety (% of time it spends in the
center of the open ﬁeld - a separate experiment for characterization of affective traits), its novelty
response (% of time it spends in the center of the ﬁeld once a novel object is introduced there),

4

stress prior to a training session (0 or 1), motivation (% of initial weight, correlating with hunger),
noradrenergic manipulation (-1 for NA reduction, 1 for NA increase, and 0 for control), and two
important measures describing performance on the previous day - a number of food pellets eaten
(’rewards’), and a number of nose pokes during which no food was consumed (’misses’). Our NN
had merely 4 hidden layer ”neurons” (to prevent from over-ﬁtting, as we only had 762 samples of
data for training and validation). Its target outputs were the daily estimated meta-parameter sets, and
after normalizing inputs and targets to zero mean and unit variance, the network was trained (100
times) using the Levenberg-Marquardt method [18]. Because of the normalization, the resulting
mean square errors (MSEs) directly indicated how much variance in the meta-parameters could not
be explained by the NN.
Using 10 trained networks with lowest MSEs, we performed simulations to analyze how much dif-
ferent input factors affect each meta-parameter. For this purpose we simulated the NN 106 times,
linearly varying 1 or 2 selected inputs, while all the remaining inputs would be given random val-
ues with zero mean and unit variance. Then we could plot mean resulting meta-parameter values
corresponding to different values of the selected inputs. The range of meta-parameter variation and
relative noise in such plots indicated how strongly the selected inputs (compared to other inputs)
inﬂuenced the resulting meta-parameters. Finally, to predict the performance of selected animals
and the differences between experimental groups, we simulated the NN with input values of each
animal and analyzed the resulting meta-parameters.

Figure 3: a. Comparison of model performance and animal behaviour. b. Scheme of the NN model.
c. Comparison of daily estimated meta-parameters and outputs of the trained NN model. In a and c
arbitrary performance measures and experimental groups were selected for comparison.

6 Results

The results of daily meta-parameter estimation indicated a good ﬁt between the model and animal
performance (Figure 3a). The condition P (χ2 , ν ) > 0.01 was satisﬁed for 92% of estimated param-
eter sets. The mean χ2 value was (cid:104)χ2 (cid:105) = 5.4, or only (cid:104)χ2 (cid:105) = 0.77 per PM.

Figure 4: Estimated daily meta-parameter values and differences between experimental conditions.
a. Exploitation factors β , strain, and stress. b. Reward discount factors γ and mouse strain. c.
Effects of noradrenergic manipulations (on days 3, 6, and 8).

5

Meta-parameters, estimated for each daily session, indicated interesting dynamics as well as some
profound differences depending on stress condition, animal’s strain, and noradrenergic manipula-
tion. During the process of learning, estimated exploitation-exploration factors β and future reward
discount factors γ showed progressive increase (Figure 4a,b; regression p < 0.001), meaning that
the better animals learn the task - the more accurately they use their knowledge for selecting ac-
tions, and the longer time horizon they can take into account. In addition, extrinsic stress increases
exploitation factors β for calm C57BL/6 mice (ANOVA p < 0.01) but not for anxious DBA/2
mice (Figure 4a). Reward discount factors γ were higher for C57BL/6 mice (Figure 4b, ANOVA
p < 0.001), indicating that anxious DBA/2 mice act more impulsively. Dynamics of the learning
rates and effects of stress on future reward discounting showed certain trends, however, for these
daily estimated values they were not signiﬁcant. For the pharmacological manipulations, two results
were signiﬁcant (Figure 4c): a decrease in noradrenaline led to reduced exploitation factors for the
anxious DBA/2 mice (ANOVA p < 0.001), and to increased reward discount factors for C57BL/6
mice (on day 3, t-test p < 0.01), suggesting that decreasing NA levels counteracts anxiety and
impulsivity.
A problem of daily estimated meta-parameters is their excessive ﬂexibility, allowing them to follow
everyday ups and downs of individual animal behaviour, many of which happen because of factors
unknown to the experimenter. This ”noise” often makes it difﬁcult to see the effects that known
factors (such as stress and strain) have on meta-parameter dynamics. Results of the trained NN
model for prediction of daily meta-parameters indicated that only about 25% of their variation could
be explained. However, the resulting meta-parameter averages for experimental groups indicated
a very good ﬁt with estimated daily meta-parameters (Figure 3c). It is also evident that different
meta-parameters can be predicted to a different extent: for the learning rates only a small part of
variation can be explained (M SE (α) = 0.92), while for exploitation and reward discount factors -
a substantial part (M SE (β ) = 0.72, M SE (γ ) = 0.62), showing that their values are more reliable
and more sensitive to modulatory inﬂuences. The comparison of NN training and validation errors
(Figure 5a) indicated that the effects of over-ﬁtting were negligible.

Figure 5: a. Typical training and validation errors for the NN model. b. Model simulations: inter-
actions between anxiety and noradrenaline in affecting exploitation factors β and reward discount
factors γ . c. Model simulations: interactions between rewards and misses in task performance. In b
and c light colors represent high meta-parameter values, dark colors - low values.

The meta-parameter prediction model allows us to analyze how (and how much) each modulatory
factor affects meta-parameters and what the interactions between factors are. This is particularly
useful for studying possibly non-linear interactions between continuous-valued factors, such as anx-
iety, motivation, and previous task performance. Results in Figure 5b,c describe such interactions.
The level of noise in the color plots indicate that previous task performance (Fig. 5c) has a rela-
tively strong inﬂuence on meta-parameters, compared to that of anxiety (Fig. 5b). Future reward
discounting is mainly affected by received rewards, while for exploitation factors misses also have
a signiﬁcant effect, supporting an observation that well trained animals (who receive many rewards
and make few misses) decrease their effort to perform quickly and accurately (Fig. 5c). Finally, anx-
iety and high noradrenaline levels act additively in lowering the reward discount factors, while their
effects on exploitation factors are more complex: for calm animals NA increase leads to higher ex-
ploitation, but for highly anxious animals (whose NA levels are already presumably high) increasing
NA does not improve their performance accuracy (Fig. 5b).

6

When comparing meta-parameter averages between various experimental conditions, the output of
the NN model ﬁts well the daily estimated values (Figure 3c), however, the dynamics become much
smoother and the error bars - much smaller, since they account only for known factors, included in
the NN input. While all meta-parameter effects observed when comparing daily estimated values are
reproduced, excluding unpredicted variability makes some additional effects statistically signiﬁcant.
For instance, it is evident (Figure 6a) that extrinsic stress decreases future reward discount factors
for the DBA/2 mice (ANOVA p < 0.01) and that the learning rates slightly decrease with learning,
particularly for the C57BL/6 mice (regression p < 0.01). The effects of the pharmacological ma-
nipulations of the noradrenergic system have been ”denoised” as well, and several additional effects
become evident (Figure 6b). For C57BL/6 mice, stress plays an important role in modulating effects
of NA: non-stressed mice increase their exploitation upon increased NA level (ANOVA p < 0.01),
and slightly decrease it upon decreased NA levels. Stressed mice do not show signiﬁcant changes
in exploitation factors. For DBA/2 mice, stimulating noradrenergic function does not lead to higher
exploitation factors (similarly to stressed C57BL/6 mice), but their future reward discounting is
sensitive to NA changes - the lower NA, the higher their γ values (ANOVA, p < 0.01).

Figure 6: ”Denoised” meta-parameters: outputs of the trained neural network model. Several ad-
ditional differences between experimental conditions become evident. a. Meta-parameters, stress,
and strain. b. Effects of noradrenergic manipulations (on days 3, 6, and 8).

7 Discussion

In this paper, we demonstrated that a simple RL model, whose parameters are controlled by a neural
network that uses the information about various modulatory inﬂuences, can successfully predict
mouse behaviour in the hole-box conditioning task. Compared to the conventional performance
measures, the resulting meta-parameters of our model showed more pronounced effects between
experimental groups and they have the additional advantage of being easier to relate to cognitive
processes. Moreover, the results of pharmacological manipulations provided supporting evidence
that RL meta-parameters are indeed related to neuromodulators such as noradrenaline.
The progressive increase of exploitation factors β and the decrease of learning rates α are consis-
tent with how the meta-parameters of artiﬁcial agents should presumably be controlled to achieve
optimal performance [14]. The increase in reward discount factors γ may have fundamental rea-
sons too, e.g. when exposed to a new environment, hungry animals may become anxious about the
uncertainty in the situation (whether they will be able to ﬁnd food to survive), which makes them
prefer immediate rewards to delayed ones. However, it may also be related to the speciﬁc reward
structure in the model. In order to stay in the hole for longer than 1 time step (and thus have a higher
chance to pick up the food) γ values should be much larger than 0.5. In addition, to avoid making
unnecessary ITI pokes (given that food is usually picked up during the trial response) γ values close
to 1.0 are necessary. For this reason, animal behavioural dynamics (e.g. when the mice start mak-
ing sufﬁciently long nose pokes, and when, if at all, they learn to avoid making ITI pokes) could
determine (or be determined by) the prevailing dynamics of γ -s.
Our speciﬁc results provide insights into biological mechanisms of stress, anxiety, behavioural per-
formance, and how they relate to formal RL quantities. Stress increased performance accuracy (β
factors) for the calm C57BL/6 mice, but not for the anxious DBA/2 mice. Similarly, increasing
noradrenaline levels had a positive effect on β -s only for the non-stressed C57BL/6 mice, but not for

7

the other groups, while decreasing NA levels had the strongest negative effect on β -s for the anxious
DBA/2 mice. This suggests that within a certain range (which is dependent on animal’s anxiety) per-
formance accuracy is determined by NA level. Outside this range, NA effects get saturated or may
even get reversed, as suggested by the inverse-U-shaped-relation theory of arousal/stress effects on
cognition [4]. The effects of stress, strain, and NA on future reward discounting indicate that stress,
high anxiety, and elevated noradrenaline are all detrimental for learning delayed future rewards.
However, since the effects of NA and stress on reward discount factors are more pronounced for
DBA/2 mice, γ -s might be sensitive to noradrenaline at higher levels than β -s are. It is also likely
that serotonin, mPFC, and other brain systems often implicated in processing of delayed rewards
[15, 19] may be interacting with stress and NA in controlling future reward discounting.
Although the basis of our hole-box behavioural prediction is a simple RL model with discrete states
and actions, it is not obvious that such a model could predict animal behaviour in other signiﬁcantly
more complex tasks. However, even in more complex models (involving continuous state-action
spaces, episodic memories, etc.), a RL-like module is likely to be central to their performance,
and a similar approach could be applied for controlling its meta-parameters based on numerous
modulatory inﬂuences. Further studies relating such meta-parameters to other neuromodulatory
systems and activation patterns of speciﬁc brain areas could provide interesting insights and may
prove to be an ultimate test-box for the biological relevance of such an approach.

References
[1] J. J. Kim and K. S. Yoon. Stress: metaplastic effects in the hippocampus. TINS, 21(12):505–9. 1998.
[2] C. Sandi, M. Loscertales, and C. Guaza. Experience-dependent facilitating effect of corticosterone on
spatial memory formation in the water maze. Eur J Neurosci., 9(4):637–42., Apr 1997.
[3] M. Joels, Z. Pu, O. Wiegert, M. S. Oitzl, and H. J. Krugers. Learning under stress: how does it work?
Trends Cogn Sci., 10(4):152–8. Apr 2006.
[4] G. Aston-Jones, J. Rajkowski, and J. Cohen. Locus coeruleus and regulation of behavioral ﬂexibility and
attention. Prog Brain Res., 126:165–82., 2000.
[5] A. J. Yu and P. Dayan. Uncertainty, Neuromodulation, and Attention. Neuron, 46:681–92, May 19 2005.
[6] A. Holmes, C. C. Wrenn, A. P. Harris, K. E. Thayer, and J. N. Crawley. Behavioral proﬁles of inbred
strains on novel olfactory, spatial and emotional tests for reference memory in mice. Genes Brain Behav.,
1(1):55–69., Jan 2002.
[7] M. J. Kreek, D. A. Nielsen, E. R. Butelman, and K. S. LaForge. Genetic inﬂuences on impulsivity, risk
taking, stress responsivity and vulnerability to drug abuse and addiction. Nat Neurosci., 8:1450–7, 2005.
[8] P. Dayan and B. W. Balleine. Reward, Motivation, and Reinforcement Learning. Neuron, 36:285–98, 2002.
[9] M. M. Botvinick, T. S. Braver, C. S. Carter, D. M. Barch, and J. D. Cohen. Conﬂict monitoring and
cognitive control. Psychol Review,108(3):624–52, Mar 2001.
[10] R. Sutton and A. G. Barto. Reinforcement Learning - An Introduction. MIT Press, 1998.
[11] W. Schultz, P. Dayan, and P. R. Montague. A neural substrate of prediction and reward. Science,
275(5306):1593–9, Mar 14 1997.
[12] S. C. Tanaka, K. Doya, G. Okada, K. Ueda, Y. Okamoto, and S. Yamawaki. Prediction of immediate
and future rewards differentially recruits cortico-basal ganglia loops. Nat Neurosci., 7:887–93, Jul 2004.
[13] A. D. Redish. Addiction as a Computational Process Gone Awry. Science., 306(5703):1944–7, 2004.
[14] K. Doya. Metalearning and neuromodulation. Neural Netw, 15(4-6):495–506, Jun-Jul 2002.
[15] K. Doya. Modulators of decision making. Nat Neurosci., 11:410–6, Apr 2008.
[16] Y. Clement, C. Joubert, C. Kopp, E. M. Lepicard, P. Venault, R. Misslin, M. Cadot, and G. Chapouthier
Anxiety in Mice: A Principal Component Analysis Study. Neural Plast., 35457, Mar 21 2007.
[17] W. H. Press, B. P. Flannery, S. A. Teukolsky, and W. T. Vetterling. Numerical Recipes in C : The Art of
Scientiﬁc Computing. Cambridge University Press, 1992.
[18] D. Marquardt. An algorithm for least squares estimation of nonlinear parameters. SIAM J. Appl. Math,
11:431–441, 1963.
[19] J. Amat, M. V. Baratta, E. Paul, S. T. Bland, L. R. Watkins, and S. F. Maier. Medial prefrontal cortex
determines how stressor controllability affects behavior and dorsal raphe nucleus. Nat Neurosci., 8(3):365–
71. Mar 2005.

8

