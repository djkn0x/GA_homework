M AC H IN E L EA R N ING FO R G EN E B EHAV IOUR C LA S S I FICAT ION

Karan Mangla Arunanshu Roy

December 12, 2008

Abstract

An interesting problem in biology is to determine the ac-
tivation phase of genes. The human body contains nearly
20,000 genes. Many of these genes play a wide variety of
roles in the cell cycle. Identifying the phase of activation
of the gene can help determine its function in the gene.
Experimentally determining the phase of all these genes
can be expensive. Our tool attempts to use machine learn-
ing to determine the activation phase of a gene based on
its expression pro ﬁle. We ﬁrst normalize the genes to be
able to capture activation and deactivation. Next we apply
SVM on this dataset using a small number of preclassi-
ﬁed genes as our training set. Since genes can be active in
multiple phases, we created a separate classiﬁer for each
activation phase.

12

10

8

6

4

2

a
t
a
d
 
)
S
1
G
(
 
2
E
N
C
C
 
d
n
a
 
)
M
2
G
(
 
2
B
N
C
C

CCNB2 (G2M) vs BUB1B (G2M)
CCNE2 (G1S) vs BUB1B (G1S)

0

1

2

3

4
8
7
6
5
BUB1B (G2M) microarray data

9

10

11

Figure 1: Plot of BUB1B (G2M) data vs CCNB2 (G2M)
and CCNE2 (G1S) data

1

Introduction

2 Errors in data

The cell cycle is one of the most important gene processes,
involving a large number of genes in a wide variety of
functions. Gene transcription in the cell cycle occurs in
phases, with each phase having its own speciﬁc transcrip-
tion factors. Understanding the genes involved in each
phase, would provide a better understanding of the cell cy-
cle and also make it easier to identify the function of the
gene. Running experiments to ﬁnd the phase for all 20,000
genes would be quite time consuming. Our tool provides a
fast machine learning approach to classify genes to cell cy-
cle phases, based on their expression pro ﬁles in microar-
ray experiments.
Our data consist of 4,787 Affymetrix U133Plus 2.0 hu-
man microarrays [4]. The datasets were normalized using
the standard Robust Multi-chip Analysis(RMA) [3]. In to-
tal, we have 57,000 gene pro ﬁles, as genes are associated
to multiple probes. We have also obtained set of 607 genes
classiﬁed into cell cycle activation phases, correspondin g
to 1712 probes in the microarray. Genes were classiﬁed
into the G1/S, G2, G2/M, M/G1 and S cell cycle phases.
As can be observed in Figure 1, genes in similar phases
appear to be correlated while genes in different phases are
less so.

One of the major issues in tackling this problem is the
inaccuracy of the data. There are various reasons for errors
in the data.

• Errors in Expression Pro ﬁles: While the expression
data was carefully collected there are many sources
of errors in this data. Firstly, the experiments were
not conducted on synchronized cultures. Hence the
cultures would have contained a mixture of cells in
different phases at time of collection of expression
data. This will greatly reduce the strength of phase
signal in the expression pro ﬁles
Further, microarray analysis suffers from errors due
to dead probes and other problems that corrupt the
expression pro ﬁles.

• Errors in classiﬁed data: Our collection of classiﬁed
genes are also expected to have errors due to the dif-
ﬁculty in experimentally classifying genes. It is esti-
mated that 20% of our classiﬁed genes are incorrectly
placed into activation phases. This will also greatly
hamper the accuracy of the algorithm.

1

3 Experimental Procudure

We split our data randomly into 80% training data and
20% test data. All algorithms were trained and tested only
on the training data. Testing of algorithms was done by
creating a hold-out data set which was used to evaluate the
model learned by the algorithm on the remaining training
set. Our best algorithm was then veriﬁed on the 20% test
data.

4 GDA

We ﬁrst applied GDA to the problem. We used the simple
GDA algorithm to the data. However, running the GDA al-
gorithm over the entire data gave a covariance matrix that
was nearly singular, making the calculation error-prone.
Using standard PCA analysis we reduced dimensionality
of the input data. After running PCA, the top k compo-
nents were chosen as input for the learning algorithm.
In order to measure our results, we chose to compare
precision and recall rather than accuracy. Since for each
phase the proportion of genes not active in that phase are
much larger than the proportion of genes active in that
phase, even classifying all the genes as not active in the
phase gives high accuracy, which is not actually desirable.
We observed that our system had high variance. To re-
duce the number of parameters in the system and prevent
over ﬁtting, we applied the Naive Bayes Assumption on
our data. P (x(i) |y = 1) and P (x(i) |y = 0) were modeled
as Gaussian distribution which were independent for all
i. Thus the number of parameters learned is reduced and
prevents over ﬁtting.
This method was applied for a variety of number of in-
put parameters. The results have been shown in Figure
2. We have plotted precision and recall values obtained in
the different runs. We observe that the overall F-values are
very low for GDA. This is expected since our features are
unlikely to be independent.

5 Bayesian Logistic Regression

Since generative algorithms were performing quite poorly
on our problem we attempted to apply discriminative al-
gorithms. We applied Bayesian logistic regression using
an online software [2].
We observed improved results suggesting that our data
cannot be represented as a Gaussian distribution. Note
that while the individual values of the precision and re-
call are not higher than those observed in the earlier al-
gorithms, the F-value of our results is much better. The
Table 1 provides a tradeoff between precision and recall
using Bayesian Logistic Regression for the G2M phase.

2

Precision Recall Curve for GDA

0.65

0.6

0.55

0.5

n
o
i
s
i
c
e
r
P

0.45

0.4

0.35

0.3

0.25

0.2
0.2

0.25

0.3

0.35

0.4

0.45
Recall

0.5

0.55

0.6

0.65

Figure 2: GDA results for classiﬁcation of G2M genes

recall
73.7
57.8
51.9
44.8
11.0

precision
51.6
54.6
55.9
57.5
70.8

Table 1: Precision and Recall Tradeoff for Logistic Re-
gression

We used Pearsons correlation to try to select good fea-
tures for this dataset. However, as can be seen from from
Table 2 feature reduction did not improve our results, im-
plying that most features are useful in evaluating the acti-
vation phase of the gene.

6 Support Vector Machines

Support vector machines were used to attempt classica-
tion of the genes due to their inherent advantage in deal-
ing with large feature spaces and large training sets. SVMs
also give us the option of trying out different kernels that
suit our data and has the advantage of handling outliers
through the use of regularization. SVM software written

k
200
500
800
1000

recall
53.2
55.2
53.9
54.50

precision
47.4
51.2
47.4
49.4

Table 2: Precision and Recall for different number of fea-
tures

Phase Recall
G1S
61
46
MG1
G2M
58

Precision
53
39
54

Table 3: SVM based classiﬁcation results on hold out set

in MATLAB [1] which is available online was used for
these simulations. The ﬁrst classication of G1S genes was
done using a linear kernel. The results from the SVM were
superior to the other supervised learning techiniques that
we tried. We achieved a precision of 55% and a recall of
52%. We then used a modiﬁed kernel using the Pearson
correlation between feature vectors. This improved our
precision to 58% and recall to 54%.
All the 4787 features were used in these computations.
However some feature reduction techniques have been
tried on this data as explained in the next section and we
observed that similar precision and recall can be achived
with fewer features but there is no signiﬁcant improve-
ment using feature reduction. The results were not af-
fected by value of C lying between 1 and 100 and the value
of the regularization parameter is chosen to be 100. Table
3 shows the results for classication of three phases using
this scheme. We get the best results for G2M and G1S
phases for which we have the largest amount of classiﬁed
genes.

)
%
(
 
l
l
a
c
e
R
 
d
n
a
 
n
o
i
s
i
c
e
r
P

100

90

80

70

60

50

40

30

20

10

0
−3

−2

−1

0
Threshold value

1

2

3

Figure 3: Precision and Recall for G2M classiﬁcation us-
ing SVM

7 Feature selection

Number of features used Recall
100
55
51
300
48
500
1000
49

Precision
45
49
47
44

Table 4: SVD based feature reduction results on hold out
set

Rank Recall
100
48
51
100
46
200
500
58

Precision
51
59
42
54

Table 5: Low rank approximation denoising results

G2M since the largest amount of data is available for that
class.

7.1 SVD based feature selection

Singular Value Decomposition was used to select a re-
duced set of features for classiﬁcation. It was observed
that reducing the number of features did not help to im-
prove the classiﬁcation of genes in G2M. The results are
summarised in Table 4.

7.2 Low rank approximations to denoise
training data

Using singular value decomposition on training data, low
rank aproximations were obtained. We expect this to help
reduce the noise that may be present in the training data.
The results however showed that this method of denoising
did not improve classiﬁcation. The results are summarised
in Table 5.

7.3 Removing low variance data to ﬁlter out
dead probes

The microarray data was ﬁltered to remove genes for
which the data showed a low variance. We believe that
this can be indicative of a dead probe and hence using a
minimum threshold variance, the data was ﬁltered to re-
move probes with a low variance in measurements. No
signiﬁcant improvement could be obtained with this tech-
nique. The results are summarised in Table 6.

Since the best results obtained could only achieve about
60% precision and recall on the data we tried feature se-
lection and data cleaning techniques to improve classiﬁ-
cation.. The results are for the classiﬁcation of genes in

8 K-Nearest Neighbors

Given that linear classiﬁers such as SVM and logistic re-
gression were working very poorly on this data, we tried

3

Correlation threshold Recall
0.1
56
52
0.2
0.3
46

Precision
51
48
44

Table 6: Low variance ﬁltering results

Phase
G1S
G2
MG1
S
G2M

F-Value
54.3
35.9
45.5
37.0
57.7

Table 7: Precision and Recall for each Phase for 1-NN

non-linear classiﬁers in an attempt to improve the accu-
racy of our classiﬁcation. One classiﬁer that we consid-
ered was 1-NN. This classiﬁer would help reduce the inac-
curacy caused by classiﬁcation errors in our training set as
it uses more local characteristics to learn models. We ran
this algorithm using the Weka software [5]. 1-NN however
performed quite purely on our problem. We have provided
the per phase F-values in Table 7 received for 10-fold cross
validation.

9 Decision Trees

Another popular non-linear classiﬁer is Decision trees. We
tested whether using simple decision trees would allow
our data to improve. Again we observed quite poor re-
sults. We tried to apply the ADA Boost algorithm to im-
prove our decision trees. However, their was very little
improvement in classiﬁcation. Both these algorithms were
run using Weka implementations [5].
Results obtained for ADA Boost for various boost iter-
ations are given in Table 8. Classiﬁcation was only done
for the G2M phase of the cell cycle.

No. of Iterations
10
30
50

Precision Recall
38.3
46.2
44.5
46
48.2
43

10 Discussion on Data

Since no improvment could be obtained through the above
feature selection and data denoising techniques we at-
tempted to understand the data better through a study of
correlation among data belonging to different classes. It
appears that while genes belonging to the same activation
phase are often well correlated, there may be a good cor-
relation with genes belong to other activation phases too.
The plots here show the correlation between the genes
classiﬁed as G2M and those classiﬁed as G1S. The corre-
lation between G2M and G1S genes is also shown. We see
that several genes in G1S are well correlated with genes
classiﬁed as G2M. This illustrates why the classiﬁcation
of genes based on the available microarray data is inher-
ently a difﬁcult problem. Given that the data may contain
misclassiﬁed genes and other sources of noise we believe
that it is difﬁcult to achieve better classiﬁcation using th
is
data.

Visualization of correlation matrix for G1S

140

120

100

80

60

40

20

S
1
G
 
n
i
 
s
e
n
e
G

0.8

0.6

0.4

0.2

0

−0.2

−0.4

20

40

60

80
Genes in G1S

100

120

140

Figure 4: Correlation between G1S genes

11 Final Results

Having noted that the SVM and the Bayesian Logistic re-
greassion perform best in classifying our data. we ran the
classiﬁcation on the initially described test set. THe SVM
achieved a precison of 56% and a recall of 60% while the
Bayesoan logistic regression showed a precision of 57%
and 59% recall.

12 Conclusion

Table 8: Precision and Recall for different number of
Boosting Iteration in ADA-Boost

As we can observe the data is very noisy. Hence, we
get better classiﬁcation results from linear classiﬁers th
an

4

140

120

100

80

60

40

20

M
2
G
 
n
i
 
s
e
n
e
G

140

120

100

80

60

40

20

M
2
G
 
n
i
 
s
e
n
e
G

Visualization of correlation matrix for G2M

20

40

60

80
Genes in G2M

100

120

140

Figure 5: Correlation between G2M genes

Visualization of correlation matrix

20

40

60

80
Genes in G1S

100

120

140

non-linear classiﬁers. The best results are obtained on us-
ing SVM’s on this data. Normalization of the data helps
give a small increase in accuracy of the classiﬁer. How-
ever, feature selection techniques completely fails on this
dataset, suggesting that most features are important for
classiﬁcation. Finally, attempts to denoise the data were
also not successful.
We, however, noted that results improved as the num-
ber of training examples for a phase that we could provide
increased. This suggests that with a larger training set this
system would provide increased accuracy. Another major
problem with this data is the fact that there are errors in the
classiﬁcation of the training set. A more accurate training
set should also boost the usefulness of this system
While there are a lot of problems with misclassiﬁcation,
we see that we do get good results which means that using
this algorithm to pre ﬁlter genes will help to classify genes
in to their correct phases. It is important to note that of
the 57,000 gene probes only 1712 have been classiﬁed as
yet. Thus we believe that inspite of the modest precison
and recall attained, the tool can be used to classify a large
number of genes and greatly increment the current infor-
mation on the activation phases and roles of genes in the
cell cycle.

References

[1] S. Canu, Y. Grandvalet, V. Guigue, and A. Rako-
tomamonjy. Svm and kernel methods matlab toolbox.
Perception Systmes et Information, INSA de Rouen,
Rouen, France, 2005.

[2] Alexander Genkin, David D. Lewis, and David Madi-
gan. Bbr: Bayesian logistic regression software.

[3] R. A. Irizarry, B. M. Bolstad, F. Collin, L. M. Cope,
B. Hobbs, and T. P. Speed. Summaries of affymetrix
genechip probe level data. Nucleic Acids Res, 31(4),
February 2003.

[4] Debashis Sahoo, David L. Dill, Andrew J. Gentles,
Robert Tibshirani, and Sylvia K. Plevritis. Boolean
implication networks derived from large scale, whole
genome microarray datasets.
Genome Biology,
9:R157+, October 2008.

[5] Ian H. Witten, Eibe Frank, Len Trigg, Mark Hall,
Geoffrey Holmes, and Sally Jo Cunningham. The
waikato environment for knowledge analysis.

0.8

0.6

0.4

0.2

0

−0.2

−0.4

0.8

0.6

0.4

0.2

0

−0.2

−0.4

−0.6

Figure 6: Correlation between G1S and G2M genes

5

