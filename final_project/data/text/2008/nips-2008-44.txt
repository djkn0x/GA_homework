Exact Convex Conﬁdence-Weighted Learning

Koby Crammer Mark Dredze Fernando Pereira∗
Department of Computer and Information Science , University of Pennsylvania
Philadelphia, PA 19104
{crammer,mdredze,pereira}@cis.upenn.edu

Abstract

Conﬁdence-weighted (CW) learning [6], an online learning method for linear clas-
siﬁers, maintains a Gaussian distributions over weight vectors, with a covariance
matrix that represents uncertainty about weights and correlations. Conﬁdence
constraints ensure that a weight vector drawn from the hypothesis distribution
correctly classiﬁes examples with a speciﬁed probability. Within this framework,
we derive a new convex form of the constraint and analyze it in the mistake bound
model. Empirical evaluation with both synthetic and text data shows our version of
CW learning achieves lower cumulative and out-of-sample errors than commonly
used ﬁrst-order and second-order online methods.

1

Introduction

Online learning methods for linear classiﬁers, such as the perceptron and passive-aggressive (PA)
algorithms [4], have been thoroughly analyzed and are widely used. However, these methods do not
model the strength of evidence for different weights arising from differences in the use of features
in the data, which can be a serious issue in text classiﬁcation, where weights of rare features should
be trusted less than weights of frequent features.
Conﬁdence-weighted (CW) learning [6], motivated by PA learning, explicitly models classiﬁer
weight uncertainty with a full multivariate Gaussian distribution over weight vectors. The PA ge-
ometrical margin constraint is replaced by the probabilistic constraint that a classiﬁer drawn from
the distribution should, with high probability, classify correctly the next example. While Dredze
et al. [6] explained CW learning in terms of the standard deviation of the margin induced by the
hypothesis Gaussian, in practice they used the margin variance to make the problem convex. In this
work, we use their original constraint but maintain convexity, yielding experimental improvements.
Our primary contributions are a mistake-bound analysis [11] and comparison with related methods.
We emphasize that this work focuses on the question of uncertainty about feature weights, not on
conﬁdence in predictions. In large-margin classiﬁcation, the margin’s magnitude for an instance
is sometimes taken as a proxy for prediction conﬁdence for that instance, but that quantity is not
calibrated nor is it connected precisely to a measure of weight uncertainty. Bayesian approaches to
linear classiﬁcation, such as Bayesian logistic regression [9], use a simple mathematical relationship
between weight uncertainty and prediction uncertainty, which unfortunately cannot be computed
exactly. CW learning preserves the convenient computational properties of PA algorithms while
providing a precise connection between weight uncertainty and prediction conﬁdence that has led to
weight updates that are more effective in practice [6, 5].
We begin with a review of the CW approach, then show that the constraint can be expressed in a
convex form, and solve it to obtain a new CW algorithm. We also examine a dual representation
that supports kernelization. Our analysis provides a mistake bound and indicates that the algorithm
is invariant to initialization. Simulations show that our algorithm improves over ﬁrst-order methods
∗Current afﬁliation: Google, Mountain View, CA 94043, USA.

1

(perceptron and PA) as well as other second order methods (second-order perceptron). We conclude
with a review of related work.

2 Conﬁdence-Weighted Linear Classiﬁcation

The CW binary-classiﬁer learner works in rounds. On round i, the algorithm applies its current
linear classiﬁcation rule hw (x) = sign(w · x) to an instance xi ∈ Rd to produce a prediction
ˆyi ∈ {−1, +1}, receives a true label yi ∈ {−1, +1} and suffers a loss !(yi , ˆyi ). The rule hw can be
identiﬁed with w up to a scaling, and we will do so in what follows since our algorithm will turn out
to be scale-invariant. As usual, we deﬁne the margin of an example on round i as mi = yi (w i · xi ),
where positive sign corresponds to a correct prediction.
CW classiﬁcation captures the notion of conﬁdence in the weights of a linear classiﬁer with a prob-
ability density on classiﬁer weight vectors, speciﬁcally a Gaussian distribution with mean µ ∈ Rd
and covariance matrix Σ ∈ Rd×d . The values µp and Σp,p represent knowledge of and conﬁdence
in the weight for feature p. The smaller Σp,p , the more conﬁdence we have in the mean weight value
µp . Each covariance term Σp,q captures our knowledge of the interaction between features p and q .
In the CW model, the traditional signed margin is the mean of the induced univariate Gaussian
random variable
M ∼N !y(µ · x), x#Σx" .
(1)
This probabilistic model can be used for prediction in different ways. Here, we use the average
weight vector E [w ] = µ, analogous to Bayes point machines [8]. The information captured by the
covariance Σ is then used just to adjust training updates.

3 Update Rule

min

The CW update rule of Dredze et al. [6] makes the smallest adjustment to the distribution that
ensures the probability of correct prediction on instance i is no smaller than the conﬁdence hyper-
parameter η ∈ [0, 1]: Pr [yi (w · xi ) ≥ 0] ≥ η . The magnitude of the update is measured by its KL
divergence to the previous distribution, yielding the following constrained optimization:
(µi+1 , Σi+1 ) = arg min
DKL (N (µ, Σ) %N (µi , Σi ))
s.t. Pr [yi (w · xi ) ≥ 0] ≥ η.
(2)
µ,Σ
They rewrite the above optimization in terms of the standard deviation as:
(µi − µ)& s.t. yi (µ · xi ) ≥ φ’x#i Σxi .
det Σ % + Tr !Σ−1
2 #log $ det Σi
1
i Σ" + (µi − µ)# Σ−1
i
(3)
is not convex in Σ.
Unfortunately, while the constraint of this problem is linear in µ,
it
Dredze et al. [6, eq. (7)] circumvented that lack of convexity by removing the square root from
the right-hand-size of the constraint, which yields the variance. However, we found that the origi-
nal optimization can be preserved while maintaining convexity with a change of variable. Since Σ
is positive semideﬁnite (PSD), it can be written as Σ=Υ 2 with Υ= Qdiag(λ1/2
, . . . , λ1/2
)Q#
1
d
where Q is orthonormal and λ1 , . . . , λd are the eigenvalues of Σ; Υ is thus also PSD. This change
yields the following convex optimization with a convex constraint in µ and Υ simultaneously:
log $ det Υ2
det Υ2 % +
1
1
1
Tr !Υ−2
i Υ2 " +
(µi − µ)# Υ−2
(µi − µ)
(µi+1 , Υi+1 ) = arg min
i
2
2
2
i
s.t. yi (µ · xi ) ≥ φ%Υxi %
, Υ is PSD .
We call our algorithm CW-Stdev and the original algorithm of Dredze et al. CW-Var.

(4)

3.1 Closed-Form Update

While standard optimization techniques can solve the convex program (4), we favor a closed-form
solution. Omitting the PSD constraint for now, we obtain the Lagrangian for (4),
(µi − µ))+α (−yi (µ · xi ) + φ%Υxi %)
2 (log $ det Υ2
det Υ2 % + Tr !Υ−2
1
i Υ2 " + (µi − µ)# Υ−2
L =
i
i
(5)
2

Input parameters a > 0 ; η ∈ [0.5, 1]
Initialize µ1 = 0 , Σ1 = aI , φ =Φ −1 (η) ,ψ = 1 + φ2 /2 ,ξ = 1 + φ2 .
For i = 1, . . . , n
• Receive a training example xi ∈ Rd
• Compute Gaussian margin distribution Mi ∼N ` (µi · xi ) , `x#i Σixi ´ ´
• Receive true label yi and compute
i φ2 + 4vi«2
4 „−αviφ + qα2 v2
1
vi = x#i Σixi , mi = yi (µi · xi ) (11)
, ui =
αi = max (0,
+ viφ2 ξ!) (14)
vi ξ  −miψ + rm2
φ4
1
αiφ
√ui + viαiφ
,β i =
i
4
• Update
µi+1 = µi + αi yiΣixi
Σi+1 =Σ i − βiΣixix#i Σi
Σi+1 = „Σ−1
diag2 (xi )«−1
i + αiφu− 1
2
i
Output Gaussian distribution N `µn+1 , Σn+1 ´.
Figure 1: The CW-Stdev algorithm. The numbers in parentheses refer to equations in the text.

(diag)

(full)

(12)

(22)

(10)

(15)

+ αφ

Υ−2
i Υ+

ΥΥ−2
i + αφ

µi+1 = µi + αyiΥ2
i xi ,

∂
∂Υ L = −Υ−1 +
from which we obtain the implicit-form update

At the optimum, it must be that
∂
∂µ L =Υ −2
(µ − µi ) − αyixi = 0
⇒
i
where we assumed that Υi is non-singular (PSD). At the optimum, we must also have,
1
1
xix#i Υ
Υxix#i
2*x#i Υ2xi
2*x#i Υ2xi
2
2
xix#i
’x#i Υ2
i+1xi
Conveniently, these updates can be expressed in terms of the covariance matrix 1 :
xix#i
*x#i Σi+1xi
i+1 as the sum of a rank-one PSD matrix and Σ−1
We observe that (9) computes Σ−1
. Thus, if Σ−1
has
i
i
strictly positive eigenvalues, so do Σ−1
i+1 and Σi+1 . Thus, Σi and Υi are indeed PSD non-singular,
as assumed above.

µi+1 = µi + αyiΣixi

i+1 =Υ −2
Υ−2
i + αφ

i+1 =Σ −1
Σ−1
i + αφ

= 0 ,

(7)

(6)

(8)

(9)

.

,

.

3.2 Solving for the Lagrange Multiplier α

We now determine the value of the Lagrange multiplier α and make the covariance update explicit.
We start by computing the inverse of (9) using the Woodbury identity [14, Eq. 135] to get
*x#i Σi+1xi + x#i Σixiαφ , x#i Σi . (10)
*x#i Σi+1xi ,−1
Σi+1 = +Σ−1
=Σ i − Σixi +
xix#i
αφ
i + αφ
Let
ui = x#i Σi+1xi
vi = x#i Σixi
, mi = yi (µi · xi ) .
(11)
,
1Furthermore, writing the Lagrangian of (3) and solving it would yield the same solution as Eqns. (9). Thus
the optimal solution of both (3) and (4) are the same.

3

Multiplying (10) by x#i
solved for ui to obtain

αφ√ui+viαφ . vi , which can be
(12)

(left) and xi (right) we get ui = vi − vi -
√ui = −αviφ + *α2 v2
i φ2 + 4vi
.
2
The KKT conditions for the optimization imply that either α = 0 and no update is needed, or the
constraint (4) is an equality after the update. Using the equality version of (4) and Eqs. (9,10,11,12)
we obtain mi + αvi = φ −αvi φ+√α2 v2
i φ2+4vi
, which can be rearranged into a quadratic equation
i !1 + φ2 " + 2αmi vi -1 + φ2
2 . + !m2
2
i − viφ2 " = 0 . The smaller root of this equation
in α: α2 v2
is always negative and thus not a valid Lagrange multiplier. We use the following abbreviations for
ξ = 1 + φ2 . The larger root is then
writing the larger root γi : ψ = 1 + φ2 /2
;
γi = −mi viψ + *m2
i ψ (m2
i − viφ2 )
i v2
i ψ2 − v2
(13)
.
v2
i ψ
The constraint (4) is satisﬁed before the update if mi − φ√vi ≥ 0. If mi ≤ 0, then mi ≤ φ√vi and
from (13) we have that γi > 0. If, instead, mi ≥ 0, then, again by (13), we have
γi > 0 ⇔ mi viψ< ’m2
i − viφ2 ) ⇔ mi < φvi .
i ψ (m2
i ψ2 − v2
i v2
From the KKT conditions, either αi = 0 or (3) is satisﬁed as an equality and αi = γi > 0. We
summarize the discussion in the following lemma:
Lemma 1 The solution of (13) satisﬁes the KKT conditions, that is either αi ≥ 0 or the constraint
of (3) is satisﬁed before the update with the parameters µi and Σi .
We obtain the ﬁnal form of αi by simplifying (13) together with Lemma 1,
−miψ + ’m2
max 

i
0,
ξ
To summarize, after receiving the correct label yi the algorithm checks whether the probability of a
correct prediction under the current parameters is greater than a conﬁdence threshold η = Φ(φ). If
so, it does nothing. Otherwise it performs an update as described above. We initialize µ1 = 0 and
Σ1 = aI for some a > 0. The algorithm is summarized in Fig. 1.
Two comments are in order. First, if η = 0.5, then from Eq. (9) we see that only µ will be updated,
not Σ, because φ = 0 ⇔ η = 0.5. In this case the covariance Σ parameter does not inﬂuence the
decision, only the mean µ. Furthermore, for length-one input vectors, at the ﬁrst round we have
Σ1 = aI , so the ﬁrst-round constraint is yi (wi · xi ) ≥ a %xi %2 = a, which is equivalent to the
original PA update.
Second, the update described above yields full covariance matrices. However, sometimes we may
prefer diagonal covariance matrices, which can be achieved by projecting the matrix Σi+1 that
results from the update onto the set of diagonal matrices.
In practice it requires setting all the
off-diagonal elements to zero, leaving only the diagonal elements. In fact, if Σi is diagonal then we
only need to project xix#i
to a diagonal matrix. We thus replace (9) with the following update,
αi√ui
where diag2 (xi ) is a diagonal matrix made from the squares of the elements of xi on the diagonal.
Note that for diagonal matrices there is no need to use the Woodbury equation to compute the inverse,
as it can be computed directly element-wise. We use CW-Stdev (or CW-Stdev-full) to refer to the
full-covariance algorithm, and CW-Stdev-diag to refer to the diagonal-covariance algorithm.
Finally, the following property of our algorithm shows that it can be used with Mercer kernels:

i+1 =Σ −1
Σ−1
i + φ

diag2 (xi ) ,

(15)

1
vi

φ4
4 + viφ2 ξ

.

(14)

4

Theorem 2 (Representer Theorem) The mean µi and covariance Σi parameters computed by the
algorithm in Fig. 1 can be written as linear combinations of the input vectors with coefﬁcients that
depend only on inner products of input vectors:
i−15p
i−15p,q=1
The proof, given in the appendix, is a simple induction.

p,q xpx#q + aI
π (i)

ν (i)
p xp .

µi =

Σi =

(16)

,

4 Analysis

We analyze CW-Stdev in two steps. First, we show that performance does not depend on initializa-
tion and then we compute a bound on the number of mistakes that the algorithm makes.

4.1

Invariance to Initialization

The algorithm in Fig. 1 uses a predeﬁned parameter a to initialize the covariance matrix. Since the
decision to update depends on the covariance matrix, which implicitly depends on a through αi and
vi , one may assume that a effects performance. In fact the number of mistakes is independent of
a, i.e. the constraint of (3) is invariant to scaling. Speciﬁcally, if it holds for mean and covariance
parameters µ and Σ, it holds also for the scaled parameters cµ and c2Σ for any c > 0. The following
lemma states that the scaling is controlled by a. Thus, we can always initialize the algorithm with a
value of a = 1. If, in addition to predictions, we also need the distribution over weight vectors, the
scale parameter a should be calibrated.

Lemma 3 Fix a sequence of examples (x1 , y1 ) . . . (xn , yn ). Let Σi , µi , mi , vi ,α i , ui be the quan-
tities obtained throughout the execution of the algorithm described in Fig. 1 initialized with (0, I )
(a = 1). Let also ˜Σi , ˜µi , ˜mi , ˜vi , ˜αi , ˜ui be the corresponding quantities obtained throughout the exe-
cution of the algorithm, with an alternative initialization of (0, aI ) (for some a > 0). The following
relations between the two set of quantities hold:
1
˜mi = √ami , ˜vi = avi , ˜αi =
αi , ˜µi = √aµi , ˜ui = aui , ˜Σi = aΣi .
√a

(17)

Proof sketch: The proof proceeds by induction. The initial values of these quantities clearly satisfy
the required equalities. For the induction step we assume that (17) holds for some i and show that
these identities also hold for i + 1 using Eqs. (9,14,11,12) .
From the lemma we see that the quantity ˜mi /√˜vi = mi /√vi is invariant to a. Therefore, the
behavior of the algorithm in general, and its updates and mistakes in particular, are independent to
the choice of a. Therefore, we assume a = 1 in what follows.

4.2 Analysis in the Mistake Bound Model

The main theorem of the paper bounds the number of mistakes made by CW-Stdev.

Theorem 4 Let (x1 , y1 ) . . . (xn , yn ) be an input sequence for the algorithm of Fig. 1, initialized
with (0, I ), with xi ∈ Rd and y i ∈ {−1, +1} . Assume there exist µ∗ and Σ∗ such that for all i for
which the algorithm made an update (αi > 0),
µ∗#xi yi ≥ µ#i+1xi yi
and x#i Σ∗xi ≤ x#i Σi+1xi
Then the following holds:
-− log det Σ∗ + Tr (Σ∗ ) + µ∗#Σ−1
n+1µ∗ − d.
no. mistakes ≤ 5i

1 + φ2
φ2

α2
i vi ≤

(19)

(18)

.

5

200
180
160
140
120
100
80
60
40
20

s
s
o
L
 
e
v
i
t
a
l
u
m
u
C

(a)

Perceptron
PA
2nd Ord
Std−diag
Std−full
Var−diag
Var−full

 

r
o
r
r
E
 
t
s
e
T

9

8

7

6

5

4

3

2

1

 

100

200

300

400

500
Round

600

700

800

900 1000

0
(b)

Perceptron PA 2nd OrderStd−diag Std−full Var−diag Var−full

1.00

0.95

0.90

0.85

0.80

y
c
a
r
u
c
c
A
 
v
e
d
t
S

(c)

Reuters
Sentiment
20 Newsgroups

0.80

0.85
0.90
Variance Accuracy

0.95

1.00

Figure 2: (a) The average and standard deviation of the cumulative number of mistakes for seven
algorithms. (b) The average and standard deviation of test error (%) over unseen data for the seven
algorithms. (c) Comparison between CW-Stdev-diag and CW-Var-diag on text classiﬁcation.

The proof is given in the appendix.
The above bound depends on an output of the algorithm, Σn+1 , similar to the bound for the second-
order perceptron [3]. The two conditions (18) imply linear separability of the input sequence by
µ∗ :
≥ φ’x#i Σi+1xi
(4)
(18)
(18)
µ∗#xi yi
x#i Σ∗xi > 0 ,
≥ x#i Σ∗xi ≥ min
≥ µ#i+1xi yi
i
where the superscripts in parentheses refer to the inequalities used. From (10), we observe that
Σi+1 * Σi for all i, so Σn+1 * Σi+1 * Σ1 = I for all i. Therefore, the conditions on Σ∗ in (18)
are satisﬁed by Σ∗ =Σ n+1 . Furthermore, if µ∗ satisﬁes the stronger conditions yi (µ∗ · xi ) ≥ %xi %,
from Σi+1 * I above it follows that
(φµ∗ )#xi yi ≥ φ%xi % = φ’x#i I xi ≥ φ’x#i Σi+1xi = µ#i+1xi yi ,
where the last equality holds since we assumed that an update was made for the ith example. In this
situation, the bound becomes
(− log det Σn+1 + Tr (Σn+1 ) − d) + (φ2 + 1) -µ∗#Σ−1
n+1µ∗. .
φ2 + 1
φ2
n+1µ∗ in this bound is analogous to the quantity R2 %µ∗ %2 in the perceptron
The quantity µ∗#Σ−1
bound [13], except that the norm of the examples does not come in explicitly as the radius R of the
enclosing ball, but implicitly through the fact that Σ−1
n+1 is a sum of example outer products (9). In
addition, in this version of the bound we impose a margin of 1 under the condition that examples
have unit norm, whereas in the perceptron bound, the margin of 1 is for examples with arbitrary
norm. This follows from the fact that (4) is invariant to the norm of xi .

5 Empirical Evaluation

We illustrate the beneﬁts of CW-Stdev with synthetic data experiments. We generated 1, 000 points
in R20 where the ﬁrst two coordinates were drawn from a 45◦ rotated Gaussian distribution with
standard deviation 1. The remaining 18 coordinates were drawn from independent Gaussian distri-
butions N (0, 2). Each point’s label depended on the ﬁrst two coordinates using a separator parallel
to the long axis of the ellipsoid, yielding a linearly separable set (Fig. 3(top)). We evaluated ﬁve on-
line learning algorithms: the perceptron [16] , the passive-aggressive (PA) algorithm [4], the second-
order perceptron (SOP) [3], CW-Var-diag, CW-Var-full [6], CW-Stdev-diag and CW-Stdev-full. All
algorithm parameters were tuned over 1, 000 runs.
Fig. 2(a) shows the average cumulative mistakes for each algorithm; error bars indicate one unit of
standard deviation. Clearly, second-order algorithms, which all made fewer than 80 mistakes, out-
perform the ﬁrst-order ones, which made at least 129 mistakes. Additionally, CW-Var makes more
mistakes than CW-Stdev: 8% more in the diagonal case and 17% more in the full. The diagonal
methods performed better than the ﬁrst order methods, indicating that while they do not use any

6

second-order information, they capture additional information for single features. For each repeti-
tion, we evaluated the resulting classiﬁers on 10, 000 unseen test examples (Fig. 2(b)). Averaging
improved the ﬁrst-order methods. The second-order methods outperform the ﬁrst-order methods,
and CW-Stdev outperforms all the other methods. Also, the full case is less sensitive across runs.
The Gaussian distribution over weight vectors after 50 rounds is represented in Fig. 3(bot). The 20
dimensions of the version space are grouped into 10 pairs, the ﬁrst containing the two meaningful
features. The dotted segment represents the ﬁrst two coordinates of possible representations of
the true hyperplane in the positive quadrant. Clearly, the corresponding vectors are orthogonal to
the hyperplane shown in Fig. 3(top). The solid black ellipsoid represents the ﬁrst two signiﬁcant
feature weights; it does not yet lie of the dotted segment because the algorithm has not converged.
Nevertheless, the long axis is already parallel to the true set of possible weight vectors. The axis
perpendicular to the weight-vector set is very small, showing that there is little freedom in that
direction. The remaining nine ellipsoids represent the covariance of pairs of noise features. Those
ellipsoids are close to circular and have centers close to the origin, indicating that the corresponding
feature weights should be near zero but without much conﬁdence.

NLP Evaluation: We compared CW-Stdev-diag with CW-Var-diag, which beat many state of the
art algorithms on 12 NLP datasets [6]. We followed the same evaluation setting using 10-fold cross
validation and the same splits for both algorithms. Fig. 2(c) compares the accuracy on test data of
each algorithm; points above the line represent improvements of CW-Stdev over CW-Var. Stdev
improved on eight of the twelve datasets and, while the improvements are not signiﬁcant, they show
the effectiveness of our algorithm on real world data.

6 Related Work

2.5

0

−10

−20

1.5

−5

0

2

1

0

5

10

15

20

25

30

20

10

−30
−25

−20

−15

−10

Online additive algorithms have a long history, from with the
perceptron [16] to more recent methods [10, 4]. Our update
has a more general form, in which the input vector xi is lin-
early transformed using the covariance matrix, both rotating
the input and assigning weight speciﬁc learning rates. Weight-
speciﬁc learning rates appear in neural-network learning [18],
although they do not model conﬁdence based on feature vari-
ance.
The second order perceptron (SOP) [3] demonstrated that
second-order information can improve on ﬁrst-order methods.
Both SOP and CW maintain second-order information. SOP
is mistake driven while CW is passive-aggressive. SOP uses
the current instance in the correlation matrix for prediction
while CW updates after prediction. A variant of CW-Stdev
similar to SOP follows from our derivation if we ﬁx the La-
grange multiplier in (5) to a predeﬁned value αi = α, omit
the square root, and use a gradient-descent optimization step.
Fundamentally, CW algorithms have a probabilistic motiva-
tion, while the SOP is geometric: replace the ball around an
example with a reﬁned ellipsoid. Shivaswamy and Jebara [17]
used a similar motivation in batch learning.
Ensemble learning shares the idea of combining multiple clas-
siﬁers. Gaussian process classiﬁcation (GPC) maintains a
Gaussian distribution over weight vectors (primal) or over re-
gressor values (dual). Our algorithm uses a different update
criterion than the standard GPC Bayesian updates [15, Ch.3],
avoiding the challenge of approximating posteriors. Bayes
point machines [8] maintain a collection of weight vectors
consistent with the training data, and use the single linear classiﬁer which best represents the collec-
tion. Conceptually, the collection is a non-parametric distribution over the weight vectors. Its online
version [7] maintains a ﬁnite number of weight-vectors which are updated simultaneously. The rele-

Figure 3: Top : Plot of the two in-
formative features of the synthetic
data. Bottom: Feature weight dis-
tributions of CW-Stdev-full after 50
examples.

−0.5

−0.5

0.5

1.5

2.5

0.5

2

3

−1

0

1

7

vance vector machine [19] incorporates probabilistic models into the dual formulation of SVMs. As
in our work, the dual parameters are random variables distributed according to a diagonal Gaussian
with example speciﬁc variance. The weighted-majority [12] algorithm and later improvements [2]
combine the output of multiple arbitrary classiﬁers, maintaining a multinomial distribution over the
experts. We assume linear classiﬁers as experts and maintain a Gaussian distribution over their
weight vectors.

7 Conclusion

We presented a new conﬁdence-weighted learning method for linear classiﬁer based on the standard
deviation. We have shown that the algorithm is invariant to scaling and we provided a mistake-bound
analysis. Based on both synthetic and NLP experiments, we have shown that our method improves
upon recent ﬁrst and second order methods. Our method also improves on previous CW algorithms.
We are now investigating special cases of CW-Stdev for problems with very large numbers of fea-
tures, multi-class classiﬁcation, and batch training.

References
[1] Y. Censor and S.A. Zenios. Parallel Optimization: Theory, Algorithms, and Applications. Oxford Uni-
versity Press, New York, NY, USA, 1997.
[2] N. Cesa-Bianchi, Y. Freund, D. Haussler, D. P. Helmbold, R. E. Schapire, and M. K. Warmuth. How to
use expert advice. Journal of the Association for Computing Machinery, 44(3):427–485, May 1997.
[3] Nicol ´o Cesa-Bianchi, Alex Conconi, and Claudio Gentile. A second-order perceptron algorithm. Siam
Journal of Commutation, 34(3):640–668, 2005.
[4] K. Crammer, O. Dekel, J. Keshet, S. Shalev-Shwartz, and Y. Singer. Online passive-aggressive algorithms.
Journal of Machine Learning Research, 7:551–585, 2006.
[5] Mark Dredze and Koby Crammer. Active learning with conﬁdence. In ACL, 2008.
[6] Mark Dredze, Koby Crammer, and Fernando Pereira. Conﬁdence-weighted linear classiﬁcation. In Inter-
national Conference on Machine Learning, 2008.
[7] E. Harrington, R. Herbrich, J. Kivinen, J. Platt, and R.C. Williamson. Online bayes point machines. In
7th Paciﬁc-Asia Conference on Knowledge Discovery and Data Mining (PAKDD), 2003.
[8] R. Herbrich, T. Graepel, and C. Campbell. Bayes point machines. JMLR, 1:245–279, 2001.
[9] T. Jaakkola and M. Jordan. A variational approach to bayesian logistic regression models and their
extensions. In Workshop on Artiﬁcial Intelligence and Statistics, 1997.
[10] J. Kivinen and M. K. Warmuth. Exponentiated gradient versus gradient descent for linear predictors.
Information and Computation, 132(1):1–64, January 1997.
[11] N. Littlestone. Learning when irrelevant attributes abound: A new linear-threshold algorithm. Machine
Learning, 2:285–318, 1988.
[12] N. Littlestone and M. K. Warmuth. The weighted majority algorithm. Information and Computation,
108:212–261, 1994.
[13] A. B. J. Novikoff. On convergence proofs on perceptrons.
In Proceedings of the Symposium on the
Mathematical Theory of Automata, volume XII, pages 615–622, 1962.
[14] K. B. Petersen and M. S. Pedersen. The matrix cookbook, 2007.
[15] C. E. Rasmussen and C. K. I. Williams. Gaussian Processes for Machine Learning. The MIT Press, 2006.
[16] F. Rosenblatt. The perceptron: A probabilistic model for information storage and organization in the
brain. Psychological Review, 65:386–407, 1958. (Reprinted in Neurocomputing (MIT Press, 1988).).
[17] P. Shivaswamy and T. Jebara. Ellipsoidal kernel machines. In AISTATS, 2007.
[18] Richard S. Sutton. Adapting bias by gradient descent: an incremental version of delta-bar-delta.
In
Proceedings of the Tenth National Conference on Artiﬁcial Intelligence, pages 171–176. MIT Press, 1992.
[19] M. E. Tipping. Sparse bayesian learning and the relevance vector machine. Journal of Machine Learning
Research, 1:211–244, 2001.
[20] L. Xu, K. Crammer, and D. Schuurmans. Robust support vector machine training via convex outlier
ablation. In AAAI-2006, 2006.

8

