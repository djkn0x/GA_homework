Self-organization using synaptic plasticity

Vicenc¸ G ´omez1
vgomez@iua.upf.edu

Andreas Kaltenbrunner2
andreas.kaltenbrunner@upf.edu

Hilbert J Kappen1
b.kappen@science.ru.nl

Vicente L ´opez2
vicente.lopez@barcelonamedia.org

1Department of Biophysics
Radboud University Nijmegen
6525 EZ Nijmegen, The Netherlands

2Barcelona Media - Innovation Centre
Av. Diagonal 177,
08018 Barcelona, Spain

Abstract

Large networks of spiking neurons show abrupt changes in their collective dy-
namics resembling phase transitions studied in statistical physics. An example of
this phenomenon is the transition from irregular, noise-driven dynamics to regu-
lar, self-sustained behavior observed in networks of integrate-and-ﬁre neurons as
the interaction strength between the neurons increases. In this work we show how
a network of spiking neurons is able to self-organize towards a critical state for
which the range of possible inter-spike-intervals (dynamic range) is maximized.
Self-organization occurs via synaptic dynamics that we analytically derive. The
resulting plasticity rule is deﬁned locally so that global homeostasis near the crit-
ical state is achieved by local regulation of individual synapses.

1

Introduction

It is accepted that neural activity self-regulates to prevent neural circuits from becoming hyper- or
hypoactive by means of homeostatic processes [14]. Closely related to this idea is the claim that
optimal information processing in complex systems is attained at a critical point, near a transi-
tion between an ordered and an unordered regime of dynamics [3, 11, 9]. Recently, Kinouchi and
Copelli [8] provided a realization of this claim, showing that sensitivity and dynamic range of a
network are maximized at the critical point of a non-equilibrium phase transition. Their ﬁndings
may explain how sensitivity over high dynamic ranges is achieved by living organisms.

Self-Organized Criticality (SOC) [1] has been proposed as a mechanism for neural systems which
evolve naturally to a critical state without any tuning of external parameters. In a critical state, typi-
cal macroscopic quantities present structural or temporal scale-invariance. Experimental results [2]
show the presence of neuronal avalanches of scale-free distributed sizes and durations, thus giv-
ing evidence of SOC under suitable conditions. A possible regulation mechanism may be provided
by synaptic plasticity, as proposed in [10], where synaptic depression is shown to cause the mean
synaptic strengths to approach a critical value for a range of interaction parameters which grows
with the system size.

In this work we analytically derive a local synaptic rule that can drive and maintain a neural network
near the critical state. According to the proposed rule, synapses are either strengthened or weakened
whenever a post-synaptic neuron receives either more or less input from the population than the
required to ﬁre at its natural frequency. This simple principle is enough for the network to self-
organize at a critical region where the dynamic range is maximized. We illustrate this using a model
of non-leaky spiking neurons with delayed coupling for which a phase transition was analyzed in [7].

1

2 The model

ai (t + 1) =

ǫij HL (aj (t)) + 1 with probability p

The model under consideration was introduced in [12] and can be considered as an extension of [15,
5]. The state of a neuron i at time t is encoded by its activation level ai (t), which performs at discrete
timesteps a random walk with positive drift towards an absorbing barrier L. This spontaneous
evolution is modelled using a Bernoulli process with parameter p. When the threshold L is reached,
the states of the other units j in the network are increased after one timestep by the synaptic efﬁcacy
ǫj i , ai is reset to 1, and the unit i remains insensitive to incoming spikes during the following
timestep. The evolution of a neuron i can be described by the following recursive rules:

ai (t) +

ai (t) +
ai (t + 1) = 1 +

N
Xj=1,j 6=i
N
Xj=1,j 6=i
N
Xj=1,j 6=i
ǫij HL (aj (t))
where HL (x) is the Heaviside step function: HL (x) = 1 if x ≥ L, and 0 otherwise.
Using the mean synaptic efﬁcacy: hǫi = PN
i PN
j,j 6=i ǫij /(N (N − 1)) we describe the degree of
interaction between the units with the following characteristic parameter:
L − 1
η =
(N − 1)hǫi

with probability 1 − p

ǫij HL (aj (t))

if ai (t) < L

if ai (t) ≥ L

(1)

(2)

,

which indicates whether the spontaneous dynamics (η > 1) or the message interchange mechanism
(η ≤ 1) dominates the behavior of the system. As illustrated in the right raster-plot of Figure 1, at
η > 1 neurons ﬁre irregularly as independent oscillators, whereas at η = 1 (central raster-plot) they
synchronize into several phase-locked clusters. The lower η , the less clusters can be observed. For
η = 0.5 the network is fully synchronized (left raster-plot).

In [7] it is shown that the system undergoes a phase transition around the critical value η = 1.
The study provides upper (τmax ) and lower bounds (τmin ) for the mean inter-spike-interval (ISI)
τ of the ensemble and shows that the range of possible ISIs taking the average network behavior
(∆τ = τmax -τmin ) is maximized at η = 1. This is illustrated in Figure 1 and has been observed as
well in [8] for a similar neural model.

The average of the mean ISI hτ i is of order N x with exponent x = 1 for η > 1, x = 0.5 for η = 1,
and x = 0 for η < 1 as N → ∞, and can be approximated as shown in [7] with 1 :
+ s(cid:18) L − 1 − N hǫi
+ 1(cid:19)2
2p
3 Self-organization using synaptic plasticity

L − 1 − N hǫi
2p

N hǫi
2p

τapp = 1 +

(3)

+

.

We now introduce synaptic dynamics in the model. We ﬁrst present the dissipated spontaneous
evolution, a magnitude also maximized at η = 1. The gradient of this magnitude turns to be simple
analytically and leads to a plasticity rule that can be expressed using only local information encoded
in the post-synaptic unit.

3.1 The dissipated spontaneous evolution

During one ISI, we distinguish between the spontaneous evolution carried out by a unit and the
actual spontaneous evolution needed for a unit to reach the threshold L. The difference of both
quantities can be regarded as a surplus of spontaneous evolution, which is dissipated during an ISI.

1The equation was denoted hτ imin in [7]. We slightly modiﬁed it using hǫi and replacing η by Eq. (2).

2

n
i
m
τ
 
−
 
x
a
m
τ
 
=
 
τ
∆

60

50

0

n
o
r
u
e
n
 
#

40

30

20

10

0
0.5

n
o
r
u
e
n
 
#
20

time
10

0

25

50

    η ≤ 1
clustering

0

n
o
r
u
e
n
 
#

time
50

100

         η = 0.5
full synchronization

      η > 1
noisy firing

0.6

0.7

0.8

0.9

1
η

1.1

1.2

1.3

1.4

1.5

Figure 1: Number of possible ISIs according to the bound ∆τ = τmax − τmin derived in [7].
For η > 1 the network presents sub-critical behavior and is dominated by the noise. For η < 1 it
shows super-critical behavior. Criticality is produced at η = 1, which coincides to the onset of
sustained activity. At this point, the network is also broken down in a maximal number of clusters
of units which ﬁre according to a periodic pattern.

Figure 2a shows an example trajectory of a neuron’s state. First, we calculate the spontaneous evolu-
tion of the given unit during one ISI, which it is just its number of stochastic state transitions during
an ISI of length τ (thick black lines in Figure 2a). These state transitions occur with probability p
at every timestep except from the timestep directly after spiking. Using the average ISI-length hτ i
over many spikes and all units we can calculate the average total spontaneous evolution:
Etotal = (hτ i − 1)p.
Since the state of a given unit can exceed the threshold because of the received messages from the
rest of the population (blue dashed lines in Figure 2a), a fraction of (4) is actually not required to
induce a spike in that unit, and therefore is dissipated. We can obtain this fraction by subtracting
from (4) the actual number of state transitions that was required to reach the threshold L. The latter
quantity can be referred to as effective spontaneous evolution Eef f and is on average L − 1 minus
(N − 1)hǫi, the mean evolution caused by the messages received from the rest of the units during an
ISI. For η ≤ 1, the activity is self-sustained and the messages from other units are enough to drive
a unit above the threshold. In this case, all the spontaneous evolution is dissipated and Eef f = 0.
Summarizing, we have that:
Eef f = max{0, L − 1 − (N − 1)hǫi} = (cid:26)L − 1 − (N − 1)hǫi
0
If we subtract (5) from Etotal (4), we obtain the mean dissipated spontaneous evolution, which is
visualized as red dimensioning in Figure 2a:
Ediss = Etotal − Eef f = (hτ i − 1)p − max{0, L − 1 − (N − 1)hǫi}.
(6)
Using (3) as an approximation of hτ i we can get an analytic expression for Ediss . Figures 2b and c
show this analytic curve Ediss in function of η together with the outcome of simulations.

for η ≥ 1
for η < 1

(4)

(5)

At η > 1 the units reach the threshold L mainly because of their spontaneous evolution. Hence,
Etotal ≈ Eef f and Ediss ≈ 0. The difference between Etotal and Eef f increases as η approaches 1
because the message interchange progressively dominates the dynamics. At η < 1, we have Eef f =
0. In this scenario Ediss = Etotal , is mainly determined by the ISI hτ i and thus decays again for
decreasing η . The maximum can be found at η = 1.

3.2 Synaptic dynamics

After having presented our magnitude of interest we now derive a plasticity rule in the model. Our
approach essentially assumes that updates of the individual synapses ǫij are made in the direction of

3

)
t
(
1
a

(a)

L

11

9

7

5

3

1
 
0

Spontaneous evolution
Messages from other units

threshold

 spike

 

s
s
i
d
E

ε
13

ε
12

p
)
1
−
〉
τ
〈
(
 
≈
 
l
a
t
o
t
E

f
f
e
E

1
−
L

3
1
ε
+
2
1
ε

〉
ε
〈
 
)
1
−
N
(
 
≈

20

15

(b)
n
o
25
i
t
u
l
o
v
e
 
s
u
o
e
n
a
t
n
o
p
s
 
f
o
 
s
u
l
p
r
u
S

10

5

0
 
0.5

E
total
E
eff
E
diss

(c)
100

80

60

40

20

2

4

6

8

10

14

16

12
t

0
 
0.8

0.9

 

Sim.
E

diss

1.5

 

1.1

1.2

1
η

1
η

Figure 2: (a) Example trajectory of the state of a neuron:
the dissipated spontaneous evolution
Ediss is the difference between the total spontaneous evolution Etotal (thick black lines) and the
actual evolution required to reach the threshold Eef f (dark gray dimensioning) in one ISI. (b) Ediss
is maximized at the critical point. (c) The three different evolutions involved in the analysis (pa-
rameters for (b) and (c) are N = L = 1000 and p = 0.9. For the mean ISI we used τapp of
Eq. (3)).

the gradient of Ediss . The analytical results are rather simple and allow a clear interpretation of the
underlying mechanism governing the dynamics of the network under the proposed synaptic rule.

(7)

2

ǫik .

N hǫi = (N − 1)hǫi + hǫi ≈ (N − 1)hǫi =

We start approximating the terms N hǫi and (N − 1)hǫi by the sum of all pre-synaptic efﬁcacies ǫik :
N
Xi=1 Xk 6=i
ǫik /N ≈ Xk 6=i
This can be done for large N and if we suppose that the distribution of ǫik is the same for all i. Ediss
is now deﬁned in terms of each individual neuron i as:
diss = 
+ s(cid:18) L − 1 − Pk 6=i ǫik
L − 1 − Pk 6=i ǫik
E i

2p
2p

2p 
+ Pk 6=i ǫik
+ 1(cid:19)
 p
− max{0, L − 1 − Xk 6=i
An update of ǫij occurs when a spike from the pre-synaptic unit j induces a spike in a post-synaptic
unit i. Other schedulings are also possible. The results are robust as long as synaptic updates are
produced at the spike-time of the post-synaptic neuron.
∂ ǫij ! ,
= κ   ∂E i
∂E i
ef f
total
∂ ǫij
where the constant κ scales the amount of change in the synapse. We can write the gradient as:
− 
2 (cid:17)
2 (cid:16) L−1−Pk 6=i ǫik
if (L − 1 − Pk 6=i ǫik ) < 0
0
− 1
+ 1
2p
if (L − 1 − Pk 6=i ǫik ) = 0
indef
r(cid:16) L−1−Pk 6=i ǫik
+ 1(cid:17)2
Pk 6=i ǫik
if (L − 1 − Pk 6=i ǫik ) > 0.

−1
2p
2p
(10)
For a plasticity rule to be biologically plausible it must be local, so only information encoded in the
states of the pre-synaptic j and the post-synaptic i neurons must be considered to update ǫij .

∂E i
diss
∂ ǫij

∂E i
diss
∂ ǫij

∆ǫij = κ

ǫik }.

(8)

−

1
2

−

(9)

=

+

4

(a)

1

0.5

0

−0.5

 

dE
total
dE
+1
total
dE
diss

(b)
0.5

0.25

j
i
ε
∆

0

−0.25

 

c = 0.05
c = 0.5
c = 5

−1
 
−500

−250

0
Li

250

500

−0.5
 
−500

−250

250

500

0
Li

(a) First derivative of the dissipated spontaneous evolution Ediss for
Figure 3: Plasticity rule.
κ = 1, L = 1000 and c = 0.9. (b) The same rule for different values of c.

We propagate Pk 6=i ǫik to the state of the post-synaptic unit i by considering for every unit i, an ef-
fective threshold Li which decreases deterministically every time an incoming pulse is received [6].
At the end of an ISI Li ≈ (L − 1 − Pk 6=i ǫik ) and encodes implicitly all pre-synaptic efﬁcacies of i.
Intuitively, Li indicates how the activity received from the population in the last ISI differs from the
activity required to induce and spike in i.
The only term involving non-local information in (10) is the noise rate p. We replace it by a constant
c and show later its limited inﬂuence on the synaptic rule. With these modiﬁcations we can write
the derivative of E i
diss with respect to ǫij as a function of only local terms:

∂E i
diss
∂ ǫij

=

+

−Li − c
2q(Li + 2c)2 + 2c(L − Li )
Note that, although the derivation based on the surplus spontaneous evolution (10) may involve
information not locally accessible to the neuron, the derived rule (11) only requires a mechanism to
keep track of the difference between the natural ISI and the actual one.

sgn(Li )
2

(11)

We can understand the mechanism involved in a particular synaptic update by analyzing in detail
Eq. (11). In the case of a negative effective threshold (Li < 0) unit i receives more input from
the rest of the units than the required to spike, which translates into a weakening of the synapse.
Conversely, if Li > 0 some spontaneous evolution was required for the unit i to ﬁre, Eq. (11) is
positive and the synapse is strengthened. The intermediate case (Li = 0), corresponds to η = 1 and
no synaptic update is needed (nor is it deﬁned). We will consider it thus 0 for practical purposes.

Figure 3a shows Eq. (11) in bold lines together with ∂E i
total /∂ ǫij (dashed line, corresponding to
η < 1) and ∂E i
total /∂ ǫij + 1 (dashed-dotted, η > 1), for different values of the effective threshold
Li of a given unit at the end on an ISI. Etotal indicates the amount of synaptic change and Eef f
determines whether the synapse is strengthened or weakened. The largest updates occur in the
transition from a positive to a negative Li and tend to zero for larger absolute values of Li . Therefore,
signiﬁcant updates correspond to those synapses with post-synaptic neurons which during the last
ISI have received a similar amount of activity from the whole network as the one required to ﬁre.

We remark the similarity between Figure 3b and the rule characterizing spike time dependent plas-
ticity (STDP) [4, 13]. Although in STDP the change in the synaptic conductances is determined
by the relative spike timing of the pre-synaptic neuron and the post-synaptic neuron and here it is
determined by Li at the spiking time of the post-synaptic unit i, the largest changes in STDP occur
also in an abrupt transition from strengthening to weakening corresponding to Li = 0 in Figure 3a.

Figure 3b illustrates the role of c in the plasticity rule. For small c, updates are only signiﬁcant in a
tiny range of Li values near zero. For higher values of c, the interval of relevant updates is widened.
The shape of the rule, however, is preserved, and the role of c is just to scale the change in the
synapse. For the rest of this manuscript, we will use c = 1.

5

1.8

1.6

1.4

’
η

1.2

1

0

1

’
η

0.8

0.6

0

κ = 0.1

κ = 0.01

200

400

600

1.02

’
η

1

0.98

 

1.02

’
η

1

0.98

 

1.02

’
η

1

0.98

 

1.02

’
η

1

 

 

 

 

1.8

1.6

1.4

’
η

1.2

1

0

1

’
η

0.8

0.6

κ = 0.1

κ = 0.01

κ = 0.1

κ = 0.01

1000

2000

3000

1000
# periods

2000

0.98
 
0

100
200
# periods

300

0

1
# periods

2
4
x 10

Figure 4: Empirical results of convergence toward η = 1 for three different initial states above (top
four plots) and below (bottom four plots) the critical point. Horizontal axis denote number of ISIs
of the same random unit during all the simulations. On the left, results using the constant κ = 0.1.
Larger panels shows the full trajectory until 103 timesteps after convergence. Smaller panels are a
zoom of the ﬁrst trajectory η0 = 1.1 (top) and η = 0.87 (bottom). Right panels show the same type
of results but using a smaller constant κ = 0.01.

3.3 Simulations

In this section we show empirical results for the proposed plasticity rule. We focus our analysis on
the time τconv required for the system to converge toward the critical point. In particular, we analyze
how τconv depends on the starting initial conﬁguration and on the constant κ.

For the experiments we use a network composed of N = 500 units with homogeneous L = 500 and
p = 0.9. Synapses are initialized homogeneously and random initial states are chosen for all units
in each trial. Every time a unit i ﬁres, we update its afferent synapses ǫij , for all j 6= i, which breaks
the homogeneity in the interaction strengths. The network starts with a certain initial condition η0
and evolves according to its original discrete dynamics, Eq. (1), together with plasticity rule (9).
To measure the time τconv necessary to reach a value close to η = 1 for the ﬁrst time, we select a
neuron i randomly and compute η every time i ﬁres. We assume convergence when η ∈ (1−ν, 1+ν )
for the ﬁrst time. In these initial experiments, ν is set to κ/5 and κ is either 0.1 or 0.01.

We performed 50 random experiments for different initial conﬁgurations.
In all cases, after
an initial transient, the network settles close to η = 1, presenting some ﬂuctuations. These
ﬂuctuations did not grow even after 106 ISIs in all realizations. Figure 4 shows examples for
η0 ∈ {0.58, 0.7, 0.87, 1.1, 1.3, 1.7}.

We can see that for larger updates of the synapses (κ = 0.1) the network converges faster. How-
ever, ﬂuctuations around the reached state, slightly above η = 1, are approximately one order of
magnitude bigger than for κ = 0.01. We therefore can conclude that κ determines the speed of
convergence and the quality and stability of the dynamics at the critical state: high values of κ cause
fast convergence but turn the dynamics of the network less stable at the critical state.

We study now how τconv depends on η0 in more detail. Given N , L, c and κ, we can approximate
the global change in η after one entire ISI of a random unit assuming that all neurons change its
afferent synapses uniformly. This gives us a recursive deﬁnition for the sequence of ηt s generated
by the synaptic plasticity rule:
∆(ηt ) = κ(N − 1) 


−Lef f (ηt ) − c
2q(Lef f (ηt ) + 2c)2 + 2c(L − Lef f (ηt ))
6


 ,

+

sgn(ηt − 1)
2

(a)

5
10

4
10

)
s
d
o
i
r
e
p
(
 
e
m
i
t

3
10

2
10

1
10

0
10
 
0.5

Periods required to reach η=1

(b)

6
10

 

Time−steps required to reach η=1

 

)
s
p
e
t
s
e
m
i
t
 
f
o
 
r
e
b
m
u
n
(
 
e
m
i
t

5
10

4
10

3
10

2
10

1
10

0
10
 
0.5

κ = 0.01
τ
conv

Simulations
−−−−−−−−−−−
κ = 0.1
τ
conv

Simulations

1

η
0

1.5

2

κ = 0.01
τ
conv_steps

Simulations
−−−−−−−−−−−
κ = 0.1
τ
conv_steps

Simulations

1

η
0

1.5

2

Figure 5: Number of ISIs (a) and timesteps (b) required to reach the critical state in function of
the initial conﬁguration η0 . Rounded dots indicate empirical results as averages over 10 different
realizations starting from the same η0 . Continuous curves correspond to Eq. (12). Parameter values
are N = 500, L = 500, p = 0.9, c = 1, ν = κ/5.

ηt+1 = ηt + ∆(ηt ).

τconv = min({i : |ηt − 1| ≤ ν }),

where Lef f (ηt ) = (L − 1) (cid:18)1 −
ηt (cid:19) and
1
Then the number of ISIs and the number of timesteps can be obtained by2 :
τconv
Xt=0
Figure 5 shows empirical values of τconv and τconv steps for several values of η0 together with the
approximations (12). Despite the inhomogeneous coupling strengths, the analytical approximations
(continuous lines) of the experiments (circles) are quite accurate. Typically, for η0 < 1 more spikes
are required for convergence than for η0 > 1. However, the opposite occurs if we consider timesteps
as time units. A hysteresis effect (described in [7]) present in the system if η0 < 1, causes the
system to be more resistant against synaptic changes, which increases the number of updates (spikes)
necessary to achieve the same effect as for η0 > 1. Nevertheless, since the ISIs are much shorter for
supercritical coupling the actual number of time steps is still lower than for subcritical coupling.

τconv steps =

τapp (ηt ).

(12)

4 Discussion

Based on the amount of spontaneous evolution which is dissipated during an ISI, we have derived a
local synaptic mechanism which causes a network of spiking neurons to self-organize near a critical
state. Our motivation differs from those of similar studies, for instance [8], where the average
branching ratio σ of the network is used to characterize criticality. Brieﬂy, σ is deﬁned as the
average number of excitations created in the next time step by a spike of a given neuron.

The inverse of η plays the role of the branching ratio σ in our model. If we initialize the units
uniformly in [1, L], we have approximately one unit in every subinterval of length ηǫ, and in conse-
quence, the closest unit to the threshold spikes in 1/η cases if it receives a spike. For η > 1, a spike
of a neuron rarely induces another neuron to spike, so σ < 1. Conversely, for η < 1, the spike of a
single neuron triggers more than one neuron to spike (σ > 1). Only for η = 1 the spike of a neuron
elicits the order of one spike (σ = 1). Our study thus represents a realization of a local synaptic
mechanism which induces global homeostasis towards an optimal branching factor.

This idea is also related to the SOC rule proposed in [3], where a mechanism is deﬁned for threshold
gates (binary units) in terms of bit ﬂip probabilities instead of spiking neurons. As in our model,
criticality is achieved via synaptic scaling, where each neuron adjusts its synaptic input according to
an effective threshold called margin.

2The value of τapp (ηt ) has to be calculated using an hǫi corresponding to ηt in Eq. (3).

7

When the network is operating at the critical regime, the dynamics can be seen as balancing between
a predictable pattern of activity and uncorrelated random behavior typically present in SOC. One
would also expect to ﬁnd macroscopic magnitudes distributed according to scale-free distributions.
Preliminary results indicate that, if the stochastic evolution is reset to zero (p = 0) at the critical
state, inducing an artiﬁcial spike on a randomly selected unit causes neuronal avalanches of sizes
and lengths which span several orders of magnitude and follow heavy tailed distributions. These
results are in concordance with what is usually found for SOC and will be published elsewhere.

The spontaneous evolution can be interpreted for instance as activity from other brain areas not
considered in the pool of the simulated units, or as stochastic sensory input. Our results indicate
that the amount of this stochastic activity that is absorbed by the system is maximized at an optimal
state, which in a sense minimizes the possible effect of ﬂuctuations due to noise on the behavior of
the system.

The application of the synaptic rule for information processing is left for future research. We ad-
vance, however, that external perturbations when the network is critical would cause a transient
activity. During the transient, synapses could be modiﬁed according to some other form of learning
to encode the proper values which drive the whole network to attain a characteristic synchronized
pattern for the external stimuli presented. We conjecture that the hysteresis effect shown in the
regime of η < 1 may be suitable for such purposes, since the network then is able to keep the same
pattern of activity until the critical state is reached again.

Acknowledgments

We thank Joaqu´ın J. Torres and Max Welling for useful suggestions and interesting discussions.

References

[1] P. Bak. How nature works: The Science of Self-Organized Criticality. Springer, 1996.

[2] J. M. Beggs and D. Plenz. Neuronal avalanches in neocortical circuits.
23(35):11167–11177, December 2003.

Journal of Neuroscience,

[3] N. Bertschinger, T. Natschl ¨ager, and R. A. Legenstein. At the edge of chaos: Real-time computations
and self-organized criticality in recurrent neural networks. In Advances in Neural Information Processing
Systems 17, pages 145–152. MIT Press, Cambridge, MA, 2005.

[4] G. Q. Bi and M. M. Poo. Synaptic modiﬁcations in cultured hippocampal neurons: Dependence on spike
timing, synaptic strength, and postsynaptic cell type. Journal Of Neuroscience, 18:10464–10472, 1998.

[5] G. L. Gerstein and B. Mandelbrot. Random walk models for the spike activity of a single neuron. Biophys
J., 4:41–68, 1964.

[6] V. G ´omez, A. Kaltenbrunner, and V. L ´opez. Event modeling of message interchange in stochastic neural
ensembles. In IJCNN’06, Vancouver, BC, Canada, pages 81–88, 2006.

[7] A. Kaltenbrunner, V. G ´omez, and V. L ´opez. Phase transition and hysteresis in an ensemble of stochastic
spiking neurons. Neural Computation, 19(11):3011–3050, 2007.

[8] O. Kinouchi and M. Copelli. Optimal dynamical range of excitable networks at criticality. Nature Physics,
2:348, 2006.

[9] C. G. Langton. Computation at the edge of chaos: Phase transitions and emergent computation. Physica
D Nonlinear Phenomena, 42:12–37, jun 1990.

[10] A. Levina, J. M. Herrmann, and T. Geisel. Dynamical synapses causing self-organized criticality in neural
networks. Nature Physics, 3(12):857–860, 2007.

[11] N. H. Packard. Adaptation toward the edge of chaos. In: Dynamics Patterns in Complex Systems, pages
293–301. World Scientiﬁc: Singapore, 1988. A. J. Mandell, J. A. S. Kelso, and M. F. Shlesinger, editors.

[12] F. Rodr´ıguez, A. Su ´arez, and V. L ´opez. Period focusing induced by network feedback in populations of
noisy integrate-and-ﬁre neurons. Neural Computation, 13(11):2495–2516, 2001.

[13] S. Song, K. D. Miller, and L. F. Abbott. Competitive hebbian learning through spike-timing-dependent
synaptic plasticity. Nature Neuroscience, 3(9):919–926, 2000.

[14] G. G. Turrigiano and S. B. Nelson. Homeostatic plasticity in the developing nervous system. Nature
Reviews Neuroscience, 5(2):97–107, 2004.

[15] C. Van Vreeswijk and L. F. Abbott. Self-sustained ﬁring in populations of integrate-and-ﬁre neurons.
SIAM J. Appl. Math., 53(1):253–264, 1993.

8

