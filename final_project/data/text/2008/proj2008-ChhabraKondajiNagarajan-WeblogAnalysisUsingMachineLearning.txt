Weblog Analysis and Classi ﬁcation

Puneet Chhabra
iCME, Stanford
pun@stanford.edu

Srinidhi Kondaji
EE, Stanford
skondaji@stanford.edu

December 12, 2008

Nagarajan
iCME, Stanford
nag.rajan@stanford.edu

Introduction

The text content of a large set of weblogs was ana-
lyzed along with its associated metadata (contain-
ing information related to the URL, author’s gen-
der, age, interests, location, etc) to classify blogs
based on the gender and the age of the author us-
ing machine learning techniques. In particular, the
following approaches were investigated:

1. Multinomial Naive Bayes Classiﬁcation.

on the assumption that they would have little in-
formation about the author, and most of them were
products of typing errors and occurred only once
or twice in the whole list. This resulted in a set of
around 35000 unique words in the vocabulary.
Using this dictionary of 35000 words, the blogs
were converted into feature vectors for small stor-
age and fast retrieval. These feature vectors were
subsequently used for training the Naive Bayes and
the SVM classiﬁcation algorithms.

2. Support Vector Machines using LibSVM.

Implementation

3. Feature Improvement through χ

2 analysis.

Data-set Preprocessing

A data-set of about 3 million blogs was obtained
from Prof. Sepandar Kamvar(iCME, Stanford),
and around 65000 english language blogs were
ﬁltered out from Blogger and LiveJournal which
contained the complete author information includ-
ing age and gender.
The text from each of these blogs was extracted
using Python and an initial dictionary was created
which contained around 140,000 words, with help
from WordNet dictionary. During the extraction,
a standard list of stop words, which occur fre-
quently but have low classiﬁcation value (a, an,
the, of, etc), were eliminated and similar words
were stemmed to a common root. From this initial
dictionary, words occuring rarely were eliminated

The Python programming environment was used
due to its strong text processing capabilities. The
WordNet dictionary Python port was additionally
used for recognizing words from the English lan-
guage as well as for stemming purposes.

Stemming and Vocabulary

Instead of only using the Wordnet dictionary
stemming function (morphy) we implemented a
combination of Porter stemming algorithm along
with the Wordnet dictionary stemmer. This gave a
better stemming result than just using either of the
methods.

After ﬁltering low frequency words from this
stemmed vocabulary, blogs were converted into
variable length vectors. Figure 1 shows the rela-
tive frequency (log scale) of the various extracted

1

Male
Mathematician
Radeon
CNet
Engadget
Jihadist
Information
Parakeet
GeForce
Democracy
SourceForge

Female
Charmer
LivingRoom
BabySit
HomeSchool
Popsicle
Swarovski
Pediatrician
Anthropology
Petticoat
MySpace

Figure 1: Relative frequency of features

Table 1: Top Distinguishing Words

0.30

0.25

0.20

0.15

0.10

0.05

0.00
0

fold cross validation was performed by leaving out
one set of blogs at a time. The generalization error
was found to be 24%. It is interesting to note the
words which were most indicative of the author’s
gender (Table 1).

5

10

15

20

As can be seen from the learning curve (Figure
2), the naive bayes classiﬁer has a high bias. To
reduce the bias, the complexity of the model was
increased using a SVM classiﬁer.

Figure 2: Learning Curve for Gender Classiﬁca-
tion (Naive Bayes)

Gender Classi ﬁcation using SVM

stemmed words.

Results

Gender Classi ﬁcation using Naive Bayes

The ﬁrst approach we tried was to implement a
multinomial Naive Bayes Classiﬁer using the set
of 30,000 words in the vocabulary as the features.
The sample complexity was found by plotting the
learning curve which is shown in Figure 2.
The data was then divided into 66 sets of 1017
blogs each. To estimate the generalization error, k-

2

LibSVM was used for SVM based gender classiﬁ-
cation, using a smaller set of features, to increase
the speed of computation. A set of 5000 and 10000
most frequent words were selected as features. The
learning curve for the the SVM classiﬁers using the
above features are shown in Figures 3 and 4 respec-
tively.
As can be seen, there was no improvement from
the naive bayes approach. A χ
2 based feature se-
lection method was implemented to enhance the
classiﬁer performance. Some of the top and the
worst words as found by this method are shown in
Table 2.

40

38

36

34

32

30

28

40

38

36

34

32

30

28

26
0.0

0.5

1.0

1.5

2.0

2.5

3.0

3.5

4.0
x1e+4

26
0.0

0.5

1.0

1.5

2.0

2.5

3.0

3.5

4.0
x1e+4

Figure 3: Gender Classiﬁcation with SVM using
5k High-Frequency features

Figure 5: Gender Classiﬁcation with SVM using
5k Chi-Square features

44

42

40

38

36

34

32

30

28

26
0.0

0.5

1.0

1.5

2.0

2.5

3.0

3.5

4.0
x1e+4

Figure 4: Gender Classiﬁcation with SVM using
10k High-Frequency features

Best Words
Love
Obama
Google
McCain
Husband
Internet
America
Blogger
War
Technology

Worst Words
Quiznos
Dynasty
Algebra
Shameless
Strangler
Hedonist
Hoodlum
Astronomy
Nymphomaniac
Gravitate

Table 2: Words from Chi-Square Analysis

3

The learning curve for SVM classiﬁcation using
the best 5000 and 10000 words obtained from χ
based feature selection are shown in Figures 5 and
6.

2

Age Classi ﬁcation

The naive bayes approach was extended to classify
blogs based on the author’s age, ﬁrst into 2 classes
and then into 5 classes. In the ﬁrst case, the two
classes were chosen as the age groups (0-20, 50+)
and in the second case the ﬁve classes were the age
groups (10-25, 25-30, 30-35, 35-45, 45+). The ﬁve
classes were chosen to have a uniform distribution
of the number of blogs across the age groups.
The learning curves for the 2-class and 5-class
age classiﬁcation follow in ﬁgures 7 and 8 respec-
tively. The 2-class age classiﬁcation performed
well with a hold-out test error of 15%.

Conclusion

Intuitively, age and gender classiﬁcation based on
text analysis is difﬁcult, even for a human. So, it
is not surprising to see that the performance was
not as high as those observed in other text classiﬁ-
cation problems, like spam and document classiﬁ-
cation in news groups. However, the achieved ac-

curacy is encouraging and our analysis show that
there exist distinguishing features, across gender
and age groups, which can be exploited using ma-
chine learning approaches.

References

[1] Shlomo Argamon, Moshe Koppel, James
W. Pennebaker, and Jonathan Schler, 2007,
”Mining the Blogosphere: Age, gender and
, Text, volume
the varieties of selfexpression”
23, number 3, pp. 321.

[2] S. Argamon, M. Koppel, J. Fine, A. R. Shi-
moni, 2003,
”Gender, Genre, and Writing
, Text, volume
Style in Formal Written Texts”
23, number 3, pp. 321.

[3] J.D. Burger and J.C. Henderson, 2006,
”An exploration of observable features re-
, First Monday, vol-
lated to blogger age,”
ume 12, number 9,
”http://eprints.pascal-
network.org/archive/00003406/01/ ”.

[4] S. Herring and J. Paolillo, 2006, ”Gender and
, Journal of Soci-
genre variation in weblogs,”
olinguistics, volume 10, number 4, pp. 439.

42

40

38

36

34

32

30

28

26
0.0

0.5

1.0

1.5

2.0

2.5

3.0

3.5

4.0
x1e+4

Figure 6: Gender Classiﬁcation with SVM using
10k Chi-Square features

0.30

0.25

0.20

0.15

0.10

0.05

0.00
0

5

10

15

20

Figure 7: 2-class Age Classiﬁcation using Naive
Bayes

0.7

0.6

0.5

0.4

0.3

0.2
0

10

20

30

40

50

Figure 8: 5-class Age Classiﬁcation using Naive
Bayes

4

