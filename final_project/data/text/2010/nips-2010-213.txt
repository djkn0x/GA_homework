On the Theory of Learning with Privileged
Information

Dmitry Pechyony
NEC Laboratories
Princeton, NJ 08540, USA
pechyony@nec-labs.com

Vladimir Vapnik
NEC Laboratories
Princeton, NJ 08540, USA
vlad@nec-labs.com

Abstract

In Learning Using Privileged Information (LUPI) paradigm, along with the stan-
dard training data in the decision space, a teacher supplies a learner with the priv-
ileged information in the correcting space. The goal of the learner is to ﬁnd a
classiﬁer with a low generalization error in the decision space. We consider an
empirical risk minimization algorithm, called Privileged ERM, that takes into ac-
count the privileged information in order to ﬁnd a good function in the decision
space. We outline the conditions on the correcting space that, if satisﬁed, allow
Privileged ERM to have much faster learning rate in the decision space than the
one of the regular empirical risk minimization.

1 Introduction

In the classical supervised machine learning paradigm the learner is given a labeled training set
of examples and her goal is to ﬁnd a decision function with the small generalization error on the
unknown test examples. If the learning problem is easy (e.g. if learner’s space of decision functions
contains a one with zero generalization error) then, when the training size increases, the decision
function found by the learner converges quickly to the optimal one. However if the learning problem
is hard and the learner’s space of decision functions is large then the convergence (or learning) rate
is slow. The example of such hard learning problem is XOR when the space of decision functions is
2-dimensional hyperplanes.
The obvious question is “Can we accelerate the learning rate if the learner is given an additional
information about the learning problem?”. During the last years several new paradigms of learning
with additional information were proposed that, under some conditions, provably accelerate the
learning rate. For example, in semi-supervised learning such additional information is unlabeled
training examples.
In this paper we consider a recently proposed Learning Using Privileged Information (LUPI)
paradigm [8, 9, 10], that uses additional information of different kind. Let X be a decision space.
In LUPI paradigm, in addition to the standard training data, (x, y) ∈ X × Y , a teacher supplies
the learner with a privileged information x∗ in the correcting space X ∗ . The privileged information
is only available for the training examples and is never available for the test examples. The LUPI
paradigm requires, given a training set {(xi , x∗
i , yi )}n
i=1 , to ﬁnd a decision function h : X → Y
with the small generalization error for the unknown test examples x ∈ X .
The above question about accelerating the learning rate, reformulated in terms of the LUPI paradigm,
is “What kind of additional information should the teacher provide to the learner in order to accel-
erate her learning rate?”. Paraphrased, this question is essentially “Who is a good teacher?”. In this
paper we outline the conditions for the additional information provided by the teacher that allow for
fast learning rate even in the hard problems.

1

‘X ∗ (φ(x∗
i ))

min
h=(w,b),φ=(w∗ ,d)
s.t. ∀ 1 ≤ i ≤ n,

LUPI paradigm emerges in a number of applications, for example time series prediction, protein
classiﬁcation and human computation. The experiments [9] in these domains demonstrated a clear
advantage of LUPI paradigm over the supervised learning.
LUPI paradigm can be implemented by SVM+ algorithm [8], which in turn is based on the well-
known SVM algorithm [2]. We now present the version of SVM+ for classiﬁcation, the version for
regression can be found in [9]. Let h(x) = sign(w · x + b) be a decision function and φ(x∗
i ) =
n(cid:88)
w∗ · x∗
i + d be a correcting function. The optimization problem of SVM+ is
1
(w∗ · x∗
kwk2
kw∗ k2
2 + γ
2 + C
i + d)
min
2
2
w,b,w∗ ,d
i=1
yi (w · xi + b) ≥ 1 − (w∗ · x∗
s.t. ∀ 1 ≤ i ≤ n,
i + d)
i + d ≥ 0.
∀ 1 ≤ i ≤ n, w∗ · x∗
The objective function of SVM+ contains two hyperparameters, C > 0 and γ > 0. The term
γ kw∗ k2
2 /2 in (1) is intended to restrict the capacity (or VC-dimension) of the function space con-
taining φ.
Let ‘X (h(x), y) = 1 − y(w · x + b) be a hinge loss of the decision function h = (w, b) on the
example (x, y) and ‘X ∗ (φ(x∗ )) = [w∗ · x∗ + d]+ be a loss of the correcting function φ = (w∗ , d)
n(cid:88)
on the example x∗ . The optimization problem (1) can be rewritten as
1
kw∗ k2
kwk2
2 + γ
2 + C
2
2
i=1
‘X (h(xi ), y) ≤ ‘X ∗ (φ(x∗
i )).
n(cid:88)
The following optimization problem is a simpliﬁed and a generalized version of (2):
‘X ∗ (φ(x∗
i ), yi )
min
h∈H,φ∈Φ
i=1
‘X (h(xi ), yi ) ≤ ‘X ∗ (φ(x∗
s.t. ∀ 1 ≤ i ≤ n,
i ), yi ),
(4)
where ‘X and ‘X ∗ are arbitrary bounded loss functions, H is a space of decision functions and Φ is
a space of correcting functions. Let C > 0 be a constant (that is deﬁned later), [t]+ = max(t, 0) and
1
· ‘X ∗ (φ(x∗ ), y) + [‘X (h(x), y) − ‘X ∗ (φ(x∗ ), y)]+
‘0 ((h, φ), (x, x∗ , y)) =
(5)
C
n(cid:88)
be the loss of the composite hypothesis (h, φ) on the example (x, x∗ , y). In this paper we study the
relaxation of (3):
i=1
We refer to the learning algorithm deﬁned by the optimization problem (6) as empirical risk mini-
mization with privileged information, or abbreviated Privileged ERM.
The basic assumption of Privileged ERM is that if we can achieve a small loss ‘X ∗ (φ(x∗ ), y) in the
correcting space then we should also achieve a small loss ‘X (h(x), y) in the decision space. This
assumption reﬂects the human learning process, where the teacher tells the learner what are the most
important examples (the ones with the small loss in the correcting space) that the learner should take
The regular empirical risk minimization (ERM) ﬁnds a hypothesis (cid:98)h ∈ H that minimizes the training
(cid:80)n
into account in order to ﬁnd a good decision rule.
i=1 ‘X (h(xi ), yi ). While the regular ERM directly minimizes the training error of h, the
error
privileged ERM minimizes the training error of h indirectly, via the minimization of the training
error of the correcting function φ and the relaxation of the constraint (4).
Let h∗ be the best possible decision function (in terms of generalization error) in the hypothesis space
H. Suppose that for each training example xi an oracle gives us the value of the loss ‘X (h∗ (xi ), yi ).
We use these ﬁxed losses instead of ‘X ∗ (φ(x∗
i ), yi ) and ﬁnd h that satisﬁes the following system of
inequalities:
∀ 1 ≤ i ≤ n, ‘X (h(xi ), yi ) ≤ ‘X (h∗ (xi ), yi ).
(7)

‘0 ((h, φ), (xi , x∗
i , yi )),

min
h∈H,φ∈Φ

(1)

(2)

(3)

(6)

2

of the proof of Proposition 1 of [9] shows that the generalization error of the hypothesis (cid:98)h found
We denote the learning algorithm deﬁned by (7) as OracleERM. A straightforward generalization
by OracleERM converges to the one of h∗ with the rate of 1/n. This rate is much faster than the
√
worst-case convergence rate 1/
n of the regular ERM [3].
In this paper we consider more realistic setting, when the above oracle is not available. Our subse-
quent derivations rely heavily on the following deﬁnition:

Deﬁnition 1.1 A decision function h is uniformly better than the correcting function φ if for any
i ), yi ) ≥ ‘X (h(xi ), yi ).
example (x, x∗ , y) that has non-zero probability, ‘X ∗ (φ(x∗
Given a space H of decision functions and a space Φ of correcting functions we deﬁne
Φ = {φ ∈ Φ | ∃h ∈ H that is uniformly better than φ}.
Note that Φ ⊆ Φ and Φ does not contain correcting functions that are too good for H. Our results
are based on the following two assumptions:
Assumption 1.2 Φ 6= ∅.
This assumption is not restrictive, since it only means that the optimization problem (3) of Privileged
ERM has a feasible solution when the training size goes to inﬁnity.
Assumption 1.3 There exists a correcting function φ ∈ Φ, such that for any (x, x∗ , y) that has
non-zero probability, ‘X (h∗ (xi ), yi ) = ‘X ∗ (φ(x∗
i ), yi ).
Put it another way, we assume the existence of correcting function in Φ that mimics the losses of h∗ .
Let r be a learning rate of the Privileged ERM when it is ran over the joint X × X ∗ space with the
space of decision and correcting functions H × Φ. We develop an upper bound for the risk of the
decision function found by Privileged ERM. Under the above assumptions this bound converges to
h∗ with the same rate r . This implies that if the correcting space is good, so that the Privileged ERM
in the joint X × X ∗ space has a fast learning rate (e.g 1/n), then the Privileged ERM will have the
√
same fast learning rate (e.g. the same 1/n) in the decision space. That is true even if the decision
space is hard and the regular ERM in the decision space has a slow learning rate (e.g. 1/
n). We
√
illustrate this result with the artiﬁcial learning problem, where the regular ERM in the decision space
can not learn with the rate faster than 1/
n, but the correcting space is good and Privileged ERM
learns in the decision space with the rate of 1/n.
The paper has the following structure. In Section 2 we give additional deﬁnitions. In Section 3 we
review the existing risk bounds that are used to derive our results. Section 4 contains the proof of the
risk bound for Privileged ERM. In Section 5 we show an example when Privileged ERM is provably
better than the regular ERM. We conclude and give the directions for future research in Section 6.
Due to the space constraints, most of the proofs appear in the supplementary material.
Previous work
The ﬁrst attempt of theoretical analysis of LUPI was done by Vapnik and Vashist [9]. In addition
to the analysis of learning with oracle (mentioned above), they considered the algorithm, which is
close, but different from Privileged ERM. They developed a risk bound (Proposition 2 in [9]) for
the decision function found by their algorithm. This bound also applies to Privileged ERM. The
bound of [9] is tailored to the classiﬁcation setting, with 0/1-loss functions in the decision and
correcting function (cid:98)φ found by Privileged ERM. Vapnik and Vashist [9] concluded that if we could
the correcting space. By contrast, our bound holds for any bounded loss functions and allows the
bound the convergence rate of (cid:98)φ then this bound will imply the bound on the convergence rate of the
loss functions ‘X and ‘X ∗ to be different. The bound of [9] depends on generalization error of the
decision function found by their algorithm.

2 Deﬁnitions
The triple (x, x∗ , y) is sampled from the distribution D , which is unknown to the learner. We denote
by DX the marginal distribution over (x, y) and by DX ∗ the marginal distribution over (x∗ , y). The
distribution DX is given by the nature and the distribution DX ∗ is constructed by the teacher. The
spaces H and Φ of decision and correcting functions are chosen by learner.

3

(8)

inf

Let R(h) = E(x,y)∼DX {‘X (h(x), y)} and R(φ) = E(x∗ ,y)∼DX ∗ {‘X ∗ (φ(x∗ ), y)} be the general-
ization errors of the decision function h and the correcting function φ respectively. We assume that
the loss functions ‘X and ‘X ∗ have range [0, 1]. This assumption can be satisﬁed by any bounded
loss function by simply dividing it by its maximal value. We denote by h∗ = arg minh∈H R(h)
and φ∗ = arg minφ∈Φ R(φ) the decision and the correction function with the minimal gener-
the loss functions ‘X and ‘X ∗ . Also, we denote by ‘01 the 0/1 loss, by
alization error w.r.t.
(cid:80)n
R01 (h) = E(x,y)∼DX {‘01 (h(x), y)} the generalization error of h w.r.t.
the 0/1 loss and by
01 = arg minh∈H R01 (h) the decision function in H with the minimal generalization 0/1 error.
h∗
i=1 ‘0 ((h, φ), (xi , x∗
Let R0
n (h, φ) = 1
i , yi )) and
n
R0 (h, φ) = E(x,x∗ ,y) ∼D {‘0 ((h, φ), (x, x∗ , y))}
‘0 . We denote by ((cid:98)h, (cid:98)φ) = arg min(h,φ)∈H×Φ R0
be respectively empirical and generalization errors of the hypothesis (h, φ) w.r.t. the loss function
n (h, φ) the empirical risk minimizer and by
R0 (h, φ)
(h0 , φ0 ) = arg min
(h,φ)∈H×Φ
the minimizer of the generalization error w.r.t. the loss function ‘0 . Note that in general h∗ can be
different from h0 , and also φ0 can be different from φ∗ .
Let

(H, Φ) = {(h, φ) ∈ H × Φ | h is uniformly better than φ}.
By Assumption 1.2, (H, Φ) 6= ∅. We will use additional technical assumption:
(cid:169)
(cid:170) ≥ A.
Assumption 2.1 There exists a constant A > 0 such that
E(x,x∗ ,y)∼D {[‘X (h(x), y) − ‘X ∗ (φ(x∗ ), y)]+} | (h, φ) /∈ (H, Φ), R(φ) < R(φ)
This assumption is satisﬁed, for example, in the classiﬁcation setting when ‘X and ‘X ∗ are
0/1 loss functions and the probability density function p(x, x∗ , y) of the underlying distribu-
tion D is bounded away from zero for all points with nonzero probability.
In this case A ≥
inf {p(x, x∗ , y) | (x, x∗ , y) such that p(x, x∗ , y) 6= 0}.
The following lemma (proved in Appendix A in the full version of the paper) shows that for sufﬁ-
ciently large C the optimization problems (3) and (6) are asymptotically (when n → ∞) equivalent:
Lemma 2.2 Suppose that Assumptions 1.2, 1.3 and 2.1 hold true. Then there exists a ﬁnite C1 ∈ R
such that for any C ≥ C1 , (h0 , φ0 ) ∈ (H, Φ). Moreover, h0 = h∗ and φ0 = φ.
In all our subsequent derivations we assume that C has a ﬁnite value for which (3) and (6) are
equivalent. Later on we will show how we choose the value of C that optimizes the forthcoming
risk bound.
The risk bounds presented in this paper are based on VC-dimension of various function classes.
While the deﬁnition of VC-dimension for binary functions is well-known in the learning community,
the one for the real-valued functions is less known and we review it here. Let F be a set of real-
valued functions f : S → R and T (F ) = {(x, t) ∈ S × R | ∃ f ∈ F s.t. 0 ≤ |f (x)| ≤ t}. We say
that the set T = {(xi , ti )}|T |
i=1 ⊆ T (F ) is shattered by F if for any T 0 ⊆ T there exists a function
f ∈ F such that for any (xi , ti ) ∈ T 0 , |f (xi )| ≤ ti and for any (xi , ti ) ∈ T \ T 0 , |f (xi )| > ti . The
VC-dimension of F is deﬁned as a VC-dimension of the set T (F ), namely the maximal size of the
set T ⊆ T (F ) that is shattered by F .

3 Review of existing excess risk bounds with fast convergence rates

We derive our risk bounds from generic excess risk bounds developed by Massart and Nedelec [6]
and generalized by Gine and Koltchinskii [4] and Koltchinkii [5]. In this paper we use the version
of the bounds given in [4] and [5].
Let F be a space of hypotheses f : S → S 0 , ‘ : S 0 × {−1, +1} → R be a real-valued
loss function such that 0 ≤ ‘(f (x), y) ≤ 1 for any f ∈ F and any (x, y). Let f ∗ =

4

(b) Hypothesis space with large D
(a) Hypothesis space with small D
Figure 1: Visualization of the hypothesis spaces. The horisontal axis measures the distance (in
terms of the variance) between hypothesis f and the best hypothesis f ∗ in F . The vertical axis is
the minimal error of hypotheses in F with the ﬁxed distance from f ∗ . Note that the error function
(cid:80)n
displayed in graphs can be non-continuous. The large value of D in the hypothesis space in graph
arg minf ∈F E(x,y) {‘(f (x), y)}, (cid:98)fn = arg minf ∈F
(b) is caused by hypothesis A, which is signiﬁcantly different from f ∗ but has nearly-optimal error.
i=1 ‘(f (xi ), yi ) and D > 0 be a constant
such that for any f ∈ F ,
Var(x,y) {‘(f (x), y) − ‘(f ∗ (x), y)} ≤ D · E(x,y) {‘(f (x), y) − ‘(f ∗ (x), y)}.
(9)
This condition is a generalization of Tsybakov’s low-noise condition [7] to arbitrary loss functions
and arbitrary hypothesis spaces.
The constant D in (9) characterizes the error surface of the hypothesis space F . Suppose that
E(x,y) {‘(f (x), y) − ‘(f ∗ (x), y)} is very small, namely f is nearly optimal. If f is almost the same
as f ∗ then the variance in the left hand side of (9), as well as the value of D , will be small. But if
f differs signiﬁcantly from f ∗ then the variance in the left hand side of (9), as well as the value of
D , will be large. Thus, if we take the variance in the left hand side of (9) as a measure of distance
between f and f ∗ then the hypothesis spaces with large and small D can be visualized as shown in
Figure 1.
Let V be a VC-dimension of F . The following theorem is a straightforward generalization of The-
orem 5.8 in [5].
(cid:182)
(cid:181)
Theorem 3.1 ([5]) There exists a constant K > 0 such that if n > V · D2 then for any δ > 0, with
E(x,y) {‘( (cid:98)f (x), y)} ≤ E(x,y) {‘(f ∗ (x), y)} + KD
probability of at least 1 − δ
n
Let B = (V log n + log(1/δ))/n. If the condition of Theorem 3.1 does not hold, namely if n ≤
V · D2 then we can use the following fallback risk bound:
(cid:179)(cid:113)
(cid:180)
Theorem 3.2 ([1, 8]) There exists a constant K 0 such that for any δ > 0, with probability of at least
E(x,y) {‘( (cid:98)f (x), y)} ≤ E(x,y) {‘(f ∗ (x), y)} + K 0
1 − δ ,
E(x,y) {‘(f ∗ (x), y)}B + B
(11)
.
Deﬁnition 3.3 Let T = T (E(x,y) {‘(f ∗ (x), y)}, V , δ) be a constant such that for all n < T it holds
that E(x,y) {‘(f ∗ (x), y)} < B .
For n ≤ T the bound (11) has a convergence rate of 1/n, and for n > T the bound (11) has a
√
√
convergence rate of 1/
n. The main difference between (10) and (11) is the fast convergence rate
n in the regime of n > max(T , V · D2 ). By Theorem 3.1, starting
of 1/n vs. the slow one of 1/
from n > n(D) = V · D2 we always have the convergence rate of 1/n. Thus, the smaller value of
D , the smaller will be the threshold n(D) for obtaining the fast convergence rate of 1/n.

V log n
V D2 + ln

(10)

1
δ

.

4 Upper Risk Bound
For any C ≥ 1, any (x, x∗ , y), any h ∈ H and φ ∈ Φ, and any loss functions ‘X and ‘X ∗ ,
‘X (h(x), y) ≤ ‘X ∗ (φ(x∗ ), y) + C [‘X (h(x), y) − ‘X ∗ (φ(x∗ ), y)]+ .

5

(cid:110)
(cid:111)
= C · R0 ((cid:98)h, (cid:98)φ).
‘0 (((cid:98)h, (cid:98)φ), (x, x∗ , y))
R((cid:98)h) = E(x,y) {‘X ((cid:98)h(x), y)} ≤ C · E(x∗ ,y)
Hence, using (5) we obtain that
(12)
Let ‘1 (h, h∗ , x, y) = ‘X (h(x), y) − ‘X (h∗ (x), y) and DH ≥ 0 be a constant such that for any
h ∈ H
DH · E(x,y) {‘1 (h, h∗ , x, y)} ≥ Var(x,y) {‘1 (h, h∗ , x, y)} .
(13)
Similarly, let ‘2 (h, h0 , φ, φ0 , x, x∗ , y) = ‘0 ((h, φ), (x, x∗ , y))− ‘0 ((h0 , φ0 ), (x, x∗ , y)) and DH,Φ ≥ 0
be a constant such that for all (h, φ) ∈ H × Φ,
DH,Φ · E(x,x∗ ,y) {‘2 (h, h0 , φ, φ0 , x, x∗ , y)} ≥ Var(x,x∗ ,y) {‘2 (h, h0 , φ, φ0 , x, x∗ , y)} .
Let L(H, Φ) = {‘0 ((h, φ), (·, ·, ·)) | h ∈ H, φ ∈ Φ} be a set of the loss functions ‘0 corresponding
to hypotheses from H × Φ and VL(H,Φ) be a VC-dimension of L(H, Φ). Similarly, let L(H) =
{‘X (h(·), ·) | h ∈ H} and L(Φ) = {‘X ∗ (φ(·), ·) | φ ∈ Φ} be the sets of loss functions that
correspond to the hypotheses in H and Φ, and VL(H) and VL(Φ) be VC dimensions of L(H) and
L(Φ) respectively. Note that if ‘X = ‘01 then VL(H) is also a VC-dimension of H (the same holds
also for VL(Φ) ).
Lemma 4.1 VL(H,Φ) = VL(H) + VL(Φ) .

(14)

+ ln

1
δ

n
VL(H,Φ)D2H,Φ

VL(H,Φ) ln
(cid:195)

Proof See Appendix C in the full version of the paper.
We apply Theorem 3.1 to the hypothesis space H × Φ and the loss function ‘0 ((h, φ), (x, x∗ , y)) and
obtain that there exists a constant K > 0 such that if n > VL(H,Φ) · D2H,Φ then for any δ > 0, with
(cid:33)
(cid:195)
probability at least 1 − δ
R0 ((cid:98)h, (cid:98)φ) ≤ R0 (h0 , φ0 ) + KDH,Φ
n
Using (12) we obtain that
R((cid:98)h) ≤ C · R0 (h0 , φ0 ) + CKDH,Φ
n
It follows from Assumption 1.3 and Lemma 2.2 that
1
1
1
R0 (h0 , φ0 ) =
R(h∗ ).
R(φ0 ) =
R(φ) =
(16)
C
C
C
We substitute (16) into (15) and obtain that there exists a constant K > 0 such that if n > VL(H,Φ) ·
(cid:195)
(cid:33)
D2H,Φ then for any δ > 0, with probability at least 1 − δ ,
R((cid:98)h) ≤ R(h∗ ) + CKDH,Φ
n
We bound VH,Φ by Lemma 4.1 and obtain our ﬁnal risk bound, that is summarized in the following
theorem:

n
VL(H,Φ)D2H,Φ

n
VL(H,Φ)D2H,Φ

VL(H,Φ) ln

VL(H,Φ) ln

.
(cid:33)

+ ln

.

+ ln

.

1
δ

(15)

1
δ

Theorem 4.2 Suppose that Assumptions 1.2, 1.3 and 2.1 hold. Let DH,Φ be as deﬁned in (14),
C1 be as deﬁned in Lemma 2.2, and V L(H,Φ) = VL(H) + VL(Φ) . Suppose that C > C1 and
(cid:195)
(cid:33)
n > V L(H,Φ) · D2H,Φ . Then for any δ > 0 with probability of at least 1 − δ ,
R((cid:98)h) ≤ R(h∗ ) + CKDH,Φ
n
where K > 0 is a constant.

n
V L(H,Φ) · D2H,Φ

V L(H,Φ) ln

+ ln

(17)

1
δ

,

6

According to this bound, R((cid:98)h) converges to R(h∗ ) with the rate of 1/n. If Assumption 1.3 does not
In this case the upper bound on R((cid:98)h) converges to R(φ0 ) with the rate of 1/n.
hold then it is easy to see that we obtain the same bound as (17), but with R(h∗ ) replaced by R(φ0 ).
We now provide further analysis of the risk bound (17). Let ‘3 (φ, φ0 , x∗ , y) = ‘X ∗ (φ(x∗ ), y) −
‘X ∗ (φ0 (x∗ ), y) and DΦ ≥ 0 be a constant such that for any φ ∈ Φ,
DΦ · E(x∗ ,y) {‘3 (φ, φ0 , x∗ , y)} ≥ Var(x∗ ,y) {‘3 (φ, φ0 , x∗ , y)} .
H,Φ ≥ 0 be a constant such that for all (h, φ) ∈ (H × Φ) \ (H, Φ),
Similarly, let D 0
(cid:162)
(cid:161)
H,ΦE(x,x∗ ,y) {‘2 (h, h0 , φ, φ0 , x, x∗ , y)} ≥ Var(x,x∗ ,y) {‘2 (h, h0 , φ, φ0 , x, x∗ , y)} .
D 0
Lemma 4.3 DH,Φ ≤ max
DΦ /C, D 0
.
H,Φ

(18)

Proof See Appendix B in the full version of the paper.
By Lemma 4.3, C · DH,Φ ≤ max(DΦ , C · D 0
H,Φ ). Since the loss function ‘2 depends on C , the
constant D 0
H,Φ depends on C too. Thus, ingoring the left-hand logarithmic term in (17), the optimal
value of C is the one that is larger that C1 and minimizes C · D 0
(cid:189)
(cid:190)
H,Φ . We now show that such
minimum indeed exists. By the deﬁnition of the loss function ‘2 ,
Var(x,x∗ ,y) {‘2 (h, h0 , φ, φ0 , x, x∗ , y)}
sup
0 < lim
E(x,x∗ ,y) {‘2 (h, h0 , φ, φ0 , x, x∗ , y)}
C→∞
(h,φ)∈(H×Φ)\(H,Φ)
H,Φ ≤ 1, where s is the value of the above limit.
Therefore for very large C it holds that 0 < s ≤ D 0
Consequently limC→∞ C · D 0
H,Φ = ∞. Since the function g(C ) = C · D 0
H,Φ is continuous and
ﬁnite in C = C1 , there exists a point C = C ∗ ∈ [C1 , ∞) that minimizes it.

≤ 1.

(19)

5 When Privileged ERM is provably better than the regular ERM

We show an example that demonstrates the difference between the emprical risk minimization in
X space and empirical risk minimization with privileged information in the joint X × X ∗ space.
√
In particular, we show in this example that for not too small training sizes (as speciﬁed by the
conditions of Theorems 11 and 4.2) the learning rate of the regular ERM in X space is 1/
n while
the learning rate of the privileged ERM in the joint X × X ∗ space is 1/n.
We consider the classiﬁcation setting and all loss functions in our example are 0/1 loss. Let
DX = {DX ()|0 <  < 0.1} be an inﬁnite family of distributions of examples in X space. All
distributions in DX have non-zero support in four points, denoted by X1 , X2 , X3 and X4 . We
assume that these points lie on a 1-dimensional line, as shown in Figure 2(a). Figure 2(a) also shows
the probability mass of each point in the distribution DX (). The hypothesis space H consists of
t = −sign(x − t). The best hypothesis in H is h0
hypotheses ht (x) = sign(x − t) and h0
1 and its
generalization error is 1/4 − 2. The hypothesis space H contains also a hypothesis h0
3 , which is
slightly worse than h0
1 and has generalization error of 1/4 + . It can be veriﬁed that for a ﬁxed
DX () and H the constant DH (deﬁned in equation (13)) is
DH = 1/(6) − (1/3) −  ≤ 1/(6).
(20)
Note that the inequality in (20) is very tight since  can be arbitrary small. The VC-dimension VH
of H is 2. Suppose that  is sufﬁciently small such that VH · D2H > T (1/4 − 2, VH , δ), where the
function T (·, ·, ·) is deﬁned in Deﬁnition 3.3. In order to use the risk bound (10) with our DX and
H, the condition
n > VH · D2H = 1/(182 )
(21)
obtain that R01 ((cid:98)h) converges to R01 (h∗ ) with the rate of at least 1/
should be satisﬁed. But since  can be very small, the condition (21) is not satisﬁed for a large range
of n’s. Hence, according to (11), for distributions DX () that satisfy T (1/4 − 2, 2, δ) ≤ 1
182 we
√
The following lower bound shows that R01 ((cid:98)h) converges to R01 (h∗ ) with the rate of at most 1/
n.
√
7

n.

(b) X ∗ space

(a) X space

Figure 2: X and X ∗ spaces.
(cid:112)
Lemma 5.1 Suppose that  < 1/16. Let δn = exp(−20n2 ). Then for any n > 256, with proba-
R01 ((cid:98)h) − R01 (h∗ ) ≥
bility at least δn ,
By combining upper and lower bounds we obtain that the convergence rate of R01 ((cid:98)h) to R01 (h∗ ) is
ln(1/δn )/(20n).
√
exactly 1/
n. The proof of the lower bound appears in Appendix D in the full version of the paper.
Suppose that the teacher constructed the distribution DX ∗ () of examples in X ∗ space in the fol-
lowing way. DX ∗ () has non-zero support in four points, denoted by X ∗
1 , X ∗
2 , X ∗
3 and X ∗
4 , that
lie on a 1-dimensional line, as shown in Figure 2(b). Figure 2(b) shows the probability mass of
each point in X ∗ space. We assume that the joint distribution (X, X ∗ ) has non-zero support only
on points (X1 , X ∗
1 ), (X2 , X ∗
2 ), (X3 , X ∗
3 ) and (X4 , X ∗
4 ). The hypothesis space Φ consists of hy-
potheses φt (x) = sign(x∗ − t) and φ0
t = −sign(x∗ − t). The best hypothesis in Φ is φ0
2 and its
generalization error is 0. However there is no h ∈ H that is uniformly better than φ0
2 . The best hy-
pothesis in Φ, among those that have uniformly better hypothesis in H, is φ0
1 and its generalization
error is 1/4 − 2. h0
1 . It can be veriﬁed that for such DX ∗ () and Φ the
1 is uniformly better than φ0
constant DΦ (deﬁned in equation (18)) is
DΦ = (11/16 − 3 − 42 )/(1/4 + 2) ≤ 2.75.
(22)
Note that the inequality in (22) is very tight since  can be arbitrary small. Moreover, it can be
veriﬁed that C that minimizes C · D 0
H,Φ is C ∗ = 2.6. For C = C ∗ it holds that D 0
H,Φ = 1.71
and DΦ/C = 1.06. It is easy to see that our example satisﬁes Assumptions 1.2 and 1.3 (the last
assumption is satisﬁed with φ = −φ0
Theorem 4.2 and Lemma 4.3, if n > (2 + 2) · 1.712 = 11.7 then R01 ((cid:98)h) converges to R01 (h∗ ) with
1 ). Also, it can be veriﬁed that Assumption 2.1 is satisﬁed with
A = 1/4 − 2 and C1 = 1.1 < C ∗ satisﬁes Lemma 2.2. The VC-dimension of Φ is 2. Hence by
the rate of at least 1/n. Since our bounds on DΦ and D 0
H,Φ are independent of , the convergence
rate of 1/n holds for any distribution in DX .
We obtained that for 11.7 < n ≤ 1
182 the upper bound (17) converges to R01 (h∗ ) with the rate of
√
1/n, while the upper bound (11) converges to R01 (h∗ ) with the rate of 1/
n. This improvement
was possible due to teacher’s construction of DX ∗ () and learner’s choice of Φ. The hypothesis h0
3
caused the value of DH to be large and thus prevented us from 1/n convergence rate for a large
range of n’s. We constructed DX ∗ () and Φ in such a way that Φ does not have a hypothesis φ that
3 . With such construction any φ ∈ Φ, such
has exactly the same dichotomy as the bad hypothesis h0
3 is uniformly better than φ, has generalization error signiﬁcantly larger than the one of h0
that h0
3 .
For example, the best hypothesis in Φ for which h0
3 is uniformly better, is φ0 and its generalization
error is 1/2.

6 Conclusions

We formulated the algorithm of empirical risk minimization with privileged information and derived
the risk bound for it. Our risk bound outlines the conditions for the correcting space that, if satisﬁed,
will allow fast learning in the decision space, even if the original learning problem in the decision
space is very hard. We showed an example where the privileged information provably signiﬁcantly
improves the learning rate.
√
In this paper we showed that the good correcting space can improve the learning rate from 1/
n
to 1/n. But, having the good correcting space, can we achieve a learning rate faster than 1/n?
Another intersting problem is to analyze Privileged ERM when the learner does not completely trust
the teacher. This condition translates to the constraint ‘X (h(x), y) ≤ ‘X ∗ (φ(x∗ ), y) +  in (3)
and the term [‘X (h(x), y) − ‘X ∗ (φ(x∗ ), y)]+ in (6), where  ≥ 0 is a hyperparameter. Finally, the
important direction is to develop risk bounds for SVM+ (which is a regularized version of Privileged
ERM) and show when it is provably better than SVM.

8

References
[1] S. Boucheron, O. Bousquet, and G. Lugosi. Theory of classiﬁcation: a survey of some recent
advances. ESAIM: Probability and Statistics, 9:329–375, 2005.
[2] C. Cortes and V. Vapnik. Support-vector networks. Machine Learning, 20(3):273–297, 1995.
[3] L. Devroye and G. Lugosi. Lower bounds in pattern recognition and learning. Pattern Recog-
nition, 28(7):1011–1018, 1995.
[4] E. Gine and V. Koltchinskii. Concentration inequalities and asymptotic resutls for ratio type
empirical processes. Annals of Probability, 34(3):1143–1216, 2006.
[5] V. Koltchinskii. 2008 Saint Flour lectures: Oracle inequalities in empirical risk minimization
and sparse recovery problems, 2008. Available at fodava.gatech.edu/ﬁles/reports/FODAVA-
09-17.pdf.
[6] P. Massart and E. Nedelec. Risk bounds for statistical learning. Annals of Statistics,
34(5):2326–2366, 2006.
[7] A. Tsybakov. Optimal aggregation of classiﬁers in statistical learning. Annals of Statistics,
32(1):135–166, 2004.
[8] V. Vapnik. Estimation of dependencies based on empirical data. Springer–Verlag, 2nd edition,
2006.
[9] V. Vapnik and A. Vashist. A new learning paradigm: Learning using privileged information.
Neural Networks, 22(5-6):544–557, 2009.
[10] V. Vapnik, A. Vashist, and N. Pavlovich. Learning using hidden information: Master class
learning. In Proceedings of NATO workshop on Mining Massive Data Sets for Security, pages
3–14. 2008.

9

