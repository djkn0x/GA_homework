Classi(cid:12)cation and Quanti(cid:12)cation of Matrix Micro-cracks in
Composite Structures

C. Larrosa, K.Lonkar, S.K.Shankar
Dept of Aeronautics and Astronautics, Stanford University, CA

December 10, 2010

Fiber reinforced composites have been widely
used in aerospace applications due to their func-
tional properties such as high strength-to-weight
ratios. But many challenges are yet to be over-
come in order to have more conﬁdence on the per-
formance of composites structures. Particularly,
composites have diﬀerent failures types and modes
that make the damage prediction and propagation
a very challenging sub ject. The current work will
focus on developing structural health monitoring
(SHM) techniques for inspection to reduce mainte-
nance costs and increase aircraft safety by under-
standing and identifying damage types. The steps
in implementing a successful Structural Health
Monitoring System are to: 1) Locate damage, 2)
Identify damage type, 3) Quantify damage and 4)
Estimate remaining life. Stanford’s Structures and
Composites Lab has developed Structural Health
Monitoring techniques based on ultrasonic Lamb
wave [1] propagation via the use of piezoelectric
sensor networks. Using the sensor network in its ac-
tive sensing mode, damage in a composite structure
can be monitored. But the current state-of-the-art
detection methods can only detect changes in sen-
sor signal but do not distinguish among damage
types or quantify the damage. Knowing the type
of damage and quantifying it would provide the in-
puts needed for physics based prognostic models
(lifetime estimation) which would predict the re-
maining life of the structure for its safe use.

Experimental studies of damage caused in com-
posite plates under tensile-tensile fatigue loading
are being conducted by Stanford SACL in collabo-
ration with NASA Ames. The generation of guided
Lamb waves is achieved by a surface mounted
piezoelectric sensor network (Acellent’s SMART
Layers R⃝
). The sets of sensors serve as a signal gen-
erator and receiver pair. The tensile-tensile cyclic
loading is generated using SACLs MTS machine.
At the end of every N cycle, sensor data along with
X-radiography of the sample are recorded. The X-
ray images provide the real damage type and quan-
tity. The sensor signals for all paths (the diﬀerent

paths correspond to diﬀerent combinations of the
6-signal generating sensor and the 6-signal receiv-
ing sensors attached to the composite structure)
can be processed using diﬀerent signal processing
techniques and diﬀerent features/parameters can
be extracted in the time and frequency domain.
The ob jectives of the current work are: 1) to ﬁnd
which features are more sensitive to diﬀerent dam-
age types: delamination or matrix micro-cracks;
and 2) to learn the relationship between these fea-
tures and matrix micro-crack density. We will com-
pare diﬀerent learning algorithms as well as diﬀer-
ent combinations of features, to ﬁnd the features
and algorithm that yield the best results.

Experiment
Each sample has two SMART Layer R⃝
strips with
six piezoelectric sensors attached to a surface as
shown in Fig. 1. One SMART Layer R⃝
strip acts
as actuators while the other as the sensors. There
are 36 actuator-sensor path combinations. The
sensed data is acquired using the commercial pack-
age ScanScentry from Acellent. Before loading the
sample baseline data is taken which will be used
as the base case for data analysis and feature ex-
traction. The sample is then tested under tension-
tension fatigue using a standard MTS machine. Ev-
ery 50,000 cycles the test is paused, sensor data is
acquired and an X-ray image is taken. The test is
continued until the sample fails.

Data Set

For the pilot run of the algorithms 6 diﬀerent fea-
tures were chosen and computed from the raw ex-
perimental data. The feature and the correspond-
ing quantity it represents is shown in Table. 1.
PSD here is the power spectra density, a quantity
which is the measure of the energy content of the
time-signal in frequency domain. The data were

The error obtained on the test set was measured by
means of a (75 % -25% test) hold-out cross valida-
tion method.

GDA

In order to test generative learning algorithms,
we implemented GDA, ﬁrst assuming same co-
variance matrix (Σ) for 4xjy = 0 and xjy = 1;
and then assuming diﬀerent covariance matrices
(xjy = 0 (cid:24) N (µ0 , Σ0 ) and xjy = 1 (cid:24) N (µ1 , Σ1 )).
Expression for the parameters ϕy , µ0 and µ1 are
as given in the lecture notes [3] while expressions
∑
for Σ0 and Σ1 are:
∑
∑
1{y(i)=0}(x(i)−µ0 )T (x(i)−µ0 )
m
∑
1{y(i)=0}
i=1
m
i=1
1{y(i)=1}(x(i)−µ1 )T (x(i)−µ1 )
m
1{y(i)=1}
i=1
m
i=1

Σ0 =

Σ1 =

Figure 1:
Illustration of the wave propagation
across the composite structure showing the 36 dif-
ferent paths (1, 2, 3, 4, 5, 6) ! (7, 8, 9, 10, 11, 12)
across which the signal can be measured.

non-dimensionalized with the corresponding values
of the baseline signal. Diﬀerent learning algorithms
were employed to learn on the training data, and
their performance was measured on the test data.

Classi(cid:12)cation algorithms

Five diﬀerent algorithm in supervised and unsu-
pervised category were used and their performance
measured on the data set. They are described as
follows

SVM

The SVM classiﬁcation was implemented using the
SV M light source package provided by Thorsten
Joachims [4].
It implements a fast optimization
algorithm to solve both the classiﬁcation and re-
gression problem. The software supports various
other features and the details can be found on
(http://svmlight.joachims.org). We patched the
source code writtein in C language with MATLAB
using the MATLAB-MEX interface to SV M light
provided by Anton Schwaighofer [5]. This provided
us the seamless capability to perfom the SVM-
classiﬁcation on our data set from MATLAB user
interface. The classiﬁcation was performed using a
linear kernel, polynomial and sigmoid tanh kernels.
The test error measured by 75% (cid:0) 25% hold-out
validation using the linear kernel was found to be
the least.

Supervised learning algorithms

Logistic Regression

First model we implemented was logistic regression,
as described in the lecture notes [2] with learning
rate α = 1. Hold-out cross validation was used to
test the performance of the algorithm, in which the
data set S was randomly split into Strain (75% of
the data) and SC V (the remaining 25%).

Naive Bayes

The Naive Bayes algorithm was implemented using
the discretized set of features (the feature is dis-
cretized into 190 bins, the choice based on Fig. 2).

Unsupervised learning algorithms

Mixture of Gaussians

To test the performance of unsupervised learning
algorithm on our data set, we implemented the mix-
ture of Gaussian method to classify our examples.
To test the performance of unsupervised learn-
ing algorithm on our data set, we implemented the
mixture of Gaussians method to classify our exam-
ples. To ﬁt mixture of two Gaussian distributions,
a MATLAB function ’gmdistribution’ in statistics
toolbox was used.
’gmdistribution’ gives us the
model parameters, ϕj , µj and Σj for j = 1,2. Once
we have model parameters, probabilities of latent
parameter z for a given feature vector can be com-
puted using the following relation.

2

∑
wj = p(x(i) |z (i)=j ;µ,(cid:6))p(z (i)=j ;ϕ)
∑
p(x(i) |z (i)=l;µ,(cid:6))p(z (i)=l;ϕ)
2
l=1
N (µj ,(cid:6)j )ϕj
N (µl ,(cid:6)l )ϕl
2
l=1

wj =

The classiﬁcation error on test data measured while
using MG is shown in Fig. 4 for diﬀerent combina-
tions of the input feature vector.

Feature Selection

The features set consists of continuous real number
valued variables. To discretize the feature set the
interval of variation of each feature was divided into
equal bins of diﬀerent sizes.
We started out with a train data set containing
6 features. Hold-out cross validation (75-25) was
used to test the performance of the models under
consideration. The accuracy of the models were
tested for all possible combinations of the input fea-
ture set. With an input feature size of 6, there are
26 (cid:0) 1 = diﬀerent combinations of feature sets. This
study will help us in 1) identifying the set of fea-
tures that yield the least test error and 2) it would
help in identifying other features which would be
more informational for the classiﬁcation problem
at hand. Table 2 gives the test error (i.e. estimate
of generalization error) for ten best combinations
of feature set for the four supervised learning algo-
rithms.
Using the results from the above feature selection
study we conducted a physics based analysis of the
problem and introduced three additional features
into the input variable. The added set of features
is listed in Table. 1 hence increasing the size of the
feature vector to nine.
The correlation of the individual features to de-
lamination is measured. Mutual information was
scored based on Kulleback-Liebler divergence. The
mutual information scores for the nine features for
diﬀerent bin numbers is shown in Fig. 2. Prelimi-
nary physics based studies on this data concluded
that Time of Flight (x1 ) should be highly corre-
lated to delamination. With this background infor-
mation in hand, a bin size of 190 bins was selected
because it produces the highest mutual information
score for x1 .
To assess the algorithms, the error that they yield
on the test data set is measured while using the
whole set of 9-features. The resulting training and
test errors are shown in Fig. 3. With the added
features, there are 29 (cid:0) 1 = 511 diﬀerent combina-
tions of the features. Fig. 4 shows the test error
obtained for the 511 diﬀerent combinations for each
of the algorithms being considered. Table 3 gives
the test error for the ten best combinations of fea-
tures.

Precision and recall were computed for all dif-
ferent combinations of new feature set. The scat-
ter plot of precision versus recall is shown in Fig.
6. Choice of best algorithm and feature vector de-
pends on the ob jective function that we want op-
timize. Ob jective 1 in Fig. 6 is to minimize to-
tal error (i.e.
false alarms (FP) + missed alarms
(FN)), which is equivalent to maximizing precision
+ recall. Ob jective 2 in Fig. 6 represents mini-
mization of missed alarms, which is equivalent to
maximization of recall. In SHM, missed alarms are
more important than false alarms.
Table 3 gives the test error for ten best combina-
tions of feature set for all the algorithms considered.

Conclusions and Future Work

The present study focuses on applying machine
learning algorithms for classiﬁcation of delamina-
tion in composite samples loaded under in-plane
tension-tension cyclic loading. The samples were
instrumented with a piezoelectric sensor network
that was able to monitor damage. Features were
extracted using time domain and frequency domain
analysis. The study had two stages. We ﬁrst im-
plemented the algorithms with a 6 feature set. The
test and training errors were very close, indicat-
ing that there could be high bias in the models.
This suggested using a higher dimensional feature
set. Three new features were added and the al-
gorithms were tested for the 511 diﬀerent possible
combinations of features. The addition of new fea-
tures improved the performance of the algorithms
from approximately 26 % test error to 20 % test er-
ror. Gaussian Discriminant Analysis with diﬀerent
covariance matrices yielded the least error of 19.5
% and maximum recall. GDA assumes that the
data is normally distributed. Since it had the best
performance it can be concluded that the data is
normally distributed with respect to damage types.
The best feature combinations consisted of both
time domain and frequency domain features which
indicates that for a successful classiﬁcation both
time domain and frequency domain analysis must
be considered. In this study the experimental data
for three diﬀerent layups was merged into one set
of data, therefore ignoring lamb wave propagation
sensitivity to laminate conﬁguration. In the future
when more data is acquired for each separate layup,
the classiﬁcation algorithms could be implemented
to each layup separately. This will reduce variabil-
ity in the data compared to this study, and lower
classiﬁcation errors (better performance) would be
expected. This work has proved that classiﬁcation
algorithms can distinguish between delamination
and matrix cracks. With this information in hand,
we can quantify matrix cracks per path. Fig. 5
presents the results of implementing Weighted Lin-

3

ear Regression on one feature for the matrix crack
data (label = 0). Future work will explore diﬀerent
regression analysis to learn a relationship between
matrix cracks and the raw signal data.

Acknowledgements

We are grateful to Structures And Composites Lab-
oratory (SACL),Stanford and Prognostics Center
Of Excellence (PCOE), NASA Ames for providing
data for the present studies.

References

[1] Su, Z., Ye, L., Lu, Y. “Guided Lamb waves for
identiﬁcation of damage in composite structures:
A review,” Journal of Sound and Vibration , 295
(2006) 753780.

[2] Andrew Ng,
“Lecture Notes 1-Supervised
Learning, Discriminative Algorithms,” CS229-
Course Material , pp 16-19.

[3] Andrew Ng, “Lecture Notes 2-Generative Algo-
rithms,” CS229-Course Material , pp 2-7.

[4] Joachims, T., “Making large-scale SVM learn-
ing Practical,” Advances in Kernel Methods-
Support Vector Learning, MIT-Press , 1999

[5] Anton, S., “MATLAB-MEX interface to SVM-
light,”Software version provided by antonsc at
microsoft dot com

Figure 3: Generalization error measured while us-
ing 9-dimensional feature vector for the three dif-
ferent algorithms.

Figure 4: Error obtained while using diﬀerent com-
bination of input feature set for diﬀerent algo-
rithms.

Figure 2: Measure of mutual information.

Figure 5: Weighted linear regression model to
quantify the matrix crack density.

4

Feature
(x1 , x2 , x4 )
(x1 , x2 , x3 , x4 )
(x1 , x2 , x3 , x5 , x6 )
(x1 , x2 , x3 )
(x1 , x2 , x5 , x6 )
(x1 , x2 , x3 , x6 )
(x1 , x2 , x6 )
(x1 , x2 , x3 , x4 , x5 )
(x1 , x2 , x4x5 )
(x1 , x2 , x5 )

Table 2: Test error for diﬀerent feature sets
GDA (Σ) GDA (Σ0 , Σ1 )
LR
0.2408
0.2551
0.6044
0.6253
0.2467
0.2408
0.2414
0.2466
0.6167
0.2418
0.2535
0.6155
0.2422
0.2545
0.5934
0.2422
0.2472
0.6032
0.602
0.2566
0.2426
0.243
0.2449
0.6229
0.2444
0.2554
0.602
0.6106
0.2563
0.2455

NB
0.2592
0.2628
0.2664
0.2572
0.2628
0.2597
0.2564
0.2653
0.2653
0.2558

Feature
(x1 ,x2 ,x4 ,x7 ,x8 )
(x1 ,x3 ,x4 ,x6 ,x9 )
(x2 ,x3 ,x5 ,x6 ,x7 ,x9 )
(x2 ,x3 ,x4 ,x7 ,x8 ,x9 )
(x1 ,x3 ,x4 ,x6 ,x7 ,x9 )
(x1 ,x2 ,x3 ,x8 ,x9 )
(x1 ,x2 ,x4 ,x5 ,x6 ,x8 ,x9 )
(x2 ,x3 ,x4 ,x5 ,x7 ,x9 )
(x1 ,x2 ,x3 ,x6 ,x9 )
(x1 ,x2 ,x3 ,x4 ,x8 )

Table 3: Test error for the new feature set
GDA (Σ) GDA (Σ0 , Σ1 )
LR
0.6202
0.2155
0.1953
0.1984
0.2109
0.6021
0.2047
0.2326
0.6253
0.2078
0.2295
0.6163
0.6176
0.231
0.2078
0.2093
0.2388
0.615
0.2093
0.2403
0.6098
0.2109
0.2233
0.6021
0.2124
0.245
0.6279
0.6098
0.2295
0.2124

NB
0.2589
0.2961
0.2915
0.2961
0.2651
0.2543
0.2868
0.3008
0.262
0.2713

SVM
0.2494
0.2481
0.2584
0.2674
0.2377
0.2623
0.2481
0.2636
0.2481
0.27

SVM
0.2429
0.2481
0.261
0.2597
0.2416
0.27
0.2791
0.2571
0.3062
0.2752

MG
0.4436
0.3917
0.3692
0.384
0.4676
0.3088
0.3402
0.3692
0.3208
0.3654

Table 1: Feature set used. The new set of features
added are denoted in red.
Feature
Quantity
Time of ﬂight(TOF) wrt base
x1
x2
Change in amplitude
Energy content
x3
Peak value of PSD
x4
Change in PSD wrt base
x5
x6
Rate of change in PSD
TOF/PSD
x7
x8
PSD/TOF
Amplitude/TOF
x9

Figure 6: Precision-Recall curve for the diﬀerent
algorithms.

5

