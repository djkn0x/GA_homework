Bayesian Action-Graph Games

Albert Xin Jiang
Department of Computer Science
University of British Columbia
jiang@cs.ubc.ca

Kevin Leyton-Brown
Department of Computer Science
University of British Columbia
kevinlb@cs.ubc.ca

Abstract

Games of incomplete information, or Bayesian games, are an important game-
theoretic model and have many applications in economics. We propose Bayesian
action-graph games (BAGGs), a novel graphical representation for Bayesian games.
BAGGs can represent arbitrary Bayesian games, and furthermore can compactly
express Bayesian games exhibiting commonly encountered types of structure in-
cluding symmetry, action- and type-speciﬁc utility independence, and probabilistic
independence of type distributions. We provide an algorithm for computing ex-
pected utility in BAGGs, and discuss conditions under which the algorithm runs in
polynomial time. Bayes-Nash equilibria of BAGGs can be computed by adapting
existing algorithms for complete-information normal form games and leveraging
our expected utility algorithm. We show both theoretically and empirically that our
approaches improve signiﬁcantly on the state of the art.

1

Introduction

In the last decade, there has been much research at the interface of computer science and game
theory (see e.g. [19, 22]). One fundamental class of computational problems in game theory is
the computation of solution concepts of a ﬁnite game. Much of current research on computation
of solution concepts has focused on complete-information games, in which the game being played
is common knowledge among the players. However, in many multi-agent situations, players are
uncertain about the game being played. Harsanyi [10] proposed games of incomplete information (or
Bayesian games) as a mathematical model of such interactions. Bayesian games have found many
applications in economics, including most notably auction theory and mechanism design.
Our interest is in computing with Bayesian games, and particularly in identifying sample Bayes-Nash
equilibrium. There are two key obstacles to performing such computations efﬁciently. The ﬁrst
is representational: the straightforward tabular representation of Bayesian game utility functions
(the Bayesian Normal Form) requires space exponential in the number of players. For large games,
it becomes infeasible to store the game in memory, and performing even computations that are
polynomial time in the input size are impractical. An analogous obstacle arises in the context of
complete-information games: there the standard representation (normal form) also requires space
exponential in the number of players. The second obstacle is the lack of existing algorithms for
identifying sample Bayes-Nash equilibrium for arbitrary Bayesian games. Harsanyi [10] showed
that a Bayesian game can be interpreted as an equivalent complete-information game via “induced
normal form” or “agent form” interpretations. Thus one approach is to interpret a Bayesian game
as a complete-information game, enabling the use of existing Nash-equilibrium-ﬁnding algorithms
(e.g. [24, 9]). However, generating the normal form representations under both of these complete-
information interpretations causes a further exponential blowup in representation size.
Most games of interest have highly-structured payoff functions, and thus it is possible to overcome
the ﬁrst obstacle by representing them compactly. This has been done for complete information
games through (e.g.) the graphical games [16] and Action-Graph Games (AGGs) [1] representations.
In this paper we propose Bayesian Action-Graph Games (BAGGs), a compact representation for

1

Bayesian games. BAGGs can represent arbitrary Bayesian games, and furthermore can compactly
express Bayesian games with commonly encountered types of structure. The type proﬁle distribution
is represented as a Bayesian network, which can exploit conditional independence structure among
the types. BAGGs represent utility functions in a way similar to the AGG representation, and like
AGGs, are able to exploit anonymity and action-speciﬁc utility independencies. Furthermore, BAGGs
can compactly express Bayesian games exhibiting type-speciﬁc independence: each player’s utility
function can have different kinds of structure depending on her instantiated type. We provide an
algorithm for computing expected utility in BAGGs, a key step in many algorithms for game-theoretic
solution concepts. Our approach interprets expected utility computation as a probabilistic inference
problem on an induced Bayesian Network. In particular, our algorithm runs in polynomial time
for the important case of independent type distributions. To compute Bayes-Nash equilibria for
BAGGs, we consider the agent form interpretation of the BAGG. Although a naive normal form
representation would require an exponential blowup, BAGGs can act as a compact representation
of the agent form. Computational tasks on the agent form can be done efﬁciently by leveraging our
expected utility algorithm for BAGGs. We have implemented our approach by adapting two Nash
equilibrium algorithms, the simplicial subdivision algorithm [24] and Govindan and Wilson’s global
Newton method [9]. We show empirically that our approach outperforms the existing approaches of
solving for Nash on the induced normal form or on the normal form representation of the agent form.
We now discuss some related literature. There has been some research on heuristic methods for
ﬁnding Bayes-Nash equilibria for certain classes of auction games using iterated best response (see
e.g. [21, 25]). Such methods are not guaranteed to converge to a solution. Howson and Rosenthal
[12] applied the agent form transformation to 2-player Bayesian games, resulting in a complete-
information polymatrix game. Our approach can be seen as a generalization of their method to
general Bayesian games. Singh et al. [23] proposed a incomplete information version of the graphical
game representation, and presented efﬁcient algorithms for computing approximate Bayes-Nash
equilibria in the case of tree games. Gottlob et al. [7] considered a similar extension of the graphical
game representation and analyzed the problem of ﬁnding a pure-strategy Bayes-Nash equilibrium.
Like graphical games, such representations are limited in that they can only exploit strict utility
independencies. Oliehoek et al. [20] proposed a heuristic search algorithm for common-payoff
Bayesian games, which has applications to cooperative multi-agent problems. Bayesian games can
be interpreted as dynamic games with a initial move by Nature; thus, also related is the literature
on representations for dynamic games, including multi-agent inﬂuence diagrams (MAIDs) [17]
and temporal action-graph games (TAGGs) [14]. Compared to these representations for dynamic
games, BAGGs focus explicitly on structure common to Bayesian games; in particular, only BAGGs
can efﬁciently express type-speciﬁc utility structure. Also, by representing utility functions and
type distributions as separate components, BAGGs can be more versatile (e.g., a future direction
is to answer computational questions that do not depend on the type distribution, such as ex-post
equilibria). Furthermore, BAGGs can be solved by adapting Nash-equilibrium algorithms such as
Govindan and Wilson’s global Newton method [9] for static games; this is generally more practical
than their related Nash equilibrium algorithm [8] that directly works on dynamic games: while both
approach avoids the exponential blowup of transforming to the induced normal form, the algorithm
for dynamic games has to solve an additional quadratic program at each step.

2 Preliminaries
2.1 Complete-information Games
We assume readers are familiar with the basic concepts of complete-information games and here we
by ai ∈ Ai one of i’s actions. An action proﬁle a = (a1 , . . . , an ) ∈ (cid:81)
only establish essential notation. A complete-information game is a tuple (N , {Ai }i∈N , {ui }i∈N )
agents’ actions. Agent i’s utility function is ui : (cid:81)
where N = {1, . . . , n} is the set of agents; for each agent i, Ai is the set of i’s actions. We denote
i∈N Ai is a tuple of the
j∈N Aj → R. A mixed strategy σi for player i
is a probability distribution over Ai . A mixed strategy proﬁle σ is a tuple of the n players’ mixed
strategies. We denote by ui (σ) the expected utility of player i under the mixed strategy proﬁle σ . We
adopt the following notational convention: for any n-tuple X we denote by X−i the elements of X
corresponding to players other than i.
this representation is n (cid:81)
A game representation is a data structure that stores all information needed to specify a game. A
normal form representation of a game uses a matrix to represent each utility function ui . The size of
j∈N |Aj |, which grows exponentially in the number of players.

2

2.2 Bayesian Games
the set of players; each Ai is player i’s action set, and A = (cid:81)
We now deﬁne Bayesian games and discuss common types of structure.
Θ = (cid:81)
Deﬁnition 1. A Bayesian game is a tuple (N , {Ai}i∈N , Θ, P, {ui }i∈N ) where N = {1, . . . , n} is
i Ai is the set of action proﬁles;
i Θi is the set of type proﬁles, where Θi is player i’s set of types; P : Θ → R is the type
distribution and ui : A × Θ → R is the utility function for player i.
As in the complete-information case, we denote by ai an element of Ai , and a = (a1 , . . . , an ) an
action proﬁle. Furthermore we denote by θi an element of Θi , and by θ a type proﬁle. The game
is played as follows. A type proﬁle θ = (θ1 , . . . , θn ) ∈ Θ is drawn according to the distribution P .
Each player i observes her type θi and, based on this observation, chooses from her set of actions Ai .
Each player i’s utility is then given by ui (a, θ), where a is the resulting action proﬁle.
Player i can deterministically choose a pure strategy si , in which given each θi ∈ Θi she deterministi-
cally chooses an action si (θi ). Player i can also randomize and play a mixed strategy σi , in which her
probability of choosing ai given θi is σi (ai |θi ). That is, given a type θi ∈ Θi , she plays according to
distribution σi (·|θi ) over her set of actions Ai . A mixed strategy proﬁle σ = (σ1 , . . . , σn ) is a tuple
of the players’ mixed strategies.
(cid:88)
(cid:88)
(cid:89)
The expected utility of i given θi under a mixed strategy proﬁle σ is the expected value of i’s utility
under the resulting joint distribution of a and θ , conditioned on i receiving type θi :
ui (σ |θi ) =
P (θ−i |θi )
σj (aj |θj ).
θ−i
a
j
A mixed strategy proﬁle σ is a Bayes-Nash equilibrium if for all i, for all θi , for all ai ∈ Ai ,
ui (σ |θi ) ≥ ui (σθi→ai |θi ), where σθi→ai is the mixed strategy proﬁle that is identical to σ except
that i plays ai with probability 1 given θi .
In specifying a Bayesian game, the space bottlenecks are the type distribution and the utility functions.
normal form. The size of this representation is n × (cid:81)n
i=1 (|Θi | × |Ai |) + (cid:81)n
Without additional structure, we cannot do better than representing each utility function ui : A × Θ →
R as a table and the type distribution as a table as well. We call this representation the Bayesian
i=1 |Θi |.
i.e. the type-proﬁle distribution P (θ) is a product distribution: P (θ) = (cid:81)
distribution P can be represented compactly using (cid:80)
We say a Bayesian game has independent type distributions if players’ types are drawn independently,
i P (θi ). In this case the
i |Θi | numbers.
Given a permutation of players π : N → N and an action proﬁle a = (a1 , . . . , an ), let aπ =
(aπ(1) , . . . , aπ(n) ). Similarly let θπ = (θπ(1) , . . . , θπ(n) ). We say the type distribution P is symmetric
if |Θi | = |Θj | for all i, j ∈ N , and if for all permutations π : N → N , P (θ) = P (θπ ). We say a
Bayesian game has symmetric utility functions if |Ai | = |Aj | and |Θi | = |Θj | for all i, j ∈ N , and if
a game range over at most |Θi ||Ai |(cid:0)n−2+|Θi ||Ai |
(cid:1) unique utility values.
for all permutations π : N → N , we have ui (a, θ) = uπ(i) (aπ , θπ ) for all i ∈ N . A Bayesian game
is symmetric if its type distribution and utility functions are symmetric. The utility functions of such
|Θi ||Ai |−1
A Bayesian game exhibits conditional utility independence if each player i’s utility depends on the
action proﬁle a and her own type θi , but does not depend on the other players’ types. Then the utility
function of each player i ranges over at most |A||Θi | unique utility values.

ui (a, θ)

(1)

2.2.1 Complete-information interpretations

Harsanyi [10] showed that any Bayesian game can be interpreted as a complete-information game,
such that Bayes-Nash equilibria of the Bayesian game correspond to Nash equilibria of the complete-
information game. There are two complete-information interpretations of Bayesian games.
A Bayesian game can be converted to its induced normal form, which is a complete-information game
with the same set of n players, in which each player’s set of actions is her set of pure strategies in the
Bayesian game. Each player’s utility under an action proﬁle is deﬁned to be equal to the player’s
expected utility under the corresponding pure strategy proﬁle in the Bayesian game.
Alternatively, a Bayesian game can be transformed to its agent form, where each type of each player
in the Bayesian game is turned into one player in a complete-information game. Formally, given a

3

game ( ˜N , { ˜Aj,θj }(j,θj )∈ ˜N , { ˜uj,θj }(j,θj )∈ ˜N ), where ˜N consists of (cid:80)
Bayesian game (N , {Ai }i∈N , Θ, P, {ui }i∈N ), we deﬁne its agent form as the complete-information
j∈N |Θj | players, one for every
type of every player of the Bayesian game. We index the players by the tuple (j, θj ) where j ∈ N
action set of j in the Bayesian game. The set of action proﬁles is then ˜A = (cid:81)
and θj ∈ Θj . For each player (j, θj ) ∈ ˜N of the agent form game, her action set ˜A(j,θj ) is Aj , the
A(j,θj ) . The utility
j,θj
function of player (j, θj ) is ˜uj,θj : ˜A → R. For all ˜a ∈ ˜A, ˜uj,θj (˜a) is equal to the expected utility of
player j of the Bayesian game given type θj , under the pure strategy proﬁle s˜a , where for all i and all
θi , s˜a
i (θi ) = ˜a(i,θi ) . Observe that there is a one-to-one correspondence between action proﬁles in
the agent form and pure strategies of the Bayesian game. A similar correspondence exists for mixed
strategy proﬁles: each mixed strategy proﬁle σ of the Bayesian game corresponds to a mixed strategy
˜σ of the agent form, with ˜σ(i,θi ) (ai ) = σi (ai |θi ) for all i, θi , ai . It is straightforward to verify that
˜ui,θi ( ˜σ) = ui (σ |θi ) for all i, θi . This implies a correspondence between Bayes Nash equilibria of a
Bayesian game and Nash equilibria of its agent form.
Proposition 2. σ is a Bayes-Nash equilibrium of a Bayesian game if and only if ˜σ is a Nash
equilibrium of its agent form.

3 Bayesian Action-Graph Games

In this section we introduce Bayesian Action-Graph Games (BAGGs), a compact representation of
Bayesian games. First consider representing the type distributions. Speciﬁcally, the type distribution
P is speciﬁed by a Bayesian network (BN) containing at least n random variables corresponding to
the n players’ types θ1 , . . . , θn . For example, when the types are independently distributed, then P
can be speciﬁed by the simple BN with n variables θ1 , . . . , θn and no edges.
Now consider representing the utility functions. Our approach is to adapt concepts from the AGG
representation [1, 13] to the Bayesian game setting. At a high level, a BAGG is a Bayesian game on
an action graph, a directed graph on a set of action nodes A. To play the game, each player i, given
her type θi , simultaneously chooses an action node from her type-action set Ai,θi ⊆ A. Each action
node thus corresponds to an action choice that is available to one or more of the players. Once the
players have made their choices, an action count is tallied for each action node α ∈ A, which is the
number of agents that have chosen α. A player’s utility depends only on the action node she chose
and the action counts on the neighbors of the chosen node.
We now turn to a formal description of BAGG’s utility function representation. Central to our model
is the action graph. An action graph G = (A, E ) is a directed graph where A is the set of action
nodes, and E is a set of directed edges, with self edges allowed. We say α(cid:48) is a neighbor of α if there
is an edge from α(cid:48) to α, i.e., if (α(cid:48) , α) ∈ E . Let the neighborhood of α, denoted ν (α), be the set of
neighbors of α.
i = (cid:83)
For each player i and each instantiation of her type θi ∈ Θi , her type-action set Ai,θi ⊆ A is the set
We denote by A = (cid:81)
of possible action choices of i given θi . These subsets are unrestricted: different type-action sets
may (partially or completely) overlap. Deﬁne player i’s total action set to be A∪
Ai,θi .
θi∈Θi
the set of action proﬁles, and by a ∈ A an action proﬁle. Observe that
i A∪
i
the action proﬁle a provides sufﬁcient information about the type proﬁle to be able to determine the
outcome of the game; there is no need to additionally encode the realized type distribution. We note
i ∈ Θi , Ai,θi and Ai,θ(cid:48)
that for different types θi , θ (cid:48)
may have different sizes; i.e., i may have different
i
numbers of available action choices depending on her realized type.
A conﬁguration c is a vector of |A| non-negative integers, specifying for each action node the
numbers of players choosing that action. Let c(α) be the element of c corresponding to the action
α. Let C : A (cid:55)→ C be the function that maps from an action proﬁle a to the corresponding
conﬁguration c. Formally, if c = C (a) then c(α) = |{i ∈ N : ai = α}| for all α ∈ A. Deﬁne
C = {c : ∃a ∈ A such that c = C (a)}. In other words, C is the set of all possible conﬁgurations.
We can also deﬁne a conﬁguration over a subset of nodes. In particular, we will be interested in
conﬁgurations over a node’s neighborhood. Given a conﬁguration c ∈ C and a node α ∈ A, let
the conﬁguration over the neighborhood of α, denoted c(α) , be the restriction of c to ν (α), i.e.,
c(α) = (c(α(cid:48) ))α(cid:48)∈ν (α) . Similarly, let C (α) denote the set of conﬁgurations over ν (α) in which at
least one player plays α. Let C (α) : A (cid:55)→ C (α) be the function which maps from an action proﬁle to
the corresponding conﬁguration over ν (α).

4

G, {uα }α∈A ) where N is the set of agents; Θ = (cid:81)
Deﬁnition 3. A Bayesian action-graph game (BAGG) is a tuple (N , Θ, P, {Ai,θi }i∈N ,θi∈Θi ,
i Θi is the set of type proﬁles; P is the type
distribution, represented as a Bayesian network; Ai,θi ⊆ A is the type-action set of i given θi ;
G = (A, E ) is the action graph; and for each α ∈ A, the utility function is uα : C (α) → R.

Intuitively, this representation captures two types of structure in utility functions: ﬁrstly, shared
actions capture the game’s anonymity structure: if two action choices from different type-action sets
share an action node α, it means that these two actions are interchangeable as far as the other players’
utilities are concerned. In other words, their utilities may depend on the number of players that chose
the action node α, but not the identities of those players. Secondly, the (lack of) edges between
nodes in the action graph expresses action- and type-speciﬁc independencies of utilities of the game:
depending on player i’s chosen action node (which also encodes information about her type), her
utility depends on conﬁgurations over different sets of nodes.
Lemma 4. An arbitrary Bayesian game given in Bayesian normal form can be encoded as a BAGG
storing the same number of utility values.

Proof. Provided in the supplementary material.

Bayesian games with symmetric utility functions exhibit anonymity structure, which can be expressed
in BAGGs by sharing action nodes. Speciﬁcally, we label each Θi as {1, . . . , T }, so that each
t ∈ {1, . . . , T } corresponds to a class of equivalent types. Then for each t ∈ {1, . . . , T }, we have
Ai,t = Aj,t for all i, j ∈ N , i.e. type-action sets for equivalent types are identical.
3.1 BAGGs with function nodes
In this section we extend the basic BAGG representation by introducing function nodes to the action
graph. The concept of function nodes was ﬁrst introduced in the (complete-information) AGG setting
[13]. Function nodes allow us to exploit a much wider variety of utility structures in BAGGs.
In this extended representation, the action graph G’s vertices consist of both the set of action nodes A
and the set of function nodes F . We require that no function node p ∈ F can be in any player’s action
set. Each function node p ∈ F is associated with a function f p : C (p) → R. We extend c by deﬁning
c(p) to be the result of applying f p to the conﬁguration over p’s neighbors, f p (c(p) ). Intuitively, c(p)
can be used to describe intermediate parameters that players’ utilities depend on. To ensure that the
BAGG is meaningful, the graph restricted to nodes in F is required to be a directed acyclic graph. As
before, for each action node α we deﬁne a utility function uα : C (α) → R.
Of particular computational interest is the subclass of contribution-independent function nodes
(also introduced by [13]). A function node p in a BAGG is contribution-independent if ν (p) ⊆ A,
there exists a commutative and associative operator ∗, and for each α ∈ ν (p) an integer wα , such
that given an action proﬁle a = (a1 , . . . , an ), c(p) = ∗i∈N :ai∈ν (p) wai . A BAGG is contribution-
independent if all its function nodes are contribution-independent. Intuitively, if function node p is
contribution-independent, each player’s strategy affects c(p) independently.
A very useful kind of contribution-independent function nodes are counting function nodes, which
set ∗ to the summation operator + and the weights to 1. Such a function node p simply counts the
for P is exponential only in the in-degree of the BN. The utility functions store (cid:80)
number of players that chose any action in ν (p).
Let us consider the size of a BAGG representation. The representation size of the Bayesian network
α |C (α) | values. As
in similar analysis for AGGs [15], estimations of this size generally depend on what types of function
nodes are included. We state only the following (relatively straightforward) result since in this paper
we are mostly concerned with BAGGs with counting function nodes.
by a constant, then the sizes of the BAGGs are bounded by a polynomial in n, |A|, |F |, (cid:80)
Theorem 5. Consider BAGGs whose only function nodes, if any, are counting function nodes. If the
in-degrees of the action nodes as well as the in-degrees of the Bayesian networks for P are bounded
i |Θi | and
the sizes of domains of variables in the BN.

This theorem shows a nice property of counting function nodes: representation size does not grow
exponentially in the in-degrees of these counting function nodes. The next example illustrates the
usefulness of counting function nodes, including for expressing conditional utility independence.

5

Example 6 (Coffee Shop game). Consider a symmetric Bayesian game involving n players; each
player plans to open a new coffee shop in a downtown area, but has to decide on the location. The
downtown area is represented by a r × k grid. Each player can choose to open a shop located within
any of the B ≡ rk blocks or decide not to enter the market. Each player has T types, representing
her private information about her cost of opening a coffee shop. Players’ types are independently
distributed. Conditioned on player i choosing some location, her utility depends on: (a) her own
type; (b) the number of players that chose the same block; (c) the number of players that chose any of
the surrounding blocks; and (d) the number of players that chose any other location.

The Bayesian normal form representation of this game has size n[T (B + 1)]n . The game can be
expressed as a BAGG as follows. Since the game is symmetric, we label the types as {1, . . . , T }. A
contains one action O corresponding to not entering and T B other action nodes, with each location
corresponding to a set of T action nodes, each representing the choice of that location by a player
with a different type. For each t ∈ {1, . . . , T }, the type-action sets Ai,t = Aj,t for all i, j ∈ N and
each consists of the action O and B actions corresponding to locations for type t. For each location
(x, y) we create three function nodes: pxy representing the number of players choosing this location,
p(cid:48)
xy representing the number of players choosing any surrounding blocks, and p(cid:48)(cid:48)
xy representing the
number of players choosing any other block. Each of these function nodes is a counting function
node, whose neighbors are action nodes corresponding to the appropriate locations (for all types).
Each action node for location (x, y) has three neighbors, pxy , p(cid:48)
xy , and p(cid:48)(cid:48)
xy . Since the BAGG action
graph has maximum in-degree 3, by Theorem 5 the representation size is polynomial in n, B and T .

4 Computing a Bayes-Nash Equilibrium

In this section we consider the problem of ﬁnding a sample Bayes-Nash equilibrium given a BAGG.
Our overall approach is to interpret the Bayesian game as a complete-information game, and then to
apply existing algorithms for ﬁnding Nash equilibria of complete-information games. We consider
two state-of-the-art Nash equilibrium algorithms, van der Laan et al’s simplicial subdivision [24]
and Govindan and Wilson’s global Newton method [9]. Both run in exponential time in the worst
case, and indeed recent complexity theoretic results [3, 6, 4] imply that a polynomial-time algorithm
for Nash equilibrium is unlikely to exist.1 Nevertheless, we show that we can achieve exponential
speedups in these algorithms by exploiting the structure of BAGGs.
Recall from Section 2.2.1 that a Bayesian game can be transformed into its induced normal form or
its agent form. In the induced normal form, each player i has |Ai ||Θi | actions (corresponding to her
pure strategies of the Bayesian game). Solving such a game would be infeasible for large |Θi |; just to
represent an Nash equilibrium requires space exponential in |Θi |.
A more promising approach is to consider the agent form. Note that we can straightforwardly adapt
complete-information game has (cid:80)
the agent-form transformation described in Section 2.2.1 to the setting of BAGGs: now the action set
Nash equilibrium can be represented using just (cid:80)
(cid:80)
of player (i, θi ) of the agent form corresponds to the type-action set Ai,θi of the BAGG. The resulting
i∈N |Θi | players and |Ai,θi | actions for each player (i, θi ); a
representation of the agent form has size (cid:80)
j∈N |Θj | (cid:81)
|Ai,θi | numbers. However, the normal form
|Ai,θi |, which grows exponentially in n
θi
i
i,θi
and |Θi |. Applying the Nash equilibrium algorithms to this normal form would be infeasible in terms
of time and space. Fortunately, we do not have to explicitly represent the agent form as a normal
form game. Instead, we treat a BAGG as a compact representation of its agent form, and carry out
any required computation on the agent form by operating on the BAGG. A key computational task
required by both Nash equilibrium algorithms in their inner loops is the computation of expected
utility of the agent form. Recall from Section 2.2.1 that for all (i, θi ) the expected utility ˜ui,θi ( ˜σ) of
the agent form is equal to the expected utility ui (σ |θi ) of the Bayesian game. Thus in the remainder
of this section we focus on the problem of computing expected utility in BAGGs.

4.1 Computing Expected Utility in BAGGs
Recall that σθi→ai is the mixed strategy proﬁle that is identical to σ except that i plays ai given θi .
The main quantity we are interested in is ui (σθi→ai |θi ), player i’s expected utility given θi under
1There has been some research on efﬁcient Nash-equilibrium-ﬁnding algorithms for subclasses of games,
such as Daskalakis and Papadimitriou’s [5] PTAS for anonymous games with ﬁxed numbers of actions. One
future direction would be to adapt these algorithms to subclasses of Bayesian games.

6

ui (σ |θi ) = (cid:80)
the strategy proﬁle σθi→ai . Note that the expected utility ui (σ |θi ) can then be computed as the sum
ui (σθi→ai |θi )σi (ai |θi ).
ai
One approach is to directly apply Equation (1), which has (|Θ−i | × |A|) terms in the summation.
For games represented in Bayesian normal form, this algorithm runs in time polynomial in the
representation size. Since BAGGs can be exponentially more compact than their equivalent Bayesian
normal form representations, this algorithm runs in exponential time for BAGGs.
In this section we present a more efﬁcient algorithm that exploits BAGG structure. We ﬁrst formulate
the expected utility problem as a Bayesian network inference problem. Given a BAGG and a mixed
strategy proﬁle σθi→ai , we construct the induced Bayesian network (IBN) as follows.
We start with the BN representing the type distribution P , which includes (at least) the random
variables θ1 , . . . , θn . The conditional probability distributions (CPDs) for the network are unchanged.
We add the following random variables: one strategy variable Dj for each player j ; one action
count variable for each action node α ∈ A, representing its action count, denoted c(α); one function
variable for each function node p ∈ F , representing its conﬁguration value, denoted c(p); and one
utility variable U α for each action node α. We then add the following edges: an edge from θj to Dj
for each player j ; for each player j and each α ∈ A∪
j , an edge from Dj to c(α); for each function
variable c(p), all incoming edges corresponding to those in the action graph G; and for each α ∈ A,
for each action or function node m ∈ ν (α) in G, an edge from c(m) to U α in the IBN.
The CPDs of the newly added random variables are deﬁned as follows. Each strategy variable
Dj has domain A∪
j , and given its parent θj , its CPD chooses an action from A∪
j according to the
. In other words, if j (cid:54)= i then Pr(Dj = aj |θj ) is equal to σj (aj |θj ) for all
mixed strategy σθi→ai
j
aj ∈ Aj,θj and 0 for all aj ∈ A∪
j \ Aj,θj ; and if j = i we have Pr(Dj = ai |θj ) = 1. For each
action node α, the parents of its action-count variable c(α) are strategy variables that have α in their
domains. The CPD is a deterministic function that returns the number of its parents that take value α;
i.e., it calculates the action count of α. For each function variable c(p), its CPD is the deterministic
function f p . The CPD for each utility variable U α is a deterministic function speciﬁed by uα .
It is straightforward to verify that the IBN is a directed acyclic graph (DAG) and thus represents a
valid joint distribution. Furthermore, the expected utility ui (σ ti→ai |θi ) is exactly the expected value
of the variable U ai conditioned on the instantiated type θi .
Lemma 7. For all i ∈ N , all θi ∈ Θi and all ai ∈ Ai,θi , we have ui (σθi→ai |θi ) = E [U ai |θi ].
Standard BN inference methods could be used to compute E [U ai |θi ]. However, such standard
algorithms do not take advantage of structure that is inherent in BAGGs. In particular, recall that
in the induced network, each action count variable c(α)’s parents are all strategy variables that
have α in their domains, implying large in-degrees for action count variables. Applying (e.g.) the
clique-tree algorithm would yield large clique sizes, which is problematic because running time scales
exponentially in the largest clique size of the clique tree. However, the CPDs of these action count
variables are structured counting functions. Such structure is an instance of causal independence in
BNs [11]. It also corresponds to anonymity structure for complete-information game representations
like symmetric games and AGGs [13]. We can exploit this structure to speed up computation of
expected utility in BAGGs. Our approach is a specialization of Heckerman and Breese’s method
[11] for exploiting causal independence in BNs, which transforms the original BN by creating new
nodes that represent intermediate results, and re-wiring some of the arcs, resulting in an equivalent
BN with small in-degree. Given an action count variable c(α) with parents (say) {D1 . . . Dn}, for
each i ∈ {1 . . . n − 1} we create a node Mα,i , representing the count induced by D1 . . . Di . Then,
instead of having D1 . . . Dn as parents of c(α), its parents become Dn and Mα,n−1 , and each Mα,i ’s
parents are Di and Mα,i−1 . The resulting graph has in-degree at most 2 for c(α) and the Mα,i ’s. The
CPDs of function variables corresponding to contribution-independent function nodes also exhibit
causal independence, and thus we can use a similar transformation to reduce their in-degree to 2. We
call the resulting Bayesian network the transformed Bayesian network (TBN) of the BAGG.
It is straightforward to verify that the representation size of the TBN is polynomial in the size of the
BAGG. We can then use standard inference algorithms to compute E [U α |θi ] on the TBN. For classes
of BNs with bounded treewidths, this can be computed in polynomial time. Since the graph structure
(and thus the treewidth) of the TBN does not depend on the strategy proﬁle and only depends on the
BAGG, we have the following result.

7

Figure 4:
subdivision.

simplicial

Figure 3: GW, varying
types.

Figure 1: GW, varying
Figure 2: GW, varying
players.
locations.
time polynomial in n, |A|, |F | and | (cid:80)
Theorem 8. For BAGGs whose TBNs have bounded treewidths, expected utility can be computed in
i Θi |.
Bayesian games with independent type distributions are an important class of games and have many
applications, such as independent-private-value auctions. When contribution-independent BAGGs
have independent type distributions, expected utility can be efﬁciently computed.
Theorem 9. For contribution-independent BAGGs with independent type distributions, expected
utility can be computed in time polynomial in the size of the BAGG.
Proof. Provided in the supplementary material.

Note that this result is stronger than that of Theorem 8, which only guarantees efﬁcient computation
when TBNs have constant treewidth.

5 Experiments

We have implemented our approach for computing a Bayes-Nash equilibrium given a BAGG by
applying Nash equilibrium algorithms on the agent form of the BAGG. We adapted two algorithms,
GAMBIT’s [18] implementation of simplicial subdivision and GameTracer’s [2] implementation of
Govindan and Wilson’s global Newton method, by replacing calls to expected utility computations
of the complete-information game with corresponding expected utility computations of the BAGG.
We ran experiments that tested the performance of our approach (denoted by BAGG-AF) against
two approaches that compute a Bayes-Nash equilibrium for arbitrary Bayesian games. The ﬁrst
(denoted INF) computes a Nash equilibrium on the induced normal form; the second (denoted NF-
AF) computes a Nash equilibrium on the normal form representation of the agent form. Both were
implemented using the original, normal-form-based implementations of simplicial subdivision and
global Newton method. We thus studied six concrete algorithms, two for each game representation.
We tested these algorithms on instances of the Coffee Shop Bayesian game described in Example 6.
We created games of different sizes by varying the number of players, the number of types per player
and the number of locations. For each size we generated 10 game instances with random integer
payoffs, and measured the running (CPU) times. Each run was cut off after 10 hours if it had not yet
ﬁnished. All our experiments were performed using a computer cluster consisting of 55 machines
with dual Intel Xeon 3.2GHz CPUs, 2MB cache and 2GB RAM, running Suse Linux 11.1.
We ﬁrst tested the three approaches based on the Govindan-Wilson (GW) algorithm. Figure 1 shows
running time results for Coffee Shop games with n players, 2 types per player on a 2 × 3 grid, with
n varying from 3 to 7. Figure 2 shows running time results for Coffee Shop games with 3 players,
2 types per player on a 2 × x grid, with x varying from 3 to 10. Figure 3 shows results for Coffee
Shop games with 3 players, T types per player on a 1 × 3 grid, with T varying from 2 to 8. The data
points represent the median running time of 10 game instances, with the error bars indicating the
maximum and minimum running times. All results show that our BAGG-based approach (BAGG-AF)
signiﬁcantly outperformed the two normal-form-based approaches (INF and NF-AF). Furthermore,
as we increased the dimensions of the games the normal-form based approaches quickly ran out of
memory (hence the missing data points), whereas BAGG-NF did not.
We also did some preliminary experiments on BAGG-AF and NF-AF running the simplicial subdivi-
sion algorithm. Figure 4 shows running time results for Coffee Shop games with n players, 2 types
per player on a 1 × 3 grid, with n varying from 3 to 6. Again, BAGG-AF signiﬁcantly outperformed
NF-AF, and NF-AF ran out of memory for game instances with more than 4 players.

8

110100100010000100000in secondsBAGG-AFNF-AFINF0.111010010001000010000034567CPU time in secondsnumber of playersBAGG-AFNF-AFINF10000100000100010000100000nds10100100010000100000econds110100100010000100000in seconds0.1110100100010000100000time in seconds0.111010010001000010000068101214161820CPU time in secondsnumberoflocations0.111010010001000010000068101214161820CPU time in secondsnumber of locations10000100100010000ds10100100010000econds01110100100010000in seconds0.010.1110100100010000time in seconds0.010.11101001000100002345678CPU time in secondstypes perplayer0.010.11101001000100002345678CPU time in secondstypes perplayer10100100010000e in secondsBAGG-AFNF-AF110100100010000234567CPU time in secondsnumber of playersBAGG-AFNF-AFReferences
[1] N. Bhat and K. Leyton-Brown. Computing Nash equilibria of action-graph games. In UAI,
pages 35–42, 2004.
[2] B. Blum, C. Shelton, and D. Koller. Gametracer. http://dags.stanford.edu/Games/
gametracer.html, 2002.
In FOCS:
[3] X. Chen and X. Deng. Settling the complexity of 2-player Nash-equilibrium.
Proceedings of the Annual IEEE Symposium on Foundations of Computer Science, pages
261–272, 2006.
[4] C. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou. The complexity of computing a Nash
equilibrium. In STOC: Proceedings of the Annual ACM Symposium on Theory of Computing,
pages 71–78, 2006.
[5] C. Daskalakis and C. Papadimitriou. Computing equilibria in anonymous games. In FOCS:
Proceedings of the Annual IEEE Symposium on Foundations of Computer Science, pages 83–93,
2007.
[6] P. W. Goldberg and C. H. Papadimitriou. Reducibility among equilibrium problems. In STOC:
Proceedings of the Annual ACM Symposium on Theory of Computing, pages 61–70, 2006.
[7] G. Gottlob, G. Greco, and T. Mancini. Complexity of pure equilibria in Bayesian games. In
IJCAI, pages 1294–1299, 2007.
[8] S. Govindan and R. Wilson. Structure theorems for game trees. Proceedings of the National
Academy of Sciences, 99(13):9077–9080, 2002.
[9] S. Govindan and R. Wilson. A global Newton method to compute Nash equilibria. Journal of
Economic Theory, 110:65–86, 2003.
[10] J.C. Harsanyi. Games with incomplete information played by “Bayesian” players, i-iii. part i.
the basic model. Management science, 14(3):159–182, 1967.
[11] David Heckerman and John S. Breese. Causal independence for probability assessment and
inference using Bayesian networks. IEEE Transactions on Systems, Man and Cybernetics,
26(6):826–831, 1996.
[12] J.T. Howson Jr and R.W. Rosenthal. Bayesian equilibria of ﬁnite two-person games with
incomplete information. Management Science, pages 313–315, 1974.
[13] A. X. Jiang and K. Leyton-Brown. A polynomial-time algorithm for Action-Graph Games. In
AAAI, pages 679–684, 2006.
[14] A. X. Jiang, A. Pfeffer, and K. Leyton-Brown. Temporal Action-Graph Games: A new
representation for dynamic games. In UAI, 2009.
[15] Albert Xin Jiang, Kevin Leyton-Brown, and Navin Bhat. Action-graph games. Games and
Economic Behavior, 2010. In press.
[16] M.J. Kearns, M.L. Littman, and S.P. Singh. Graphical models for game theory. In UAI, pages
253–260, 2001.
[17] D. Koller and B. Milch. Multi-agent inﬂuence diagrams for representing and solving games. In
IJCAI, 2001.
[18] R. D. McKelvey, A. M. McLennan, and T. L. Turocy. Gambit: Software tools for game theory,
2006. http://econweb.tamu.edu/gambit.
[19] N. Nisan, T. Roughgarden, E. Tardos, and V. Vazirani, editors. Algorithmic Game Theory.
Cambridge University Press, Cambridge, UK, 2007.
[20] Frans A. Oliehoek, Matthijs T. J. Spaan, Jilles Dibangoye, and Christopher Amato. Heuristic
search for identical payoff bayesian games. In AAMAS: Proceedings of the International Joint
Conference on Autonomous Agents and Multiagent Systems, pages 1115–1122, May 2010.
[21] Daniel M. Reeves and Michael P. Wellman. Computing best-response strategies in inﬁnite
games of incomplete information. In UAI, pages 470–478, 2004.
[22] Y. Shoham and K. Leyton-Brown. Multiagent Systems: Algorithmic, Game-Theoretic, and
Logical Foundations. Cambridge University Press, New York, 2009.
[23] S. Singh, V. Soni, and M. Wellman. Computing approximate Bayes-Nash equilibria in tree-
games of incomplete information. In EC: Proceedings of the ACM Conference on Electronic
Commerce, pages 81–90. ACM, 2004.
[24] G. van der Laan, A.J.J. Talman, and L. van der Heyden. Simplicial variable dimension algorithms
for solving the nonlinear complementarity problem on a product of unit simplices using a general
labelling. Mathematics of Operations Research, 12(3):377–397, 1987.
[25] Yevgeniy Vorobeychik. Mechanism Design and Analysis Using Simulation-Based Game Models.
PhD thesis, University of Michigan, 2008.

9

