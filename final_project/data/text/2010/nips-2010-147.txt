Practical Large-Scale Optimization
for Max-Norm Regularization

Jason Lee
Institute of Computational and Mathematical Engineering
Stanford University
email: jl115@yahoo.com

Benjamin Recht
Department of Computer Sciences
University of Wisconsin-Madison
email: brecht@cs.wisc.edu

Ruslan Salakhutdinov
Brain and Cognitive Sciences and CSAIL
Massachusetts Institute of Technology
email: rsalakhu@mit.edu

Nathan Srebro
Toyota Technological Institute at Chicago
email: nati@ttic.edu

Joel A. Tropp
Computing and Mathematical Sciences
California Institute of Technology
email: jtropp@acm.caltech.edu

Abstract

The max-norm was proposed as a convex matrix regularizer in [1] and was shown
to be empirically superior to the trace-norm for collaborative ﬁltering problems.
Although the max-norm can be computed in polynomial time, there are currently
no practical algorithms for solving large-scale optimization problems that incor-
porate the max-norm. The present work uses a factorization technique of Burer
and Monteiro [2] to devise scalable ﬁrst-order algorithms for convex programs
involving the max-norm. These algorithms are applied to solve huge collabora-
tive ﬁltering, graph cut, and clustering problems. Empirically, the new methods
outperform mature techniques from all three areas.

1
Introduction
A foundational concept in modern machine learning is to construct models for data by balancing
the complexity of the model against ﬁdelity to the measurements. In a wide variety of applications,
such as collaborative ﬁltering, multi-task learning, multi-class learning and clustering of multivariate
observations, matrices offer a natural way to tabulate data. For such matrix models, the matrix rank
provides an intellectually appealing way to describe complexity. The intuition behind this approach
holds that many types of data arise from a noisy superposition of a small number of simple (i.e.,
rank-one) factors.
Unfortunately, optimization problems involving rank constraints are computationally intractable ex-
cept in a few basic cases. To address this challenge, researchers have searched for alternative com-
plexity measures that can also promote low-rank models. A particular example of a low-rank reg-
ularizer that has received a huge amount of recent attention is the trace-norm, equal to the sum of
the matrix’s singular values (See the comprehensive survey [3] and its bibliography). The trace-
norm promotes low-rank decompositions because it minimizes the (cid:96)1 norm of the vector of singular
values, which encourages many zero singular values.
Although the trace-norm is a very successful regularizer in many applications, it does not seem to be
widely known or appreciated that there are many other interesting norms that promote low rank. The

1

.

(1)

A2
jk

paper [4] is one of the few articles in the machine learning literature that pursues this idea with any
vigor. The current work focuses on another rank-promoting regularizer, sometimes called the max-
norm, that has been proposed as an alternative to the rank for collaborative ﬁltering problems [1, 5].
(cid:110)(cid:107)U (cid:107)2,∞ (cid:107)V (cid:107)2,∞ : X = U V (cid:48)(cid:111)
The max-norm can be deﬁned via matrix factorizations:
(cid:107)X (cid:107)max := inf
where (cid:107)·(cid:107)2,∞ denotes the maximum (cid:96)2 row norm of a matrix:
(cid:16)(cid:88)
(cid:17)1/2
(cid:107)A(cid:107)2,∞ := maxj
k
For general matrices, the computation of the max-norm can be rephrased as a semideﬁnite pro-
gram; see (4) below. When X is positive semideﬁnite, we may force U = V and then verify that
(cid:107)X (cid:107)max = maxj xj j , which should explain the terminology.
The fundamental result in the metric theory of tensor products, due to Grothendieck, states that the
(cid:110)(cid:107)σ(cid:107)1 : X = (cid:88)
(cid:111)
max-norm is comparable with a nuclear norm (see Chapter 10 of [6]):
(cid:107)X (cid:107)max ≈ inf
j where (cid:107)uj (cid:107)∞ = 1 and (cid:107)vj (cid:107)∞ = 1
σj uj v (cid:48)
.
j
The factor of equivalence 1.676 ≤ κG ≤ 1.783 is called Grothendieck’s constant. The trace-norm,
(cid:111)
(cid:110)(cid:107)σ(cid:107)1 : X = (cid:88)
on the other hand, is equal to
(cid:107)X (cid:107)tr := inf
j
This perspective reveals that the max-norm promotes low-rank decompositions with factors in (cid:96)∞ ,
rather than the (cid:96)2 factors produced by the trace-norm! Heuristically, we expect max-norm regular-
ization to be effective for uniformly bounded data, such as preferences.
The literature already contains theoretical and empirical evidence that the max-norm is superior to
the trace-norm for certain types of problems. Indeed, the max-norm offers better generalization
error bounds for collaborative ﬁltering [5], and it outperforms the trace-norm in small-scale experi-
ments [1]. The paper [7] provides further evidence that the max-norm serves better for collaborative
ﬁltering with nonuniform sampling patterns.
We believe that the max-norm has not achieved the same prominence as the trace-norm because of an
apprehension that it is challenging to solve optimization problems involving a max-norm regularizer.
The goal of this paper is to refute this misconception.
We provide several algorithms that are effective for very large scale problems, and we demonstrate
the power of the max-norm regularizer using examples from a variety of applications. In particular,
we study convex programs of the form
min f (X ) + µ (cid:107)X (cid:107)max
where f is a smooth function and µ is a positive penalty parameter. Section 4 outlines a proximal-
point method, based on the work of Fukushima and Mine [8], for approaching (2). We also study
the bound-constrained problem

j where (cid:107)uj (cid:107)2 = 1 and (cid:107)vj (cid:107)2 = 1
σj uj v (cid:48)

.

(2)

subject to

min f (X )

(cid:107)X (cid:107)max ≤ B .
Of course, (2) and (3) are equivalent for appropriate choices of µ and B , but we describe scenarios
where there may be a preference for one versus the other. Section 3 provides a projected gradient
method for (3), and Section 5 develops a stochastic implementation that is appropriate for decom-
posable loss functions. These methods can be coded up in a few lines of numerical python or Matlab,
and they scale to huge instances, even on a standard desktop machine. In Section 6, we apply these
new algorithms to large-scale collaborative ﬁltering problems, and we demonstrate performance su-
perior to methods based on the trace-norm. We apply the algorithms to solve enormous instances
of graph cut problems, and we establish that clustering based on these cuts outperforms spectral
clustering on several data sets.

(3)

2

=

.

(4)

subject to

2 The SDP and Factorization Approaches
(cid:20)W1 X
(cid:21)
The max-norm of an m × n matrix X can be expressed as the solution to a semideﬁnite program:
(cid:107)X (cid:107)max = min t
(cid:23) 0,
diag(W1 ) ≤ t,
diag(W2 ) ≤ t.
X (cid:48) W2
Unfortunately, standard interior-point methods for this problem do not scale to matrices with more
than a few hundred rows or columns. For large-scale problems, we use an alternative formulation
suggested by (1) that explicitly works with a factorization of the decision variable X .
We employ an idea of Burer and Monteiro [2] that has far reaching consequences. The positive
(cid:21) (cid:20)L
(cid:20)L
(cid:20)W1 X
(cid:21)
(cid:21)(cid:48)
deﬁnite constraint in the SDP formulation above is trivially satisﬁed if we deﬁne L and R via
X (cid:48) W2
R
R
Burer and Monteiro showed that as long as L and R have sufﬁciently many columns, then the global
optimum of (4) is equal to that of
2,∞ , (cid:107)R(cid:107)2
2,∞ } .
(cid:107)X (cid:107)max =
max{(cid:107)L(cid:107)2
min
(L,R) : LR(cid:48)=X
In particular, we may assume that the number of columns is less than m + n. This formulation of the
max-norm is nonconvex because it involves a constraint on the product LR(cid:48) , but Burer and Mon-
teiro proved that each local minimum of the reformulated problem is also a global optimum [9]. If
we select L and R to have a very small number of columns, say r , then the number of real decision
variables in the optimization problems (2) and (3) is reduced from mn to r(m + n), a dramatic
improvement in the dimensionality of the problem. On the other hand, the new formulation is non-
convex with respect to L and R so it might not be efﬁciently solvable. In what follows, we present
fast, ﬁrst-order methods for solving (2) and (3) via this low-dimensional factored representation.
3 Projected Gradient Method
The constrained formulation (3) admits a simple projected gradient algorithm. We replace X with
the product LR(cid:48) and use the factored form of the max-norm (5) to obtain
2,∞ , (cid:107)R(cid:107)2
subject to max{(cid:107)L(cid:107)2
2,∞ } ≤ B .
minimize(L,R) f (LR(cid:48) )
(cid:20)L
(cid:21)
(cid:18)(cid:20) L − τ ∇f (LR)R
(cid:21)(cid:19)
The projected gradient descent method ﬁxes a step size τ and computes updates with the rule
← PB
R − τ ∇f (LR)(cid:48)L
R
where PB denotes the Euclidean projection onto the set {(L, R) : max((cid:107)L(cid:107)2
2,∞ , (cid:107)R(cid:107)2
2,∞ ) ≤ B }.
√
√
√
This projection can be computed by re-scaling the rows of the current iterate whose norms exceed
B so their norms equal
B are unchanged by the projection. The
B . Rows with norms less than
projected gradient algorithm is elegant and simple, and it has an online implementation, described
below. Moreover, using an Armijo line search rule to guarantee sufﬁcient decrease of the cost
function, we can guarantee convergence to a stationary point of (3); see [10, Sec. 2.3].
4 Proximal Point Method for Penalty Formulation
Solving (2) is slightly more complicated than its constrained counterpart. We employ a classical
proximal point method, proposed by Fukushima and Mine [8], which forms the algorithmic foun-
dation of many popular ﬁrst-order methods of for (cid:96)1 -norm minimization [11, 12] and trace-norm
minimization [13, 14]. The key idea is that our cost function is the sum of a smooth term plus a
convex term. At each iteration, we replace the smooth term by a linear approximation. The new
cost function can then be minimized in closed form. Before describing the proximal point algorithm
in detail, we ﬁrst discuss how a simple max-norm problem (the Frobenius norm plus a max-norm
penalty) admits an explicit formula for its unique optimal solution.
Consider the simple regularization problem
F + β (cid:107)W (cid:107)2
minimizeW (cid:107)W − V (cid:107)2
2,∞

(5)

(6)

(7)

3

Algorithm 1 Compute W = squash(V , β )
Require: A d × D matrix V , a positive scalar β .
F + β (cid:107)Z (cid:107)2
(cid:107)Z − V (cid:107)2
Ensure: A d × D matrix W ∈ arg minZ
2,∞ .
1: for k = 1 to d set nk ← (cid:107)vk (cid:107)2
2: sort {nk } in descending order. Let π denote the sorting permutation such that nπ(j ) is the j th
3: for k = 1 to d set sk ← (cid:80)k
largest element in the sequence.
i=1 nπ(i) .
k+β }
4: q ← max{k : nπ(k) ≥ sk
5: η ← sq
q+β
6: for k = 1 to d, if k ≤ q , set wπ(k) ← ηvπ(k)/(cid:107)vπ(k) (cid:107)2 . otherwise set wπ(k) ← vπ(k)

where W and V are d × D matrices. Just as with (cid:96)1 -norm and trace-norm regularization, this
problem can be solved in closed form. An efﬁcient algorithm to solve (7) is given by Algorithm 1.
We call this procedure squash because the rows of V with large norm have their magnitude clipped
at a critical value η = η(V , β ).

Proposition 4.1 squash(V , β ) is an optimal solution of (7)

The proof of this proposition follows from an analysis of the KKT conditions for the regularized
problem. We include a full derivation in the appendix. Note that squash can be computed in
O(d max{log(d), D}) ﬂops. Computing the row norms requires O(dD) ﬂops, and then the sort
requires O(d log d) ﬂops. Computing η and q require O(d) operations. Constructing W then re-
quires O(dD) operations.
With the squash function in hand, we can now describe our proximal-point algorithm. Replace
the decision variable X in (2) with LR(cid:48) . With this substitution and the factored form of the max-
norm, (5), Problem (2) reduces to
2,∞ , (cid:107)R(cid:107)2
minimize(L,R) f (LR(cid:48) ) + µ max{(cid:107)L(cid:107)2
2,∞} .

(8)
(cid:21)
(cid:20) L
For ease of notation, deﬁne A to be the matrix of factors stacked on top of one another A =
.
R
2,∞ , (cid:107)R(cid:107)2
2,∞ = max{(cid:107)L(cid:107)2
2,∞ }. Also let ˜f (A) denote f (LR(cid:48) ),
With this notation, we have (cid:107)A(cid:107)2
and ϕ(A) := ˜f (A) + µ (cid:107)A(cid:107)2
2,∞ .
Using the squash algorithm, we can solve
F + µ (cid:107)A(cid:107)2
k (cid:107)A − Ak (cid:107)2
minimize(cid:104)∇ ˜f (Ak ), A(cid:105) + τ −1
2,∞
(cid:17)
(cid:16)
in closed form. To see this, complete the square and multiply by τk . Then (9) is equivalent to (7)
with the identiﬁcations W = A, V = Ak − τk∇ ˜f (Ak ), β = τk µ. That is, the optimal solution
Ak − τk∇ ˜f (Ak ), τk µ
of (9) is squash
.
We can now directly apply the proximal-point algorithm of Fukushima and Mine, detailed in Algo-
rithm 2. Step 2 is the standard linearized proximal-point method that is prevalent in convex algo-
rithms like Mirror Descent and Nesterov’s optimal method. The cost function ˜f is replaced with a
quadratic approximation localized at the previous iterate Ak , and the resulting approximation (9)
can be solved in closed form. Step 3 is a backtracking line search that looks for a step that obeys
an Armijo step rule. This linesearch guarantees that the algorithm produces a sufﬁciently large de-
crease of the cost function at each iteration, but it may require several function evaluations to ﬁnd l.
This algorithm is guaranteed to converge to a critical point of (8) as long as the step sizes are chosen
commensurate with the norm of the Hessian [8]. In particular, Nesterov has recently shown that if ˜f
has a Lipschitz-continuous gradient with Lipschitz constant L, then the algorithm will converge at a
rate of 1/k where k is the iteration counter [15].

(9)

4

Algorithm 2 A proximal-point method for max-norm regularization
Require: Algorithm parameters α > 0, 1 > γ > 0, tol > 0. A sequence of positive numbers {τk }.
An initial point A0 = (L0 , R0 ) and a counter k set to 0.
(cid:16)
(cid:17)
Ensure: A critical point of (8).
1: repeat
Solve (9) to ﬁnd ˆAk . That is, ˆAk ← squash
Ak − τk∇ ˜f (Ak ), τk µ
2:
Compute the smallest nonnegative integer l such that
3:
ϕ(Ak + γ l ( ˆAk − Ak )) ≤ ϕ(Ak ) − αγ l (cid:107)Ak − ˆAk (cid:107)2
F .

.

set Ak+1 ← (1 − γ l )Ak + γ l ˆAk , k ← k + 1.
4:
5: until (cid:107)Ak− ˆAk (cid:107)2
< tol
F
(cid:107)Ak (cid:107)2
F

5 Stochastic Gradient

(10)

(cid:96)(Yij , L(cid:48)
iRj )

For many problems, including matrix completion and max-cut problems, the cost function decom-
poses over the individual entries in the matrix, so the function f (LR(cid:48) ) takes the particularly simple
f (L, R) = (cid:88)
form:
i,j∈S
where (cid:96) is some ﬁxed loss function, S is a set of row-column indices, Yij are some real numbers,
and Li and Rj denote the ith row of L and j th row of R respectively. When dealing with very
large datasets, S may consist of hundreds of millions of pairs, and there are algorithmic advantages
to utilizing stochastic gradient methods that only query a very small subset of S at each iteration.
Indeed, the above decomposition for f immediately suggests a stochastic gradient method: pick one
training pair (i, j ) at random at each iteration, take a step in the direction opposite the gradient of
iRj ) and then either apply the projection PB described in Section 3 or the squash function
(cid:96)(Yi,j , L(cid:48)
described in 4.
The projection PB is particularly easy to compute in the stochastic setting. Namely, if (cid:107)Li (cid:107)2 > B ,
√
we project it back so that (cid:107)Li (cid:107) =
B , otherwise we do not do anything (and similarly for Rj ). We
need not look at any other rows of L and R. As we demonstrate in experimental results section, this
simple algorithm is computationally as efﬁcient as optimization with the trace-norm.
We can also implement an efﬁcient algorithm for stochastic gradient descent for problem (2). If we
wanted to apply the squash algorithm to such a stochastic gradient step, only the norms correspond-
ing to Li and Rj would be modiﬁed. Hence, in Algorithm 1, if the set of row norms of L and R
is sorted from the previous iteration, we can implement a balanced-tree data structure that allows us
to perform individual updates in amortized logarithmic time. We leave such an implementation to
future work. In the experiments, however, we demonstrate that the proximal point method is still
quite efﬁcient and fast when dealing with stochastic gradient updates corresponding to medium-size
batches {(i, j )} selected from S , even if a full sort is performed at each squash operation.

6 Numerical Experiments

Matrix Completion. We tested our proximal point and projected gradient methods on the Net-
ﬂix dataset, which is the largest publicly available collaborative ﬁltering dataset. The training set
contains 100,480,507 ratings from 480,189 anonymous users on 17,770 movie titles. Netﬂix also
provides a qualiﬁcation set, containing 1,408,395 ratings. The “qualiﬁcation set” pairs were selected
by Netﬂix from the most recent ratings for a subset of the users. As a baseline, Netﬂix provided the
test score of its own system trained on the same data, which is 0.9514. This dataset is interesting for
several reasons. First, it is very large, and very sparse (98.8% sparse). Second, the dataset is very
imbalanced, with highly nonuniform samples. It includes users with over 10,000 ratings as well as
users who rated fewer than 5 movies.

5

Algorithm

Proximal Point
Projected Gradient
Trace-norm
Weighted Trace-norm

f (X )

0.7676
0.7728
-
-

Training RMSE
(cid:107)X (cid:107)max
f (X ) +
+ µ (cid:107)X (cid:107)max
0.7689
0.7739
-
-

2.5549
2.2500
-
-

Qual
f (X )

0.9150
0.9138
0.9235
0.9105

Figure 1: Performance of regularization methods on the Netﬂix dataset.

minimizeL,R

For the netﬂix dataset, we will evaluate our algorithms based on the root mean squared error (RMSE)
(cid:88)
of their predictions. To this end, the objective we seek to minimize takes the following form:
1
(Yij − L(cid:48)
iRj )2 + µ max{(cid:107)L(cid:107)2
2,∞ , (cid:107)R(cid:107)2
2,∞}
|S |
(i,j )∈S
where S here represents the set of observed user-movie pairs and Yij denote the provided ratings.
For all of our experiments, we learned a factorization L(cid:48)R with k = 30 dimensions (factors).
In our experiments, all ratings were normalized to be zero-mean by subtracting 3.6.
To
speed up learning, we subdivided the Netﬂix dataset into minibatches, each containing 100,000
user/movie/rating triplets. Both proximal-point and projected gradient methods performed 40
epochs (or passes through the training set), with parameters {L, R} updated after each minibatch.
For both algorithms we used momentum of 0.9, and a step size of 0.005, which was decreased by
a factor of 0.8 after each epoch. For the proximal-point method, µ was set to 5×10−4 , and for
the projected gradient algorithm, B was set to 2.25. The running times of both algorithms on this
large-scale Netﬂix dataset is comparable. On a 2.5 GHz Intel Xeon, our implementation of projected
gradient takes 20.1 minutes per epoch, whereas the proximal-point method takes about 19.6 minutes.
Figure 1 shows predictive performance of both the proximal-point and projected gradient algorithms
on the training and qualiﬁcation set. Observe that the proximal-point algorithm converges consider-
ably faster than projected gradient, but both algorithms achieve a similar RMSE of 0.9150 (proximal
point) and 0.9138 (projected gradient) on the qualiﬁcation set. Figure 1, left panel, further shows that
the max-norm based regularization signiﬁcantly outperforms the corresponding trace-norm based
regularization, which is widely used in many large-scale collaborative ﬁltering applications. We
also note that the differences between the max-norm and the weighted trace-norm [7] are rather
small, with the weighted trace-norm slightly outperforming max-norm.
Gset Max-Cut Experiments.
minimize (cid:88)
In the MAX -CUT problem, we are given a graph G = (V , E ), and
we aim to solve the problem
(i,j )∈E
minimize (cid:88)
The heralded Goemans-Williamson relaxation [16] converts this problem into a constrained, sym-
metric max-norm problem:
(1 − Xij ) subject to (cid:107)X (cid:107)max ≤ 1, X (cid:23) 0 .
(i,j )∈E
minimize (cid:88)
In our nonconvex formulation, this optimization becomes
iAj ) subject to (cid:107)A(cid:107)2
(1 − A(cid:48)
2,∞ ≤ 1 .
(i,j )∈E
Since the decision variable is symmetric and positive deﬁnite, we only need one factor A of size
|V | × r . In all of our experiments with MAX -CUT type problems, we ﬁxed r = 20. We used a
diminishing step size rule of τk = τ0√
where k is the iteration counter.
k

(1 − xixj ) subject to x2
i = 1 ∀i ∈ V

6

05101520253035400.750.80.850.90.9511.051.11.15Number of epochs RMSE  TrainingQualificationProximal PointProjected GradientPrimal
Obj.
14128.5
8007.4
7998.3
20116.6
15207.0
7736.4
9851.51
7800.4
11034.1
15639.6

Time
(.1%)
0.6
0.5
0.5
2
2.1
21.4
8.7
13.8
18.6
28.4

Iterations
(.1%)
150
200
200
300
400
2050
1700
2250
2150
2200

Time
(1%)
0.4
0.3
0.3
.7
0.29
1.3
.5
.6
.9
1.35

Iterations
(1%)
100
100
100
100
50
100
100
100
100
100

SDPLR
Obj.
14135.7
8014.6
8005.9
20135.90
15221.9
7744.1
9861.2
7808.2
11045.1
15655.2

SDPLR
Time
3
4
7
29
6
15
21
15
20
33

G22
G35
G36
G58
G60
G67
G70
G72
G77
G81

|V |
2000
2000
2000
5000
7000
10000
10000
10000
14000
20000

|E |
19990
11778
11766
29570
17148
20000
9999
20000
28000
40000

Table 1: Performance of projected gradient on Gset graphs. Columns show primal objective within .1% of
optimal, running time for .1% of optimal, number of iterations to reach .1% of optimal, running time for 1% of
optimal, number of iterations to reach 1% of optimal, primal objective using SDPLR, running time of SDPLR,
number of vertices, and number of edges. In our experiments, we set τ0 = 1.

(a) Spectral Clustering

(b) Max-cut clustering

Figure 2: Comparison of spectral clustering (left) with MAX -CUT clustering (right).

We tested our projected gradient algorithm on graphs drawn from the Gset, a collection of graphs
designed for testing the efﬁcacy of max-cut algorithms [17]. The results for a subset of these appears
in Table 1 along with a comparison against a C implementation of Burer’s SDPLR code which has
been optimized for the particular structure of the MAX -CU T problem [18]. On the same modern
hardware, a Matlab implementation of our projected gradient method can reach .1% of the optimal
value faster than the optimized and compiled SDPLR code.
(cid:16)− ||xi−xj ||2
(cid:17)
2-class Clustering Experiments. For the 2-class clustering problem, we ﬁrst build a K -nearest
neighbor graph with K = 10 and weights wij deﬁned as wij = max(si (j ), sj (i)), with si (j ) =
exp
and σi equal to the distance from xi to its K th closest neighbor. We then choose
2σ2
a scalar δ > 0 and deﬁne an inverse similarity adjacency matrix Q by Qij = δ −Wij . The parameter
i
δ controls the balancing of the clusters, a large value of δ forces the clusters to be of equal size. We
solve the MAX -CU T problem on the graph Q to ﬁnd our cluster assignments.
As a synthetic example, we generated a “two moons” dataset consisting of two half-circles in R2
with the bottom half circle shifted to the right by 1/2 and shifted up by 1/2. The data is then
embedded into RD and each embedded component is corrupted with Gaussian noise with variance
√
.02 as done in [19]. The
σ2 . For the two moons experiments, we ﬁx D = 100, n = 2000 and σ =
parameters are set to δ = .01 and τ0 = 3/2; the algorithm was executed for 1500 iterations. For
the clustering experiments, we repeat the randomized rounding technique [16] for 100 trials, and we
choose the rounding with highest primal objective.
We compare our MAX -CUT clusterings with the spectral clustering method [20] and the Total Vari-
ation Graph Cut algorithm [19]. Figure 2 shows the clustering results for spectral clustering and
maxcut clustering. In all the trials, spectral clustering incorrectly clustered the two ends of both
deﬁned as (cid:80)
half-circles. For the clustering problems, the two measures of performance we consider are mis-
classiﬁcation error rate (number of misclassiﬁed points divided by n) and cut cost. The cut cost is
i∈V1 ,j∈V2 Wij . The MAX -CU T clustering obtained smaller misclassiﬁcation error in 98
of the 100 trials we performed and smaller cut cost in every trial.
On the MNIST database, we build the 10-NN graph described above on the digits 4 and 9, where
we set δ = .001 and r = 8. The NN-graph is of size 14, 000 and the MAX -CUT algorithm takes

7

Two Moons
MNIST 4 and 9
MNIST 3 and 5

Error Rate
0.053
0.021
0.016

max-cut
Time
13
90
53

Cost
311.9
1025.5
830.9

min(|V1 |,|V2 |)
|V1 |+|V2 |
.495
.493
.476

spectral
Error Rate
0.171
0.458
0.092

Cost
387.8
1486.5
2555.1

TV
Error Rate
0.082
N/A
N/A

Table 2: Clustering results. Error rate, cut cost, and running time comparison for MAX -CUT, spectral, and
total variation (TV) algorithms. The balance of the cut is computed as min(|V1 |,|V2 |)
. The two moons results
|V1 |+|V2 |
are averaged over 100 trials.

approximately 1 minute to run 1,000 iterations. The same procedure is repeated for the digits 3 and
5. The results are shown in Table 2. Our MAX -CU T clustering algorithm again performs substantially
better than the spectral method.
7 Summary
In this paper we presented practical methods for solving very large scale optimization problems
involving a max-norm constraint or regularizer. Using this approaches, we showed evidence that
the max-norm can often be superior to established techniques such as trace-norm regularization and
spectral clustering, supplementing previous evidence on small-scale problems. We hope that the
increasing evidence of the utility of max-norm regularization, combined with the practical optimiza-
tion techniques we present here, will reignite interest in using the max-norm for various machine
learning applications.

Acknowledgements
RS supported by NSERC, Shell, and NTT Communication Sciences Laboratory. JAT supported by
ONR award N00014-08-1-0883, DARPA award N66001-08-1-2065, and AFOSR award FA9550-
09-1-0643. JL thanks TTI Chicago for hosting him while this work was completed.

A Proof of the correctness of squash
Pd
Rewrite (7) as the constrained optimization
i=1 (cid:107)wi − vi (cid:107)2 + β t
minimizeW ,t
(cid:107)wi (cid:107)2 ≤ t
for 1 ≤ i ≤ d
subject to
Forming a Lagrangian with a vector of Lagrange multipliers p ≥ 0
dX
dX
pi ((cid:107)wi (cid:107)2 − t) ,
(cid:107)wi − vi (cid:107)2 + β t +
L(W , t, p) =
vi , (b) p ≥ 0, (c) Pd
i=1
i=1
i=1 pi = β , (d) (cid:107)wi (cid:107)2 ≤ t
the KKT conditions for this problem thus read (a) wi = 1
1+pi
for 1 ≤ i ≤ d, (e) pi > 0 =⇒ (cid:107)wi (cid:107)2 = t, and (f) (cid:107)wi (cid:107)2 < t =⇒ pi = 0.
( (cid:107)vk (cid:107)
With our candidate W = squash(V , β ), we need only ﬁnd t and p to verify the optimality conditions. Let π
be as in Algorithm 1 and set t = η2 and
η − 1 1 ≤ π(k) ≤ q
pk =
otherwise
0
This deﬁnition of p immediately gives (a). For (b), note that by the deﬁnition of q , (cid:107)vk (cid:107) ≥ η for 1 ≤ π(k) ≤ q .
P
dX
Thus, p ≥ 0. Moreover,
1≤π(k)≤q (cid:107)vk (cid:107)
− q = q + β − q = β ,
pk =
η
k=1
yielding (c). Also, by construction, (cid:107)wk (cid:107) = η if π(k) ≤ q verifying (e). Finally, again by the deﬁnition of q ,
q+1X
we have
(cid:107)vπ(q+1) (cid:107) +
(cid:107)vπ(k) (cid:107) =
(cid:107)vπ(q+1) (cid:107) <
β + q
1
1
η
β + q + 1
β + q + 1
β + q + 1
k=1
which implies (cid:107)vπ(q+1) (cid:107) < η . Since (cid:107)vk (cid:107) ≤ (cid:107)vπ(q+1) (cid:107) for π(k) > q , this gives (d) and the slackness
condition (f).

8

In 18th Annual Conference on

References
[1] Nathan Srebro, Jason Rennie, and Tommi Jaakkola. Maximum margin matrix factorization. In Advances
in Neural Information Processing Systems, 2004.
[2] Samuel Burer and R. D. C. Monteiro. A nonlinear programming algorithm for solving semideﬁnite
programs via low-rank factorization. Mathematical Programming (Series B), 95:329–357, 2003.
[3] Benjamin Recht, Maryam Fazel, and Pablo Parrilo. Guaranteed minimum rank solutions of matrix
SIAM Review, 2007. To appear. Preprint Available at
equations via nuclear norm minimization.
http://pages.cs.wisc.edu/˜brecht/publications.html.
[4] Francis R. Bach, Julien Marial, and Jean Ponce. Convex sparse matrix factorizations. Preprint available
at arxiv.org/abs/0812.1869, 2008.
[5] Nathan Srebro and Adi Shraibman. Rank, trace-norm and max-norm.
Learning Theory (COLT), 2005.
[6] G. J. O. Jameson. Summing and Nuclear Norms in Banach Space Theory. Number 8 in London Mathe-
matical Society Student Texts. Cambridge University Press, Cambridge, UK, 1987.
[7] Ruslan Salakhutdinov and Nathan Srebro. Collaborative ﬁltering in a non-uniform world: Learning with
the weighted trace norm. Preprint available at arxiv.org/abs/1002.2780, 2010.
[8] Masao Fukushima and Hisashi Mine. A generalized proximal point algorithm for certain non-convex
minimization problems. International Journal of Systems Science, 12(8):989–1000, 1981.
[9] Samuel Burer and Changhui Choi. Computational enhancements in low-rank semideﬁnite programming.
Optimization Methods and Software, 21(3):493–512, 2006.
[10] Dimitri P. Bertsekas. Nonlinear Programming. Athena Scientiﬁc, Belmont, MA, 2nd edition, 1999.
[11] T Hale, W Yin, and Y Zhang. A ﬁxed-point continuation method for l 1-regularized minimization with
applications to compressed sensing. Dept. Computat. Appl. Math., Rice Univ., Houston, TX, Tech. Rep.
TR07-07, 2007.
[12] Stephen J. Wright, Robert Nowak, and M ´ario A. T. Figueiredo. Sparse reconstruction by separable ap-
proximation. Journal version, to appear in IEEE Transactions on Signal Processing. Preprint available at
http:http://www.optimization-online.org/DB_HTML/2007/10/1813.html, 2007.
[13] Jian-Feng Cai, Emmanuel J. Cand `es, and Zuowei Shen. A singular value thresholding algorithm for
matrix completion. To appear in SIAM J. on Optimization. Preprint available at http://arxiv.org/
abs/0810.3286, 2008.
[14] Shiqian Ma, Donald Goldfarb, and Lifeng Chen. Fixed point and Bregman iterative methods for matrix
rank minimization. Preprint available at http://www.optimization-online.org/DB_HTML/
2008/11/2151.html, 2008.
[15] Yurii Nesterov. Gradient methods for minimizing composite objective function. To appear. Preprint
Available at http://www.optimization-online.org/DB_HTML/2007/09/1784.html,
September 2007.
[16] M. X. Goemans and D. P. Williamson. Improved approximation algorithms for maximum cut and satisﬁ-
ability problems using semideﬁnite programming. Journal of the ACM, 42:1115–1145, 1995.
[17] The Gset is available for download at http://www.stanford.edu/˜yyye/yyye/Gset/.
[18] Samuel Burer. Sdplr. Software available at http://dollar.biz.uiowa.edu/˜sburer/www/
doku.php?id=software#sdplr.
[19] Arthur Szlam and Xavier Bresson. A total variation-based graph clustering algorithm for cheeger
ratio cuts. To appear in ICML 2010. Preprint available at ftp://ftp.math.ucla.edu/pub/
camreport/cam09-68.pdf, 2010.
[20] Jianbo Shi and Jitendra Malik. Normalized cuts and image segmentation. IEEE Transactions on Pattern
Analysis and Machine Intelligence, 22(8):888–905, 2000.

9

