Probabilistic Multi-Task Feature Selection

Yu Zhang , Dit-Yan Yeung , Qian Xu 
Department of Computer Science and Engineering,  Bioengineering Program
Hong Kong University of Science and Technology
zhangyu,dyyeung@cse.ust.hk, fleurxq@ust.hk

Abstract

Recently, some variants of the  norm, particularly matrix norms such as the  
and Ý norms, have been widely used in multi-task learning, compressed sens-
ing and other related areas to enforce sparsity via joint regularization.
In this
paper, we unify the   and Ý norms by considering a family of  norms for
   ࣘ Ý and study the problem of determining the most appropriate sparsity
enforcing norm to use in the context of multi-task feature selection. Using the
generalized normal distribution, we provide a probabilistic interpretation of the
general multi-task feature selection problem using the  norm. Based on this
probabilistic interpretation, we develop a probabilistic model using the noninfor-
mative Jeffreys prior. We also extend the model to learn and exploit more general
types of pairwise relationships between tasks. For both versions of the model,
we devise expectation-maximization (EM) algorithms to learn all model parame-
ters, including  , automatically. Experiments have been conducted on two cancer
classiﬁcation applications using microarray gene expression data.

1

Introduction

Learning algorithms based on  regularization have a long history in machine learning and statistics.
A well-known property of  regularization is its ability to enforce sparsity in the solutions. Recently,
some variants of the  norm, particularly matrix norms such as the   and Ý norms, were
proposed to enforce sparsity via joint regularization [24, 17, 28, 1, 2, 15, 20, 16, 18]. The   norm
is the sum of the   norms of the rows and the Ý norm is the sum of the Ý norms of the rows.
Regularizers based on these two matrix norms encourage row sparsity, i.e., they encourage entire
rows of the matrix to have zero elements. Moreover, these norms have also been used for enforcing
group sparsity among features in conventional classiﬁcation and regression problems, e.g., group
LASSO [29]. Recently, they have been widely used in multi-task learning, compressed sensing and
other related areas. However, when given a speciﬁc application, we often have no idea which norm
is the most appropriate choice to use.
In this paper, we study the problem of determining the most appropriate sparsity enforcing norm
to use in the context of multi-task feature selection [17, 15].
Instead of choosing between spe-
ciﬁc choices such as the   and Ý norms, we consider a family of  norms. We restrict 
to the range    ࣘ Ý to ensure that all norms in this family are convex, making it easier to
solve the optimization problem formulated based on it. Within this family, the   and Ý norms
are just two special cases. Using the  norm, we formulate the general multi-task feature se-
lection problem and give it a probabilistic interpretation. It is noted that the automatic relevance
determination (ARD) prior [9, 3, 26] comes as a special case under this interpretation. Based on
this probabilistic interpretation, we develop a probabilistic formulation using a noninformative prior
called the Jeffreys prior [10]. We devise an expectation-maximization (EM) algorithm [8] to learn
all model parameters, including  , automatically. Moreover, an underlying assumption of existing
multi-task feature selection methods is that all tasks are similar to each other and they share the
same features. This assumption may not be correct in practice because there may exist outlier tasks

1

or tasks with negative correlation. As another contribution of this paper, we propose to use a matrix
variate generalized normal prior [13] for the model parameters to learn the relationships between
tasks. The task relationships learned here can be seen as an extension of the task covariance used
in [4, 32, 31]. Experiments will be reported on two cancer classiﬁcation applications using microar-
ray gene expression data.

 N
  M
 
     9

2 Multi-Task Feature Selection
 . For the th task  , the training set  consists
Suppose we are given  learning tasks  
 ࢠ Ó and
of  labeled data points in the form of ordered pairs N
 ,         , with N
   
 ࢠ ࢤ  if it is a binary
 ࢠ Ó if it is a regression problem and  
its corresponding output  
classiﬁcation problem. The linear function for  is deﬁned as  N  M
 N   . For applications
that need feature selection, e.g., document classiﬁcation, the feature dimensionality is usually very
high and it has been found that linear methods usually perform better.
The objective functions of most existing multi-task feature selection methods [24, 17, 28, 1, 2, 15,
20, 16, 18] can be expressed in the following form:
ࢣ
ࢣ


where 9  M      M ,   denotes the loss function (e.g., squared loss for regression and
hinge loss for classiﬁcation),  is the regularization function that enforces feature sparsity un-
der the multi-task setting, and  is the regularization parameter controlling the relative contribution
of the empirical loss and the regularizer. Multi-task feature selection seeks to minimize the ob-
jective function above to obtain the optimal parameters M   . Two regularization functions are
of 9 [17, 28, 1, 2, 16, 18]: 9  ࢣ
widely used in existing multi-task feature selection methods. One of them is based on the   norm
 ࢱM ࢱ  where ࢱ  ࢱ denotes the  -norm (or  norm) of a
9  ࢣ
vector and M denotes the  th row of 9. Another one is based on the Ý norm of 9 [24, 15, 20]:
 ࢱM ࢱÝ .
In this paper, we unify these two cases by using the  norm of 9 to deﬁne a more general
ࢣ
regularization function:

Note that when   , 9 is non-convex with respect to 9. Although 9 is convex when
  , each element of 9 is independent of each other and so the regularization function cannot
enforce feature sparsity. Thus we restrict the range to    ࣘ Ý.
Even though restricting the range to    ࣘ Ý can enforce feature sparsity between different tasks,
different values of  imply different ‘group discounts’ for sharing the same feature. Speciﬁcally,
when  approaches 1, the cost grows almost linearly with the number of tasks that use a feature, and
when   Ý, only the most demanding task matters. So selecting a proper  can potentially have a
signiﬁcant effect on the performance of the learning algorithms.
In the following, we ﬁrst give a probabilistic interpretation for multi-task feature selection methods.
Based on this probabilistic interpretation, we then develop a probabilistic model which, among other
things, can solve the model selection problem automatically by estimating  from data.

9 

(1)

ࢱM ࢱ 

   ࣘ Ý

3 Probabilistic Interpretation

In this section, we will show that existing multi-task feature selection methods are related to the
maximum a posteriori (MAP) solution of a probabilistic model. This probabilistic interpretation
sets the stage for introducing our probabilistic model in the next section.
We ﬁrst introduce the generalized normal distribution [11] which is useful for the model to be intro-
duced.

2

  

ANF



 

Deﬁnition 1  is a univariate generalized normal random variable iff its probability density func-
 ࢤ ࢯ ࢤ ࢯ

tion (p.d.f.) is given as follows:

 Ɖ  

 
where Ɖ denotes the Gamma function and ࢯ  ࢯ denotes the absolute value of a scalar.
For simplicity, if  is a univariate generalized normal random variable, we write  ß    .
The (ordinary) normal distribution can be viewed as a special case of the generalized normal distribu-
tion when     and the Laplace distribution is a special case when   . When  approaches Ý,
the generalized normal distribution approaches the uniform distribution in the range  ࢤ    .
The generalized normal distribution has proven useful in Bayesian analysis and robustness studies.
Deﬁnition 2 A standardized     multivariate generalized normal random variable  
        consists of  independent and identically distributed (i.i.d.) univariate generalized
normal random variables.
If  is a standardized     multivariate generalized normal random variable, we write  ß
ࢣ
ࡕ    with the following p.d.f.:

 ࢤ
 Ɖ  
  ANF
 ࢯ ࢤ ࢯ


With these deﬁnitions, we now begin to present our probabilistic interpretation for multi-task feature
selection by proposing a probabilistic model. For notational simplicity, we assume that all tasks
perform regression. Extension to include classiﬁcation tasks will go through similar derivation.
For a regression problem, we use the normal distribution to deﬁne the likelihood for N
 :
 ß  M
 N
 
      
where      denotes the (univariate) normal distribution with mean  and variance   .
We impose the generalized normal prior on each element of 9:
 ß     
(3)
where  is the   th element of 9 (or, equivalently, the th element of M or the  th element
of M ). Then we can express the prior on M as
M  ß ࡕ    
When    , this becomes the ARD prior [9, 3, 26] commonly used in Bayesian methods for
enforcing sparsity. From this view, the generalized normal prior can be viewed as a generalization
of the ARD prior.
With the above likelihood and prior, we can obtain the MAP solution of 9 by solving the following

 ࢱM ࢱ
ࢣ
ࢣ
ࢣ
problem:






where >          and           .
 ࢱM ࢱ 
 
We set the derivative of  with respect to  to zero and get
 

ࢣ
ࢣ
ࢣ
Plugging this into problem (4), the optimization problem can be reformulated as



Note that problem (5) is non-convex since the second term is non-convex with respect to 9. Be-
cause   ࣘ  ࢤ  for any   , problem (5) can be relaxed to problem (1) by setting     .

 N
  M
 
     

 
 N
  M
    

 ࢱM ࢱ 

E
9>

 

   



E
9>

 


 


 



(2)

(4)

(5)

3

So the solutions of multi-task feature selection methods can be viewed as the solution of the relaxed
optimization problem above. In many previous works such as [5, 27],  can be used as an ap-
proximation of   ࢧ  where   is an indicator function. Using this view, we can regard the
second term in problem (5) as an approximation of the number of rows with nonzero  -norms.
the second term with  ࢣ
Note that we can directly solve problem (5) using a majorization-minimization (MM) algorithm [14].
For numerical stability, we can slightly modify the objective function in problem (5) by replacing
 ࢱM ࢱ   where  can be regarded as a regularization parameter.
We denote the solution obtained in the  th iteration as M
 . In the   th iteration, due to the


concavity property of , we can bound the second term in problem (5) as follows
ࢱM ࢱ   ࣘ ࢣ
ࢣ
ࢱM ࢱ ࢤ ࢱM
 ࢱ
ࢱM
 ࢱ   
ࢱM
 ࢱ  


ࢣ
ࢣ
ࢣ
Thus, in the   th iteration, we need to solve a weighted version of problem (1):
ࢱM ࢱ

ࢱM
 ࢱ  
 



According to [14], the MM algorithm is guaranteed to converge to a local optimum.

 N
  M
 
     

E
9>





4 A Probabilistic Framework for Multi-Task Feature Selection
In the probabilistic interpretation above, we use a type II method to estimate  in the generalized
normal prior which can be viewed as a generalization of the ARD prior. In the ARD prior, according
to [19], this approach is likely to lead to overﬁtting because the hyperparameters in the ARD prior
are treated as points. Similar to the ARD prior, the model in the above section may overﬁt since  
are estimated via point estimation. In the following, we will present our probabilistic framework for
multi-task feature selection by imposing priors on the hyperparameters.

4.1 The Model

As in the above section, the likelihood for N
 is also deﬁned based on the normal distribution:
 ß  M
     
 N
 
(6)
 
Here we use different noise variances  for different tasks to make our model more ﬂexible. The
prior on 9 is also deﬁned similarly:
 ß     
(7)
Ý
The main difference here is that we treat  as a random variable with the noninformative Jeffreys
   Ý 
 ࢚  M ࢯ 
  Ý Ý   
prior:

(8)
M ࢯ

࢚ 

where    denotes the Fisher information for  and   denotes the expectation with respect
to  . One advantage of using the Jeffreys prior is that the distribution has no hyperparameters.

4.2 Parameter Learning and Inference

Here we use the EM algorithm [8] to learn the model parameters. In our model, we denote Ǝ 
9 >   as the model parameters and           as the hidden variables.
Þ
In the E-step, we construct the so-called -function as the surrogate for the log-likelihood:
 ƎࢯO ࢯO Ǝ 
ƎࢯƎ  

where Ǝ denotes the estimate of Ǝ in the  th iteration and O  
      

show that

 ࢣ
 ƎࢯO  Ý  Oࢯ9     9ࢯ
ࢣ
ࢤ ࢣ
Ý ࢤ ࢣ
 ࢤ M
 ࢤ   
 
 N
  






   

 







 . It is easy to

ࢯ ࢯ ࢤ   Ɖ 






4






(9)









   

 

ࢯO Ǝ  as

ࢯ ࢯ ࢤ   Ɖ 

 ࢤ M
 ࢤ   
 N
 
  



 ࢱ
ࢱM

ࢣ




and ࢯO Ǝ  Ý Ü
Þ Ý
 ࢯ 
. We then compute  
(cid:12)(cid:12)O Ǝ 
 
 M


Þ Ý

 ࢯ 
 M




 ࢯ 


  M

 ࢣ

ࢤ ࢣ
ƎࢯƎ   ࢤ ࢣ
So we can get



where  
.

 ࢱ
ࢱM

In the M-step, we maximize ƎࢯƎ  to update the estimates of 9, >,   and  .
ࢣ
For the estimation of 9, we need to solve  convex optimization problems
 M ࢱ 
   ࢱO ࢤ :
 ࢯ  ࢯ 
E
  
M

ࢤ 
 ࢤ 
  . When    ,
, and  
 , :  N
where O   

      N
      




 

this becomes the conventional ridge regression problem. Here  is related to the sparsity of the
 th row in 9 : the more sparse the  th row in 9 , the larger the  . When  is large,  
will be enforced to approach 0. We use a gradient method such as conjugate gradient to optimize
   
::
problem (9). The subgradient with respect to M is
 M ࢤ : O
࢚ 
  
࢚M
where    ࢯ ࢯࢤ sign       ࢯ ࢯࢤ sign  and sign denotes the sign func-
tion.


We set the derivatives of ƎࢯƎ  with respect to  and  to 0 and get
ࢣ
 ࢤ M

(cid:118)(cid:117)(cid:117) 
 
 


ࢣ


 ࢤ 
 ࢤ M
 
 N
 





 ࢤ ࢣ
ࢣ
(cid:12)(cid:12) 
(cid:12)(cid:12)  (cid:12)(cid:12)
(cid:12)(cid:12)
For the estimation of  , we also use a gradient method. The gradient can be calculated as
࢚


࢚ 




where  ࣕ ࢚  Ɖ
is the digamma function.
࢚

       







  















 N




ࢧ

4.3 Extension to Deal with Outlier Tasks and Tasks with Negative Correlation

An underlying assumption of multi-task feature selection using the  norm is that all tasks are
similar to each other and they share the same features. This assumption may not be correct in
practice because there may exist outlier tasks (i.e., tasks that are not related to all other tasks) or
tasks with negative correlation (i.e., tasks that are negatively correlated with some other tasks). In
this section, we will discuss how to extend our probabilistic model to deal with these tasks.
We ﬁrst introduce the matrix variate generalized normal distribution [13] which is a generalization
of the generalized normal distribution to random matrices.
Deﬁnition 3 A matrix  ࢠ Ó  is a matrix variate generalized normal random variable iff its p.d.f.
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) 
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ࢣ

ࢣ
ࢤ ࢣ
ࢣ
is given as follows:
 Ɖ  
  det det
ࢤ   ࢤ  
ࢯ    
ࢤ 


ANF




where  ࢠ Ó  and  ࢠ Ó  are nonsingular, det denotes the determinant of a square matrix,
 is the   th element of matrix ) and ࢤ  is the   th element of the matrix inverse )ࢤ .



5

(10)





 

ࢤ 

We write  ß ࡕ      for a matrix variate generalized normal random variable .
When    , the matrix variate generalized normal distribution becomes the (ordinary) matrix
variate normal distribution [12] with row covariance matrix  and column covariance matrix
 , which has been used before in multi-task learning [4, 32, 31]. From this view,  is used
to model the relationships between the rows of  and  is to model the relationships between the
columns.
9 ß ࡕ   diag         1  
We note that the prior on 9 in Eq. (7) can be written as
where  denotes a zero vector or matrix of proper size, 1 denotes the     identity matrix and
diag converts a vector into a diagonal matrix. In this formulation, it can be seen that the columns
9 ß ࡕ   diag          
of 9 (and hence the tasks) are independent of each other. However, the tasks are in general not
independent. So we propose to use a new prior on 9:
where  models the pairwise relationships between tasks.
The likelihood is still based on the normal distribution. Since in practice the relationships between
tasks are not known in advance, we also need to estimate  from data.
For parameter learning, we again use the EM algorithm to learn the model parameters. Here the
(cid:12)(cid:12)(cid:12) ࢣ
(cid:12)(cid:12)(cid:12)
 ࢣ
 ࢤ ࢣ
model parameters are denoted as Ǝ  9 >    . It is easy to show that
 ƎࢯO  Ý ࢤ ࢣ
ࢣ
 ࢤ M
 ࢤ   
 
 N
   



  
 







 ࢤ   det
ࢤ   Ɖ 


Þ Ý
ࢯO Ǝ  as
Then we compute  
(cid:12)(cid:12)O Ǝ 
 

Þ Ý
 ࢤ 

 ࢯ 
 M




 ࢯ 


  M


(cid:12)(cid:12)(cid:12) ࢣ
 ࢣ
ƎࢯƎ   ࢤ ࢣ
ࢣ
In the E-step, the -function can be formulated as
 ࢤ   
 ࢤ M
 N
 
  





ࢤ   Ɖ 
 ࢤ   det


(cid:12)(cid:12)(cid:12) ࢣ
(cid:12)(cid:12)(cid:12)
ࢣ
ࢣ
ࢣ
ࢣ
In the M-step, for 9 and , the optimization problem becomes
 ࢤ M
ࢤ 

 
 N
  
   
   det
 







  . We deﬁne a new variable 9  9ࢤ to rewrite the above problem as
ࢣ
ࢣ
ࢣ
ࢣ
 ࢤ A
ࢯ  ࢯ    det
 

  9 N
  
   
E
 


9




where A denotes the th column of the     identity matrix. We use an alternating method to
solve this problem. For a ﬁxed , the problem with respect to 9 is a convex problem and we use

  
ࢣ
ࢣ
conjugate gradient to solve it with the following subgradient
  ࢤ  
࢚
 
  9A A
 N
 N
N
 A

࢚ 9


ࢯ  ࢯࢤ sign  . For a ﬁxed 9, we
where  is a     matrix with the   th element 
 9 N

ࢣ
ࢣ

also use conjugate gradient with the following gradient
 ࢤ  
࢚
  9A A
 N

࢚


After obtaining the optimal 9ਭ and ਭ , we can compute the optimal 9ਭ as 9ਭ  9ਭਭ . The
update rules for  ,   and  are similar to those in the above section.

(cid:12)(cid:12) ࢣ

  

 ࢤ ࢣ


 ࢣ


(cid:12)(cid:12) ࣕ 


(cid:12)(cid:12)(cid:12)

ࢤ 

9 N
 A


  

where  
 



   

 




 

E
9


 


  

 

  

 


ࢤ 

6

5 Related Work

Some probabilistic multi-task feature selection methods have been proposed before [28, 2]. How-
ever, they only focus on the   norm. Moreover, they use point estimation in the ARD prior and
hence, as discussed in Section 3, are susceptible to overﬁtting [19].
Zhang et al. [30] proposed a latent variable model for multi-task learning by using the Laplace prior
to enforce sparsity. This is equivalent to using the  norm in our framework which, as discussed
above, cannot enforce group sparsity among different features over all tasks.

6 Experiments

In this section, we study our methods empirically on two cancer classiﬁcation applications using
microarray gene expression data. We compare our methods with three related methods: multi-task
feature learning (MTFL) [1]1 , multi-task feature selection using   regularization [16]2 , and multi-
task feature selection using Ý regularization [20]3 .

6.1 Breast Cancer Classiﬁcation

We ﬁrst conduct empirical study on a breast cancer classiﬁcation application. This application con-
sists of three learning tasks with data collected under different platforms [21]. The dataset for the
ﬁrst task, collected at the Koo Foundation Sun Yat-Sen Cancer Centre in Taipei, contains 89 sam-
ples with 8948 genes per sample. The dataset for the second task, obtained from the Netherlands
Cancer Institute, contains 97 samples with 16360 genes per sample. Most of the patients in this
dataset had stage I or II breast cancer. The dataset for the third task, obtained using 22K Agilent
oligonucleotide arrays, contains 114 samples with 12065 genes per sample. Even though these three
datasets were collected under different platforms, they share 6092 common genes which are used in
our experiments.
Here we abbreviate the method in Section 4.2 as PMTFS1 and that in Section 4.3 as PMTFS2. For
each task, we choose 70% of the data for training and the rest for testing. We perform 10 random
splits of the data and report the mean and standard derivation of the classiﬁcation error over the
10 trials. The results are summarized in Table 1. It is clear that PMTFS1 outperforms the three
previous methods, showing the effectiveness of our more general formulation with  determined
automatically. Moreover, we also note that PMTFS2 is better than PMTFS1. This veriﬁes the
usefulness of exploiting the relationships between tasks in multi-task feature selection. Since our
methods can estimate  automatically, we compute the mean of the estimated  values over 10 trials.
The means for PMTFS1 and PMTFS2 are 2.5003 and 2.6718, respectively, which seem to imply that
smaller values of  are preferred for this application. This probably explains why the performance
of MTFSÝ is not good when compared with other methods.
Table 1: Comparison of different methods on the breast cancer classiﬁcation application in terms of
classiﬁcation error rate (in mean std-dev). Each column in the table represents one task.
3rd Task
2nd Task
1st Task
Method
0.3478 0.1108
0.0364 0.0345
0.3091 0.0498
MTFL
0.2855 0.0337
0.0343 0.0134
0.3370 0.0228
MTFS 
0.2909 0.0761
0.1136 0.0579
MTFSÝ 0.3896 0.0583
0.3072 0.0234
0.0298 0.0121
0.1786 0.0245
PMTFS1
0.2870 0.0228
0.0273 0.0102
0.1455 0.0263
PMTFS2

6.2 Prostate Cancer Classiﬁcation

We next study a prostate cancer classiﬁcation application consisting of two tasks. The Singh
dataset [22] for the ﬁrst task is made up of laser intensity images from each microarray. The RMA
preprocessing method was used to produce gene expression values from these images. On the other
1 http://ttic.uchicago.edu/ßargyriou/code/index.html
2 http://www.public.asu.edu/ßjye02/Software/SLEP/index.htm
3 http://www.lsi.upc.edu/ßaquattoni/

7

hand, the Welsh dataset [25] for the second task is already in the form of gene expression values.
Even though the collection techniques for the two datasets are different, they have 12600 genes in
common and are used in our experiments.
The experimental setup for this application is similar to that in the previous subsection, that is, 70%
of the data of each task are used for training and the rest for testing, and 10 random splits of the data
are performed. We report the mean and standard derivation of the classiﬁcation error over the 10
trials in Table 2. As in the ﬁrst set of experiments, PMTFS1 and PMTFS2 are better than the other
three methods compared and PMTFS2 slightly outperforms PMTFS1. The means of the estimated
 values for PMTFS1 and PMTFS2 are 2.5865 and 2.6319, respectively. So it seems that smaller
values are also preferred for this application.
Table 2: Comparison of different methods on the prostate cancer classiﬁcation application in terms
of classiﬁcation error rate (in mean std-dev). Each column in the table represents one task.
1st Task
Method
2nd Task
0.3500 0.0085
0.1226 0.0620
MTFL
0.1232 0.0270
0.3420 0.0067
MTFS 
MTFSÝ 0.2216 0.1667
0.4200 0.1304
0.1123 0.0170
0.3214 0.0053
PMTFS1
0.3000 0.0059
0.1032 0.0136
PMTFS2

7 Concluding Remarks

In this paper, we have proposed a probabilistic framework for general multi-task feature selection
using the  norm (   ࣘ Ý). Our model allows the optimal value of  to be determined
from data automatically. Besides considering the case in which all tasks are similar, we have also
considered the more general and challenging case in which there also exist outlier tasks or tasks with
negative correlation.
Compressed sensing aims at recovering the sparse signal M from a measurement vector >  )M for
a given matrix ). Compressed sensing can be extended to the multiple measurement vector (MMV)
model in which the signals are represented as a set of jointly sparse vectors sharing a common set
of nonzero elements [7, 6, 23]. Speciﬁcally, joint compressed sensing considers the reconstruction
of the signal represented by a matrix 9, which is given by a dictionary (or measurement matrix) )
and multiple measurement vector * such that *  )9. Similar to multi-task feature selection,
we can use ࢱ9ࢱ to enforce the joint sparsity in 9. Since there usually exists noise in the data,
the optimization problem of MMV can be formulated as: E9 ࢱ9ࢱ  ࢱ)9 ࢤ *ࢱ 
  . This
problem is almost identical to problem (1) except that the loss deﬁnes the reconstruction error rather
than the prediction error. So we can use the probabilistic model presented in Section 4 to develop
a probabilistic model for joint compressed sensing. Besides, we are also interested in developing a
full Bayesian version of our model to further exploit the advantages of Bayesian modeling.

Acknowledgment

This research has been supported by General Research Fund 622209 from the Research Grants
Council of Hong Kong.

References
[1] A. Argyriou, T. Evgeniou, and M. Pontil. Convex multi-task feature learning. Machine Learning,
73(3):243–272, 2008.
[2] J. Bi, T. Xiong, S. Yu, M. Dundar, and R. B. Rao. An improved multi-task learning approach with
applications in medical diagnosis. In ECMLPKDD, 2008.
[3] C. M. Bishop. Pattern Recognition and Machine Learning. Springer, New York, 2006.
[4] E. Bonilla, K. M. A. Chai, and C. Williams. Multi-task Gaussian process prediction. In NIPS 20, 2008.
[5] E. J. Cand `es, M. B. Wakin, and S. P. Boyd. Enhancing sparsity by reweighted  minimization. Journal
of Fourier Analysis and Applications, 14(5):877–905, 2008.

8

[6] J. Chen and X. Huo. Theoretical results on sparse representations of multiple-measurement vectors. IEEE
Transactions on Signal Processing, 54(12):4634–4643, 2006.
[7] S. F. Cotter, B. D. Rao, K. Engan, and K. Kreutz-Delgado. Sparse solutions to linear inverse problems
with multiple measurement vectors. IEEE Transactions on Signal Processing, 53(7):2477–2488, 2005.
[8] A. P. Dempster, N. M. Laird, and D. B. Rubin. Maximum likelihood from incomplete data via the EM
algorithm. Journal of the Royal Statistic Society, B, 39(1):1–38, 1977.
[9] M. A. T. Figueiredo. Adaptive sparseness for supervised learning. IEEE Transactions on Pattern Analysis
and Machine Intelligence, 25(9):1150–1159, 2003.
[10] A. Gelman, J. B. Carlin, H. S. Stern, and D. B. Rubin. Bayesian Data Analysis. Chapman & Hall, 2nd
edition, 2003.
[11] I. R. Goodman and S. Kotz. Multivariate -generalized normal distributions. Journal of Multivariate
Analysis, 3(2):204–219, 1973.
[12] A. K. Gupta and D. K. Nagar. Matrix Variate Distributions. Chapman & Hall, 2000.
[13] A. K. Gupta and T. Varga. Matrix variate -generalized normal distribution. Transactions of The American
Mathematical Society, 347(4):1429–1437, 1995.
[14] K. Lange, D. R. Hunter, and I. Yang. Optimization transfer using surrogate objective functions. Journal
of Computational and Graphical Statistics, 9(1):1–59, 2000.
[15] H. Liu, M. Palatucci, and J. Zhang. Blockwise coordinate descent procedures for the multi-task lasso,
with applications to neural semantic basis discovery. In ICML, 2009.
[16] J. Liu, S. Ji, and J. Ye. Multi-task feature learning via efﬁcient   -norm minimization. In UAI, 2009.
[17] G. Obozinski, B. Taskar, and M. Jordan. Multi-task feature selection. Technical report, Department of
Statistics, University of California, Berkeley, June 2006.
[18] G. Obozinski1, B. Taskar, and M. I. Jordan. Joint covariate selection and joint subspace selection for
multiple classiﬁcation problems. Statistics and Computing, 20(2):231–252, 2010.
[19] Y. Qi, T. P. Minka, R. W. Picard, and Z. Ghahramani. Predictive automatic relevance determination by
expectation propagation. In ICML, 2004.
[20] A. Quattoni, X. Carreras, M. Collins, and T. Darrell. An efﬁcient projection for Ý regularization. In
ICML, 2009.
[21] A. A. Shabalin, H. Tjelmeland, C. Fan, C. M. Perou, and A. B. Nobel. Merging two gene-expression
studies via cross-platform normalization. Bioinformatics, 24(9):1154–1160, 2008.
[22] D. Singh, P. G. Febbo, K. Ross, D. G. Jackson, J. Manola, C. Ladd, P. Tamayo, A. A. Renshaw, A. V.
DAmico, J. P. Richie, E. S. Lander, M. Loda, P. W. Kantoff, T. R. Golub, and W. R.Sellers. Gene
expression correlates of clinical prostate cancer behavior. Cancer Cell, 1(2):203–209, 2002.
[23] L. Sun, J. Liu, J. Chen, and J. Ye. Efﬁcient recovery of jointly sparse vectors. In NIPS 22. 2009.
[24] B. A. Turlach, W. N. Wenables, and S. J. Wright. Simultaneous variable selection. Technometrics,
47(3):349–363, 2005.
[25] J. B. Welsh, L. M. Sapinoso, A. I. Su, S. G. Kern, J. Wang-Rodriguez, C. A. Moskaluk, F. H. Frierson,
Jr., and G. M. Hampton. Analysis of gene expression identiﬁes candidate markers and pharmacological
targets in prostate cancer. Cancer Research, 61(16):5974–5978, 2001.
[26] D. Wipf and S. Nagarajan. A new view of automatic relevance determination. In NIPS 20, 2007.
[27] D.P. Wipf and S. Nagarajan. Iterative reweighted  and   methods for ﬁnding sparse solutions. Journal
of Selected Topics in Signal Processing, 2010.
[28] T. Xiong, J. Bi, B. Rao, and V. Cherkassky. Probabilistic joint feature selection for multi-task learning.
In SDM, 2007.
[29] M. Yuan and Y. Lin. Model selection and estimation in regression with grouped variables. Journal of the
Royal Statistical Society, Series B, 2006.
[30] J. Zhang, Z. Ghahramani, and Y. Yang. Flexible latent variable models for multi-task learning. Machine
Learning, 73(3):221–242, 2008.
[31] Y. Zhang and D.-Y. Yeung. A convex formulation for learning task relationships in multi-task learning.
In UAI, 2010.
[32] Y. Zhang and D.-Y. Yeung. Multi-task learning using generalized  process. In AISTATS, 2010.

9

