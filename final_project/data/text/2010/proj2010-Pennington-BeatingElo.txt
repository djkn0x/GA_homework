Beating Elo

Jeﬀrey S. Pennington

December 10, 2010

1

Introduction

The Elo system is a rating system of competitive head-to-head games. It or small modiﬁcations of it are
used by the United States Chess Federation (USCF), the World Chess Federation (FIDE), American college
football and basketball and Ma jor League Baseball.
The Elo system assigns a single rating to each player and calculates expected outcomes based on the
rating diﬀerences:

EA =

1
1 + e(RA−RB )/Λ

, EB =

1
1 + e(RB −RA )/Λ

(1)

where EA and EB are the expected outcomes for players A and B , and RA and RB are their ratings. Here
we designate a win by 1, a loss by 0, and a draw by 0.5. The spread of the ratings is set by Λ, which for
chess ratings is usually taken to be Λ = 400/ log(10) = 173.72.
The result of each game updates each player’s rating according to an update rule. The update rule is
usually based on the diﬀerence between the actual outcome and the expected outcome,
RA ← RA + K (IA − EA ),

(2)

where IA is the actual outcome of the game. The factor K is a constant which, given Λ, determines the
volatility of each player’s rating. The diﬀerent Elo chess rating systems use diﬀerent values of K , usually
between 16 and 32. Most systems take K = K (RA ) to be a decreasing function of the rating, so that higher
rated player’s ratings are less volatile.

2 Elo versus the Rest of the World

The website kaggle.com hosted a competition to ﬁnd an approach that predicts the outcomes of chess games
more accurately than the Elo rating system. The contest provides a dataset of 65,053 games from 100
consecutive months between 8,631 of the top chess players. Each element of the dataset contains four pieces
of information: the month, a number identifying the white player, a number identifying the black player,
and the score. The score is 0 for a white loss, 0.5 for a draw, and 1 for a white win. The test data contains
5 additional months of data for the same players. The submissions are evaluated based on the RMSE of the
players’ predicted total scores per month and their actual total scores per month during those 5 months.

3 Feature Selection

We illustrate the diﬃculty of selecting good features with a simple linear regression model. A little thought
(cid:26) percent of games won/lost/drawn
suggests that perhaps some good features to include for each player are:
total number of games played

F1 =

1

Or, better, yet,

This gives very high training error, and indeed F1 does not really capture the information very well. One
(cid:26) F1 as white
might consider,
F1 as black

the mean of F2 of all opponents defeated as white,
the mean of F2 of all opponents drawn as white,
the mean of F2 of all opponents lost to as white,
the mean of F2 of all opponents defeated as black,
the mean of F2 of all opponents drawn as black,
the mean of F2 of all opponents lost to as black
We select the n = {1, . . . , 19} most relevant features from set F3 using stepwise regression and plot the
learning curve in ﬁgure1.

F2 =

F3 =

Figure 1: Learning curve for linear regression. The dotted line shows the competition’s best submission. The test error was
calculated after the full data set became public.

The learning curve shows that the test error is high even though the training error is relatively low, an
indication that our feature set is suboptimal. F3 has 36 elements and it has only included the relevant data
of each players’ opponents. To add more features, we would need to include some information about the
opponents of each player’s opponents. Actually, the number of features is exponential in the recursion depth,
d:

|F | = 2 × 6d

(3)

It is impractical to include features for a recursion depth larger than about 5, but, in principle, d should be
as large as the total number of games played by the player with the most games, which in this data set is
over 100. This obstacle is not limited to linear regression and will be present with any model. It is therefore
necessary to consider an entirely diﬀerent approach.

2

024681012141618200.50.60.70.80.91Number of FeaturesRMSE (per player per month)Learning Curve  Training ErrorTest ErrorBest Score3.1 Optimal Ratings

One observation about the ﬁtted linear regression model is that the coeﬃcients of the features associated
with the white player are roughly equal and opposite in sign to the coeﬃcients of the features associated
with the black player. This indicates that a good model might be to model the predicted outcomes as,
pi = β0 + rwi − rbi ,

(4)

where pi is the predicted outcome of the ith game, β0 = 0.5468 is the mean score, wi and bi are the white
and black players in game i, and rwi and rbi are their ratings, which we will attempt to ﬁt.
This model has 8, 631 features and 65, 053 training examples. It is only numerically tractable because
the model is linear and the design matrix is quite sparse, which allows for certain iterative least squares
algorithms to succeed. We solve this problem using the lsqr function in MATLAB. We ﬁnd,

training error = 0.5630,

test error = 0.7377

(5)

which is a substantial improvement from the previous model.

4 Time Dependence

Performance in chess, like all games, varies over time. For this reason, one would expect a player’s recent
games to be the best indicator of his future performance. The most convenient method to account for this
(cid:88)
phenomenon is by weighting each month diﬀerently in the least squares calculation,
wi (ti )(yi − pi )2 ,
i

error =

(6)

where yi is the actual outcome of the ith game, pi is given as in (4) and wi (t) is a weight function. The
variable ti is discretized by month, as dictated by the data. As a model for wi (t), we choose a monotonically
decreasing function. The simplest such choice is,

Post-analysis shows that the optimal value for α is 0.64, which gives some improvement:

training error = 0.5929,

test error = 0.7293

w(t) = tα .

(7)

(8)

Unfortunately, ﬁtting α by cross-validation is diﬃcult. This is due to an unfortunate feature of the training
data, namely that it is heavily end-weighted. There are many more games in the last 10 months than in the
remainder of the data set. This can be seen in ﬁgure (2).
To make matters worse, the function w(t) turns out to be crucially important to achieving optimal scores,
and the simple power law model is actually quite poor. As a demonstration of this, ﬁgure (3) shows the
optimal weighting function as determined by post-analysis. Such a model achieves a test error of 0.692, well
below the winning score for this competition. We expect that a weight function which is not monotonically
decreasing will not generalize to other contexts, but such a model may be necessary to win the competition.

5 Optimization

5.1 Reduce over-ﬁtting

There are several further techniques that should be employed to optimize predictions. First, there are many
players who engage in very few games, and as such their optimized ratings will be skewed. There are a
number of ways to reduce such over-ﬁtting, but we are constrained by the very large size of the design

3

Figure 2: The number of training examples per month. The
last months are more populated, making cross-validation diﬃ-
cult.

Figure 3: The optimal weight function and the power law
approximation. The optimal weight function produces a test
error of 0.692.

matrix. One method which is computationally eﬃcient is to introduce a damping factor to the least squares
ﬁt,

|Ar − y |2 + d2 |r|2 .

min
r

(9)

The damping factor d governs the penalty for ratings which diﬀer from zero. A quadratic penalty is not
necessarily optimal, but such a mechanism is simple to incorporate into an iterative least squares algorithm
and the problem remains numerically tractable.
In addition to penalizing outlying ratings, it is also possible to penalize outlying predictions. If B r gives
the predicted values for the test set, then we can optimize the following,
|Ar − y |2 + d2
1 |r|2 + d2
2 |B r |2 .
The above problem remains feasible, and post-analysis shows that the optimal values for the parameters are
d1 = 0 and d2 = 0.70. This produces a substantial increase in performance, and the resulting scores are now,

min
r

(10)

training error = 0.5925,

test error = 0.7025,

(11)

which would put the model into 15th place in the competition.

5.2 Include quadratic ratings

Evidence shows that at the highest level of chess competition, draws are more frequent. That is to say, the
prediction pi should tend towards 0.5 as rw+rb increases. This behavior cannot be captured by the current
linear model, which only uses the rating diﬀerence rw -rb .
This suggests we introduce a more complicated model, but unfortunatley we are computationally limited.
Running a single minimization with a non-linear model (using gradient descent) takes approximately ﬁfteen
minutes on modern hardware. While this is reasonable for the computation of a ﬁnal prediction, this is
prohibitive for the lengthy process of model- and parameter-selection.
One compromise is to employ a non-linear model to the linearly-determined ratings. One might ques-
tion whether this is a reasonable procedure since the ratings were already optimized based on their linear
diﬀerences. Figure (4) shows that indeed there is additional information in the ratings beyond their linear
diﬀerences. Notice that rA − rB is a good predictor for the overall score, but that as rA + rB increases, the
likelihood of a draw increases. This is in accord with the phenomenon we expected to observe.
So, given the linearly-ﬁtted ratings as features, we can generate a non-linear ﬁt to the data to improve
our results. It turns out that a quadratic model has the best performance, and decreases the error a small
amount:

training error = 0.5917,

test error = 0.7011,

(12)

4

020406080100050010001500200025003000MonthNumber of games10203040506070809010000.20.40.60.811.21.41.61.82monthWeightLocally Reweighted Least Squares  Best ModelOptimum Weights (from post−analysis)Figure 4: The observed score as a function of the linearly-ﬁtted ratings. The likelihood of a draw increases with the sum of
the ratings.

5.3 Post-processing

Finally, a bit of post-processing can be performed on the predictions for further optimization. Binning the
predictions near 0, 0.5, and 1, to those values helps a small amount. Curiously, it turns out that previous
games between the same opponents are actually very poor indicators of future outcomes. This problem is
exacerbated with the optimal ratings because the ratings are chosen to ﬁt past outcomes. This particular
limitation can be alleviated to some extent by rescaling the predictions between players who have previously
played each other closer toward the mean. All together, these post-processing procedures can reduce the
overall error to the ﬁnal result:

training error = 0.6035,

test error = 0.6992,

(13)

6 Conclusions

The Elo benchmark for this competition was 0.7438. This benchmark was easily surpassed with a simple
implementation of the optimal ratings method. Further modiﬁcations and optimizations allowed this model
to achieve a minimum score of 0.692, well above the winning score for this competition. Unfortunately, the
parameter choices for this particular model are unintuitive, unlikely to generalize, and impossible to obtain
without the full data set on hand. Nevertheless, the basic framework allows for the construction of very
good models with reasonable parameter choices. The best model we found with realistic parameter values
obtained a score of 0.6992, which would ﬁnish in the top ten of the competition. Unfortunately, many of the
improvements to the model came after the competition ended, so they couldn’t be submitted!
One potential drawback to the optimal ratings method is that for large datasets it is computationally
impractical. This problem has a fairly straightforward remedy. Once the overall scale and mean of the
ratings are set, ratings which are calculated within inclusive sub-populations are comparable. This means
that optimal ratings can be calculated in separate, manageable blocks. Moreover, the ﬁnal ratings could be
constructed from an average of several diﬀerent partitions of the entire population into such blocks. In this
way, ratings could be assigned regardless of how large the population happens to be.

5

