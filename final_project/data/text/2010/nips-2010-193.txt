A Theory of Multiclass Boosting

Indraneel Mukherjee

Robert E. Schapire

Princeton University, Department of Computer Science, Princeton, NJ 08540
{imukherj,schapire}@cs.princeton.edu

Abstract

Boosting combines weak classiﬁers to form highly accurate predictors. Although
the case of binary classiﬁcation is well understood, in the multiclass setting, the
“correct” requirements on the weak classiﬁer, or the notion of the most efﬁcient
boosting algorithms are missing.
In this paper, we create a broad and general
framework, within which we make precise and identify the optimal requirements
on the weak-classiﬁer, as well as design the most effective, in a certain sense,
boosting algorithms that assume such requirements.

Introduction
1
Boosting [17] refers to a general technique of combining rules of thumb, or weak classiﬁers, to form
highly accurate combined classiﬁers. Minimal demands are placed on the weak classiﬁers, so that a
variety of learning algorithms, also called weak-learners, can be employed to discover these simple
rules, making the algorithm widely applicable. The theory of boosting is well-developed for the case
of binary classiﬁcation. In particular, the exact requirements on the weak classiﬁers in this setting
are known: any algorithm that predicts better than random on any distribution over the training set
is said to satisfy the weak learning assumption. Further, boosting algorithms that minimize loss as
efﬁciently as possible have been designed. Speciﬁcally, it is known that the Boost-by-majority [6]
algorithm is optimal in a certain sense, and that AdaBoost [11] is a practical approximation.
Such an understanding would be desirable in the multiclass setting as well, since many natural clas-
siﬁcation problems involve more than two labels, e.g. recognizing a digit from its image, natural
language processing tasks such as part-of-speech tagging, and object recognition in vision. How-
ever, for such multiclass problems, a complete theoretical understanding of boosting is lacking. In
particular, we do not know the “correct” way to deﬁne the requirements on the weak classiﬁers, nor
has the notion of optimal boosting been explored in the multiclass setting.
Straightforward extensions of the binary weak-learning condition to multiclass do not work. Requir-
ing less error than random guessing on every distribution, as in the binary case, turns out to be too
weak for boosting to be possible when there are more than two labels. On the other hand, requiring
more than 50% accuracy even when the number of labels is much larger than two is too stringent,
and simple weak classiﬁers like decision stumps fail to meet this criterion, even though they often
can be combined to produce highly accurate classiﬁers [9]. The most common approaches so far
have relied on reductions to binary classiﬁcation [2], but it is hardly clear that the weak-learning
conditions implicitly assumed by such reductions are the most appropriate.
The purpose of a weak-learning condition is to clarify the goal of the weak-learner, thus aiding in
its design, while providing a speciﬁc minimal guarantee on performance that can be exploited by a
boosting algorithm. These considerations may signiﬁcantly impact learning and generalization be-
cause knowing the correct weak-learning conditions might allow the use of simpler weak classiﬁers,
which in turn can help prevent overﬁtting. Furthermore, boosting algorithms that more efﬁciently
and effectively minimize training error may prevent underﬁtting, which can also be important.
In this paper, we create a broad and general framework for studying multiclass boosting that formal-
izes the interaction between the boosting algorithm and the weak-learner. Unlike much, but not all,
of the previous work on multiclass boosting, we focus speciﬁcally on the most natural, and perhaps

1

weakest, case in which the weak classiﬁers are genuine classiﬁers in the sense of predicting a single
multiclass label for each instance. Our new framework allows us to express a range of weak-learning
conditions, both new ones and most of the ones that had previously been assumed (often only im-
plicitly). Within this formalism, we can also now ﬁnally make precise what is meant by correct
weak-learning conditions that are neither too weak nor too strong.
We focus particularly on a family of novel weak-learning conditions that have an especially ap-
pealing form: like the binary conditions, they require performance that is only slightly better than
random guessing, though with respect to performance measures that are more general than ordinary
classiﬁcation error. We introduce a whole family of such conditions since there are many ways of
randomly guessing on more than two labels, a key difference between the binary and multiclass set-
tings. Although these conditions impose seemingly mild demands on the weak-learner, we show that
each one of them is powerful enough to guarantee boostability, meaning that some combination of
the weak classiﬁers has high accuracy. And while no individual member of the family is necessary
for boostability, we also show that the entire family taken together is necessary in the sense that for
every boostable learning problem, there exists one member of the family that is satisﬁed. Thus, we
have identiﬁed a family of conditions which, as a whole, is necessary and sufﬁcient for multiclass
boosting. Moreover, we can combine the entire family into a single weak-learning condition that is
necessary and sufﬁcient by taking a kind of union, or logical OR, of all the members. This combined
condition can also be expressed in our framework.
With this understanding, we are able to characterize previously studied weak-learning conditions. In
particular, the condition implicitly used by AdaBoost.MH [19], which is based on a one-against-all
reduction to binary, turns out to be strictly stronger than necessary for boostability. This also applies
to AdaBoost.M1 [9], the most direct generalization of AdaBoost to multiclass, whose conditions
can be shown to be equivalent to those of AdaBoost.MH in our setting. On the other hand, the
condition implicit to Zhu et al.’s SAMME algorithm [21] is too weak in the sense that even when the
condition is satisﬁed, no boosting algorithm can guarantee to drive down the training error. Finally,
the condition implicit to AdaBoost.MR [19, 9] (also called AdaBoost.M2) turns out to be exactly
necessary and sufﬁcient for boostability.
Employing proper weak-learning conditions is important, but we also need boosting algorithms that
can exploit these conditions to effectively drive down error. For a given weak-learning condition,
the boosting algorithm that drives down training error most efﬁciently in our framework can be
understood as the optimal strategy for playing a certain two-player game. These games are non-
trivial to analyze. However, using the powerful machinery of drifting games [8, 16], we are able to
compute the optimal strategy for the games arising out of each weak-learning condition in the family
described above. These optimal strategies have a natural interpretation in terms of random walks, a
phenomenon that has been observed in other settings [1, 6].
Our focus in this paper is only on minimizing training error, which, for the algorithms we derive,
provably decreases exponentially fast with the number of rounds of boosting. Such results can be
used in turn to derive bounds on the generalization error using standard techniques that have been
applied to other boosting algorithms [18, 11, 13]. (We omit these due to lack of space.)
The game-theoretic strategies are non-adaptive in that they presume prior knowledge about the edge,
that is, how much better than random are the weak classiﬁers. Algorithms that are adaptive, such as
AdaBoost, are much more practical because they do not require such prior information. We show
therefore how to derive an adaptive boosting algorithm by modifying one of the game-theoretic
strategies.
We present experiments aimed at testing the efﬁcacy of the new methods when working with a very
weak weak-learner to check that the conditions we have identiﬁed are indeed weaker than others that
had previously been used. We ﬁnd that our new adaptive strategy achieves low test error compared
to other multiclass boosting algorithms which usually heavily underﬁt. This validates the potential
practical beneﬁt of a better theoretical understanding of multiclass boosting.
Previous work. The ﬁrst boosting algorithms were given by Schapire [15] and Freund [6], followed
by their AdaBoost algorithm [11]. Multiclass boosting techniques include AdaBoost.M1 and Ad-
aBoost.M2 [11], as well as AdaBoost.MH and AdaBoost.MR [19]. Other approaches include [5, 21].
There are also more general approaches that can be applied to boosting including [2, 3, 4, 12]. Two
game-theoretic perspectives have been applied to boosting. The ﬁrst one [10, 14] views the weak-

2

learning condition as a minimax game, while drifting games [16, 6] were designed to analyze the
most efﬁcient boosting algorithms. These games have been further analyzed in the multiclass and
continuous time setting in [8].

2 Framework
We introduce some notation. Unless otherwise stated, matrices will be denoted by bold capital letters
like M, and vectors by bold small letters like v. Entries of a matrix and vector will be denoted as
M (i, j ) or v(i), while M(i) will denote the ith row of a matrix. Inner product of two vectors u, v
is denoted by (cid:104)u, v(cid:105). The Frobenius inner product of two matrices Tr(MM(cid:48) ) will be denoted by
M • M(cid:48) . The indicator function is denoted by 1 [·]. The distribution over the set {1, . . . , k} will be
denoted by ∆ {1, . . . , k}.
In multiclass classiﬁcation, we want to predict the labels of examples lying in some set X . Each
example x ∈ X has a unique y label in the set {1, . . . , k}, where k ≥ 2. We are provided a training
set of labeled examples {(x1 , y1 ), . . . , (xm , ym )}.
Boosting combines several mildly powerful predictors, called weak classiﬁers, to form a highly
accurate combined classiﬁer, and has been previously applied for multiclass classiﬁcation. In this
paper, we only allow weak classiﬁer that predict a single class for each example. This is appealing,
since the combined classiﬁer has the same form, although it differs from what has been used in much
previous work.
We adopt a game-theoretic view of boosting. A game is played between two players, Booster and
Weak-Learner, for a ﬁxed number of rounds T . With binary labels, Booster outputs a distribution
in each round, and Weak-Learner returns a weak classiﬁer achieving more than 50% accuracy on
that distribution. The multiclass game is an extension of the binary game. In particular, in each
round t: (1) Booster creates a cost-matrix Ct ∈ Rm×k , specifying to Weak-Learner that the cost
{1, . . . , k} from a ﬁxed space ht ∈ H so that the cost incurred is Ct • 1ht = (cid:80)m
of classifying example xi as l is C (i, l). The cost-matrix may not be arbitrary, but should conform
to certain restrictions as discussed below. (2) Weak-Learner returns some weak classiﬁer ht : X →
i=1 Ct (i, ht (xi )),
is “small enough”, according to some conditions discussed below. Here by 1h we mean the m × k
matrix whose (i, j )-th entry is 1 [h(i) = j ]. (3) Booster computes a weight αt for the current weak
classiﬁer based on how much cost was incurred in this round.
At the end, Booster predicts according to the weighted plurality vote of the classiﬁers returned in
T(cid:88)
each round:
(cid:77)
= argmax
l∈{1,...,k}
t=1
By carefully choosing the cost matrices in each round, Booster aims to minimize the training error
of the ﬁnal classifer H , even when Weak-Learner is adversarial. The restrictions on cost-matrices
created by Booster, and the maximum cost Weak-Learner can suffer in each round, together deﬁne
classﬁer returned is at most (1/2 − γ /2) (cid:80)
the weak-learning condition being used. For binary labels, the traditional weak-learning condition
states: for any non-negative weights w(1), . . . , w(m) on the training set, the error of the weak
i wi . Here γ parametrizes the condition. There are many
ways to translate this condition into our language. The one with fewest restrictions on the cost-
(cid:8)(cid:0) 1
(cid:1) C (i, ¯yi ) + (cid:0) 1
(cid:1) C (i, yi )(cid:9) . By the correspondence
i C (i, h(xi )) ≤ (cid:80)
randomly: (cid:80)
matrices requires labeling correctly should be less costly than labeling incorrectly: ∀i : C (i, yi ) ≤
C (i, ¯yi ), while the restriction on the returned weak classiﬁer h requires less cost than predicting
2 − γ
2 + γ
w(i) = C (i, ¯yi ) − C (i, yi ), we may verify the two conditions are the same.
i
2
2
We will rewrite this condition after making some simplifying assumptions. Henceforth, without
loss of generality, we assume that the true label is always 1. Let C bin ⊆ Rm×2 consist of matrices
C which satisfy C (i, 1) ≤ C (i, 2). Further, let Ubin
γ ∈ Rm×2 be the matrix whose each row is
condition if: ∀C ∈ C bin , ∃h ∈ H : C • (cid:0)1h − Ubin
(cid:1) ≤ 0. There are two main beneﬁts to this refor-
(1/2 + γ /2, 1/2 − γ /2). Then, Weak-Learner searching space H satisﬁes the binary weak-learning
γ
mulation. With linear homogeneous constraints, the mathematics is simpliﬁed, as will be apparent
later. More importantly, by varying the restrictions C bin on the cost vectors and the matrix Ubin , we
can generate a vast variety of weak-learning conditions for the multiclass setting k ≥ 2 as we now
show.

fT (x, l), where fT (x, l)

H (x)

(cid:77)
=

1 [ht (x) = l] αt .

(1)

3

(cid:104)c(i), B(i)(cid:105) .

(2)

i.e.,

∀C ∈ C , ∃h ∈ H : C • (1h − B) ≤ 0,

Let C ⊆ Rm×k and matrix B ∈ Rm×k , which we call the baseline; we say a weak classiﬁer space
H satisﬁes the condition (C , B) if
m(cid:88)
c(i, h(i)) ≤ m(cid:88)
i=1
i=1
In (2), the variable matrix C speciﬁes how costly each misclassiﬁcation is, while the baseline B
speciﬁes a weight for each misclassiﬁcation. The condition therefore states that a weak classi-
ﬁer should not exceed the average cost when weighted according to baseline B. This large class
of weak-learning conditions captures many previously used conditions, such as the ones used by
AdaBoost.M1 [9], AdaBoost.MH [19] and AdaBoost.MR [9, 19] (see below), as well as novel con-
ditions introduced in the next section.
By studying this vast class of weak-learning conditions, we hope to ﬁnd the one that will serve the
main purpose of the boosting game: ﬁnding a convex combination of weak classiﬁers that has zero
training error. For this to be possible, at the minimum the weak classiﬁers should be sufﬁciently rich
data: ∀i : argmaxl∈{1,...,k} (cid:80)
for such a perfect combination to exist. Formally, a collection H of weak classiﬁers is eligible for
boosting, or simply boostable, if there exists a distribution λ on this space that linearly separates the
h∈H λ(h)1 [h(xi ) = l] = yi . The weak-learning condition plays two
roles. It rejects spaces that are not boostable, and provides an algorithmic means of searching for the
right combination. Ideally, the second factor will not cause the weak-learning condition to impose
additional restrictions on the weak classiﬁers; in that case, the weak-learning condition is merely a
reformulation of being boostable that is more appropriate for deriving an algorithm. In general, it
could be too strong, i.e. certain boostable spaces will fail to satisfy the conditions. Or it could be too
weak i.e., non-boostable spaces might satisfy such a condition. Booster strategies relying on either
of these conditions will fail to drive down error; the former due to underﬁtting, and the latter due
to overﬁtting. In the next section we will describe conditions captured by our framework that avoid
being too weak or too strong.

3 Necessary and sufﬁcient weak-learning conditions

The binary weak-learning condition has an appealing form: for any distribution over the examples,
the weak classiﬁer needs to achieve error not greater than that of a random player who guesses
the correct answer with probability 1/2 + γ . Further, this is the weakest condition under which
boosting is possible as follows from a game-theoretic perspective [10, 14] . Multiclass weak-learning
conditions with similar properties are missing in the literature. In this section we show how our
framework captures such conditions.
In the multiclass setting, we model a random player as a baseline predictor B ∈ Rm×k whose rows
are distributions over the labels, B(i) ∈ ∆ {1, . . . , k}. The prediction on example i is a sample from
B(i). We only consider the space of edge-over-random baselines Beor
γ ⊆ Rm×k who have a faint
clue about the correct answer. More precisely, any baseline B ∈ Beor
γ in this space is γ more likely
to predict the correct label than an incorrect one on every example i: ∀l (cid:54)= 1, B (i, 1) ≥ B (i, l) + γ ,
with equality holding for some l.
When k = 2, the space Beor
consists of the unique player Ubin
γ , and the binary weak-learning
γ
condition is given by (C bin , Ubin
correct label, i.e., the rows of the cost-matrices should come from the set (cid:8)c ∈ Rk : ∀l, c(1) ≤ c(l)(cid:9).
γ ). The new conditions generalize this to k > 2. In particular, deﬁne
C eor to be the multiclass extension of C bin : any cost-matrix in C eor should put the least cost on the
Then, for every baseline B ∈ Beor
γ , we introduce the condition (C eor , B), which we call an edge-
over-random weak-learning condition. Since C • B is the expected cost of the edge-over-random
baseline B on matrix C, the constraints (2) imposed by the new condition essentially require better
than random performance.
We now present the central results of this section. The seemingly mild edge-over-random conditions
guarantee eligibility, meaning weak classiﬁers that satisfy any one such condition can be combined
to form a highly accurate combined classiﬁer.
Theorem 1 (Sufﬁciency). If a weak classiﬁer space H satisﬁes a weak-learning condition (C eor , B),
for some B ∈ Beor
γ , then H is boostable.

4

(3)

The proof involves the Von-Neumann Minimax theorem, and is in the spirit of the ones in [10]. On
the other hand the family of such conditions, taken as a whole, is necessary for boostability in the
sense that every eligible space of weak classiﬁers satisﬁes some edge-over-random condition.
Theorem 2 (Relaxed necessity). For every boostable weak classiﬁer space H, there exists a γ > 0
and B ∈ Beor
such that H satisﬁes the weak-learning condition (C eor , B).
γ
us choose the right condition. Experiments in Section 5 suggest (cid:0)C eor , Uγ
(cid:1) is effective with very
The proof shows existence through non-constructive averaging arguments. Theorem 2 states that
any boostable weak classiﬁer space will satisfy some condition in our family, but it does not help
simple weak-learners compared to popular boosting algorithms. (Here Uγ ∈ Beor
γ is the edge-over-
random baseline closest to uniform; it has weight (1 − γ )/k on incorrect labels and (1 − γ )/k + γ
on the correct label.) However, there are theoretical examples showing each condition in our family
is too strong (supplement).
A perhaps extreme way of weakening the condition is by requiring the performance on a cost matrix
to be competitive not with a ﬁxed baseline B ∈ Beor
γ , but with the worst of them:
∀C ∈ C eor , ∃h ∈ H : C • 1h ≤ max
C • B.
B∈Beor
γ
Condition (3) states that during the course of the same boosting game, Weak-Learner may choose
to beat any edge-over-random baseline B ∈ Beor
γ , possibly a different one for every round and every
cost-matrix. This may superﬁcially seem much too weak. On the contrary, this condition turns out
to be equivalent to boostability. In other words, according to our criterion, it is neither too weak nor
too strong as a weak-learning condition. However, unlike the edge-over-random conditions, it also
turns out to be more difﬁcult to work with algorithmically.
Furthermore, this condition can be shown to be equivalent to the one used by AdaBoost.MR [19, 9].
This is perhaps remarkable since the latter is based on the apparently completely unrelated all-pairs
γ ), where CMR consists of
multiclass to binary reduction: the MR condition is given by (CMR , BMR
cost-matrices that put non-negative costs on incorrect labels and whose rows sum up to zero, while
γ ∈ Rm×k is the matrix that has γ on the ﬁrst column and −γ on all other columns(supplement).
BMR
Further, the MR condition, and hence (3), can be shown to be neither too weak nor too strong.
Theorem 3 (MR). A weak classiﬁer space H satisﬁes AdaBoost.MR’s weak-learning condition
(C MR , BMR
γ ) if and only if it satisﬁes (3). Moreover, this condition is equivalent to being boostable.
Next, we illustrate the strengths of our random-over-edge weak-learning conditions through concrete
comparisons with previous algorithms.
Comparison with SAMME. The SAMME algorithm of [21] requires the weak classiﬁers to
achieve less error than uniform random guessing for multiple labels; in our language, their weak-
learning condition is (C = {(−t, t, t, . . .) : t ≥ 0} , Uγ ). As is well-known, this condition is
not sufﬁcient for boosting to be possible. In particular, consider the dataset {(a, 1), (b, 2)} with
k = 3, m = 2, and a weak classiﬁer space consisting of h1 , h2 which always predict 1, 2, respec-
tively. Since neither classiﬁer distinguishes between a, b we cannot achieve perfect accuracy by
combining them in any way. Yet, due to the constraints on the cost-matrix, one of h1 , h2 will always
manage non-positive cost while random always suffers positive cost. On the other hand our weak-
learning condition allows the Booster to choose far richer cost matrices. In particular, when the
cost matrix is C = (c(1) = (−1, +1, 0), c(2) = (+1, −1, 0)) ∈ C eor , both classiﬁers in the above
example suffer more loss than the random player Uγ , and fail to satisfy our condition.
Comparison with AdaBoost.MH. AdaBoost.MH is a popular multiclass boosting algorithm that is
based on the one-against-all reduction[19]. However, we show that its implicit demands on the weak
classiﬁer space is too strong. We construct a classiﬁer space that satisﬁes the condition (C eor , Uγ )
in our family, but cannot satisfy AdaBoost.MH’s weak-learning condition.
Consider a space H that has, for every (1/k + γ )m element subset of the examples, a classiﬁer
that predicts correctly on exactly those elements. The expected loss of a randomly chosen classiﬁer
from this space is the same as that of the random player Uγ . Hence H satisﬁes this weak-learning
condition. On the other hand, it can be shown (supplement) that AdaBoost.MH’s weak-learning
condition is the pair (CMH , BMH
γ ), where CMH has non-(positive)negative entries on (in)correct labels,
is the vector (1/2 + γ /2, 1/2 − γ /2, . . . , 1/2 − γ /2). A
and where each row of the matrix BMH
γ

5

min
C1∈C

. . . min
CT ∈C

elsewhere, C • (cid:0)1h − BMH
(cid:1) = 1/2 − 1/k . This is positive when k > 2, so that H fails to satisfy
quick calculation shows that for any h ∈ H, and C ∈ CMH with −1 in the ﬁrst column and zeroes
γ
AdaBoost.MH’s condition.
4 Algorithms
In this section we devise algorithms by analyzing the boosting games that employ our edge-over-
random weak-learning conditions. We compute the optimum Booster strategy against a completely
adversarial Weak-Learner, which here is permitted to choose weak classiﬁers without restriction,
i.e. the entire space Hall of all possible functions mapping examples to labels. By modeling Weak-
Learner adversarially, we make absolutely no assumptions on the algorithm it might use. Hence,
error guarantees enjoyed in this situation will be universally applicable. Our algorithms are derived
from the very general drifting games framework [16] for solving boosting games, in turn inspired
by Freund’s Boost-by-majority algorithm [6], which we review next.
The OS Algorithm. Fix the number of rounds T and an edge-over-random weak-learning condition
(C , B). For simplicity of presentation we ﬁx the weights αt = 1 in each round. With fT deﬁned as
m(cid:88)
in (1), the optimum Booster payoff can be written as
max
max
(1/m)
h1∈Hall :
hT ∈Hall :
C1 •(1h1 −B)≤0
CT •(1hT −B)≤0
i=1
Here the function L : Rk → R is error, but we can also consider other loss functions such as
exponential loss, hinge loss, etc. that upper-bound error and are proper: i.e. L(x) is increasing in
the weight of the correct label x(1), and decreasing in the weights of the incorrect labels x(l), l (cid:54)= 1.
Directly analyzing the optimal payoff is hard. However, Schapire [16] observed that the payoffs
can be very well approximated by certain potential functions. Indeed, for any b ∈ Rk deﬁne the
(cid:8)El∼p
(cid:2)φb
t−1 (s + el )(cid:3) : El∼p [c(l)] ≤ (cid:104)b, c(cid:105)(cid:9) ,
t : Rk → R by the following recurrence:
potential function φb
max
0 = L;
t (s) =
min
(4)
φb
φb
p∈∆{1,...,k}
c∈Rk :∀l:c(1)≤c(l)
where el ∈ Rk is the unit-vector whose lth coordinate is 1 and the remaining coordinates zero.
(cid:80)t−1
t (st ) of whether an example x will be misclassiﬁed,
These potential functions compute an estimate φb
based on its current state st consisting of counts of votes received so far on various classes st (l) =
1 [ht(cid:48) (x) = l], and the number of rounds t remaining. Using these functions, Schapire [16]
t(cid:48)=1
proposed a Booster strategy, aka the OS strategy, which, in round t, constructs a cost matrix C ∈ C ,
whose each row C(i) achieves the minimum of the right hand side of (4) with b replaced by B(i), t
replaced by T − t, and s replaced by current state st (i). The following theorem provides a guarantee
for the loss suffered by the OS algorithm, and also shows that it is the game-theoretically optimum
Booster employs the OS algorithm, then the average potential of the states (1/m) (cid:80)m
strategy when the number of examples is large.
Theorem 4 (Extension of results in [16]). Suppose the weak-learning condition is given by (C , B), If
(1/m) (cid:80)m
i=1 φB(i)
(s(i))
t
never increases in any round.
In particular, loss suffered after T rounds of play is at most
i=1 φB(i)
(0). Further, for any  > 0, when the loss function satisﬁes some mild condi-
tions, and m (cid:29) T , k , 1/, no Booster strategy can achieve loss  less than the above bound in T
T
rounds.

L(fT (xi , 1), fT (xi , 2), . . . , fT (xi , k)).

Computing the potentials.
In order to implement the OS strategy using our weak-learning con-
t for distributions b ∈ ∆ {1, . . . , k}. Fortunately,
ditions, we only need to compute the potential φb
these potentials have a very simple solution in terms of the homogeneous random-walk Rt
b (x), the
random position of a particle after t time steps, that starts at location x ∈ Rk , and in each step moves
in direction el with probability b(l).
Theorem 5. If L is proper, and b ∈ ∆ {1, . . . , k} satisﬁes ∀l : b(1) ≥ b(l), then φb
t (s) =
E [L (Rt
b (s))]. Furthermore, the vector achieving the minimum in the right hand side of (4) is
given by c(l) = φb
t−1 (s + el ).
Theorem (5) implies the OS strategy chooses the following cost matrix in round t: c(i, l) =
φb(i)
T −t−1 (st (i) + el ), where st (i) is the state of example i in round t. Therefore everything boils

6

c(i, l) =

down to computing the potentials, which is made possible by Theorem 5. There is no simple closed
form solution for the non-convex 0-1 loss L(s) = 1[s1 ≤ (maxi>1 si )]. However, using Theo-
rem 4, we can write the potential φt (s) explicitly, and then compute it using dynamic programming
in O(t3k) time. This yields very tight bounds.
To obtain a more efﬁcient procedure, and one that we will soon show can be made adaptive, we next
t (s) = (cid:80)k
focus on the exponential loss associated with AdaBoost that does have a closed form solution.
Lemma 1. If L(s) = exp(η2 (s2 − s1 )) + · · · + exp(ηk (sk − s1 )), where each ηl is positive, then
l=2 (al )t eηl (sl−s1 ) , where al = 1 − (b1 + bl ) +
the solution in Theorem 5 evaluates to φb
eηl bl + e−ηl b1 .
η = (η , η , . . .), the relevant potential is φt (s) = κ(γ , η)t (cid:80)k
In particular, when the condition is (C eor , Uγ ) and
The proof by induction is straightforward.
l=2 eη(sl−s1 ) where κ(γ , η) =
1 + (1−γ )
(eη + e−η − 2) − (1 − e−η ) γ .
The cost-matrix output by the OS algorithm can be
k
(cid:40)(eη − 1) eη(sl−s1 )
simpliﬁed by rescaling, or adding the same number to each coordinate of a cost vector, without
affecting the constraints it imposes on a weak classiﬁer, to the following form
(e−η − 1) (cid:80)k
if l > 1,
j=2 eη(sj −s1 )
if l = 1,
(1/m) (cid:80)m
With such a choice, Theorem 4 and the form of the potential guarantee that the average loss
i=1 L(st (i)) of the states st (i) changes by a factor of at most κ (γ , η) every round. Hence
the ﬁnal loss is at most (k − 1)κ (γ , η)T .
Variable edges. So far we have required Weak-Learner to beat random by at least a ﬁxed amount
γ > 0 in each round of the boosting game.
In reality, the edge over random is larger initially,
and gets smaller as the OS algorithm creates harder cost matrices. Therefore requiring a ﬁxed
edge is either unduly pessimistic or overly optimistic. If the ﬁxed edge is too small, not enough
progress is made in the initial rounds, and if the edge is too large, Weak-Learner fails to meet the
weak-learning condition in latter rounds. We attempt to ﬁx this via two approaches: prescribing a
decaying sequence of edges γ1 , . . . , γT , or being completely ﬂexible, aka adaptive, with respect to
the edges returned by the weak-learner. In either case, we only use the edge-over-random condition
(C eor , Uγ ), but with varying values of γ .
Fixed sequence of edges. With a prescribed sequence of edges γ1 , . . . , γT the weak-learning condi-
tion (C eor , Uγt ) in each round t is different. We allow the weights α1 , . . . , αT to be arbitrary, but they
In particular, by the arguments leading to (5), if we want to minimize (cid:80)m
(cid:80)k
must be ﬁxed in advance. All the results for uniform γ and weights αt = 1 hold in this case as well.
l=2 e{ft (i,l)−ft (i,1)} ,
(cid:40)(eαt − 1) eft−1 (i,j )−ft−1 (i,1)
i=1
where ft is as deﬁned in (1), then the following strategy is optimal: in round t output the cost matrix
(e−αt − 1) (cid:80)k
if l > 1,
This will ensure that the expression (cid:80)m
(cid:80)k
C (i, l) =
j=2 eft−1 (i,j )−ft−1 (i,1)
if l = 1.
κ(γt , αt ) in each round. Hence the ﬁnal loss will be at most (k − 1) (cid:81)T
l=2 e{ft (i,l)−ft (i,1)} changes by a factor of at most
i=1
t=1 κ(γt , αt ).
Adaptive.
In the adaptive setting, we depart from the game-theoretic framework in that Weak-
Learner is no longer adversarial. Further, we are no longer guaranteed to receive a certain sequence
(cid:81)T
of edges. Since the choice of cost-matrix in (6) does not depend on the edges, we could ﬁx an
arbitrary set of weights αt in advance, follow the same algorithm as before and enjoy the same bound
t=1 κ(γt , αt ). The trouble with this is κ(γt , αt ) is not less than 1 unless αt is small compared to
γt . To ensure progress, the weight αt must be chosen adaptively as a function of γt . Since we do not
(cid:40)(eα − 1) eft−1 (i,j )−ft−1 (i,1)
know what edge we will receive, we choose the cost matrix as before but anticipating inﬁnitesimally
small edge, in the spirit of [7], (and with some rescaling)
(e−α − 1) (cid:80)k
(cid:77)
1
(cid:40)
=
Cα (i, l)
C (i, l) = lim
j=2 eft−1 (i,j )−ft−1 (i,1)
α→0
α
− (cid:80)k
eft−1 (i,j )−ft−1 (i,1)
if l > 1,
j=2 eft−1 (i,j )−ft−1 (i,1)
if l = 1.

if l > 1,
if l = 1.

=

(5)

(6)

(7)

7

(a)

(b)

Figure 1: Figure 1(a) plots the ﬁnal test-errors of M1(black, dashed), MH(blue, dotted) and New method(red,
solid) against the maximum tree-sizes allowed as weak classiﬁers. Figure 1(b) plots how fast the test-errors of
these algorithms drop with rounds, when the maximum tree-size allowed is 5.

Since Weak-Learner cooperates, we expect the edge δt of the returned classiﬁer ht on the supplied
cost-matrix limα→0 Cα to be more than just inﬁnitesimal. In that case, by continuity, there are non-
(cid:16) 1+δt
(cid:17)
inﬁnitesimal choices of the weight αt such that the edge γt achieved by ht on the cost-matrix Cαt
remains large enough to ensure κ(γt , αt ) < 1. In fact, with any choice of αt , we get κ (γt , αt ) ≤
κ (γt , αt ) ≤ (cid:112)1 − δ2
2 (eαt + e−αt − 2) (supplement). Tuning αt to 1
1 − 1
2 (eαt − e−αt ) δt + 1
2 ln
(cid:110)−(1/2) (cid:80)T
(cid:111)
results in
(cid:112)1 − δ2
1−δt
T rounds is at most (k − 1) (cid:81)T
t . This algorithm is adaptive, and ensures that the loss, and hence error, after
t ≤ (k − 1) exp
.
t=1 δ2
t
t=1
5 Experiments
We report preliminary experimental results on six, varying multiclass UCI datasets.
The ﬁrst set of experiments were aimed at determining
overall performance of our new algorithm. We compared
a standard implementation M1 of AdaBoost.M1 with C4.5
as weak learner, and the Boostexter implementation MH
of AdaBoost.MH using stumps [20], with the adaptive
algorithm described in Section 4, which we call New
method, using a naive greedy tree-searching algorithm
Greedy for weak-learner. The size of trees was chosen
to be of the same order as the tree sizes used by M1. Test
errors after 500 rounds of boosting are plotted in Figure 2.
The performance is comparable with M1 and far better
than MH (understandably since stumps are far weaker than
trees), even though our weak-learner is very naive com-
pared to C4.5.
We next investigated how each algorithm performs with
less powerful weak-classiﬁers, namely, decision trees whose size has been sharply limited to various
pre-speciﬁed limits. Figure 1(a) shows test-error plotted as a function of tree size. As predicted by
our theory, our algorithm succeeds in boosting the accuracy even when the tree size is too small
to meet the stronger weak learning assumptions of the other algorithms. The differences in perfor-
mance are particularly strong when using the smallest tree sizes.
More insight is provided by plots in Figure 1(b) of the rate of convergence of test error with rounds
when the tree size allowed is very small (5). Both M1 and MH drive down the error for a few rounds.
But since boosting keeps creating harder cost-matrices, very soon the small-tree learning algorithms
are no longer able to meet the excessive requirements of M1 and MH. However, our algorithm makes
more reasonable demands that are easily met by the weak learner.

Figure 2: This is a plot of the ﬁnal test-errors
of standard implementations of M1, MH and
New method after 500 rounds of boosting.

8

5201005000.300.350.40connect45201005000.30.50.7forest5201005000.00.40.8letter520502000.10.30.5pendigits5201005000.200.300.400.50poker520502000.080.140.20satimage0.320.360.40connect401003005000.40.60.81.0forest01003005000.40.60.81.0letter01003005000.10.30.5pendigits01003005000.400.50poker01003005000.100.150.200.25satimage0100300500connect4forestletterpendigitspokersatimage0.00.10.20.30.4MHM1New MethodInformation and Computation,

References
[1] Jacob Abernethy, Peter L. Bartlett, Alexander Rakhlin, and Ambuj Tewari. Optimal stragies and min-
imax lower bounds for online convex games. In Proceedings of the Nineteenth Annual Conference on
Computational Learning Theory, pages 415–424, 2008.
[2] Erin L. Allwein, Robert E. Schapire, and Yoram Singer. Reducing multiclass to binary: A unifying
approach for margin classiﬁers. Journal of Machine Learning Research, 1:113–141, 2000.
[3] Alina Beygelzimer, John Langford, and Pradeep Ravikumar. Error-correcting tournaments. In Algorith-
mic Learning Theory: 20th International Conference, pages 247–262, 2009.
[4] Thomas G. Dietterich and Ghulum Bakiri. Solving multiclass learning problems via error-correcting
output codes. Journal of Artiﬁcial Intelligence Research, 2:263–286, January 1995.
[5] G ¨unther Eibl and Karl-Peter Pfeiffer. Multiclass boosting for weak classiﬁers. Journal of Machine Learn-
ing Research, 6:189–210, 2005.
[6] Yoav Freund. Boosting a weak learning algorithm by majority.
121(2):256–285, 1995.
[7] Yoav Freund. An adaptive version of the boost by majority algorithm. Machine Learning, 43(3):293–318,
June 2001.
[8] Yoav Freund and Manfred Opper. Continuous drifting games. Journal of Computer and System Sciences,
pages 113–132, 2002.
[9] Yoav Freund and Robert E. Schapire. Experiments with a new boosting algorithm. In Machine Learning:
Proceedings of the Thirteenth International Conference, pages 148–156, 1996.
[10] Yoav Freund and Robert E. Schapire. Game theory, on-line prediction and boosting. In Proceedings of
the Ninth Annual Conference on Computational Learning Theory, pages 325–332, 1996.
[11] Yoav Freund and Robert E. Schapire. A decision-theoretic generalization of on-line learning and an
application to boosting. Journal of Computer and System Sciences, 55(1):119–139, August 1997.
[12] Trevor Hastie and Robert Tibshirani. Classiﬁcation by pairwise coupling. Annals of Statistics, 26(2):451–
471, 1998.
[13] V. Koltchinskii and D. Panchenko. Empirical margin distributions and bounding the generalization error
of combined classiﬁers. Annals of Statistics, 30(1), February 2002.
[14] Gunnar R ¨atsch and Manfred K. Warmuth. Efﬁcient margin maximizing with boosting. Journal of Machine
Learning Research, 6:2131–2152, 2005.
[15] Robert E. Schapire. The strength of weak learnability. Machine Learning, 5(2):197–227, 1990.
[16] Robert E. Schapire. Drifting games. Machine Learning, 43(3):265–291, June 2001.
[17] Robert E. Schapire. The boosting approach to machine learning: An overview. In MSRI Workshop on
Nonlinear Estimation and Classiﬁcation, 2002.
[18] Robert E. Schapire, Yoav Freund, Peter Bartlett, and Wee Sun Lee. Boosting the margin: A new explana-
tion for the effectiveness of voting methods. Annals of Statistics, 26(5):1651–1686, October 1998.
[19] Robert E. Schapire and Yoram Singer. Improved boosting algorithms using conﬁdence-rated predictions.
Machine Learning, 37(3):297–336, December 1999.
[20] Robert E. Schapire and Yoram Singer. BoosTexter: A boosting-based system for text categorization.
Machine Learning, 39(2/3):135–168, May/June 2000.
[21] Ji Zhu, Hui Zou, Saharon Rosset, and Trevor Hastie. Multi-class AdaBoost. Statistics and Its Interface,
2:349360, 2009.

9

