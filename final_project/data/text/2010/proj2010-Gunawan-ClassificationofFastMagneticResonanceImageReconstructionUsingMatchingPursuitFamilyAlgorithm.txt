Classification of Fast Magnetic Resonance Image Reconstruction Using Matching Pursuit 
Family Algorithm 
 
Aldi Gunawan 
December 10, 2010 
aldi@stanford.edu 

 
1 

Introduction 
Magnetic  Resonance  Imaging  (MRI)  is  one  of  imaging  machine  that  has  a  low 
throughput  outcome.  A  single  patient  can  take  approximately  30  minutes  to  an  hour  of 
measurement  depending  on  the  part  of  the  body  being  measured.  The  lengthy  process 
bottlenecked  the  income  generated  by  a  single machine,  and  increasing  discomforts  for  patients 
as well. 
There  is  a huge motivation  to  increase  the  throughput  of MRI machine output by  cutting 
down  the  number  of  image  sample  below Nyquist  threshold. Hence  dramatically  decreasing  the 
measurement  time  and  increasing  the  number  of  patients  that  can  use  the  MR I  machine. 
Unfortunately, the reduction of number of image sampling will increase the difficulty and cost in 
image  reconstruction  process  considerably.  For  example,  a  brute  force  image  reconstruction 
could take weeks to reconstruct and image with 10% sampling. 
Compressed  Sensing  (CS)  is  a  recently  introduced  theory  for  the  recovery  of  sparse 
signals  from  limited amount of measurement data. There are many novel  solutions  to  solve such 
reconstruction. This  paper will  discuss  the Matching  Pursuit  family  technique  such  as Matching 
Pursuit,  Orthogonal  Matching  Pursuit,  Regularized  Orthogonal  Matching  Pursuit,  Compressive 
Sampling  Matching  Pursuit  and  Subspace  Pursuit  in  classifying  the  image.  “Matching  Pursuit 
family  is  a  general,  greedy,  sparse  function  approximation  scheme  with  the  squared  error  loss, 
which  iteratively  adds  new  functions  (i.e.  basis  functions)  to  the  linear  expansion.  If  we  take  as 
“dictionary  of  functions”  the  functions     (  )  of  the  form   (         )  where       is  the  input  part  of 
training  example,  then  the  linear  expansion  has  essentially  the  same  form  as  Support  Vector 
Machine”[1].  Our  goal  is  to  use  Matching  Pursuit  algorithm  to  determine  which  parts  of  the 
pixel  contains  an  image  and which  parts  do  not, while maintaining  image  quality  and  time  cost. 
We finally discuss the optimum algorithm for solving the problem. 
 
2 
Problem Formulation 
In MRI,  the measurement can be  represented by  a  linear combination of vector sets  in   
 
such that: 

        
Where      is  the  measured  Fourier  transformed  signal  in  the  k-space  domain.     is  the 
 
dictionary and    is the target sparse reconstructed image, such that: 
 

                                

 

In CS,  the  problem  arises  as we  decrease  the  number  of measurement  data   significantly, 
such  that       .  Therefore  the  dimensionality  of  full  row  rank     becomes  an  under-
deterministic  problem  with  multiple  solutions.  Moreover,  the  solution  estimation  difficulty  is 
increasing exponentially as the dimension scale is increased. The problem is further increased by 
inefficient implementation of Matching Pursuit family algorithm to solve larger dimension scale, 

such  as  an  image.  Fortunately,  if  the  signal      is  sparse  with  k  non-zero  feature  or  element,  the 
solution may be unique. 
 
3 
Matching Pursuit Family Algorithm 
 
There are several Matching Pursuit family algorithms  that will be studied here: Matching 
Pursuit  (MP)  [2],  Orthogonal  Matching  Pursuit  (OMP)  [3],  Regularized  Orthogonal  Matching 
Pursuit  (ROMP)  [4],  Compressive  Sampling  Matching  Pursuit  (CoSaMP)  [5]  and  Subspace 
Pursuit (SP) [6]. Only MP algorithm is shown. 
 
3.1  Matching Pursuit 
 
Mallat and Zhang proposed a scheme to recover a sparse signal by using a method called 
Matching Pursuit. 

     ̂
        
Where  ̂
   is the approximation of    after k-th iteration, and     is the residual and is orthogonal to 
 ̂
  .  Let       be  the  coefficients  of  the  k  chosen  vectors  from  normalized   .  Let     be  the  k-th 
chosen  vector,  the  algorithm will  choose      with  the  largest magnitude  element  from  the  proxy 
with the following: 

‖    ‖    ‖   ‖    |〈          〉|   

 
We want to minimize the next residual by maximizing the proxy 〈          〉. 
 
Algorithm 1 MP: 
1.  Normalized   
2.  Initialized          
3.  Loop until k: 
a.  Choose unpicked index of the largest proxy 
b.      = de-normalized correlation value 
c.                           

 
4 

Inverse Problem 
Given a dictionary   and a measurement   , we want to reconstruct the sparse signal   , 
such that it contains only k number of non-zero elements. The purpose of this experiment 
is to compare the accuracy of the reconstructed signal to the true solution and the run time 
of each algorithms to finish the computation. Furthermore, the behavior of the run time 
will be used to predict the feasibility of the algorithms in large scale problem. 

 
 

 

Algorithms  Current Implementation  Theoretical 
O(mnk) 
O(mnk) 
MP 
O(mnk) 
O(mnk) 
OMP 
O(mk^3) 
O(mnk) 
ROMP 
O(mnk) 
O(mk^3) 
CoSaMP 
O(mk^3) 
O(mnk) 
SP 

 
The current algorithms implementation is still inefficient for solving the inverse problem. 
As  shown  in  the  figure,  as  the  number  of  dimension  is  increased,  the  running  time  will  be 
increased  as  well.  The  bottleneck  of  the  implementation  occurs  at  the  computation  of  the 
projection:     (   )     . At  this point ROMP  algorithm will  be dropped  from  comparison 
study. 
 
In  the  next  section,  we  will  discuss  a  novel  way  to  solve  the  bottleneck  problem  using 
fixed point iteration called Richardson Iteration, which arguably faster than Newton’s Method, to 
achieve the theoretical computation cost. 
 
5 
 

Richardson Iteration 
Suppose we want to solve: 

   ‖      ‖ 
 
let   be an orthonormal tall matrix and let the linear equation be: 
(   )         
            

Joining the above equations yields: 

                  

 
Algorithm 2 Richardson Iteration: 
1.  Calculate proxy =      
2.  Initialized        
3.  Form             
4.  Repeat 
                  
5.  Until ‖          ‖      

 
5.1   Richardson Iteration Implementation on CoSaMP and SP 
 

 

 

Compared  to  previous  figures  in  section  4,  the  new  implementation  of  CoSaMP  and  SP 
 
with  Richardson  Iteration  now  scale  well  as  the  dimension  of  the  problem  becomes  large. 
CoSaMP and SP performances’ are also better than MP and OMP performances’. 
 
2D-FFT Implementation and Large Scale Problem 
6 
 
At this point, we will further increase the magnitude of dimension to 256 by 256 pixels to 
mimic  the  original  MRI  image  dimension.  At  this  point,  we  will  drop  MP  and  OMP  from 
discussion  as  it  is  shown  that  CoSaMP  and  SP  performed  better  compared  to  MP  and  OMP  as 
the dimension is increased. 
 

 

 

 
7 
 

Image Reconstruction Comparison 
We will introduce Lustig’s scheme [7] for MRI image reconstruction comparison. 

                  Original 
 
With the same sampling pattern: 

 

  
       10% acceleration sampling 

   

    Lustig’s reconstruction 

                         
 
 
 

   CoSaMP 

 

           
 

 

SP 

 

Qualitatively,  all  3  reconstruced  images  are  comparable.  We  will  provide  quantitative 
comparison  based  on  the  Peak  Signal  to Noise  Ratio  (PSNR)  to  compare  reconstruction  quality 
and computation run time to compare the cost. 
 

 

References 

 
As  the  number  of  acceleration  is  increased,  the  reconstructed  quality  of  CoSaMP  is 
decreasing much more  than SP.  It  is also more costly  in  the experiments compared  to SP. While 
SP are generally perform better than Lustig’s scheme and CoSaMP. 
 
Conclusion 
7 
For overall, CoSaMP does not provide better reconstruction compared  to  the results from 
 
SP.  Under  certain  conditions,  SP  generally  provide  us  with  better  run  time  and  accuracy 
compared  to  the  algorithms  implemented  by  Lustig  and  CoSaMP.  Therefore,  SP  is  the  best 
choice among the studied algorithms in this project. 
 
8 
 
[1] P. Vincent and Y. Bengio, “Kernel Matching Pursuit,” Machine Learning on, vol. 48,  pp. 165–187, 
2002. 
 
[2] S. Mallat and Z. Zhang, “Matching pursuits with time-frequency dictionaries,” Signal Processing, 
IEEE Transactions on, vol. 41, no. 12, pp. 3397–3415, 1993. 
 
[3] Y. Pati, R. Rezaiifar, and P. Krishnaprasad, “Orthogonal matching pursuit: recursive  function 
approximation withapplications to wavelet decomposition,” Proceedings of 27th Asilomar Conference on 
Signals, Systems and Computers, pp. 40–44, 1993. 
 
[4] D. Needell and R. Vershynin, “Uniform uncertainty principle and signal recovery via  regularized 
orthogonal matching pursuit,” Arxiv preprint arXiv:0707.4203, 2007. 
 
[5] J. Tropp and D. Needell, “CoSaMP: Iterative signal recovery from incomplete and in-accurate 
samples,” Arxiv preprint arXiv:0803.2392, 2008. 
 
[6] W. Dai and O. Milenkovic, “Subspace Pursuit for Compressive Sensing: Closing the Gap Between 
Performance and Complexity,” Arxiv preprint arXiv:0803.0811, 2008. 
 
[7]  M. Lustig, D. Donoho, and J. Pauly, “Sparse MRI: The application of compressed sensing for rapid 
MR imaging,” MAGNETIC RESONANCE IN MEDICINE, vol. 58, no. 6, p. 1182, 2007. 
 

