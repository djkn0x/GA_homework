Construction of Dependent Dirichlet Processes
based on Poisson Processes

Dahua Lin
CSAIL, MIT
dhlin@mit.edu

Eric Grimson
CSAIL, MIT
welg@csail.mit.edu

John Fisher
CSAIL, MIT
fisher@csail.mit.edu

Abstract

We present a novel method for constructing dependent Dirichlet processes. The
approach exploits the intrinsic relationship between Dirichlet and Poisson pro-
cesses in order to create a Markov chain of Dirichlet processes suitable for use
as a prior over evolving mixture models. The method allows for the creation, re-
moval, and location variation of component models over time while maintaining
the property that the random measures are marginally DP distributed. Addition-
ally, we derive a Gibbs sampling algorithm for model inference and test it on both
synthetic and real data. Empirical results demonstrate that the approach is effec-
tive in estimating dynamically varying mixture models.

1

Introduction

As the cornerstone of Bayesian nonparametric modeling, Dirichlet processes (DP) [22] have been
applied to a wide variety of inference and estimation problems [3, 10, 20] with Dirichlet process
mixtures (DPMs) [15, 17] being one of the most successful. DPMs are a generalization of ﬁnite
mixture models that allow an indeﬁnite number of mixture components. The traditional DPM model
assumes that each sample is generated independently from the same DP. This assumption is limiting
in cases when samples come from many, yet dependent, DPs. HDPs [23] partially address this
modeling aspect by providing a way to construct multiple DPs implicitly depending on each other
via a common parent. However, their hierarchical structure may not be appropriate in some problems
(e.g. temporally varying DPs).
Consider a document model where each document is generated under a particular topic and each
topic is characterized by a distribution over words. Over time, topics change: some old topics fade
while new ones emerge. For each particular topic, the word distribution may evolve as well. A
natural approach to model such topics is to use a Markov chain of DPs as a prior, such that the DP
at each time is generated by varying the previous one in three possible ways: creating a new topic,
removing an existing topic, and changing the word distribution of a topic.
Since MacEachern introduced the notion of dependent Dirichlet processes (DDP) [12], a vari-
ety of DDP constructions have been developed, which are based on either weighted mixtures of
DPs [6, 14, 18], generalized Chinese restaurant processes [4, 21, 24], or the stick breaking construc-
tion [5, 7]. Here, we propose a fundamentally different approach, taking advantage of the intrinsic
relationship between Dirichlet processes and Poisson processes: a Dirichlet process is a normal-
ized Gamma process, while a Gamma process is essentially a compound Poisson process. The key
idea is motivated by the following: observations that preserve complete randomness when applied
to Poisson processes result in a new process that remains Poisson. Consequently, one can obtain
a Dirichlet process which is dependent on other DPs by applying such operations to their underly-
ing compound Poisson processes. In particular, we discuss three speciﬁc operations: superposition,
subsampling, and point transition. We develop a Markov chain of DPs by combining these opera-
tions, leading to a framework that allows creation, removal, and location variation of particles. This

1

construction inherently comes with an elegant property that the random measure at each time is
marginally DP distributed. Our approach relates to previous efforts in constructing dependent DPs
while overcoming inherent limitations. A detailed comparison is given in section 4.

2 Poisson, Gamma, and Dirichlet Processes

Our construction of dependent Dirichlet processes rests upon the connection between Poisson,
Gamma, and Dirichlet processes, as well as the concept of complete randomness. We brieﬂy re-
view these concepts; Kingman [9] provides a detailed exposition of the relevant theory.
Let (Ω, FΩ ) be a measurable space, and Π be a random point process on Ω. Each realization of Π
uniquely corresponds to a counting measure NΠ deﬁned by NΠ (A) (cid:44) #(Π ∩ A) for each A ∈ FΩ .
Hence, NΠ is a measure-valued random variable or simply a random measure. A Poisson process
Π on Ω with mean measure µ, denoted Π ∼ PoissonP(µ), is deﬁned to be a point process such
that NΠ (A) has a Poisson distribution with mean µ(A) and that for any disjoint measurable sets
A1 , . . . , An , NΠ (A1 ), . . . , NΠ (An ) are independent. The latter property is referred to as complete
randomness. Poisson processes are the only point process that satisﬁes this property [9]:
Theorem 1. A random point process Π on a regular measure space is a Poisson process if and only
if NΠ is completely random. If this is true, the mean measure is given by µ(A) = E(NΠ (A)).
Σ∗ (cid:44) (cid:88)
Consider Π∗ ∼ PoissonP(µ∗ ) on a product space Ω × R+ . For each realization of Π∗ , We deﬁne
Σ∗ : FΩ → [0, +∞] as
(1)
wθ δθ
(θ,wθ )∈Π∗
Intuitively, Σ∗ (A) sums up the values of wθ with θ ∈ A. Note that Σ∗ is also a completely random
measure (but not a point process in general), and is essentially a generalization of the compound
Poisson process. As a special case, if we choose µ∗ to be
µ∗ = µ × γ with γ (dw) = w−1 e−w dw,
(2)
Then the random measure as deﬁned in Eq.(1) is called a Gamma process with base measure µ,
denoted by G ∼ ΓP(µ). Normalizing any realization of G ∼ ΓP(µ) yields a sample of a Dirichlet
process, as
D (cid:44) G/G(Ω) ∼ DP(µ).
(3)
In conventional parameterization, µ is often decomposed into two parts: a base distribution pµ (cid:44)
µ/µ(Ω), and a concentration parameter αµ (cid:44) µ(Ω).

3 Construction of Dependent Dirichlet Processes

Motivated by the relationship between Poisson and Dirichlet processes, we develop a new approach
for constructing dependent Dirichlet processes (DDPs). Our approach can be described as follows:
given a collection of Dirichlet processes, one can apply operations that preserve the complete ran-
domness of their underlying Poisson processes. This yields a new Poisson process (due to theorem 1)
and a related DP which depends on the source. In particular, we consider three such operations: su-
perposition, subsampling, and point transition.
Superposition of Poisson processes: Combining a set of independent Poisson processes yields a
Poisson process whose mean measure is the sum of mean measures of the individual ones.
Theorem 2 (Superposition Theorem [9]). Let Π1 , . . . , Πm be independent Poisson processes on Ω
with Πk ∼ PoissonP(µk ), then their union has
Π1 ∪ · · · ∪ Πm ∼ PoissonP(µ1 + · · · + µm ).
(cid:32) m(cid:88)
(cid:33)
(cid:32)(cid:32) m(cid:88)
(cid:33)
(cid:33)
Given a collection of independent Gamma processes G1 , . . . , Gm , where for each k = 1, . . . , m,
k ∼ PoissonP(µk × γ ). By theorem 2, we have
Gk ∼ ΓP(µk ) with underlying Poisson process Π∗
m(cid:91)
k ∼ PoissonP
(µk × γ )
× γ
Π∗
k=1
k=1
k=1

= PoissonP

(4)

µk

.

(5)

2

(6)

Due to the relationship between Gamma processes and their underlying Poisson processes, such a
combination is equivalent to the direct superposition of the Gamma processes themselves, as
G(cid:48) := G1 + · · · + Gm ∼ ΓP(µ1 + · · · + µm ).
Let Dk = Gk /Gk (Ω), and gk = Gk (Ω), then Dk is independent of gk , and thus
Here, ck = gk / (cid:80)m
D (cid:48) := G(cid:48)/G(cid:48) (Ω) = (g1D1 + · · · + gmDm )/(g1 + · · · + gm ) = c1D1 + · · · + cmDm .
(7)
l=1 gl , which has (c1 , . . . , cm ) ∼ Dir(µ1 (Ω), . . . , µm (Ω)). Consequently, one
can construct a Dirichlet process through a random convex combination of independent Dirichlet
processes. This result is summarized by the following theorem:
Theorem 3. Let D1 , . . . , Dm be independent Dirichlet processes on Ω with Dk ∼ DP(µk ), and
(c1 , . . . , cm ) ∼ Dir(µ1 (Ω), . . . , µm (Ω)) be independent of D1 , . . . , Dm , then
D1 ⊕ · · · ⊕ Dm := c1D1 + · · · cmDm ∼ DP(µ1 + · · · + µm ).
(8)
µk (Ω) and α(cid:48) = (cid:80)m
Here, we use the symbol ⊕ to indicate superposition via a random convex combination. Let αk =
m(cid:88)
k=1 αk , then for each measurable subset A,
E(D (cid:48) (A)) =
and Cov(D (cid:48) (A), Dk (A)) = αk
αk
α(cid:48) E(Dk (A)),
α(cid:48) Var(Dk (A)).
k=1

(9)

Subsampling Poisson processes: Random subsampling of a Poisson process via independent
Bernoulli trials yields a new Poisson process.
Theorem 4 (Subsampling Theorem). Let Π ∼ PoissonP(µ) be a Poisson process on the space Ω,
and q : Ω → [0, 1] be a measurable function. If we independently draw zθ ∈ {0, 1} for each θ ∈ Π0
with P(zθ = 1) = q(θ), and let Πk = {θ ∈ Π : zθ = k} for k = 0, 1, then Π0 and Π1 are
independent Poisson processes on Ω, with Π0 ∼ PoissonP((1 − q)µ) and Π1 ∼ PoissonP(qµ)1 .
We emphasize that subsampling is via independent Bernoulli trials rather than choosing a ﬁxed
process G is equivalent to subsampling the terms of G. Let G = (cid:80)∞
number of particles. We use Sq (Π) := Π1 to denote the result of subsampling, where q is referred
to as the acceptance function. Note that subsampling the underlying Poisson process of a Gamma
G(cid:48) = Sq (G) := (cid:88)
i=1 wi δθi , and for each i, we
draw zi with P(zi = 1) = q(θi ). Then, we have
wi δθi ∼ ΓP(qµ).
i:zi=1
Let D be a Dirichlet process given by D = G/G(Ω), then we can construct a new Dirichlet pro-
cess D (cid:48) = G(cid:48)/G(cid:48) (Ω) by subsampling the terms of D and renormalizing their coefﬁcients. This is
Theorem 5. Let D ∼ DP(µ) be represented by D = (cid:80)n
summarized by the following theorem.
i=1 ri δθi and q : Ω → [0, 1] be a measur-
D (cid:48) = Sq (D) := (cid:88)
able function. For each i we independently draw zi with P(zi = 1) = q(θi ), then
i δθi ∼ DP(qµ),
r (cid:48)
i := ri/ (cid:80)
i:zi=1
where r (cid:48)
j :zj =1 rj are the re-normalized coefﬁcients for those i with zi = 1.
(cid:82)
Let α = µ(Ω) and α(cid:48) = (qµ)(Ω), then for each measurable subset A,
(cid:82)
and Cov(D (cid:48) (A), D(A)) = α(cid:48)
(qµ)(A)
A qdµ
E(D (cid:48) (A)) =
(qµ)(Ω)
α
Ω qdµ
Point transition of Poisson processes: The third operation moves each point independently fol-
lowing a probabilistic transition. Formally, a probabilistic transition is deﬁned to be a function
T : Ω × FΩ → [0, 1] such that for each θ ∈ FΩ , T (θ , ·) is a probability measure on Ω that describes
the distribution of where θ moves, and for each A ∈ FΩ , T (·, A) is integrable. T can be considered
(cid:90)
as a transformation of measures over Ω, as
1 qµ is a measure on Ω given by (qµ)(A) = R
(T µ)(A) :=
Ω
A qdµ, or equivalently (qµ)(dθ) = q(θ)µ(dθ).

Var(D (cid:48) (A)).

T (θ , A)µ(dθ).

(12)

=

,

(10)

(11)

(13)

3

Theorem 6 (Transition Theorem). Let Π ∼ PoissonP(µ) and T be a probabilistic transition, then
T (Π) := {T (θ) : θ ∈ Π} ∼ PoissonP(T µ).
(14)
With a slight abuse of notation, we use T (θ) to denote an independent sample from T (θ , ·).
Theorem 7. Let D = (cid:80)∞
As a consequence, we can derive a Gamma process and thus a Dirichlet process by applying the
probabilistic transition to the location of each term, leading to the following:
i=1 ri δθi ∼ DP(µ) be a Dirichlet process on Ω, then
∞(cid:88)
ri δT (θi ) ∼ DP(T µ).
i=1

T (D) :=

(15)

Theorems 1 and 2 are immediate consequences of the results in [9]. We derive Theorems 3 to The-
orem 7 independently as part of the proposed approach. Detailed explanation of relevant concepts
and the proofs of Theorem 2 to Theorem 7 are provided in the supplement.

3.1 A Markov Chain of Dirichlet Processes

Integrating these three operations, we construct a Markov chain of DPs formulated as
Dt = T (Sq (Dt−1 )) ⊕ Ht ,
with Ht ∼ DP(ν ).
(16)
The model can be explained as follows: given Dt−1 , we choose a subset of terms by subsampling,
then move their locations via a probabilistic transition T , and ﬁnally superimpose a new DP Ht on
the resultant process to form Dt . Hence, creating new particles, removing existing particles, and
varying particle locations are all allowed, respectively, via superposition, subsampling, and point
transition. Note that while they are based on the operations of the underlying Poisson processes, due
to theorems 3, 5, and 7, we operate directly on the DPs, without the need of explicitly instantiating
the associated Poisson processes or Gamma processes. Let µt be the base measure of Dt , then
µt = T (qµt−1 ) + ν.
(17)
Particularly, if the acceptance probability q is a constant, then αt = qαt−1 + αν . Here, αt = µt (Ω)
and αν = ν (Ω) are the concentration parameters. One may hold αt ﬁxed over time by choosing
appropriate values for q and αν . Furthermore, it can be shown that
Cov(Dt+n (A), Dt (A)) ≤ qnVar(Dt (A)).
(18)
The covariance with previous DPs decays exponentially when q < 1. This is often a desirable
property in practice. Moreover, we note that ν and q play different roles in controlling the process.
Generally, ν determines how frequently new terms appear; while q governs the life span of a term
which has a geometric distribution with mean (1 − q)−1 .
We aim to use the Markov chain of DPs as a prior of evolving mixture models. This provides
a mechanism with which new component models can be brought in, existing components can be
removed, and the model parameters can vary smoothly over time.

4 Comparison with Related Work

In his pioneering work [12], MacEachern proposed the “single-p DDP model”. It considers DDP
as a collection of stochastic processes, but does not provide a natural mechanism to change the
collection size over time. M ¨uller et al [14] formulated each DP as a weighted mixture of a common
DP and an independent DP. This formulation was extended by Dunson [6] in modeling latent trait
distributions. Zhu et al [24] presented the Time-sensitive DP, in which the contribution of each DP
decays exponentially. Teh et al [23] proposed the HDP where each child DP takes its parent DP as
the base measure. Ren [18] combines the weighted mixture formulation with HDP to construct the
dynamic HDP. In contrast to the model proposed here, a fundamental difference of these models is
that the marginal distribution at each node is generally not a DP.
Caron et al [4] developed a generalized Polya Urn scheme while Ahmed and Xing [1] developed the
recurrent Chinese Restaurant process (CRP). Both generalize the CRP to allow time-variation, while

4

retaining the property of being marginally DP. The motivation underlying these methods fundamen-
tally differs from ours, leading to distinct differences in the sampling algorithm. In particular, [4]
supports innovation and deletion of particles, but does not support variation of locations. Moreover,
its deletion scheme is based on the distribution in history, but not on whether a component model
ﬁts the new observation. While [1] does support innovation and point transition, there is no explicit
way to delete old particles. It can be considered a special case of the proposed framework in which
subsampling operation is not incorporated. We note that [1] is motivated from an algorithmic rather
than theoretical perspective.
Griﬁn and Steel [7] present the πDDP based on the stick breaking construction [19], reordering
the stick breaking ratios for each time so as to obtain different distributions over the particles. This
work is further extended [8] to a generic stick breaking processes. Chung et al [5] propose a local DP
that generalizes πDDP. Rather than reordering the stick breaking ratios, they regroup them locally
such that dependent DPs can be constructed over a general covariate space. Inference in these mod-
els requires sampling a series of auxiliary variables, considerably increasing computational costs.
Moreover, the local DP relies on a truncated approximation to devise the sampling scheme.
Recently, Rao and Teh [16] proposed the spatially normalized Gamma process. They construct a
universal Gamma process in an auxiliary space and obtain dependent DPs by normalizing it within
overlapped local regions. The theoretical foundation differs in that it does not exploit the relationship
between the Gamma and Poisson process which is at the heart of the proposed model. In [16], the
dependency is established through region overlapping; while in our work, this is accomplished by
explicitly transferring particles from one DP to another. In addition, this work does not support
location variation, as it relies on a universal particle pool that is ﬁxed over time.

5 The Sampling Algorithm

.

(19)

We develop a Gibbs sampling procedure based on the construction of DDPs introduced above. The
key idea is to derive sampling steps by exploiting the fact that our construction maintains the property
of being marginally DP via connections to the underlying Poisson processes. Furthermore, the
derived procedure uniﬁes distinct aspects (innovation, removal, and transition) of our model. Let
D ∼ DP(µ) be a Dirichlet process on Ω. Then given a set of samples Φ ∼ D , in which φi appears
ci times, we have D |Φ ∼ DP(µ + c1 δφ1 + · · · + cn δφn ). Let D (cid:48) be a Dirichlet process depending
(cid:32)
(cid:33)
on D as in Eq.(16), α0 = (qµ)(Ω), and qi = q(θi ). Given Φ ∼ D , we have
m(cid:88)
D (cid:48) |Φ ∼ DP
qk ck T (φk , ·)
αν pν + α0pqµ +
k=1
Sampling from D (cid:48) . Let θ1 ∼ D (cid:48) . Marginalizing over D (cid:48) , we get
m(cid:88)
m(cid:88)
θ1 |Φ ∼ αν
T (φk , ·) with α(cid:48)
pν + α0
qk ck
1 = αν + α0 +
α(cid:48)
α(cid:48)
α(cid:48)
1
1
1
k=1
k=1
Thus we sample θ1 from three types of sources: the innovation distribution pν , the q -subsampled
base distribution pqµ , and the transition distribution T (φk , ·). In doing so, we ﬁrst sample a variable
u1 that indicates which source to sample from. Speciﬁcally, when u1 = −1, u1 = 0, or u1 = l > 0,
we respectively sample θ1 from pν , pqµ , or T (φl , ·). The probabilities of these cases are αν /α(cid:48)
1 ,
1 , and qi ci/α(cid:48)
α0/α(cid:48)
1 respectively. After u1 is obtained, we then draw θ1 from the indicated source.
(cid:32)
(cid:33)
The next issue is how to update the posterior given θ1 and u1 . The answer depends on the value of
u1 . When u1 = −1 or 0, θ1 is a new particle, and we have
m(cid:88)
D (cid:48) |θ1 , {u1 ≤ 0} ∼ DP
αν pν + α0pqµ +
k=1
 .
αν pν + α0pqµ + (cid:88)
If u1 = l > 0, we know that the particle φl is retained in the subsampling process (i.e. the corre-
sponding Bernoulli trial outputs 1), and the transited version T (φl ) is determined to be θ1 . Hence,
k (cid:54)=l
5

D (cid:48) |θ1 , {u1 = l > 0} ∼ DP

qk ck T (θk , ·) + (cl + 1)δθ1

qk ck T (φk , ·) + δθ1

.

qk ck .

(20)

pqµ +

(21)

(22)

With this posterior distribution, we can subsequently draw the second sample and so on. This process
generalizes the Chinese restaurant process in several ways: (1) it allows either inheriting previous
particles or drawing new ones; (2) it uses qk to control the chance that we sample a previous particle;
(3) the transition T allows smooth variation when we inherit a previous particle.
Inference with Mixture Models. We use the Markov chain of DPs as the prior of evolving mixture
models. The generation process is formulated as
θ1 , . . . , θn ∼ D (cid:48) i.i.d.,
xi ∼ L(θi ), i = 1, . . . , n.
(23)
and
Here, L(θi ) is the observation model parameterized by θi . According to the analysis above, we
derive an algorithm to sample θ1 , . . . , θn conditioned on the observations x1 , . . . , xn as follows.
Initialization.
(1) Let ˜m denote the number of particles, which is initialized to be m and will
increase as we draw new particles from pν or pqµ . (2) Let wk denote the prior weights of different
sampling sources which may also change during the sampling. Particularly, we set wk = qk ck for
k > 0, w−1 = αν , and w0 = α0 . (3) Let ψk denote the particles, whose value is decided when a
new particle or the transited version of a previous one is sampled. (4) The label li indicates to which
particle θi corresponds and the counter rk records the number of times that ψk has been sampled
(set to 0 initially). (5) We compute the expected likelihood, as given by F (k , i) := Epk (f (xi |θ)).
Here, f (xi |θ) is the likelihood of xj with respect to the parameter θ , and pk is pν , pqµ or T (φk , ·)
respectively when k = −1, k = 0 and k ≥ 1.
Sequential Sampling. For each i = 1, . . . , n, we ﬁrst draw the indicator ui with probability P(ui =
k) ∝ wk F (k , i). Depending on the value of ui , we sample θi from different sources. For brevity,
let p|x to denote the posterior distribution derived from the prior distribution p conditioned on the
observation x. (1) If ui = −1 or 0, we draw θi from pν |xi or pqµ |xi , respectively, and then add it
as a new particle. Concretely, we increase ˜m by 1, let ψ ˜m = θj , r ˜m = w ˜m = 1, and set li = ˜m.
Moreover, we compute F (m, i) = f (xi |ψ ˜m ) for each i. (2) Suppose ui = k > 0. If rk = 0 then it is
the ﬁrst time we have drawn ui = k . Since ψk has not been determined, we sample θi ∼ T (φk , ·)|xi ,
then set ψk = θi . If rk > 0, the k-th particle has been sampled before. Thus, we can simply set
θi = ψk . In both cases, we set the label li = k , increase the weight wi and the counter ri by 1, and
update F (k , i) to f (xi |ψk ) for each i.
Note that this procedure is inefﬁcient in that it samples each particle φk merely based on the ﬁrst
observation with label k . Therefore, we use this procedure for bootstrapping, and then run a Gibbs
sampling scheme that iterates between parameter update and label update.
(Parameter update): We resample each particle ψk from its source distribution conditioned on all
samples with label k . In particular, for k ∈ [1, m] with rk > 0, we draw ψk ∼ T (φk , ·)|{xi : li =
k}, and for k ∈ [m + 1, ˜m], we draw ψk ∼ p|{xi : li = k}, where p = pqµ or pν , depending which
source ψk was initially sampled from. After updating ψk , we need to update F (k , i) accordingly.
(Label update): The label updating is similar to the bootstrapping procedure described above. The
only difference is that when we update a label from k to k (cid:48) , we need to decrease the weight and
counter for k . If rk decreases to zero, we remove ψk , and reset wk to qk ck when k ≤ m.
At the end of each phase t, we sample ψk ∼ T (φk , ·) for each k with rk = 0. In addition, for each
such particle, we update the acceptance probability as qk ← qk · q(φk ), which is the prior probability
that the particle φk will survive in next phase. MATLAB code is available in the following website:
http://code.google.com/p/ddpinfer/.

6 Experimental Results

Here we present experimental results on both synthetic and real data.
In the synthetic case, we
compare our method with dynamic FMM in modeling mixtures of Gaussians whose number and
centers evolve over time. For real data, we test the approach in modeling the motion of people in
crowded scenes and the trends of research topics reﬂected in index terms.

6.1 Simulations on Synthetic Data

The data for simulations were synthesized as follows. We initialized the model with two Gaussian
components, and added new components following a temporal Poisson process (one per 20 phases

6

(a) Comparison with D-FMM (b) For different acceptance prob.

(c) For different diffusion var.

Figure 1: The simulation results: (a) compares the performance between D-DPMM and D-FMM with differing
numbers of components. The upper graph shows the median of distance between the resulting clusters and the
ground truth at each phase. The lower graph shows the actual numbers of clusters. (b) shows the performance of
D-DPMM with different values of acceptance probability, under different data sizes. (c) shows the performance
of D-DPMM with different values of diffusion variance, under different data sizes.

on average). For each component, the life span has a geometric distribution with mean 40, the mean
evolves independently as a Brownian motion, and the variance is ﬁxed to 1. We performed the
simulation for 80 phases, and at each phase, we drew 1000 samples for each active component. At
each phase, we sample for 5000 iterations, discarding the ﬁrst 2000 for burn-in, and collecting a
sample every 100 iterations for performance evaluation. The particles of the last iteration at each
phase were incorporated into the model as a prior for sampling in the next phase. We obtained
the label for each observation by majority voting based on the collected samples, and evaluated
the performance by measuring the dissimilarity between the resultant clusters and the ground truth
using the variation of information [13] criterion. Under each parameter setting, we repeated the
experiment 20 times, utilizing the median of the dissimilarities for comparison.
We compare our approach (D-DPMM) with dynamic ﬁnite mixtures (D-FMM), which assumes a
ﬁxed number of Gaussians whose centers vary as Brownian motion. From Figure 1(a), we observe
that when the ﬁxed number K of components equals the actual number, they yield comparable per-
formance; while when they are not equal, the errors of D-FMM substantially increase. Particularly,
K less than the actual number results in signiﬁcant underﬁtting (e.g. D-FMM with K = 2 or 3 at
phases 30 − 50 and 66 − 76); when K is greater than the actual number, samples from the same com-
ponent are divided into multiple groups and assigned to different components (e.g. D-FMM with
K = 5 at phases 1 − 10 and 30 − 50). In all cases, D-DPMM consistently outperforms D-FMM due
to its ability to adjust the number of components to adapt to the change of observations.
We also studied how design parameters impact performance. In Figure 1(b), we see that an ac-
ceptance probability q to 0.1 creates new components rather than inheriting from previous phases,
leading to poor performance when the number of samples is limited. If we set q = 0.9, the com-
ponents in previous phases have a higher survival rate, resulting in more reliable estimation of the
component parameters from multiple phases. Figure 1(c) shows the effect of the diffusion variance
that controls the parameter variation. When it is small, the parameter in the next phase is tied tightly
with the previous value; when it is large, the estimation basically relies on new observations. Both
cases lead to performance degradation on small datasets, which indicates that it is important to main-
tain a balance between inheritance and innovation. Our framework provides the ﬂexibility to attain
such a balance. Cross-validation can be used to set these parameters automatically.

6.2 Real Data Applications

Modeling People Flows. It was observed [11] that the majority of people walking in crowded areas
such as a rail station tend to follow motion ﬂows. Typically, there are several ﬂows at a time, and
each ﬂow may last for a period. In this experiment, we apply our approach to extract the ﬂows.
The test was conducted on video acquired in New York Grand Central Station, which comprises
90, 000 frames for one hour (25 fps). A low level tracker was used to obtain the tracks of people,
which were then processed by a rule-based ﬁlter that discards obviously incorrect tracks. We adopt
the ﬂow model described in [11], which uses an afﬁne ﬁeld to capture the motion patterns of each
ﬂow. The observation for this model is in the form of location-velocity pairs. We divided the entire

7

0102030405060708000.050.10.150.2median distance  D−DPMMD−FMM (K = 2)D−FMM (K = 3)D−FMM (K = 5)0102030405060708005tactual # comp.05010015020000.050.10.150.2# samples/componentmedian distance  q=0.1q=0.9q=105010015020000.10.20.30.40.50.60.70.8# samples/componentmedian distance  var=0.0001var=0.1var=100(a) People ﬂows

(b) PAMI topics

Figure 2: The experiment results on real data. (a) left: the timelines of the top 20 ﬂows; right: illustration of
ﬁrst two ﬂows. (Illustrations of larger sizes are in the supplement.) (b) left: the timelines of the top 10 topics;
right: the two leading keywords for these topics. (A list with more keywords is in the supplement.)

sequence into 60 phases (each for one minute), extract location-velocity pairs from all tracks, and
randomly choose 3000 pairs for each phase for model inference. The algorithm infers 37 ﬂows in
total, while at each phase, the numbers of active ﬂows range from 10 to 18. Figure 2(a) shows the
timelines of the top 20 ﬂows (in terms of the numbers of assigned observations). We compare the
performance of our method with D-FMM by measuring the average likelihood on a disjoint dataset.
The value for our method is −3.34, while those for D-FMM are −6.71, −5.09, −3.99, −3.49, and
−3.34, when K are respectively set to 10, 20, 30, 40, and 50. Consequently, with a much smaller
number of components (12 active components on average), our method attains a similar modeling
accuracy as a D-FMM with 50 components.
Modeling Paper Topics. Next we analyze the evolution of paper topics for IEEE Trans. on PAMI.
By parsing the webpage of IEEE Xplore, we collected the index terms for 3014 papers published in
PAMI from Jan, 1990 to May, 2010. We ﬁrst compute the similarity between each pair of papers
in terms of relative fraction of overlapped index terms. We derive a 12-dimensional feature vector
using spectral embedding [2] over the similarity matrix for each paper. We run our algorithm on
these features with each phase corresponding to a year. Each cluster of papers is deemed a topic.
We compute the histogram of index terms and sorted them in decreasing order of frequency for each
topic. Figure 2(b) shows the timelines of top 10 topics, and together with the top two index terms
for each of them. Not surprisingly, we see that topics such as “neural networks” arise early and then
diminish while “image segmentation” and “motion estimation” persist.

7 Conclusion and Future Directions

We developed a principled framework for constructing dependent Dirichlet processes. In contrast to
most DP-based approaches, our construction is motivated by the intrinsic relation between Dirichlet
processes and compound Poisson processes. In particular, we discussed three operations: super-
position, subsampling, and point transition, which produce DPs depending on others. We further
combined these operations to derive a Markov chain of DPs, leading to a prior of mixture models
that allows creation, removal, and location variation of component models under a uniﬁed formula-
tion. We also presented a Gibbs sampling algorithm for inferring the models. The simulations on
synthetic data and the experiments on modeling people ﬂows and paper topics clearly demonstrate
that the proposed method is effective in estimating mixture models that evolve over time.
This framework can be further extended along different directions. The fact that each completely
random point process is a Poisson process suggests that any operation that preserves the complete
randomness can be applied to obtain dependent Poisson processes, and thus dependent DPs. Such
operations are deﬁnitely not restricted to the three ones discussed in this paper. For example, random
merging and random splitting of particles also possess this property, which would lead to an extended
framework that allows merging and splitting of component models. Furthermore, while we focused
on Markov chain in this paper, the framework can be straightforwardly generalized to any acyclic
network of DPs. It is also interesting to study how it can be generalized to the case with undirected
network or even continuous covariate space. We believe that as a starting point, this paper would
stimulate further efforts to exploit the relation between Poisson processes and Dirichlet processes.

8

010203040506002468101214161820timeindexflow 1 flow 2 1990199520002005201001234567891011timeindex1 motion estimation, video sequences 2 pattern recognition, pattern clustering 3 statistical models, optimization problem 4 discriminant analysis, information theory 5 image segmentation, image matching 6 face recognition, biological 7 image representation, feature extraction 8 photometry, computational geometry 9 neural nets, decision theory 10 image registration, image color analysis References
[1] A. Ahmed and E. Xing. Dynamic Non-Parametric Mixture Models and The Recurrent Chinese Restaurant
Process : with Applications to Evolutionary Clustering. In Proc. of SDM’08, 2008.
[2] F. R. Bach and M. I. Jordan. Learning spectral clustering. In Proc. of NIPS’03, 2003.
[3] J. Boyd-Graber and D. M. Blei. Syntactic Topic Models. In Proc. of NIPS’08, 2008.
[4] F. Caron, M. Davy, and A. Doucet. Generalized Polya Urn for Time-varying Dirichlet Process Mixtures.
In Proc. of UAI’07, number 6, 2007.
[5] Y. Chung and D. B. Dunson. The local Dirichlet Process. Annals of the Inst. of Stat. Math., (October
2007), January 2009.
[6] D. B. Dunson. Bayesian Dynamic Modeling of Latent Trait Distributions. Biostatistics, 7(4), October
2006.
[7] J. E. Grifﬁn and M. F. J. Steel. Order-Based Dependent Dirichlet Processes. Journal of the American
Statistical Association, 101(473):179–194, March 2006.
[8] J. E. Grifﬁn and M. F. J. Steel. Time-Dependent Stick-Breaking Processes. Technical report, 2009.
[9] J. F. C. Kingman. Poisson Processes. Oxford University Press, 1993.
[10] J. J. Kivinen, E. B. Sudderth, and M. I. Jordan. Learning Multiscale Representations of Natural Scenes
Using Dirichlet Processes. In Proc. of ICCV’07, 2007.
[11] D. Lin, E. Grimson, and J. Fisher. Learning Visual Flows: A Lie Algebraic Approach.
CVPR’09, 2009.
[12] S. N. MacEachern. Dependent Nonparametric Processes.
Statistical Science, 1999.
[13] M. Meila. Comparing clusterings - An Axiomatic View. In Proc. of ICML’05, 2005.
[14] P. Muller, F. Quintana, and G. Rosner. A Method for Combining Inference across Related Nonparametric
Bayesian Models. J. R. Statist. Soc. B, 66(3):735–749, August 2004.
[15] R. M. Neal. Markov Chain Sampling Methods for Dirichlet Process Mixture Models. Journal of compu-
tational and graphical statistics, 9(2):249–265, 2000.
[16] V. Rao and Y. W. Teh. Spatial Normalized Gamma Processes. In Proc. of NIPS’09, 2009.
[17] C. E. Rasmussen. The Inﬁnite Gaussian Mixture Model. In Proc. of NIPS’00, 2000.
[18] L. Ren, D. B. Dunson, and L. Carin. The Dynamic Hierarchical Dirichlet Process. In Proc. of ICML’08,
New York, New York, USA, 2008. ACM Press.
[19] J. Sethuraman. A Constructive Deﬁnition of Dirichlet Priors. Statistica Sinica, 4(2):639–650, 1994.
[20] K.-a. Sohn and E. Xing. Hidden Markov Dirichlet process: modeling genetic recombination in open
ancestral space. In Proc. of NIPS’07, 2007.
[21] N. Srebro and S. Roweis. Time-Varying Topic Models using Dependent Dirichlet Processes, 2005.
[22] Y. W. Teh. Dirichlet Process, 2007.
[23] Y. W. Teh, M. I. Jordan, M. J. Beal, and D. M. Blei. Hierarchical Dirichlet Processes. Journal of the
American Statistical Association, 101(476):1566–1581, 2006.
[24] X. Zhu and J. Lafferty. Time-Sensitive Dirichlet Process Mixture Models, 2005.

In Proceedings of the Section on Bayesian

In Proc. of

9

