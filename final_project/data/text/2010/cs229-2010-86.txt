CS 229 FINAL PROJECT, AUTUMN 2010

1

Parking Spot Detection from Aerial Images
Mehmet Ozan Kabak (5229284), Ozhan Turgut (5588872)

Abstract—Finding an available parking spot
in big and
crowded city centers has been an important problem for people
who use their own cars for transportation. Hence, parking
spot detection has been an interesting problem that has drawn
considerable attention. Although parking spot detection using
ground based camera imagery has been studied extensively, doing
the same using aerial images is a relatively unexplored problem.
In this work we present a machine learning based approach for
the latter.

I . IN TRODUC T ION
A UTOMATIC parking spot detection using digital imagery
became an important application area for the last decade
as digital visual information become easily accessible. Sur-
veying the literature one sees that researchers have analyzed
the general problem in two particular contexts. In the ﬁrst one
digital imagery obtained from ground based cameras are used
to classify parking spots in a parking lot and/or on a street.
This particular setting has been studied pretty extensively. In
particular, [1] and [2] are good examples of such work. In
the second context, digital aerial imagery is used to classify
parking spots in a parking lot. Again, [3] and [4] can be given
as examples. In this work we generalize the second context and
present a method to classify both parking lot and street parking
spaces using digital aerial imagery. Outline of the developed
method is given below.
Input: Training and test sets of aerial images with labelled
parking spots.
Parameters: Minimum segment area
1: Generate an Luv color space representation of the image.
2: Segmentate the image using the Luv color space repre-
sentation.
3: Extract features.
4: Use a binary SVM with linear kernel
parking spots.
Output: Prediction results on the test set.
Image segmentation was done using the publicly available
mean shift image segmentation implementation EDISON [5].
For the last step we used the popular LIBLINEAR [6] package
for the SVM. These steps will be explained in further detail
in the following sections.

to classify the

I I . DATA ACQU I S I T ION
We used the well known software Google Earth [7] to
obtain the aerial imagery used in this work. The location
was randomly chosen to be Cambridge, UK. Eye altitude and
resolution are 433 ft and 1664 × 1091 respectively. Seven
images have been used to provide data for both training
and test sets. Parking spots on these images were marked

Fig. 1. Example image with marked parking spots

Fig. 2. Example segmented image. Minimum segment area is 200 pixel2 .

manually. Each parking spot is represented by a smaller 60×60
subimage. In ﬁgure 1 we give an example image with the
marked parking spots.

I I I . IMAG E S EGM EN TAT ION
Image segmentation is an important part of the algorithm
since many features are extracted from the data obtained
through image segmentation. Although there are many al-
gorithms for image segmentation (i.e. k-means, statistical
region merging, mean shift etc.), we found mean shift based
algorithms suit best for the purpose of this work. Although
image segmentation algorithms have many tuning parameters,
default values of all parameters except the minimum segment
area work ﬁne in our algorithm. Minimum segment area thus
becomes the only tuning parameter of our algorithm that stems
from image segmentation. In ﬁgure 2 we give an an example
segmented image.

CS 229 FINAL PROJECT, AUTUMN 2010

2

TABLE I
F EATUR E L I S T

Feature #

Explanation

Feature 1 : mini ||xij − sj ||2 where sj is the center of the parking
spot in question and xij is the mean coordinates of i’th
segment touching the parking spot in question.

Feature 2 :

Area of the segment found above.

Feature 3 :

Feature 4 :

|Average grayscale color value of the parking spot −
Average grayscale color value of the center region of the
parking spot|
Standard deviation of the grayscale color value of the center
region of the parking spot.

Feature 5 :

Luv color values of the segment with the maximum area
touching the parking spot in question.

Feature 6 :

Feature 7 :

|| The above color vector - Luv color of the segment found
in feature 1||2
Luv color of the segment including the center of the parking
spot in question.

Feature 8 :

Area of the maximum area segment touching the parking
spot in question.

IV. F EATUR E EX TRACT ION

This is arguably the most crucial part of the algorithm. In
the literature, feature extraction is unfortunately overlooked in
the context of parking spot detection. Raw pixel information
and shallow statistics thereof (e.g. histograms) are almost
exclusively used. This, however, results in poor performance
in many cases. We used a heterogenous set of features incor-
porating a wide range of information; including geometrical,
optical and statistical information. The full list of the features
are given in table I. In this table, “center region” of a parking
spot means the L/2 × L/2 sub image having the same center
with the parking spot image. Here L = 60 is the side length
of a parking spot image.

Feature selection
Our intution led us to think that each feature captures
different information and thus is necessary. To validate the
necessity of each individual feature, an exhaustive search for
the best feature combination was performed. Best 80% hold-
out cross validation accuracy was achieved with the full set of
features.

V. SU P PORT V EC TOR MACH IN E

Although we tried many different kernels and solvers, the
best kernel/solver combination for this problem was found to
be linear kernel and l2 regularized logistic regression (primal).
The cost parameter of the SVM and the error tolerance of the
solver is found to have little effect on the performance of
the algorithm. Particular values that are found to work well
are C = 1 and ￿ = 10−6 . Finally, we used the LIBLINEAR
software as our implementation of choice.

Fig. 3. Typical result with 80% hold out cross validation. Spots correctly
marked as “available” are marked in green whereas spots correctly marked as
“occupied” are marked with red. Spots marked in blue are misclassiﬁed.

Fig. 4. Another typical result with 80% hold out cross validation.

TABLE II
CON FU S ION MATR IX FOR TH E TRA IN ING S ET

Case

Real Available

Real Occupied

Predicted Available
Predicted Occupied

125
10

10
205

V I . R E SU LT S
We used 80% hold out cross validation to measure the per-
formance parameters of the algorithm. Results for a typical run
are given in ﬁgure 4 and performance metrics are summarized
in tables II, III and IV.
Sensitivity analysis on “Minimum Segment Area” parameter
Being the only non machine learning parameter of the algo-
rithm, minimum segment area warrants a sensitivity analysis.
As seen in ﬁgure 5, the algorithm is robust with respect to
changes in the parameter. The plot also shows that the chosen
value of 200 pixel2 is indeed a good choice for a reasonable
balance between precision, recall and speciﬁcity.

V I I . D I SCU S S ION AND FU TUR E WORK
First of all, we actually wanted to plot the precision-recall
curve of our detector as well. However, LIBLINEAR software

CS 229 FINAL PROJECT, AUTUMN 2010

3

critical step. Results show that the algorithm works pretty
well compared to similar work in the literature. While working
on the project, we also realized an important possible future
extension that could lead to a new and practical technology
which could make lives of drivers much easier.

ACKNOW LEDGM ENT
The authors would like to thank all class TA’s as well as
Professor Andrew Ng for their valuable guidance and support.
We would also like to thank SLAC for letting us print a
poster to present this work and Professor Ada Poon’s lab for
providing us with computational resources.

R E F ER ENC E S
[1] Qi Wu,Yi Zhang, Parking Lots Space Detection.
[2] Nicholas True, Vacant Parking Space Detection in Static Images.
[3] Xiaoguang Wang and Allen R. Hanson, Parking Lot Analysis & Visual-
ization from Aerial Images.
[4] Young-Woo Seo, Chris Urmson, Utilizing Prior Information to Enhance
Self-Supervised Aerial Image Analysis for Extracting Parking Lot Struc-
tures, (2009), The 2009 IEEE/RSJ Internation Conference on Intelligent
Robots and Systems.
[5] http://www.wisdom.weizmann.ac.il/ bagon/matlab.html/
[6] http://www.csie.ntu.edu.tw/ cjlin/liblinear/
[7] http://earth.google.com/

Fig. 5. Sensitivity analysis on the parameter “Minimum Segment Area”

TABLE III
CON FU S ION MATR IX FOR TH E T E ST S E T

Case

Real Available

Real Occupied

Predicted Available
Predicted Occupied

30
4

2
52

TABLE IV
P ER FORMANC E M ETR IC S FOR TH E T E S T S E T

Metric

Percentage (%)

Training Accuracy
Test Accuracy
Test Recall
Test Precision
Test Speciﬁcity

94.29
93.18
88.24
93.75
96.30

does not give us the freedom to apply a bias for certain solvers
(probably due to a bug). Unfortunately, the solver that works
well in our problem happens to be one of these “problematic”
solvers.
Tables showing the performance metrics indicate that the
algorithm works pretty well compared to similar work in the
literature. Thus, future work should probably be concentrated
on expanding the functionality of the detector instead of trying
to squeeze a little more performance out of it. One of the main
possible future additions could be using a three class SVM to
automatically classify non-parking regions in an image. This
would eliminate the need for a human operator to mark parking
spots in test data. This would make the algorithm much more
useful in real life applications. One way to achieve this would
be extracting road information from the images and using the
distance to road edges as a new feature.

V I I I . CONCLU S ION
In this work we presented a new algorithm to generalize
automatic parking spot detection to street parking in addition
to parking lots. The main stages of the algorithm are image
segmentation, feature extraction and classiﬁcation using an
SVM with linear kernel; feature extraction being the most

