Storage Efﬁcient NL-Means Burst Denoising for Programmable Cameras

Brendan Duncan
Stanford University
brendand@stanford.edu

Miroslav Kukla
Stanford University
mkukla@stanford.edu

Abstract

An effective way to reduce noise in images involves tak-
ing a burst of snapshots, aligning them, and averaging them
together. However, a burst of photos takes up a lot of mem-
ory, and most users only take single photographs. In this
paper, we examine a novel way to denoise photos using only
select regions from a burst of snapshots. First, we train an
SVM to recognize image regions that stand to beneﬁt the
most from burst denoising. Then, whenever a burst of im-
ages is taken, only those regions selected by the SVM as
‘beneﬁcial’ are stored. On a programmable camera, such
as the Frankencamera, these regions can be selected and
stored automatically. Finally, a non-local means denoising
algorithm is performed ofﬂine, where the select regions are
leveraged to improve the original image. The end result is
noise reduction comparable to burst denoising, without the
associated storage cost.

,

SN R =

1. Introduction
An equation for signal to noise ratio in digital cameras is
given below:
(cid:112)P Qe t + Dt + N 2
P Qe t
r
where P is the number of photons per second, Qe is the
quantum efﬁciency, t is the exposure time, D is the dark
current noise, and Nr is the read noise. Noise that is con-
stant across images is not shown in the equation because it
can be calculated and removed easily.
The above equation shows that increasing the exposure
time will increase the signal to noise ratio. However, it is
not always possible to increase the exposure time. For ex-
ample, increasing the exposure time of a handheld camera
can result in a blurry image due to camera shake. Instead,
the photographer can take a burst of short exposure images,
align them, and average them together. Since averaging to-
gether several exposures is effectively increasing the expo-
sure time, the equation shows that this will increase the sig-
nal to noise ratio.

While this avoids the pitfalls of simply increasing ex-
posure time, aligning and averaging entire images can in-
troduce motion blur and ghosting effects. Moreover, it is
expensive to store an entire burst of photos.
In this paper, we introduce a new technique which stores
a representative subset of image regions from the entire
burst of photos. Because we are using small regions instead
of entire photos, this will reduce ghosting effects caused by
motion across the images. Also, by storing only a subset of
image patches, we address the problem of memory usage.
We use an SVM to determine which patches are the
most important to store, and collect patches from different
regions of the image to encourage variety in the patches.
These patches can then be used to perform non-local means
denoising.

2. Previous work
The bilateral ﬁlter [5] can be used to denoise images
while preserving edges. This approach, however, still has
the disadvantage of performing spatial ﬁltering in a neigh-
borhood, which results in textures being smoothed. This
results in an undesirable loss of texture, and leads to poor
results around edges.
Another simple denoising technique is non-local means
(NL-means) [2], which instead averages together pixels
with similar surrounding regions. The proximity of the pix-
els is not taken into account at all. This is an effective tech-
nique because it reﬂects the fact that repeated patterns are
often found in separate regions of an image, and thus simi-
lar pixels may not be in the same immediate neighborhood.
NL-means is also more effective at improving noisy pix-
els, since an entire neighborhood is used to determine pixel
similarity, rather than just a single noisy pixel value.
Burst denoising and video denoising methods, such as
[4] and [1], are also common. One advantage of these
methods is that temporal ﬁltering is used, which reduces
potential blurring. When the images in the burst are prop-
erly aligned, these techniques effectively increase the ex-
posure time in the aforementioned SNR equation. While
these techniques deal with motion blur and ghosting arti-
facts, they are expensive because of the need to store an

entire burst of photos.
In addition to these traditional approaches to deniosing,
there are some existing techniques which explicitly use ma-
chine learning to denoise photos. One of them, by Yang et
al. [7], trains an -SVM to approximate a bilateral ﬁlter.
Our approach leverages the predictive power of machine
learning to supplement the aforementioned NL-means algo-
rithm, and applies the NL-means algorithm in a novel way.

BF [I ]p =

1
Wp

Gσ(x) =

− x2
e
2σ2 ,

2.0.1 Bilateral ﬁlter in detail
(cid:88)
The bilateral ﬁlter formula is given below:
Gσs((cid:107)p − q(cid:107)) Gσr((cid:107)Ip − Iq(cid:107)) Iq ,
q∈Sp
where G is the Gaussian function
√
1
2π
σ
p and q are x, y pixel coordinates and Ia is the pixel value
at pixel coordinate a. The Gaussian functions Gσs and Gσr
provide the weights for the weighted average of the set Sp
of pixels Iq surrounding pixel Ip . Wp is the sum of the
Gaussian weights calculated for each pixel in Sp ( 1
is the
Wp
normalizing term).
Again, the bilateral ﬁlter is useful in that it can reduce
noise while preserving edges to some degree. However, be-
cause it performs spatial ﬁltering, there will be some blur-
ring of more complex regions - namely, textures and edges.
By training our SVM to determine the difference between
the bilateral ﬁltered and high-quality images, we can isolate
these complex regions and store them for denoising.

For each pixel, we obtain an n2 -dimensional vector,
comprised of the pixels values of the surrounding n × n
region. This n2 -dimensional feature vector is then mapped
to a value z , which is the corresponding pixel in the differ-
ence image. To perform this mapping, we learn a mapping
function using -Support Vector Regression [6]. Given a
set of m training examples, {(x1 , z1 ), ..., (xm , zm )}, where
xi ∈ R(n2 ) is a feature vector and zi ∈ R is the correspond-
ing target variable, training our -SVM requires solving the
0.5wT w + C (cid:80)l
following optimization problem:
p=1 (ζp + ζ ∗
p )
wT φ(xp ) + b − zp ≤  + ζp
zp − wT φ(xp ) − b ≤  + ζ ∗
p ≥ 0, p = 1, ..., l
p
ζp , ζ ∗

min
w,b,ζ ,ζ ∗
s.t.

Predictions within  of the true value are not penal-
ized. C is a constant term penalty for predictions that are
not within  of the true value, and ζp , ζ ∗
p are slack vari-
ables that control the upper error bound. We used the -
Support Vector Regression provided with SVM-LIB [3],
and a simple linear kernel, for speed purposes. We ran 10-
fold cross validation multiple times to select the appropriate
parameters, and the parameter values we decided on were
C = 5,  = .1.

3. Methodology
3.1. Obtain training data
First, we obtained an image pair consisting of a noisy im-
age and a high-quality image of the same scene. To do this,
we used a tripod to take a burst of high-ISO photos, then
averaged these images together. A single high-ISO image
serves as our noisy image, and the averaged image serves
as our high-quality image.
We then perform bilateral ﬁltering on the noisy image,
with σs=2, σr =0.045 (see Figure 1). We subtract the bilat-
eral ﬁltered image from the high-quality image and square
the result, so that we get an absolute measure of how far off
the bilateral ﬁltered estimate is from the high-quality photo.
We call this the ‘difference image’ (see Figure 2). We will
want to train our SVM to predict ’difference images’.

3.2. Train an SVM to ﬁnd ‘important patches’
We deﬁne an important patch as an n × n region that
cannot easily be denoised using a simple bilateral ﬁlter.

1: Noisy input image

Figure 2: Difference image (red = high, blue = low)

3.3. Use the SVM: take a burst of images, and store
the important patches

Take a burst of images. The ﬁrst image will be stored
in its entirety. We call this the this the ‘base image’, and
the other images the ‘support images’. Our trained SVM
will examine each support image and determine some X
important patches for each image. These patches will be
stored, and the support images will be discarded.
To encourage variety in the X patches, we split each sup-
port image into k subregions, such that the top X important
patches are distributed evenly among the subregions. For
our tests, we split up the images into 3 × 3 subregions.
It would be expensive to have the SVM make a predic-
tion on each patch in each region, so we instead choose
patches at random within each of the k subregions. Our
SVM then determines the top X/k most important patches
it encounters in each of these subregions. These regions will
be stored; the rest will be discarded.

3.4. Piece together the ﬁnal denoised image using
NL-means

We now have the base image and X important patches.
We will employ this collection of important patches to de-
noise our base image using a modiﬁed NL-means algorithm.
For each pixel p in the base image, we construct a vector
vp ∈ R(n2 ) . We compare these vectors to all patches in
the set S , which consists of surrounding patches in the base
image and the set of ‘important patches’ determined in the
previous set. The pixel is then set to be the weighed average
of pixels with patches similar to its own. This calculation is
performed ofﬂine.
(cid:88)
The formula for the weighted average is as follows:
x∈S

Gσr((cid:107)vp − x(cid:107)2 ) x

Rp =

1
Wp

4. SVM Results
We trained our SVM on the 288 × 248 image depicted
in Figure 1. Our features were the 3 × 3 patches that sur-
round each of the pixels, and our target values were the
corresponding values in the ‘difference image’, depicted in
Figure 2. Again, our SVM was trained using using C = 5
and  = .1.
Below are the results of SVM predictions, along with the
ground zero truth images - that is, the actually ‘difference
images’. Each of these images is individually scaled to bet-
ter show the relative importance of each image region. The
‘zipper’ image was 288 × 248 pixels, the ‘text’ image was
298 × 228 pixels, and the ‘face’ image was 1278 × 1308
pixels.

Figure 3: Zipper ground truth difference image

Figure 4: Zipper SVM difference image

Figure 5: Text ground truth difference image

Figure 6: Text SVM difference image

Figure 7: Face ground truth difference image

Figure 9: Noisy base image

Figure 8: Face SVM difference image

We thought that these predictions looked quite good, es-
pecially given the small size of the training image. Our
SVM was especially good at recognizing edge regions, al-
most all of which were important. We would have liked
more importance to be placed on textures, but our difference
images do not weigh textured regions very heavily. Also,
we had to use a linear kernel since running higher dimen-
sional kernels took prohibitively long. In light of this, we
were surprised by the effectiveness of the SVM.

5. Denoising results

Here is our denoising result for the zipper image. We
used 13 support images, and our algorithm determined a
subset of the important regions which took up roughly one
picture’s worth of storage. For the NL-means, we used σ =
0.03.

Figure 10: Bilateral ﬁltered image

Figure 11: Our result

Figure 12: High-quality image

The Nature of Statistical Learning Theory.
[6] V. Vapnik.
Springer, New York, 1995.
[7] Q. Yang, S. Wang, and N. Ahuja. Svm for edge-preserving
ﬁltering. In CVPR, 2010.

6. Discussion and future work

We thought that our result looked noticeably sharper than
the bilateral ﬁltered image. It clearly performs less blurring
across edges. However, when compared with a simple NL-
means algorithm on the base image, our results were only
very slightly better in terms of mean squared error. There
were slight or no visual difference. This leads us to con-
clude that, because NL-means is already an effective ofﬂine
denoising algorithm, the additional regions detected by our
SVM are not necessary for ofﬂine denoising. We hypoth-
esize that the extra regions may be helpful for a scene that
contains many unique regions. Since our images had re-
peated patterns, however, we were not able to test this case.
Although our regions were not very helpful for ofﬂine
NL-means denoising, they may be more useful for on-
line denoising.
If we store these patches in a kd-tree or
other data structure that allows quick searching for similar
patches, it may be possible to denoise images on the ﬂy
in the camera, using only important regions, since running
NL-means on a camera would be too expensive.
In summary, we found that our trained SVM was very ef-
fective at recognizing those regions of an image for which
bilateral ﬁltering is inefective. Using these extra regions to
perform NL-means denoising signiﬁcantly reduced noise,
and our approach noticeably outperformed the bilateral
ﬁler. However, our results were very similar to those ob-
tained when performing NL-means on the base image alone,
which already closely approximates an aligned and aver-
aged burst of snapshots. We conclude that providing the
NL-means with additional image regions from a burst of
photos is mostly unnecessary. Nonetheless, the effective-
ness of the SVM at predicting important edge and texture
regions is noteworthy, and while using these regions to as-
sist an NL-means algorithm proved unnecessary, this appli-
cation of SVM’s might be relevant to related problems in
computational photography.

References

[1] E. P. Bennett and L. McMillan. Video enhancement using per-
pixel virtual exposures. ACM SIGGRAPH 2005 Papers, 2005.
[2] A. Buades, B. Coll, and J. Morel. A review of image denoising
algorithms, with a new one. Multiscale Modeling and Simu-
lation: A SIAM Interdisciplinary Journal, 4:490–530, 2005.
[3] C.-C. Chang and C.-J. Lin. LIBSVM: a library for support
vector machines, 2001.
[4] H. J. Seo and P. Milanfar. Video denoising using higher order
In Proceedings of IEEE In-
optimal space-time adaptation.
ternational Conference on Acoustics, Speech and Signal Pro-
cessing, 2008.
[5] C. Tomasi and R. Manduchi. Bilateral ﬁltering for gray and
color images. In Proceedings of the Sixth International Con-
ference on Computer Vision, 1998.

