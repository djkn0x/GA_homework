CS 229 Project: A Machine Learning Framework for Biochemical Reaction Matching

Tomer Altman1,2 , Eric Burkhart1 , Irene M. Kaplow1 , and Ryan Thompson1
1Stanford University, 2SRI International

Biochemical reaction databases capture the sum of human knowledge of biochemical reactions and chemical com-
pounds. As the amount of data available on metabolic reactions and chemical substrates increases, the necessity of
central repositories increases as well. Unfortunately, there is no established algorithm for being able to calculate the
degree of similarity between reactions in diﬀerent databases. A set of features have been deﬁned and were calcu-
lated for all pairs of reactions between the Kegg and MetaCyc reaction databases. Features include reaction name
match, Tanimoto coeﬃcient of the reactions in stoichiometric vector form, enzyme identiﬁer matching, and Enzyme
Commission classiﬁcation diﬀerences. Logistic regression, non-linear SVM, na¨ıve Bayes, and decision tree learning
methods were implemented, and feature selection, cross-validation, k-means clustering and other debugging methods
were applied to determine how to improve the algorithms and data. We conclude that decision trees and logistic
regression provide the most accurate methods, and the Tanimoto coeﬃcient is a key feature for the performance of
both learning methods.

1. Introduction

Biochemical reaction databases capture the sum
of human knowledge of biochemical reactions and
chemical compounds as found across a multitude of
organisms, and not one particular organism. As the
amount of data available on metabolic reactions and
chemical compounds increases, the necessity of cen-
tral repositories increases as well. Several encyclope-
dic repositories of metabolic network data have been
established over the years, including Rhea1 , Kegg2 ,
and MetaCyc3 .
The problem is that, unlike with chemical com-
pounds and polymer sequences, there is no estab-
lished algorithm for computing the degree of similar-
ity between reactions in diﬀerent databases. With-
out a means of comparing the contents of diﬀerent
reaction datasets, there is no easy way to combine or
interlink these new bioinformatic data sources. We
have deﬁned a set of features for comparing two re-
actions from diﬀerent databases and have evaluated
them in the context of logistic regression, SVM, na¨ıve
Bayes, and decision tree classiﬁers.
In prior work4 , a set of features were deﬁned and
calculated for all pairs of reactions between the Kegg
and MetaCyc reaction databases. Features include
reaction name/synonym matching, cosine similarity
of the reactions in stoichiometric vector form, en-
zyme identiﬁer matching, and Enzyme Commission
number match.

2. Features

2.1. Feature Details

Here we brieﬂy describe the set of features:

2.1.1. Reaction Name Matching

Reactions either have a primary name and synonyms,
or names and synonyms can be derived by the asso-
ciated enzymes that are known to catalyze the re-
action. Both an exact case-insensitive string match
and the natural-language processing capabilities of
Pathway Tools5 for understanding enzymatic nomen-
clature have been utilized to ﬁnd matching reaction
names.

2.1.2. Stoichiometry Vector Features

A chemical reaction can be represented as a vector by
having columns represent compounds, and by having
rows represent reactions, using the stoichiometric co-
eﬃcient for the numerical values. If a compound is
not present in a reaction, it has a value of zero. One
measure of similarity of two stoichiometry vectors is
taken as the absolute value of the cosine similarity:
cos(θ) = ~RK egg · ~RM eta
|| ~RK egg ||·|| ~RM eta || .
Biochemical reaction networks exhibit a “small-
world” network property6 . In other words, a small
fraction of the chemicals participate in a large num-
ber of reactions. This means that trivial participants
in reactions, such as NAD, ATP, water, and pro-
tons are weighted equally with more rare or signif-

icant reactants. In analogy to information retrieval
from documents, a inverse-frequency scaling coeﬃ-
cient was applied to the values of the stoichiometry
vectors when calculating the cosine similarity.
In addition to the cosine similarity, we imple-
mented features for the Tanimoto coeﬃcient (no
inverse-frequency scaling applied), the number of
compounds in common between the two reactions,
the number of compounds in the MetaCyc reaction
that had links to Kegg compounds, but not ones in
the given Kegg reaction, the number of compounds
in the MetaCyc reaction that had no known link
to a Kegg compound, the number of compounds in
the Kegg reaction that had links to MetaCyc com-
pounds, but not ones in the given MetaCyc reaction,
and the number of compounds in the Kegg reaction
that had no known link to a MetaCyc compound.

2.1.3. Enzyme Commission Hierarchy

The Enzyme Commission of the International Union
of Biochemistry and Molecular Biology7 curates an
ontology of enzymatic activities. Classes or in-
stances in this ontology are assigned unique “EC
numbers”. This forms the back-bone of many re-
action databases. Unfortunately, there are often du-
plicates of any given EC number, misannotations to
the close, but incorrect, EC number, or partial EC
numbers. We have used the ontology to compare re-
actions on the degree of similarity of their EC num-
bers, when present. The similarity was represented
both as a categorical feature (with values from zero
to four, representing how many levels of the hierar-
chy are shared), and as individual binary features
for each category. Only one of the two forms (bi-
nary versus categorical) was included for any given
learning algorithm.
Reactions that represent a reaction exactly as
the Enzyme Commission depicts them are termed
“oﬃcial EC reactions”. Variants of the oﬃcial EC
reaction will have the same EC number, but will have
slight diﬀerences in the reaction equation. EC num-
ber matches for all four levels between “oﬃcial’ EC
reactions” were provided as a separate feature.

2.1.4. UniProt Identiﬁer Match

UniProt8 is the preeminent protein database. Reac-
tions either link directly to the UniProt entry rep-
resenting the enzyme that catalyzes the reaction, or
the reaction is linked to a protein ob ject that in turn
links to UniProt. Two reactions that can be mapped
to the same identiﬁer in UniProt are then catalyzed
by the same enzyme, and therefore are essentially the
same reaction.

2.1.5. UniRef50 protein cluster match

UniProt provides the UniRef509 dataset, which in-
cludes proteins from UniProt clustered at 50% se-
quence identity or higher. Proteins with this degree
of sequence similarity are typically functionally re-
lated. Two reactions with enzymes within the same
UniRef50 cluster are thus likely to share the same
enzymatic function.

2.1.6. Biochemical pathway match

A network of biochemical reactions form a biochem-
ical pathway. Kegg pathways tend to be ten times
as large as MetaCyc pathways, and thus a one-to-one
mapping between the two databases’ pathways is not
possible. Related biochemical pathways between the
two datasets were determined, and pairs of reactions
were evaluated to determine if they are present in
related pathways.

2.1.7. Data completeness features

One of the characteristics of bioinformatic databases
is that the attributes of entries are inconsistently
populated with data. For example, even though a re-
action may have a ‘pathway’ attribute, some entries
might have zero, one, or more pathways populating
that attribute. When comparing two reactions to de-
termine if they are a match, it is possible that both,
one, the other, or neither of the two reactions have
pathway information speciﬁed.
If we report which
reaction pairs are within the same pathway, without
representing the situation where there was no match
possible due to one or both of the reactions missing
pathway links, then we are introducing a form of bias
into our training dataset.
We used four categories to represent missing

data: both, 0; Kegg only, 1; MetaCyc only, 2;
neither, 3. We have created such status features
for sequence data (covering exact UniProt identiﬁer
matches and UniRef50 features), stoichiometry vec-
tor features, and ‘same pathway’ features. We did
not create a status feature for the name match fea-
ture, as the full set of attributes that the natural
language processing program utilizes is unknown.

2.2. Development of a Gold Standard
Training Set

In continuing work at SRI International, Ph.D. biol-
ogist curators have reviewed matches made by a con-
servative ad hoc rule over the feature set, and have
identiﬁed true and false predictions. These man-
ual assessments formed the gold standard training
dataset.
Kegg version 50 and MetaCyc version 14.5 were
used in this pro ject. MetaCyc version 14.5 contains
7818 small molecule reactions, and Kegg version 50
contains 7827 small-molecule reactions. Data from
MetaCyc was extracted using the Pathway Tools
software, and data from Kegg was extracted using
the BioWarehouse Kegg Loader10 .
This leads to a potential dataset of over 61 mil-
lion pairs of reactions. Extracting features and an-
alyzing a training dataset of millions of examples
proved to be too ineﬃcient for generating results for
this pro ject. Additionally, the ma jority of the full
dataset contains millions of examples where there are
no non-zero features. Thus, we included a sampling
of the full space of reaction pairs, based on data con-
tent and curated match information. The ﬁnal train-
ing dataset contained 9162 examples and twenty-one
features.

3. Utilized Learning Algorithms

3.1. Na¨ıve Bayes with Laplace
Smoothing

We implemented na¨ıve Bayes with Laplace smooth-
ing to classify MetaCyc and Kegg reaction matches.
Since the subset of EC number features are not
mutually independent, we used only the “oﬃcial”
EC number level four feature. Similarly, the sub-
set of stoichiometry vector-related features are also
not mutually independent, so we used only the num-

ber of compounds in the Kegg reaction that did not
have a match in the MetaCyc reaction but did have a
matching compound in the MetaCyc database. Since
95.2% reaction pairs have a value of four or or less for
this feature, we binned the integer number of com-
pounds by setting any value greater than four to four.

3.2. Logistic Regression

We
implemented logistic
regression using the
Newton-Raphson method and applied it to the train-
ing data.

3.3. SVM with Radial Basis Function

We have used libSVM11 to train a non-linear SVM
using a radial basis function kernel with an optimized
γ value of 0.5: e−γ ·|u−v |2 .

3.4. Decision Trees with Gini coeﬃcient

We used a decision tree program12 to create a deci-
sion tree based on our features.

3.5. k-means Clustering

A debugging technique based on unsupervised learn-
ing was utilized to locate sets of training examples
that had poor separation between positive and neg-
ative labels. The training dataset was stripped of
its labels, and several rounds of k-means clustering
of the examples were performed for values of k rang-
ing from 2 to 100. Manual inspection of the resulting
clusters revealed ﬁve predominant clusters with more
than 1000 examples. Clusters with approximately
50% positively-labeled members were examined to
search for potential missing features that could be
added to better separate the clusters.

4. Results

We ran our learning algorithms with 30/70 hold-out
cross-validation to assess performance. The results
for the utilized learning algorithms are summarized
in Table 1.
We ran na¨ıve Bayes with 30% hold-out cross-
validation for ten randomly partitioned sets. In or-
der to determine the most signiﬁcant features, we
ran na¨ıve Bayes several times with diﬀerent features
removed.

Table 1. Learning method performance

Method

Mean Training Set Error Mean Test Set Error

Most Important Feature

2nd Most Important Feature

Na¨ıve Bayes
Decision Tree
Logistic Regression
SVM

9.86%
2.46%
4.88%
4.81%

9.67%
5.88%
4.84%
5.13%

# Mismatched Compounds in Kegg
Tanimoto Coeﬃcient
Tanimoto Coeﬃcient
Tanimoto Coeﬃcient

EC Match 4 Oﬃcial
EC Match 4 Oﬃcial
EC Match level 2
EC Match 4 Oﬃcial

The most useful feature for each of the ten de-
cision trees tested was the Tanimoto coeﬃcient (the
top node of the decision tree always split on a thresh-
old of the Tanimoto coeﬃcient). Cosine similarity
and “oﬃcial” EC number match level four features
were secondary in importance, always splitting nodes
at the second level of the decision tree.

Fig. 2. Learning curve for Logistic Regression.

The decision tree additionally shows evidence of
a variance problem, with the test error being twice
the size of the train error.

5. Conclusion

5.1. Performance of Learning
Algorithms

Na¨ıve Bayes did not perform as well as the other
classiﬁers. This is possibly due to a violation of
the mutual independence assumption. Another pos-
sible reason for the inferior performance could be
due to a suboptimal categorization of the integer and
real-valued features, such as the Tanimoto coeﬃcient
and cosine similarity. Alternative categorization ap-
proaches could be explored to attempt to improve
performance.
The decision tree classiﬁer has the best perfor-
mance (Table 1) in terms of train error. In contrast
to other classiﬁers, its performance on the training
set was consistently better than its performance on
the test set.
Its performance may be explained in
part because the ma jority of our features are binary
or categorical.
The logistic regression classiﬁer has the best per-
formance in terms of test error. It also lacks the vari-
ance problem observed with the decision tree, indi-
cating that it might be a more reliable classiﬁer.

Fig. 1. Receiver-Operator Characteristic curve for decision
tree classiﬁer.

Points on an ROC curve were plotted for each
leaf corresponding to a true match based on a de-
cision tree trained on the entire dataset (Figure 1).
Many of the points being located in the upper-left
corner, along with an AUC value of 0.995 suggests
that our classiﬁer performs well.
The logistic regression cross-validation training
error mean was 4.88% with a standard deviation of
0.24% and the test error mean was 4.84% with a
standard deviation of 0.49%. The optimal θ found
the had the following components with the largest
magnitudes: 5.59, Tanimoto Score; -2.47, EC Match
2; 1.40, EC Match 4; 1.29, Name Match.
All of the classiﬁers had indications of high bias
in our learning problem. The logistic regression clas-
siﬁer was used to construct a learning curve (Fig-
ure 2), which illustrates the bias.

The superior signiﬁcance of the Tanimoto coeﬃ-
cient might indicate that the inverse frequency scal-
ing applied to the cosine similarity was detrimental,
and may be analyzed in future work. The k-means
clustering analysis also indicated problems with co-
sine similarity not diﬀerentiating properly between
positive and negative examples.
learning framework approach
The machine
to the problem of matching biochemical
re-
over
actions
improvement
an
demonstrates
the ad hoc rule previously implemented.
It
can be
summarized as:
Official EC Match
4 OR (cosine similarity > 0.75 AND UniProt
Link) OR (cosine similarity > 0.75 AND Name
Match).
Applied to the training set, the ad hoc rule has
an error rate of 11.7%. Every learning method at-
tempted succeeded in surpassed the performance of
the ad hoc rule, with the best approaches reducing
the error rate by more than half.

5.2. High Bias Problem

The small diﬀerence between training and test error
for logistic regression in Figure 2 indicates the chosen
hypothesis has not over-ﬁt the data. The magnitude
of the errors indicate that the available features are
not suﬃcient and that we can beneﬁt from ﬁnding
additional useful features.
A fundamental question is whether we have a
systematic bias in our training dataset due to the na-
ture of evaluating pairs of entities. For two databases
with N reactions each, there are potentially order
O(N 2 ) reaction pairs, with only O(N ) pairs being
true matches. This means that training on the full
set of pairs, or a random sampling of the pairs might
have one or more orders of magnitude in diﬀerence
between the number of positively and negatively la-
beled examples.
In our sampling of the O(N 2 ) reaction pair
space, we speciﬁcally ﬁltered out reaction pairs that
had no non-zero feature values. This introduces an-
other layer of bias.
As we discovered useful features, we found ways
to break up the feature into a number of more reﬁned
features. This has incrementally improved the per-
formance of our learning algorithms on our dataset.
Future work will involve evaluation of classiﬁcation
results to identify additional hidden features and re-

ﬁnement of well-performing features.
We would like to acknowledge the work of Dr.
Ron Caspi and Ms. Anamika Kothari, who reviewed
predicted matches and curated our gold-standard
training dataset with true matches and mismatches,
and helpful discussions on the work with Dr. Dou-
glas Brutlag, Dr. Peter D. Karp, Joseph M. Dale,
and Dr. Luciana Ferrer.

References

1. Rhea database. http://www.ebi.ac.uk/rhea/
2. Kanehisa, M., Goto, S., Furumichi, M., Tanabe, M.,
and Hirakawa, M.; “KEGG for representation and
analysis of molecular networks involving diseases and
drugs”. Nucleic Acids Res. 38, D355-D360 (2010).
3. Caspi R, Altman T, Dale JM, Dreher K, Fulcher
CA, Gilham F, Kaipa P, Karthikeyan AS, Kothari
A, Krummenacker M, Latendresse M, Mueller LA,
Paley S, Popescu L, Pujar A, Shearer AG, Zhang
P, Karp PD. “The MetaCyc database of metabolic
pathways and enzymes and the BioCyc collection
of pathway/genome databases.” Nucleic Acids Res.
2010. 38(Database issue):D473-9.
4. Altman T..“BioChem 218 Final Paper: Large-Scale
Alignment of Encyclopedic Metabolic Networks.”
2009. http://tinyurl.com/29cells
5. Karp PD, Paley SM, Krummenacker M, Latendresse
M, Dale JM, Lee TJ, Kaipa P, Gilham F, Spauld-
ing A, Popescu L, Altman T, Paulsen I, Keseler IM,
Caspi R. “Pathway Tools version 13.0:
integrated
software for pathway/genome informatics and sys-
tems biology.” Brief Bioinform. 2010 Jan;11(1):40-
79.
6. Barabasi AL, Oltvai ZN. “Network biology: under-
standing the cell’s functional organization.” Nature
Reviews Genetics 5, 101-113. 2004.
7. The Enzyme Commission -
IUBMB. “Enzyme
Nomenclature”, Supplement 5. Eur. J. Biochem.
1999, 264, 610-650.
8. The UniProt Consortium. “The Universal Protein
Resource (UniProt) in 2010.” Nucleic Acids Res.
38:D142-D148 (2010).
9. Suzek B.E., Huang H., McGarvey P., Mazumder
R., Wu C.H. “UniRef: Comprehensive and Non-
Redundant UniProt Reference Clusters.” Bioinfor-
matics 23:1282-1288(2007).
10. Lee TJ, Pouliot Y, Wagner V, Gupta P, Stringer-
Calvert DW, Tenenbaum JD, Karp PD. “BioWare-
house:
a bioinformatics database warehouse
toolkit.” BMC Bioinformatics. 2006 Mar 23;7:170.
11. Chih-Chung Chang and Chih-Jen Lin, “LIBSVM
: a library for support vector machines”, 2001.
http://www.csie.ntu.edu.tw/~cjlin/libsvm
12. Padoan, Andrea. “Decision Trees and Predictive
Models with cross-validation and ROC analysis
plot.” http://tinyurl.com/22padwn. 2010.

