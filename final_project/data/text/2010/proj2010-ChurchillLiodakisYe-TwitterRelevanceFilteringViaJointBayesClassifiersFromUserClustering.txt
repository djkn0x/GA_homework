Twitter Relevance Filtering via Joint Bayes Classiﬁers
from User Clustering

Alexander L. Churchill

Emmanouel G. Liodakis

Simon H. Ye

achur@stanford.edu

liodakis@stanford.edu

sye@stanford.edu

Dec. 12, 2010

1

Introduction

The task of classifying feed item data, such
as email or RSS items, has been a sub ject
of proposed learning algorithms since the
mid 1990s. Unlike spam classiﬁers, rele-
vance classiﬁcation cannot use a universal
training set, but rather must be trained
by each individual user, however most rel-
evance classiﬁers use an approach similar
to spam classiﬁers. Most research in rel-
evance classiﬁcation has employed a clas-
siﬁer over an individualized training set,
usually one of a na¨ıve Bayesian classiﬁer,
support vector machines, or neural-network,
case-based, or knowledge-based approaches
[2] [3]. However, in practice, few of these
algorithms have been implemented, and
those that have enjoy only limited success.
In large part, this is due to common user
expectations with regard to classiﬁcation
accuracy. Users tolerate few errors and
expect immediate results [1].
The past few years have seen a radical
shift in the way users consume data.
In
particular, services like Twitter have dra-
matically increased social feed consump-
tion. This poses the opportunity to build
implicit social graphs to improve the qual-
ity of relevance classiﬁcation over smaller

training sets.
In this paper, we exam-
ine the use of Hierarchical Clustering on
Twitter users to build these implicit social
graphs and to then use the multinomial
Bayesian classiﬁcation approach over the
augmented training sets to do Tweet rele-
vance classiﬁcation. In this way, we lever-
age the power of social feeds to improve
the quality and training speed of individ-
ualized relevance classiﬁers.

2 Dataset Description

The dataset consisted of approximately 1,200
tweets curated from 24 of the most inﬂu-
ential users on twitter based on number of
followers. This consisted mostly of celebri-
ties, comedians, heads of state, and promi-
nent news sources. The distribution was
roughly even so approximately 50 tweets
were gathered per tweeter. The user rat-
ings were performed by 25 users, with each
person rating approximately 600 tweets ran-
domly sampled from half of the users in
the dataset, totaling approximately 15,000
tweets. All ratings were performed in a
binary manner for which the user either
liked or disliked the tweet.

Twitter Relevance Filtering via Joint Bayes Classifiers from User Clustering,

1

3 Algorithm Description

3.1 Data Preprocessing

The textual content for each tweet was to-
kenized through a multistage process. All
urls were ﬁrst parsed from the tweet and
normalized to the base domain name of
the linked-to site. Bit.ly links were also
followed through and the resulting url was
also stripped to the base domain name.
To process the textual content, all punc-
tuation was stripped from both sides of
words while all casing was converted to
lowercase. Tokenizing was performed us-
ing whitespace as a delimiter. Each token
was then stemmed using the Porter stem-
ming algorithm to conﬂate diﬀerently suf-
ﬁxed versions of the words into stemmed
tokens. Finally for each tweet, a meta-
token was added to indicate the author
of the tweet. All of the tweets were then
processed for the most signiﬁcant bigrams
according to chi-squared signiﬁcance, of
which the most signiﬁcant 200 bigrams were
also added to the token dictionary. Tweets
were also processed similarly for training
and testing phases of the classiﬁer.

3.2 Hierarchical Clustering

Hierarchical Clustering progressively clus-
ters data points by taking the two clos-
est training examples and placing them
as sibling nodes in a tree. These cluster
centroids are then reweighted to represent
consituent training examples before mak-
ing the next clustering assignment. Twit-
ter users are represented as sparse vectors
in n-dimensional space, where n is the to-
tal number of tweets. Each element of the
vector takes on a three values [-1, 0 ,1]
where -1 corresponds to ‘disliking’ a tweet,
0 for no answer, and ‘1’ for liking a tweet.

Users are clustered using the Jacard dis-
tance.

3.3 Multinomial Bayesian Clas-
siﬁcation using Clustering
Results

Multinomial Bayesian Classiﬁers are a set
of discriminative algorithms that predict
the probability of classifying a tweet as ei-
ther -1 or 1 based on its features by using
Bayes’ rule and calculating the predicate
probability of each feature qualiﬁed on the
rating of its tweet and the predicate that
the feature exists in the tweet, which can
be easily calculated with one pass through
the data.

3.4 Mathematical Description
of Algorithm
(cid:0)(X (n) , Y (n) ), ..., (X (n) , Y (n) )(cid:1)
Given a training set:
where each X (i) is a vector of tweets and
each Y (i) is a vector of their corresponding
ratings r ∈ {−1, 1}, we let W = {w1 , ..., wp}
be the set of all words in the training set.

Twitter Relevance Filtering via Joint Bayes Classifiers from User Clustering,

2

j = (cid:80)n
j = (cid:80)n
(cid:80)
For each (X (i) , Y (i) ), deﬁne η (i)
j 1{X (i) |Y (i)=1} and deﬁne ˆη (i)
k=1
k=1
The multinomial Bayesian classiﬁer applied to a single (X (i) , Y (i) ) yeilds:

(cid:80)

j 1{X (i) |Y (i)=−1} .

so we derive that

E(cid:96) [P (Y (i)
(cid:96)

|Y (j )
(cid:96)

ˆη (i)
j
η (i)
j + ˆη (i)
j

.

wj ∈X (i)
k

.

(cid:81)

wj ∈X (i)
k

(cid:96) = 1|X (i)
P (Y (i)
(cid:96) ) =

k = 1|wj ∈ X (i)
P (Y (i)
k ) =

η (i)
k = −1|wj ∈ X (i)
j
and P (Y (i)
k ) =
η (i)
j + ˆη (i)
j
(cid:81)
k = 1)P (Y (i) = 1) + (cid:81)
P (wj |Y (i)
k = 1)P (Y (i) = 1)
wj ∈X (i)
k
P (wj |Y (i)
P (wj |Y (i)
k = −1)P (Y (i) = −1)
Additionally, given our data set, we can calculate our sample expected value to estimate
(cid:88)
our expectation
k = −1|Y (i)
k ) − P (Y (j )
k = 1|Y (i)
)] ≈ 1
P (Y (j )
k )
k
k
(cid:32) (cid:80)
(cid:33)
which we can estimate using f (1 − J (Z (i) , Z (j ) )) where J is the Jacard distance; i.e., we
(cid:80)
estimate
k 1{Y (i)
k }
)] ≈ aij := f
|Y (j )
k =Y (j )
E(cid:96) [P (Y (i)
(cid:96)
(cid:96)
k 1{Y (i)
k (cid:54)=0 and Y (j )
k (cid:54)=0}
where f : [0, 1] → [−1, 1] monotonically. However, sample expected value is highly sub-
ject to outliers. To mitigate this issue and to estimate the values for f , we hierarchically
cluster the users using the Jacard distance and let f = 1 for i and j in the same cluster
and let f = 0 elsewhere. Note that aii = 1.
(cid:88)
1(cid:80)
j aij
j
In practice, we use log-liklihood (cid:96)(θ) and Laplace smoothing to classify by selecting the
(cid:88)
larger of:
log(φwj |Y (i)=1 ) and
(cid:88)
wj ∈X (i)
k
k = −1) +
k = −1|X (i)
log P (Y (i)
k ) = log P (Y (i)
wj ∈X (i)
(cid:80)
(cid:80)
k
(cid:80)
(cid:80)
(cid:80)
(cid:80)
j aij η(j )
j aij ˆη(j )
k +1
k +1
h ˆη(j )
h η(j )
j aij
j aij
h +p
h +p

k = 1|X (i)
k ) = log P (Y (i)
log P (Y (i)
k = 1) +

n = 1|X (j )
aij P (y (j )
n ).

where φwk |Y (i)=1 =

and φwk |Y (i)=−1 =

.

Therefore, we estimate

P (Y (i)
n ) =

log(φwj |Y (i)=−1 )

Twitter Relevance Filtering via Joint Bayes Classifiers from User Clustering,

3

4 Experimental Proceedure

Testing was performed using k -folds cross validation running our algorithm on the dataset
for k = 2, 4, 7, 10 to predict the tweets for an invidual user (holding ﬁxed and training
on the values of the other users for clustering purposes). We ran our algorithm using
cluster sizes of 1, 6, 9, 16, and 25. For a control set, we also ran the same experimental
proceedure using the stock Bayesian classiﬁer in the NLTK toolkit.

5 Results

In comparison with the NLTK Na¨ıve
Bayes, our algorithm outperformed the
toolkit in Positive Precision (73.98% to
62.67%),
in Positive Recall (64.76% to
36.59%), and Negative Precision (85.50%
to 76.06%), while the toolkit implemen-
tation very slightly outperformed our al-
gorithm in Negative Recall (90.23% to
90.12%).
In overall accuracy, our al-
gorithm substantially outperformed the
toolkit Na¨ıve Bayes, 82.46% to 73.64%.
Our performace by fold was largely
consistant with a slight bump on 2-fold cross validation (by approximately 84.3% to 78.9%.
Results were also most positive with 6 clusters, achieving an accuracy of 84.25%, compared
with 76.55% for 1 cluster, 80.14% for 9 clusters, 76.28% for 16 clusters, and 68.45% for 25
clusters.

Twitter Relevance Filtering via Joint Bayes Classifiers from User Clustering,

4

author whereas the qualities exhibited for
a liked tweet are much more nuanced, with
only a small fraction of tweets even from
the users favorite tweeters being worthy
of being liked. This makes it diﬃcult to
predict whether a user will like a tweet, re-
sulting in poor performance in predicting
liked tweets. Nevertheless, the overall ac-
curacy of our classiﬁer is fairly high. Our
test error was actually smaller for 2-folds
cross validation, indicating that the mod-
eling each word (with relevant preprocess-
ing) as a feature likely overﬁts the data.
Future research will focus on improving
the choice and quality of features, which
should additionally improve the overall ac-
curacy. The consistancy across folds did
indicate success in earlier prediction of tweets,
which as introduced with the problem, is
an important factor in a successful algo-
rithm. Given the diﬃculty in classifying
tweets because of their short nature and
lack of very much informational content,
the classiﬁer did a good job at determin-
ing whether a user would like or dislike a
tweet.

References

[1] Mock, Kenrick. Dynamic Email Or-
ganization via Relevance Categories.
Intel Architecture Labs. May 6, 1999.
[2] Mock, K., Vemuri, V.
Informa-
tion Filtering via Hybrid Techniques.
Journal of Information Processing
and Management, Permagon Press,
v33, n5, pp 633-644. 1997.
[3] Sahami, M., Dumais, S., Heckerman,
D., Horvitz, E. A Bayesian approach
to ﬁltering junk e-mail. AAAI’98
Workshop on Learning for Text Cat-
egorization, Madison, WI, July 1998.

6 Conclusion

The overall accuracy of the collated clas-
siﬁer was around 75-85% based on the av-
erage results of all 25 users. The simple
Na¨ıve Bayes classiﬁer from the NLTK nat-
ural language processing package achieved
around 70%. The advantage of our classi-
ﬁer over the toolkit implementation lies on
the collated nature of the classiﬁer which
strengthens the classiﬁcations by bringing
in extra information for each users base
Bayesian classiﬁer. In particular, our algo-
rithm signiﬁcantly outperformed the NLTK
toolkit classiﬁer on positive recall, which is
arguably the most signiﬁcant metric with
regards to user experience.
Examining overall trends, our classiﬁer
performed very well on precision and re-
call metrics for disliked tweets, but signiﬁ-
cantly worse on the same metrics for liked
tweets. There are a number of reasons
for this disparity between classifying likes
and dislikes. Ratings were more heavily
weighted towards dislikes as an overall trend
by raters, with simply the pure number
of dislikes heavily outweighing the num-
ber of likes. Therefore, there were much
fewer examples of liked tweets to train the
Bayesian classiﬁer to begin with. Further-
more, users were much more likely to dis-
like entire blocks of tweets simply based on

Twitter Relevance Filtering via Joint Bayes Classifiers from User Clustering,

5

