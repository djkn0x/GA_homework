Handwritten Character Recognition

Saurabh Mathur

December 10, 2010

1

Introduction

3 Character Features

Touchpad based devices like phones and tablets are
now ubiquitous and growing even more in popularity.
Due to their form factors, however, otherwise stan-
dard means of input like keyboards are less eﬀective
in these devices. Infact using scribbling to recognize
handwriting is a viable alternative.
In this pro ject
we investigated a method of recognizing handwritten
characters to allow automatic recognition of charac-
ters. We used a gaussian mixture model for modelling
the feature distributions.

2 Previous Work

Most of the published literature in this ﬁeld is about
a decade old partly because touch input devices were
limited to specialized usage and were not commonly
used, thus limiting the impact of any research in this
area.
[4] and [5] oﬀer a good summary of all the
techniques that have been tried for online and oﬄine
handwriting recognition.

Among the approaches taken towards handwriting
recognition one is to ﬁrst segment the given words
into characters and then recognize each of the char-
acters. The online problem where timestamp is given
for each point is similar to speech recognition and
thus ideas from that ﬁeld have been applied to hand-
writing recognition mainly by modelleing either the
words or the characters using markov models [2]. Our
approach is based on that taken by [3] as a ﬁrst step.

1

Most touch devices can convert a scribble on the
touch screen to a series of x and y coordinates with
timestamps. For the scope of this work we only con-
sidered the oﬄine part of this data, which is a se-
quence of coordinates without the timestamp there-
fore assuming uniform speed. This also makes the
problem less writer speciﬁc by ignoring diﬀerences in
writing speed. However, since the input is otherwise
unconstrained it is desriable for our features to be
independent of the length, orientation and scale of
the input. We call a series of coordinates generated
without lifting the pen a stroke. Each character can
be made from one of more strokes. For cursive hand-
writing every word can also have arbitary number of
strokes.
Since our input is a series of points our features are
deﬁned at these points. At each point we use

1. The horizontal and the vertical components of
the gradient deﬁned between every two consecu-
tive points.

2. The sine and the cosine of the angle made by the
gradient with the horizontal axis. This feature
is scale invariant.

3. The gaussian curvature deﬁned as the angle be-
tween the two segments joined by a point. As
can be seen in ﬁgure 1 it is both scale and rota-
tion invariant.

These features allow us to capture local details. To
recognize a stroke we need this information deﬁned
at several points. Thus we deﬁne a frame as these
features deﬁned on a window of consecutive points

boundaries between each character in a word is al-
ready known. We can also remove the constraint on
segmentation if the handwriting is modelled as a Hid-
den Markov process.

4 Gaussian Mixture Model
In order to ﬁnd P r(Fi | (cid:126)C ) we model our features as
a mixture of gaussians. The features can then be
pro jected on the gaussians which have certain prior
K(cid:88)
for each character learned during training.
j=0

P r(Fi |Gj )P r(Gj | (cid:126)C )

P r(Fi | (cid:126)C ) =

(5)

P r(Gj | (cid:126)C ) =

We train the parameters of our gaussians mixture
model using EM algorithm and by using the labelling
of the training set estimate the P r(Gj | (cid:126)C ) as
(cid:80)F
j=0 N (cid:80)F
(cid:80)
i=0 1{Fi∃ (cid:126)C }P r(Gj |Fi )
i=0 1{Fi∃ (cid:126)C }P r(G
j |Fi )
(cid:48)
where F is all the features in the training set, N is
the number of gaussians and 1{Fi∃ (cid:126)C } is the indicator
function of features coming from character (cid:126)C . During
Fs(cid:89)
K(cid:88)
the testing phase we can then rank the characters by
j
i

(P r(Fi |Gj )P r(Gj | (cid:126)C ))

(6)

(7)

5 Results

We used the UJIpenchars2 dataset from the UCI Ma-
chine Learning repository for our experiments. This
is a dateset of about 11k samples of handwritten char-
acters from 11 writers. Characters include the both
upper and lower case English letters, digits, 16 other
ASCII characters and 14 spanish non ASCII charac-
ters. An example character is shown in ﬁgure 2.
In our experiments we found that this approach
is insuﬃcient to predict a character with very high
accuracy. At best this can be a preprocessing step to
a more detailed prediction based on markov models

Figure 1: Features computed at a point.

of a ﬁxed length. Since using all points on a stroke
may lead to overﬁtting, as we expect the number of
points to vary with scale and writing style, we only
use a subset of frames deﬁned on a stroke. By using
local extremas on a stroke as the center of these win-
dows we expect to cover the most important features
within each stroke. To formalize, each character se-
quence (cid:126)C can contain any number of strokes (cid:126)S . And
each stroke has some features F1 , F2 ... deﬁned on it.
Thus our problem is to ﬁnd the character that has
the maximum a posteriori probability given a set of
features.
P r( (cid:126)C | (cid:126)S )

(1)

(cid:126)C ∗ = arg max
(cid:126)C

This is the same as maximizing
P r( (cid:126)S | (cid:126)C )P r( (cid:126)C )
(cid:126)C ∗ = arg max
(cid:126)C

(2)

P r(C ) is the prior of the character or the character
sequence under consideration. For instance, we can
use the frequency of each word in the english lan-
guage as its prior. For our experiments we assume
each character to be equally likely. Thus we try to
maximize

(cid:126)C ∗ = arg max
(cid:126)C

P r(F1 , F2 , ...| (cid:126)C )

(3)

where we simply replaced S by its constituent fea-
tures. Assuming independence of features and ignor-
(cid:89)
ing the order between them
i

(cid:126)C ∗ = arg max
(cid:126)C

P r(Fi | (cid:126)C )

(4)

We used our approach to distinguish discretely
written individual characters however our approach
can be extended to cursive writing as well if the

2

Gauss CurvatureGradientfor 10 gaussians. Figure 5 plots the accuracy with

Figure 4: Accuracy increases with window size.

increasing features. The ﬁrst iteration only included
gradient pro jections, the second included the sines
and cosines and the last also included the curvature.
The number of gaussians were ﬁxed at 10 and the
window size at 15.

Figure 5: Accuracy increases with more features.

6 Future Work

In our experiments we ignored the sequence or the
temporal
information among the strokes within a
character. Using that information could give a good
boost to our results. Also using language dictionaries
would limit the search space once we move to word
recognitions.

Figure 2: An example character in our dataset.

and further restricted by dictionary search on words
or characters. In order to quantify the accuracy of
this approach we choose as a metric our performance
measure as the average position of the actual label in
the sorted list of labels predicted by our algorithm. In
the plots ahead accuracy is the inverse of the average
of this index for all characters.
We used hold out cross validation for these results.
EM was initialized using k-means to avoid singular-
ities and get faster convergence[1].
In ﬁgure a we
show the improvement in accuracy with increasing
features.
In ﬁgure 3 we show the accuracy with increasing
number of gaussians used to model the feature set.
The accuracy increases upto a certain point but past
that it leads to overﬁtting and the convergence also
suﬀers. Figure 4 plots the accuracy with window size

Figure 3: About 100 gaussians is our optimal point.

3

01020304050607080901000.01980.020.02020.02040.02060.02080.021Accuracy vs Number of GaussiansAccuracyNumber of Gaussians2468101214160.01990.020.02010.02020.02030.02040.02050.0206Window sizeAccuracyAccuracy vs Window size11.21.41.61.822.22.42.62.8348.548.648.748.848.94949.149.249.349.449.5Iterations with increasing featuresAccuracyAccuracy vs featuresReferences

[1] S. Calinon, F. Guenter, and A. Billard. On
learning, representing and generalizing a task in
a humanoid robot.
IEEE Transactions on Sys-
tems, Man and Cybernetics, Part B, 37(2):286–
298, 2007.

[2] Jianying Hu, M.K. Brown, and W. Turin. Hmm
based online handwriting recognition. Pattern
Analysis and Machine Intel ligence, IEEE Trans-
actions on, 18(10):1039 –1045, October 1996.

[3] K.S. Nathan, H.S.M. Beigi, Jayashree Subrahmo-
nia, G.J. Clary, and H. Maruyama. Real-time
on-line unconstrained handwriting recognition us-
ing statistical methods. In Acoustics, Speech, and
Signal Processing, 1995. ICASSP-95., 1995 In-
ternational Conference on, volume 4, pages 2619
–2622 vol.4, May 1995.

[4] R. Plamondon and S.N. Srihari. Online and oﬀ-
line handwriting recognition: a comprehensive
survey. Pattern Analysis and Machine Intel li-
gence, IEEE Transactions on, 22(1):63 –84, jan.
2000.

[5] C. C. Tappert, C. Y. Suen, and T. Wakahara.
The state of the art in online handwriting recog-
nition. IEEE Trans. Pattern Anal. Mach. Intel l.,
12(8):787–808, 1990.

4

