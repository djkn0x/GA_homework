Convex Multiple-Instance Learning by
Estimating Likelihood Ratio

Fuxin Li and Cristian Sminchisescu
Institute for Numerical Simulation, University of Bonn
{fuxin.li,cristian.sminchisescu}@ins.uni-bonn.de

Abstract

We propose an approach to multiple-instance learning that reformulates the prob-
lem as a convex optimization on the likelihood ratio between the positive and the
negative class for each training instance. This is casted as joint estimation of both
a likelihood ratio predictor and the target (likelihood ratio variable) for instances.
Theoretically, we prove a quantitative relationship between the risk estimated un-
der the 0-1 classiﬁcation loss, and under a loss function for
likelihood ratio. It
is shown that likelihood ratio estimation is generally a good surrogate for the 0-1
loss, and separates positive and negative instances well. The likelihood ratio esti-
mates provide a ranking of instances within a bag and are used as input features
to learn a linear classiﬁer on bags of instances.
Instance-l evel classiﬁcation is
achieved from the bag-level predictions and the individual likelihood ratios. Ex-
periments on synthetic and real datasets demonstrate the competitiveness of the
approach.

1 Introduction

Multiple Instance Learning (MIL) has been proposed over 10 years ago as a methodology to learn
models under weak labeling constraints [1]. Unlike traditional binary classiﬁcation problems, the
positive items are represented as bags, which are sets of instances. A feature vector is used to
represent each instance in the bag. There is an OR relationship in a bag: if one of the feature
vectors is classiﬁed as positive, the entire bag is consider ed positive. A simple intuition is: one has
a number of keys and faces a locked door. To enter the door, we only need one matching keys.
MIL is a natural weak labeling formulation for text categorization [2] and computer vision problems
[3]. In document classiﬁcation, one is given ﬁles made of man
y sentences, and often only a few
are useful. In computer vision, an image can be decomposed into different regions, and only some
delineate objects. Therefore, MIL can be used in sophisticated tasks, such as identifying the location
of object parts from bounding box information in images [4]. Although efforts have been made to
provide datasets with increasingly more detailed supervisory information [5], without automation
such a minutiae level of detail becomes prohibitive for large datasets, or more complicated data like
video [6, 7]. In this case, one necessarily needs to resort to multiple-instance learning.

MIL is interesting mainly because of its potential to provide instance-level labels from weak supervi-
sory information. However the state-of-the-art in MIL is often obtained by simply using a weighted
sum of kernel values between all instance pairs within the bags, while ignoring the prediction of
instance labels [8, 9, 10]. It is intriguing why MIL algorithms that exploit instance level information
cannot achieve better performance, as constraints at instance level seems abundant – none of the
negative instances is positive. This should provide additional constraints in de ﬁning the region of
positive instances and should help classiﬁcation in input s pace.

A major challenge is the non-convexity of many instance-level MIL algorithms [2, 11, 12, 13, 14].
Most of these algorithms perform alternating minimization on the classiﬁer and the instance weights.

1

This procedure usually gives only a local optimum since the objective is non-convex. The benchmark
performance of MIL methods is overall quite similar, although techniques differ signiﬁcantly: some
assign binary weights to instances [2], some assign real weights [12, 13], yet others use probabilistic
formulations [14]; some optimize using conventional alternating minimization, others use convex-
concave procedures [11].

Gehler and Chapelle [15] have recently performed an interesting analysis of the MIL costs, where
deterministic annealing (DA) was used to compute better local optima for several formulations. In
the case of a previous mi-SVM formulation [2], annealing methods did not improve the performance
signiﬁcantly. A newly proposed algorithm, ALP-SVM, was als o introduced, which used a preset pa-
rameter de ﬁning the ﬁxed ratio of witnesses – the true positi
ve instances in a positive bag. Excellent
results were obtained with this witness rate parameter set to the correct value. However, in prac-
tice it is unclear whether this can be known beforehand and whether it is stationary across different
bags. In principle, the witness rate should also be estimated, and this learning stage partially ac-
count for the non-convexity of the MIL problem. It remains however unclear whether the observed
performance variations are caused by non-convexity or by other modeling aspects.

Although performance considerations have hindered the application of MIL to practical problems,
the methodology has started to gain momentum recently [4, 16]. The success of the Latent SVM for
person detection [4] shows that a standard MIL procedure (the reformulation of the alternating mini-
mization MI-SVM algorithm in [2]) can achieve good results if properly initialized. However, prop-
er initialization of MIL remains elusive in general, as it often requires engineering experience with
the individual problem structure. Therefore, it is still of broad interest to develop an initialization-
independent formulation for MIL. Recently Li et al. [17] proposed a convex instance-level MIL
algorithm based on multiple kernel learning, where one kernel was used for each possible combi-
nation of instances. This creates an exponential number of constraints and requires a cutting-plane
solver. Although the formulation is convex, its scalability drops signiﬁcantly for bags with many
instances.

In this paper we make an alternative attempt towards a convex formulation: we establish that non-
convex MIL constraints can be recast reliably into convex constraints on the likelihood ratio between
the positive and negative classes for each instance. We transform the multiple-instance learning
problem into a convex joint estimation of the likelihood ratio function and the likelihood ratio values
on training instances. The choice of the jointly convex loss function is rich, remarkably at least from
a family of f-divergences. Theoretically, we prove consistency results for likelihood ratio estimation,
thus showing that f-divergence loss functions upper bound the classiﬁcation 0-1 loss tightly, unless
the likelihood is very large.

A support vector regression scheme is implemented to estimate the likelihood ratio, and it is shown
to separate positive and negative instances well. However, determining the correct threshold for
instance classiﬁcation from the training set remain non-tr ivial. To address this problem, we propose
a post-processing step based on a bag classiﬁer computed as a
linear combination of likelihood
ratios. While this is shown to be suboptimal in synthetic experiments, it still achieves state-of-the-
art results in practical datasets, demonstrating the vast potential of the proposed approach.

2 Convex Reformulation of the Multiple Instance Constraint

Let us consider a learning problem with n training instances in total, n+ positive and n− negative.
In negative bags, every instance is negative, hence we do not separately de ﬁne such bags – instead
we directly work with the instances. Let B = {B1 , B2 , . . . , Bk } be positive bags and X + =
{x+
1 , x+
n+ }, X − = {x−
1 , x−
} be the training input, where each xi belongs to a
2 , . . . , x+
2 , . . . , x−
n−
positive bag Bj and each x−
is a negative instance. The goal of multiple instance learning is, given
i
{X + , X − , B}, to learn a decision rule, sign(f (x)), to predict the label {+1, −1} for the test instance
x.
The MIL problem can be characterized by two properties. 1) negative-exclusion: if none of the
instances in a bag is positive, the bag is not positive. 2) positive-identiﬁability :
if one of the
instances in the bag is positive, the bag is positive. These properties are equivalent to a constraint
maxxi∈Bj f (xi ) ≥ 0 on positive bags. This constraint is not convex since the negative max function
is concave. Reformulation into a sum constraint such as P f (x) ≥ 0 would be convex, when
2

f (x) = wT x is linear [6]. However, this hardly retains positive-identiﬁability , since if there is
only one xi with f (xi ) > 0, this can be superseded by other instances with f (xi ) < 0. Apparently,
the distinction between the sum and the max operations is signiﬁcant and difﬁcult to ignore in this
context.

> |Bj |

Pr(y = 1|xi )
Pr(y = −1|xi )

However, in this paper we show that if MIL conditions are formulated as constraints on the likelihood
ratio, convexity can be achieved. For example, the constraint:
Xxi∈Bj
can ensure both of the MIL properties. Positive-identiﬁability is satisﬁed when Pr(y = 1|xi ) ≥
|Bi |
|Bi |+1 or equivalently, when the positive examples all have very large margin.
When the size of the bag is large, the assumption Pr(y = 1|xi ) > |Bj |
|Bj |+1 can be too strong.
Therefore, we exploit large deviation bounds to reduce the quantity |Bj |, such that Pr(y = 1|xi )
does not have to be very large to satisfy the constraint. Intuitively, if the examples are not very
ambiguous, i.e. Pr(y = 1|xi ) is not close to 1/2, then likelihood ratio sums on negative examples
can become much smaller, hence we can adopt a signiﬁcantly lo wer threshold at some degree of
violation of the negative-exclusion property. To this end, a common assumption is the low label
noise [18, 19]:

(1)

| ≤ ǫ) ≤ cǫβ .

Mβ : ∃c > 0, ∀ǫ, Pr(0 < |Pr(y = 1|xi ) −

1
2
This assumes that the posterior Pr(y = 1|xi ) is usually not very close to 1/2, meaning that most
examples are not very ambiguous, which is usually reasonable. In [18, 19, 20], a number of results
have been obtained implying that classiﬁers learned under t his assumption converge to the Bayes
error much faster than the conventional empirical process rate O(n−1/2 ) of most standard classiﬁers,
and can be as fast as O(n−1 ). These theoretical results show that low label noise assumptions indeed
supports learning with fewer observations.
Assuming Mβ holds, we prove the following result which allows us to relax the hard constraint (1):
Theorem 1 ∀δ > 0, for each xi in a bag Bj , assume yi is drawn i.i.d.
from the distribution
PrBj (yi |xi ) that satisﬁes Mβ . If all instances xi ∈ Bj are negative, then the probability that
|Bj |+s

4β + 1
2(β + 1)2 (2β + 3)

β + 4
2(β + 1)(β + 2)

log 1/δ
3

Pr(y = 1|xi )
Pr(y = −1|xi )

≥

|Bj | log 1/δ+

(2)

Xxi∈Bj
is at most δ .

The proof is given in an accompanying technical report [21]. From Theorem 1, we could weaken
the constraint (1) to obtain constraint (2) and still ensure negative-exclusion with probability 1 − δ .
When β is large, the reduction is signiﬁcant. For example, for β = 2 and δ = 0.05, the right-
4 |Bi | + q 3
hand side of (2) is approximately 1
14 |Bi | + 1, which is an important decrease over |Bi |,
whenever |Bi | ≥ 3. Note that the i.i.d. assumption in Theorem 1 applies to each bag. Different bags
can have different label distributions. This is often a signiﬁcantly weaker assumption than the ones
based on global i.i.d. of labels [8].

3 Likelihood Ratio Estimation

To estimate the likelihood ratio, one possibility would be to use kernel methods as nonparametric
estimators over a RKHS. This approach was taken in [22], where predictions of the ratio provided
a variational estimate of an f -divergence (or Ali-Silvey divergence) between two distributions. The
formulation is powerful, yet not immediately applicable here. In our case, because of the uncertainty
in the positive examples, Pr(y = 1|x) is not observed but has to be estimated. Therefore we need
to optimize jointly as minf ,Pr(y=1|x) D(f , Pr(y = 1|x)) + λ||f ||2 with loss function D(f , g ). This
optimization would not be convex if a framework in [22] were taken.

3

(3)

The requirement to estimate two sets of variables simultaneously (e.g. f and Pr(y = 1|x) here), is
one of the major difﬁculties in turning multiple-instance l earning into a convex problem. Approaches
based on classiﬁcation-style loss functions lead to non-co nvex optimization [2, 13]. However, since
we are outside a classiﬁcation setting, we can optimize over divergence measures Dφ(f , g ) that are
convex w.r.t. both f and g . These measures are common. For example, the f -divergence family that
includes many statistical distances, satisﬁes the followi ng properties [23]:
(xi−yi )2
L1 : D(x, y ) = Pi |xi − yi |; χ2 : D(x, y ) = Pi
;
xi
Kullback-Leibler : D(x, y ) = Pi xi log xi − xi log yi − xi + yi ;
Symmetric Kullback-Leibler : D(x, y ) = Pi (yi − xi ) log yi + (xi − yi ) log xi − xi + yi
In principle, any of the measures given above can be used to estimate the likelihood ratio.
An important issue is the relationship between the likelihood ratio estimation and our ﬁnal goal:
binary classiﬁcation. In [20], the authors give necessary a nd sufﬁcient conditions for Bayes con-
sistent learners by minimizing the mean of a surrogate loss function of the data. In this paper we
extend these results to loss functions for likelihood ratio estimation. Let R(f ) = P (sign(y ) 6=
sign(f (x) − 1)) be the 0-1 risk of a likelihood estimator f , with classiﬁcation rule given by
sign(f (x) ≥ 1). The Bayes risk is then R∗ = inf f R(f ).
For a generic loss function C (α, η), let η = Pr(y = 1|x), we can de ﬁne the C-risk as RC (f ) =
E(C (f , η)) and R∗
C = inf f RC (f ). Our goal is to bound the excess 0-1 risk R(f ) − R∗ by the
excess-C risk RC (f ) − R∗
C , so that minimizing the excess-C risk can be converted into minimizing
the classiﬁcation loss. Let us further de ﬁne the optimal con
ditional risk as H (η) = inf α∈R C (α, η),
and H − (η) = inf α,(α−1)(2η−1)≤0 C (α, η). We say C (α, η) is classiﬁcation-calibrated if for any
η 6= 1/2, H − (η) > H (η). Then, we de ﬁne the ψ -transform of C (α, η) as ψ(θ) = ˜ψ∗∗ (θ), where
˜ψ(θ) = H −( 1+θ
2 ) − H ( 1+θ
2 ), θ ∈ [−1, 1], and g ∗∗ is the Fenchel-Legendre biconjugate of g , which
is essentially the largest convex lower bound of g [20].
The difference between likelihood ratio estimation and the classiﬁcation setting is in the asymmetric
scaling of the loss function for positive and negative examples. Let ψ− = ψ(−x), R− (f ) =
− = inf f R− (f ), R+ (f ) = Pr(y = 1, f (x) < 1) and R∗
Pr(y = −1, f (x) > 1), R∗
+ = inf f R+ (f )
be the risk and Bayes risks on negative and positive examples, respectively. It is easy to prove that
+ . We derived the following theorem:
R(f ) − R∗ = R− (f ) − R∗
− + R+ (f ) − R∗
Theorem 2 a) For any nonnegative loss function C (α, η), any measurable f : X → R, and any
+ ) ≤ RC (f ) − R∗
− ) + ψ(R+ (f ) − R∗
probability distribution on X × {±1}, ψ− (R− (f ) − R∗
C . b) The
following conditions are equivalent: (1) C is classiﬁcation-calibrated; (2) For any sequence (θi ) in
[0, 1], ψ(θi ) → 0 if and only if θi → 0; (3) For every sequence of measurable functions fi : X → R
and every probability distribution on X × {±1}, RC (fi ) → R∗
C implies R(fi ) → R∗ .

The proof is given in an accompanying technical report [21]. This suggests that if ψ is well-behaved,
minimizing RC (f ) still gives a reasonable surrogate for the classiﬁcation ri sk. Compared against
Theorem 3 in [20] which has the form ψ(R(f ) − R∗ ) ≤ RC (f ) − R∗
C , the difference here stems
from the different loss transforms used for the positive and the negative examples.
We consider an f -divergence of the likelihood as the loss function, i.e., C (α, η) = D(α, η
1−η ),
where η
1−η is the likelihood ratio when the Pr(y = 1|x) = η . From convexity arguments, it can be
1−η ), therefore ˜ψ(θ) = D(1, 1+θ
easily seen that H (η) = C ( η
1−η , η) = 0 and H − (η) = D(1, η
1−θ ).
The ψ for all the loss functions listed in (4) can be computed accordingly. In ﬁg. 3 (a) we show the
ψ(θ) of L1 and the KL-divergence from (4) and compare it against the hinge loss (where ˜ψ(θ) = |θ|
[20]) used for SVM classiﬁcation. It could be seen that our ap proximation of the classiﬁcation loss is
accurate when Pr(yi = 1|xi ) is small. However, likelihood estimation would severely penalize the
misclassiﬁed positive examples with large Pr(yi = 1|xi ). This suggests that for the joint estimation
of f and Pr(yi = 1|xi ), the optimizer would tend to make Pr(yi = 1|xi ) smaller, in order to avoid
high penalties, as shown in ﬁg. 1(b).
In ﬁg. 1(a) we plot ψ functions for different losses. We prefer an L1 measure as it is closer to the
classiﬁcation hinge loss, at least for the negative example s. In the end we solve the nonparametric
function estimation in RKHS using an epsilon-insensitive L1 loss, which can be reformulated as

4

100

)
θ
(
ψ

10−5

 
−1

−0.5

0
θ
(a)

 

L1 divergence
KL−divergence
Hinge Loss

1.2

1

0.8

0.6

0.4

0.2

0

 
Positive
Negative

1.2

1

0.8

0.6

0.4

0.2

0

d
o
o
h
i
l
e
k
i
L
 
d
e
t
a
m
i
t
s
E

 

Positive
Negative
Undecided

0.5

1

−0.2

 
0

50

100

150

200

−0.2

 
0

50

(b)

150

100
Example
(c)

Figure 1: Loss functions and their in ﬂuence on the estimatio n bias. (a) The function ψ appearing
in the losses used for likelihood estimation (L1 , KL-divergence) is similar to the hinge loss when
θ > 0; however it goes to in ﬁnity as θ approaches 1. This deviation essentially means the surrogate
(b)
loss is going to be extremely large if an example with very large Pr(yi = 1|xi ) is misclassiﬁed.
Example estimated likelihood for a synthetic example. The estimated likelihood is biased towards
smaller values. However, with a fully labeled training set, the threshold can still be obtained. (c)
If we only know the label of the negative examples (blue) and the maximal positive example (red),
determining the optimal threshold becomes non-trivial.

(4)

support vector regression on the conditional likelihood, with the additional MIL constraints in (2):
j ) − η+
max(|f (x+
max(|f (x−
j )| − ǫ, 0) + λ||f ||2
f ,η+ Px+
j | − ǫ, 0) + Px−
min
j
j
j ≥ Di , η+
η+
s.t.
Px+
j ≥ 0
j ∈Bi
where ||f ||2 is the RKHS norm; Di is a constant for each bag and can be determined from Theorem
is an estimate of P r(y=1|x+
i )
1, with appropriately chosen values for constants β and δ ; η+
for the
i
P r(y=−1|x+
i )
training set. In this paper we use β = 2 and δ = 0.05, which gives the estimate of the bound for
4 |Bi | + q 3
each bag as Di = 1
14 |Bi | + 1, when Bi ≥ 3 and Di = |Bi | when |Bi | < 3.
It can be proved that optimization problem (4) is jointly convex in both arguments. A standard repre-
senter theorem [24] would convert it to an optimization on vectors, which we omit here. The problem
can be solved by different methods. The one easiest to implement is the alternating minimization
y+
between solving for the SVM and projecting on the constraint sets given by Px+
j ≥ Di and
j ∈Bi
y+
j ≥ 0. As this can turn out to be slow for large datasets, approaches such as the dual SMO or
primal subgradient projection algorithms (in the case of linear SVM) can be used. In this paper we
implement the alternating minimization approach, which is provably convergent since the optimiza-
tion problem (4) is convex. In the accompanying technical report [21] we derive an SMO algorithm
based on the dual of (4) and characterize the basic properties of the optimization problem.

4 Bag and Instance Classi ﬁcation

If the likelihood ratio is obtained using an unbiased estimator, a decision rule based on sign(f (x) ≥
1) should give the optimal classiﬁer. However as previously ar gued, the joint estimation on f and
η+ introduces a bias which is not always easy to identify. In positive bags, it is unclear whether an
instance should be labeled positive or negative, as long as it does not contribute signiﬁcantly to the
classiﬁcation error of its bag ( ﬁg. 3(b),(c)). In the synthe
tic experiments, we noticed that knowledge
of the correct threshold would make the algorithm outperform competitors by a large margin ( ﬁg.
2). This means that based on the learned likelihood ratio, the positive examples are usually well
separated from the negative ones. Developing a theory that would advance these aspects remains
a promising avenue for future work. The main difﬁculty stems
from the compound source of bias
which arises from both the estimation of η+ and the loss minimization over η+ and f .
Here we propose a partial solution. Instead of directly estimating the threshold, we learn a linear
combination of instance likelihood ratios to classify the bag. First, we sort the instance likelihood
ratios for each bag into a vector of length maxi |Bi |. We append 0 to bags that do not have enough

5

s
n
u
r
 
0
5
 
r
e
v
o
 
d
e
g
a
r
e
v
a
 
−
 
r
o
r
r
E

0.45

0.4

0.35

0.3

0.25

0.2

0.15

0.1

0.05

0
 

(a)

Bag Classification Error

 

AL−SVM : T=10C
mi−SVM
AW−SVM
BEST−THRESHOLD
SVR−SVM

(b)
Pattern Classification Error

AL−SVM : T=10C
mi−SVM
AW−SVM
BEST−THRESHOLD
SVR−SVM

0.35

0.3

0.25

0.2

0.15

0.1

0.05

s
n
u
r
 
0
5
 
r
e
v
o
 
d
e
g
a
r
e
v
a
 
−
 
r
o
r
r
E

0.8
0.6
0.4
0.2
percent of positive labeled points in bags
(d)

1

0
 

0.2

0.4
0.8
0.6
percent of positives in bags
(e)

 

1

(c)

Witness Rate
Estimate by SVR−SVM

1

0.8

0.6

0.4

0.2

e
t
a
r
 
s
s
e
n
t
i
w
 
d
e
t
a
m
i
t
s
E

 

0.2

0.4
0.8
0.6
Percent of positives in bags
(f)

 

1

Figure 2: Synthetic dataset (best viewed in color). (a) The true decision boundary. (b) Training
points at 40% witness rate. (c) The learned regression function. (d) Bag misclassiﬁcation rate of
different algorithms. (e) Instance misclassiﬁcation rate of different algorithms.
(f) Estimated witness
rate and true witness rate.

instances. Under this representation, bag classiﬁcation t urns into a standard binary decision problem
where a vector and a binary label is given for each bag, and a linear SVM is learned to solve the
problem. If we were to classify only the likelihood ratio on the ﬁrst instance, this procedure would
reduce to simple thresholding. We instead leverage information in the entire bag, aiming to constrain
the classiﬁer to learn the correct threshold. In this linear SVM setting, regularization never helps in
practice and we always ﬁx C to very large values. Effectively no parameter tuning is needed.1
To classify instances, a threshold is still necessary. In the current system, we follow a simple ap-
proach and take the mean between two instances: the one with the highest likelihood among training
bags that are predicted negative by the bag classiﬁer, and th e lowest scored one among instances in
positive bags with a score higher than the previous one. This approach is derived from the basic
MIL assumption that all instances in a negative bag are negative.

Based on instance classiﬁcation we could also estimate the w itness rate of the dataset. This is
computed as the ratio of positively classiﬁed instances and the total number of instances in the
positive bags of the training set. Since our algorithm automatically adjusts to different witness rates,
this estimate offers quantitative insight as to whether MIL should be used. For instance, if the
witness rate is 100%, it may be more effective to use a conventional learning approach.

5 Experiments

5.1 Synthetic Data

We start with an experiment on the synthetic dataset of [15], where the controlled setting helps
understanding the behavior of the proposed algorithm. This is a 2-D dataset with the actual decision
boundary shown in ﬁg. 2 (a). The positive bags have a fraction of points sampled uniformly from
the white region and the rest sampled uniformly from the black region. An example of the sample
at 40% witness rate is shown in ﬁg. 2 (b). In this ﬁgure, the plotted i
nstance labels are the ones
of their bags – indeed, one could notice many positive (blue)
instances in the negative (red) region.

1We have also experimented with a uniform threshold based on probabilistic estimates, as well as with
predicting an instance-level threshold. While the former tends to under ﬁt, the latter over ﬁtts. Our bag-level
classi ﬁer targets an intermediate level of granularity and turns out to be the most robust in our experiments.

6

Table 1: Performance of various MIL algorithms on weak labeling benchmarks. The best result on
each dataset is shown in bold. The second group of algorithms either not provide instance labels
(MI-Kernel and miGraph) or require a parameter that can be difﬁcult to tune (ALP-SVM). SVR-
SVM appears to give consistent results among algorithms that provide instance labels. The row
denoted “Est. WR” gives the estimated witness rates of our me
thod.

Algorithm
CH-FD
EMDD
mi-SVM
MI-SVM
MICA
AW-SVM
Ins-KI-SVM
MI-Kernel
miGraph
ALP-SVM
SVR-SVM
Est. WR

Musk-1
88.8
84.9
87.4
77.9
84.4
85.7
84.0
88.0 ± 3.1
88.9 ± 3.3
86.3
87.9 ± 1.7
100 %

Musk-2
85.7
84.8
83.6
84.3
90.5
83.8
84.4
89.3 ± 1.5
90.3 ± 2.6
86.2
85.4 ± 1.8
89.5 %

Elephant
82.4
78.3
82.2
81.4
82.5
82.0
83.5
84.3 ± 1.6
86.8 ± 0.7
83.5
85.3 ± 2.8
37.8 %

Tiger
82.2
72.1
78.4
84.0
82.0
83.0
82.9
84.2 ± 1.9
86.0 ± 2.8
86.0
79.8 ± 3.4
42.7 %

Fox
60.4
56.1
58.2
57.8
62.0
63.5
63.4
60.3 ± 1.0
61.6 ± 1.6
66.0
63.0 ± 3.5
100 %

In order to test the effect of witness rates, 10 different types of datasets are created by varying the
rates over the range 0.1, 0.2, . . . , 1. In this experiment we ﬁx the hyperparameters C = 5 and use a
Gaussian kernel with σ = 1.We show a trained likelihood ratio function in ﬁg. 2 (c), est imated on
the dataset shown in ﬁg. 2 (b). Under the likelihood ratio, th e positive examples are well separated
from negatives. This illustrates how our proposed approach converts multiple-instance learning into
the problem of deciding a one-dimensional threshold.

Complete results on datasets with different witness rates are shown in ﬁg. 2 (d) and (e). We give
both bag classiﬁcation and instance classiﬁcation results
. Our approach is referred to as SVR-
SVM. BEST THRESHOLD refers to a method where the best threshold was chosen based on the
full knowledge of training/test instance labels, i.e., the optimal performance our likelihood ratio
estimator can achieve. Comparison is done with two other approaches, the mi-SVM in [2] and
the AW-SVM from [15]. SVR-SVM generally works well when the witness rate is not very low.
From instance classiﬁcation, one can see that the original m i-SVM is only competitive when the
witness rate is near 1 – this situation is close to a supervise d SVM. With a deterministic annealing
approach in [15], AW-SVM and mi-SVM perform quite the opposite – competitive when the witness
rate is small but degrade when this is large. Presumably this is because deterministic annealing is
initialized with the apriori assumption that datasets are multiple-instance i.e. has a small witness rate
[15]. When the witness rate is large, annealing does not improve performance. On the contrary, the
proposed SVR-SVM does not appear to be affected by the witness rate. With the same parameters
used across all the experiments, the method self-adjusts to different witness rates. One could see the
effect especially in ﬁg. 2 (e): regardless of the witness rat e, the instance error rate remains roughly
the same. However, this is still inferior to our model based on the best threshold, which indicates
that important room for improvement exists.

5.2 MIL Datasets

The algorithm is evaluated on a number of popular MIL benchmarks. We use the common ex-
perimental setting, based on 10-fold cross-validation for parameter selection and we report the test
results averaged over 10 trials. The results are shown in Table 1, together with other competitive
methods in from the literature [12, 15, 10] (for some of these methods standard deviation estimates
are not available).

In our tests, the proposed SVR-SVM gives consistently good results among algorithms that provide
instance-level labels. The only atypical case is Tiger, where the algorithm underperforms other
methods. Overall, the performance of SVR-SVM is slightly worse than miGraph and ALP-SVM.
But we note that results in ALP-SVM are obtained by tuning the witness rate to the optimal value,
which may be difﬁcult in practical settings. The slightly lo wer performance compared to miGraph
suggests that we may be inferior in the bag classiﬁcation ste p, which we already know is suboptimal.

7

Table 2: Results from 20 Newsgroups. The best result on each dataset is shown in bold, pairwise
t-tests are performed to determine if the differences are statistically signiﬁcantly. miGraph is domi-
nating in 10 datasets, whereas SVR-SVM is dominating in 14.

Dataset
alt.atheism
comp.graphics
comp.windows.misc
comp.ibm.pc.hardware
comp.sys.mac.hardware
comp.window.x
misc.forsale
rec.autos
rec.motorcycles
rec.sport.baseball
rec.sport.hockey
sci.crypt
sci.electronics
sci.med
sci.space
soc.religion.christian
talk.politics.guns
talk.politics.mideast
talk.politics.misc
talk.religion.misc

MI-Kernel miGraph [10] miGraph (web)
82.0 ± 0.8
65.5 ± 4.0
60.2 ± 3.9
84.3 ± 0.4
77.8 ± 1.6
47.0 ± 3.3
70.1 ± 0.3
63.1 ± 1.5
51.0 ± 5.2
79.4 ± 0.8
46.9 ± 3.6
59.5 ± 2.7
81.0 ± 0
61.7 ± 4.8
44.5 ± 3.2
79.4 ± 0.5
69.8 ± 2.1
50.8 ± 4.3
71.0 ± 0
55.2 ± 2.7
51.8 ± 2.5
83.2 ± 0.6
52.9 ± 3.3
72.0 ± 3.7
70.9 ± 2.7
64.0 ± 2.8
50.6 ± 3.5
75.0 ± 0.6
64.7 ± 3.1
51.7 ± 2.8
92.0 ± 0
85.0 ± 2.5
51.3 ± 3.4
70.1 ± 0.8
69.6 ± 2.1
56.3 ± 3.6
94.0 ± 0
50.6 ± 2.0
87.1 ± 1.7
72.1 ± 1.3
62.1 ± 3.9
50.6 ± 1.9
79.4 ± 0.8
75.7 ± 3.4
54.7 ± 2.5
75.4 ± 1.2
59.0 ± 4.7
49.2 ± 3.4
72.3 ± 1.0
58.5 ± 6.0
47.7 ± 3.8
55.9 ± 2.8
73.6 ± 2.6
75.5 ± 1.0
72.9 ± 2.4
70.4 ± 3.6
51.5 ± 3.7
55.4 ± 4.3
63.3 ± 3.5
67.5 ± 1.0

SVR-SVM Est. WR
83.5 ± 1.7
1.83 %
85.2 ± 1.5
5.19 %
2.23 %
66.9 ± 2.6
70.3 ± 2.8
2.42 %
4.58 %
78.0 ± 1.7
83.7 ± 2.0
5.36 %
72.3 ± 1.2
4.29 %
2.75 %
78.1 ± 1.9
75.6 ± 0.9
2.86 %
76.7 ± 1.4
4.31 %
6.52 %
89.3 ± 1.6
69.7 ± 2.5
3.22 %
91.5 ± 1.0
4.29 %
74.9 ± 1.9
5.23 %
83.2 ± 2.0
3.64 %
83.2 ± 2.7
3.30 %
73.7 ± 2.6
3.23 %
80.5 ± 3.2
3.88 %
72.6 ± 1.4
2.82 %
71.9 ± 1.9
2.87 %

5.3 Text Categorization

The text datasets are taken from [10]. These data have the bene ﬁt of being designated to have a small
witness rate. Thus they serve as a better MIL benchmark compared to the previous ones. These are
derived from the 20 Newsgroups corpus, with 50 positive and 50 negative bags for each of the 20
news categories. Each positive bag has around 3% witness rate. We run 10-fold cross validation 10
times on each dataset and compute the average accuracy and standard deviations, C is ﬁxed to 100,
ǫ to 0.2. Authors of [10] reported recent results for this dataset on their website, which are vastly
superior than the ones reported in the paper. Therefore, in Table 2 we included both results in the
comparison, identiﬁed as miGraph (paper) and miGraph (webs ite), respectively.

Our SVR-SVM performs signiﬁcantly better than MI-Kernel an d miGraph (paper). It is comparable
with miGraph (web), and offers a marginal improvement. It is interesting that even though we use a
suboptimal second step, SVR-SVM fares well with the state-of-the-art. This shows the potential of
methods based on likelihood ratio estimators for multiple instance learning.
6 Conclusion

We have proposed an approach to multiple-instance learning based on estimating the likelihood ratio
between the positive and the negative classes on instances. The MIL constraint is reformulated into a
convex constraint on the likelihood ratio where a joint estimation of both the function and the target
ratios on the training set is performed. Theoretically we justify that learning the likelihood ratio is
Bayes-consistent and has desirable excess loss transform properties. Although we are not able to ﬁnd
the optimal classiﬁcation threshold on the estimated ratio function, our proposed bag classiﬁer based
on such ratios obtains state-of-the-art results in a number of difﬁcult datasets. In future work, we
plan to explore transductive learning techniques in order to leverage the information in the learned
ratio function and identify better threshold estimation procedures.

Acknowledgements

This work is supported, in part, by the European Commission, under a Marie Curie Excellence Grant
MCEXT-025481.

8

References

In: ICML.

[1] Dietterich, T.G., Lathrop, R.H., Lozano-Perez, T.: Solving the multiple-instance problem with
axis-parallel rectangles. Artiﬁcial Intelligence 89 (1997) 31 –71
[2] Andrews, S., Tsochantaridis, I., Hofmann, T.: Support vector machines for multiple-instance
learning. In: NIPS. (2003) 561 –568
[3] Maron, O., Lozano-P ´erez, T.: A framework for multiple- instance learning. In: NIPS. (1998)
570 –576
[4] Felzenszwalb, P.F., McAllester, D.A., Ramanan, D.: A discriminatively trained, multiscale,
deformable part model. In: CVPR. (2008)
[5] Russell, B.C., Torralba, A., Murphy, K.P., Freeman, W.T.: Labelme: A database and web-
based tool for image annotation. IJCV 77(1-3) (2008) 157 –173
[6] Cour, T., Sapp, B., Nagle, A., Taskar, B.: Talking pictures: Temporal grouping and dialog-
supervised person recognition. In: CVPR. (2010)
[7] Zeisl, B., Leistner, C., Saffari, A., Bischof, H.: On-line semi-supervised multiple-instance
boosting. In: CVPR. (2010)
[8] G ¨artner, T., Flach, P.A., Kowalczyk, A., Smola, A.J.: Multi-instance kernels.
(2002)
[9] Tao, Q., Scott, S., Vinodchandran, N.V., Osugi, T.T.: Svm-based generalized multiple-instance
learning via approximate box counting. In: ICML. (2004)
[10] Zhou, Z.H., Sun, Y.Y., Li, Y.F.: Multi-instance learning by treating instances as non-i.i.d.
samples. In: ICML. (2009)
[11] Cheung, P.M., Kwok, J.T.: A regularization framework for multiple-instance learning. In:
ICML. (2006) 193 –200
[12] Fung, G., Dandar, M., Krishnapuram, B., Rao, R.B.: Multiple instance learning for computer
aided diagnosis. In: NIPS. (2007)
[13] Mangasarian, O., Wild, E.: Multiple instance classiﬁc ation via successive linear programming.
Journal of Optimization Theory and Applications 137 (2008) 555 –568
[14] Zhang, Q., Goldman, S.A., Yu, W., Fritts, J.E.: Content-based image retrieval using multiple-
instance learning. In: ICML. (2002) 682 –689
[15] Gehler, P., Chapelle, O.: Deterministic annealing for multiple-instance learning. In: AISTATS.
(2007)
[16] Doll ´ar, P., Babenko, B., Belongie, S., Perona, P., Tu, Z.: Multiple component learning for
object detection. In: ECCV. (2008)
[17] Li, Y.F., Kwok, J.T., Tsang, I.W., Zhou, Z.H.: A convex method for locating regions of interest
with multi-instance learning. In: ECML. (2009)
[18] Mammen, E., Tsybakov, A.B.: Smooth discrimination analysis. Annals of Statistics 27 (1999)
1808 –1829
[19] Tsybakov, A.B.: Optimal aggregation of classiﬁers in s tatistical learning. Annals of Statistics
32 (2004) 135 –166
[20] Bartlett, P., Jordan, M.I., McAulliffe, J.: Convexity, classiﬁcation and risk bounds. Journal of
American Statistical Association 101 (2006) 138 –156
[21] Li, F., Sminchisescu, C.: Convex multiple instance learning by estimating likelihood ratio.
Technical report, Institute for Numerical Simulation, University of Bonn (November 2010)
[22] Nguyen, X., Wainwright, M., Jordan, M.I.: Estimating divergence functionals and the likeli-
hood ratio by penalized convex risk minimization. In: NIPS. (2007)
[23] Liese, F., Vajda, I.: Convex Statistical Distances. Teubner VG (1987)
[24] Hofmann, T., Sch ¨olkopf, B., Smola, A.J.: Kernel methods in machine learning. The Annals of
Statistics 36 (2008) 1171 –1220

9

