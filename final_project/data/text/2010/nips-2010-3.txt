Sparse Instrumental Variables (SPIV) for
Genome-Wide Studies

Felix V. Agakov
Public Health Sciences
University of Edinburgh
felixa@aivalley.com

Jon Krohn
WTCHG, Oxford
jon.krohn@magd.ox.ac.uk

Paul McKeigue
Public Health Sciences
University of Edinburgh
paul.mckeigue@ed.ac.uk

Amos Storkey
School of Informatics
University of Edinburgh
a.storkey@ed.ac.uk

Abstract

This paper describes a probabilistic framework for studying associations between
multiple genotypes, biomarkers, and phenotypic traits in the presence of noise and
unobserved confounders for large genetic studies. The framework builds on sparse
linear methods developed for regression and modi ﬁed here fo r inferring causal
structures of richer networks with latent variables. The method is motivated by the
use of genotypes as “instruments ” to infer causal associati ons between phenotypic
biomarkers and outcomes, without making the common restrictive assumptions of
instrumental variable methods. The method may be used for an effective screening
of potentially interesting genotype-phenotype and biomarker-phenotype associa-
tions in genome-wide studies, which may have important implications for validat-
ing biomarkers as possible proxy endpoints for early-stage clinical trials. Where
the biomarkers are gene transcripts, the method can be used for ﬁne mapping of
quantitative trait loci (QTLs) detected in genetic linkage studies. The method is
applied for examining effects of gene transcript levels in the liver on plasma HDL
cholesterol levels for a sample of sequenced mice from a heterogeneous stock,
with ∼ 105 genetic instruments and ∼ 47 × 103 gene transcripts.

1

Introduction

A problem common to both epidemiology and to systems biology is to infer causal relationships
between phenotypic measurements (biomarkers) and disease outcomes or quantitative traits. The
problem is complicated by the fact that in large bio-medical studies, the number of possible genetic
and environmental causes is very large, which makes it implausible to conduct exhaustive inter-
ventional experiments. Moreover, it is generally impossible to remove the confounding bias due to
unmeasured latent variables which inﬂuence associations b etween biomarkers and outcomes. Also,
in situations when the biomarkers are mRNA transcript levels, the measurements are known to be
quite noisy; additionally, the number of unique candidate causes may exceed the number of obser-
vations by several orders of magnitude (the p ≫ n problem). A fundamentally important practical
task is to reduce the number of possible causes of a trait to a much more manageable subset of can-
didates for controlled interventions. Developing an efﬁci ent framework for addressing this problem
may be fundamental for overcoming bottlenecks in drug development, with possible applications in
the validation of biomarkers as causal risk factors, or developing proxies for clinical trials.

Whether or not causation may be inferred from observational data has been a matter of philosophical
debate. Pearl [28] argues that causal assumptions cannot be veri ﬁed unless one makes a recourse

1

to experimental control, and that there is nothing in the probability distribution p(x, y) which can
tell whether a change in x may have an effect on y . Traditional discussions of causality are largely
focused on the question of identi ﬁability, i.e. determinin g sets of graph-theoretic conditions when a
post-intervention distribution p(y |do(x)) may be uniquely determined from a pre-intervention dis-
tribution p(y , x, z ) [27, 4, 32]. If the causal effects are shown to be identi ﬁable , their magnitudes can
be obtained by statistical estimation, which for common models often reduces to solving systems of
linear equations.
In contrast, from the Bayesian perspective, the causality detection problem may
be viewed as that of model selection, where a model Mx→y is compared with My→x . The problem
is complicated by the likelihood-equivalence, where for each setting of parameters of one model
there may exist a setting of parameters of the other giving rise to the identical likelihoods. However,
unless the priors are chosen in such a way that Mx→y and My→x also have identical posteriors, it
may be possible to infer the direction of the arrow. The view that the priors of likelihood-equivalent
models do not need to be set to ensure the equivalence of the posteriors is in contrast to e.g. [12]
(and references therein), but has been defended by MacKay (see [21], Section 35).

In this paper we are leaving aside debates about the nature of causality and focus instead on iden-
tifying a set of candidate causes for a large partially observed under-determined genetic problem.
The approach builds on the instrumental variable methods that were historically used in epidemi-
ological studies, and on approximate Bayesian inference in sparse linear latent variable models.
Speci ﬁc modeling hypotheses are tested by comparing approx imate marginal likelihoods of the cor-
responding direct, reverse, and pleiotropic models with and without latent confounders, where we
follow [21] in allowing for ﬂexible priors. The approach is l argely motivated by the observation that
independent variables do not establish a causal relation, while strong unconfounded direct depen-
dencies retained in the posterior modes even under large sparseness-inducing penalties may indicate
potential causality and suggest candidates for further controlled experiments.

2 Previous work

Inference of causal direction of x on y is to some extent simpli ﬁed if we assume existence of an
auxiliary variable g , such that g ’s effect on x may only be causal, and g ’s effect on y may only
be through x. The idea is exploited in instrumental variable methods [3, 2, 29] which typically
deal with low-dimensional linear models, where the strength of the causal effect may be estimated
as wx→y = cov(g , y)/cov(g , x). Note also that the hypothesized cause-outcome models such as
Mg→x→y and Mg→y→x are no longer Markov-equivalent, i.e.
it may be possible to select an
appropriate model via likelihood-based tests. Selecting a plausible instrument g may be difﬁcult in
some domains; however, in genetic studies it may be possible to exploit as an instrument a measure
of genotypic variation. In quantitative genetics, such applications of instrumental variable methods
have been termed Mendelian randomization [15, 34]. In accordance with the requirements of the
classic instrumental variable methods, it is assumed that effects of the genetic instrument g on the
biomarker x are unconfounded, and that effects of the instrument on the outcome y are mediated only
through the biomarker (i.e. there is no pleiotropy) [17, 35]. The former assumption is grounded in the
laws of Mendelian genetics and is satis ﬁed as long as populat
ion strati ﬁcation has been adequately
controlled. However, the assumption of no hidden pleiotropy severely restricts the application of this
approach, as most genotypic effects on complex traits are not sufﬁciently well understood to exclude
pleiotropy as a possible explanation of an association. Thus the classical instrumental variable
argument is limited to biomarkers for which suitable non-pleiotropic instruments exist, and cannot
be easily extended to exploit studies with multiple biomarkers and genome-wide data.

A more general approach to exploiting genotypic variation to infer causal relationships between
gene transcript levels and quantitative traits has been developed by Schadt et. al. [30] and subse-
quently extended (see e.g. [5]). They relax the assumption of no pleiotropy, but instead compare
models with and without pleiotropy by computing standard likelihood-based scores. After ﬁltering
to select a set of gene transcripts {xj } that are associated with the trait y , and loci {gi } at which
genotypes have effects on transcript levels xj , each possible triad of marker locus gi , transcript xj
and trait y is evaluated to compare three possible models: causal effect of transcript on trait, reverse
causation, and a pleiotropic model (see Figure 1 left, (i) –(iii) ). The support for these three models
is compared by a measure of model ﬁt penalized by complexity:
either Akaike’s Information Cri-
terion (AIC) [30], or the Bayesian Information Criterion (BIC) [5]. Schadt et. al. [30] denote this
procedure as the “likelihood-based causality model select ion” (LCMS) approach. While the LCMS

2

(i)

(ii)

(iii)

gi

gi

gi

gi

(iv)

gk

xj

y

xj

xj

y

xj

y

y

8

7

6

5

4

3

2

1

0
−6

p(AIC
−AIC
CSL

)
REV

−4

−2

0

2

4

6

−2

0

2

4

6

8

Figure 1: Left: (i –iii): Causal, reverse, and pleiotropic models of the LCMS approach [30]; (iv):
pleiotropic model with two genetic instruments. Center: Possible arbitrariness of LCMS inference.
The histogram shows the difference of the AIC scores for the causal and reverse models for a ﬁxed
biomarker and outcome, and various choices of loci from predictive regions. Right: AIC scores
of the causal (top) and reverse (bottom) models for each choice of instrument gi (the straight lines
link the scores for a ﬁxed choice of gi ). Scores were centered relative to those of the pleiotropic
model. Biomarker and outcome are liver expressions of Cyp27b1 and plasma HDL measurements
for heterogeneous mice. Based on the choice of gi , either causal or reverse explanations are favored.

and related methods [30, 5] relax the assumption of no hidden pleiotropy of the classic Mendelian
randomization method, they have three key limitations. First, effects of loci and biomarkers on out-
comes are not modeled jointly, so widely varying inferences are possible depending on the choice
of the triads {gi , xj , y}. Figure 1 center, right compares differences in the AIC scores for the causal
and reverse models constructed for a ﬁxed biomarker and outc ome, and for various choices of the
genetic instruments from the predictive region. Depending on the choice of instrument gi , either
causal or reverse explanations are favored. A second key limitation is that the LCMS method does
not allow for dependencies between multiple biomarkers, measurement noise, or latent variables
(such as unobserved confounders of the biomarker-outcome associations). Thus, for instance, with-
out allowance for noise in the biomarker measurements, non-zero conditional mutual information
I (gi , y |xj ) will be interpreted as evidence of pleiotropy or reverse causation even when the relation
between the underlying biomarker and outcome is causal. Also, the method is not Bayesian (the
BIC score is only a crude approximation to the Bayesian procedure for model selection).

One extension of the classic instrumental variable methods has been proposed by [4], who described
graph-theoretic conditions which need to be satis ﬁed in ord er for parameters of edges xi → y to
be identi ﬁable by solving a system of linear equations; howe ver, they focus on the identi ﬁability
problem rather than on addressing a large practical under-determined task with latent variables.
For example, their method does not allow for an easy integration of unmeasured confounders with
unknown correlations with the intermediate and outcome variables. Another approach to modeling
joint effects of genetic loci and biomarkers (gene expressions) was described by [41]. They modeled
the expression measurements as three ordered levels, and used a biased greedy search over model
structures from multiple starting points, to ﬁnd models wit h high BIC scores. Though applicable
for large-scale studies, the approach does not allow for measurement noise or latent variables (and
looses information by using categorical measurements). The vast majority of other recent model
selection and structure learning methods from machine learning literature are also either not easily
extended to include latent confounders (e.g. [16], [19], [22]), or applicable only for dealing with
relatively low-dimensional problems with abundant data (e.g. [33] and references therein).

3 Methods

To address the problem of causal discovery in large bio-medical studies, we need a uni ﬁed frame-
work for modeling relations between genotypes, biomarkers, and outcomes that is computationally
tractable to handle a large number of variables. Our approach extends LCMS and the instrumental
variable methods by the joint modeling of effects of genetic loci and biomarkers, and by allowing for
both pleiotropic genotypic effects and latent variables that generate couplings between biomarkers
and confound the biomarker-outcome associations. It relies on Bayesian modeling of linear associ-
ations between the modeled variables, with sparseness-inducing priors on the linear weights. The

3

i = 1 . . . n

g(i)

V

Σz

U

Ψ˜x

Ψ

x

Wg

˜x(i)

x(i)

z(i)

Wz

Ψ˜y

˜y(i)

y(i)

Ψ

y

−0.35

−0.28

−0.21

−0.14

−0.07

0.00

0.07

0.14

0.22

0.29

ρ
 
n
o
i
t
a
l
e
r
r
o
c
 
l
a
c
i
r
i
p
m
E

Bayes Factor: log
 L
x−>y
10

 − log

 L
x<−z−>y
10

, σ
2=1.0
z

 

1.4

1.2

1

0.8

0.6

0.4

0.2

0

−0.2

W

0.35
 
0.05 0.10 0.19 0.38 0.74 1.46 2.87 5.64 11.09 21.78 40.0
Concentration parameter γ
1

Figure 2: Left: SPIV structure. Filled/clear nodes correspond to observed/ latent variables. Right:
log Bayes factor of Mx←z→y and Mx→y as a function of empirical correlations ρ and γ1 for
y = 1, |x| = |y | = |z | = 1 and γ2 = 0, on the log10 scale. For
n = 100 observations, σ2
x = σ2
z = σ2
intermediate γ1 ’s and high empirical correlations, there is a strong preference for the causal model.

Bayesian framework allows prior biological information to be included if available: for instance,
cis-acting genotypic effects on transcript levels are likely to be stronger and less pleiotropic than
trans-acting effects on transcript levels. It also offers a rigorous approach to model comparison, and
is particularly attractive for addressing under-determined genetics problems (p ≫ n). The method
builds on automatic relevance determination approaches (e.g. [20], [25], [37]) and adaptive shrink-
age (e.g. [36], [8], [42]). Here it is used in the context of sparse multi-factor instrumental variable
analysis in the presence of unobserved confounders, pleiotropy, and noise.
Model Parameterization

Our sparse instrumental variables model (SPIV) is speci ﬁed with four classes of variables: gen o-
typic and environmental covariates g ∈ R|g| , phenotypic biomarkers x ∈ R|x| , outcomes y ∈ R|y| ,
and latent factors z1 , . . . , z|z| . The dimensionality of the latent factors |z| is ﬁxed at a moderately
high value (extraneous dimensions will tend to be pruned under the sparse prior). The latent factors
z play two major roles: they represent the shared structure between groups of biomarkers, and con-
found biomarker-outcome associations. The biomarkers x and outcomes y are speci ﬁed as hidden
variables inferred from noisy observations ˜x ∈ R|˜x| and ˜y ∈ R|˜y| (note that |˜x| = |x|, |˜y| = |y|). The
effects of genotype on biomarkers and outcome are assumed to be unconfounded. Pleiotropic effects
of genotype (effects on outcome that are not mediated through the phenotypic biomarkers) are ac-
counted for by an explicit parameterization of p(y|g, x, z). Graphical representation of the model is
shown on Figure 2 (left). It is clear that the SPIV structure extends that of the instrumental variable
methods [2, 3, 29] by allowing for the pleiotropic links, and also extends the pleiotropic model of
Schadt et. al. [30] (Figure 1 left (iii)) by allowing for multiple instruments and latent variables.

All the likelihood terms of p(x, ˜x, y, ˜y, z|g) are linear Gaussians with diagonal covariances
z z + WT
y = WT x + WT
x = UT g + VT z + ex ,
(1)
g g + ey , ˜x = Ax + e˜x ,
y ), e˜y ∼ N (0, Ψ˜y ), e˜x ∼ N (0, Ψ˜x ), z ∼
y ), ey ∼ N (0, Ψ
and ˜y = y + e˜y , where e˜x ∼ N (0, Ψ
z ), W ∈ R|x|×|y| , Wz ∈ R|z|×|y| , Wg ∈ R|g|×|y| , V ∈ R|z|×|x| , U ∈ R|g|×|x| are regression
N (0, Ψ
coefﬁcients (factor loadings) – for clarity, we assume the d
ata is centered. A ∈ R|x|×|x| has a banded
structure (accounting for possible couplings of the neighboring microarray measurements).
Prior Distribution

All model parameters are speci ﬁed as random variables with p rior distributions. For computa-
y , Ψ˜y , etc. are speci ﬁed
tional convenience, the variance components of the diagonal covariances Ψ
with inverse Gamma priors Γ−1 (ai , bi ), with hyperparameters ai and bi ﬁxed at values motivat-
ing the prior beliefs about the projection noise (often available to lab technicians collecting trait or
biomarker measurements). One way to view the latent confounders z is as missing genotypes or
environmental covariates, so that prior variances of the latent factors are peaked at values repre-
sentative of the empirical variances of the instruments g. Empirically, the choice of priors on the
variance components appears to be relatively unimportant, and other choices may be considered [9].

4

The considered choice of a sparseness-inducing prior on parameters W, Wz , Wg , etc. is a product
of zero-mean Laplace and zero-mean normal distributions

(2)

p(w) ∝

Lwi (0, γ1 )Nwi (0, γ2 ),

|w|
Y
i=1
Lwi (0, γ1 ) ∝ exp{−γ1 |wi |}, and Nwi (0, γ2 ) ∝ exp{−γ2w2
i }. Due to the heavy tails of the Lapla-
cian Lwi , the prior p(w) is ﬂexible enough to capture large associations even if they are rare. Higher
values of γ1 give a stronger tendency to shrink irrelevant weights to zero.
It is possible to set
different γ1 parameters for different linear weights (e.g. for the cis- and trans-acting effects); how-
ever, for clarity of this presentation we shall only use a global parameter γ1 . The isotropic Gaussian
component with the inverse variance γ2 contributes to the grouping effect (see [42], Theorem 1).
The considered family of priors (2) induces better consistency properties [40] than the commonly
used Laplacians [36, 9, 39, 26, 31]. It has also been shown [14] that important associations between
variables may be recovered even for severely under-determined problems (p ≫ n) common in ge-
netics. The SPIV model with p(w) deﬁned as in (2) generalizes LASSO and elastic net regressio n
[36, 42]. As a special case, it also includes sparse conditional factor analysis. Other sparse priors
on the weights, such as Student-t, “spike-and-slab”, or inducing Lq<1 penalties tend to result in less
tractable posteriors even for linear regression [10, 37, 8], which also motivates the choice (2).

Some additional intuition of the inﬂuence of the sparse prio r on the causal inference may be gained
by numerically comparing the marginal likelihoods of the Markov-equivalent models with and with-
out confounders Mx←z→y , Mx→y . (Comparison of these models is of particular importance in
epidemiology, because while the temporal data may often be available for distinguishing direct and
reverse models Mx→y and My→x , it is generally difﬁcult to ensure that there is no confound ing).
Figure 2 shows that when the empirical correlations are strong and γ1 is at intermediate levels, there
is a strong preference for a causal model. This is because the alternative model with the confounders
will have more parameters, and the weights will need to be larger (and therefore more strongly pe-
nalized by the prior) in order to lead to the same likelihood (note that for var(x) = var(y) = 1, the
likelihood-equivalence is achieved for w = vwz , |w| ≤ 1). Larger values of γ1 will tend to strongly
penalize all the weights, which makes the models largely indistinguishable. Also, as the number of
genetic instruments grows, evidence in favor of the causal or pleiotropic model will be less depen-
dent upon the priors on model parameters. For instance, with two genotypic variables that perturb
a single transcript, the causal model has three adjustable parameters, but the pleiotropic model has
ﬁve (see Figure 1 left, (iv)). Where several genotypic variables perturb a single transcript and the
causal model ﬁts the data nearly as well as the pleiotropic mo del, the causal model will have higher
marginal likelihood under almost any plausible prior, because the slightly better ﬁt of the pleiotropic
model will be outweighed by the penalty imposed by several extra adjustable parameters.
Inference

(3)

While the choice of prior (2) encourages sparse solutions, it makes exact inference of the posterior
parameters p(θ |D) analytically intractable. The most efﬁcient approach is ba sed on the maximum-
a-posteriori (MAP) treatment ([36], [9]), which reduces to solving the optimization problem
{log p ({˜y}, {˜x}|{g}, θ) + log p(θ)}
θM AP = arg max
θ
for the joint parameters θ , where the latent variables have been integrated out. Note that the MAP
solution for SPIV may also be easily derived for the semi-supervised case where the biomarker
and outcome vectors are only partially observed. Compared to other approximations of inference
in sparse linear models based e.g. on sampling or expectation propagation [26, 31], the MAP
approximation allows for an efﬁcient handling of very large networks with multiple instruments
and biomarkers, and makes it straightforward to incorporate latent confounders. Depending on the
choice of the global sparseness and grouping hyperparameters γ1 , γ2 , the obtained solutions for the
weights will tend to be sparse, which is also in contrast to the full inference methods. In high dimen-
sions in particular, the parsimony induced by the point-estimates will facilitate structure discovery
and interpretations of the ﬁndings.
One way to optimize (3) is by an EM-like algorithm. For example, the ﬁxed-point update for ui ∈
R|g| linking biomarker xi with the vector of instruments g is easily expressed as
+ γ2 I|g|(cid:17)(cid:17)−1
xi (cid:16)γ1 ´U(t−1)
i = (cid:16)GT G + σ2
u(t)
(cid:0)GT hxi i − GT hZivi (cid:1) ,
i

(4)

5

 = 40.0, γ
, γ
MI between biomarkers and  HDL at Θ
 = 10.0
2
1
MAP

2
1
3
g
7
5
a
p
i
f
1
s
1
m
g
o
a
r
r
e
R
p
N
U
a
c
A
l
S
F

4
q
o
C

3
5
t
7
7
l
3
9
g
b
3
h
a
x
d
3
A
D
m
n
p
0
c
c
S
b
r
D
3
i
r
r
A
c
L
T
l
S

k
i
R
9
1
M
7
1
4
0
3
9
4

k
1
a
c
s
h
D
1
d
n
a
s
H
C

3
9
x
4
s
7
M
3
5
0
C
B

7
d
r
B

2
2
b
2
4
l
l
5
1
r
s
3
3
4
c
I
d
k
t
m
b
T
i
P
M
e
m
T

k
l
1
1
i
b
R
s
7
b
0
2
H
1
p
K
y
0
C
2
5
0
3
9
4

3
k
k
2
v
i
i
x
R
R
p
b
4
7
r
T
T
1
0
A
A
1
1
0
0
4
0
0
0
3
1
5
1
5
1

5
b
2
2
m
r
a
b
k
R
r
P

4
1
r
a
E

1
m
a
c
y
l
G

j
5
p
t
A

3
5
4
1
r
f
l
O

0
2
9
z
e
2
F
1
6
0
W
A

2
a
5
k
i
.
e
a
R
4
d
i
s
7
8
i
8
C
2
0
t
0
F
S
5
9
1
2
C
4
3
A
3
9
4

Figure 3: Top: SPIV for arti ﬁcial datasets. Left/right plots show typical applications for the high
and low observation noise (σ2
˜x = 0.25 and σ2
˜x = 0.05 respectively). Top and bottom rows of each
Hinton diagram correspond to the ground truth and the MAP weights U (1–18), W (19–21), Wg (22–
27). Bottom: SPIV for a genome-wide study of causal effects on HDL in heterogeneous stock mice.
Left/right plots show maximum a-posteriori weights θM AP and the mutual information I (xi , y |e)
between the unobserved biomarkers and outcome evaluated from the model at θM AP , under the
joint Gaussian assumption. A cluster of pleiotropic links on chromosome 1 at about 173 MBP is
consistent with biology. The biomarker with the strongest unconfounded effect on HDL is Cyp27b1.
Transcripts that are most predictive of HDL through their links with pleiotropic genetic markers on
chrom 1 are Uap1, Rgs5, Apoa2, and Nr1i3. Parameters γ1,2 have been obtained by cross-validation.

where G ∈ Rn×|g| is the design matrix, ( ´Ui )kl = δkl /|uki | ∀k , l ∈ [1, |g|] ∩ Z, xi ∈ Rn , Z ∈ Rn×|z| ,
vi ∈ R|z| , and σ2
xi = (Ψx )ii . The expectations h.i are computed with respect to p(.|{˜x}, {˜y}, {g}),
which for (1) are easily expressed in the closed form. The rest is expressed analogously, and ex-
tensions to the partially observed cases are straight-forward. Faster (although more heuristic) al-
ternatives may be used for speeding up the M-step (e.g. [7]). The hyperparameters may be set
by cross-validation, marginalized out by specifying a hyper-prior, or set heuristically based on the
expected number of links to be retained in the posterior mode. Once a sparse representation is
produced by pruning irrelevant dimensions, more computationally-intensive inference methods for
the full posterior (such as expectation propagation or MCMC) may be used in the resulting lower-
dimensional model if needed. After ﬁtting SPIV to data, form al hypotheses tests were performed by
comparing the marginal likelihoods of the speci ﬁc models fo r the retained instruments, biomarkers,
and target outcomes. These were evaluated by the Laplace approximation at θM AP (e.g. [20]).

4 Results

Arti ﬁcial data: We applied SPIV to several simulated datasets, and compared speci ﬁc modeling
hypotheses for the biomarkers retained in the posterior modes. The structures were consistent with
the generic SPIV model, with all non-zero weights sampled from N (0, 1). Figure 3 (top) shows
˜y = 0.25/0.05). Note excellent sign-
typical results for the high/low observation noise (∀i, σ2
= σ2
˜xi
consistency of the results for the more important factors. Separate simulations showed robustness
under multiple EM runs and under- or over-estimation of the true number of confounders. Sub-
sequent testing of the speci ﬁc modeling hypotheses for the m ost important factors resulted in the
correct discrimination of causal and confounded associations in ≈86% of cases.
Genome-wide study of HDL cholesterol in mice: To demonstrate our method for a large-scale
practical application, we examined effects of gene transcript levels in the liver on plasma high-
density lipoprotein (HDL) cholesterol levels for a mice from a heterogeneous stock. The genetic
factors inﬂuencing HDL in mice have been well explored in bio logy e.g. by Valdar et. al. [38].
The gene expression data was collected and preprocessed by [13], who have kindly agreed to share
a part of their data. Breeding pairs for the stock were obtained at 50 generations after the stock

6

foundation. At each of the 12500 marker loci, genotypes were described by 8-D vectors of expected
founder ancestry proportions inferred from the raw marker genotypes by an HMM-based reconstruc-
tion method [23]. Mouse-speci ﬁc covariates included age an d sex, which were used to augment the
set of genetic instruments. The full set of phenotypic biomarkers consisted of 47429 transcript lev-
els, appropriately transformed and cleaned. Available data included 260 animals. Before applying
our method, we decreased the dimensionality of the genetic features and RNA expressions by using
a combination of seven feature (subset) selection methods, based on applications of ﬁlters, greedy
(step-wise) regression, sequential approximations of the mutual information between the retained
set and the outcome of interest, and applications of regression methods with LASSO and elastic
net (EN) shrinkage priors for the genotypes g, observed biomarkers ˜x, and observed HDL mea-
surements ˜y. For the LASSO and EN methods, global hyper-parameters were obtained by 10-fold
cross-validation. Note that feature selection is unavoidable for genome-wide studies using gene ex-
pressions as biomarkers. Indeed, the considered case of ∼ O(105 ) instruments and 47K biomarkers
would give rise to & O(109 ) interaction weights, which is expensive to analyze or even keep in
memory. After applying subset selection methods, SPIV was typically applied to subsets of data
with ∼ O(105 ) loci-biomarker interactions.

The results of the SPIV analysis of this dataset are shown on Figure 3 (bottom). The bottom left
plot shows maximum a-posteriori weights θM AP computed by running the EM-like optimization
procedure to convergence from 20 random initializations. For a model with latent variables and
about 30, 000 weights, each run took approximately 10 minutes of execution time (only weakly
optimized Matlab code, simple desktop). The parameters γ1,2 were obtained by 10-fold CV. Note
that only a fraction of the variables remains in the posterior. In this case and for the considered
sparseness-inducing priors, no hidden confounders appear to have strong effects on the outcome in
the posterior1 . The spikes of the pleiotropic activations in sex chromosome 20 and around chromo-
some 1 are consistent with the biological knowledge [38]. The biomarker with the strongest direct
effect on HDL (computed as the mean MAP weight wi : xi → y divided by its standard deviation
over multiple runs, where each mean weight exceeds a threshold) is the expression of Cyp27b1 (gene
responsible for vitamin D metabolism). Knockout of the Cyp27b1 gene in mice has been shown to
alter body fat stores [24], which might be expected to affect HDL cholesterol levels. Recently it
has also been shown that quantitative trait locus for circulating vitamin D levels in humans includes
a gene that codes for the enzyme that synthesizes cholesterol [1]. A subsequent comparison of 18
speci ﬁc reverse, pleiotropic, and causal models for Cyp27b1, HDL, and the whole vector of retained
genetic instruments (known to be causal by deﬁnition) showe d a slightly stronger evidence in favor
of the reverse hypothesis without latent confounders (with the ratio of Laplace approximations of
the marginal likelihoods of reverse vs causal models of ≈ 1.95 ± 0.27). This is in contrast to the
LCMS where the results are strongly affected by the choice of an instrument (Figure 1 right shows
the results for Cyp27b1, HDL, and the same choice of instruments).

To demonstrate an application to gene ﬁne-mapping studies, Figure 3 (bottom right) shows the
approximate mutual information I (xi , y |e = {age, sex}) between the underlying biomarkers and
unobserved HDL levels expressed from the model at θM AP . The mutual information takes into
account not only the strength of the direct effect of xi on y , but also associations with the pleiotropic
instruments, strengths of the pleiotropic effects, and dependencies between the instruments. Under
yj xi ), where
the as-if Gaussian assumption, I (xi , yj |θM AP ) = log(σ2
xi − σ4
yj σ2
xi ) − log(σ2
yj σ2

gg (Uwj + wgj )k2 + kΨ1/2
yj = kΣ1/2
σ2
z

(Vwj + wzj )k2 + wT
j

Ψ

xwj + Ψyj ,

(5)

with the rest expressed analogously. Here Σgg ∈ R|g|×|g| is the empirical covariance of the instru-
ments, wj ∈ R|x| , wzj ∈ R|z| , and wgj ∈ R|g| are the MAP weights of the couplings of yj with the
biomarkers, confounders, and genetic instruments respectively. When the outcome is HDL, the ma-
jority of predictive transcripts are ﬁne-mapped to a small r egion on chromosome 1 which includes
Uap1, Rgs5, Apoa2, and Nr1i3. The informativeness of these genes about the HDL cholesterol can-
not be inferred simply from correlations between the measured gene expression and HDL levels;
for example, when ranked in accordance to ρ2 ( ˜xi , ˜y |age, sex), the top 4 genes have the rankings

1No confounder effects in the posterior mode for the considered γ1
2 is speciﬁc to the considered mouse
,
HDL dataset, which shows relatively strong correlations between the measured biomarkers and the outcome.
An application of SPIV to proprietary human data for a study of effects of vitamins and calcium levels on
colorectal cancer (which we are not yet allowed to publish) showed very strong effects of the latent confounders.

7

of 838, 961, 6284, and 65 respectively. The ﬁndings are also b iologically plausible and consistent
with high-proﬁle biological literature (with association s between Apoa2 and HDL described in [38],
and strong links of Rgs5 to a genomic region strongly associated with metabolic traits discussed in
[5], while Nr1i3 and Uap1 are their neighbors on chromosome 1 within ∼ 1M bp). Note that the
couplings are via the links with the pleiotropic genetic markers on chromosome 1. Adjusting for sex
and age prior to performing feature selection and inference did not signi ﬁcantly change the results.

The results reported here appear to be stable for different choices of feature selection methods, data
adjustments, and algorithm runs. We note, however, that different results may potentially be obtained
based on the choice of animal populations and/or processing of the biomarker (gene expression)
measurements. Details of the data collection, microarray preprocessing, and feature selection, along
with the detailed ﬁndings for other biomarkers and phenotyp ic outcomes will be made available
online. Deﬁnitive conﬁrmation of these relationships woul
d require gene knock-out experiments.

5 Discussion and extensions

In large-scale genetic and bio-medical studies, we are facing a practical task of reducing a huge set
of candidate causes of complex traits to a more manageable subset of candidates where experimen-
tal control (such as gene knockout experiments or biomarker alternations) may be performed. SPIV
performs the screening of interesting biomarker-phenotype and genotype-biomarker-phenotype as-
sociations by exploiting the maximum-a-posteriori inference in a sparse linear latent variable model.
Additional screening is performed by comparing approximate marginal likelihoods of speci ﬁc mod-
eling hypotheses, including direct, reverse, and pleiotropic models with and without confounders,
which (under the assumption of no “prior equivalence”) may s
erve as an additional test of possible
causation [21]. Intuitively, the approach is motivated by the observation that while independence
of variables implies that they are not in a causal relation, a preference for an unconfounded causal
model may indicate possible causality and require further controlled experiments.

Technically, SPIV may be viewed as an extension of LASSO and elastic net regression which al-
lows for latent variables and pleiotropic dependencies. While being particularly attractive for genetic
studies, SPIV or its modi ﬁcations may potentially be applie d for addressing more general structure
learning tasks. For example, when applied iteratively, SPIV may be used to guide search over richer
model structures (where a greedy search over parent nodes is replaced by a continuous optimiza-
tion problem which combines subset selection and regression in the presence of latent variables),
which may be used for structure learning problems. Other extensions of the framework could in-
volve hybrid (discrete- and real-valued) outcomes with nonlinear/nongaussian likelihoods. Also,
as mentioned earlier, once sparse representations are produced by the MAP inference, it may be
possible to utilize more accurate approximations of the inference applicable for the induced sparse
structures [6]. Also note that sparse priors on the linear weights tend to give rise to sparse covariance
matrices. A potentially interesting alternative may involve a direct estimation of conditional preci-
sion matrices with a sparse group penalty. While SPIV attempts to focus the attention on important
biomarkers establishing strong direct associations with the phenotypes, modeling of the precisions
may be used for ﬁltering out unimportant factors (conditionally) independent of the outcome vari-
ables. Our future work will involve a direct estimation of the sparse conditional precision matrix
Σ−1
of the biomarkers, outcomes, and unmeasured confounders (given the instruments), through
xyz|g
latent variable extensions of the recently proposed graphical LASSO and related methods [11, 18].

The key purpose of this paper is to draw attention of the machine learning community to the prob-
lem of inferring causal relationships between phenotypic measurements and complex traits (disease
risks), which may have tremendous implications in epidemiology and systems biology. Our speci ﬁc
approach to the problem is inspired by the ideas of instrumental variable analysis commonly used
in epidemiological studies, which we have extended to properly address situations when the ge-
netic variables may be direct causes of the hypothesized outcomes. The sparse instrumental variable
framework (SPIV) overcomes limitations of the likelihood-based LCMS methods often used by ge-
neticists, by modeling joint effects of genetic loci and biomarkers in the presence of noise and latent
variables. The approach is tractable enough to be used in genetic studies with tens of thousands of
variables. It may be used for identifying speci ﬁc genes asso ciated with phenotypic outcomes, and
may have wide applications in identi ﬁcation of biomarkers a s possible targets for interventions, or
as proxy endpoints for early-stage clinical trials.

8

References
[1] J. Ahn, K. Yu, and R. Stolzenberg-Solomon et. al. Genome-wide association study of circulating vitamin
D levels. Human Molecular Genetics, 2010. Epub ahead of print.
[2] J. D. Angrist, G. W. Imbens, and D. B. Rubin. Identiﬁcation of caus al effects using instrumental variables
(with discussion). J. of the Am. Stat. Assoc., 91:444–455, 1996.
[3] R. J. Bowden and D. A. Turkington. Instrumental Variables. Cambridge Uni Press, 1984.
[4] C. Brito and J. Pearl. Generalized instrumental variables. In UAI, 2002.
[5] Y. Chen, J. Zhu, and P. Y. Lum et. al. Variations in DNA elucidate molecular networks that cause disease.
Nature, 452:429–435, 2008.
[6] B. Cseke and T. Heskes. Improving posterior marginal approximations in latent Gaussian models. In
AISTATS, 2010.
[7] B. Efron, T. Hastie, I. Johnstone, and R. Tibshirani. Least angle regression. The Ann. of Stat., 32, 2004.
[8] J. Fan and R. Li. Variable selection via nonconcave penalized likelihood and its oracle properties. J. of
the Am. Stat. Assoc., 96(456):1348–1360, 2001.
[9] M. Figueiredo. Adaptive sparseness for supervised learning. IEEE Trans. on PAMI, 25(9), 2003.
[10] I. E. Frank and J. H. Friedman. A statistical view of some chemometrics regression tools. Technometrics,
35(2):109–135, 1993.
[11] J. Friedman, T. Hastie, and R. Tibshirani. Sparse inverse covariance estimation with the graphical lasso.
Biostatistics, 9(3), 2008.
[12] D. Heckerman, C. Meek, and G. F. Cooper. A Bayesian approach to causal discovery. In C. Glymour and
G. F. Cooper, editors, Computation, Causation, and Discovery. MIT, 1999.
[13] G. J. Huang, S. Shifman, and W. Valdar et. al. High resolution mapping of expression QTLs in heteroge-
neous stock mice in multiple tissues. Genome Research, 19(6):1133–40, 2009.
[14] J. Jia and B. Yu. On model selection consistency of the elastic net when p ≫ n. Technical Report 756,
UC Berkeley, Department of Statistics, 2008.
[15] M. B. Katan. Apolipoprotein E isoforms, serum cholesterol and cancer. Lancet, i:507–508, 1986.
[16] S. Kim and E. Xing. Statistical estimation of correlated genome associations to a quantitative trait net-
work. PLOS Genetics, 5(8), 2009.
[17] D. A. Lawlor, R. M. Harbord, and J. Sterne et. al. Mendelian randomization: using genes as instruments
for making causal inferences in epidemiology. Stat. in Medicine, 27:1133–1163, 2008.
[18] E. Levina, A. Rothman, and J. Zhu. Sparse estimation of large covariance matrices via a nested lasso
penalty. The Ann. of App. Stat., 2(1):245–263, 2008.
[19] M. H. Maathius, M. Kalisch, and P. Buhlmann. Estimating high-dimensional intervention effects from
observation data. The Ann. of Stat., 37:3133–3164, 2009.
[20] D. J. C. MacKay. Bayesian interpolation. Neural Computation, 4:415–447, 1992.
[21] D. J. C. MacKay. Information Theory, Inference & Learning Algorithms. Cambridge Uni Press, 2003.
[22] J. Mooij, D. Janzing, J. Peters, and B. Schoelkopf. Regression by dependence minimization and its
application to causal inference in additive noise models. In ICML, 2009.
[23] R. Mott, C. J. Talbot, M. G. Turri, A. C. Collins, and J. Flint. A method for ﬁne mapping quantitative trait
loci in outbred animal stocks. Proc. Nat. Acad. Sci. USA, 97:12649–12654, 2000.
[24] C. J. Narvaez and D. Matthews et. al. Lean phenotype and resistance to diet-induced obesity in vitamin D
receptor knockout mice correlates with induction of uncoupling protein-1. Endocrinology, 150(2), 2009.
[25] R. M. Neal. Bayesian Learning for Neural Networks. Springer, 1996.
[26] T. Park and G. Casella. The Bayesian LASSO. J. of the Am. Stat. Assoc., 103(482), 2008.
[27] J. Pearl. Causality: Models, Reasoning, and Inference. Cambridge Uni Press, 2000.
[28] J. Pearl. Causal inference in statistics: an overview. Statistics Surveys, 3:96–146, 2009.
[29] J. M. Robins and S. Greenland. Identiﬁcation of causal effects u sing instrumental variables: comment. J.
of the Am. Stat. Assoc., 91:456–458, 1996.
[30] E. E. Schadt, J. Lamb, X. Yang, and J. Zhu et. al. An integrative genomics approach to infer causal
associations between gene expression and disease. Nature Genetics, 37(7):710–717, 2005.
[31] M. W. Seeger. Bayesian inference and optimal design for the sparse linear model. JMLR, 9, 2008.
[32] I. Shpitser and J. Pearl. Identiﬁcation of conditional interventional distributions. In UAI, 2006.
[33] R. Silva, R. Scheines, C. Glymour, and P. Spirtes. Learning the structure of linear latent variable models.
JMLR, 7, 2006.
[34] G. D. Smith and S. Ebrahim. Mendelian randomisation: can genetic epidemiology contribute to under-
standing environmental determinants of disease? Int. J. of Epidemiology, 32:1–22, 2003.
[35] D.C. Thomas and D.V. Conti. Commentary: The concept of Mendelian randomization. Int. J. of Epidemi-
ology, 32, 2004.
[36] R. Tibshirani. Regression shrinkage and selection via the lasso. JRSS B, 58(1):267–288, 1996.
[37] M. E. Tipping. Sparse Bayesian learning and the RVM. JMLR, 1:211–244, 2001.
[38] W. Valdar, L. C. Solberg, and S. Burnett et. al. Genome-wide genetic association of complex traits in
heterogeneous stock mice. Nature Genetics, 38:879–887, 2006.
[39] M. Wainwright. Sharp thresholds for high-dimensional and noisy sparsity recovery using L1-constrained
quadratic programmming. IEEE Trans. on Inf. Theory, 55:2183 – 2202, 2007.
[40] M. Yuan and Y. Lin. On the nonnegative garrote estimator. JRSS:B, 69, 2007.
[41] J. Zhu, M. C. Wiener, and C. Zhang et. al. Increasing the power to detect causal associations by combining
genotypic and expression data in segregating populations. PLOS Comp. Biol., 3(4):692–703, 2007.
[42] H. Zou and T. Hastie. Regularization and variable selection via the elastic net. JRSS:B, 67(2), 2005.

9

