Decoding Ipsilateral Finger Movements from ECoG
Signals in Humans

Yuzong Liu1 , Mohit Sharma2 , Charles M. Gaona2 , Jonathan D. Breshears3 , Jarod Roland 3 ,
Zachary V. Freudenburg1, Kilian Q. Weinberger1, and Eric C. Leuthardt2,3

1Department of Computer Science and Engineering, Washington University in St. Louis
2Department of Biomedical Engineering, Washington University in St. Louis
3Department of Neurosurgery, Washington University School of Medicine

Abstract

Several motor related Brain Computer Interfaces (BCIs) have been developed over
the years that use activity decoded from the contralateral hemisphere to operate de-
vices. Contralateral primary motor cortex is also the region most severely affected
by hemispheric stroke. Recent studies have identiﬁed ipsil ateral cortical activity
in planning of motor movements and its potential implications for a stroke rele-
vant BCI. The most fundamental functional loss after a hemispheric stroke is the
loss of ﬁne motor control of the hand. Thus, whether ipsilate ral cortex encodes
ﬁnger movements is critical to the potential feasibility of BCI approaches in the
future. This study uses ipsilateral cortical signals from humans (using ECoG) to
decode ﬁnger movements. We demonstrate, for the ﬁrst time, s
uccessful ﬁnger
movement detection using machine learning algorithms. Our results show high
decoding accuracies in all cases which are always above chance. We also show
that signiﬁcant accuracies can be achieved with the use of on ly a fraction of all the
features recorded and that these core features are consistent with previous phys-
iological ﬁndings. The results of this study have substanti al implications for ad-
vancing neuroprosthetic approaches to stroke populations not currently amenable
to existing BCI techniques.

1 Introduction

The evolving understanding of motor function in the brain has led to novel Brain Computer Inter-
face (BCI) platforms that can potentially assist patients with severe motor disabilities. A BCI is a
device that can decode human intent from brain activity alone in order to create an alternate com-
munication and control channel for people with severe motor impairments [39]. This brain-derived
control is dependent on the emerging understanding of cortical physiology as it pertains to motor
function. Examples are seen in the seminal discoveries by Georgopoulus and Schwartz that neu-
rons in motor cortex show directional tuning and, when taken as a population, can predict direction
and speed of arm movements in monkey models [12, 19]. In the subsequent two decades, these
ﬁndings were translated to substantial levels of brain-der ived control in monkey models and prelim-
inary human clinical trials [14, 34]. Another example is seen in Pfurtschellers work in analyzing
electroencephalography (EEG). His group was one of the ﬁrst
to describe the changes in amplitudes
in sensorimotor rhythms associated with motor movement [24]. As a result, both Pfurtscheller and
Wolpaw have used these signals to achieve basic levels of control in humans with amyotrophic lat-
eral sclerosis (ALS) and spinal cord injury [25, 40]. All these methods are based on a functioning
motor cortex capable of controlling the contralateral limb. This is the exact situation that does not
exist in unilateral stroke. Hence, these systems to date offer little hope for patients suffering from
hemispheric stroke. For a BCI to assist a hemiparetic patient, the implant will likely need to utilize

1

unaffected cortex ipsilateral to the affected limb (opposite the side of the stroke). To do so, an ex-
panded understanding of how and to what degree of complexity motor and motor associated cortex
encodes ipsilateral hand movements is essential.

Electrocorticography (ECoG), or signal recorded from the surface of the brain, offers an excellent
opportunity to further de ﬁne what level of motor informatio n can be deciphered from human ipsi-
lateral cortex related to movements (e.g. gross motor movements versus ﬁne motor kinematics of
individual ﬁnger movements). The ECoG signal is more robust compared to the EEG signal: its
magnitude is typically ﬁve times larger, its spatial resolu tion as it relates to independent signals is
much greater (0.125 versus 3.0 cm for EEG), and its frequency bandwidth is signiﬁcantly higher
(0-550 Hz versus 0- 40 Hz for EEG) [11, 30]. When analyzed on a functional level, many studies
have revealed that different frequency bandwidths carry highly speciﬁc and anatomically focal in-
formation about cortical processing. Thus far, however, no studies have utilized these ECoG spectral
features to de ﬁnitively analyze and decode cortical proces sing of the speciﬁc kinematics of ipsilat-
eral ﬁnger movements.

In the past year, the ﬁrst demonstration of this concept of ut ilizing ipsilateral motor signals for
simple device control have been published both with ECoG (in healthy subjects) and MEG (in
stroke patients) [4, 38]. In this study we set out to further explore the decoding of individual ﬁnger
movements of the ipsilateral hand that could potentially be utilized for more sophisticated BCIs in
the future. We studied 3 subjects who required invasive monitoring for seizure localization. Each had
electrode arrays placed over the frontal lobe and a portion of sensorimotor cortex for approximately a
week. Each subject performed individual ﬁnger tasks and the concurrent ECoG signal was recorded
and analyzed. The principal results show that individual ipsilateral ﬁnger movements can be decoded
with high accuracy. Through machine learning techniques, our group was able to determine the
intent to ﬂex and extend individual ﬁnger movements of the ip
silateral hand. These results indicate
that an ECoG based BCI platform could potentially operate a hand orthotic based on ipsilateral
motor signals. This could provide a neuroprosthetic alternative to patients with hemispheric stroke
who have otherwise failed non-invasive and medical rehabilitative techniques.

2 Data Collection

The subjects in this study were three patients (females; 8, 36, 48 years of age) with intractable
epilepsy who underwent temporary placement of intracranial electrode arrays to localize seizure foci
prior to surgical resection. All had normal levels of cognitive function and all were right-handed.
Subject 1 had a right hemispheric 8×8 grid while subjects 2 and 3 had left hemispheric 8×8 grids.
All gave informed consent. The study was approved by the Washington University Human Research
Protection Ofﬁce.

Each subject sat in their hospital bed 75 cm from a 17-inch LCD video screen. In this study, the
subject wore a data glove on the each hand to precisely monitor ﬁnger movements. Each hand rested
on a table in front of the screen. The screen randomly cued the patient to ﬂex and extend a given
ﬁnger (e.g., left index ﬁnger, right ring ﬁnger, etc.). A cue
came up on the monitor and as long
as it was present, subjects would, at a self-paced speed, move the indicated ﬁnger from the ﬂexed
to the extended position until the cue disappeared. They were instructed on the method prior to
participation. Each cued task period would last 2 seconds with a randomized rest period between
1.5 and 2.5 seconds(i.e., a trial). There were on average 30 trials per ﬁnger for a given subject.
For subject 1, the thumb data recording was found to be noisy and hence was eliminated from any
further analysis. Visual cues were presented using the BCI2000 program [27]. All motor hand
kinematics were monitored by the patient wearing a USB linked 5DT Data Glove 5 Ultras (Fifth
Dimension, Irvine, CA) on each hand. These data gloves are designed to measure ﬁnger ﬂexure
with one sensor per ﬁnger at up to 8-bit ﬂexure resolution. Th
e implanted platinum electrode arrays
were 8×8 electrode arrays(Ad-Tech, Racine, WI and PMT, Chanhassen, MN). The grid and system
setup details are described elsewhere [38]. ECoG signals were acquired using BCI2000, stored,
and converted to MATLAB ﬁles for further processing and anal ysis. All electrodes were referenced
to an inactive intracranial electrode. The sampling frequency was 1200 Hz and data acquisition is
band-pass ﬁltered from 0.15 to 500 Hz.

2

2.1 Data Preprocessing

Gabor Filter Analysis All ECoG data sets were visually inspected and re-referenced with respect to
the common average to account for any unwanted environmental noise. For these analyses, the time-
series ECoG data was converted into the frequency domain using a Gabor ﬁlter bank [17]. Spectral
amplitudes between 0 and 550 Hz were analyzed on a logarithmic scale. The ﬁnger positions from
the data glove were converted into velocities. These frequency responses and velocities were then
used as an input to machine learning algorithms described below. Inherent in this is the estimation
of the lag between the ECoG signal and the actual ﬁnger moveme nt. As part of the modeling
process, the value of this variable which resulted in the best decoding accuracy was chosen for
further analysis. Average time lags were then used to align the ECoG signal to the ﬁnger movement
signal. Those features optimized for predicting individual ﬁnger movement were then reviewed in
light of anatomic location and spectral association in each subject.
Dimensionality Reduction Due to the high dimensionality of the spectral data (#channels(N ) ×
#f requencies(F )), it is important to reduce the dimensions in order to build a more conducive
machine learning algorithm. Principle component analysis, or PCA, is among the most popular
dimensionality reduction algorithm. PCA projects the original high-dimensional feature space into
a much lower principle subspace, such that the variance of low-dimensional data is maximized. In
the real-time decoding task, we use PCA to reduce the input data. However, in the weight analysis,
we preserve all the N × F features because we want to study the effect of using all the features.
Electrode Co-Registration Radiographs were used to identify the stereotactic coordinates of each
grid electrode [10], and cortical areas were de ﬁned the GetL OC package for ECoG electrode local-
ization [18]. Stereotactically de ﬁned electrodes were map ped to the standardized brain model. The
experimental results were then collated with these anatomical mapping data.

3 Algorithms

In this section, we describe the machine learning algorithms used for the ﬁnger movement decoding
tasks. We focus on three different settings: 1. binary classiﬁcation, 2. multiclass classiﬁcation and
3. multitask classiﬁcation. All the data is split into a trai ning and a testing dataset. We chose our
parameters based on a validation dataset split from the training dataset.
Binary Classiﬁcation We treat the ﬁnger movement detection problem as a binary cla ssiﬁcation
setting. The data is presented as a time series with feature vector xt and velocity label yt at time t.
The goal is to predict if at time t, a ﬁnger is moving ( yt = 1) or not (yt = −1).
For this purpose, we adapted logistic regression (LR) [26] and binary support vector machines
(SVM) [7]. Both classiﬁers learn parameters (w, b) ∈ Rd × R. The prediction at time t is computed
as ˆyt = sign(w⊤ xt + b). The vector w is learned with the following optimization problem

min
(w,b)

(1)

L(w⊤ xt + b, yt) + λ|w|q .

T
X
t=1
Here, λ ≥ 0 is the regularization constant that trades off weight sparsity with complexity. The norm
of the regularization can be the ℓ1 norm (q = 1) or the ℓ2 norm (q = 2). The ℓ1 norm has the
tendency to result in sparse classiﬁers which assign non-ze ro weights to only a small subset of the
available features. This allows us to infer which brain regions and frequencies are most important
for accurate predictions. The ℓ2 norm tends to yield slightly better classiﬁcation results ( and is easier
to optimize) but is not as interpretable as it typically assigns small weights to many features. The
loss functions L differ for the two above mentioned algorithms. We will denote the loss function for
logistic regression as Llr and for SVMs as Lsvm . The exact de ﬁnitions are:

Llr (z, y ) = log(1 + exp(−yz))

Lsvm (z, y ) = max(1 − yz, 0)

(2)

Multiclass Classiﬁcation A second setting of interest is the differentiation of ﬁnger s. Here we do
not want to predict if a ﬁnger is moving but which one. Consequently, at any time point t we could
have one of K possible labels, such as “Index Finger ” ( yt = 1), “Ring Finger ” ( yt = 2), etc. We
adopt the Crammer and Singer multi-class adaptation of support vector machines (MCSVM) [8].
For each class k ∈ {1, . . . , K }, we learn class-speciﬁc parameters wk , bk . The loss only focuses on

3

(3)

|wk |q .

xt + br + 1

max(1 + wT
r

xyt + byt ), 0) + λ

xt + br − (wT
yt

min
(w1 ,b1 ),...,(wK ,bK )

pairwise comparisons between the different classes and ensures that w⊤
xt + bk ≥ w⊤
r
k
if yt = k for any r 6= k . For completeness, we re-state the optimization problem:
K
T
X
X
X
t=1
k=1
r 6=yt
Similar to the scenario of binary classiﬁcation, the consta nt λ ≥ 0 regulates the trade-off between
complexity and sparseness.
Multitask Learning In the movement detection setting, each ﬁnger is learned as a n independent
classiﬁcation problem. In the ﬁnger discrimination settin
g, we actively discriminate between the
individual ﬁngers. Multitask learning (MTL) is a way to comb ine the binary ﬁnger movement
detection problems by learning them jointly [5]. In the setting of brain decoding, it seems reasonable
to assume that there are certain features which are associated with the general cortical processing of
ﬁnger movements. This is analogous to the notion of language processing and articulation in cortical
areas. Functional magnetic resonance imaging (fMRI) studies have shown that although speech is
represented in general cortical areas, individual features speciﬁc to different kinds of words can
be found [16, 23]. We adopt the MTL adaptation for SVMs of [9], and an analogous framework
for logistic regression, which leverages the commonalities across learning tasks by modeling them
explicitly with an additional shared weight vector w0 . The prediction at time t for ﬁnger k is de ﬁned
as ˆyt = (w0 + wk )⊤ xt . The corresponding optimization problem becomes
T
K
X
X
t=1
k=0
The parameter λ0 regulates how much of the learning is shared. If λ0 → +∞, then w0 = 0 and we
reduce our setting to the original binary classiﬁcation men tioned above. On the other hand, setting
λ0 = 0 and λk>0 ≫ 0 will result in weight vectors wk>0 = 0. As a result, one would learn only a
single classiﬁer with weight vector w0 for generic ﬁnger movement.

L((w0 + wk )⊤xt , yt) + λk |wk |q .

min
w0 ,w1 ,...,wK

λ0 |w0 | +

(4)

4 Results

1

 

0.8

0.6

e
v
r
u
C
 
e
h
t
 
r
e
d
n
U
 
a
e
r
A

In this section we evaluate our algorithms for ipsilateral decoding on three subjects. First, we ap-
proximate the time-lag between ECoG signal and ﬁnger moveme nt, then we present decoding results
on ﬁnger movement detection, discrimination and also joint decoding of all ﬁngers in one hand.
Time Lag We ﬁrst study the effects of
decoding time lag between cortical signal
and movement using features. The decod-
ing accuracy is computed by shifting the
feature dataset xt and the target dataset yt
by a presumed number of sample points
(i.e. we are evaluating the performance of
decoder h: h(xt ) = yt+δT , by increasing
the value of δT ). The best time lag is
selected as the value of δT which leads
to best decoding accuracy.
Figure 1
shows the decoding accuracy as a function
of
time-lag for
four
individual
ﬁnger
movements in Subject 1. Offsets between
0 and 800 ms are tested for all ﬁngers and
an average offset time is computed. The
average time lag for the ipsilateral ﬁnger
movement for Subject 1 is observed to be
around 158 ms. This is in accordance with
previous studies by our group which show
similar time lags between cortical activity
and actual movements [38]. All further analysis is based on cortical activity (features) shifted
relative to movement by the average time-lag reported here.

300
450
Time Lag (ms)
Figure 1: Decoding time lag for ipsilateral ﬁnger move-
ment in Subject 1. The x-axis is the presumed time lag
δT (ms) between input feature vectors and target labels,
and the y-axis is the area under the ROC curve com-
puted from L1-regularized logistic regression model.
The bold black line is the average AUC, and the best
decoding time-lag is indicated by the black dotted line.

Index
Middle
Ring
Little
Average

0
 
0

750

600

150

0.4

0.2

4

1

0.8

0.6

0.4

0.2

e
t
a
R
 
e
v
i
t
i
s
o
P
 
e
u
r
T

0
 
0

 

Index
Middle
Ring
Little

1

0.8

0.6

0.4

0.2

e
t
a
R
 
e
v
i
t
i
s
o
P
 
e
u
r
T

0.8

1

0
 
0

 

Thumb
Index
Middle
Ring
Little

1

0.8

0.6

0.4

0.2

e
t
a
R
 
e
v
i
t
i
s
o
P
 
e
u
r
T

0.8

1

0
 
0

 

Thumb
Index
Middle
Ring
Little

0.8

1

0.2

0.4
0.6
False Positive Rate
(c) Subject 3

0.2

0.4
0.6
False Positive Rate
(b) Subject 2

0.2

0.4
0.6
False Positive Rate
(a) Subject 1

Figure 2: ROC curve for the ipsilateral ﬁnger movement decod er. Horizontal axis shows the false
positive rate, and the vertical axis shows the true positive rate. The dotted line is the accuracy of a
random classiﬁer. Classiﬁers that have higher
area under the ROC curve, or AUC, indicate better
classiﬁcation performance.

Detecting Finger Movement We characterize the movement detection task as a binary classiﬁca-
tion. We ﬁrst set a threshold thresh, and label the targets yt as 1 if the velocity at time t vt ≥ thresh,
and -1 otherwise. Then, we use ℓ1-regularized logistic regression for the binary classiﬁca tion. We
use receiver operating characteristic (ROC) curve to evaluate the performance of the binary clas-
siﬁcation. ROC curve is widely used in signal estimation and detection theory, and is a graphical
plot of true positive rate versus the false positive rate. ROC analysis allows user to pick the opti-
mal discrimination threshold for the binary classiﬁer. We p ick regularizer λ from validation dataset.
Figure 2 shows the result of ROC curve for three subjects. This demonstrates that ℓ1-regularized
logistic regression is a powerful tool in detecting ﬁnger mo vement.
Finger Discrimination In this section, we study how to discriminate which ﬁnger has made the
movement. We ﬁrst extract the sample points of which the ﬁnge
r is moving from the time-series.
We then apply multiclass SVM to do the classiﬁcation. The res ult is shown as the confusion
matrices in Figure 3, and the colorbar shows the accuracy. Each row of the matrix represents the
ﬁnger that actually moved and each column represents predic ted ﬁnger. The elements of the matrix
shows the percentage of all movements of a particular ﬁnger t hat has been classiﬁed as particular
predicted ﬁnger. Note that the accuracy by a random multicla ss classiﬁer is 1/(number of ﬁngers).
It can be concluded that the ECoG signal contains useful information to discriminate individual
ﬁnger movement.

	


	





t
n
e
m
e
v
o
M
 
d
e
t
c
i
d
e
r
P

Actual Movement

Figure 3: Confusion matrix of ﬁnger movement multiclass cla ssiﬁcation. The rows are the actual
movement, and the columns are the predicted movement.

4.1 Learning Commonality from the Brain Activity

In this section, we present how multitask learning improves the performance of the classiﬁer. Al-
though multitask learning has been employed in the context of brain signal decoding [2], we are the
ﬁrst to decode ECoG signals in humans. We group all the indivi dual ﬁnger movement together, such
that each task has similarity with others. First of all, we evaluate the performance of single-task
learning using SVM. Then, we study the SVM-based multitask learning. As we show in Equation 4,

5

we make trade-off between modeling joint component and and modeling class-speciﬁc components
by adjusting parameters λ0 and λ. We search a number of regularization constant (λ0 , λ), and pick
up the parameters that lead to highest average AUC for all tasks. Table 1 shows the comparison
of SVM-based single task learning and multitask learning. Here we evaluate the multitask learning
algorithm based on the improvement of (1-AUC); (1-AUC) stands for the area above the curve. The
average improvement of the decoder for three patients is 25.53%, 5.60%, and 18.57%, respectively.
This con ﬁrms our assumption that there exists brain activit y that controls the ﬁnger movement, ir-
respective of any particular ﬁnger. By carefully searching the best parameters that regulates the
trade-off between learning commonality among all ﬁnger mov ement and speciﬁcity of exact ﬁnger
movement, the classiﬁcation algorithm can be signiﬁcantly
improved. We also compare the ℓ1/ℓ2-
regularized logistic regression-based multitask learning with SVM-based multitask learning. There
is an improvement on (1-AUC) for logistic regression-based multitask learning. Again, it illustrates
that multitask learning is particularly helpful in learning similar tasks that are controlled by the brain.
However, we prefer SVM-based multitask learning because of the larger improvement.

AUC
Thumb
Index
Middle
Ring
Little

Subject 1
MTL
STL
N/A
N/A
0.8494
0.8477
0.8569
0.8393
0.8561
0.8000
0.7865
0.7425

Subject 2
MTL
STL
0.7845
0.7710
0.9061
0.8948
0.9021
0.8990
0.8894
0.8888
0.7586
0.7124

Subject 3
MTL
STL
0.8611
0.7680
0.8242
0.7454
0.9481
0.9459
0.7479
0.7404
0.7801
0.7705

Table 1: Comparison of SVM-based single-task learning (STL) and SVM-based multi-task learn-
ing (MTL). The parameters are chosen from validation dataset. The best decoding performance is
indicated in bold.

5 Weight Analysis

An important part of decoding ﬁnger movements from cortical activity is to map the features back
to cortical domain. Physiologically, it is important to understand the features which contribute most
to the decoding algorithms i.e. the features with the highest weights. As shown in Table 2 below, the
decoding accuracy, indicated by AUC, does not change much as we increase the number of features
used for classiﬁcation. This signiﬁes that from the large fe
ature set used for decoding, a few features
form the core and are the most important. To visualize these core features, we mapped the top 30
features back to the brain. Figure 4 above shows the normalized weights from the features used
to classify ﬁnger movements from non-movements. It is appar ent from the ﬁgure that the features
are wide spread and signify distributed (networked) cortical processing. It can also be seen that
many prominent features are located in the frontal cortical areas which supports previous ﬁndings
that areas anterior to the motor cortex are involved in planning of motor movements (pre-motor and
dorsolateral prefrontal cortex). Also, as previously reported, the frequency range with the highest
weights falls in the lower frequencies in ipsilateral movements [38]. In our case, the frequencies
fall in the delta-alpha range. As noted by Tallon-Baudry, attention networks of the brain affect the
oscillatory synchrony as low as theta-alpha range frequencies [31].

# features
AUC

1
0.681

2
0.717

4
0.755

8
0.787

16
0.803

32
0.807

64
0.807

256
0.807

4096
0.808

Table 2: The area under the curve (AUC) as a function of the number of features used for classiﬁ-
cation. Features were selected in decreasing order of their respective absolute weights from logistic
regression with ℓ1 regularization.

6

Subject 1

Subject 2

Subject 3

Figure 4: Brain map representing the weights of the top 30 features of the three subjects. It represents
the variability in cortical processing of ipsilateral ﬁnge r movements. It can also be seen that cortical
processing occurs as a network involving dorsolateral prefrontal cortex, pre-motor and motor areas.
The frequency range for these features is in the delta and alpha range i.e. the low frequency range.

6 Discussion

The notion that motor cortex plays a role in ipsilateral body movements was ﬁrst asserted by Nyberg-
Hansen et al. that 15% of corticospinal neurons did not decussate in cats [22]. Originally this was felt
to represent more axial motor control. Further studies in single-neuron recordings in monkey models
extended this observation to include ipsilateral hand and ﬁ nger function. Tanji et al. demonstrated
that a small percentage of primary motor cortical neurons showed increased activity with ipsilateral
hand movements [32]. This site was found to be anatomically distinct from contralateral hand sites
and, when stimulated, produced ipsilateral hand movements [1]. Additionally, a larger subset of
premotor neurons was found to demonstrate more robust activations with cues to initiate movement
during both ipsilateral and contralateral movements than with primary motor sites [3, 6]. These
ﬁndings in animal models support the conclusion that a small percent of motor and a larger percent
of premotor cortex participate in control of ipsilateral limb and hand movements.

In humans, there appears to be a dichotomy in how motor regions contribute depending on whether
the primary or non-primary motor cortex is examined. Using fMRI Newton et al. demonstrated that
there was a negative change from baseline in fMRI bold sequence in M1 associated with ipsilateral
movements and postulated this to represent increased inhibition [21]. Verstynen et al., however,
recently published contrasting results. Their group showed that anatomically distinct primary motor
sites demonstrated increased activation that became more pronounced during the execution of com-
plex movements [36]. The role that premotor cortex plays appears to be distinct from that of primary
motor cortex. In normal subjects, fMRI shows that there is more robust bilateral activation of the
dorsal premotor cortex with either contralateral or ipsilateral hand movements [15]. The ﬁndings
by Huang, et al. (2004) demonstrated that ipsilateral premotor areas have magnetoencephalogra-
phy (MEG) dipole peak latencies that signiﬁcantly precede c ontralateral M1 sensorimotor cortex
in performing unilateral ﬁnger movements. Using electroen cephalography (EEG), ipsilateral hand
movements have been shown to induce alteration in cortical potentials prior to movement; this is re-
ferred to as premotor positivity [33, 29]. Spectral analyses of EEG signals have shown bihemispheric
low-frequency responses with various ﬁnger and hand moveme nts. Utilizing electrocorticography
(ECoG), Wisneski et al more de ﬁnitively demonstrated that t he cortical physiology associated with
ipsilateral hand movements was associated with lower frequency spectral changes, an earlier timing,
and premotor predominant cortical localization, when compared to cortical physiology that was as-
sociated with contralateral hand movements [38]. Taken together, these ﬁndings support more of a
motor planning role, rather than execution role, in ipsilateral hand actions.

Decoding the information present in the ECoG signal with regard to ipsilateral ﬁnger movements is
important in de ﬁning the potential use of BCI methodologies for patients with hemispheric dysfunc-
tion due to stroke or trauma. If high resolution motor kinematics can be decoded from the ECoG
signal (e.g.
individual ﬁnger ﬂexion and extension), a BCI p
latform could potentially be created
to restore function to a stroke induced paretic hand. Since up to one-half of hemispheric stroke

7

patients are chronically left with permanent loss of function in their affected hand, this could have
substantial clinical impact [20]. Functional imaging has shown these severely affected patients to
have increased activity in the premotor regions of their unaffected hemispheres [28, 37]. The exact
role this activity plays is still unclear. It may simply be an indicator of a more severe outcome [35]
or an adapative mechanism to optimize an already poor situation [13]. Thus, incomplete recovery
and its association with heightened ipsilateral activation may re ﬂect the up-regulation of motor plan-
ning with an inability to execute or actuate the selected motor choice. In this situation, a BCI may
provide a unique opportunity to aid in actuating the nascent premotor commands. By decoding the
brain signals associated with a given motor intention, the BCI may then convert these signals into
commands that could control a robotic assist device that would allow for improved hand function
(i.e., a robotic glove that opens and closes the hand or a functional electrical simulator that operates
the nerves and muscles of the hand). The BCI would allow the ipsilateral premotor cortex to bypass
the physiological bottleneck determined by injured and dysfunctional contralateral primary cortex
(due to stroke) and the small and variable percentage of uncrossed motor ﬁbers from ipsilateral M1.
This new methodology would allow for restoration of function in chronically and severely affected
subjects for whom methods of rehabilitation have not accomplished a sufﬁciently recovery.

Although the results presented here show high decoding accuracies, it is important to discuss the
origin and physiology of ipsilateral motor related activations. The notion of ipsilateral activity orig-
inating as a result of trans-collosal inhibition from the side contralateral to the moving limb has
been discussed. Although a direct comparison between ipsilateral and contralateral activity was not
the main aim of this study, out ﬁndings from ipsilaterel cort ex mesh well with the previous studies
which did a direct comparison between the two [38]. The optimal time lag in this study for decoding
ﬁnger movements was 150 ms which is similar to ﬁndings by Wisn
eski et al. and is different from
the time difference for contralateral activations ( 90ms). This time difference supports the notion
that ipsilateral motor physiology is more associated with motor planning than its execution. Given
the earlier timing than contralateral activation, this physiology is less likely to be an after-effect of
contralateral physiology or a result of trans-collosal inhibition. Future studies need to be conducted
to further address this issue explicitly.

7 Conclusion

To our knowledge, this work describes the ﬁrst instance of su ccessful detection of individual ﬁnger
movements from human ipsilateral ECoG signals.
In this paper, we present a general decoding
framework using the following algorithms: (1) ℓ1-regularized logistic regression for detecting ﬁnger
movement; (2) Multiclass support vector machines to discriminate between ﬁngers; and (3) First
demonstration of multitask learning into the ECoG signal to improve decoding accuracy. The results
presented here suggest that there exists information on the cortex ipsilateral to the moving ﬁngers
which can be decoded with high accuracy using machine learning algorithms. These results present
a great potential in the world of neuroprosthetics and BCI. For patients suffering from stroke and
hemiparesis, decoding ﬁnger movements from the unaffected hemisphere can be of tremendous help.
Our future goals involve simultaneous decoding of ﬁnger and arm movements (using standard center
out joystick task) from both ipsilateral and contralateral hemispheres. Another important goal is the
real-time use of these decoding results and demonstrate their utility in the world of BCI.

References
[1] H. Aizawa, H. Mushiake, M. Inase, and J. Tanji. An output zone of the monkey primary motor cortex specialized for bilateral hand
movement. Experimental Brain Research, 82(1):219–221, 1990.

[2] M. Alamgir, M. Grosse-Wentrup, and Y. Altun. Multitask learning for brain-computer interfaces. Proceedings of the Thirteenth Interna-
tional Conference on Artiﬁcial Intelligence and Statistic s, 9:17–24, 2010.

[3] C. Brinkman and R. Porter. Supplementary motor area in the monkey: activity of neurons during performance of a learned motor task.
Journal of Neurophysiology, 42(3):681, 1979.

[4] E. Buch, C. Weber, L. Cohen, C. Braun, M. Dimyan, T. Ard, J. Mellinger, A. Caria, S. Soekadar, A. Fourkas, et al. Think to move: a
neuromagnetic brain-computer interface (BCI) system for chronic stroke. Stroke, 39(3):910, 2008.

[5] R. Caruana. Multitask learning. Machine learning, 28:41–75, 1997.

[6] P. Cisek, D. Crammond, and J. Kalaska. Neural activity in primary motor and dorsal premotor cortex in reaching tasks with the con-
tralateral versus ipsilateral arm. Journal of neurophysiology, 89(2):922, 2003.

[7] C. Cortes and V. Vapnik. Support-vector networks. Machine learning, 20(3):273–297, 1995.

8

[8] K. Crammer and Y. Singer. On the algorithmic implementation of multiclass kernel-based vector machines. The Journal of Machine
Learning Research, 2:265–292, 2002.

[9] T. Evgeniou and M. Pontil. Regularized multi–task learn ing. In KDD, pages 109–117, 2004.

[10] P. Fox, J. Perlmutter, and M. Raichle. A stereotactic method of anatomical localization for positron emission tomography. Journal of
Computer Assisted Tomography, 9(1):141, 1985.

[11] W. Freeman, M. Holmes, B. Burke, and S. Vanhatalo. Spatial spectra of scalp eeg and emg from awake humans. Clinical Neurophysiol-
ogy, 114(6):1053–1068, 2003.

[12] A. Georgopoulos, J. Kalaska, R. Caminiti, and J. Massey. On the relations between the direction of two-dimensional arm movements
and cell discharge in primate motor cortex. Journal of Neuroscience, 2(11):1527, 1982.

[13] C. Gerloff, K. Bushara, A. Sailer, E. Wassermann, R. Chen, T. Matsuoka, D. Waldvogel, G. Wittenberg, K. Ishii, L. Cohen, et al.
Multimodal imaging of brain reorganization in motor areas of the contralesional hemisphere of well recovered patients after capsular
stroke. Brain, 129(3):791, 2006.

[14] L. Hochberg, M. Serruya, G. Friehs, J. Mukand, M. Saleh, A. Caplan, A. Branner, D. Chen, R. Penn, and J. Donoghue. Neuronal
ensemble control of prosthetic devices by a human with tetraplegia. Nature, 442(7099):164–171, 2006.

[15] H. Johansen-Berg, M. Rushworth, M. Bogdanovic, U. Kischka, S. Wimalaratna, and P. Matthews. The role of ipsilateral premotor cortex
in hand movement after stroke. Proceedings of the National Academy of Sciences, 99(22):14518, 2002.

[16] M. Just, V. Cherkassky, S. Aryal, and T. Mitchell. A neurosemantic theory of concrete noun representation based on the underlying brain
codes. 2010.

[17] E. Leuthardt, Z. Freudenberg, D. Bundy, and J. Roland. Microscale recording from human motor cortex: implications for minimally
invasive electrocorticographic brain-computer interfaces. Journal of Neurosurgery: Pediatrics, 27(1), 2009.

[18] K. Miller, S. Makeig, A. Hebb, R. Rao, M. Dennijs, and J. Ojemann. Cortical electrode localization from x-rays and simple mapping for
electrocorticographic research: The. Journal of neuroscience methods, 162(1-2):303–308, 2007.

[19] D. Moran and A. Schwartz. Motor cortical representation of speed and direction during reaching.
82(5):2676, 1999.

Journal of Neurophysiology,

[20] H. Nakayama, H. Jørgensen, H. Raaschou, and T. Olsen. Re covery of upper extremity function in stroke patients: the copenhagen stroke
study. Archives of physical medicine and rehabilitation, 75(4):394, 1994.

[21] J. Newton, A. Sunderland, and P. Gowland. fmri signal decreases in ipsilateral primary motor cortex during unilateral hand movements
are related to duration and side of movement. Neuroimage, 24(4):1080–1087, 2005.

[22] R. Nyberg-Hansen and A. Brodal. Sites of termination of corticospinal ﬁbers in the cat. an experimental study with s ilver impregnation
methods. The Journal of Comparative Neurology, 120(3):369–391, 2004.

[23] S. Petersen, P. Fox, M. Posner, M. Mintum, and M. Raichle. Positron emission tomographic studies of the cortical anatomy of single-word
processing. Cognitive psychology: key readings, page 109, 2004.

[24] G. Pfurtscheller and A. Aranibar. Event-related cortical desynchronization detected by power measurements of scalp EEG* 1. Electroen-
cephalography and Clinical Neurophysiology, 42(6):817–826, 1977.

[25] G. Pfurtscheller, C. Guger, G. Muller, G. Krausz, and C. Neuper. Brain oscillations control hand orthosis in a tetraplegic. Neuroscience
letters, 292(3):211–214, 2000.

[26] S. Ryali and V. Menon. Feature selection and classiﬁcat ion of fmri data using logistic regression with l1 norm regularization. NeuroImage,
47:S57, 2009.

[27] G. Schalk, D. McFarland, T. Hinterberger, N. Birbaumer, and J. Wolpaw. Bci2000: a general-purpose brain-computer interface system.
IEEE Transactions on Biomedical Engineering, 51(6):1034–1043, 2004.

[28] R. Seitz, P. Hoﬂich, F. Binkofski, L. Tellmann, H. Herzo g, and H. Freund. Role of the premotor cortex in recovery from middle cerebral
artery infarction. Archives of neurology, 55(8):1081, 1998.

[29] H. Shibasaki and M. Kato. Movement-associated cortical potentials with unilateral and bilateral simultaneous hand movement. Journal
of Neurology, 208(3):191–199, 1975.

[30] R. Srinivasan, P. Nunez, R. Silberstein, E. Inc, and O. Eugene. Spatial ﬁltering and neocortical dynamics: estimat es of eeg coherence.
IEEE Transactions on Biomedical Engineering, 45(7):814–826, 1998.

[31] C. Tallon-Baudry. Oscillatory synchrony and human visual cognition. Journal of Physiology-Paris, 97(2-3):355–363, 2003.

[32] J. Tanji, K. Okano, and K. Sato. Neuronal activity in cortical motor areas related to ipsilateral, contralateral, and bilateral digit movements
of the monkey. Journal of neurophysiology, 60(1):325, 1988.

[33]

I. Tarkka and M. Hallett. Cortical topography of premotor and motor potentials preceding self-paced, voluntary movement of dominant
and non-dominant hands. Electroencephalography and Clinical Neurophysiology, 75(1-2):36–43, 1990.

[34] D. Taylor and A. Schwartz. Direct cortical control of 3d neuroprosthetic devices. Aug. 17 2004. US Patent App. 10/495,207.

[35] A. Turton, S. Wroe, N. Trepte, C. Fraser, and R. Lemon. Contralateral and ipsilateral emg responses to transcranial magnetic stimulation
during recovery of arm and hand function after stroke. Electroencephalography and Clinical Neurophysiology/Electromyography and
Motor Control, 101(4):316–328, 1996.

[36] T. Verstynen, J. Diedrichsen, N. Albert, P. Aparicio, and R. Ivry. Ipsilateral motor cortex activity during unimanual hand movements
relates to task complexity. Journal of Neurophysiology, 93(3):1209, 2005.

[37] C. Weiller, F. Chollet, K. Friston, R. Wise, and R. Frackowiak. Functional reorganization of the brain in recovery from striatocapsular
infarction in man. Annals of Neurology, 31(5):463–472, 2004.

[38] K. Wisneski, N. Anderson, G. Schalk, M. Smyth, D. Moran, and E. Leuthardt. Unique cortical physiology associated with ipsilateral
hand movements and neuroprosthetic implications. Stroke, 39(12):3351, 2008.

[39] J. Wolpaw, N. Birbaumer, D. McFarland, G. Pfurtscheller, and T. Vaughan. Brain-computer interfaces for communication and control.
Clinical neurophysiology, 113(6):767–791, 2002.

[40] J. Wolpaw and D. McFarland. Control of a two-dimensional movement signal by a noninvasive brain-computer interface in humans.
Proceedings of the National Academy of Sciences of the United States of America, 101(51):17849, 2004.

9

