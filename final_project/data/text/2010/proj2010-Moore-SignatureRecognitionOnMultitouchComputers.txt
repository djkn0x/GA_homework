Signature Recognition on Multitouch Computers

Chris Moore

10 December 2010

1 Introduction

Mobile computing devices spor ting multitouch
displays for user input such as Apple’s iPhone
and Google’s Nexus S have exploded in pop-
ularity in the last few years. On such devices,
performing a common function such as initi-
ating a phone call often requires the user to
look at the screen and tap several elements.
For instance, to call someone using an iPhone
requires looking at the screen and tapping at
least twice: once to select the icon for the
phone application, and again to select the per-
son to call. Such devices, however, are of-
ten used in situations such as driving in which
looking at the screen is dangerous or impos-
sible, so it is useful to have a way to trigger
speciﬁc, common actions without looking at
the screen. One way to do so is to allow the
user to assign speciﬁc actions (ex: “call Mom”)
to speciﬁc “signatures” - continuous shapes
traced out on the multitouch display.
Here we explore an algorithm for classifying
such signatures using training data provided
by the user. The algorithm is encapsulated
in the provided iPad app. The user is able to
deﬁne as many signature classes as he/she
wishes and provide multiple training examples
for each class. When ﬁnished, the user can
enter test mode and the app will classify each
new signature the user then enters.

2 Algorithm

2.1 Goals

At minimum, the algorithm should satisfy the
following goals:

1. Recognize signatures invariant to rota-
tion and scale.

2. Detect the presence of outliers in test
data since there is no guarantee that a
user will enter a signature that “reason-
ably” corresponds to one of the deﬁned
signature classes.

3. Ensure that all examples in one signature
class are sufﬁciently distinct from all ex-
amples in other signature classes.

2.2 Scale and Rotation Invariance

Raw input to the algorithm consists of a se-
quence of screen coordinates along the path
of the user’s signature provided by the OS. For
the sequence of coordinates pro-
instance,
duced when drawing the letter ’M’
is shown
below.
To ensure that the algorithm recognizes sig-
natures independent of rotation, we transform
the provided screen coordinates to a feature
vector that is rotation-invariant. Speciﬁcally,
we track the direction of the signature, relative

1

dinterp
, j ∈{ 1, 2, ...n}1 at which we’d like
j
to have direction information uinterp
, j ∈
j
1, 2, ...n, we linearly interpolate the di ’s and
ui ’s to calculate the uinterp
’s.
j
Finally, we calculate the elements of our
feature vector, x as:

1 uinterp
xj = cos−1 (uT
j

)

The feature vector extracted from the signa-
ture plotted in Figure 1 is shown in Figure 2

Figure 2: Features for One Example of Letter
’M’

2.3 Outlier Detection

When users enter a signature,
there is no
guarantee that they will enter a valid signature.
They could enter an outlier, a signature that
does not match any of the deﬁned classes.
Thus, a generative model was selected so that
P (x), the likelihood of seeing a given feature
vector could be computed and used to detect

1For
this
[0.2, 0.4, 0.6, 0.8]T

project,we

use

dinterp

=

2

Figure 1: Screen Coordinates while Drawing
the Letter ’M’

to the initial direction. Fur thermore, to ensure
that the algorithm recognizes signatures inde-
pendent of scale, the feature vectors list this
direction as a function of the fraction of total
distance travelled.
Speciﬁcally, let zi , i ∈{ 1, 2, ...m} be the ith
screen coordinate in the signature. The total
distance travelled is computed as:
m−1￿i=1
We then normalize the distance between
each point by the total distance travelled:

||zi+1 − zi ||

D =

di = ||zi+1 − zi ||
D

, i ∈{ 1, 2, ...m − 1}
and compute the direction between sequen-
tial points:

ui =

zi+1 − zi
||zi+1 − zi ||
Then, given a set of normalized distances

, i ∈{ 1, 2, ...m − 1}

outliers. Speciﬁcally, the Gaussian Discrimi-
nant Analysis model was used:
x|yi ∼ N (µi , Σ)
y ∼ M ultinomial(φ)
Here y is our vector of signature classes.
The threshold P (x), below which the soft-
ware considers a test example to be an out-
lier, is set to the minimum P (x(i) ) out of all the
x(i) ’s in the training set.

2.4 Distinctness Detection

One of the ﬁrst training sets collected con-
sisted of approximately 20 examples each of
the letters ’M’ and ’N’. Running leave-one-
out cross-validation (LOOCV) on this dataset
with an early implementation of the algorithm
gave a test error of 34%, unacceptably high.
Projecting the data into a 2-dimensional sub-
space selected by PCA and plotting in Figure
3 clearly shows the problem.

Figure 3: Feature Vectors Projected into 2D
Subspace

There is signiﬁcant overlap in training exam-
ples from each class using the feature vectors

3

described above. There are two ways to re-
solve this problem:

1. Modify the feature vectors so that ’M’ and
’N’ are more distinct.

2. Add a check to ensure that examples in
different classes are sufﬁciently distinct
from one another that they will not eas-
ily be confused.

While the ﬁrst modiﬁcation may help with
these examples, there is no guarantee that it
would help with all examples that users could
enter.
It would still be possible, for instance,
for users to enter identical examples (in fea-
ture space) for two different signature classes.
Thus,
the second option was chosen. Af-
ter each training example is entered, we run
LOOCV on the training set and ensure that the
test error is zero.

3 Implementation

The app was implemented using a combina-
tion of C++ and Objective-C. It requires the
iOS 4.2 SDK. Feature extraction is handled in
the C++ class DirectionVsDistanceMovedSig-
nature, while training and testing are imple-
mented in SignatureRecognizerGda. The app
will run in the iPad simulator included in the
iOS SDK, but it is much easier to enter con-
sistent training data using one’s ﬁnger on an
iPad than using a mouse in the iPad simula-
tor. The interface was designed to be used in
landscape mode.
Evaluating a multivariate Gaussian param-
eterized by covariance matrix Σ and mean µ
at a point x requires computing Σ−1 (x − µ)
and |Σ|. The LAPACK function dgetrf() was
used to perform LU decomposition of Σ, and

of values from,
for instance, dinterp =
[.01, 0.02, ...0.99]T . Care must be taken,
however, to include enough features that
outliers are not easily confused with valid
examples.

then dgetrs() was used to solve the system of
equations required to compute Σ−1 (x − µ).
The determinant is easily computed from the
product of the diagonals of the U factor, but
in reality it is not needed. When computing
P (y |x) = P (x|y)P (y)
for classiﬁcation, the nor-
P (x)
malization constant for the Gaussians cancel.
For outlier detection, all of the P (x(i) )’s for the
training examples x(i) ’s and P (x) for test ex-
ample x will be scaled by the same normaliza-
tion constant ((2π)n/2 |Σ|1/2 )−1 so it is ignored
(i.e. we actually threshold on “unnormalized
P (x)”).

4 Future Work

There is ample room for future work. Several
avenues include:
1. Evaluating other models such as hid-
den Markov models that might be better
suited to sequential data.

2. Improving how we handle failures in the
LOOCV-based distinctness test. Cur-
rently, if after the user enters a new train-
ing example,
the new training set fails
LOOCV, we simply block the user from
entering test mode. We make no effor t
to either automatically or with user input
reject the new training example. A better
approach to distinctness failures might be
to run a clustering algorithm on the train-
ing set to try and detect mis-labeled ex-
amples. The user might then be given the
option of re-labeling or rejecting an exam-
ple.

3. Instead of using a constant dinterp =
[0.2, 0.4, 0.6, 0.8]T to compute feature
vectors, applying a feature selection al-
gorithm to ﬁnd the most relevant subsets

4

