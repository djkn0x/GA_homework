Globally Convergent Dual MAP LP Relaxation
Solvers using Fenchel-Young Margins

Alexander G. Schwing
ETH Zurich
aschwing@inf.ethz.ch

Marc Pollefeys
ETH Zurich
pomarc@inf.ethz.ch

Tamir Hazan
TTI Chicago
tamir@ttic.edu

Raquel Urtasun
TTI Chicago
rurtasun@ttic.edu

Abstract
While ﬁnding the exact solution for the MAP inference problem is intractable for
many real-world tasks, MAP LP relaxations have been shown to be very effective
in practice. However, the most efﬁcient methods that perform block coordinate
descent can get stuck in sub-optimal points as they are not globally convergent.
In this work we propose to augment these algorithms with an -descent approach
and present a method to efﬁciently optimize for a descent direction in the sub-
differential using a margin-based formulation of the Fenchel-Young duality the-
orem. Furthermore, the presented approach provides a methodology to construct
a primal optimal solution from its dual optimal counterpart. We demonstrate the
efﬁciency of the presented approach on spin glass models and protein interaction
problems and show that our approach outperforms state-of-the-art solvers.

1
Introduction
Graphical models are a common method to describe the dependencies of a joint probability distribu-
tion over a set of discrete random variables. Finding the most likely conﬁguration of a distribution
deﬁned by such a model, i.e., the maximum a-posteriori (MAP) assignment, is one of the most
important inference tasks. Unfortunately, it is a computationally hard problem for many interest-
ing applications. However, it has been shown that linear programming (LP) relaxations recover the
MAP assignment in many cases of interest (e.g., [13, 23]).
Due to the large amount of variables and constraints, solving inference problems in practice still re-
mains a challenge for standard LP solvers. Development of speciﬁcally tailored algorithms has since
become a growing area of research. Many of these designed solvers consider the dual program, thus
they are based on local updates that follow the graphical model structure, which ensures suitability
for very large problems. Unfortunately, the dual program is non-smooth, hence introducing difﬁcul-
ties to existing solvers. For example, block coordinate descent algorithms, typically referred to as
convex max-product, monotonically decrease the dual objective and converge very fast, but are not
guaranteed to reach the global optimum of the dual program [3, 6, 11, 14, 17, 20, 22, 24, 25]. Dif-
ferent approaches to overcome the sub-optimality of the convex max-product introduced different
perturbed programs for which convergence to the dual optimum is guaranteed, e.g., smoothing, prox-
imal methods and augmented Lagrangian methods [6, 7, 8, 16, 18, 19, 27]. However, since these
algorithms consider a perturbed program they are typically slower than the convex max-product
variants [8, 18].
In this work we propose to augment the convex max-product algorithm with a steepest -descent
approach to monotonically decrease the dual objective until reaching the global optimum of the dual
program. To perform the -descent we explore the -subgradients of the dual program, and provide
a method to search for a descent direction in the -subdifferential using a margin-based formula-
tion of the Fenchel-Young duality theorem. This characterization also provides a new algorithm to

1

construct a primal optimal solution for the LP relaxation from a dual optimal solution. We demon-
strate the effectiveness of our approach on spin glass models and protein-protein interactions taken
from the probabilistic inference challenge (PIC 2011)1 . We illustrate that the method exhibits nice
convergence properties while possessing optimality certiﬁcates.
We begin by introducing the notation, MAP LP relaxations and their dual programs. We subse-
quently describe the subgradients of the dual and provide an efﬁcient procedure to recover a primal
optimal solution. We explore the -subgradients of the dual objective, and introduce an efﬁcient
globally convergent dual solver based on the -margin of the Fenchel-Young duality theorem. Fi-
nally, we extend our approach to graphical models over general region graphs.
2 Background
Graphical models encode joint distributions over discrete product spaces X = X1 × · · · × Xn . The
joint probability is deﬁned by combining energy functions over subsets of variables. Throughout
this work we consider two types of functions: single variable functions, θi (xi ), which correspond
p(x) ∝ exp((cid:80)
i∈V θi (xi ) + (cid:80)
to the n vertices in the graph, i ∈ {1, ..., n}, and functions over subsets of variables θα (xα ), for
α ⊂ {1, .., n}, that correspond to the graph hyperedges. The joint distribution is then given by
α∈E θα (xα )). In this paper we focus on estimating the MAP, i.e.,
(cid:88)
(cid:88)
ﬁnding the assignment that maximizes the probability, or equivalently minimizes the energy which
is the negative log probability. Estimating the MAP can be written as a program of the form [10]:
i∈V
α∈E

argmax
x1 ,...,xn

θi (xi ) +

θα (xα ).

(1)

bi (xi ) = 1,

bα (xα ) = 1,

bα (xα ) = bi (xi ).

Due to its combinatorial nature, this problem is NP-hard for general graphical models. It is tractable
only in some special cases such as tree structured graphs, where specialized dynamic programming
algorithms (e.g., max-product belief propagation) are guaranteed to recover the optimum.
The MAP program in Eq. (1) has a linear form, thus it is naturally represented as an integer linear
(cid:88)
(cid:88)
program. Its tractable relaxation is obtained by replacing the integral constraints with non-negativity
constraints as follows:
(cid:88)
(cid:88)
(cid:88)
max
bα (xα )θα (xα ) +
bi (xi )θi (xi )
bi ,bα
α,xα
i,xi
s.t. bi (xi ), bα (xα ) ≥ 0,
xα \xi
xα
xi
Whenever the maximizing argument to above linear program happens to be integral, i.e., the optimal
beliefs satisfy bi (xi ), bα (xα ) ∈ {0, 1}, the program value equals the MAP value. Moreover, the
maximum arguments of the optimal beliefs point toward the MAP assignment [26].
 .
θα (xα ) − (cid:88)
 +
θi (xi ) +
We denote by N (i) the edges that contain vertex i and by N (α) the vertices in the edge α. Following
(cid:88)
(cid:88)
(cid:88)
[22, 27] we consider the re-parametrized dual
λi→α (xi )
λi→α (xi )
α∈N (i)
i∈N (α)
α
i
The dual program value upper bounds the primal program described in Eq. (2). Therefore to compute
the primal optimal value one can minimize the dual upper bound. Using block coordinate descent
on the dual objective amounts to optimizing blocks of dual variables while holding the remaining
ones ﬁxed. This results in the convex max-product message-passing update rules [6, 17]:
(cid:111)
(cid:110)
(cid:88)
Repeat until convergence, for every i = 1, ..., n:
∀xi , α ∈ N (i) µα→i (xi ) = max
(cid:16)
(cid:17) − µα→i (xi )
λj→α (xj )
(cid:88)
θα (xα ) +
xα \xi
j∈N (α)\i
µβ→i (xi )
θi (xi ) +
β∈N (i)

∀xi , α ∈ N (i) λi→α (xi ) =

1
1 + |N (i)|

q(λ) =

max
xi

(2)

(3)

max
xα

1 http://www.cs.huji.ac.il/project/PASCAL/index.php

2

The convex max-product algorithm is guaranteed to converge since it minimizes the dual function,
which is lower bounded by the primal program. Interestingly, the convex max-product shares the
same complexity as the max-product belief propagation, which is attained by replacing the coef-
ﬁcient 1/(1 + |N (i)|) by 1. It has, however, two fundamental problems. First, it can get stuck
in non-optimal stationary points. This happens since the dual objective is non-smooth, thus the
algorithm can reach a corner, for which the dual objective stays ﬁxed when changing only a few
variables. For example, consider the case of a minimization problem where we try to descend from
a pyramid while taking only horizontal and vertical paths. We eventually stay at the same height.
The second drawback of convex max-product is that it does not always produce a primal optimal
solution, bi (xi ), bα (xα ), even when it reaches a dual optimal solution.
In the next section, we consider the dual subgradients, and provide an efﬁcient algorithm for detect-
ing corners, as well as for decoding a primal optimal solution from a dual optimal solution. This is
an intermediate step which facilitates the margin analysis of the Fenchel-Young duality theorem in
Sec. 4. It provides an efﬁcient way to get out of corners, and to reach the optimal dual value.
3 The Subgradients of the Dual Objective and Steepest Descent
Subgradients are generalizations of gradients for non-smooth convex functions. Consider the func-
tion q(λ) in Eq. (3). A vector d is called a subgradient of q(λ) if it supports the epigraph of q(λ) at
λ, i.e.,
∀ˆλ
q(ˆλ) − d(cid:62) ˆλ ≥ q(λ) − d(cid:62)λ.
(4)
The supporting hyperplane at (λ, q(λ)) with slope d takes the form d(cid:62)λ − q∗ (d), when deﬁning
the conjugate dual as q∗ (d) = maxλ {d(cid:62)λ − q(λ)}. From the deﬁnition of q∗ (d) one can derive
the Fenchel-Young duality theorem: q(λ) + q∗ (d) ≥ d(cid:62)λ, where equality holds if and only if d
is a supporting hyperplane at (λ, q(λ)). The set of all subgradients is called the subdifferential,
denoted by ∂ q(λ), which can be characterized using the Fenchel-Young theorem as ∂ q(λ) = {d :
q(λ) + q∗ (d) = λ(cid:62)d}. The subdifferential provides a way to reason about the optimal solutions of
q(λ). Using Eq. (4) we can verify that λ is dual optimal if and only if 0 ∈ ∂ q(λ). In the following
claim we characterize the subdifferential of the dual function q(λ) using the Fenchel-Young duality
(cid:80)
α = argmaxxα {θα (xα ) + (cid:80)
theorem:
i = argmaxxi {θi (xi ) −
and only if di→α (xi ) = (cid:80)
Claim 1. Consider the dual function q(λ) given in Eq. (3). Let X ∗
α∈N (i) λi→α (xi )} and X ∗
i∈N (α) λi→α (xi )}. Then d ∈ ∂ q(λ), if
bα (xα ) − bi (xi ) for probability distributions bi (xi ), bα (xα ) whose
xα \xi
nonzero entries belong to X ∗
i , X ∗
α respectively.
Proof: Using the Fenchel-Young characterization of Eq. (4) for the max-function we obtain the set
α . Summing over all regions r ∈ {i, α} while noticing the change
of maximizing elements X ∗
i , X ∗
of sign, we obtain the marginalization disagreements di→α (xi ).
The convex max-product algorithm performs block coordinate descent updates. Thus it iterates
over vertices i and computes optimal solutions λi→α (xi ) for every xi , α ∈ N (i) analytically, while
holding the rest of the variables ﬁxed. The claim above implies that the convex max-product iterates
over i and generates beliefs bi (xi ), bα (xα ) for every xi , α ∈ N (i) that agree on their marginal
probabilities. This interpretation provides an insight into the non-optimal stationary points of the
convex max-product, i.e., points for which it is not able to generate consistent beliefs bα (xα ) when
it iterates over i = 1, . . . , n. The representation of the subdifferential as the amount of disagreement
between the marginalization constraints provides a simple procedure to verify dual optimality, as
well as to construct primal optimal solutions. This is summarized in the corollary below.
α as deﬁned in Claim 1, let x∗
Corollary 1. Given a point λ, and sets X ∗
i , X ∗
i , x∗
(cid:16) (cid:88)
(cid:17)2
α be elements in
(cid:88)
i , X ∗
X ∗
α respectively. Consider the quadratic program
α ) − bi (x∗
bα (x∗
(cid:88)
(cid:88)
min
i )
bi ,bα
α \x∗
i ,α∈N (i)
i,x∗
x∗
i
α ) ≥ 0,
i ), bα (x∗
s.t. bi (x∗
x∗
x∗
α
i
λ is a dual optimal solution if and only if the value of the above program equals zero. Moreover, if
λ is a dual optimal solution, then the optimal beliefs b∗
α (xα ), b∗
i (xi ) are also the optimal solution

bα (x∗
α ) = 1,

bi (x∗
i ) = 1.

3

(cid:80)
of the primal program in Eq. (2). However, if λ is not dual optimal, then the vector d∗
i→α (xi ) =
α ) − b∗
i (x∗
b∗
α (x∗
i ) points towards the steepest descent direction of the dual function, i.e.,
α \x∗
x∗
i
q(λ + αd) − q(λ)
α

d∗ = argmin
(cid:107)d(cid:107)≤1

lim
α↓0

.

max
y∈∂ q

Proof: The steepest descent direction d of q is given by minimizing the directional derivative q (cid:48)
d ,
−(cid:107)y(cid:107)2 ,
q (cid:48)
d(cid:62) y = max
d(cid:62) y = max
min(cid:107)d(cid:107)≤1
d (λ) = min(cid:107)d(cid:107)≤1
min(cid:107)d(cid:107)≤1
y∈∂ q
y∈∂ q
which yields the above program (cf . [2], Chapter 4). If the zero vector is part of the subdifferential,
we are dual optimal. Primal optimality follows from Claim 1.
One can monotonically decrease the dual objective by minimizing it along the steepest descent
direction. Unfortunately, following the steepest descent direction does not guarantee convergence to
the global minimum of the dual function [28]. Performing steepest descent might keep minimizing
the dual objective with smaller and smaller increments, thus converging to a suboptimal solution.
The main drawback of steepest descent as well as block coordinate descent when applied to the dual
objective in Eq. (3) is that both procedures only consider the support of X ∗
i , X ∗
α deﬁned in Claim 1.
In the following we show that by considering the -margin of these supports we can guarantee that
at every iteration we decrease the dual value by at least . This procedure results in an efﬁcient
algorithm that reaches both dual and primal optimal solutions.

4 The -Subgradients of the Dual Objective and Steepest -Descent
To monotonically decrease the dual value while converging to the optimum, we suggest to explore
the -neighborhood of the dual objective in Eq. (3) around the current iterate λ. For this purpose, we
explore its family of -subgradients. Given our convex dual function q(λ) and a positive scalar , we
say that a vector d is an -subgradient at λ if it supports the epigraph of q(λ) with an -margin:
∀ˆλ
q(ˆλ) − d(cid:62) ˆλ ≥ q(λ) − d(cid:62)λ − .

(5)

The subgradients of a convex function are also -subgradients. The family of -subgradients is called
the -subdifferential and is denoted by ∂ q(λ). Using the conjugate dual q∗ (d), we can characterize
(cid:111)
(cid:110)
the -subdifferential by employing the -margin Fenchel-Young duality theorem.
d : 0 ≤ q(λ) + q∗ (d) − d(cid:62)λ ≤ 

(-margin Fenchel-Young duality)

(6)

∂ q(λ) =

The -subdifferential augments the subdifferential of q(λ) with additional directions d which control
the -neighborhood of the function. Whenever one ﬁnds a steepest descent direction within ∂ q(λ),
it is guaranteed to improve the dual objective by at least . Moreover, if one cannot ﬁnd such a
direction within the -subdifferential, then q(λ) is guaranteed to be -close to the dual optimum.
This is summarized in the following claim.
Claim 2. Let q(λ) be a convex function and let  be a positive scalar. The -subdifferential ∂ q(λ) is
a convex and compact set. If 0 (cid:54)∈ ∂ q(λ) then the direction d∗ = argmin (cid:107)d(cid:107) subject to d ∈ ∂ q(λ)
is a descent direction and inf α>0 q(λ − αd) < q(λ) − . On the other hand, if 0 ∈ ∂ q(λ) then
q(λ) ≤ inf λ q(λ) + .
Proof: [2] Proposition 4.3.1.
convex functions, i.e., q(λ) = (cid:80)m
r=1 qr (λ). The approximation ˜∂ q(λ) = (cid:80)
Although ∂ q(λ) is a convex and compact set, ﬁnding its direction of descent is computationally
challenging. Fortunately, it can be approximated whenever the convex function is a sum of simple
r ∂ qr (λ) satisﬁes
∂ q(λ) ⊂ ˜∂ q(λ) ⊂ ∂m q(λ), (see, e.g., [2]). On the one hand, if 0 (cid:54)∈ ˜∂ q(λ) then the direction of
steepest descent taken from ˜∂ q(λ) reduces the dual objective by at least . If 0 ∈ ˜∂ q(λ) then q(λ)
is m-close to the dual optimum. In the following claim we use the -margin Fenchel-Young duality
in Eq. (6) to characterize the approximated -subdifferential of the dual function.

4

∀α

max
xα

bα (xα )

only if di→α (xi ) = (cid:80)
Claim 3. Consider the dual function q(λ) in Eq. (3). Then the approximated -subdifferential con-
sists of vectors d whose entries correspond to marginalization disagreements, i.e., d ∈ ˜∂ q(λ) if and
 −  ≤ (cid:88)
θi (xi ) − (cid:88)
θi (xi ) − (cid:88)

bα (xα ) − bi (xi ) for probability distributions bi (xi ), bα (xα ) that satisfy
xα \xi
∀i
 −  ≤ (cid:88)
θα (xα ) +
 .
θα (xα ) +
λi→α (xi )
λi→α (xi )
bi (xi )
max
(cid:88)
(cid:88)
xi
α∈N (i)
α∈N (i)
xi
λi→α (xi )
λi→α (xi )
i∈N (α)
i∈N (α)
xα
Proof: Eq. (6) implies b ∈ ∂ qr ( ˆθ) if and only if qr ( ˆθ) + q∗
r (b) − b(cid:62) ˆθ ≤  with q∗
r (b) denoting the
and qi we obtain the marginalization disagreements di→α (xi ) = (cid:80)
conjugate dual of qr ( ˆθ). Plugging in qr , q∗
r we obtain not only the maximizing beliefs but all beliefs
with an -margin. Summing over r ∈ {i, α} while noticing that λi→α (xi ) change signs between qα
bα (xα ) − bi (xi ).
xα \xi
˜∂ q(λ) is described using beliefs bi (xi ), bα (xα ) that satisfy linear constraints, therefore ﬁnding a
direction of -descent can be done efﬁciently. Claim 2 ensures that minimizing the dual objec-
tive along a direction of descent decreases its value by at least . Moreover, we are guaranteed to be
(|V | + |E |)-close to a dual optimal solution if no direction of descent is found in ˜∂ q(λ). Therefore,
we are able to get out of corners and efﬁciently reach an approximated dual optimal solution. The
interpretation of the Fenchel-Young margin as the amount of disagreement between the marginaliza-
Corollary 2. Given a point λ, set ˆθi (xi ) = θi (xi ) − (cid:80)
tion constraints also provides a simple way to reconstruct an approximately optimal primal solution.
(cid:80)
This is summarized in the following corollary.
α∈N (i) λi→α (xi ) and ˆθα (xα ) = θα (xα ) +
(cid:17)2
(cid:16) (cid:88)
(cid:88)
i∈N (α) λi→α (xi ). Consider the quadratic program
bα (xα ) − bi (xi )
(cid:88)
(cid:88)
min
bi ,bα
i,xi ,α∈N (i)
xα \xi
s.t. bi (xi ), bα (xα ) ≥ 0,
(cid:88)
(cid:88)
bi (xi ) = 1
xα
xi
{ ˆθα (xα )} − .
bα (xα ) ˆθα (xα ) ≥ max
bi (xi ) ˆθi (xi ) ≥ max
{ ˆθi (xi )} − ,
xi
xα
xα
xi
q(λ) is (|V | + |E |)-close to the dual optimal value if and only if the value of the above program
i→α (xi ) = (cid:80)
i (xi ) primal value is (|V | + |E |)-close to the
equals zero. Moreover, the optimal beliefs b∗
α (xα ), b∗
optimal primal value in Eq. (2). However, if q(λ) is not (|V | + |E |)-close to the dual optimal value
α (xα ) − b∗
then the vector d∗
b∗
i (xi ) points towards the steepest -descent direction
xα \xi
of the function, namely
q(λ + αd) − q(λ) + 
d∗ = argmin
(cid:107)d(cid:107)≤1
α
Proof: The steepest -descent direction is given by the minimum norm element of the -
subdifferential, described in Claim 3. (|V | + |E |)-closeness to the dual optimum is given by ([2],
Proposition 4.3.1) once we ﬁnd the value of the quadratic program to be zero. Note that the superset
˜∂ is composed of |V | + |E | subdifferentials. If the value of the above program equals zero, the
bα (xα ) ˆθα (xα ) ≥ (cid:88)
(cid:88)
(cid:88)
(cid:88)
beliefs fulﬁll marginalization constraints and they denote a probability distribution. Summing both
-margin inequalities w.r.t. i, α, we obtain
bi (xi ) ˆθi (xi ) +
α
α,xα
i,xi
i
where the primal on the left hand side of the resulting inequality is larger then the dual subtracted
by (|V | + |E |). With the dual itself upper bounding the primal, the corollary follows.
Thus, we can construct an algorithm that performs  improvements over the dual function in each
iteration. We can either perform block-coordinate dual descent (i.e., convex max-product updates)
or steepest -descent steps. Since both methods monotonically improve the same dual function, our
approach is guaranteed to reach the optimal dual solution and to recover the primal optimal solution.

ˆθα (xα ) − (|V | + |E |).

bα (xα ) = 1,

ˆθi (xi ) +

max
xi

max
xα

lim
α↓0

.

5

(7)

q(λ) =

max
xr

λr→p (xr )

(b)
(a)
Figure 1: (a) Difference between the minimal dual value attained by convex max-product q(λCMP )
and our approach q(λ ). Convex max-product gets stuck in about 20% of all cases. (b) Dual value
achieved after a certain amount of time for cases where convex max-product gets stuck.
5 High-Order Region Graphs
Graphical models naturally describe probability distributions with different types of regions r ⊂
{1, ..., n}. However, the linear program relaxation described in Eq. (2) considers interactions be-
tween regions which correspond to variables i and regions that correspond to cliques α.
In the
following we extend the -descent framework when considering linear programming relaxations
without constraining the region interactions. Since we allow any regions to interact, we denote these
interactions through a region graph [29]. A region graph is a directed graph whose nodes represent
the regions and its direct edges correspond to the inclusion relation, i.e., a directed edge from node
r to s is possible only if s ⊂ r . We adopt the terminology where P (r) and C (r) stand for all nodes
that are parents and children of the node r , respectively. Thus we consider the linear programming
(cid:88)
relaxation of a general high-order graphical model as follows
(cid:88)
(cid:88)
br (xr )θr (xr )
max
b
r,xr
s.t. br (xr ) ≥ 0,
∀r, s ∈ P (r)
br (xr ) = 1,
xs \xr
xr
(cid:110)
(cid:88)
λc→r (xc ) − (cid:88)
(cid:88)
Following [5, 22, 27] we consider the re-parametrized dual program
θr (xr ) +
c∈C (r)
p∈P (r)
r
which is a sum of max-functions. Its approximated -subdifferential is described with respect to
their Fenchel-Young margins. Using the same reasoning as in Sec. 4 we present a simple way to
Corollary 3. Given a point λ, set ˆθr (xr ) = θr (xr ) + (cid:80)
c∈C (r) λc→r (xr ) − (cid:80)
recover an -steepest descent direction, as well as to reconstruct an approximated optimal primal
solution.
p∈P (r) λr→p (xr ).
(cid:16) (cid:88)
(cid:17)2
(cid:88)
Consider the quadratic program
bp (xp ) − br (xr )
(cid:88)
(cid:88)
r,xr ,p∈P (r)
xp \xr
br (xr ) ≥ 0,
br (xr ) ˆθr (xr ) ≥ max
xr
xr
xr
Let |R| be the total number of regions in the graph, then λ is |R|-close to the dual optimal solution
r→p (xr ) = (cid:80)
if and only if the value of the above program equals zero. Moreover, the optimal beliefs b∗
r (xr ) are
also |R|-close to the optimal solution of the primal program in Eq. (7). However, if q(λ) is not
|R| close to the dual optimal solution then the vector d∗
p (xp ) − b∗
b∗
r (xr ) points
xp \xr
towards the steepest -descent direction of the dual function.
Proof: It is a straightforward generalization of Corollary 2.
When dealing with high-order region graphs, one can choose a region graph, e.g., the Hasse diagram,
that has signiﬁcantly less edges than a region graph that connects variables i to cliques α. Therefore,
when considering many high-order regions, the formulation in the above corollary is more efﬁcient
than the one in Corollary 2.

bs (xs ) = br (xr )
(cid:111)

{ ˆθr (xr )} − 

minb

s.t.

br (xr ) = 1,

6

]
s
[

e
m
i
t

]
s
[

e
m
i
t



(c)
(b)
(a)
Figure 2: Average time required for different solvers to achieve a speciﬁed accuracy on 30 spin glass
models, (a) when solvers are applied to “hard” problems only, i.e., those where CMP gets stuck far
from the optimum. Average results over 30 models are shown in (b), (c) decrease of the dual value
over time for ADLP and our -descent approach.

6 Experimental Evaluation

To beneﬁt from the efﬁciency of convex max-product, our implementation starts by employing
block-coordinate descent iterations before switching to the globally convergent -descent approach
once the dual value decreases by less than  = 0.01. As we always optimize the same cost func-
tion, switching the gradient computation is possible. We employ a backtracking line search in our
-descent approach. In the following we demonstrate the effectiveness of our approach on synthetic
10x10 spin glass models as well as protein interactions from the probabilistic inference challenge
(PIC 2011). We consider spin glass models that consist of local factors, each having 3 states with
values randomly chosen according to N (0, 1). We use three states as convex max-product is optimal
for pairwise spin glass models with only two states per random variable. The pairwise factors of the
regular grid are weighted potentials with +1 on the diagonal and off-diagonal entries being −1. The
weights are again independently drawn from N (0, 1). In the ﬁrst experiment we are interested in
estimating how often convex max-product gets stuck in corners. We generate a set of 1000 spin glass
models and estimate the distribution of the dual value difference comparing the -descent approach
with the convex max-product result after 10, 000 iterations. We observe in Fig. 1(a) that about 20%
of the spin glass models have a dual value difference larger than zero.
Having observed that convex max-product does not achieve optimality for 20% of the models, we
now turn our attention to evaluating the run-time of different algorithms. We compare our imple-
mentation of the -steepest descent algorithm with the alternating direction method for dual MAP-
LP relaxations (ADLP) [18].
In addition, we illustrate the performance of convex max-product
(CMP) [6] and compare against the dual-decomposition work of [12] provided in a generic (DDG)
and a re-weighted (DDR) version in the STAIR library [4]. Note that ADLP is also implemented in
this library. All algorithms are restricted to at most 20, 000 iterations. We draw the readers attention
to Fig. 1(b), where we evaluate a single spin glass model and illustrate the dual value obtained after
a certain amount of time. As given by the derivations, CMP is a monotonically decreasing algorithm
that can get stuck in corners. It is important to note that our -descent approach is monotonically
decreasing as well, which contrasts all the other investigated algorithms (ADLP, DDG, DDR).
We evaluate the time it requires the different algorithms to achieve a given accuracy. We ﬁrst focus
on “hard” problems, where we deﬁned “hard” as those spin glass models whose difference between
convex max-product and the -descent method is larger than 0.2. To obtain statistically meaningful
results we average over 30 hard problems and report the time to achieve a given accuracy in Fig. 2(a).
We used the minimum across all dual values found by all algorithms as the optimum. If an algorithm
does not achieve -close accuracy within 20,000 iterations we set its time to the arbitrarily chosen
value of 105 . We note that CMP is very fast for low accuracies (high ) but gets stuck in corners,
not achieving high accuracies (low ). This is also the case for DDG and DDR. ADLP achieves
signiﬁcantly lower -closeness but the 20, 000 iteration limit stops it from reaching 10−3 . The
previous experiment focus on hard problems. In order to evaluate the average case, we randomly
generate 30 spin glass models. The results are provided in Fig. 2(b). As expected the -descent
approach performs similarly well, ADLP achieves lower accuracies on more samples. The step
apparent for CMP, DDG and DDR is not as sharp, but still very signiﬁcant.
Protein interactions: We rely on the data provided by the PIC 2011 and compare the -descent
approach to ADLP as it is the most competitive method in the previous experiments. The dual
energy obtained after a given amount of time is illustrated in Fig. 2(c).

7

7 Related Work
We explore methods to solve LP relaxations by monotonically decreasing the value of its dual ob-
jective and reconstructing a primal optimal solution. For this purpose we investigate approximated
subgradients of the dual program using the Fenchel-Young margins, and provide a method to reduce
the dual objective in every step by a constant value until convergence to the optimum. Efﬁcient dual
solvers were extensively studied in the context of LP relaxations for the MAP problem [14, 20, 25].
The dual program is non-smooth, thus subgradient descent algorithms are guaranteed to reach the
dual optimum [12], as well as recover the primal optimum [12]. Despite their theoretical guarantees,
subgradient methods are typically slow. Dual block coordinate descent methods, typically referred
to as convex max-product algorithms, are monotonically decreasing, and were shown to be faster
than subgradient methods [3, 6, 11, 17, 22, 24, 27]. Since the dual program is non-smooth, these
algorithms can get stuck in non-optimal stationary points and cannot in general recover a primal
optimal solution [26]. Our work speciﬁcally addresses these drawbacks.
Recently, several methods were devised to overcome the sub-optimality of convex max-product
algorithms. Unlike our approach, all these algorithms optimize a perturbed program. Some methods
use the soft-max with low temperature to smooth the dual objective in order to avoid corners as well
as to recover primal optimal solutions [6, 7, 8]. However, these methods are typically slower, as
computation of the low-temperature soft-max is more expensive than max-computation. [19] applied
the proximal method, employing a primal strictly concave perturbation, which results in a smooth
dual approximation that is temperature independent. This approach converges to the dual optimum
and recovers the primal optimal solution. However, it uses a double loop scheme where every
update involves executing a convex sum-product algorithm. Alternative methods applied augmented
Lagrangian techniques to the primal [16] and the dual programs [18]. The augmented Lagrangian
method guarantees to reach the global optimum and recover the dual and primal solutions. Unlike
our approach, this method is not monotonically decreasing and works on a perturbed objective, thus
cannot be efﬁciently integrated with convex max-product updates that perform block coordinate
descent on the dual of the LP relaxation.
Our approach is based on the -descent algorithm for convex functions [2]. We use the -margin
of the Fenchel-Young duality theorem to adjust the -subdifferential to the dual objective of the
LP relaxation, thus augmenting the convex max-product with the ability to get out of corners. We
also construct an efﬁcient method to recover a primal optimal solution. Our approach is related
to the Bundle method [15, 9], which performs an -subgradient descent in cases where efﬁcient
search in the -subdifferential is impossible. The graphical model structure in our setting makes
searching in the -subdifferential easy, thus our approach is signiﬁcantly faster. Our algorithm satis-
ﬁes -complementary slackness while performing -descent step, similarly to the auction algorithm.
However, our algorithm is monotonically decreasing and can be used for general graphical models,
while the auction algorithm might increase its dual and its convergence properties hold only for
network ﬂow problems.
8 Conclusions and Discussion
Evaluating the MAP assignment and solving its LP relaxations are key problems in approximate
inference. Some of the existing solvers, such as convex max-product, have limitations. Mainly, these
solvers can get stuck in a non-optimal stationary point, thus they cannot recover the primal optimal
solution. We explore the properties of subgradients of the dual objective and construct a simple
algorithm that determines if the dual stationary point is optimal and recovers the primal optimal
solution in this case (Corollary 1). Moreover, we investigate the family of -subgradients using
Fenchel-Young margins and construct a monotonically decreasing algorithm that is guaranteed to
achieve optimal dual and primal solutions (Corollary 2), including general region graphs (Corollary
3). We show that our algorithm compares favorably with pervious methods on spin glass models
and protein interactions. The approximated steepest descent direction is recovered by solving a
quadratic program subject to linear constraints. We used the Gurobi solver2 , which ignores the
graphical structure of the linear constraints. We believe that constructing a message-passing solver
for this sub-problem will signiﬁcantly speed-up our approach. Further extensions, e.g., enforcing
constraints over messages such as those arising from cloud computing are also applicable to our
setting [1, 21].

2 http://www.gurobi.com

8

References
[1] A. Auslender and M. Teboulle. Interior gradient and epsilon-subgradient descent methods for constrained
convex minimization. Mathematics of Operations Research, 2004.
[2] D. P. Bertsekas, A. Nedi ´c, and A. E. Ozdaglar. Convex Analysis and Optimization. Athena Scientiﬁc,
2003.
[3] A. Globerson and T. S. Jaakkola. Fixing max-product: convergent message passing algorithms for MAP
relaxations. In Proc. NIPS, 2007.
[4] S. Gould, O. Russakovsky, I. Goodfellow, P. Baumstarck, A. Y. Ng, and D. Koller. The STAIR Vision
Library (v2.4), 2011. http://ai.stanford.edu/ sgould/svl.
[5] T. Hazan, J. Peng, and A. Shashua. Tightening fractional covering upper bounds on the partition function
for high-order region graphs. In Proc. UAI, 2012.
[6] T. Hazan and A. Shashua. Norm-product belief propagation: Primal-dual message-passing for approxi-
mate inference. Trans. on Information Theory, 2010.
[7] J. K. Johnson. Convex relaxation methods for graphical models: Lagrangian and maximum entropy
approaches. PhD thesis, Massachusetts Institute of Technology, 2008.
[8] V. Jojic, S. Gould, and D. Koller. Accelerated dual decomposition for MAP inference. In Proc. ICML,
2010.
[9] J. H. Kappes, B. Savchynskyy, and C. Schn ¨orr. A Bundle Approach To Efﬁcient MAP-Inference by
Lagrangian Relaxation. In Proc. CVPR, 2012.
[10] D. Koller and N. Friedman. Probabilistic graphical models. MIT Press, 2009.
[11] V. Kolmogorov. Convergent tree-reweighted message passing for energy minimization. PAMI, 2006.
[12] N. Komodakis, N. Paragios, and G. Tziritas. MRF Energy Minimization & Beyond via Dual Decomposi-
tion. PAMI, 2010.
[13] T. Koo, A.M. Rush, M. Collins, T. Jaakkola, and D. Sontag. Dual decomposition for parsing with non-
projective head automata. In Proc. EMNLP, 2010.
[14] A.M.C.A. Koster, S.P.M. van Hoesel, and A.W.J. Kolen. The partial constraint satisfaction problem:
Facets and lifting theorems. Operations Research Letters, 1998.
[15] C. Lemar ´echal. An algorithm for minimizing convex functions. Information processing, 1974.
[16] A.F.T. Martins, M.A.T. Figueiredo, P.M.Q. Aguiar, N.A. Smith, and E.P. Xing. An Augmented La-
grangian Approach to Constrained MAP Inference. In Proc. ICML, 2011.
[17] T. Meltzer, A. Globerson, and Y. Weiss. Convergent Message Passing Algorithms – A Unifying View. In
Proc. UAI, 2009.
[18] O. Meshi and A. Globerson. An Alternating Direction Method for Dual MAP LP Relaxation. In Proc.
ECML PKDD, 2011.
[19] P. Ravikumar, A. Agarwal, and M. J. Wainwright. Message-passing for graph-structured linear programs:
Proximal methods and rounding schemes. JMLR, 2010.
[20] M. Schlesinger. Syntactic analysis of two-dimensional visual signals in noisy conditions. Kibernetika,76.
[21] A. G. Schwing, T. Hazan, M. Pollefeys, and R. Urtasun. Distributed message passing for large scale
graphical models. In Proc. CVPR, 2011.
[22] D. Sontag and T. S. Jaakkola. Tree block coordinate descent for MAP in graphical models.
AISTATS, 2009.
[23] D. Sontag, T. Meltzer, A. Globerson, T. Jaakkola, and Y. Weiss. Tightening LP relaxations for MAP using
message passing. In Proc. UAI, 2008.
[24] D. Tarlow, D. Batra, P. Kohli, and V. Kolmogorov. Dynamic tree block coordinate ascent. In Proc. ICML,
2011.
[25] M. J. Wainwright, T. S. Jaakkola, and A. S. Willsky. MAP estimation via agreement on trees: message-
passing and linear programming. Trans. on Information Theory, 2005.
[26] Y. Weiss, C. Yanover, and T. Meltzer. MAP Estimation, Linear Programming and Belief Propagation with
Convex Free Energies. In Proc. UAI, 2007.
[27] T. Werner. Revisiting the linear programming relaxation approach to gibbs energy minimization and
weighted constraint satisfaction. PAMI, 2010.
[28] P. Wolfe. A method of conjugate subgradients for minimizing nondifferentiable functions. Nondifferen-
tiable Optimization, 1975.
[29] J. S. Yedidia, W. T. Freeman, and Y. Weiss. Constructing free-energy approximations and generalized
belief propagation algorithms. Trans. on Information Theory, 2005.

In Proc.

9

