1

Predicting  Help-­Seeking  Behavior  in  Students  Learning  to  Program

Engin  Bumbacher,  A lfredo  Sandes,  and  Daniel  Greene

Introduction
Recent work in CS educat ion has leveraged machine-­learning techniques to gain ins ight into the ways in which s tudents
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
approach a given programming ass ignment . P iech et al. (P iech, Sahami, Koller, Cooper, & B liks tein, 2012) c reated a
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
graphical model of how s tudents in an introduc tory programming course progressed through a homework ass ignment .
  
  
  
  
  
  
  
  
  
  
  
  
  
  
They were able to ex trac t charac teris t ic pathways based on “snapshots ” of s tudent codes that were taken every t ime a
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
s tudent at tempted to compile his /her code. The authors also illus trated the relevance of their approach to educat ion by
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
showing that their paths predic ted s tudent midterm grades . This sugges ts that teachers and s tudents may be able to use
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
s tudent   path  data   to  develop   targeted   ins truc t ion.

In a s imilar approach, Helminen et al. (Helminen,
  
  
  
  
  
  
  
Ihantola, Karav irta, & Malmi, 2012) examined the pathways that
  
  
  
  
  
  
  
  
  
s tudents took to solve a collec t ion of scaf folded programming puzz les that require reordering a set of shuf f led lines of
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
code.   They    found  several  charac teris t ic   path  shapes ,    inc luding   loops ,   branches ,   and  dead-­ends .

Encouragingly , all of the work ment ioned so far is also cons is tent with prior research on the psychology of programming
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
(Soloway & Ehrlich, 1984)
  
  
  
that sugges ts that expert programmers have a mental s torehouse of charac teris t ic
  
  
  
  
  
  
  
  
  
  
  
programming idioms , and that they can read and write code in larger conceptual “chunks ” than nov ices . However, s tudent
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
homework ass ignments are unt imed, allow for a range of solut ions , and only examine the f inal produc ts of s tudent work .
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
Thus , a c loser examinat ion of the process by which s tudents complete ass ignments can reveal important dis t inguishing
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
informat ion,   such  as    the  s ize  of   code  “chunks ”   that   get    implemented   in  success ive  updates .

P iech et al. worked with of snapshots of code generated from s tudents in the fall of 2010, but conf irmed s imilar s tudent
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
development paths in data from a summer c lass . However, their work only focuses on the f irs t and s imples t ass ignment
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
of the c lass . Though P iech et al. have been able to predic t midterm grades based on the s tudent paths during this f irs t
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
ass ignment , these results do not of fer any ins ights into when a s tudent needs help at a certain point in his problem
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
solv ing process , or as to whether there is a causal relat ion between teacher help that a s tudent received and his
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
progress ion through the ass ignment . We aim at address ing this ques t ion by doing a f irs t s tudy to look at whether help
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
seek ing behav ior of s tudents correlates with their coding ac t iv it ies for an ass ignment . We use dif ferent ways of
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
represent ing s tudent by the body of code “snapshots ” they wrote during a s ingle ass ignment to predic t whether the
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
s tudent   got    teacher  help  during   the  ent ire  quarter  or  not .
Data  Sources  and  Overall  Goal
We have collec ted a range of data from 514 s tudents enrolled in the Stanford CS106A course on bas ic Java
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
programming.   Our  data  cons is t   of :

-­ Tex t “snapshots ” of every s tudent ’s code, taken every t ime a s tudent tried to compile his /her program. We have data
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
for ass ignments 1 (“Karel the Robot” problems ), 2 (s imple Java graphics and calculat ions ), 3 (a s imple “Breakout”
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
computer game), 4 (the game “Hangman”), and 5 (a graphing program). There are about 7,000 -­ 10,000 snapshots for
  
  
  
  
  
  
  
  
  
  
  
  
  
  
     
  
  
each ass ignment , ac ross all s tudents . For FindRange,
  
the ass ignment analyzed here, we had 8772 ins tances .
  
In
  
  
  
  
  
  
  
  
  
  
  
  
  
FindRange,    the  problem   is    to   f ind   the  max imum  and  minimum  of   a  sequence  of   numbers   and  output    it .

-­ Track ing data from an on-­campus homework help serv ice. Every day , c lass TAs work ing at a computer lab of fer
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
personalized help to s tudents who v is it . The TAs track who v is its and of fer brief notes , inc luding the name of the
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
s tudent , the t ime, and usually the name of the ass ignment . For example, there were around 500 help-­center v is its for
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
ass ignment   4   that   came   from  about   150  dis t inc t   s tudents .

-­ Data from a week ly survey that asks s tudents about their perceived sk ill, perceived dif f iculty of the ass ignment , their
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
help-­seek ing  s trategies ,   and  demographic    informat ion.

This projec t is the s tart of a larger machine-­learning projec t based in the lab of Ass is tant Professor Paulo B liks tein at the
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
School of Educat ion. Our data is potent ially sens it ive, so we had to es tablish IRB approval, anonymize our data, and
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  

2

work ex tens ively with the course professor and TAs . The process of get t ing approval and collec t ing our data took much
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
longer than we thought , so we have had to scale back some of our init ial ambit ions here. So, for example, as this is very
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
new  data,   we  are  s t ill   in   the  process   of   obtaining  all  grades    for   the  course  (ass ignments ,   midterm,   and   f inal   tes t).

In this projec t , we used TA help data ac ross the quarter and data from ass ignment 2 problem 5 (“FindRange”). In the
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
FindRange problem, s tudents are tasked with writ ing a piece of sof tware that will accept an arbitrary lis t of numbers and
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
output
the max imum and minimum. Solut ions to the problem typically take one of two forms -­ a set of condit ional
  
  
  
  
  
  
  
  
  
  
  
  
  
  
     
  
  
  
s tatements nes ted ins ide of a loop, or v ice-­versa. We have a sample of 370 s tudents who completed this problem. For
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
our TA help data, 50% used no TA help, 25% used it 0-­3 t imes , and 25% more than 3. Our goal is to inves t igate whether
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
features of a s tudent ’s set of snapshots can be used to predic t the degree to which he/she sought out help. This can be
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
interpreted  as   an   indirec t   metric   of   a  s tudent   needing  help,   or  as   a  way   of    ident ify ing  a  s tudent   as   a  “help-­seek ing   type”.
Methods
Our process can be broken down into three s tages (see Figure 1): characteriz ing snapshots, characteriz ing students
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
based  on  the  snapshots,   and  classifying  by   intervention  data.

1. Characteriz ing snapshots: Our f irs t s tep was to develop feature sets and metrics for charac teriz ing the data at the
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
level of indiv idual snapshots . That is , we want to be able to make meaningful s tatements about the s imilarity of dif ferent
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
snapshots .   We  developed  and   tes ted   three   feature-­sets :

-­ Cons trained bag-­of-­words : We implemented a bag-­of-­words model that modeled the counts of the 50 Java keywords like
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
“public ”, “int”, and “double”,
ignoring unique subjec t-­c reated variable names as irrelevant sources of variance. As a
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
metric ,   we  s imply   use   the  Euc lidean  dis tance  between  his tograms   of   word   frequenc ies   (Salton,   Wong,   &  Yang,   1975).

Fig  1  -­  A  summary   of    the  dif ferent   approaches    taken   in   this   projec t

features that are
features : We also ex trac ted a collec t ion of relat ively s imple snapshot
-­ Non-­semant ic tex t
  
  
tex t
  
  
  
  
  
  
  
  
  
  
  
  
  
  
“non-­semant ic ” -­ they capture a minimum of informat ion about the code. These features inc lude number of lines , number
     
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
of comments , and the magnitude of changes in both lines and comments as compared to the prev ious snapshot in a
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
s tudent ’s sequence. Here as well, we used the Euc lidian dis tance as the metric for diss imilarity measures , af ter
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
preprocess ing   the  data  by   dif ferent   means   of   normalizat ion.

-­ Semant ic tex t features : Finally , we ex trac ted a collec t ion of features that capture more of the meaning of the code itself
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
the codes varied the mos t along the
the ass ignment . Spec if ic to this FindRange ass ignment ,
in the contex t of
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
dimens ions of number of variable dec larat ions , number of func t ions and subfunc t ions , and number and nes t ing level of
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
condit ional  s tatements   and   loops .

2. Characteriz ing students: The nex t s tep is arguably the computat ionally mos t complex of the three. Our goal here is
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
to  gather   informat ion  at    the   level  of   a  s tudent ,   as   opposed   to  a  s ingle  snapshot .   We   tried   two  methods    for   this :

3

-­ Clus ter-­based s tudent feature selec t ion: Given the snapshot charac terizat ion from s tep 1, we c reated a new
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
feature set to charac terize s tudents . Firs t , we had to c lus ter the snapshots into representat ive code “s tates by
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
kernelized K-­Means (Sewell. & Rousseau, 2005). The dif f iculty was in determining an opt imal number of
  
  
  
  
  
  
  
  
  
  
  
  
  
  
c lus ters . We chose the opt imal number of c lus ters us ing a combinat ion of s ilhouet te value max imizat ion (Wang,
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
Wang, & Peng, 2009) and Dav ies -­Bouldin index minimizat ion (Petrov ic , 2006). We obtained 16 c lus ters . We then
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
built a new feature-­set at
  
  
  
  
  
the level of indiv idual s tudents based on their pat terns of travers ing the snapshot
  
  
  
  
  
  
  
  
  
  
  
  
c lus ters . Spec if ically tracked their sequence of
  
  
  
  
trans it ions from c lus ter to c lus ter, their frequency of c lus ter
  
  
  
  
  
  
  
  
  
  
changes , amount of t ime spent in any given c lus ter, t ime to solut ion, and total count of c lus ters v is ited. We then
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
trained an SVM with a gauss ian kernel on this new feature-­set to predic t the degree of intervent ion that a s tudent
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
received.

-­ Mean or f inal code snapshot : This method was a deliberately -­s imple alternat ive to the f irs t . We s imply
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
charac terized every s tudent with one of two features : the contents of his /her f inal snapshot , or the contents of
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
the mean of the second half of his /her snapshot series based on the charac terizat ions of s tep 1. The idea behind
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
tak ing a mean of second half of the submiss ions is that we observed noise in the data set aris ing from the
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
following fac ts : 1) Some s tudents preferred to work in another SDK other than Ec lipse, and therefore showed a
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
great variability in the features sequence, s ince they would copy and pas te their own code, and compile
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
af terwards   and  2)  Less   noise  was   observed   for   the  second  half   of    the  snapshots   sequence.

3. Comparing with intervention data: Our f inal s tep was to c lass ify the TA intervent ion data based on the s tudent
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
representat ions . We performed the binary c lass if icat ions (help vs no help) by running a nonlinear SVM with a mult i-­layer
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
perceptron, and the 3-­level c lass if icat ion (no help vs 1-­3 v is its vs >3 v is its ) with a Mat lab built-­in k -­Neares t-­Neighbor
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
c lass if ier   to  predic t   s tudent   help-­seek ing  based  on  s tudent    features .
Results
A summary of the results obtained can be found in the following tables in Figures 2, 3, 4 and 5. What is common to all
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
for temporal dimens ion of
the results is that despite the coarse feature representat ions that do not account
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
the
  
  
snapshots , nor for the s tate trans it ions of the s tudents as is done by P iech et al. , by us ing the s imple measures alone,
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
we have been able to show that there is a correlat ion between the help seek ing behav ior ac ross the ent ire quarter and a
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
s tudents ’  ass ignment .

Fig.   2  -­  Results   obtained   from   the  s tudent   c lus tering  approach

Fig.   3  -­  A  summary   of   our  “mean  and   f inal  snapshot”  model   feature  choices   result ing   from  Feature  Selec t ion

4

Fig.   4  -­  A  summary   of    the  results   achieved   for  each  model  choice

As shown in Figure 2, the approach of c lus tering s tudents based on the parameters that capture their progress ion through
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
the snapshot s tates produced an accuracy of 66.5% with a prec is ion of 63.6% . However, seen in Figure 4, a very s imple
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
representat ion of a s tudent with only a mean of snapshots , or even jus t the f inal snapshot was able to produce a bet ter
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
c lass if icat ion with more than 71% . Though, the prec is ion is with 55% lower for the representat ion of a s tudent with the
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
mean of snapshots . In terms of TA intervent ion labeling, we found that a binary labeling produces bet ter results than
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
ternary labeling. We assume that in order to make the dis t inc t ion between a s tudent who seeks more help than another
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
one, we have to use a more complex representat ion that takes into account the temporal dimens ion of the progress ion.
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
When it comes to the representat ion of s tudent snapshots with semant ic tex t
  
  
  
  
  
  
  
  
  
  
  
  
features , uns ing a s tandard feature
  
  
  
  
selec t ion model, we found dif ferences in what features bes t c lass ify TA intervent ion for the dif ferent models (see Figure
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
4).
Interes t ingly though,
  
  
the nes t ing of
  
  
the condit ional s tatements and loops does have a s trong impac t on the
  
  
  
  
  
  
  
  
  
  
  
  
  
c lass if icat ion  results .

In terms of s tudent c lus tering, apply ing k -­means to the diss imilarity matrix of s tudent snapshots represented by
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
semant ic tex t features , the selec t ion model sugges ted 15 c lus ters as a good representat ion (see Figure 5). Indeed, as
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
indicated by the dis tance matrix in Figure 5, the snapshots are well separated into the c lus ters (as further indicated by
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
the  s ilhouet te  value  of   about   0.72).

These results are espec ially interes t ing because they sugges t that there are generalizable charac teris t ics found in a
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
small sample of code from one ass ignment early in the c lass that can be indicat ive for help-­seek ing behav ior ac ross the
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
ent ire  quarter.
Conclusions
Us ing a s imple measure of a s tudent ’s progress and representat ion of his code in a s ingle ass ignment , we were able to
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
predic t with accuracy of about 72% s tudent help-­seek ing behav ior ac ross the whole quarter. This might not seem very
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
in light of the fac t that the representat ion is very s implis t ic , and that we have exc luded any complex
accurate. But
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
there is s truc ture in the relat ionship between a
these results indicate that
measures entailing temporal dimens ions ,
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
is worth to be further examined.
s tudent ’s progress ion through an ass ignment and his help-­seek ing behav ior that
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
Interes t ingly though, the mos t s imple representat ion of a s tudent by means of his ass ignment is the bes t predic tor for his
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
help-­seek ing  behav ior  ac ross    the  quarter.

This projec t is the s tart of an ex tended inves t igat ion of CS106a data. We are in the process of obtaining ass ignment and
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
tes t grades and all ass ignment snapshots . We are also collec t ing data from a week ly survey that evaluates s tudent
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
mot ivat ion and perceived dif f iculty on each ass ignment . In future work we intend to integrate our intervent ion data into a
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
Markov   model  of   ass ignment   progress    that   can  predic t   grades   and  sugges t   c rit ical  points    for   intervent ion.

NOTE: We thank Chris P iech, Marcelo Wors ley , and Paulo B liks tein for their invaluable sugges t ions and support on this
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
projec t .

5

Fig  5  -­  Diss imilarity   matrix   plot   of    the  k -­Means   c lus tering  and  2  representat ive  snapshots

References
B liks tein,   P.   (2011).   Us ing   learning  analy t ics    to  assess   s tudents ’  behav ior   in  open-­ended  programming   tasks .
Proceedings   of    the  Learning  Analy t ics   and  Knowledge  conferencd  (LAK11).   Retrieved   from
ht tp: / /dl.acm.org/ f t_gateway .c fm?id=2090132&f t id=1075980&dwn=1
Helminen,   J . ,    Ihantola,   P. ,   Karav irta,   V. ,   &  Malmi,   L.   (2012).   How  Do  Students   Solve  Parsons   Programming
Problems?—An  Analys is   of    Interac t ion  Traces .    In  Proceedings   of    the  E ighth  Annual   Internat ional  Comput ing
Educat ion  Research  Conference  (pp.   119–126).   Retrieved   from
ht tp: / /dl.acm.org/ f t_gateway .c fm?id=2361300&type=pdf
Kapur,   M.   (2008).   Produc t ive   failure.   Cognit ion  and   Ins truc t ion,   26(3),   379–424.
Petrov ic ,   S.   (2006).   A  comparison  between   the  s ilhouet te   index   and   the  dav ies -­bouldin   index    in   labelling   ids   c lus ters .    In
Proceedings   of    the  11th  Nordic   Workshop  of   Secure   IT  Sys tems   (pp.53–64).Retrieved   from
ht tp: / /svn.xp-­dev .com/svn/b_frydrych_K lasy f ikac jaDanych/K lasy f ikac jaDanych/doc /materialy /s ilhuet teIndexRegulaSt
opu.pdf
P iech,   C. ,   Sahami,   M. ,   Koller,   D. ,   Cooper,   S. ,   &  B liks tein,   P.   (2012).   Modeling  how  s tudents    learn   to  program.    In
Proceedings   of    the  43rd  ACM  Technical  Sympos ium  on  Computer  Sc ience  Educat ion  (pp.   153–160).   Retrieved   from
ht tp: / /dl.acm.org/c itat ion.c fm?id=2157182
Rabiner,   L. ,   &  Juang,   B.   (1986).   An   introduc t ion   to  hidden  Markov   models .   ASSP  Magaz ine,    IEEE,   3(1),   4–16.
Rabiner,   L. ,   &  Juang,   B.   H.   (1993).   Fundamentals   of   speech  recognit ion.   Retrieved   from
ht tp: / /www.c iteulike.org/group/10577/art ic le/308923
Salton,   G. ,   Wong,   A. ,   &  Yang,   C.   S.   (1975).   A  vec tor  space  model   for  automat ic    index ing.   Communicat ions   of    the  ACM,
18(11),   613–620.
Sewell,   G.   &  Rousseau,   P.   J .   (2005).   Finding  groups    in  data:   An   introduc t ion   to  c lus ter  analys is .   Retrieved   from
ht tp: / /www. lavois ier. fr/ liv re/not ice.asp?id=OKLWRLA2ALSOWQ
Soloway ,   E. ,   &  Ehrlich,   K.   (1984).   Empirical  s tudies   of   programming  knowledge.   Sof tware  Engineering,    IEEE
Transac t ions   on,   (5),   595–609.
Wang,   K. ,   Wang,   B. ,   &  Peng,   L.   (2009).   CVAP:   Validat ion   for  c lus ter  analyses .   Data  Sc ience  Journal,   (0),   904220071.

