Predicting User Ratings Using Status Models on
Amazon.com

Borui Wang
Stanford University
borui@stanford.edu

Guan (Bell) Wang
Stanford University
guanw@stanford.edu

Yun (Vincent) Lou
Stanford University
yunlou@stanford.edu

1. ABSTRACT
Amazon is the world’s largest online retailers where millions
of customers purchase and review products on its website.
However, many Amazon customers do not review and rate
products after the purchase, and tons of research pro jects
work on producing better prediction strategies for customer
ratings. In this research pro ject, we show a new approach
to enhance the accuracy of the rating prediction by using
machine learning methods that learn from a graph based on
user status, deﬁned by features such as the helpfulness votes
and total votes received by the users. We discussed how the
training performance of our model changes as we change
the training method, the dataset used for training and the
features used in the model. We compared this graphical
model with another non-graphic model that is also based on
customers’s review and status with diﬀerent settings, and we
achieved over 95% prediction accuracy using our graphical
status model.

2. RELATED WORK
Predicting user ratings is one of the core issues in recom-
mendation systems. The relevant works in recommenda-
tion systems mostly focus on enhancing the quality of the
algorithms to increase the prediction accuracy. The most
popular system for rating prediction is collaborative ﬁlter-
ing, which seeks to predict the expected rating a user may
give to an item he/she hasn’t rated yet. Memory-based and
model-based (e.g. matrix factorization) [2] are the two most
popular methods for collaborative ﬁltering. However, both
systems take a sparse user-product rating matrix as an input
and may fail to capture the quality of the users and their re-
views. In a similar pro ject ”Using Properties of the Amazon
Graph to Better Understand Reviews” [5] proposed by Leon,
Vasant, Sheldon (2011), the predicted feedback score was
represented with a linear combination of the following fea-
tures: Original Rating, Review Helpfulness Count, Review
Unhelpfulness Count, Review Helpfulness Ratio, Reviewer
Helpfulness Ratio, Reviewer Bias, Reviewer Expertise, Re-
viewer Clustering, Reviewer Betweenness, and Reviewer De-

gree. However, the goal of their pro ject is to predict the
rating of a customer who reviews the same product more
than once, while our pro ject is to predict the user’s ﬁrst-
time rating score. Also, they use stochastic gradient descent
to minimize the mean square error to capture the weights of
such features, while we tried more than ﬁve diﬀerent learn-
ing methods and analyzed their results in our pro ject.

3. DATA COLLECTION PROCESS
We used the Amazon product co-purchasing network meta-
data from pro ject SNAP[1] for our research. The dataset
includes over 7 million review scores and helpfulness votes
by 1.5 million customers for 0.5 million products. To con-
vert the Amazon meta data into the format we need, we
developed a Ruby preprocessing program for data parsing.
For the non-graphical model, we parse the data into matrix
ﬁles readable by Matlab and csv ﬁles for NetworkX libraries
in Python. Concretely, the output uses row entries to de-
scribe which products are reviewed by which customer and
their rating scores. For the graphical model, we parse the
data into hash structures representing customer-to-product
and product-to-customer relationships based on the chosen
dataset size to build the graph.

4.
INITIAL FINDING AND STATISTICS
Because using the entire dataset to build the graph for our
status model turned out to be slow on NetworkX, we can
only use a subset of all the data for training. We started
with using a graph built from 1193 customers who reviewed
200-400 products to reduce the path searching complexity
in our graphical status model. Such range of review counts
also happened to give the constructed customer graph a high
average cluster coeﬃcient of 0.55. We discussed our train-
ing result using such dataset in section 5.4. In later sections
(5.5), we show that selecting customers of diﬀerent ranges
(100-150, 150-200, 400-600, 600-800) of review counts af-
fects the graph cluster coeﬃcient and ultimately aﬀect our
learning accuracy.

5. GRAPHICAL STATUS MODEL
5.1 Overview of the graphical status model
Here we describe the details of the graphical status model.
The model assumes that the rating which user U gives to a
product is related to the status of him/herself and the sta-
tuses of the other users who also happen to review the same
products as U. The status of an user in our model is deﬁned
as the total helpfulness votes divided by the total amount

1193 nodes and 27,9147 edges in the graph. The graph
is highly connected, and the largest connected component
is the graph itself and the average clustering coeﬃcient is
0.55. As a result, when we use BFS to search the paths as
deﬁned previously for the customers, we ﬁnd that 97.14% of
all paths have length two. Thus the graph contains a large
number of triangles co-review relationships. This property
supports our model and gives suﬃcient amount of instances
to form a dataset for training and testing our model. In or-
der to apply the concept of status, we assign each customer
with a status score. We tested several means of comput-
ing a customer’s status based on statistics such as the total
number of reviews, total helpfulness, total number of votes,
and total rating scores from the customers. One simple def-
inition of status is the percentage of helpful votes, which is
total helpfulness divided by total number of votes. After
assigning the status score to each customer, we can build
the graph with signed edges. For example, if A’s status is
higher than B’s, then edge AB is positive, otherwise AB is
negative. Thus we can have eight diﬀerent triangle types,
where the triangle type will be used as one feature in our
machine learning process. Later, we found that there is usu-
ally more than one triangle for most customers in our graph
and we discussed how the training result changes as we add
more triangles in our training features in 5.5.

5.3 Other learning features
Besides the triangle type, we found some other features for
machine learning. Take the previous example. We have cus-
tomer D, B, C and product P0 . Noted that we are going to
predict customer D’s rating on P0 , and customer C has also
rated P0 . The other features we could possibly include in our
learning model are therefore D’s average rating, C’s rating
on P0 and P0 ’s average rating. The inspiration of choosing
these features is that when a customer rates a product, he
usually considers the product’s average rating which reﬂects
the general public opinion, and his own average rating which
reﬂects his own personal opinion. We also think a customer’s
rating can be inﬂuenced by his neighbors in the graph, so
we added the neighbor’s rating on the same product in our
learning model as well.

5.4
Initial Learning Results
Each three customers and one product that meet the def-
inition of a triangle as deﬁned previously is a training ex-
ample in our machine learning model. We used Weka[3] to
train and test the dataset. After testing several diﬀerent
machine learning methods, such as linear regression, neural
network, KNN, decision table, we found that KNN gave the
best performance. We tested our model on a dataset using
7,1542 instances with two test options: cross-validation with
10 folds, and percentage split with 66% training instances
and 34% testing instances. Below are the results, where we
measured mean absolute error, mean squared error and test
accuracy for each case.

From results in table 1 and table 2, we can conclude that
KNN gives the best prediction. With cross-validation, KNN
correctly predicted 91.23% of testing instances. With per-
centage split, KNN correctly predicted 87.46% of testing
instances. The results indicate that our model is reasonable
and eﬀective for predicting customers’ ratings on Amazon
products.

Figure 1:

of votes he/she received on Amazon. Under such deﬁnition,
the status of an user has the inclusive range [0, 1]. To see
how a user’s status can be related to other users’ statuses,
consider ﬁgure 1. The solid circles A, B , C, D, E , F represent
6 diﬀerent users and their statuses in decimal format, and
the shapes P0 , P1 , P3 , P3 , P4 with dotted border represent 5
distinct products. The circle representing a user U is placed
within the shape representing the product P if U reviewed
P. For example, user A , D reviewed product P3; customer
C, D , E , F reviewed P0 . We create edges between customers
who both reviewed the same product, and the direction of
the edge depends on the diﬀerence between the users’ sta-
tuses. As shown in the ﬁgure 1, the edge always points to
user of higher status. We try to observe if there is any rela-
tionship between the statuses of related customers and their
reviews. We utilize the user statuses and co-review relation-
ships in the graph to relate the users. Assume we want to
predict the rating of P0 given by customer D with all the
edge and user information in the graph. We ﬁrst ﬁnd out if
there is any outgoing path from D to another customer in
P0 in the graph, where the path itself does not pass through
an edge in P0 . If such path exists, we ﬁnd the shortest path
and record the attributes of the customers along the path to
construct the machine learning ob jectives (introduced later)
to predict the rating D given to P0. In the ﬁgure 1 above,
the shortest path D → B → C was chosen. Note that edge
D → C is not valid as it is in P0 . The length of the path
we could ﬁnd depends on the co-review patterns. We expect
the path to be short if two customers who reviewed diﬀerent
products can be connected by co-review relationships with
the same customers. We show later that over 97% of the
customers in our selected dataset could ﬁnd such path of
length two, which forms triangles of product co-review pairs
such as triangle ABD and BCD.

5.2 Triangle types and learning features in the
Graphical Status Model
In order to build conﬁdence of using the graphical model,
we explored the abundance of co-review triangles as deﬁned
previously in the graph. We used NetworkX for python to
generate the customer relationship graph using customers
who reviewed 200-400 products, and found that there are

KNN
Linear Regression
Neurak Network
Decision Table

MAE MSE
0.2546
0.1319
0.8765
0.6082
0.7896
1.2507
0.334
0.5632

Accuracy
91.23%
50.55%
40.29%
54.88%

Table 1: Cross-validation with 10 folds

KNN
Linear Regression
Neurak Network
Decision Table

MAE MSE
0.3609
0.1883
0.8765
0.6098
1.7041
1.1290
0.5647
0.8464

Accuracy
87.46%
50.33%
15.22%
55.19%

Table 2: Percentage split with 2/3 training data

5.5
Improved Graphical Model
The training methods and training model from the previous
section gave good results that verify our intuition of the
graphical model.
In this section, we improve our training
model by adding more triangle paths from our graph. We
also have done several experiments with diﬀerent datasets
that represent customers who review diﬀerent amount of
products. The results supported our model well and gave us
a good guideline on how to select features for the learning
process.

Speciﬁcally, our ﬁrst experiment is designed to check if the
model works for diﬀerent datasets that represent users who
review diﬀerent amount of reviews. The second experiment
is to apply the model on one dataset but with diﬀerent num-
ber of triangles representing co-review paths. The third ex-
periment is to measure the performance of the model when
the input graph of the dataset is not fully unveiled, for ex-
ample, by randomly removing customers from the graph.
We adopted KNN approach in Weka to perform all the ex-
periments as it is proved to give the best training method
from the previous section.

5.5.1 Experiment 1
In this experiment, we applied our training model on ﬁve
datasets with two triangle modes, where we use 1 and 2
triangle paths from the graphical model as training features.
The datasets vary in the range of the amount of the reviews
given by the customers. For example, the column ”100-150”
in the tables below represents the training set of customers
who reviewed 100-150 products.

Table 3 contains the datasets’ properties, which include the
number of instances in each dataset and the average clus-
ter coeﬃcient of the graph generated from the datasets. We
found that as the customers in our dataset review more prod-
ucts, the average cluster coeﬃcient of the graph increases
indicating that the graph becomes denser.

dataset
100-150
150-200
200-400
400-600
600-800

number of instances Average cluster coeﬃcient
0.3186
162329
0.3962
86102
0.5499
218553
59285
0.744
0.8523
8584

Table 3: dataset Properties Table

Figure 2:
For each dataset, we tested our model with cross-validation
with 10 folds. Below are the results trained for diﬀerent
datasets with 1 and 2 triangles as training features. We
measured the mean absolute error, mean squared error and
test accuracy for each case similar to the previous section.

dataset MAE MSE
0.3125
0.165
100-150
0.2377
0.1324
150-200
200-400
0.1756
0.306
0.2018
0.1324
400-600
600-800
0.0939
0.1612

Accurary
88.79%
90.63%
87.33%
89.48%
93.12%

Table 4: Cross-validation with 10 folds (1-triangle
mode)

dataset MAE
0.1283
100-150
0.0.0972
150-200
0.0.1345
200-400
0.0.0824
400-600
600-800
0.0712

MSE
0.2515
0.1832
0.2456
0.1383
0.1215

Accurary
91.56%
93.44%
90.68%
93.8%
94.79%

Table 5: Cross-validation with 10 folds (2-triangle
mode)
From the table 4 and 5, we can ﬁnd an improvement of
the training accuracy as we use more triangles for train-
ing, and the accuracy for datasets with 1-triangle path as
learning feature is around 90%, and the accuracy with 2-
triangle paths is around 93%. This prediction accuracy is
very high. In addition, the training results indicate that our
model also works for datasets of diﬀerent ranges. We will
show how many triangles gives the optimal results in the
second experiment.

5.5.2 Experiment 2
In this experiment, we applied the model on the same dataset
using diﬀerent amount of triangles derived from our graphi
as features for training. The dataset we used is the one
where the customers’ number of reviews ranges from 200
to 400. Again, similar to the ﬁrst experiment, we adopted
cross-validation with 10 folds method. The results is in table
6.

From table 6, we can ﬁnd that using 3 triangles for our
training features gives the best performance, which achieved
the highest accuracy of 96.63%. Moreover, adding the sec-
ond triangle improved the performance the most, because
the accuracy was improved by 1.93% after changing from 1-
tiangle mode to 2-triangle mode. Besides these two points,
we can also conclude that after having 3 triangles as training
features, adding more triangles does not improve the perfor-
mance. Therefore, the optimal number of triangles for our
model is 3.

# of remaining instances MAE MSE
0.1853
0.0914
1
2
0.0617
0.126
0.1173
0.0556
3
0.1176
0.0555
4
5
0.0544
0.1129

Accuracy
94.19%
96.12%
96.63%
96.62%
96.62%

Table 6: Cross-validation with 10 folds (1,2,3,4,5-
triangle mode)

# of remaining instances MAE MSE
1.1828
0.6135
20K
40K
0.5128
0.9811
0.8123
0.4272
60K
0.6734
0.3573
80K
0.5831
0.3115
100k
160k
0.2002
0.3729
0.2456
0.1345
210k

Accuracy
59.38%
65.92%
71.47%
75.97%
78.91%
86.38%
90.68%

Table 7: Cross-validation with 10 folds (2-triangle
mode, 200-400 dataset)

5.5.3 Experiment 3
In this experiment, we tested our model with incomplete
data sets to ﬁnd the relationship between prediction accu-
racy and the completeness of the data. We randomly re-
moved certain amount of nodes (customers) and edges (co-
review relationship) connecting them from the graphs gen-
erated from the datasets (200-400). The results are in table
7.

From table 7 and ﬁgure 3, we can ﬁnd that our model highly
depends on the completeness of the graph. The model per-
forms badly when a large amount of nodes are removed. This
can be explained by the fact that our model uses KNN to
produce prediction. This can be explained by the fact that
if customers with similar features are removed, the target
customer whom we want to predict will not be able to ﬁnd
co-reviewers in the training dataset, therefore hurting the
training quality and decreasing the prediction accuracy.

6. REVIEW-BASED STATUS MODEL
6.1 Overview of the Review-based Status Model
In this part of the pro ject, we explore the relationship be-
tween the reviews and their inﬂuence on customers’ future
ratings. Our training samples are based on the reviews of
each product.

Figure 3:

6.2 Baseline
baseline model is:RP ridict = (cid:80)(θ1 ∗ Hi + θ2 ∗ Pi + θ3 ∗ Vi ) ∗
In the baseline model, we only considered the impact of the
selected reviews for prediction. Our assumptions for the
Rj , j = 1, 2, ...k . where the subscript j is the j th customer,
Pi is the number of product reviews, Hi is number of help-
fulness votes, Vi is the total number of votes.

6.3
Improved Model
We have two diﬀerent assumptions with the review data. 1)
Assuming that the quality of the review is the key inﬂuencer
like: RP ridict = α ∗ RproAvg + (1 − α) ∗ RuserAvg + (cid:80)(θ1 ∗
to the users; 2) Assuming the reputation of the reviewer is
the key inﬂuencer to the users. The ﬁrst assumption goes
Hi + θ2 ∗ Vi + θ3 ∗ Hi /Vi ) ∗ (Ri − RproAvg ), j = 1, 2, ...k .
where Hi is the number of helpfulness and Vi is the number
of votes for the review j. Hi and Vi are the data to mea-
sure the quality of the review. To ﬁnd a better model, we
tried square and cubic of Hi and Vi , but the testing error
increased slightly. Moreover, when we tried Hi /Vi , the MSE
decreased by 0.04, indicating a valuable feature for the qual-
ity of the review. In the next section, we will discuss more
about the ratio Hi /Vi , such as including its square and cu-
bic forms, subtracting by its average to distinguish between
RP ridict = α ∗ RproAvg + (1 − α) ∗ RuserAvg + (cid:80)(θ1 ∗ Hi,u +
high quality reviews (with positive numbers) and low quality
reviews (with negative numbers). The second assumption is:
θ2 ∗ Vi,u + θ3 ∗ Ri,u ) ∗ (Ri − RproAvg ), j = 1, 2, ...k . where
u is the user of the ith review,Hi,u is the total number of
helpfulness of u ,and Vi,u is the total number of votes Ri,u is
the total number of ratings from the user u. Vi ,u, Ri ,u and
Hi,u are the data to measure the status of the user. To ﬁnd
the best model, we tried the square and cubic forms of Hi,u
,Ri,u and Vi,u , but reaching a higher testing error. When
we triedthe feature Hi ,u/ Vi ,u, there is no improvement in
training error.

6.4 Combination: Review-based status model
and Graphical Status Model
W2 and W3 as: Wd = (Ri − RproAvg ) ∗ (cid:80)(θd ∗ Hi,u ), d =
Based on the Improved Model 2, we incorporate it with the
features used in the Graphical Status Model. Deﬁne W1 ,
1, 2, 3, j = 1, 2, ...k . We appended W1 , W2 and W3 to the
extracted feature vectors in Improved Model 2. We would
like to provide the learning algorithm with more information
by adding graphical status data to review-based data. The
learning algorithms should be capable of ﬁguring out the
best combination of the features by adjusting the coeﬃcient
of each feature.

6.5 Learning Methods and Evaluations
We adopted the cross-validation method in this experiment.
The mean value for the target value in the training data
is 4.139, and its standard deviation is 1.132. The distribu-
tion of the ratings in our training data is shown in ﬁgure 4,
indicating that rating 4 and 5 appear most frequently.

Since the hypothesis is a combination of weights and scales
for three models abvove, we ﬁrst tried multilayer neural net-
works as our learning method. We used the Mean Square
Error (MSE) between the actual and predicted rating for
performance evaluation. The result is shown in table 9.

Combined Model
Decision Tree
KNN(K=1)
KNN(K=2)
KNN(K=3)
Linear Regression
Least Median Square Linear Regression
Locally Weighted Linear Regression
Multilayer Perceptron 1 Hidden Layers
Multilayer Perceptron 2 Hidden Layers
Multilayer Perceptron 3 Hidden Layers

Mean Square Error Absolute Mean Error Root Mean Square Error Accuracy
58.56%
0.8484
0.5056
0.7197
0.6853
1.3224
1.1500
54.17%
49.89%
0.9953
0.9906
0.6443
54.97%
0.8815
0.5491
0.7771
45.35%
1.0095
0.6849
1.0192
45.35%
1.0095
0.6849
1.0192
1.2386
0.8068
1.1129
40.91%
55.37%
1.0931
1.0931
1.1948
55.43%
1.0851
0.6481
1.1775
0.6454
1.1677
1.0806
55.45%

Table 8: Eveluation result for combined model

Figure 4: Distribution of ratings in training data

Improved Model 2
Mean Square Error
Absolute Mean Error
Root Mean Square Error
Accuracy

K=1
1.4393
0.6977
0.70
73%

K=5
2.3592
0.4876
0.75
56%

Table 9: Performance Laerned through KNN

From the evaluation result, we ﬁnd that the baseline model
has a very high bias for both the training and testing data,
but the MSE for both of them diﬀer little, indicating a low
variance in the learning model. Also, Improved Model 2 has
a better performance than the other two models. We also
tried other learning methods for Improved Model 2, and ﬁnd
that KNN has a decent performance, which is shown in table
10.

For the combined model, we tried four diﬀerent learning
methods: Decision Tree, K-Nearest N (KNN), Linear Re-
gression and Multilayer Perceptron. The results for these
learning methods are shown in table 8. KNN gave the best
prediction in terms of Mean Square Error (MSE), while De-
cision Tree, KNN and Multilayer Perceptron gives similar
prediction accuracy,around 55%. When comparing the re-
sults of the combined model with improved model 2, neithor
the accuracy nor the MSE was improved. When comparing
the results of of the combined model with graphical struc-
ture model, combined model performed worse. This was
caused by diﬀerent interpretations of review-based model
and graphical model. Concretely, the graphical model is

Neural Networks
Baseline
Improved Model 1
Improved Model 2

TrainingMSE Testing MSE
3.33
3.27
0.75
0.73
0.70
0.75

Table 10: Comparision of three models using Neural
Networks

designed to explore the network path structure of the data,
while the review-based model relies highly on the linear com-
bination of common user features. Simply combining data
from the two models does not give a better result because
there is no direct relation between the underlying meanings
of the feature vectors from the two models; as a result, the
performance with combined model is worse than graphical
model.
7. CONCLUSION AND FUTURE WORK
We have explored two models to solve the problem. The
ﬁrst model relies more on analyzing the network structure
and using status theory. The second one focus more on
review-based status information. From the results, we ﬁnd
the ﬁrst model gives better performance, which achieved a
mean square error around 0.1173 and prediction accuracy
around 96.63%. The second model gives the prediction ac-
curacy around 73% and mean square error around 0.6853. In
conclusion, applying network and status concepts in a graph-
ical model is very useful to improve prediction accuracy for
Amazon data. Other customers’ ratings in a product might
produce bias to the target user’s rating [4], which is not
considered as a parameter in the graphical status learning
model. To extend our work, it might be helpful to include
parameters reﬂecting the bias caused by other reviews in
the same product to improve our model and reduce learn-
ing errors. Furthermore, the deﬁnition of user status in the
graphical model can be overly simple and naive. Other def-
initions of user status would change the triangle type and
drastically aﬀect the learning result, which is left to be ex-
plored. During our experimentation of feature selection, the
features selected in the graphical model are not proved to
be the best choice of features, and it requires more analysis
to come up with a better set of features.

8. REFERENCES
[1] SNAP, http://snap.stanford.edu/.
[2] F. Ricci, L. Rokach, B. Shapira, and P. B. Kantor,
Recommender Systems Handboo,Springer, 2011.
[3] Weka is a col lection of machine learning algorithms for
data mining tasks,
http://www.cs.waikato.ac.nz/ml/weka/.
[4] C. Danescu-Niculescu-Mizil, G. Kossinets, J. Kleinberg,
L. Lee, How opinions are received by online
communities: A case study on Amazon.com helpfulness
votes. ,In Proc. ACM WWW, 2009.
[5] Leon, Vasant, Sheldon, Using Properties of the Amazon
Graph to Better Understand Reviews

