Recommendation System For HCD Connect

Kesinee Ninsuwan, Mike Phulsuksombati, Umnouy Ponsukcharoen

Abstract— HCD Connect is a social platform by IDEO.org
that aims to connect social entrepreneurs around the world.
The users can post the stories about their past experiences in
service work as well as their prospective project ideas on the
website. When other users see the project ideas of their interest,
they can interact on the platform and get connected with other
users. With each story or project, a user is allowed to click
like, follow a story, post comments, or share it via other social
networks. Moreover, the website provides a space for the users
to ask and answer questions which are not limited to speciﬁc
stories or projects.
This project aims to build a recommendation system on
the stories to the users. There are four main states for this
project including processing data, implementing unsupervised
text classiﬁcation algorithms,
implementing supervised text
classiﬁcation algorithms, and building a score system for the
stories. The unsupervised classiﬁcations that we uses includes
Hierarchical Agglomerative Clustering (HAC), k-means cluster-
ing, and topic modeling. The results indicate that they do not
discover signiﬁcant topics underlying the stories. The supervised
classiﬁcations used in the project includes k-nearest neighbors
(kNN), support vector machine (SVM), and multi-label rank-
SVM. kNN performs best among all algorithms. However, the
precision are still low. This suggests that more data needs to
be collected. Therefore, we have to wait for more stories to be
posted on the website in order to improve the performance of
the recommendation system.

I . INTRODUCT ION
Since HCD was launched in 2011, the system is still in the
state of initial development. Our project aims to use machine
learning to build a recommendation system to feed users
with the projects and stories that potentially interest them.
Also, we expect to build a system that connects a user to
another user who share the same interest which can create
huge impact to social sector around the world.
From the initial data sets provided by the IDEO.org, HCD
now has 15,000 users and 310 stories. Each user provides
personal information including sex, age, location, interest,
and organization. For each story,
the data includes title,
description, author, topic, location, and design methods used.
Due to the lack of information on browsing history and
user-story interaction, we cannot build the personalized rec-
ommendation system as we wish before. Therefore,
this
project will focus on the text classiﬁcation of the stories. On
each page of story, we aim to build a recommendation section
on the relevant stories of the same class based on machine
learning algorithm. This will improve the user’s experience
on the website.
This project consists of four main states. The ﬁrst state is
processing data. In the second state, we use unsupervised text
classiﬁcation algorithms in order to discover topics or clus-
ters underlying the stories. In the third state, we build “auto-

labeling” system from supervised learning algorithms. When
a user posts a story on the website, he is asked to choose
appropriate labels for the story. There are nine labels to
choose from including agriculture, community development,
education, energy, environment, ﬁnancial services, gender
equity, health and water . A story can have multiple labels.
Given the stories with labels, we can use supervised text
classiﬁcation algorithms to automatically recommend the
labels for each story. The last state does not involve machine
learning. However, it creates a complete recommendation
system that can be used on the website. In this state, we
give a score to each story based on page view, post date,
number of comments and likes. On each page of story, we
can then recommend three stories with highest scores which
are in the same class as the story on that page.

I I . PROCESS ING DATA :
VECTOR SPACE MODEL AND METR IC

is a collection of m
In this project,
the training set
documents with n unique tokens. Each story gives one
training example. Here, a token is one single word, not an n-
gram. We use a vector space model to represent the training
set as an m × n term-document matrix. Each document is
a vector of m dimensions. The number in row i, column
j of the matrix represents the number of times word i
j. Note that this representation does
appears in document
not keep the information of the order in which each word
appears in the document. The size of our training set is
m = 310, and the number of words throughout documents
after preprocessing is n = 2037. In order to construct a term-
document matrix, we ﬁrst have to preprocess the document.
Preprocessing takes an input as a plain text document from
the name, title, and description of a story and provides an
output as a set of tokens. Preprocessing are done in steps
by ﬁltering, tokenization, stemming, stopword removal, and
pruning. We use TMG matlab toolbox[8] to preprocess the
documents. Once we obtain the term-document matrix, a
weight is assigned to each token indicating the importance
of that token. This is done by tf-idf weighing scheme. The
document vectors are now composed of weights reﬂecting
the frequency of terms in the document multiplied by inverse
of their frequency in the entire collection.
In order to measure the distance or similarity between
two documents, we use the Euclidean norm. Since SVM is
developed under Euclidean norm, this gives the consistency
in testing different algorithms that we use in this project.
Then the document vectors are normalized to unit vectors.

I I I . UNSUPERV ISED TEXT CLUSTER ING
After we process the text document to get a matrix of
training set, we apply unsupervised text clustering algorithms
to the training set in order to discover the structure of the
data and possibly new topics in the cluster.

A. Hierarchical Agglomerative Clustering (HAC)
The ﬁrst algorithm that we implement
is Hierarchical
Agglomerative Clustering (HAC). This algorithm is based
on the idea of hierarchical clustering in which clusters build
by the algorithm creates hierarchy or a rooted tree. There are
two types of hierarchical clustering. The ﬁrst type is “bottom-
up”, where at
the beginning each document
is its own
cluster. At each step, clusters merge based on some similarity
measure. The second type is “bottom-down”, where initially
all documents are in one cluster. Then at each step, a cluster
is divided into two clusters. HAC uses the idea of “bottom-
up” algorithm. The clusters will be merged and converged
to the root of hierarchy. The merges are determined by
similarity between two clusters called linkage. There are
three common linkages: single, complete, and group average
link. Here we use group average link only.
The algorithm can be summarized as follows:
1) Calculate linkage matrix whose entry (i, j) is the
linkage between the it h and jt h clusters.
2) Merge two clusters with highest linkage.
3) Update the linkage matrix to reﬂect pairwise linkage
between the new cluster and the original clusters.
4) Repeat step 2 and 3 until there is only one cluster
remains.
When implementing the algorithm, we can decide where
to cut the hierarchical tree into clusters. There is a quality
measure for HAC known as insufﬁciency measure cutoff.
The results are the followings.

cutoff
1.0
1.1
1.15
1.155
1.16

number of clusters
79
60
30
1
1
TABLE I
TH E RE SU LT FROM HAC

Here one can see that the number of clusters is either
too large or too small. The results indicate that there is no
signiﬁcant topics or clusters discovered.

B. K-means Clustering
Another unsupervised algorithm is k-mean clustering. It
is categorized as a non-hierarchical clustering. The data is
assumed to have k clusters as priori without hierarchy. In our
implementation, we measure the distance between clusters
using the Euclidean norm. The algorithm can be summarized
as follows:
1) Select k points as initial centroids.

2) Assign all points to the closest centroids using Eu-
clidean norm.
3) Recompute the centroid of each cluster to be the
centroid of those points assign to it.
4) Repeat step 2 and 3 until centroids no longer move.
First we attempt to ﬁnd appropriate number of clusters
k. Given k, we measure how well-separated the resulting
clustering are using silhouette numbers. We then ﬁnd the
average of silhouette values of k clusters. Small silhouette
value means the clusters are not well separated. The plot
below shows the average silhouette numbers for each k.

Fig. 1. The graph of average silhouette value vs. k

The average silhouette value is small (< 0.1) for all k.
And for k > 22, the algorithm fails since an empty cluster
is created. Therefore, there is no new signiﬁcant topics or
clusters discovered.

C. Topic Modeling
While HAC and k-means algorithms are known as hard-
clustering, topic modeling is known as soft clustering be-
cause it clusters the training set by probabilistic model of
topics. It speciﬁes a simple probabilistic procedure by which
documents can be generated. For each document, we assume
that words are chosen in a two-stage process:
1) Randomly choose a distribution over topics.
2) For each word in the document
• Randomly choose a topic from the distribution
over topics in step 1).
• Randomly choose a word from the corresponding
distribution over the vocabulary.
The algorithm is designed to ﬁnd the hidden structure, i.e.
the per-document topic distributions, the per-document and
per-word topic assignments. We use the observed documents
to infer the hidden topic structure. This is known as Latent
Dirichlet Allocation (LDA). After constructing the joint
distribution of the hidden and observed variables, Bayes’s
rule gives the conditional distribution of the topic structure
given the observed documents. However,
in general,
the
marginal probability of the observations, which is the sum
of the joint distribution over every possible instantiation
of the hidden topic structure, is exponentially large. Topic
modeling algorithms need to form an approximation for

such probability. Those algorithms fall into two categories
- sampling based algorithms and variational algorithms. In
this project, we only focus on a sampling-based algorithm
in which Gibbs sampling is used. It is a statistical technique
meant to quickly construct a sample distribution. Here we
implement Gibbs sampling based LDA algorithm using 10
topics, which is comparable to the number of labels we had.
The resulting topics are shown below.

topic
1
2
3
4
5
6
7
8
9
10

signiﬁcant words
ideo learn organ org women earli tedx
commun creat model live work understand impact
project experi hear interview anim power base
team org busi fellow chang idea cookstov
improv health small process support opportun educ
prototyp ﬁeld help research challeng india kenya
farm innov water urban program aquapon light
farmer food school local connect incom low
design center social rural human garden system
develop agricultur product sustain hcd servic technolog
TABLE II
TH E S IGN I FICAN T WORD S FOR EACH C LU ST ER FROM TO P IC MOD EL ING
A LGOR I THM

Notice that these clusters do not form according to the
labels, for example, words related to agriculture appear
in topic 7,8,9,10. Yet words in each topic do not share
outstanding category. Hence, no new signiﬁcant topics or
clusters are discovered.

IV. SUPERV ISED TEXT CLUSTER ING :
AUTO -LABEL ING SYSTEM
In this section, we use the information on labels from the
writers of the stories to implement the supervised learning
algorithms. For each story, we will use clustering algorithm
to identify the labels that are ﬁt the story the most based
on our models. This system will help the writer identify
the correct labels to the story. Throughout this section, we
use q to denote the number of all possible labels, and m
to denote the number of data. For this project, q = 9 and
m = 310. Because a story can have multiple labels, this
system relies on multi-label classiﬁcation and corresponding
evaluation methods. The multi-label classiﬁcation methods
can be divided into two categories: problem transformation
methods and algorithm adaption methods.
The problem transformation methods transform one multi-
label classiﬁcation problem into multiple single-label classi-
ﬁcation problems, or into one classiﬁcation problem with
multiple labels. There are two canonical ways to do this.
The ﬁrst way is to do q-binary classiﬁcations, where q is the
number of all possible labels. For each label i, we perform
a single-label classiﬁcation on the data to identify if each
story should have label i or not. The other way is to do one
classiﬁcation with 2q classes. Each of 2q classes represents
a subset of the set of q labels. In this project, q = 9 gives
29 = 512 classes, while there are 310 training examples. The
training size is very small compared to the number of classes.
This method will not work well with our problem. Therefore,
we will only implement the ﬁrst method of transforming the

problem into multiple single-label classiﬁcation problems.
We will use the k-nearest neighbor (kNN), and support vector
machine (SVM) for this project. For the algorithm adaption
methods, we will use method based on kNN and SVM.

A. Evaluations
For the evaluations, we use three methods including persis-
tent precision, persistent recall, and Hamming loss. Suppose
there are m test documents and q labels. The persistent
precision and recall break the data into m × q instance-
label pairs, and evaluate by regular precision and recall.
Notice that these two evaluations do not utilize the idea
of multi-label data. Another evaluation is Hamming loss. It
measures the cardinality of symmetric difference between
the set of predicted labels and the set of actual test labels
averaged over the number of test documents and number
of all possible labels. Hamming loss equal to zero means
the algorithm makes a perfect prediction. And the algorithm
performs well when Hamming loss closes to 0, while the
algorithm performs poorly when Hamming loss closes to 1.
In this project, we use simple cross validation by splitting
310 data instances into 210 instances for training, and 100
instances for testing.

B. Problem Transformation Methods
k-Nearest Neighbors (kNN). In kNN method, for each
label and each example in testing set, we ﬁnd its k nearest
neighbors in the training set using Euclidean norm. Then that
example is identify whether it should be tagged with that
label or not based on the statistical model we construct from
the training set. The results from implementing q single-label
kNN methods are below.

Value of k
Precision
Recall
Hamming Loss

11
0.713
0.444
0.224

12
0.697
0.451
0.228

8
0.659
0.400
0.247

9
0.764
0.353
0.231
TABLE III
TH E EVA LUAT ION O F kNN M E THOD

10
0.711
0.465
0.221

Support Vector Machine
(SVM). We
implement
SVM using 5 different kernels including linear kernel
γ (x(i) )T x( j)(cid:17)n
(cid:16)
K (x(i) , x( j) ) = (x(i) )T x( j) , Gaussian kernel K (x(i) , x( j) ) =
exp(−γ kx(i) − x j k2 ),
and n-degree polynomial kernel
K (x(i) , x( j) ) =
. Here we use γ = 1 for both
Gaussian kernel and n-degree polynomial kernel. The cost
parameter C is chosen to be one by default. The results are
shown below.

Kernel
Precision
Recall
Hamming Loss

Polynomial of degree
4
2
3
0.550
0.550
0.550
0.200
0.200
0.200
0.294
0.294
0.294

Gaussian
0.550
0.200
0.294

Linear
0.550
0.200
0.294
TABLE IV
TH E EVA LUAT ION O F SVM

Value of k
Precision
Recall
Hamming Loss

8
0.659
0.400
0.247

9
0.764
0.353
0.231
TABLE V
TH E EVA LUAT ION O F MU T I - LAB EL kNN

10
0.711
0.465
0.221

11
0.713
0.444
0.224

12
0.697
0.451
0.228

For this application, it is more important that the users
do not miss a chance to read the stories they are interested
in than they are recommended the stories in other topics.
Therefore, recall is more important than precision. In kNN
algorithm, recall is highest when k = 10. In SVM algorithm,
it is somewhat surprising that different kernels give the same
performance through all evaluation measure. One possible
reason is the examples x(i) ’s do not contribute signiﬁcant
changes. Thus, we conclude that among SVM algorithm,
linear is sufﬁcient to implement. Overall, kNN algorithm
outperforms SVM algorithm.

C. Algorithm Adaptation Methods
Algorithm adaptation methods consider all q labels to-
gether. Most of these methods are variations of single-label
classiﬁcation algorithms. In this project, we use methods
based on kNN and SVM.
Multi-label kNN For this method, we used the algorithm
based on the paper by Zhang and Zhao[9] . Proposed by Zhang
and Zhao in 2007, multi-label kNN is a variation of kNN
algorithm applied to multi-label classiﬁcation. In regular
kNN algorithm, an unlabeled vector is classiﬁed by assigning
the label which has the greatest probability among the k
nearest training examples query point based on the statistical
model constructed from the training data. In multi-label
kNN, we need an alternative method to utilize information
from neighbors. After identifying all neighbors, the algorithm
chooses labels on the query point to maximize a posteriori
(MAP) principle. When training the data, for each label t , we
construct the probability that a given example has label t and
the probability that it does not have label t given that it has
l neighbors with label t , where t = 1, . . . , q and l = 0, . . . , k.
Based on these probabilities, we can assign the labels to each
test example, and evaluate the performance of the algorithm.
The results are shown below.
Similar to regular kNN, Multi-label kNN performs best
when k = 10 . Notice that the value of all evaluation measure
are same as regular kNN method. This is because in the
paper by Zhang and Zhao[9] , each label is treated separately
in building the statistical model and in assigning the labels to
the test examples. Therefore, this is equivalent to the regular
kNN we present in section IV-B.

Rank-SVM Proposed by Eisseeff and Weston in 2002,
Rank-SVM is a variation of SVM algorithm applied to
multi-label classiﬁcation[3] . In regular SVM algorithm, an
unlabeled vector is classiﬁed by its location with respect
to a separating hyperplane. The separating hyperplane is
chosen to maximize the margin and minimize penalty from
separating hyperplane violation. In multi-label kernel learner,
we need an alternative method to draw hyperplanes and
assign penalty function for multi-label data. In regular SVM,
we ﬁnd the hyperplanes by solving the optimization problem

(1)

(2)
(3)

min
ξ ,w j ,b j , j=1,...,q

min
ξ ,w,b
subject to

2 ||w||2 + C ∑m
1
i=1 ξi
y(i) (< w, x(i) > −b) ≥ 1 − ξi ,
ξi ≥ 0, i = 1, . . . , m
Ideally, we would prefer all data with positive label to
be above the hyperplane < w, x(i) > −b = 0. ξ represents the
violation to such ideal. In Rank-SVM, we now have multiple
hyperplanes {wk , bk } where k = 1, . . . , q. The optimization
problem associated to Rank-SVM is the following.
q
m
1
1
||wk ||2 + C
|Yi || ¯Yi | ∑
∑
∑
2
(k,l )∈Yi× ¯Yi
i=1
k=1
subject to < wk − wl , xi > −bl + bk ≥ 1 − ξikl , (k, l ) ∈ Yi × ¯Yi ,(5)
ξikl ≥ 0,
(6)
where Yi is the set of labels for document i, and ¯Yi is the
complement of Yi . Here, we may view quantity < wk , x > +bk
as a kt h score. Ideally, we would prefer all data with label k
to have kt h score higher than any scores associated to non-
labels l. That is why this algorithm called Rank-SVM. ξ
represents the violation to such ideal.
To implement rank-SVM algorithm, we need to specify
parameters associated to each kernel as in regular SVM in
Section IV-B. Here we use γ = 1 for Gaussian kernel and for
n-degree polynomial kernel. The cost parameter C is chosen
to be one by default. The results are shown below.

ξikl

(4)

Kernel
Precision
Recall
Hamming Loss

Polynomial of degree
4
2
3
0.515
0.515
0.515
0.382
0.382
0.382
0.299
0.299
0.299

Gaussian
0.515
0.382
0.299

Linear
0.591
0.426
0.266
TABLE VI
TH E EVA LUAT ION O F RANK -SVM

Here one can see that Rank-SVM performs better than
regular SVM throughout all evaluation measures. It shows

effectiveness of algorithm adaptation methods. However,
Rank-SVM gives relatively poor performance compared to
even regular kNN. Overall, regardless of algorithms, the auto-
labeling system performs poorly, recall rate is below 50%.
There are two explanations for this. First, the quality of labels
given in our data set may be poor. Consider the histogram
below.

Fig. 2. Histogram of number of labels for 310 documents

There are 43 documents with at least 5 labels. These labels
may not reﬂect important topics that we can capture by
learning from the content of the document. It is possible
that the writers know by themselves that the story related to
many labels. However, the content of the documents do not
reﬂect the relationship with the labels. If we remove those
documents out, we might improve the performance of the
auto-labeling system. Another way to improve the labeling
system is to have a person other than the writer assigning
the labels to the stories. Another reason explaining why the
algorithms perform poorly is the dataset here may be too
small. This might be the reason why kNN, a local-based
algorithm, outperforms SVM, a global-based algorithm. We
need to wait for more stories and labels from the users in
order to fully implement the auto-labeling system.

V. SCORE OF RECOMMENDAT ION SYSTEM
In this part, we assign a score for each story. Once the
user visits a story j, we will collect all stories with at least
one similar label to the current story and compute the score
as follows:
score (story j, current story i) = f2 (number of page views
j) + f3 (number of comments j) + f4 ( number of likes j)
+g1 (current date - post date j) + g2 (distance(i, j)),
where f refers to an increasing function since parameters
inside f s contribute to positive effects (more preferable to
users), while parameters inside gs contribute to negative

effects (less preferable to users). Simple functions for f s and
gs are linear functions with positive and negative parameters,
respectively. These parameters should be weighted depend-
ing on importance of each factor. For example, if it does not
matter how long the stories has been published, we may set a
factor of g1 to be zero. Then, we can recommend three stories
with highest scores on the page of the current story. This
score system may extend to personalized recommendation
system if we know a story-user interaction. For example,
we may add g3 (∑k ( j, k)) where k refers to the stories that
the user has visited. To complete machine-learning based
recommendation system even with the early state, we need
to improve auto-labeling system which requires more data.

V I . CONCLUS ION
The unsupervised classiﬁcation algorithms do not give
signiﬁcant topics underlying the stories. From the supervised
classiﬁcation algorithms, the multi-label SVM performs bet-
ter than the regular SVM. Overall, the k-nearest neighbors
algorithm (kNN) outperforms all other algorithms. However,
the precision of the algorithm is still very low. This is
because the data set is too small. Therefore, looking at the
local structure at each data point (kNN) gives the better
results. Moreover, this indicates that we should wait for more
stories to be posted by the writers in order to improve the
performance of the recommendation system. However, in
term of memory storage, SVM is the most efﬁcient algorithm
because the computer only have to store the relevant param-
eters instead of the whole data set. Therefore, we predict that
once there is large enough data set, rank-SVM will perform
best in term of both precision and efﬁciency.

R E F ER ENC E S
[1] A. Nicholas O., and F. Edward A., Recent Developments in Document
Clustering, October 2007.
[2] B. David M., Introduction to Probabilistic Topic Models, Princeton
University.
[3] E. Andre, and W. Jason, A kernel method for multi-labelled classiﬁ-
cation.
[4] G. Tom, and S. Mark, Matlab Topic Modeling Toolbox 1.4. Release
Date: April 2011.
[5] G. Tom, and S. Mark, Probabilistic Topic Models. University of
California, Irvine.
[6] “Hierarchical Clustering.” MathWorks. The MathWorks, Inc.
[7] “K-Mean Clustering.” MathWorks. The MathWorks, Inc.
Text
To
Matrix
[8] “TMG.”
<http://scgroup20.ceid.upatras.gr:8000/tmg/>.
[9] Z. Min-Ling, Z. Shi-Hua, ML-KNN: A Lazy Learning Approach to
Multi-Label Learning. Pattern Recognition, 2007, 40(7): 2038-2048.

Generator.

