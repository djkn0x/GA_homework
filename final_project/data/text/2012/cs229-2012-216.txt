That’s Hot: Predicting Daily Temperature for Diﬀerent
Locations

Alborz Bejnood, Max Chang, Edward Zhu
Stanford University
Computer Science 229: Machine Learning

December 14, 2012

1 Abstract

2 Introduction

.
The problem of eﬀectively modeling weather
has been a focus of numeric simulations since
the early 1950s. We address the speciﬁc task
of modeling daily temperature using only
temperature data from preceding days and
equivalent days in previous years. Weather
data compiled by the National Oceanic and
Atmospheric Administration (NOAA) for ﬁve
chosen cities over a period of 31 years was
used as training data. An autoregressive
analysis generated a temperature hypoth-
esis function with mean absolute error of
2.58◦F against the true temperature val-
ues. For validation of the applicability of
a temperature-based data assumption, we
used the k-nearest neighbors algorithm (with
previous days’ temperatures used as coordi-
nates), obtaining a mean absolute error of
2.70◦F . The similar predictions of the two
models suggests stronger conﬁdence in the ef-
fectiveness of temperature modeling through
a singular dependence on preceding temper-
ature data.

1

Weather
simulations have predominantly
studied weather changes on a relatively mi-
croscopic level, with less consideration of
longer time scale data trends and regulari-
ties. This ”small-change” assumption–that
the weather tomorrow can best be determined
by the weather from the preceding week–
usually provides reasonably accurate short-
term measurements (which is why it is often
used for daily forecasts), yet performs poorly
on predictions more than a week into the fu-
ture due to the chaotic nature of atmospheric
perturbations. Our approach targets a par-
ticular aspect of the weather-temperature-
measured at noon daily at particular loca-
tions, and looks to generate a predictive tem-
perature model using solely prior tempera-
ture information. To improve both the imme-
diate and extended temperature predictions,
we used weather data collected over a 30 year
period as a training data set.

3 Data Acquisition

The data used was obtained from publicly
available weather information from the Na-

tional Oceanic and Atmospheric Administra-
tion. Temperature data for various cities and
locations, with information from over a hun-
dred years ago to the current day, was ob-
tained from airports (as weather-related in-
formation from airports are likely to be more
reliable due to their relevance in ﬂying) from
the years 1982 to 2012. We decided (based on
the data quality and availability) to analyze
the temperature data in the following ﬁve lo-
cations:
1. London, United Kingdom
2. New York City, United States
3. Paris, France
4. San Francisco, United States
5. Tokyo, Japan

4 Temperature Models

We implemented two models: an autoregres-
sive model to forecast the temperature one
day ahead based on seven-day trailing tem-
peratures, and a k-nearest neighbors model
which looked at a weighted average of the 100
closest three-day trailing temperatures.

4.1 Autoregressive Model

An autoregressive model is a linear regression
of the current value in a series against one or
p(cid:88)
more prior values. More formally,
i=1

θiXt−i + At

Xt = θ0 +

Ft = θ0 + θ1Ft−1 + θ2Ft−2 + θ3Ft−3
+ θ4My−1 + θ5My−2

(1)
(2)

where

t = time, in days
Ff = temperature as a function of t
y = time, in years

5 K Nearest Neighbors

The k nearest neighbors (KNN) algorithm is
a method for supervised classiﬁcation of an
unknown ob ject based on the closest exam-
ples of that ob ject in the previously classiﬁed
training data. The KNN process is as follows:

1. Determine the distance between the un-
known ob ject (cid:126)xin and all examples (cid:126)ytr
in the training data, where the distance
function d((cid:126)xin , (cid:126)ytr ) between the ob jects
(cid:118)(cid:117)(cid:117)(cid:116) n(cid:88)
is given by
i=0
2. Choose
corresponding
examples
test
with the k(1 ≤ k ≤ n) smallest distances
d((cid:126)xin , (cid:126)ytr )

(xi − yi )2

d((cid:126)xin , (cid:126)ytr ) =

3. Use a weighted average of the values in
the training set to make a prediction for
the unknown value

where At is white noise, θi are the parame-
ters, and Xt represents the value being pre-
dicted. In our case, the autoregressive model
considered temperature values on a rolling 7-
day basis, using those values to predict the
temperature of the following day. The hy-
pothesis function is given by

In the context of creating a temperature
model, we let the temperatures of the days
preceding the test day being predicted repre-
sent the coordinates of (cid:126)ytr (such that (cid:126)ytr =
[Tt−1 , Tt−2 , ...Tt−m ], where t is the day, Tt is
the temperature in Fahrenheit, and m is the
number of trailing days used in predicting Tt ),

2

and found the k closest neighbors to (cid:126)xin . For
example, if we look at the measured temper-
ature in London over a 5-day span in August
2005, we might ﬁnd that the temperatures are
given by (cid:126)ytr = [71◦F, 78◦F, 81◦F, 74◦F, 75◦F ].
To predict the temperature on the follow-
ing day, we look at all temperature vectors
over 5 consecutive days, and calculate the dis-
tance (as deﬁned above) between that vec-
tor and (cid:126)ytr . We then choose the 100 vectors
corresponding with the minimum distances,
check the following temperature value of each
of the vectors in the training data set, and
use a weighted mean of those known results
to estimate (cid:126)xin . An empirical analysis sug-
gested an optimal result of using the preced-
ing three days, for which we let k = 100.
Given the likelihood of periodic weather be-
havior on short-term scales (and correspond-
ingly more arbitrary results when extrapolat-
ing farther backwards), we included an ex-
ponential decay weighting function to priori-
tize minimum-distance vectors occurring at a
more recent time to the predicted day.

6 Results

Figure 1 and 2 show the temperature func-
tion as predicted by the autoregressive and
the weighted 100-nearest neighbors models
for London, with the corresponding graphs
for San Francisco shown in Figure 3 and 4.
The mean absolute errors for the cities ex-
amined ranged from 1.66◦F from the autore-
gressive model for San Francisco to 3.80◦F
from the KNN model in New York City (see
Figure 5 for complete table of error values
at all evaluated locations).
In all cases, we
note that the autoregressive model predic-
tions slightly outperform those of the KNN
model, though the diﬀerence in the errors re-
mains relatively consistent. A possible ex-

Figure 1: Autoregressive model for London in
year 2012. The black o’s represent the true
data points, and the green x’s represent the
model’s predicted values

planation for this discrepancy would be due
to the empirical determination of several of
the parameters used. For instance, the size
of the vector used in the KNN implementa-
tion (for which we chose to check the three
prior days at each data point), as well as
the number of closest such vectors consid-
ered (again chosen empirically with k = 100)
are likely to have been suboptimal, despite
relatively accurate results. Further testing
would likely reveal stronger parameter values.
Alternatively, the KNN algorithm might be
improved in a multidimensional context, for
which other factors besides only the temper-
ature (such as wind speed, humidity, or pe-
riodic weather phenomenon such as El Nino)
would also be included in an analysis. Simi-
lar arguments would apply to the autoregres-
sive model; however, the coeﬃcient values for
more than three days before the actual day
were found to be small (Figure 6), indicating
that temperatures from more than three days
prior to the current day have little predic-
tive value. This point was conﬁrmed using an
Auto-Correlation Function (ACF). One par-

3

(cid:18) 2π
(cid:18) 2π
(cid:19)
τ (t) = θ1 sin
365
7
+θ5 t + θ6

+θ3 sin

t

+ θ4 cos

(cid:19)
t

(cid:18) 2π
(cid:19)
(cid:18) 2π
+ θ2 cos
365
t
7

(cid:19)
t

(3)

(4)

(5)

Figure 2: KNN model for London in year
2012.
The black o’s represent the true
data points, and the green x’s represent the
model’s predicted values

ticular observation with regards to the error
shows a link between a region’s climate and
the predictive value of the models used. In-
tuitively, one expects that a geography with
less temperature variance would correspond
with more accurate predictions, as increased
temperature ranges introduce greater ﬂuctu-
ations that are diﬃcult to accurately antici-
pate. The results in Figure 5 are consistent
with that logic, given that San Francisco rel-
atively consistent temperature patterns has
a mean absolute error of more than 2◦F less
than that of New York City, which undergoes
a much larger range of temperatures over the
course of a year. Several eﬀorts to generate
more realistic models produced less accurate
results. One such model hypothesized that
the temperature function could be assumed
to be periodic over the course of a year, with
a hypothesis function deﬁned by

4

Figure 3: Autoregressive model for San Fran-
cisco in year 2012. The black o’s represent the
true data points, and the green x’s represent
the model’s predicted values

Figure 4: KNN model for San Francisco in
year 2012. The black o’s represent the true
data points, and the green x’s represent the
model’s predicted values

(such as El Nino eﬀect, hurricanes, etc)
to provide a more comprehensive, multi-
dimensional analysis
• Extend this method to other locations
with poorer data quality to check for
consistency

Figure 5: Table of cities analyzed, with cor-
responding algorithms used and error values

8 References

1. IURL: ftp://ftp.ncdc.noaa.gov/pub/data/gsod/

2. Importing Weather Data from Wunder-
ground — California Soil Research Lab,
http://casoilresource.lawr.ucdavis.edu/drupal/node/991,
10 November, 2012

3. Hayati, M et all. ”Temperature Fore-
casting Based on Neural Network Ap-
proach.” World Applied Sciences Jour-
nal, 2007.

4. Baboo, S et all. ”An Eﬃcient Weather
Forecasting System using Artiﬁcial Neu-
ral Network.” International Journal of
Environmental Science and Develop-
ment, Vol 1. October 2010.

5. Lai, L et all. ”Intelligent Weather Fore-
cast.” International Conference on Ma-
chine Learning and Cybernetics, Shang-
hai. August 2004.

Figure 6: Coeﬃcients associated with 7-day
autoregressive analysis

7 Conclusions

The results support the idea that a sophisti-
cated model to predict temperature can pro-
vide accurate results through use of only a
temperature data set. The autoregressive
model and the KNN model both produced
predictions to within a mean absolute error
of 4◦F of the true temperatures. Future anal-
ysis would be liable to include the following:
• Use the above method on all locations
(instead of a select few cases) to increase
potential to notice trends, in turn im-
proving parameter estimations to reduce
overall error
• Use other, more sophisticated techniques
to verify/reﬁne algorithmic results
• Include knowledge about other factors

5

