Fully Bayesian inference for neural models with
negative-binomial spiking

Jonathan W. Pillow
Center for Perceptual Systems
Department of Psychology
The University of Texas at Austin
pillow@mail.utexas.edu

James G. Scott
Division of Statistics and Scientiﬁc Computation
McCombs School of Business
The University of Texas at Austin
james.scott@mccombs.utexas.edu

Abstract

Characterizing the information carried by neural populations in the brain requires
accurate statistical models of neural spike responses. The negative-binomial dis-
tribution provides a convenient model for over-dispersed spike counts, that is,
responses with greater-than-Poisson variability. Here we describe a powerful
data-augmentation framework for fully Bayesian inference in neural models with
negative-binomial spiking. Our approach relies on a recently described latent-
variable representation of the negative-binomial distribution, which equates it to
a Polya-gamma mixture of normals. This framework provides a tractable, con-
ditionally Gaussian representation of the posterior that can be used to design ef-
ﬁcient EM and Gibbs sampling based algorithms for inference in regression and
dynamic factor models. We apply the model to neural data from primate retina
and show that it substantially outperforms Poisson regression on held-out data,
and reveals latent structure underlying spike count correlations in simultaneously
recorded spike trains.

1

Introduction

A central problem in systems neuroscience is to understand the probabilistic representation of infor-
mation by neurons and neural populations. Statistical models play a critical role in this endeavor, as
they provide essential tools for quantifying the stochasticity of neural responses and the information
they carry about various sensory and behavioral quantities of interest.
Poisson and conditionally Poisson models feature prominently in systems neuroscience, as they
provide a convenient and tractable description of spike counts governed by an underlying spike rate.
However, Poisson models are limited by the fact that they constrain the ratio between the spike count
mean and variance to one. This assumption does not hold in many brain areas, particularly cortex,
where responses are often over-dispersed relative to Poisson [1].
A second limitation of Poisson models in regression analyses (for relating spike responses to stimuli)
or latent factor analyses (for ﬁnding common sources of underlying variability) is the difﬁculty of
performing fully Bayesian inference. The posterior formed under Poisson likelihood and Gaussian
prior has no tractable representation, so most theorists resort to either fast, approximate methods
based on Gaussians, [2–9] or slower, sampling-based methods that may scale poorly with data or
dimensionality [10–15].
The negative-binomial (NB) distribution generalizes the Poisson with a shape parameter that con-
trols the tradeoff between mean and variance, providing an attractive alternative for over-dispersed
spike count data. Although well-known in statistics, it has only recently been applied for neural
data [16–18]. Here we describe fully Bayesian inference methods for the neural spike count data
based on a recently developed representation of the NB as a Gaussian mixture model [19]. In the

1

Figure 1: Representations of the negative-binomial (NB) regression model. (A) Graphical model for
standard gamma-Poisson mixture representation of the NB. The linearly projected stimulus ψt =
β T xt deﬁnes the scale parameter for a gamma r.v. with shape parameter ξ , giving λt ∼ Ga(eψt , ξ ),
which is in turn the rate for a Poisson spike count: yt ∼ Poiss(λt ). (B) Graphical model illustrating
novel representation as a Polya-Gamma (PG) mixture of normals. Spike counts are represented as
NB distributed with shape ξ and rate pt = 1/(1 + e−ψt ). The latent variable ωt is conditionally PG,
while ψ (and β |x) are normal given (ωt , ξ ), which facilitates efﬁcient inference. (C) Relationship
between spike-count mean and variance for different settings of shape parameter ξ , illustrating super-
Poisson variability of the NB model.

following, we review the conditionally Gaussian representation for the negative-binomial (Sec. 2),
describe batch-EM, online-EM and Gibbs-sampling based inference methods for NB regression
(Sec. 3), sampling-based methods for dynamic latent factor models (Sec. 4), and show applications
to spiking data from primate retina.

2 The negative-binomial model
Begin with the single-variable case where the data Y = {yt} are scalar counts observed at times
t = 1, . . . , N . A standard Poisson generalized linear model (GLM) assumes that yt ∼ Pois(eψt ),
where the log rate parameter ψt may depend upon the stimulus. One difﬁculty with this model is
that the variance of the Poisson distribution is equal to its mean, an assumption that is violated in
many data sets [20–22].
To relax this assumption, we can consider the negative binomial model, which can be described as a
doubly-stochastic or hierarchical Poisson model [18]. Suppose that yt arises according to:
(λt | ξ , ψt ) ∼ Ga (cid:0)ξ , eψt (cid:1) ,
(yt | λt ) ∼ Pois(λt )
where we have parametrized the Gamma distribution in terms of its shape and scale parameters. By
marginalizing over the top-level model for λt , we recover a negative-binomial distribution for yt :
p(yt | ξ , ψt ) ∝ (1 − pt )ξ pyt
t
where pt is related to ψt via the logistic transformation:
eψt
1 + eψt
The extra parameter ξ therefore allows for over-dispersion compared to the Poisson, with the count
yt having expected value ξeψt and variance ξeψt (1 + eψt ). (See Fig. 1).
Bayesian inference for models of this form has long been recognized as a challenging problem, due
to the analytically inconvenient form of the likelihood function. To see the difﬁculty, suppose that
t β is a linear function of known inputs xt = (xt1 , . . . , xtP )T . Then the conditional posterior
ψt = xT
p(β | ξ , Y ) ∝ p(β ) · N(cid:89)
distribution for β , up to a multiplicative constant, is
{exp(xT
t β )}yt
{1 + exp(xT
t β )}ξ+yt
t=1
where p(β ) is the prior distribution, and where we have assumed for the moment that ξ is ﬁxed.
The two major issues are the same as those that arise in Bayesian logistic regression: the response

pt =

,

,

(1)

.

2

AweightsshapestimulusresponseClatentBPoisson0501000100200300meanvarianceX D=

,

(2)

depends non-linearly upon the parameters, and there is no natural conjugate prior p(β ) to facilitate
posterior computation.
One traditional approach for Bayesian inference in logistic models is to work directly with the
discrete-data likelihood. A variety of tactics along these lines have been proposed, including numer-
ical integration [23], analytic approximations to the likelihood [24–26], or Metropolis-Hastings [27].
A second approach is to assume that the discrete outcome is some function of an unobserved contin-
uous quantity or latent variable. This is most familiar in the case of Bayesian inference for the probit
or dichotomized-Gaussian model [28, 29], where binary outcomes yi are assumed to be thresholded
versions of a latent Gaussian quantity zi . The same approach has also been applied to logistic
and Poisson regression [30, e.g.]. Unfortunately, none of these schemes lead to a fully automatic
approach to posterior inference, as they require either approximations (whose quality must be vali-
dated) or the careful selection of tuning constants (as is typically required when using, for example,
the Metropolis–Hastings sampler in very high dimensions).
To proceed with Bayesian inference in the negative-binomial model, we appeal to a recent latent-
variable construction (depicted in Fig. 1B) from [19] based on the theory of Polya-Gamma random
variables. The basic result we exploit is that the negative binomial likelihood can be represented as
a mixture of normals with Polya-Gamma mixing distribution. The algorithms that result from this
scheme are both exact (in the sense of avoiding analytic approximations) and fully automatic.
Deﬁnition 1. A random variable X has a Polya-Gamma distribution with parameters b > 0 and
∞(cid:88)
c ∈ R, denoted X ∼ PG(b, c), if
1
gk
(k − 1/2)2 + c2/(4π2 )
2π2
k=1
where each gk ∼ Ga(b, 1) is an independent gamma random variable, and where D= denotes equality
in distribution.
(cid:90) ∞
We make use of four important facts about Polya-Gamma variables from [19]. First, suppose that
p(ω) denotes the density of the random variable ω ∼ PG(b, 0), for b > 0. Then for any choice of a,
(eψ )a
(1 + eψ )b = 2−b eκψ
e−ωψ2 /2 p(ω) dω ,
(3)
0
where κ = a − b/2. This integral identity allows us to rewrite each term in the negative binomial
(cid:90) ∞
likelihood (eq. 1) as
{exp(ψt )}yt
(1 − pt )ξ pyt
∝ eκtψt
e−ωtψ2 /2 p(ω | ξ + yt , 0) dω ,
(4)
{1 + exp(ψt )}h+yt
t =
0
where κt = (yt − ξ )/2, and where the mixing distribution is Polya-Gamma. Conditional upon ωt ,
we have a likelihood proportional to e−Q(ψt ) for some quadratic form Q, which will be conditionally
conjugate to any Gaussian or mixture-of-Gaussians prior for ψt . This conditional Gaussianity can
be exploited to great effect in MCMC, EM, and sequential Monte Carlo algorithms, as described in
the next section.
A second important fact is that the conditional distribution
(cid:82) ∞
e−ωψ2 /2 p(ω)
p(ω | ψ) =
0 e−ωψ2 /2 p(ω) dω
is also in the Polya-Gamma class: (ω | ψ) ∼ PG(b, ψ). In this sense, the Polya-Gamma distribution
is conditionally conjugate to the NB likelihood, which is very useful for Gibbs sampling.
Third, although the density of a Polya-Gamma random variable can be expressed only as an inﬁnite
series, its expected value is known in closed form: if ω ∼ PG(b, c), then
b
2c
As we show in the next section, this expression comes up repeatedly when ﬁtting negative-binomial
models via expectation-maximization, where these moments of ωt form a set of sufﬁcient statistics
for the complete-data log posterior distribution in β .

tanh(c/2) .

E (ω) =

(5)

3

Finally, despite the awkward form of the density function, it is still relatively easy to simulate random
Polya-Gamma draws, avoiding entirely the need to truncate the inﬁnite sum in Equation 2. As the
authors of [19] show, this can be accomplished via a highly efﬁcient accept-reject algorithm using
ideas from [31]. The proposal distribution requires only exponential, uniform, and normal random
variates; and the algorithm’s acceptance probability is uniformly bounded below at 0.9992 (implying
roughly 8 rejected draws out of every 10,000 proposals).
As we now describe, these four facts are sufﬁcient to allow straightforward Bayesian inference for
negative-binomial models. We focus ﬁrst on regression models, for which we derive simple Gibbs
sampling and EM algorithms. We then turn to negative-binomial dynamic factor models, which can
be ﬁt using a variant of the forward-ﬁlter, backwards-sample (FFBS) algorithm [32].

3 Negative-binomial regression

3.1 Fully Bayes inference via MCMC

Suppose that ψt = xT
t β for some p-vector of regressors xt . Then, conditional upon ωt , the contri-
bution of observation t to the likelihood is
(cid:40)
(cid:19)2(cid:41)
(cid:18) yt − ξ
t β )2 /2}
t β − ωt (xT
Lt (β ) ∝ exp{κtxT
− ωt
∝ exp
− xT
t β
.
2
2ωt
Let Ω = diag(ω1 , . . . , ωn ); let zt = (yt − ξ )/(2ωt ); and let z denote the stacked vector of zt terms.
Combining all terms in the likelihood leads to a Gaussian linear-regression model where
(z | β , Ω) ∼ N (X β , Ω−1 ) .
It is usually reasonable to assume a conditionally Gaussian prior, β ∼ N (c, C ). Note that C itself
may be random, as in, for example, a Bayesian lasso or horseshoe prior [33–35]. Gibbs sampling
proceeds in two simple steps:

(ωt | ξ , β ) ∼ PG(yt + ξ , xT
t β )
(β | Ω, z ) ∼ N (m, V ) ,
where PG denotes a Polya-Gamma draw, and where
V = (X T ΩX + C −1 )−1
m = V (X T Ωz + C −1 c) .
One may update the dispersion parameter ξ via Gibbs sampling, using the method described in [36].

3.2 Batch EM for MAP estimation

We may also use the same data-augmentation trick in an expectation-maximization (EM) algorithm
to compute the maximum a-posteriori (MAP) estimate ˆβ . Returning to the likelihood in (4) and
ignoring constants of proportionality, we may write the complete-data log posterior distribution,
(cid:27)
(cid:26)
N(cid:88)
given ω1 , . . . , ωN , as
t β ) · yt − ξ
(xT
t β )2
− ωt
Q(β ) = log p(β | Y , ω1 , . . . , ωN ) =
(xT
+ log p(β )
2
2
t=1
for some prior p(β ). This expression is linear in ωt . Therefore we may compute E {Q(β )} by
substituting ˆωt = E (ωt | β ), given the current value of β , into the above expression. Appealing to
(cid:18) κt
(cid:19)
(5), these conditional expectations are available in closed form:
E (ωt | β ) =
tanh(xT
t β /2) ,
xT
t β
where κt = (yt − ξ )/2. In the M step, we re-express E {Q(β )} as
E {Q(β )} = − 1
β T S β + β T d + log p(β ) ,
2

4

where the complete-data sufﬁcient statistics are

S = X T ˆΩX
d = X T κ
for ˆΩ = diag( ˆω1 , . . . , ˆωN ) and κ = (κ1 , . . . , κN )T . Thus the M step is a penalized weighted least
squares problem, which can be solved using standard methods. In fact, it is typically unnecessary
to maximize E {Q(β )} exactly at each iteration. As is well established in the literature on the EM
algorithm, it is sufﬁcient to move to a value of β that merely improves that observed-data objective
function. We have found that it is much faster to take a single step of the conjugate conjugate-
gradient algorithm (in which case in will be important to check for improvement over the previous
iteration); see, e.g. [37] for details.

3.3 Online EM

where

S (t−1) =

ˆωixixT
i

(6)

d(t−1) =

For very large data sets, the above batch algorithm may be too slow. In such cases, we recommend
computing the MAP estimate via an online EM algorithm [38], as follows. Suppose that our current
estimate of the parameter is β (t−1) , and that the current estimate of the complete-data log posterior
is
Q(β ) = − 1
2

β T S (t−1)β + β T d(t−1) + log p(β ) ,
t−1(cid:88)
t−1(cid:88)
i=1
κixi ,
i=1
(cid:18) κt
(cid:19)
recalling that κi = (yi − ξ )/2. After observing new data (yt , xt ), we ﬁrst compute the expected
value of ωt as
ˆωt = E (ωt | yt , β (t−1) ) =
tanh(ψt/2) ,
ψt
t β (t−1) denoting the linear predictor evaluated at the current estimate. We then update
with ψt = xT
the sufﬁcient statistics recursively as
S (t) = (1 − γt )S (t−1) + γt ˆωtxtxT
t
d(t) = (1 − γt )d(t−1) + γtκtxt ,
where γt is the learning rate. We then plug these updated sufﬁcient statistics into (6), and solve the
M step to move to a new value of β . The data can also be processed in batches of size larger than 1,
√
with obvious modiﬁcations to the updates for S (t) and d(t) ; we have found that batch sizes of order
p tend to work well, although we are unaware of any theory to support this choice.

In high-dimensional problems, the usual practice is to impose sparsity via an (cid:96)1 penalty on the
regression coefﬁcients, leading to a lasso-type prior. In this case, the M-step in the online algorithm
can be solved very efﬁciently using the modiﬁed shooting algorithm, a coordinate-descent method
t=1 γt = ∞ and (cid:80)∞
learning rate decays in time such that (cid:80)∞
described in a different context by [39] and [40].
This online EM is guaranteed to converge to a stationary point of the log posterior distribution if the
t < ∞. (If the penalty function is
t=1 γ 2
concave and ξ is ﬁxed, then this stationary point will be the global maximum.) A simple choice for
the learning rate is γt = 1/ta for a ∈ (0.5, 1), with a = 0.7 being our default choice.

4 Factor analysis for negative-binomial spiking

Let ψt = (ψt1 , . . . , ψtK ) denote a vector of K linear predictors at time t, corresponding to K
different neurons with observed counts Yt = (yt1 , . . . , ytK )T . We propose a dynamic negative-

5

for k = 1, . . . K

binomial factor model for Yt , with a vector autoregressive (VAR) structure for the latent factors:
ytk ∼ NB(ξ , eψtk )
ψt = α + B ft
t ∼ N(0, τ 2 I ) .
ft = Γft−1 + t ,
Here ft denotes an L-vector of latent factors, with L typically much smaller than P . The K × L
factor-loadings matrix B is restricted to have zeroes above the diagonal, and to have positive diag-
onal entries. These restrictions are traditional in Bayesian factor analysis [41], and ensure that B
is formally identiﬁed. We also assume that Γ is a diagonal matrix, and impose conjugate inverse-
gamma priors on τ 2 to ensure that, marginally over the latent factors ft , the entries of ψt have
approximately unit variance. Although we do not pursue the point here, the mean term α can incor-
porate the effect of known predictors with no additional complication to the analysis.
By exploiting the Polya-Gamma data-augmentation scheme, posterior inference in this model may
proceed via straightforward Gibbs sampling—something not previously possible for count-data fac-
tor models. Prior work on latent variable modeling of spike data has relied on either Gaussian
approximations [2–6, 8] or variants of particle ﬁltering [10–13].
Gibbs sampling proceeds as follows. Conditional upon B and ft , we update the latent variables as
ωtk ∼ PG(ytk + ξ , Bk ft ), where Bk denotes the k th row of the loadings matrix. The mean vector
α and factor-loadings matrix B can both be updated in closed-form via a Gaussian draw using the
full conditional distributions given in, for example, [42] or [43].
Given all latent variables and other parameters of the model, the factors ft can be updated in a single
block using the forward-ﬁlter, backwards-sample (FFBS) algorithm from [32]. First, pass forwards
through the data from y1 to yN , recursively computing the ﬁltered moments of ft as
Mt = (V −1
t + B T ΩtB )−1
mt = Mt (B T Ωt zt + V −1
t Γmt−1 ) ,

where

Vt = ΓMt−1ΓT + τ 2 I

zt = (zt1 , . . . , ztK )T

,

ztk =

ytk − ξ
2ωtk

− αk

Ωt = diag(ωt1 , . . . , ωtK ) .
Then draw fN ∼ N(mN , MN ) from its conditional distribution. Finally, pass backwards through
the data, sampling ft as (ft | mt , Mt , ft+1 ) ∼ N(at , At ), where
A−1
= M −1
t + τ −2 I
t
at = A−1
t (M −1
t mt + τ −2 ft+1 ) .
This will result in a block draw of all N × L factors from their joint conditional distribution.

5 Experiments

To demonstrate our methods, we performed regression and dynamic factor analyses on a dataset of
27 neurons recorded from primate retina (published in [44] and re-used with authors’ permission).
Brieﬂy, these data consist of spike responses from a simultaneously-recorded population of ON and
OFF parasol retinal ganglion cells, stimulated with a ﬂickering, 120-Hz binary white noise stimulus.

5.1 Regression

Figure 2 shows a comparison of a Poisson model versus a negative-binomial model for each of the
27 neurons in the retinal dataset. We binned spike counts in 8 ms bins, and regressed against a
temporally lagged stimulus, resulting in a 100-element (10 × 10 pixel) spatial receptive ﬁeld β for
each neuron. To benchmark the two methods, we created 50 random train/test splits from a full
dataset of 30,000 points, with 7,500 points held out for validation. Using each training set, we used

6

Figure 2: Boxplots of improvement in held-out log likelihoods (NB versus Poisson regression) for
50 train/test splits on each of the 27 neurons in the primate retinal data.

our online maximum-likelihood method to ﬁt an NB model to each of the 27 neurons, and then used
these models to compute held-out log-likelihoods on the test set versus a standard Poisson GLM.
As Figure 2 shows, the NB model has a higher average held-out log-likelihood than the Poisson
model. In some cases it is dozens of orders of magnitude better (as in neurons 12–14 and 22–27),
suggesting that there is substantial over-dispersion in the data that is not faithfully captured by the
Poisson model. We emphasize that this is a “weak-signal” regime, and that overdispersion is likely
to be less when the signal is stronger. Yet these results suggest, at the very least, that many of these
neurons have marginal distributions that are quite far from Poisson. Moreover, regardless of the
underlying signal strength, the regression problem can be handled quite straightforwardly using our
online method, even in high dimensions, without settling for the restrictive Poisson assumption.

5.2 Dynamic factor analysis

To study the factor-modeling framework, we conducted parallel experiments on both simulated and
real data. First, we simulated two different data sets comprising 1000 time points and 11 neurons,
each from a two-factor model: one with high factor autocorrelation (Γ = 0.98), and one with low
factor autocorrelation (Γ = 0.5). The two questions of interest here are: how well does the fully
Bayesian method reconstruct the correlation structure among the unobserved rate parameters ψtk ;
and how well does it distinguish between a high-autocorrelation and low-autocorrelation regime in
the underlying low-dimensional representation?
The results in Figure 3 suggest that the results, on both counts, are highly accurate. It is especially
interesting to compare the left-most column of Figure 3 with the actual cross-sectional correlation
of ψt , the systematic component of variation, in the second column. The correlation of the raw
counts yt show a dramatic attenuation effect, compared to the real latent states. Yet this structure is
uncovered easily by the model, with together with a full assessment of posterior uncertainty. The
approach behaves much like a model-based version of principal-components analysis, appropriate
for non-Gaussian data.
Finally, Figure 4 shows the results of ﬁtting a two-factor model to the primate retinal data. We
are able to uncover latent structure in the data in a completely unsupervised fashion. As with the
simulated data, it is interesting to compare the correlation of the raw counts yt with the estimated
correlation structure of the latent states. There is also strong support for a low-autocorrelation regime
in the factors, in light of the posterior mean factor scores depicted in the right-most pane.

6 Discussion

Negative-binomial models have only recently been explored in systems neuroscience, despite their
favorable properties for handling data with larger-than-Poisson variation. Likewise, Bayesian infer-
ence for the negative binomial model has traditionally been a difﬁcult problem, with the existence
of a fully automatic Gibbs sampler only recently discovered [19]. Our paper has made three spe-
ciﬁc contributions to this literature. First, we have shown that negative-binomial models can lead to

7

NeuronIncrease in Held-Out Log Likelihood123456789101112131415161718192021222324252627020406080100120140Figure 3: Results for two simulated data sets with high factor autocorrelation (top row) and low
factor autocorrelation (bottom row). The three left-most columns show the raw correlation among
t ), of the latent states; and the posterior mean estimator
the counts yt ; the actual correlation, E (ψtψT
for the correlation of the latent states. The right-most column shows the simulated spike trains for
the 11 neurons, along with the factors ft in blue (with 75% credible intervals), plotted over time.

Figure 4: Results for factor analysis of the primate retinal data.

substantial improvements in ﬁt, compared to the Poisson, for neural data exhibiting over-dispersion.
Such models can be ﬁt straightforwardly via MCMC for a wide class of prior distributions over
model parameters (including sparsity-inducing choices, such as the lasso). Second, we have pro-
posed a novel online-EM algorithm for sparse NB regression. This algorithm inherits all the con-
vergence properties of EM, but is scalable to extremely large data sets. Finally, we have embedded
a dynamic factor model inside a negative-binomial likelihood. This latter approach can be extended
quite easily to spatial interactions, more general state-space models, or mixed models incorporating
both regressors and latent variables. All of these extensions, as well as the model-selection question
(how many factors?) form promising areas for future research.

Acknowledgments

We thank E. J. Chichilnisky, A. M. Litke, A. Sher and J. Shlens for retinal data, J. Windle for
PG sampling code, and J. H. Macke for helpful comments. This work was supported by a Sloan
Research Fellowship, McKnight Scholar’s Award, and NSF CAREER Award IIS-1150186 (JP).

8

Correlation Among Spike CountsNeuron1110987654321Actual Correlation Among Latent StatesEstimated Correlation Among Latent StatesIndexIndexIndexIndexIndexIndexIndexIndexIndexCorrelation Among Spike CountsNeuron1110987654321Actual Correlation Among Latent StatesEstimated Correlation Among Latent StatesIndexIndexIndexIndexIndexIndexIndexIndexIndexNeuron1110987654321IndexIndexIndexIndexIndexIndexIndexIndexIndexIndexCorrelation among spike countsEstimated correlation of latent statesSpike countsPosterior mean factor scoresIEEE Trans

References
[1] Roland Baddeley, L. F. Abbott, Michael C. A. Booth, Frank Sengpiel, Tobe Freeman, Edward A. Wake-
man, and Edmund T. Rolls. Proceedings of the Royal Society of London. Series B: Biological Sciences,
264(1389):1775–1783, 1997.
[2] E. Brown, L. Frank, D. Tang, M. Quirk, and M. Wilson. Journal of Neuroscience, 18:7411–7425, 1998.
[3] L. Srinivasan, U. Eden, A. Willsky, and E. Brown. Neural Computation, 18:2465–2494, 2006.
[4] B. M. Yu, J. P. Cunningham, G. Santhanam, S. I. Ryu, K. V. Shenoy, and M. Sahani. Journal of Neuro-
physiology, 102(1):614, 2009.
[5] W. Wu, J.E. Kulkarni, N.G. Hatsopoulos, and L. Paninski. Neural Systems and Rehabilitation Engineer-
ing, IEEE Transactions on, 17(4):370–378, 2009.
[6] Liam Paninski, Yashar Ahmadian, Daniel Gil Ferreira, Shinsuke Koyama, Kamiar Rahnama Rad, Michael
Vidne, Joshua Vogelstein, and Wei Wu. J Comput Neurosci, Aug 2009.
[7] J. W. Pillow, Y. Ahmadian, and L. Paninski. Neural Comput, 23(1):1–45, Jan 2011.
[8] M Vidne, Y Ahmadian, J Shlens, J W Pillow, J Kulkarni, A M Litke, E J Chichilnisky, E P Simoncelli,
and L Paninski. J. Computational Neuroscience, pages 1–25, 2012. To appear.
[9] John P. Cunningham, Krishna V. Shenoy, and Maneesh Sahani. Proceedings of the 25th international
conference on Machine learning, ICML ’08, pages 192–199, New York, NY, USA, 2008. ACM.
[10] A. E. Brockwell, A. L. Rojas, and R. E. Kass. J Neurophysiol, 91(4):1899–1907, Apr 2004.
[11] S. Shoham, L. Paninski, M. Fellows, N. Hatsopoulos, J. Donoghue, and R. Normann. IEEE Transactions
on Biomedical Engineering, 52:1312–1322, 2005.
[12] Ayla Ergun, Riccardo Barbieri, Uri T. Eden, Matthew A. Wilson, and Emery N. Brown.
Biomed Eng, 54(3):419–428, Mar 2007.
[13] A. E. Brockwell, R. E. Kass, and A. B. Schwartz. Proceedings of the IEEE, 95:1–18, 2007.
[14] R. P. Adams, I. Murray, and D. J. C. MacKay. Proceedings of the 26th Annual International Conference
on Machine Learning. ACM New York, NY, USA, 2009.
[15] Y. Ahmadian, J. W. Pillow, and L. Paninski. Neural Comput, 23(1):46–96, Jan 2011.
[16] M.C. Teich and W.J. McGill. Physical Review Letters, 36(13):754–758, 1976.
[17] Arno Onken, Steffen Grnewlder, Matthias H. J. Munk, and Klaus Obermayer. PLoS Comput Biol,
5(11):e1000577, 11 2009.
[18] R Goris, E P Simoncelli, and J A Movshon. Computational and Systems Neuroscience (CoSyNe), Salt
Lake City, Utah, February 2012.
[19] N.G. Polson, J.G. Scott, and J. Windle. Arxiv preprint arXiv:1205.0310, 2012.
[20] P. L ´ansk `y and J. Vaillant. Biosystems, 58(1):27–32, 2000.
[21] V. Ventura, C. Cai, and R.E. Kass. Journal of neurophysiology, 94(4):2928–2939, 2005.
[22] Neural Comput, 18(11):2583–2591, Nov 2006.
[23] A.M. Skene and J. C. Wakeﬁeld. Statistics in Medicine, 9:919–29, 1990.
[24] J. Carlin. Statistics in Medicine, 11:141–58, 1992.
[25] Eric T. Bradlow, Bruce G. S. Hardie, and Peter S. Fader. Journal of Computational and Graphical Statis-
tics, 11(1):189–201, 2002.
[26] A. Gelman, A. Jakulin, M.G. Pittau, and Y. Su. The Annals of Applied Statistics, 2(4):1360–83, 2008.
[27] A. Dobra, C. Tebaldi, and M. West. Journal of Statistical Planning and Inference, 136(2):355–72, 2006.
[28] James H. Albert and Siddhartha Chib. Journal of the American Statistical Association, 88(422):669–79,
1993.
[29] M. Bethge and P. Berens. Advances in neural information processing systems, 20:97–104, 2008.
[30] C. Holmes and L. Held. Bayesian Analysis, 1(1):145–68, 2006.
[31] Luc Devroye. Statistics & Probability Letters, 79(21):2251–9, 2009.
[32] Chris Carter and Robert Kohn. Biometrika, 81(541-53), 1994.
[33] Trevor Park and George Casella. Journal of the American Statistical Association, 103(482):681–6, 2008.
[34] Chris M. Hans. Biometrika, 96(4):835–45, 2009.
[35] Carlos M. Carvalho, Nicholas G. Polson, and James G. Scott. Biometrika, 97(2):465–80, 2010.
[36] Mingyuan Zhou, Lingbo Li, David Dunson, and Lawrence Carin. International Conference on Machine
Learning (ICML), 2012.
[37] Nicholas G. Polson and James G. Scott.
http://arxiv.org/abs/1103.5407v3, 2011.
[38] O. Capp ´e and E. Moulines. Journal of the Royal Statistical Society (Series B), 71(3):593–613, 2009.
[39] Suhrid Balakrishnan and David Madigan. Journal of Machine Learning Research, 9:313–37, 2008.
[40] Liang Sun and James G. Scott. Technical report, University of Texas at Austin, 2012.
[41] H. Lopes and M. West. Statistica Sinica, 14:41–67, 2004.
[42] Joyee Ghosh and David B. Dunson. Journal of Computational and Graphical Statistics, 18(2):306–20,
2009.
[43] P.R. Hahn, Carlos M. Carvalho, and James G. Scott. Journal of the Royal Statistical Society, Series C,
2012.
[44] J. W. Pillow, J. Shlens, L. Paninski, A. Sher, A. M. Litke, and E. P. Chichilnisky, E. J. Simoncelli. Nature,
454:995–999, 2008.

report, University of Texas at Austin,

Technical

9

