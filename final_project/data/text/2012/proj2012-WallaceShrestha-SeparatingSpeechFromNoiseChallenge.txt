Autumn	2012

CS229	Project 	:	Separating	Speech	From	Noise	Challenge

S e parating Spe

e

c h From Noise   C halle nge

Wehaveusedthedatafrom thePASCAL CHiME challengewiththegoaloftrainingaSupport Vector
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Machine( SVM)
 
to estimateanoisemaskthat labels time-frames/frequency-bins oftheaudio as ‘r
 
 
 
 
 
 
 
 
 
 
 
 
 
e liab le ’or
 
‘u n r
e liab le ’.This noisemaskcouldbeusedby another blockin thesignalprocessingpipelineto treat the
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
unreliabledataas missingandthen replacethemissingdatawithan estimateoftheclean audio by searchinga
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
corpus ofclean audio samples for themost probablematchusingthefeatures oftheunreliabledataandthe
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
surroundingaudio.For this project,wehavefocusedon thenoisemaskestimation usingan SVM andnot on the
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
that given agoodnoise
dataimputation portion oftheproblem.It has been demonstratedby Kallasjokiet al.[ 1]
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
mask,it is possibleto achievesignificant improvements in automatedspeechrecognition accuracy rates by
 
 
 
 
 
 
 
 
 
 
 
 
 
 
replacing unreliable portions of the audio with estimates of the clean audio.

In order to judgetheSVM classification accuracy in generatinganoisemask,weneededan ‘o r ac le
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
mas k’whichgavethecorrect answer for themask.Theoraclemaskgenerates alabelofreliableor unreliablefor
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
timeframe/frequency pairs,usingtheMelfilterbankenergies oftheclean signalandthenoisy signalandlabeling
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
time/frequency pairs as unreliable if the SNR is less than -3 dB.

Usingtheoraclemask,weestimatedthebest-caseperformanceofnoisemaskestimation anddata
 
 
 
 
 
 
 
 
 
 
 
 
 
 
imputation by replacingunreliabletime/frequency segments ( as labeledby theoraclemask) withtheknown clean
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
speechaudio.As expected,this achieves very goodrecognition rates that approachtheaccuracy oftheusingthe
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
clean speechaudio. As previously discussed,previous work[ 1] has demonstratedsignificant performance
 
 
 
 
 
 
 
 
 
 
 
 
improvements usingan oraclemaskalongwithsparseimputation methods.Estimatingthenoisemaskwas aweak
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
point in thepaper citedabove.Our goalhas been to improveon thenoisemaskgeneration usingmachinelearning
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
methods.

Sincetheautomaticspeechrecognition system usedin theCHiME project ( HTK ) uses theMelfilterbank
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
energies as features for ahidden Markov model,westartedby usingthesesamefilterbankenergies as features
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
for thesupport vector machineto estimateanoisemask.Wehaveusedthefreely availabletools LIBLINEAR
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
[ 2] andLIBSVM [ 3] for trainingandprediction rather than writingan SVM fromscratch,allowingus to focus on
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
featureselection,kernelselection,etc.Sincethenoisemaskgenerates alabelofreliable/unreliablefor each
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
frequency bin, time frame pair, we needed to train a separate SVM for each frequency bin.

Thefulldataset consistedofhundreds ofthousands oftrainingexamples ( whereeachtrainingexample
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
consists ofatimeframeofMelfilterbankenergies for eachfrequency bin) .This largedataset hadthepotential
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
to result in longtrainingandprediction times. Twenty separateSVMs neededto betrained,onefor each
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
frequency bin ofinterest.Weexperimentedandfoundthat thetrainingaccuracies for theSVMs for different
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
frequency bins wererelatively similar,so to keep theproblemtractable,wefocusedon asinglefrequency bin ( one
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
SVM)  while learning about the SVM.

Westartedby usingthelogfilterbankenergies for allfrequency bins in agiven timeframeas features for
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
allSVMs ( all20 SVMs hadthesamefeatures,just different labels ) .Weusedalinear kernel( LIBLINEAR) and
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
foundthat theclassification accuracy was unacceptably low.Usingthemiddlefrequency bin ( k=10) and100,000
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
examples ( out ofroughly 600,000 totaltrainingexamples,split with90,000 trainingexamples and10,000 test
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 Page	1
examples ) ,thelinear kernelresultedin aclassification accuracy of56.3%. Scalingthefeatures to arangeof
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

Autumn	2012

CS229	Project 	:	Separating	Speech	From	Noise	Challenge

[ -1,1]  improved the accuracy to 64.7% while reducing the runtime by an order of magnitude.

Sincethetrainingset was quitelarge,trainingandprediction withanonlinear kernel( usingLIBSVM) was
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
very slow,so wepursuedimprovingtheaccuracy ofthelinear kernel.By observingthetrainingandtesting
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
accuracy for various trainingset sizes,wedeterminedthat theSVM usingalinear kernelwas underfittingthedata,
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
so weconsideredwhat additionalfeatures couldbeaddedthat wouldberelevant to generatingan accuratenoise
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
mask.

Temporalinformation about what thespectrum oftheaudio is beforeandafter thetimeframeofinterest
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
couldbeusedto provideadditionalinformation to theclassifier.Addingfeatures for theframebeforeandthe
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
frameafter for allfrequency bins improvedtheaccuracy relativeto only scalingthefeatures from64.7% to 65.8%
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
for our test setup  ( 90,000 training examples, 10,000 test examples, frequency bin 10, linear kernel) .

Wethought that therewas likely to besomecorrelation between thefeatures that was not accountedfor
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
withthelinear kernel,so weinvestigatedaddingfeatures that consistedofproduct terms ofthefeatures.This
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
improvedaccuracy relativeto only scalingthefeatures from 64.7% to 70.1%.However,addingthesquared
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
features meant that thenumber offeatures went from 20 to 400.Wewerelimitedby thevirtualaddress space
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
availablein Matlab( 32-bit student edition) in addition to theruntimefor SVM trainingandclassification,so we
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
were limited in the number of additional features we could add.

In theCHiME setup,thespeaker was in afixedlocation whilethenoisecouldbeat any location,andthe
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
audio was recordedviatwo microphones. Up to this point wehadbeen usingtheaverageofthetwo audio
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
channels to findthelogfilterbankenergies to beusedas features.Weaddedadditionallogfilterbankenergy
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
features for thedifferencebetween theaudio channels. Usingscaling,differenceandrepeatedtimeframes
 
 
 
 
 
 
 
 
 
 
 
 
 
 
improved the accuracy slightly from 70.1% to 70.5%.

At this point our classification accuracy on thetrainingset was stillunacceptably low andthelinear kernel
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
was stillunderfittingthedata.Wewererunninginto issues addingadditionalfeatures becausewewerehittingthe
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
maximumarray sizein 32-bit Matlab.DespitethehighruntimeoftheSVM usinganonlinear kernel( libSVM) we
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
knew we likely needed a nonlinear kernel in order to have the model complexity necessary to fit the data.

Similar to thelinear kernel,werecordedaccuracy vs modelcomplexity for severalpossiblefeaturesets.
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Usingtheoriginalunscaledlogfilterbankenergy features,aradialbasis function kernel,thesame100,000 training
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
examples but split using4-way cross validation ( vs 90/10 without cross-validation for thelinear kernel) ,theSVM
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
achievedan accuracy of52.3% on themiddlefrequency bin ( k=10) . This is similar to what thelinear kernel
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
achieved. Weperformedasearchover theSVM parameters,usingcross-validation to select theoptimal
 
 
 
 
 
 
 
 
 
 
 
 
 
 
parameters ( unfortunately wedidnot recordabefore/after accuracy for this step) . Usingscaledfeatures
 
 
 
 
 
 
 
 
 
 
 
 
 
 
increasedtheaccuracy to 71.9% whiledecreasingtheruntime. Addingthedifferencefeatures that were
 
 
 
 
 
 
 
 
 
 
 
 
 
 
previously describedalongwithscalingincreasedtheaccuracy from 71.9% to 77.4% Addingthefeatures for the
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
timeframebeforeandafter theframeofinterest alongwithscalingandusingdifferencefeatures increasedthe
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
cross-validation accuracy from 77.4% to 82.1%.At this point theaccuracy when testingon thesamedataas the
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
SVM was trainedresultedin an accuracy of~87% vs 82.1% usingcross-validation,so thetest accuracy was
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
approachingthetrainingaccuracy.It was difficult to tellwhether thetrainingaccuracy wouldconvergeto thetest
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
accuracy given enoughdataor not.However weknew that thetrainingaccuracy representedan upper boundon
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
theaccuracy for thecurrent featureset.Weaddedonemoreset offeatures representingthespeaker identify
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Page	2

Autumn	2012

CS229	Project 	:	Separating	Speech	From	Noise	Challenge

( whichis known for theCHiME dataset) ,wherea‘1’in aparticular position in thefeaturevector indicates that
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
that speaker is talking.After proper scalingandremovalofempty rows in thefeaturematrix,thetest accuracy
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
using the same 100,000 training example subset improved from 82.1% to 84.6%.

Withthis featureset webegan lookinginto usingthefulldataset as wellas featureselection and
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
parameter selection. Usingscaledfeatures,differencefeatures,theoptimalparameters foundfor asmaller
 
 
 
 
 
 
 
 
 
 
 
 
 
dataset,andall626,000 trainingexamples ( with90% usedfor trainingand10% usedfor testing) ,theSVM
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
achievedaclassification accuracy of82.3%,similar to thetest accuracy of82.1% withthesamefeatures anda
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
100,000 trainingexamplesubset ofthedata.Addingthespeaker identity features previously describedimproved
 
 
 
 
 
 
 
 
 
 
 
 
 
 
thetest accuracy of86.4%,indicatingthat theincreasedmodelcomplexity that resultedfromaddingthespeaker
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
identity features increased the variance when using a subset of the data.

Trainingandtestingwiththefulldataset requiredseveraldays ofruntime. Featureselection and
 
 
 
 
 
 
 
 
 
 
 
 
 
 
parameter selection bothrequirecross-validation for multiplepermutations ofparameters andfeatures. We
 
 
 
 
 
 
 
 
 
 
 
 
initially performedfeatureselection andparameter selection usinga10,000 trainingexamplesubset ofthedataset.
 
 
 
 
 
 
 
   
 
 
 
 
 
 
Cross-validation accuracy degradedwhen usingasubset ofthefeatures,so featureselection usingthis subset of
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
thedatadidnot indicatethat it was possibleto reducethefeatureset.Wealso foundtheoptimalfeatures through
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
cross-validation on the10,000 examplesubset ofthedata.However,intuition andexperimentation indicatedthat
 
 
 
 
 
 
 
 
 
 
 
 
 
 
theoptimalparameters werenot constant across trainingset size,sincethemodelparameters impactedthebias
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
versus variancetradeoff.Wechoseto perform featureselection andparameter selection again usingalarger
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
subset ofthedata( 160,000 trainingexamples ) and5-way cross-validation for eachsetting( Figure2) .Thefeature
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
selection indicatedthat reducingthefeatureset sizewoulddegradetheSVM classification accuracy significantly
 
 
 
 
 
 
 
 
 
 
 
 
 
 
so wedidnot pursuethis further.As expected,theoptimalparameters for thelarger trainingset sizewerenot the
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
sameas for asmaller trainingset size. WeretrainedtheSVM withthenew estimatedoptimalparameters,but
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
unfortunately theSVM trainingandprediction tookseveraldays anddidnot quitecompletein time.In parallel,we
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
used thesamefulldataset ( 626,000 examples,90% training,10% testing) withthenew estimatedoptimal
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
parameters to correlatewithanother frequency bin.Wechosebin k=3 as abin withahighconcentration of
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
speechenergy. This run didcompletein time,andwefoundaclassification accuracy on thetest set of89.7%.
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
This concludedour optimization oftheSVM.Given thetimerequiredfor trainingandtestingtheSVM withthefull
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
dataset,wedidnot extendtrainingandtestingto SVMs for other frequency bins apart from thecorrelation run
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
describedabove,althoughour experimentation withsmaller dataset sizes indicates that thetrainingandtesting
 
 
 
 
 
 
 
 
 
 
 
 
 
 
accuracy is similar for other frequencies.

Figure2 below shows theoraclenoisemask,theSVM estimatednoisemask,andthedifferencebetween
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
themasks for asubset ofthetest dataset.For runtimereasons,asubset ofthetrainingdataset was usedto train
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
than what theSVM achievedfor
 
theSVM when generatingthis plot,so thetrainingaccuracy was lower ( ~75%)
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
thefulltrainingandtest datasets.Table1 summarizes theclassification accuracy versus settings usinganon-linear
 
 
 
 
 
 
   
 
 
 
 
 
   
 
kernel in libSVM.

In this paper wehavedescribedthedesign ofan SVM classifier whichtakes audio clips andgenerates a
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
noisemaskwithlabels ofreliableor unreliablefor timeframeandfrequency bin pairs.Thenoisemaskcan be
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
usedby adataimputation system to replaceunreliableaudio withan estimateoftheclean audio to improve
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
automatedspeechrecognition accuracy.Thefeatures usedby theSVM arethelogMelfilterbankenergies for
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 Page	3
theaverageanddifferenceoftheaudio channels alongwiththespeaker identity.TheresultingSVM achieveda
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

Autumn	2012

CS229	Project 	:	Separating	Speech	From	Noise	Challenge

classification accuracy of89.7% for aspeech-dominatedfrequency bin,whichis representativeoftheaccuracy
 
 
 
 
 
 
 
 
 
 
 
 
 
 
that can be achieved for the SVMs for other frequencies.

Ta

b le  1.
  Co mp

a riso

n

 

o f  cla ssifica tio
n

 

a ccura cy  vs  fea ture  set 
a

n d  settin gs

Fe ature s, se tup

Unscaled FBE, libs vm

Scaled FBE, libs vm

Scaled FBE, difference featu res, libs vm

Scaled FBE, difference featu res, befo re/after
featu res, libs vm

Scaled FBE, difference featu res, befo re/after
featu res, , s peaker iden tity, libs vm

Same as  above

A

c

c urac y

Note s

52.3%

71.9%

77.4%

82.1%

84.6%

86.4%

100k examples, 4-way  CV, freq  k=10

Same as  above

Same as  above

Same as  above

100k examples, 90% train, 10% tes t, k=10

626k examples, 90% train, 10% tes t, k=10

Same as  above with op timized SVM  parameters

Didn’t  finish in
time

Same as  above

Same as  above with op timized SVM  parameters

89.7%

Same examples  as  above, freq  k=3

  Cla ssifica tio
Figure  1.
n

 

a ccura cy  versus  SVM 

p

a ra meters  usin g  160, 000  exa mp les

Page	4

Autumn	2012

CS229	Project 	:	Separating	Speech	From	Noise	Challenge

  SVM  estima ted 
Figure  2.
n

o ise  ma sk  versus 
o ra cle  ma sk

Re fe re n c

e s

[ 1] Kallasjoki,Keronen,Gemmmeke,Remes,Palomaki,“ Maskestimation andsparseimputation for missingdata
 
 
 
 
 
 
 
 
 
 
 
 
 
speechrecognition in multisourcereverberant environments,” in CHiM E 2011 W o r k s
 
 
 
 
 
 
 
 
h op on M ac
 
h in e Lis
 
 
t
e n in g
 
in   M
s
e  En v ir onme n t
c
r
u lt is o u
[ 2]  LIBLINEAR -- A Library for Large Linear Classification. Machine Learning Group at National Taiwan
University. 2012.  8 Dec. 2012 http://www.csie.ntu.edu.tw/~cjlin/liblinear/
[ 3]  LIBSVM -- A Library for Support Vector Machines. Chih-Chung Chang and Chih-Jeh Lin. 2012.  8 Dec.
2012 http://www.csie.ntu.edu.tw/~cjlin/libsvm/

Page	5

