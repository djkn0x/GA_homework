Semantic Kernel Forests from Multiple Taxonomies

Sung Ju Hwang
University of Texas
Austin, TX 78701
sjhwang@cs.utexas.edu

Kristen Grauman
University of Texas
Austin, TX 78701
grauman@cs.utexas.edu

Fei Sha
University of Southern California
Los Angeles, CA 90089
feisha@usc.edu

Abstract

When learning features for complex visual recognition problems, labeled image
exemplars alone can be insufﬁcient. While an object taxonomy specifying the cat-
egories’ semantic relationships could bolster the learning process, not all relation-
ships are relevant to a given visual classiﬁcation task, nor does a single taxonomy
capture all ties that are relevant. In light of these issues, we propose a discrim-
inative feature learning approach that leverages multiple hierarchical taxonomies
representing different semantic views of the object categories (e.g., for animal
classes, one taxonomy could reﬂect their phylogenic ties, while another could re-
ﬂect their habitats). For each taxonomy, we ﬁrst learn a tree of semantic kernels,
where each node has a Mahalanobis kernel optimized to distinguish between the
classes in its children nodes. Then, using the resulting semantic kernel forest, we
learn class-speciﬁc kernel combinations to select only those relationships relevant
to recognize each object class. To learn the weights, we introduce a novel hier-
archical regularization term that further exploits the taxonomies’ structure. We
demonstrate our method on challenging object recognition datasets, and show that
interleaving multiple taxonomic views yields signiﬁcant accuracy improvements.

1 Introduction

Object recognition research has made impressive gains in recent years, with particular success
in using discriminative learning algorithms to train classiﬁers tuned to each category of interest
(e.g., [1, 2]). As the basic “image features + labels + classiﬁer” paradigm has reached a level of
maturity, we believe it is time to reach beyond it towards models that incorporate richer semantic
knowledge about the object categories themselves.

One appealing source of such external knowledge is a taxonomy. A hierarchical semantic taxonomy
is a tree that groups classes together in its nodes according to some human-designed merging or
splitting criterion. For example, well-known taxonomies include WordNet, which groups words
into sets of cognitive synonyms and their super-subordinate relations [3], and the phylogenetic tree
of life, which groups biological species based on their physical or genetic properties. Critically,
such trees implicitly embed cues about human perception of categories, how they relate to one
another, and how those relationships vary at different granularities. Thus, in the context of visual
object recognition, such a structure has the potential to guide the selection of meaningful low-level
features, essentially augmenting the standard supervision provided by image labels. Some initial
steps have been made based on this intuition, typically by leveraging the WordNet hierarchy as a
prior on inter-class visual similarity [4, 5, 6, 7, 8, 9, 10, 11].

Two fundamental issues, however, complicate the use of a semantic taxonomy for learning visual
objects. First, a given taxonomy may offer hints about visual relatedness, but its structure need not
entirely align with useful splits for recognition. (For example, monkey and dog are fairly distant
semantically according to WordNet, yet they share a number of visual features. An apple and apple-
sauce are semantically close, yet are easily separable with basic visual features.) Second, given the
complexity of visual objects, it is highly unlikely that some single optimal semantic taxonomy exists
to lend insight for recognition. While previous work relies on a single taxonomy out of convenience,

1

Biological 

Appearance 

Habitat 

Animal 

Texture 

Tameness 

canine 

feline

Spotted 

Pointy 
Ears 

Domestic 

Wild 

Dalmatian 

wolf 

Siamese 
cat 

leopard 

Dalmatian 

Leopard 

Siamese 
cat 

Wolf 

Dalmatian 

Siamese 
Cat 

Wolf 

leopard 

Figure 1: Main idea: For a given set of classes, we assume multiple semantic taxonomies exist, each
one representing a different “view” of the inter-class semantic relationships. Rather than commit to
a single taxonomy—which may or may not align well with discriminative visual features—we learn
a tree of kernels for each taxonomy that captures the granularity-speciﬁc similarity at each node.
Then we show how to exploit the inter-taxonomic structure when learning a combination of these
kernels from multiple taxonomies (i.e., a “kernel forest”) to best serve the object recognition tasks.

in reality objects can be organized along many semantic dimensions or “views”. (For example, a
Dalmatian belongs to the same group as the wolf according to a biological taxonomy, as both are ca-
nines. However, in terms of visual attributes, it can be grouped with the leopard, as both are spotted;
in terms of habitat, it can be grouped with the Siamese cat, as both are domestic. See Figure 1.)

Motivated by these issues, we present a discriminative feature learning approach that leverages mul-
tiple taxonomies capturing different semantic views of the object categories. Our key insight is
that some combination of the semantic views will be most informative to distinguish a given visual
category. Continuing with the sketch in Figure 1, that might mean that the ﬁrst taxonomy helps
learn dog- and cat-like features, while the second taxonomy helps elucidate spots and pointy corner
features, while the last reveals context cues such as proximity to humans or indoor scene features.
While each view differs in its implicit human-designed splitting criterion, all separate some classes
from others, thereby lending (often complementary) discriminative cues. Thus, rather than commit
to a single representation, we aim to inject pieces of the various taxonomies as needed.

To this end, we propose semantic kernel forests. Our method takes as input training images labeled
according to their object category, as well as a series of taxonomies, each of which hierarchically
partitions those same labels (object classes) by a different semantic view. For each taxonomy, we
ﬁrst learn a tree of semantic kernels: each node in a tree has a Mahalanobis-based kernel optimized to
distinguish between the classes in its children nodes. The kernels in one tree isolate image features
useful at a range of category granularities. Then, using the resulting semantic kernel forest from
all taxonomies, we apply a form of multiple kernel learning (MKL) to obtain class-speciﬁc kernel
combinations, in order to select only those relationships relevant to recognize each object class. We
introduce a novel hierarchical regularization term into the MKL objective that further exploits the
taxonomies’ structure. The output of the method is one learned kernel per object class, which we
can then deploy for one-versus-all multi-class classiﬁcation on novel images.

Our main contribution is to simultaneously exploit multiple semantic taxonomies for visual fea-
ture learning. Whereas past work focuses on building object hierarchies for scalable classiﬁca-
tion [12, 13] or using WordNet to gauge semantic distance [5, 6, 8, 9], we learn discriminative ker-
nels that capitalize on the cues in diverse taxonomy views, leading to better recognition accuracy.
The primary technical contributions are i) an approach to generate semantic base kernels across tax-
onomies, ii) a method to integrate the complementary cues from multiple suboptimal taxonomies,
and iii) a novel regularizer for multiple kernel learning that exploits hierarchical structure from the
taxonomy, allowing kernel selection to beneﬁt from semantic knowledge of the problem domain.

We demonstrate our approach with challenging images from the Animals with Attributes and Im-
ageNet datasets [14, 7] together with taxonomies spanning cognitive synsets, visual attributes, be-
havior, and habitats. Our results show that the taxonomies can indeed boost feature learning, letting
us beneﬁt from humans’ perceived distinctions as implicitly embedded in the trees. Furthermore,
we show that interleaving the forest of multiple taxonomic views leads to the best performance,
particularly when coupled with the proposed novel regularization.

2

2 Related Work

Leveraging hierarchies for object recognition Most work in object recognition that leverages
category hierarchy does so for the sake of efﬁcient classiﬁcation [15, 16, 12, 13, 17]. Making coarse
to ﬁne predictions along a tree of classiﬁers efﬁciently rules out unlikely classes at an early stage.
Since taxonomies need not be ideal structures for this goal, recent work focuses on novel ways to
optimize the tree structure itself [12, 13, 17], while others consider splits based on initial inter-class
confusions [16]. A parallel line of work explores unsupervised discovery of hierarchies for image
organization and browsing, from images alone [18, 19] or from images and tags [20]. Whereas all
such work exploits tree structures to improve efﬁciency (whether in classiﬁcation or browsing), our
goal is for externally deﬁned semantic hierarchies to enhance recognition accuracy.

More related to our problem setting are techniques that exploit the inter-class relationships in a
taxonomy [5, 6, 8, 9, 10, 11]. One idea is to combine the decisions of classiﬁers along the semantic
hierarchy [5, 4]. Alternatively, the semantic “distance” between nodes can be used to penalize
misclassiﬁcations more meaningfully [9], or to share labeled exemplars between similar classes [8].
Metric learning and feature selection can also beneﬁt from an object hierarchy, either by preferring
to use disjoint feature sets to discriminate super- and sub-classes [10], by using a taxonomy-induced
loss for structured sparsity [21], or by sharing parameters between metrics along the same path [11].
All prior work commits to a single taxonomy, however, which as discussed above may restrict the
semantics’ impact and will not always align well with the visual data.

Classiﬁcation with multiple semantic views Combining information from multiple “views” of
data is a well-researched topic in the machine learning, multimedia, and computer vision commu-
nities. In multi-view learning, the training data typically consists of paired examples coming from
different modalities—e.g., text and images, or speech and video; basic approaches include recov-
ering the underlying shared latent space for both views [22, 20], bootstrapping classiﬁers formed
independently per feature space [23, 24], or accounting for the view dependencies during cluster-
ing [25, 26]. When the classiﬁcation tasks themselves are grouped, multi-task learning methods
leverage the parallel tasks to regularize parameters learned for the individual classiﬁers or features
(e.g., [27, 28, 29]). Broadly speaking, our problem has a similar spirit to such settings, since we want
to leverage multiple parallel taxonomies over the data; however, our goal to aggregate portions of
the taxonomies during feature learning is quite distinct. More speciﬁcally, while previous methods
attempt to ﬁnd a single structure to accommodate both views, we seek complementary information
from the semantic views and assemble task-speciﬁc discriminative features.

Learning kernel combinations Multiple kernel learning (MKL) algorithms [30] have shown
promise for image recognition (e.g., [31, 32]) and are frequently employed in practice as a prin-
cipled way to combine feature types. Our approach also employs a form of MKL, but rather than
pool kernels stemming from different low-level features or kernel hyperparameters, it pools kernels
stemming from different semantic sources. Furthermore, our addition of a novel regularizer exploits
the hierarchical structure from which the kernels originate.

3 Approach

We cast the problem of learning semantic features from multiple taxonomies as learning to combine
kernels. The base kernels capture features speciﬁc to individual taxonomies and granularities within
those taxonomies, and they are combined discriminatively to improve classiﬁcation, weighing each
taxonomy and granularity only to the extent useful for the target classiﬁcation task.

We describe the two main components of the approach in turn: learning the base kernels—which we
call a semantic kernel forest (Sec. 3.1), and learning their combination across taxonomies (Sec. 3.2),
where we devise a new hierarchical regularizer for MKL.

In what follows, we assume that we are given a labeled dataset D = {(xi , yi )}N
n=1 where (xi , yi )
stands for the ith instance (feature vector) and its class label is yi , as well as a set of tree-structured
taxonomies {Tt}T
t=1 . Each taxonomy Tt is a collection of nodes. The leaf nodes correspond to class
labels, and the inner nodes correspond to superclasses—or, more generally, semantically meaningful
groupings of categories. We index those nodes with double subscripts tn, where t refers to the tth
taxonomy and n to the nth node in that taxonomy. Without loss of generality, we assign the leaf
nodes (i.e., the class nodes) a number between 1 and C, where C is the number of class labels.

3

3.1 Learning a semantic kernel forest

Our ﬁrst step is to learn a forest of base kernels. These kernels are granularity- and view-speciﬁc;
that is, they are tuned to similarities implied by the given taxonomies. While base kernels are learned
independently per taxonomy, they are learned jointly within each taxonomy, as we describe next.

Formally, for each taxonomy Tt , we learn a set of Gaussian kernels for the superclass at every
internal node tn for which n ≥ C + 1. The Gaussian kernels are parameterized as
Mtn (xi , xj )} = exp{−γtn(xi − xj )TMtn (xi − xj )},
Ktn (xi , xj ) = exp{−γtnd2
(1)
where the Mahalanobis distance metric Mtn is used in lieu of the conventional Euclidean metric.
Note that for leaf nodes where n ≤ C, we do not learn base kernels.

We want the base kernels to encode similarity between examples using features that reﬂect their
respective granularity in the taxonomy. Certainly, the kernel Ktn should home in on features that
are helpful to distinguish the node tn’s subclasses. Beyond that, however, we speciﬁcally want it
to use features that are as different as possible from the features used by its ancestors. Doing so
ensures that the subsequent combination step can choose a sparse set of “disconnected” features.

To that end, we apply our Tree of Metrics (ToM) technique [10] to learn the Mahalanobis param-
eters Mtn . In ToM, metrics are learned by balancing two forces: i) discriminative power and ii) a
preference for different features to be chosen between parent and child nodes. The latter exploits the
taxonomy semantics, based on the intuition that features used to distinguish more abstract classes
(dog vs. cat) should differ from those used for ﬁner-grained ones (Siamese vs. Persian cat).

Brieﬂy, for each node tn, the training data is reduced to Dn = {(xi , yin )}, where yin is the label
of n’s child on the path to the leaf node yi . If yi is not a descendant of the superclass at the node n,
then xi is excluded from Dn . The metrics are learned jointly, with each node mutually encouraging
the others to use non-overlapping features. ToM achieves this by augmenting a large margin nearest
neighbor [33] loss function Pn ℓ(Dn ; Mtn ) with the following disjoint sparsity regularizer:
X
Trace[Mtn ] + µ X
Ωd (M ) = λ X
kdiag(Mtn ) + diag(Mtm )k2
2 ,
m∼n
n≥C+1
n≥C+1
where m ∼ n denotes that node m is either an ancestor or descendant of n. The ﬁrst part of
the regularizer encourages sparsity in the diagonal elements of Mtn , and the second part incurs a
penalty when two different metrics “compete” for the same diagonal element, i.e., to use the same
feature dimension. The resulting optimization problem is convex and can be solved efﬁciently [10].

(2)

After learning the metrics {Mtn} in each taxonomy, we construct base kernels as in eq. (1). The
bandwidths γtn are set as the average distances on training data. We call the collection F = {Ktn}
of all base kernels the semantic kernel forest. Figure 1 shows an illustrative example.

While ToM has shown promising results in learning metrics in a single taxonomy, its reliance on
linear Mahalanobis metrics is inherently limited. A straightforward convex combination of ToMs
would result in yet another linear mapping, incapable of capturing nonlinear inter-taxonomic inter-
actions. In contrast, our kernel approach retains ToM’s granularity-speciﬁc features but also enables
nontrivial (nonlinear) combinations, especially when coupled with a novel hierarchical regularizer,
which we will deﬁne next.

3.2 Learning class-speciﬁc kernels across taxonomies

Base kernels in the semantic kernel forest are learned jointly within each taxonomy but indepen-
dently across taxonomies. To leverage multiple taxonomies and to capture different semantic views
of the object categories, we next combine them discriminatively to improve classiﬁcation.

Basic setting To learn class-speciﬁc features (or kernels), we compose a one-versus-rest supervised
learning problem. Additionally, instead of combining all the base kernels in the forest F , we pre-
select a subset of them based on the taxonomy structure. Speciﬁcally, from each taxonomy, we
select base kernels that correspond to the nodes on the path from the root to the leaf node class. For
example, in the Biological taxonomy of Figure 1, for the category Dalmatian, this path includes the
nodes (superclasses) canine and animal. Thus, for class c, the linearly combined kernel is given by
X
Fc (xi , xj ) = X
t
n∼c

βctnKtn(xi , xj ),

(3)

4

where n ∼ c indexes the nodes that are ancestors of c, which is a leaf node (recall that the ﬁrst C
nodes in every taxonomy are reserved for leaf class nodes). The combination coefﬁcients βctn are
constrained to be nonnegative to ensure the positive semideﬁniteness of the resulting kernel Fc (·, ·).

We apply the kernel Fc (·, ·) to construct the one-versus-rest binary classiﬁer to distinguish instances
from class c from all other classes. We then optimize βc = {βctn} such that the classiﬁer attains
the lowest empirical misclassiﬁcation risk. The resulting optimization (in its dual formulation) is
analogous to standard multiple kernel learning [30]:
1
2 X
i

X
i
s.t. X
i
where αc is the Lagrange multipliers for the binary SVM classiﬁer, C is the regularizer for the
SVM’s hinge loss function, and qci = ±1 is the indicator variable of whether or not xi ’s label is c.

αciqci = 0, 0 ≤ αci ≤ C, ∀ i,

αciαcj qci qcj Fc (xi , xj )

X
j

αci −

min
βc

max
αc

(4)

Hierarchical regularization Next, we extend the basic setting to incorporate richer modeling
assumptions. We hypothesize that kernels at higher-level nodes should be preferred to lower-level
nodes. Intuitively, higher-level kernels relate to more classes, thus are likely essential to reduce loss.

We leverage this intuition and knowledge about the relative priority of the kernels from each taxon-
omy’s hierarchical structure. We design a novel structural regularization that prefers larger weights
for a parent node compared to its children. Formally, the proposed MKL-H regularizer is given by:
βctn + µ X
Ω(βc ) = λ X
t,n∼c
t,n∼c

max(0, βctn − βctpn + 1).

(5)

The ﬁrst part prefers a sparse set of kernels. The second part (in the form of hinge loss) encodes our
desire to have the weight assigned to a node n be less than the weight assigned to the node’s parent
pn . We also introduce a margin of 1 to further increase the difference between the two weights.

Hierarchical regularization was previously explored in [34], where a mixed (1, 2)-norm is used to
regularize the relative sizes between the parent and the children. The main idea there is to discard
children nodes if the parent is not selected. Our regularizer is similar, but is simpler and more com-
putationally efﬁcient. (Additionally, our preliminary studies show [34] has no empirical advantage
over our approach in improving recognition accuracy.)

3.3 Numerical optimization

Our learning problem is cast as a convex optimization that balances the discriminative loss in eq. (4)
and the regularizer in eq. (5):
min
βc

f (βc ) = g (βc ) + Ω(βc ),

s.t. βc ≥ 0,

(6)

where we use the function g (β) to encapsulate the inner maximization problem over αc in eq. (4).

We use the projected subgradient method to solve eq. (6), for its ease of implementation and practical
effectiveness [35]. Speciﬁcally, at iteration t, let β t
c be the current value of βc . We compute f (βc )’s
subgradient st , then perform the following update,
c ← max (cid:0)0, β t
β t+1
c − αtst (cid:1) ,
where the max( ) function implements the projection operation such that the update does not fall
outside of the feasible region βc ≥ 0. For step size αt , we use the modiﬁed Polyak’s step size [36].

(7)

4 Experiments

We validate our approach on multiple image datasets, and compare to several informative baselines.

4.1 Image datasets and taxonomies

We consider two publicly available image collections: Animals with Attributes (AWA) [14] and
ImageNet [7]1 . We form two datasets from AWA. The ﬁrst consists of the four classes shown in

1attributes.kyb.tuebingen.mpg.de/ and image-net.org/challenges/LSVRC/2011/

5

