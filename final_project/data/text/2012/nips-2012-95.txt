Synchronization can Control Regularization in
Neural Systems via Correlated Noise Processes

Jake Bouvrie
Department of Mathematics
Duke University
Durham, NC 27708
jvb@math.duke.edu

Jean-Jacques Slotine
Nonlinear Systems Laboratory
Massachusetts Institute of Technology
Cambridge, MA 02138
jjs@mit.edu

Abstract

To learn reliable rules that can generalize to novel situations, the brain must be ca-
pable of imposing some form of regularization. Here we suggest, through theoreti-
cal and computational arguments, that the combination of noise with synchroniza-
tion provides a plausible mechanism for regularization in the nervous system. The
functional role of regularization is considered in a general context in which cou-
pled computational systems receive inputs corrupted by correlated noise. Noise on
the inputs is shown to impose regularization, and when synchronization upstream
induces time-varying correlations across noise variables, the degree of regular-
ization can be calibrated over time. The resulting qualitative behavior matches
experimental data from visual cortex.

Introduction
1
The problem of learning from examples is in most circumstances ill-posed. This is particularly true
for biological organisms, where the “examples” are often complex and few in number, and the abil-
ity to adapt is a matter of survival. Theoretical work in inverse problems has long established that
regularization restores well-posedness [5, 20] and furthermore, implies stability and generalization
of a learned rule [2]. How the nervous system imposes regularization is not entirely clear, however.
Bayesian theories of learning and decision making [14, 12, 29] hold that that brain is able to repre-
sent prior distributions and assign (time-varying) uncertainty to sensory measurements. By way of
a Bayesian integration, the brain may effectively work with hypothesis spaces of limited complexity
when appropriate, trading off prior knowledge against new evidence [9]. But while these mecha-
nisms can effect regularization, it is still not clear how to calibrate it: when to cease adaptation or
how to ﬁx a hypothesis space suited to a given task. A second possible explanation is that regulariza-
tion – and a representation of uncertainty – may emerge naturally due to noise. Intuitively, if noise
is allowed to “smear” observations presented to a learning apparatus, overﬁtting may be mitigated –
a well known phenomenon in artiﬁcial neural networks [1].
In this paper we argue that noise provides an appealing, plausible mechanism for regularization in
the nervous system. We consider a general context in which coupled computational circuits subject
to independent noise receive common inputs corrupted by spatially correlated noise. Information
processing pathways in the mammalian visual cortex, for instance, fall under such an organizational
pattern [10, 24, 7]. The computational systems in this setting represent high-level processing stages,
downstream from localized populations of neurons which encode sensory input. Noise correlations
in the latter arise from, for instance, within-population recurrent connections, shared feed-forward
inputs, and common stimulus preferences [24]. Independent noise impacting higher-level computa-
tional elements may arise from more intrinsic, ambient neuronal noise sources, and may be roughly
independent due to broader spatial distribution [6].
To help understand the functional role of noise in inducing regularization, we propose a high-level
model that can explain quantitatively how noise translates into regularization, and how regularization
may be calibrated over time. The ability to adjust regularization is key: as an organism accumulates

1

experience, its models of the world should be able to adjust to the complexity of the relationships
and phenomena it encounters, as well as reconcile new information with prior probabilities. Our
point of view is complementary to Bayesian theories of learning; the representation and integration
of sensory uncertainty is closely related to a regularization interpretation of learning in ill-posed
settings. We postulate that regularization may be plausibly controlled by one of the most ubiquitous
mechanisms in the brain: synchronization. A simple, one-dimensional regression (association) prob-
lem in the presence of both independent ambient noise and correlated measurement noise sufﬁces to
illustrate the core ideas.
When a learner is presented with a collection of noisy observations, we show that synchroniza-
tion may be used to adjust the dependence between observational noise variables, and that this
in turn leads to a quantiﬁable change in the degree of regularization imposed upon the learning
task. Regularization is further shown to both improve the convergence rate towards the solution
to the regression problem, and reduce the negative impact of ambient noise. The model’s qualita-
tive behavior coincides with experimental data from visual tracking tasks [10] (area MT) and from
anesthetized animals [24] (area V1), in which correlated noise impacts sensory measurements and
correlations increase over short time scales. Other experiments involving perceptual learning tasks
have shown that noise correlations decrease with long-term training [8]. The mechanism we propose
suggests that changes in noise correlations arising from feedback synchronization can calibrate reg-
ularization, possibly leading to improved convergence properties or better solutions. Collectively,
the experimental evidence lends credence to the hypothesis that, at a high level, the brain may be op-
timizing its learning processes by adapting dependence among noise variables, with regularization
an underlying computational theme.
Lastly, we consider how continuous dynamics solving a given learning problem might be efﬁciently
computed in cortex. In addition to supporting regularization, noise can be harnessed to facilitate
distributed computation of the gradients needed to implement a dynamic optimization process. Fol-
lowing from this observation, we analyze a stochastic ﬁnite difference scheme approximating deriva-
tives of quadratic objectives. Difference signals and approximately independent perturbations are
the only required computational components. This distributed approach to the implementation of
dynamic learning processes further highlights a connection between parallel stochastic gradient de-
scent algorithms [25, 15, 28], and neural computation.
2 Learning as noisy gradient descent on a network
The learning process we will consider is that of a one-dimensional linear ﬁtting problem described
by a dynamic gradient based minimization of a square loss objective, in the spirit of Rao & Bal-
lard [21]. This is perhaps the simplest and most fundamental abstract learning problem that an
organism might be confronted with – that of using experiential evidence to infer correlations and
ultimately discover causal relationships which govern the environment and which can be used to
make predictions about the future. The model realizing this learning process is also simple, in
that we capture neural communication as an abstract process “in which a neural element (a single
neuron or a population of neurons) conveys certain aspects of its functional state to another neural
element” [22]. In doing so, we focus on the underlying computations taking place in the nervous
system rather than particular neural representations. The analysis that follows, however, may be
extended more generally to multi-layer feedback hierarchies.
To make the setting more concrete, assume that we have observed a set of input-output examples
{xi ∈ R, yi ∈ R}m
i=1 , with each xi representing a generic unit of sensory experience, and want to
estimate the linear regression function fw (x) = wx (we assume the intercept is 0 for simplicity).
m(cid:88)
m(cid:88)
Adopting the square loss, the total prediction error incurred on the observations by the rule fw is
given by
(yi − fw (xi ))2 = 1
(yi − wxi )2 .
E (w) = 1
2
2
with respect to the slope parameter is given by ∇wE = − (cid:80)m
i=1
i=1
Note that there is no explicit regularization penalty here. We will model adaptation (training) by
a noisy gradient descent process on this squared prediction error loss function. The gradient of E
i=1 (yi − wxi )xi , and generates the
continuous-time, noise-free gradient dynamics
˙w = −∇wE (w).
The learning dynamics we will consider, however, are assumed to be corrupted by two distinct kinds
of noise:

(1)

(2)

2

(N1) Sensory observations (xi )i are corrupted by time-varying, correlated noise processes.
(N2) The dynamics are themselves corrupted by additive “ambient” noise.

To accommodate (N1) we will borrow an averaging or, homogenization, technique for multi-scale
systems of stochastic differential equations (SDEs) that will drastically simplify analysis. We have
discussed the origins of (N1) above. The noise (N2) may be signiﬁcant (we do not take small noise
limits) and can be attributed to some or all of: error in computing and sensing a gradient, intrinsic
neuronal noise [6] (aggregated or localized), or interference between large assemblies of neurons or
circuits.
Synchronization among circuits and/or populations will be modeled by considering multiple coupled
dynamical systems, each receiving the same noisy observations. Such networks of systems capture
common pooling or averaging computations, and provides a means for studying variance reduction.
The collective enhancement of precision hypothesis suggests that the nervous system copes with
noise by averaging over collections of signals in order to reduce variation in behavior and improve
computational accuracy [23, 13, 26, 3]. Coupling synchronizes the collection of dynamical systems
so that each tends to a common “consensus” trajectory having reduced variance. If the coupling is
strong enough, then the variance of the consensus trajectory decreases as O(1/n) after transients,
if there are n signals or circuits [23, 17, 19, 3]. We will consider regularization in the context of
networks of coupled SDEs, and investigate the impact of coupling, redundancy (n) and regulariza-
tion upon the convergence behavior of the system. Considering networks will allow a more general
analysis of the interplay between different mechanisms for coping with noise, however n can be
small or 1 in some situations.
Formally, the noise-free ﬂow (2) can be modiﬁed to include noise sources (N1) and (N2) as follows.
dwt = −(cid:0)wt(cid:107)x + Zt(cid:107)2 − (cid:104)x + Zt , y(cid:105)(cid:1)dt + σdBt
Noise (N1) may be modeled as a white-noise limit of Ornstein-Uhlenbeck (OU) processes (Zt )i ,
and (N2) as an additive diffusive noise term. In differential form, we have
√
t = − Z i
2γ√
t
dB i
dZ i
i = 1, . . . , m.
dt +
t ,
ε
ε
Here, Bt denotes the standard 1-dimensional Brownian motion and captures noise source (N2). The
t , following (N1). For the
observations (x)i = xi are corrupted by the noise processes (Zt )i = Z i
t are independent, but we will relax this assumption later. The parameter 0 < ε (cid:28) 1
moment, the Z i
controls the correlation time of a given noise process. In the limit as ε → 0, Z i
t may be viewed as a
family of independent zero-mean Gaussian random variables indexed by t. Characterizing the noise
Zt as (3b) with ε → 0 serves as both a modeling approximation/idealization and an analytical tool.
2.1 Homogenization

(3b)

(3a)

The system (3a)-(3b) above is a classic “fast-slow” system:
the gradient descent trajectory wt
evolves on a timescale much longer than the O(ε) stochastic perturbations Zt . Homogenization
considers the dynamics of wt after averaging out the effect of the fast variable Zt . In the limit as
ε → 0 in (3b), the solution to the averaged SDE converges (in a sense to be discussed below) to the
solution of the original SDE (3a).
The following Theorem is an instance of [18, Thm. 3], adapted to the present setting.
Theorem 2.1. Let 0 < ε (cid:28) 1, σ, γ > 0 and let X , Y denote ﬁnite-dimensional Euclidean spaces.
Consider the system

x(0) = x0

(4a)
dx = f (x, y)dt + γ dWt ,
dy = ε−1 g(y)dt + ε−1/2σdBt ,
(4b)
y(0) = y0 ,
where x ∈ X , y ∈ Y , and Wt ∈ X , Bt ∈ Y are independent multivariate Brownian motions.
Assume that for all x ∈ X , y ∈ Y the following conditions on (4) hold:
(cid:104)g(y), y/(cid:107)y(cid:107)(cid:105) ≤ −r(cid:107)y(cid:107)α ,
(cid:107)f (x, y) − f (x(cid:48) , y)(cid:107) ≤ C (y)(cid:107)x − x(cid:48)(cid:107)
(cid:107)f (x, y)(cid:107) ≤ K (1 + (cid:107)x(cid:107))(1 + (cid:107)y(cid:107)q ),
with r > 0, α ≥ 0, q < ∞, and where C (y) is a constant depending on y . If the SDE (4b) is ergodic,
then there exists a unique invariant measure µ∞ characterizing the probability distribution of yt in

3

Y f (x, y)µ∞ (dy).

the steady state, and we may deﬁne the vector ﬁeld F (x) (cid:44) Eµ∞ [f (x, y)] = (cid:82)
Furthermore, x(t) solving (4a) is closely approximated by X (t) solving
dX = F (X )dt + γ dWt , X (0) = x0
in the sense that, for any t ∈ [0, T ], x(t) ⇒ X (t) in C ([0, T ], X ) as ε → 0.
It may be readily shown that the system (3) satisﬁes the conditions of Theorem 2.1. Moreover, the
OU process (3b) on Rm is known to be ergodic with stationary distribution Z∞ ∼ N (0, γ 2 I ) (see
e.g. [11]), where N (µ, Σ) denotes the multivariate Gaussian distribution with mean µ and covariance
dwt = −(cid:2)wt ((cid:107)x(cid:107)2 + mγ 2 ) − (cid:104)x, y(cid:105)(cid:3)dt + σdBt ,
Σ. Averaging over the fast variable Zt appearing in (3a) with respect to this distribution gives
(5)
and by Theorem 2.1, we can conclude that Equation (5) well-approximates (3a) when ε → 0 in (3b)
in the sense of weak convergence of probability measures.
2.2 Network structure
ciated parameters w(t) = (cid:0)w1 (t), . . . , wn (t)(cid:1). If Wij ≥ 0 is the coupling strength between systems
Now consider n ≥ 1 diffusively coupled neural systems implementing the dynamics (5), with asso-
i and j , L = diag(W 1) − W is the network Laplacian [16]. We assume here that L is symmetric
and deﬁnes a connected network graph. Letting α := (cid:107)x(cid:107)2 + mγ 2 , β := (cid:104)x, y(cid:105) and µ := (β /α)1,
the coupled system can be written concisely as
dwt = −(L + αI )wtdt + β1dt + σdBt
= (L + αI )(µ − wt )dt + σdBt ,
with Bt an n-dimensional Brownian motion. The diffusive couplings here should be interpreted
as modeling abstract intercommunication between and among different neural circuits, populations,
or pathways. In such a general setting, diffusive coupling is a natural and mathematically tractable
choice that can capture the key, aggregate aspects of communication among neural systems. Note
that one can equivalently consider n systems (3a) and then homogenize assuming n copies of the
t }i ; either choice also leads to (6).
same noise process Zt , or n independent noise processes {Z(i)
3 Learning with noisy data imposes regularization
(cid:90) t
w(t) = e−(L+αI )tw(0) + (cid:0)I − e−(L+αI )t (cid:1)µ + σ
Equation (6) is seen by inspection to be an OU process, and has solution (see e.g. [11])
e−(L+αI )(t−s)dBs .
(7)
characterized entirely by its time-dependent mean and covariance, w(t) ∼ N (cid:0)µw (t), Σw (t)(cid:1). A
0
Integrals of Brownian motion are normally distributed, so w(t) is a Gaussian process and can be
µw (t) : = E[w(t)] = e−(L+αI )t E[w(0)] + (cid:0)I − e−(L+αI )t (cid:1)µ
straightforward manipulation (details omitted due to lack of space) gives
Σw (t) : = E (cid:104)(cid:0)w(t) − E w(t)(cid:1)(cid:0)w(t) − E w(t)(cid:1)(cid:62)(cid:105)
(8)
(L + αI )−1 (cid:0)I − e−2(L+αI )t (cid:1).
σ2
= e−(L+αI )t E[w(0)w(0)(cid:62)]e−(L+αI )t +
2
The solution to the noise-free regression problem (minimizing (1)) is given by w∗ = (cid:104)x, y(cid:105)/(cid:107)x(cid:107)2 ,
however (7) together with (8) reveals that, for any i ∈ {1, . . . , n},
(cid:104)x, y(cid:105)
E[wi (t)] t→∞−−−→ (µ)i =
(cid:107)x(cid:107)2 + mγ 2
which is exactly the solution to the regularized regression problem
w∈R (cid:107)y − wx(cid:107)2 + λw2
min
with regularization parameter λ := mγ 2 . To summarize, we have considered a network of cou-
pled, noisy gradient ﬂows implementing unregularized linear regression. When the observations
x are noisy, all elements of the network converge in expectation to a common equilibrium point
representing a regularized solution to the original regression problem.

(6)

(9)

4

3.1 Convergence behavior

In the previous section we showed that the network converges to the solution of a regularized re-
gression problem, but left open a few important questions: What determines the convergence rate?
address these questions by decomposing w(t) into orthogonal components, w(t) = ¯w(t)1 + (cid:101)w(t),
How does the noise (N1),(N2) impact convergence? How does coupling and redundancy (number
of circuits n) impact convergence? How do these quantities affect the variance of the error? We can
n 1(cid:62)w, and ﬂuctuations about the mean (cid:101)w = w − ¯w1.
representing the mean-ﬁeld trajectory ¯w = 1
E(cid:2) 1
n (cid:107) (cid:101)w(t)(cid:107)2 (cid:3) + E(cid:2) 1
n (cid:107)w(t) − µ(cid:107)2 (cid:3) = E(cid:2) 1
n (cid:107) ¯w(t)1 − µ(cid:107)2 (cid:3)
We may then study the error
(10)
by studying each term separately. Decomposing the error into ﬂuctuations about the average and the
chronization subspace (where (cid:101)w = 0), and the another determines convergence to the equilibrium
distance between the average and the noise-free equilibrium allows one to see that there are actually
two different convergence rates governing the system: one determines convergence towards the syn-
Theorem 3.1. Let (cid:101)C , C be constants which do not depend on time, and let λ denote the smallest
point µ. The following result provides quantitative answers to the questions posed above:
(cid:19)
(cid:18) 1
non-zero eigenvalue of L. Set α := (cid:107)x(cid:107)2 + mγ 2 and µ := ((cid:104)x, y(cid:105)/α)1, as before. Then for all
E(cid:2) 1
n (cid:107)w(t) − µ(cid:107)2 (cid:3) ≤ (cid:101)C e−2(λ+α)t + C e−2αt +
t > 0,
λ + α
A proof is given in the supplementary material. The ﬁrst term of (11) estimates the transient part
of the ﬂuctuations term in (10), and we ﬁnd that the rate of convergence to the synchronization
subspace is 2(λ + α). The second term term estimates the transient part of the centroid’s trajectory,
and we see that the rate of convergence of the mean trajectory to equilibrium is 2α. In the presence of
noise, however, the system will neither synchronize nor reach equilibrium exactly. After transients,
we see that the residual error is given by the last term in (11). This term quantiﬁes the steady-state
interaction between: gradient noise (σ ); regularization (α, via the observation noise γ ); network
topology (via λ), coupling strength (via λ), and redundancy (n; possibly λ).
3.2 Discussion

1
αn

σ2
2

+

.

(11)

From the results above we can draw a few conclusions about networks of noisy learning systems:

1. Regularization improves both the synchronization rate and the rate of convergence to equilibrium.
2. Regularization contributes towards reducing the effect of the gradient noise σ : (N1) counteracts
(N2).
3. Regularization changes the solution, so we cannot view regularization as a “free-parameter” that
can be used solely to improve convergence or reduce noise. Faster convergence rates and noise
reduction should be viewed as beneﬁcial side-effects, while the appropriate degree of regulariza-
tion primarily depends on the learning problem at hand.
4. The number of circuits n and the coupling strength contribute towards reducing the effect of the
gradient noise (N2) (that is, the variance of the error) and improve the synchronization rate, but
do not affect the rate of convergence toward equilibrium.
5. Coupling strength and redundancy cannot be used to control the degree of regularization, since
the equilibrium solution µ does not depend on n or the spectrum of L. This is true no matter how
the coupling weights Wij are chosen, since constants will always be in the null space of L and µ
is a constant vector.
In the next section we will show that if the noise processes {Z i
t }i are themselves trajectories of
a coupled network, then synchronization can be a mechanism for controlling the regularization
imposed on a learning process.
4 Calibrating regularization with synchronization

If instead of assuming independent noise processes corrupting the data as in (3b), we consider cor-
related noise variables (Z i
i=1 , it is possible for synchronization to control the regularization which
t )m
the noise imposes on a learning system of the form (3a). A collection of dependent observational
noise processes is perhaps most conveniently modeled by coupling the OU dynamics (3b) introduced

5

(12)

dBt ,

(Lz + ηI )Ztdt +

before through another (symmetric) network Laplacian Lz :
√
2γ√
dZt = − 1
ε
ε
for some η > 0. We now have two networks: the ﬁrst network of gradient systems is the same as
before, but the observational noise process Zt is now generated by another network. For purposes
of analysis, this model sufﬁces to capture generalized correlated noise sources. In the actual biol-
ogy, however, correlations may arise in a number of possible ways, which may or may not include
diffusively coupled dynamic noise processes.
To analyze what happens when a network of learning systems (3a) is driven by observation noise of
Zt ∼ N (cid:0)µz (t), Σz (t)(cid:1) is a Gaussian process characterized by
the form (12), we take an approach similar to that of the previous Section. The ﬁrst step is again
homogenization. The system (12) may be viewed as a zero-mean variation of (6), and its solution
Σz (t) = e−(Lz +ηI )t/ε E[Z(0)Z(0)(cid:62)]e−(Lz +ηI )t/ε + γ 2 (Lz + ηI )−1 (cid:0)I − e−2(Lz +ηI )t/ε (cid:1).
µz (t) = e−(Lz +ηI )t/ε E[Z(0)]
(13a)
Taking t → ∞ in (13) yields the stationary distribution µ∞ = N (cid:0)0, γ 2 (Lz + ηI )−1 (cid:1). We can now
(13b)
(cid:110)(cid:0)wt(cid:107)x + Zt(cid:107)2 − (cid:104)x + Zt , y(cid:105)(cid:1)(cid:111)
consider (3a) deﬁned with Zt governed by (12), and average with respect to µ∞ :
= −(cid:104)
(cid:0)(cid:107)x(cid:107)2 + γ 2 tr(Lz + ηI )−1 (cid:1) − (cid:104)x, y(cid:105)(cid:105)
dwt = − Eµ∞
dt + σdBt
dt + σdBt
wt
where we have used that E[(cid:107)Zt(cid:107)2 ] = γ 2 tr(Lz + ηI )−1 . As before, the averaged approximation is
good when ε → 0. An expression identical to (6),
dwt = (L + αI )(µ − wt )dt + σdBt
is obtained by redeﬁning α := (cid:107)x(cid:107)2 + γ 2 tr(Lz + ηI )−1 and µ := ((cid:104)x, y(cid:105)/α)1. In this case,
λ = α − (cid:107)x(cid:107)2 = γ 2 tr(Lz + ηI )−1 .
Theorem 3.1 may be immediately applied to understand (14). As before, the covariance of Zt
ﬁgures into the regularization parameter. However now the covariance of Zt is a function of the
network Laplacian Lz = Lz (t), which is deﬁned by the topology and potentially time-varying
coupling strengths of the noise network. By adjusting the coupling in (12), we adjust the regulariza-
t increases and
tion λ imposed upon (14). When coupling increases, the dependence among the Z i
tr(Lz + ηI )−1 (and therefore α) decreases. Thus, increased correlation among observational noise
variables implies decreased regularization.
In the case of all-to-all coupling with uniform strength κ ≥ 0, for example, Lz has eigenvalues
0 = λ0 < λ1 = · · · = λm = mκ. The regularization may in this case range over the interval
γ 2 ≤ m
tr(Lz + ηI )−1
tr(Lz + ηI )−1 =
λ
1
= sup
<
inf
η
η
κ
κ
by adjusting the coupling strength κ ∈ [0, ∞). Note that all-to-all coupling may be plausibly imple-
mented with O(n) connections using mechanisms such as quorum sensing (see [3, §2.3], [27]).
5 Distributed computation with noise
We have argued that noise can serve as a mechanism for regularization. Noise may also be har-
nessed, in a different sense, to compute dynamics of the type discussed above. The distributed
nature of the mechanism we will explore adheres to the general theme of parallel computation in the
brain, and provides one possible explanation for how the gradients introduced previously might be
estimated. The development is closely related to stochastic gradient descent (SGD) ideas appearing
in stochastic approximation [25, 15] and adaptive optics [28].
5.1 Parallel stochastic gradient descent
Let J (u) : Rd → R be a locally Lipschitz Lyapunov cost functional we wish to minimize with
respect to some set of control signals u(t) ∈ Rd . Gradient descent on J can be described by the
collection of ﬂows
= −γ

(u1 , . . . , ud ),

i = 1, . . . , d.

(14)

dui (t)
dt

∂ J
∂ui

6

We consider the case where the gradients above are estimated via ﬁnite difference approximations
of the form
≈ J (u1 , . . . , ui + δui , . . . , ud ) − J (u1 , . . . , ui , . . . , ud )
∂ J (u)
∂ui
δui
where δui is a small perturbation applied to the i-th input. Parallel stochastic gradient descent
(PSGD, see e.g. [28]) involves applying i.i.d. stochastic perturbations δui simultaneously to all in-
puts in parallel, so that the gradients ∂iJ (u) are estimated as
≈ δJ δui ,
∂ J (u)
(15)
i = 1, . . . , d
∂ui
where δJ = J (u1 + δu1 , . . . , ui + δui , . . . , ud + δud ) − J (u1 , . . . , ui , . . . , ud ). If δui are symmetric
random variables with mean zero and variance σ2 , then σ−2 E[δJ δui ] is accurate to O(σ2 ) [28].
5.2 Stochastic gradient model
The parallel ﬁnite difference approximation (15) suggests a more biologically plausible mechanism
for implementing gradient dynamics. If the perturbations δui are taken to be Gaussian i.i.d. random
dut = −γ (cid:2)J (ut + Zt ) − J (ut )(cid:3)Ztdt,
variables, we can model parallel stochastic gradient descent as an Ito process:
σ√
dZt = − 1
dBt ,
Ztdt +
ε
ε

u(0) = u0

Z(0) = z0

,

(16a)

(16b)

where Bt is a standard d-dimensional Brownian motion. Additive noise affecting the gradient has
been omitted from (16a) for simplicity, and does not change the fundamental results discussed in
this section. The perturbation noise Zt has again been modeled as a white-noise limit of Ornstein-
Uhlenbeck processes (16b). When ε → 0, Equation (16a) implements PSGD using the approxima-
tion given by Equation (15) with δui zero-mean i.i.d. Gaussian random variables.
We will proceed with an analysis of (16) in the particular case where J is chosen from the quadratic
family of cost functionals of the form J (u) = u(cid:62)Au where A is a symmetric, bounded and strictly
positive deﬁnite matrix1 . In this setting the analysis is simpler and sufﬁces to illustrate the main
points. This cost function satisﬁes minu∈Rd J (u) = 0 with minimizer u∗ = 0, and J is a Lyapunov
dut = −γ (cid:0)2u(cid:62)
(cid:1)Ztdt,
function. Equation (16a) now takes the form
t AZt + Z(cid:62)
t AZt
5.3 Convergence of continuous-time PSGD with quadratic cost

u(0) = u0 .

(17)

We turn to studying the convergence behavior of (17) and the precise role of the stochastic per-
turbations Zt used to estimate the gradients. These perturbations must be small in order to obtain
accurate approximations of the gradients. However, one may also expect that the noise will play
an important role in determining convergence properties since it is the noise that ultimately kicks
the system “downhill” towards equilibrium. Homogenizing (17) with respect to Zt leads to the
following Theorem, the proof of which is given in the supplementary material.
Theorem 5.1. For any 0 ≤ t ≤ T < ∞, the solution u(t) to (17) satisﬁes
E[u(t)] = e−γσ2Atu(0).

lim
ε→0
It is clear from this result that the PSGD system (16), for ε → 0, converges in expectation globally
and exponentially to the minimum of J when J is a positive deﬁnite quadratic form. Our earlier
intuition that the perturbation noise σ should play a role in the rate of convergence is also conﬁrmed:
greater noise amplitudes lead to faster convergence. However this comes at a price. The covariance
of u(t) after transients is exactly the covariance of Zt . Thus an inherent tradeoff between speed and
accuracy must be resolved by any organism implementing PSGD-like mechanisms.

(18)

1Without loss of generality we may assume A is symmetric since the antisymmetric part does not contribute
to the quadratic form. In addition, objectives of the form u(cid:62)Au+ b(cid:62)u+ c may be expressed in the homogeneous
form u(cid:62)Au by a suitable change of variables.

7

Figure 1: (Left stack) Increased observation noise imposes greater regularization, and leads to a reduction
in ambient noise. (Right stack) Stronger coupling/correlation between observation noise processes decreases
regularization. See text for details.

6 Simulations

We ﬁrst simulated a network of gradient dynamics with uncoupled observation noise processes obey-
ing (3). To illustrate the effect of increasing observation noise variance, the parameter γ in (3b) was
increased from 0.5 to 7 along a monotonic, sigmoidal path over the duration of the simulation. We
used n = 5 systems (3a) with σ = 4, coupled all-to-all with uniform strength κ = 2. Observa-
tions were sampled according to (x)i ∼ N (0, 0.04), (y)i ∼ Uniform[0, 20] with m = 20 entries,
once and for all, at the beginning of the experiment. Initial conditions were drawn according to
w(0) ∼ Uniform[−3, 3], and Z(0) was set to 0. Figure 1 (left three plots) veriﬁes some of main
conclusions of Section 3.2. The top plot shows the sample paths w(t) and time course of the obser-
vational noise deviation γ (t) (grey labeled trace). When the noise increases near t = 2.5s, a dra-
matic drop in the variance of w(t) is visible. The middle plot shows the center of mass (mean-ﬁeld)
trajectory ¯w(t) superimposed upon the time-varying noise-free solution µ(t) (gray labeled trace).
Because the observation noise is increasing, the regularization λ = mγ 2 increases and the solution
µ(t) to the regularized problem decreases in magnitude following (9). The bottom plot shows the
mean-squared distance to the time-dependent noise-free solution µ(t), and the mean-squared size of
the ﬂuctuations about the centroid ¯w2 . It is clear that the error rapidly drops off when γ (t) increases,
conﬁrming the apparent reduction in the variance of w(t) in the top plot.
A second experiment, described by the right-hand stack of plots in Figure 1, shows how synchroniza-
tion can function to adjust regularization over time. This simulation is inspired by the experimental
study of noise correlations in cortical area MT due to [10], where it was suggested that time-varying
correlations between pairs of neurons play a signiﬁcant role in explaining behavioral variation in
smooth-pursuit eye movements. In particular, the ﬁndings in [10] and [4] suggest that short-term
increases in noise correlations are likely to occur after feedback arrives and neurons within and up-
stream from MT synchronize. We simulated a collection of correlated observation noise processes
obeying (12) (ε = 10−3 , η = 3) with all-to-all topology and uniform coupling strength κz (t) in-
creasing from 0 to 2 along the proﬁle shown in Figure 1 (top-right plot, labeled gray trace). This
noise process Zt was then fed to a population of n = 5 units obeying (3a), with ambient noise σ = 1
and all-to-all coupling at ﬁxed strength Wij = κ = 2. New data x, y and initial conditions were
chosen as in the previous experiment. The middle plot on the right-hand side shows the effect of
increasing synchronization among the observation noise processes. As the coupling increases, the
noise becomes more correlated and regularization decreases. This in turn causes the desired solution
µ(t) to the regression problem to increase in magnitude (labeled gray trace). With decreased regu-
larization, the ambient noise is more pronounced. The bottom-right plot shows the mean ﬂuctuation
size and distance to the noise-free solution (total error). An increase in the noise variance is apparent
following the increase in observational noise correlation.

2These quantities are similar to those deﬁned in (10), but represent only this single simulation – not in
expectation. Here, ergodic theory allows one to (very roughly) infer ensemble averages by visually estimating
time averages.

8

00.511.522.533.544.55−505time(s)w(t)00.511.522.533.544.55−4−20time(s)¯w(t)00.511.522.533.544.55024time(s)Error  Total ErrorFluctuations ErrorSteady-statesolutionµ(t)Noiseamplitudeγ(t)00.511.522.533.544.55024w(t)time(s)00.511.522.533.544.550123¯w(t)time(s)00.511.522.533.544.5500.51Errortime(s)  Total ErrorFluctuations ErrorCouplingstrengthκz(t)Steady-statesolutionµ(t)Acknowledgments
The authors are grateful to Rodolfo Llinas for pointing out the plausible analogy between gradient
search in adaptive optics and learning mechanisms in the brain. JB was supported under DARPA
FA8650-11-1-7150 SUB#7-3130298, NSF IIS-08-03293 and WA State U. SUB#113054 G002745.
References

[1] C. M. Bishop. Training with noise is equivalent to Tikhonov regularization. Neural Computation,
7(1):108–116, 1995.
[2] O. Bousquet and A. Elisseeff. Stability and generalization. J. Mach. Learn. Res., 2(3):499–526, 2002.
[3] J. Bouvrie and J.-J. Slotine. Synchronization and redundancy: Implications for robustness of neural
learning and decision making. Neural Computation, 23(11):2915–2941, 2011.
[4] S. C. de Oliveira, A. Thiele, and K. P. Hoffmann. Synchronization of neuronal activity during stimulus
expectation in a direction discrimination task. J Neurosci., 17(23):9248–60, 1997.
[5] H. W. Engl, M. Hanke, and A. Neubauer. Regularization of Inverse Problems. Kluwer, 1996.
[6] A. Faisal, L. Selen, and D. Wolpert. Noise in the nervous system. Nat. Rev. Neurosci., 9:292–303, April
2008.
[7] T. J. Gawne and B. J. Richmond. How independent are the messages carried by adjacent inferior temporal
cortical neurons? J Neurosci., 13(7):2758–71, 1993.
[8] Y. Gu, S. Liu, C. R. Fetsch, Y. Yang, S. Fok, A. Sunkara, G. C. DeAngelis, and D.E. Angelaki. Perceptual
learning reduces interneuronal correlations in macaque visual cortex. Neuron, 71(4):750 – 761, 2011.
[9] T. D. Hanks, M. E. Mazurek, R. Kiani, E. Hopp, and M. N. Shadlen. Elapsed decision time affects the
weighting of prior probability in a perceptual decision task. J. Neurosci., 31(17):6339–52, 2011.
[10] X. Huang and S. G. Lisberger. Noise correlations in cortical area MT and their potential impact on
trial-by-trial variation in the direction and speed of smooth-pursuit eye movements. J. Neurophysiol,
101:3012–3030, 2009.
[11] O. Kallenberg. Foundations of Modern Probability. Springer, 2002.
[12] R. Kiani and M. N. Shadlen. Representation of conﬁdence associated with a decision by neurons in the
parietal cortex. Science, 324(5928):759–764, 2009.
[13] T. Kinard, G. De Vries, A. Sherman, and L. Satin. Modulation of the bursting properties of single mouse
pancreatic β -cells by artiﬁcial conductances. Biophysical Journal, 76(3):1423–1435, 1999.
[14] K. P. K ¨ording and D. M. Wolpert. Bayesian decision theory in sensorimotor control. Trends in Cognitive
Sciences, 10(7):319–326, 2006.
Stochastic Approximation and Recursive Algorithms and Applications.
[15] H. J. Kushner and G. Yin.
Springer, 2nd edition, 2003.
[16] M. Mesbahi and M. Egerstedt. Graph Theoretic Methods in Multiagent Networks. Princeton U. Press,
2010.
[17] D. J. Needleman, P. H. Tiesinga, and T. J. Sejnowski. Collective enhancement of precision in networks of
coupled oscillators. Physica D: Nonlinear Phenomena, 155(3-4):324–336, 2001.
[18] E. Pardoux and A. Yu. Veretennikov. On the Poisson equation and diffusion approximation. I. Annals of
Probability, 29(3):1061–1085, 2001.
[19] Q.-C. Pham, N. Tabareau, and J.-J. Slotine. A contraction theory approach to stochastic incremental
stability. IEEE Transactions on Automatic Control, 54(4):816–820, April 2009.
[20] T. Poggio and S. Smale. The mathematics of learning: dealing with data. Notices Amer. Math. Soc.,
50(5):537–544, 2003.
[21] R. P. Rao and D. H. Ballard. Predictive coding in the visual cortex: A functional interpretation of some
extra-classical receptive-ﬁeld effects. Nat. Neurosci., 2:79–87, 1999.
[22] A. Schnitzler and J. Gross. Normal and pathological oscillatory communication in the brain. Nature
Reviews Neuroscience, 6:285–296, 2005.
[23] A. Sherman and J. Rinzel. Model for synchronization of pancreatic beta-cells by gap junction coupling.
Biophysical Journal, 59(3):547–559, 1991.
[24] M. A. Smith and A. Kohn. Spatial and temporal scales of neuronal correlation in primary visual cortex. J
Neurosci., 28(48):12591–12603, 2008.
[25] J.C. Spall. Multivariate stochastic approximation using a simultaneous perturbation gradient approxima-
tion. IEEE Transactions on Automatic Control, 37:332–341, 1992.
[26] N. Tabareau, J.-J. Slotine, and Q.-C. Pham. How synchronization protects from noise. PLoS Comput Biol,
6(1):e1000637, Jan 2010.
[27] A. Taylor, M. Tinsley, F. Wang, Z. Huang, and K. Showalter. Dynamical quorum sensing and synchro-
nization in large populations of chemical oscillators. Science, 323(5914):614–617, 2009.
[28] M. A. Vorontsov, G. W. Carhart, and J. C. Ricklin. Adaptive phase-distortion correction based on parallel
gradient-descent optimization. Opt. Lett., 22(12):907–909, Jun 1997.
[29] T. Yang and M. N. Shadlen. Probabilistic reasoning by neurons. Nature, 447(7148):1075–1080, 2007.

9

