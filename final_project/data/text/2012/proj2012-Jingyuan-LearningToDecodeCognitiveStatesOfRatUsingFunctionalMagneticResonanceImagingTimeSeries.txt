CS 229 Final Project Report 
Learning to Decode Cognitive States of Rat using Functional Magnetic Resonance Imaging Time Series   
Jingyuan Chen  //Department of Electrical Engineering, cjy2010@stanford.edu// 

I Background 

 

 
Recent  fMRI  studies  have  observed  that  the  functional 
connectivity  between  different  brain  regions  may  exhibit 
significant  dynamic  changes  when  people  are  at  rest  [1]. 
Despite  the  little-known  nature  of  the  temporal  dynamics  at 
rest,  it’s  still  possible  for  us  to  localize  those  ‘dynamic 
sources’  by  comparing  the  fMRI  time  series  at  ‘rest-state’  to 
‘anesthetized-state’,  a  mental  state  characterized  by  a 
profound  loss  of  conscious  and  a  more  ‘stable’  baseline 
condition of the brain. However, as both states are ‘task-free’, 
we  are  unable  to  reference  an  external  task  waveform  and 
utilize 
linear 
regression  method 
to  pre-select 
the 
voxels/regions  of  interest  [2,3].  It  naturally  becomes  a 
problem dealt with machine learning project. Patterns that are 
informative  with  respect  to  the  differentiation  of  ‘rest-state’ 
and 
strong 
have 
likely 
‘anesthetized-state’  may 
neurobiological  relevance,  and  are  hypothesized  to  be  a 
potential candidate for the ‘dynamic source’ in the rat brain.     
For  the  specific  project,  advantages  of  using  rat  as  the 
object  are  twofold:  (i)  the  cognitive  mental  states  of  rats  are 
anticipated to be less complicated compared to human beings, 
along  with  the  smaller  voxel  amount,  the  dimensionality  of 
classification  features  can  be  greatly  reduced  without  losing 
useful information; (ii) anesthesia can be easily accomplished 
in rats.       
 

II Problem Illustration 

i. Object     
The  fMRI  datasets  from  3  rats  were  analyzed  in  the 
present project. Each rat underwent an 8-min ‘rest-state’ scan 
and an 8-min ‘anesthetized-state’ scan.     
 
Preprocessing  of  the  fMRI  time  series  consisted  of: 
slice-time correction, motion correction, low-frequency drift   
detrending.  Signal  amplitudes  were  further  scaled 
to 
percentage change.   
 

 
ii. Classifiers   
Classifiers were trained using short intervals of rat fMRI   
to  either 
to  correspond 
data  known 
‘rest-state’  or 
‘anesthetized-state’.  After 
training, 
the  classifier  was                                                                                                         
supposed  to  determine  whether  an  unseen  segment  of  fMRI 
dataset corresponded to a ‘rest-state’ or ‘anesthetized-state’. 
The analysis consisted of five steps:     
(a) Choose p  elements  (voxels/ networks)  that will  enter 
the classification analysis;       
(b)  Define  measures  of  brain  activity  (voxel  intensity/ 
functional  connectivity/ 
time-frequency  coherence)  and 
corresponding samples;   
 
(c)  Use  a  subset  of  trials  to  train  the  classifier  via 
Support Vector Machines (SVMs);       
 
(d) Use 10-fold cross validation to test the generalization 
error of the classifier;   
   
(e) Map the weighting of each element.   
and  (b)  !  Section  III  IV  V.  From  now  on,  let  {! ! }  denote 
 
the  fMRI  time  series  of  voxel  i  after  preprocessing,  {!!!! } 
The  primary  focus  of  the  present  project  was  step  (a) 
 
denote  the  ‘rest-state’  time  series,  { !!!! }  denote  the 
‘anesthetized-state’ time series.   
In  Section  III,  p  voxels/clusters were  pre-selected  based 
each  other,  the  modified  voxel  intensity:  !! ! ! !! ! !! ,  i.e. 
on  various  dimensionality  reduction  methods.  Considering 
that  the  fMRI  time  series  were  temporally  correlated  with 
average  of 
the  absolute  voxel 
intensities  across  five 
consecutive  time  points,  was  chosen  as  the  measure  of  brain 
activity;     
In  Section 
IV,  p  networks  were  generated  via 
independent 
(ICA).  Network 
analysis 
component 
connectivity  measure:  sliding-window  Pearson  correlation 
and  wavelet 
transform  coherence,  were 
introduced 
to 
characterize the brain activity. 

!
Since  the  number  of  voxels  inside  the  rat  brain  is  large 
(>20,000  with  the  protocol  in  the  present  data  acquisition), 
including all voxels for classification analysis  is sub-optimal: 
(i) it would increase the computation complexity and be quite 
time-consuming,  given  the  large  feature  dimension;  (ii) 
machine  learning  algorithms,  like  SVM,  might  degrade  their 
performances  if  the  number  of  voxels  conveying  the 
discriminative  information  is  much  smaller  compared  to  the 
total  number  of  voxels  [3,4],  which  is  always  true  under  the 
small-world  assumption  of  brain  models, 
this 
is  also 
confirmed  by  the  results  of  the  present  project.  Thus,  it’s 
reasonable and helpful  to perform a dimensionality  reduction 
prior  to  SVM  classification.  Three  dimensionality  reduction 
approaches were implemented in the project.   

 
i.  Significance-based  feature  selection  Under  the  hypothesis 
that  informative  patterns  only  consist  of  voxels  that  show  a 
significant 
and 
‘rest-state’ 
between 
difference 
‘anesthetized-state’,  it  would  therefore  be  reasonable  to 
restrict  our  analysis  to  those  ‘significant’  voxels,  which  can 
intensity  of  fMRI  time  series  {! ! }  can  be  well  fitted  by 
also simply the interpretation of the final results.   
Previous  studies  have  demonstrated  that  the  raw  voxel 
{! ! ! !! ! !}  actually  follow  folded  normal  distributions,  a 
Gaussian  models,  noting  that  our  modified  observations 
simple  two-sample  t  test  used  by  previous  literatures  [2,3] 
might  introduce  bias  into  the  present  testing  model.  To 
address  this  problem,  non-parametric  Wilcoxon’s  rank-sum 
{‘significant’ voxels}!{ t test: p<0.01} & {rank-sum test, p<0.01} 
tests  were  introduced  in  addition  to  t-test  to  select  those 
‘significant voxels’:   
fMRI  studies,  !!"#$%& ! !!"#$%&'()!*#   always  hold,  the 
 
ii.  Principal  Component  Analysis  Consider  the  fact  that  in 
!!!!! !!
!!!!! !!
computation  of  SVM  can  be  greatly  reduced  via  the  PCA 
concatenated,  !!!   denotes  z  transformation  (zero-centered 
kernel  trick,  while  preserving  all  the  feature  information: 
specifically, 
  and 
  were 
temporally 
under  two  states).  However,  !!!!! !  and  !!!!! !  were  taken 
and  divided  by  its  standard  derivation,  to  avoid  the  improper 
mapping  due  to  significant  differences  in  signal  intensity 
as  the  training  samples  of  SVM,  so  here  existed  an 
inconsistency  between  PCA  mapping  and  SVM  training. 

III Feature Selection – Voxel Intensity 

Later,  we  can  notice  a  difference  between  various  data 
reduction  methods,  the  inconsistency  here  was  thought  as  a 
candidate source to the observed differences.     
 
iii.  Clustering  Analysis  I  also  utilized  cluster-analysis 
methods 
to  accomplish  dimensionality 
reduction, 
i.e.   
separated  the  rat  brain  into  various  small  regions,  and 
simplified  each  small  region  as  a  single  feature.  Due  to  the 
slow  computation  of  K-means  clustering  method,  I  chose 
Normalized-cut  method  (http://www.cis.upenn.edu/~jshi/soft 
ware/)  to  perform  the  clustering  analysis,  which  takes  each 
voxel  as  a  node,  and  recast  the  image  segmentation  as  a 
graphic partition problem (in  the current analysis,  I chose  the 
Pearson correlation with threshold 0.1 as the weight measure). 
The  observation  corresponding  to  each  cluster  is  derived  as 
follows:  for  each  voxel  within  the  cluster,  sum  up  its 
correlation  with  all  the  other  voxels  within  the  same  cluster, 
choose  20  voxels  with  the  highest  summation  of  correlation 
values, and take the average of their observations.       
To  be  more  confident  with  the  clustering  result,  I  also 
measure of  similarity  !"#!!!   between  the generated clusters 
compared  the  clustering  results  from  N-cut  method  with 
those  from  K-means  method  for  a  couple  of  datasets.  A 
Let  !!! , !!!!   denote  the  cluster  index  of  voxel  !   resulted  from 
is defined as follows:     
!"#!!! ! ! !!!!!!!!!"# !!!!!!!!!"# ! !!!!! ! !!! ! ! !!!!!! ! !!! !
!!!!!!!!!!" !!!!!!!!!"# !
K-means methods and Normalized-cut methods:   
 
i.e.  the  ratio  of  cases  that  two  methods  give  consistent 
clustering  results with  respect  to a voxel-pair  (two voxels are 
reliable  the  clustering  result  is.  !"#!!! ! !"#  in  the  tested 
within  the  same  network  or  not),  I  assume  that  the  larger 
extent  that  the  two clusters overlap with each other,  the more 
datasets  indicated  a  convincing  clustering  result,  shown  in 
Figure 2.     
 
The  classifiers  trained  after  dimensionality  reduction 
worked  surprisingly  well,  the  generation  error  in  the  10-fold 
cross validation were 0 for all the three approaches. However, 
the  discriminative  patterns  were  inconsistent  across  rats 
(Figure  1  c,d)  and  dimensionality  reduction methods  (Figure 
1,  a,  b,  c  ),  |wi|  larger  than  30%  of  the  max(|wi|)  was  to 
approximate p < 0.05 [6].   

 

IV Feature Selection – Network Connectivity 

As  mentioned  above,  previous  machine 
learning 
approaches  to  fMRI  analysis  were  mainly  confined  to 
voxel/ROI  intensities,  I  was  especially  interested  to  see 
whether  choosing  features  that  can  characterize  connectivity 
behaviors,  which  attracts  the  primary  attention  of  fMRI 
researchers,  can  also  give 
informative  discriminations 
between  various  mental  states.  Again,  the  dimensionality 
!!"#$%&" ! !!"#$%!
! 
! !!!!"#$%
issue  becomes  more  problematic  when  it  comes  to  the 
!
connectivity behavior, as   
Therefore,  I  attempted  to  explore  the  connectivity  at  the 
 
network  level  instead  of  the  voxel  level.  Independent 
Component  Analysis  (ICA)  method  (via  a  matlab  based 
toolbox:  http://mialab.mrn.org/software/gift/)  was  utilized  to 
generate  the  networks(ICs),  to  be  consistent  with  prior 
literatures,  IC  number  was  set  to  be  30  [7,8].  Networks  of 
interest(NOI)  were  further  chosen  through  visual  inspection, 
resulting 10~20 networks per rat.   
 
i.  sliding-window  Pearson  correlation  analysis  To  get  the 
time-varying  observations  of 
the  connectivity  between 
different  network  pairs,  the  sliding-window  correlation 
and  y)  is  defined  as  ! ! ! !"##!!!!!!!! !!"# !!!!!!!! !,  where  w  is  the 
coefficient [1] was introduced, Figure 3:         
window  size,  !!!!!!!   and  !!!!!!!   denote  the  portion  of  the  time  series 
The  sliding-window  correlation  between  two  network  time  series  (x 
from  t  to  t+w-1,  corr(  )  denotes  the  computation  of  Pearson  correlation 
However,  features  (network-pairs) with  the maximum!!! !are 
coefficient.     
Not surprisingly, like using voxel intensity as the feature, 
SVM  gives  0%  training  error  in  10-fold  cross  validation. 
still  not  consistent  across  rats.  Taking  together  the  result 
from  Section  III,  0%  training  error  indicates  that  ‘rest-state’ 
and  ‘anesthetized-state’  are  highly  separable,  inconsistency 
across  methods/rats  may 
likely 
imply  a  wide-spread 
discriminative  patterns,  or  perhaps  due  to  rats’  individual 
differences,  as  the  mental  states  of  rats  are  less  controllable 
compared to human beings.             
!
!!"# $%&'(')#
)*%+,-.*/# 0.1'*'+0'23456# %+%(7,!,#
Classifiers  trained  by  voxel  intensity  and Pearson  correlation 

have  achieved  perfect  generative  performance,  but  the 
discriminative  patterns 
(voxels/network-pairs)  are  not 
consistent  across  rats.  I  further  extended  the  features  into  the 
frequency  domain,  hoping 
the 
to  explore  whether 
discriminative  patterns  of  different  rats  reside  in  similar 
frequency bands (Figure 4 a).       
WTC(http://www.pol.ac.uk/home/research/waveletcoher
ence/)  offers  a  measure  of  the  time-varying  coherences 
!! ! ! ! !
!!!!!! !!! ! ! !!!!! ! !!! ! ! !!! ! !! ! ! ! ! !# 8#
!!!!!!" !!! ! !
within different frequency bands for each network pair [1]:   
! !" ! ! ! ! ! ! ! ! ! ! !! ! ! ! 8# $1'*'# ! ! ! ! ! # !,# )1'# $%&'(')#
)*%+,-.*/#.-#,!9+%(#:8#;'+.)!+9#)1'#%/.<+)#.-#=.$'*#!+#>#%,#%#-<+0)!.+#.-#
)!/'#2+6#%+;#-*'?<'+07#2,6"# #
To  simplify  the  computation,  I  further  separated  the 
frequency 
into 
four 
frequency 
bands: 
0~0.02Hz, 
0.02~0.05Hz,  0.05~0.16Hz,  0.16~0.2Hz  (TR,  the  sampling 
For N  network  pairs, we  therefore  got  ! !!   features,  by 
rate is 1s) by averaging the WTC falls into the corresponding 
frequency range (Figure 4 b).     
weightings  !!!! ! ! ! !! ! !!! ! ! !! ! !! !! !   of  the  coherence  of 
taking the coherence value at different time spots as a sample 
and  applying  SVMs  to  the  WTC  results,  we  got  the 
frequency band  ! !   is defined as:   
different network pairs across different frequency bands.   
! ! ! ! !! !!!! !
! ! !! ! !! !! ! ! ! !! ! !!#
  For  each  rat,  the  discrimination  level  of  a  specific 
!! !! !!!! ! !
! !   reflects  how  discriminative  the  between-network 
coherences  within  the  j  th  frequency  band  is  compared  to 
other frequency bands.     
As  shown  in  Figure  5,  the  3  rats  showed  a  similar 
pattern:  the  most  discriminative  information  mainly  resided 
in  the  low-frequency bands. This  result  is  in accordance with 
general acknowledgement  that  ‘rest-state’  is characterized by 
low-frequency fluctuations.     
 

!!!Figure 1 Feature Mapping after dimensionality Reduction, green: brain mask (15 slices), red: voxels surpassing the thresholds     
!"#$%&$
!"#$%&$
!"#$%&$
!"#$%'$

".$ 7&.<'!8('=/#)6!">?,>!@!34A89B">?,>$$ !
"#$ %&'()'!*!+,-./)/0&'()'!"123435$6!
+,'=!#,8(0),/09-,':!;(#<.',/0!
7/!#,8(0),/09-,':!;(#<.',/0!
Figure 2 Clustering results of K-means and N-cut (similarity = 0.966)   

"C$ DEF !8('=/#)6!">?,>!@!34A89B">?,>$$!
"9$ DEF !8('=/#)6!">?,>!@!34A89B">?,>$$!
+,'=!#,8(0),/09-,':!;(#<.',/0!
+,'=!#,8(0),/09-,':!;(#<.',/0!
%,8(!)(;,() !/G!/0(!0('?/;H!19,;!
Figure 3 Illustration of Sliding-window Pearson correlation   
I-,#,0J&?,0#/?!./;;(-9',/0!

N&8(90)!
Figure 4 Illustration of WTC   

7&.<'!

Figure 5   

"9$
%,8(&K9;:,0J!+%E!9.;/))!L!#,GG(;(0'!
G;(M<(0.:!C90#)!G/;!(9.=!0('?/;H!19,; !

"C$ +%E!/G!9!0('?/;H!19,;! !

V Feature Selection-Revisit 

Feature  selection  methods  introduced  in  Lecture  Note  5 
and  Recursive  Feature  Elimination  (RFE)  proposed  in  [4] 
were  also  tested  in  the  present  study  to  see  whether  they 
absolute value {! ! ! !! ! !} as the voxel intensity resulted in 0% 
could 
improve 
the  generalization  performance  of 
the 
classifiers. As mentioned in section II and III, using the mean 
raw  voxel  intensity  {! ! }  to  train  the  classifiers,  100  clusters 
generalization  error  for  all  dimensionality  reduction  cases   
(which  could  not  be  further  improved).  Instead,  I  used  the 
generated  by  the  Normalized-cut method  were  chosen  as  the 
features.     
 
i. mutual information + forward feature selection   
(a) KL divergence was utilized as a criterion to sort the 100 features;   
(b)  Forward  feature  selection  &  10-fold  cross  validation  were 
combined to find the optimum features;     
 
ii. RFE       
while (~stop) 
! ! ! !! ! ! !"",   
  !!"# ! ! !
(a) Train SVMs using 10-fold cross valiation;   
!!! !!!!
!"!!! !"
(c) Sort the features based on  !!"# !  
(b) Compute the scoring function of each feature: 
(d) Eliminate features with smallest scores   
end     
 
The results are shown below:     

!"# "$%&'(# )$"# "*+"# "*'# %+,# -).'/# 0&"'&10"2# ,+1#
3)%# 5/+110305+"0)&6#
&)"# +&#
0&3)%4+"0-'#
3'+"$%'#
!&5/$10)&# )3# 4)%'# 3'+"$%'1# 75/$1"'%18# 5)$/(# )&/2#
 
0&"%)($5'# 4)%'# &)01290%%'/'-+&"# 0&3)%4+"0)&# +&(#
(':%+('#"*'#;'%3)%4+&5'#)3#"*'#5/+11030'%6# #

VI Summary     

VII Acknowledgement   

#
 
In  the  present  project,  I’ve  tried  to  apply  machine 
learning  knowledge  to  detect  patterns  (voxel  intensity/ 
network  connectivity)  that  are  informative  respect  to  the 
differentiation  of  ‘rest-state’  and  ‘anesthetized-state’  in  rats. 
Results  indicated  that:  (a)  Both  voxel-intensity-based  and 
network-connectivity-based  feature  selection  methods  can 
result  in  minimum  classification  error;  (b)  The  trained 
classifiers  are  sensitive  to  the  dimensionality  reduction 
methods  &  rats’  individual  differences  in  the  present  study; 
#
(c)  WTC  analysis  showed  that  the  network  coherence 
differences  between  ‘rest-state’  and  ‘anesthetized-state’ 
mainly reside in the relative low frequency band.   
#
 
I  gratefully  acknowledge  Dr.  Gary  Glover  in  Radiology 
Department and Emily Ferenczi  in Neuroscience Department 
for rat fMRI data acquisition.     
VIII References   
connectivity measured with fMRI. NeuroImage 50 (2010) 81-98;  #
<=># ?+&+0&+# '"# +/6@# A/+110320&:# B%+0&# 1"+"'1# +&(# ('"'%40&0&:# "*'#
[1]  Chang  et  al.,  Time–frequency  dynamics  of  resting-state  brain 
(015%040&+"0&:# +5"0-+"0)&# ;+""'%&1C# D$;;)%"# E'5")%# F+5*0&'# )&#
3$&5"0)&+/#FG!#(+"+6#H'$%)!4+:'#=I#7=JJK8#LIJMLLKN# #
<O># P'%'0%+# '"# +/6@# F+5*0&'# Q'+%&0&:# 5/+11030'%1# +&(# 3FG!C# +#
"$")%0+/#)-'%-0',6#H'$%)!4+:'#RK#7=JJL8#DSLLMD=JJN# #
<R># F+%"0&)# '"# +/6@# A)4B0&0&:# 4$/"0-+%0+"'# -).'/# 1'/'5"0)&# +&(#
1$;;)%"#-'5")%#4+5*0&'1#3)%#4+;;0&:#+&(#5/+110305+"0)&#)3#3FG!#
1;+"0+/#;+""'%&16#H'$%)!4+:'#RO#7=JJI8#RRMKIN# #
<K># D*0# '"# +/6@# H)%4+/0T'(# A$"1# +&(# !4+:'# D':4'&"+"0)&6# !UUU#
"%+&1+5"0)&1# )&# ;+""'%&# +&+/2101# +&(# 4+5*0&'# 0&"'//0:'&5'@# E)/#
==6#H)6#I@#=JJJ6#
<V># A+"0'# A*+&:6@# W'5)(0&:# A):&0"0-'# D"+"'1#
3%)4#
3FG!#
X04'1'%0'1@#AD#==L#=JJK#30&+/#;%)Y'5"1N# #
<Z>#Q$#'"#+/6@#G+"#B%+0&1#+/1)#*+-'#+#('3+$/"#4)('#&'",)%[6#PH\D@#
=JS=@#E)/#SJL@#H)#SJ@#OLZLMOLIR6# # # #
<I># Q0+&:# '"# +/6@# ]&5)-'%0&:# !&"%0&105# A)&&'5"0)&+/# \%5*0"'5"$%'#
)3# ^$&5"0)&+/# H'",)%[1# 0&# \,+['# G+"# _%+0&6# X*'# Y)$%&+/# )3#
H'$%)150'&5'@#=JSS@#OS#7SJ8@#OZZVMOZIO6# # #

