Efﬁcient Spike-Coding with Multiplicative
Adaptation in a Spike Response Model

Sander M. Bohte
CWI, Life Sciences
Amsterdam, The Netherlands
S.M.Bohte@cwi.nl

Abstract

Neural adaptation underlies the ability of neurons to maximize encoded informa-
tion over a wide dynamic range of input stimuli. Recent spiking neuron mod-
els like the adaptive Spike Response Model implement adaptation as additive
ﬁxed-size fast spike-triggered threshold dynamics and slow spike-triggered cur-
rents. Such adaptation accurately models neural spiking behavior over a limited
dynamic input range. To extend efﬁcient coding over large changes in dynamic in-
put range, we propose a multiplicative adaptive Spike Response Model where the
spike-triggered adaptation dynamics are scaled multiplicatively by the adaptation
state at the time of spiking. We show that, unlike the additive adaptation model,
the ﬁring rate in our multiplicative adaptation model saturates to a realistic max-
imum spike-rate regardless of input magnitude. Additionally, when simulating
variance switching experiments, the model quantitatively ﬁts experimental data
over a wide dynamic range. Dynamic threshold models of adaptation furthermore
suggest a straightforward interpretation of neural activity in terms of dynamic dif-
ferential signal encoding with shifted and weighted exponential kernels. We show
that when thus encoding rectiﬁed ﬁltered stimulus signals, the multiplicative adap-
tive Spike Response Model achieves a high coding efﬁciency and maintains this
efﬁciency over changes in the dynamic signal range of several orders of magni-
tude, without changing model parameters.

1

Introduction

The ability of neurons to adapt their responses to greatly varying sensory signal statistics is central
to efﬁcient neural coding [1, 2, 3, 4, 5, 6, 7]. Consequently, accurate models for the underlying
mechanisms can provide insight into the nature of neural coding itself. For this, models of neural
computation have to account for adaptation in a manner consistent with both experimental ﬁndings
and notions of efﬁcient neural coding.
Neural computation is often reduced to a linear-nonlinear-poisson (LNP) model: input signals are
ﬁltered, followed by a thresholding function that determines the ﬁring probability of the neuron. In
the Generalized Linear Model (GLM) [8] a refractory response in the form of a post-spike ﬁlter is
added (ﬁgure 1). With experimental responses ﬁtted to such LNP models, adaptation is found to
adjust both the effective gain in the thresholding function and the linear ﬁltering function [9, 10].
Neural adaptation responds primarily to changes in local stimulus contrast or, equivalently, to the
local detection threshold [11, 12], and a number of theoretical studies account for adaptation from
the perspective of optimal contrast estimation [12, 13]. Recent work by Ozuysal & Baccus [14]
suggests that in a Linear-Nonlinear ﬁrst-order Kinetics model (LNK), the gain depends on the local
contrast of the ﬁltered and rectiﬁed input signal.

1

Figure 1: Generalized Linear Model (GLM) of neural computation.

With substantial spike-rate adaptation occurring on a time scale of just tens of milliseconds [4, 5],
adapting neurons necessarily generate at most tens of spikes in that period. From an adaptive coding
perspective, this implies that for a neuron’s adaptation to be computable by downstream neurons,
the adaptation effects have to be derivable from just the emitted spike-train. Spike-based models are
thus central when accounting for adaptation as adaptive neural coding.
In variations of adaptive integrate-and-ﬁre neurons [15, 16, 17], adaptation can be incorporated as
a combination of two mechanisms: spike-triggered adaptation currents and a dynamical action-
potential threshold. In such models, the adaptation mechanisms together increase the distance be-
tween the reversal potential and the threshold, effectively changing the gain of the neuron. The
adaptive Spike Response Model [16, 17] in particular has been shown to be effective for modeling
neural behavior in response to input currents with limited dynamic range [17]. On longer timescales,
spike-triggered adaptation currents ﬁt a power-law decay rather than an exponential decay, linking
to observations of long-range power-law rate-adaptation [18, 19, 20, 21, 17].
Still, in spite of its success, the additive model of adaptation in adaptive Spike Response Model
effectively changes neural gain with at most a ﬁxed step-size, and thus cannot respond quickly to
changes in signal variance that are large compared to this step-size. In particular, Brette [22] argues
that adaptation modulation has to be multiplicative for neurons to respond with the same level of
neural activity to drastic changes in dynamic range, as is observed experimentally (e.g. [4]).
We augment the adaptive Spike Response Model with multiplicative adaptation dynamics. We show
that such a multiplicative adaptive Spike Response Model quantitatively matches neural responses in
variance switching experiments and maximizes information transfer. Furthermore, we demonstrate
that the model’s effective gain responds to changes in either mean or variance of the ﬁltered signal,
similar to the LNK kinetic model in [14].
In the adaptive Spike Response Model, gain modulation derives from the difference between the
adapted reversal potential and the dynamic threshold. This suggests a straightforward interpreta-
tion of spike-trains in terms of threshold-based detection of discernible signal levels in the rectiﬁed
ﬁltered input signal: adaptive spike-coding. We show how non-linear signal encoding with a multi-
plicative adaptive Spike Response Model maintains a high coding efﬁciency for stimuli that vary in
magnitude over several orders of magnitude, unlike the additive version of the adaptive Spike Re-
sponse Model. The coding efﬁciency is further comparable to the additive adaptive Spike Response
Model when the adaptation step-size in the latter is optimized for the local dynamic range.

2 Spike-rate Adaptation in the Spike Response Model

We follow Naud et al [17] in modeling adaptation in an augmented Spike-Response Model [23]. In
(cid:90)
(cid:90)
the adaptive Spike Response Model (aSRM), the dynamics of the (normalized) membrane-potential
(cid:88)
V (t) are described as a sum of integrated input current I (t) and spike-triggered currents η(t):
φ(t − s)I (s)ds −
φ(t − s)
η(s − ti )ds,
{ti }
(cid:18) −t
(cid:19)
where {ti } denotes the set of past emitted spikes, and the kernel φ(t) is a fast exponential low-pass
ﬁlter on membrane currents:
τm

φ(t) = φ0 exp

V (t) =

(1)

,

2

Linear (cid:31)lterSpikingNonlinearitypost-spike-(cid:31)lteroutputdelayinputg(t)s(t)u(t){t  }i,

(2)

VT (t) = V0 +

with τm determined by the membrane capacitance and conductance, and is typically on the order of
several milliseconds [23, 17] .
(cid:88)
The dynamical threshold is computed as the sum of a resting threshold V0 and spike-triggered thresh-
old dynamics γ (t):
γ (t − ti ).
{ti }
Spikes are generated either deterministically when V (t) − VT (t) becomes positive, or stochastically
(cid:18) V (t) − VT (t)
(cid:19)
following an inhomogeneous point process with conditional ﬁring rate:
λ(t|V (t), VT (t)) = λ0 exp
∆V
where ∆V determines the slope of the exponential function; small values of ∆V approximate a
neuron with a deterministic threshold. Naud et al [17] report that the threshold kernel γ (t) is best
ﬁtted with an exponentially decaying function, whereas the shape of the spike-triggered current η(t)
depends on the type of neuron, and furthermore for longer timescales best ﬁts a decaying power-law:
η(t − ti ) ∝ (t − ti )−β for t >> ti , with β ≈ 1.
the (ﬁltered) spike-triggered current: ϑ ∝ VT (t) + (cid:82) φ(t − s) (cid:80){ti } η(s − ti )ds. We can move the
We can denote the effective neural threshold ϑ as the amount of input that will trigger a spike. In
the adaptive Spike Response Model this amounts to the sum of the dynamic threshold, VT (t), and
(cid:20)
(cid:21)
(cid:90)
(cid:88)
reset response from (1) to the dynamic threshold (2) to obtain adaptation as the effective threshold
dynamics ϑ(t):
φ(t − s)η(s − ti )ds
γ (t − ti ) +
{ti }
where ϑ0 = V0 denotes the effective threshold for an inactive neuron. As the adaptation dynamics
in this model are strictly additive, we will refer to it further as the additive aSRM.
The maximum effective threshold in the additive aSRM is limited by the maximum number of spikes
that can be generated within the short time-window reported for variance adaptation. Effectively,
the refractory period determines the upper bound for the adaptation step-size, and adaptation speed
is upper-bounded by this value times the number of generated spikes.

ϑ(t) = ϑ0 +

(3)

,

(4)

2.1 Multiplicative Dynamic Adaptation

ϑ(ti )

ϑ(t) = ϑ0 +

We propose a modiﬁcation of the additive aSRM where the effective spike-triggered adaptation is
not a ﬁxed quantity but depends on the effective adaptation at the time of spiking. We include the
(cid:20)
(cid:21)
(cid:90)
multiplicative interaction in the aSRM by scaling the effective adaptation in (4) with the current
(cid:88)
adaptation value at the time of spiking:
φ(t − s)η(s − ti )ds
γ (t − ti ) +
{ti }
For sparse spiking and adaptation response kernels that decay fairly rapidly to zero, such multi-
plicative adaptive threshold dynamics are approximately similar to the effective threshold dynamics
in (4). For rapid signal variance transitions however, the multiplicative dynamics ensure that the
effective threshold adaptation can rapidly range over multiple orders of magnitude.
The key difference in adaptation dynamics for the two aSRM models is illustrated in Figure 2. For
a given spike-train, the respective adaptation magnitudes are plotted in Figure 2a , and the neural
responses to different levels of step-size current injections are shown in Figure 2b. The additive
aSRM responds to an increasing input current with a ﬁring rate that is essentially only bounded
by the refractory response; the ﬁring rate in the aSRM with multiplicative adaptation saturates at a
much lower value as the effective threshold catches up with the magnitude of the injected current.
2.2 Adaptive Spike-Coding

(5)

.

The interpretation of spike-triggered adaptation as dynamic neural gain in the Spike Response Model
suggests a straightforward application to a spike-based neural coding model. Spike-rate adaptation

3

Figure 2: Illustration of multiplicative and additive threshold adaptation dynamics. (a) Effective
adaptation as a sum of threshold dynamics (solid lines) and spike-triggered currents (dashed lines)
given an input spike-train (black dots). Red lines correspond to additive adaptation dynamics, blue
lines to multiplicative. (b) Firing rate as a function of signal strength. Red solid line is response for
(stochastic) additive aSRM, blue solid line for the stochastic multiplicative aSRM; dotted blue line
corresponds to a deterministic version of the multiplicative aSRM.

has been extensively studied from the point of view of optimal contrast estimation or signal threshold
detection [13, 12]. In particular the notion of signal threshold detection suggests a simple model
where individual spikes signal that the neuron has detected that its internally computed value has
reached a level distinguishable from the local noise level [11].
Taking the standard Linear-Non-Linear model of neural computation, we follow Ozuysal & Baccus
[14] in assuming that it is the rectiﬁed ﬁltered version of the stimulus signal, u(t), that is encoded
by the spikes emitted by a neuron. We then deﬁne the Linear-Non-Linear-Adaptive-Thresholding
(LNL-AT) model as greedy differential signaling: if the signal u(t) exceeds a threshold value ϑ(ti )
at time ti , a spike is generated communicating a scaled response kernel ϑ(ti )κ(t − ti ) to downstream
neurons. This response kernel is then also subtracted from the signal u(t), and the dynamic threshold
is updated to account for threshold adaptation (ﬁgure 3). In such greedy differential spike-coding,
(cid:88)
the signal u(t) is effectively approximated as a sum of shifted and weighted response kernels:
ϑ(ti )κ(t − ti ).
ˆu(t) =
ﬁltered reset function (cid:82) φ(t − s)η(t)ds is interpreted as a response kernel κ(t − ti ):
ti<t
This adaptive spike-coding model corresponds to the multiplicative adaptive SRM in (5), where the
(cid:90)
φ(t − s)I (s)ds − (cid:88)
ϑ(ti )κ(t − ti ),
V (t) =
(cid:88)
ti<t
= u(t) − ˆu(t),
ϑ(ti )γ (t − ti ),
ϑ(t) = ϑ0 +
{ti }

(6)

where spikes are generated when the membrane potential V (t) exceeds the dynamic threshold ϑ(t).
We let the threshold kernel γ (t) ﬁt a decaying power-law γ (t − ti ) ∝ (t − ti )−β , and, to take
advantage of temporal correlations, we model κ(t) as an exponentially decaying kernel with time-
constant τκ similar to the (average) correlation time of u(t), κ(t) = exp(−t/τκ ) [24] (note that
equation (5) implies that interchanging the behavior of η(t) and γ (t) does not change the SRM
responses). Difference based neural coding models for spike-based neural coding have been noted
in the context of probabilistic coding [25], and fast visual coding [26].
In this adaptive spike-coding model, each spike ti communicates a signal amount of magnitude
ϑ(ti ). In particular for signal ranges where the ﬁring rate saturates, the effective signal magnitude
per spike grows linearly with signal size. This is depicted in ﬁgure 4, for a neuron with a stochastic

4

010203040506070−20−10010203040  time (ms)E(cid:31)ective Adaptation Voltage(a)(b)910012345678020406080100120signalspike rate additive adaptationmultiplicative adaptationdeterministic thresholdspikesmultiplicative thresholdmultiplicative spike−triggered currenteffective additive thresholdeffective multiplicative thresholdadditive thresholdadditive spike−triggered currentFigure 3: The Linear-Non-Linear-Adaptive-Thresholding (LNL-AT) model.

threshold (large ∆V in (3); ﬁgure 4a) and for a neuron with a deterministic threshold (small ∆V
in (3); ﬁgure 4b). Plotted is the neural behavior in response to a range of step-size increases in the
signal u(t), where ﬁring rate and effective adapted threshold are measured two seconds after the
step-size signal increase. The average ﬁring rate shows the traditional saturation of neural response
with increasing signal size. However, the effective adapted threshold increases linearly with signal
size, paralleling the u = u signal identity.

Figure 4: Effective adapted threshold ϑ(ti ) (right axis) and ﬁring rate (left axis) as a function of
signal size u (a) stochastic multiplicative aSRM; (b) deterministic multiplicative aSRM.

3 Results

We demonstrate how the multiplicative aSRM quantitatively ﬁts with key ﬁndings on adaptation in
experimental data.

3.1 Variance Switching

The neural responses to variance switching [4, 5] in sensory signals are considered central evidence
for the information maximizing effect of adaptation, and also demonstrate the fast timescale of (ini-
tial) adaptation. In these key experiments, recordings are obtained from the blowﬂy’s H1 neuron,
and its responses are measured to a repeated change in perceived velocity variance. Signal variance
is repeatedly scaled from σ1 to σ2 = 10 ∗ σ1 , with a cycle time T . As the cycle-time T is increased,
the effective time constant of adaptation grows (as measured by ﬁtting an exponent on the initial
segment of the decaying curve). This time-constant of adaptation shows scale-free behavior: when
normalizing for the interval time T , the neural response curves overlap, and there is linear relation-
ship between cycle-time T and effective adaptation time constant τ . As reported in [27], the additive
aSRM is only able to match these ﬁndings qualitatively for a limited change in variance.
As in [4, 5], we generated random white noise within an interval enclosed by [−σi , σi ], for different
values of the variance σi (1 and 10 respectively). This signal was ﬁltered with ﬁlters obtained by the
GLM-model [8] on the original data from [4]. We fed the thus ﬁltered and rectiﬁed signal into the
multiplicative aSRM and optimized the model parameters using exhaustive line-search.

5

Linear (cid:31)lterSpikingNonlinearity(cid:31)lteroutputdelayinputpost-spike-012345678910signal urate  012345678910signal u0102030405060010203040506000101055ratearbitrary unitsarbitrary units  (a)(b)rateu = u1515The optimized multiplicative aSRM exhibits both the same ﬁring behavior and the same relationship
between normalized switching interval and normalized ﬁring rate as the experimental data in [5]
(Figure 5b,c). Furthermore, characterizing the input-output relationship as in [5] recovers the same
overlapping response-curves after normalizing the projected velocity signal for the scaled variance.
The ﬁtted adaptation decay time-constant τ also closely matches the experimental data [5] (Figure
5e, simulation: red circles, data: black circles). Changing the dynamic range for both σ1 and
σ2 = 10 ∗ σ1 by a factor of 10 did not change the relationship (green dots). We also characterized
the signal versus ﬁring rate response for three scaled versions of the same velocity signal, with
scaling factors 1, 2 and 3, similar to [4] (open markers, Figure 5f). As in [4], the adapted signal-
rate response curves also overlap after normalizing the signal for the scaled variance (solid markers,
Figure 5f). Multiplicative effective adaptation thus maximizes the transmitted information as in
[4, 5].

Figure 5: Variance switching. (a) variance of sensory input is switched with a ﬁxed cycle time.
(b) The aSRM neuron adapts its ﬁring rate after each switch. Switching responses for different
cycle times are overlapped. (c) The response curves for various cycle times overlap when time is
normalized for cycle time T . (d) Input-output relationship derived from 1-s-wide time windows in
the two signal variance conditions: left projected velocity signal s vs normalized ﬁring rate, right,
projected velocity signal s normalized by respective variance σ . (e) Relationship between ﬁtted
adaptation timescale τ as a function of cycle time T . Red circles simulation data; black circles
experimental data from [5]. Green dots are simulation data for switching signals multiplied by a
factor 10.
(f) Simulation response to signal scaled by factors σ1 = 1, σ2 = 2, σ3 = 3 (open
markers), and responses rescaled by signal scale factor (solid markers). (g) Effective gain (1/ϑ(t))
in the multiplicative aSRM neuron as a function of contrast, for signal u with mean held constant
and variance varied (blue line), and variance held constant and mean varied (green line). For the
experiments, resting threshold ϑ0 was set to 0.008, spike-triggered adaptation currents decayed with
a power-law constant of β = 1.15, as 3.5(t − ti + 0.7)−β and response kernels as 2.5 exp(−t/9)
(time t in ms).

6

−10−8−6−4−20246810−1100101102projected velocity sFiring rate  −0.8−1−0.6−0.4−0.200.20.40.60.81Normalized stimulus s/σ 101−s segment of high contrast1−s segment of low contrast0510152025303540Firing rate00.10.20.30.40.50.60.70.80.91Normalized time t/T(a)(b)(c)0Normalized rate−3−2−1012310203040506070051015202530354000.20.40.60.811.21.41.61.8Cycle time T (s)Timescale τ (s)experimental datasimulationsimulation x 10(e)(f)00.20.40.60.811.21.40102030405060signal sFiring rate  01234511.21.41.61.822.22.42.62.8contrastgain mean held constantstd dev held constant(d)(g)time (s)Normalized firing rate10−1100101102Figure 6: Multiplicative Spike-Coding: (a) illustration of stimulus encoding as a sum of shifted
and weighted response kernels. Black dots denote spike-times, black solid line the signal u(t), and
magenta the approximated signal ˆu(t). (b) Computed coding efﬁciency. Information rate Rinfo was
computed, with effective signal and noise bandwidth cutoff at 50Hz (matching the original stimulus
signal). Coding efﬁciency was computed by dividing Rinfo by the spike-train entropy rate S/T [28]
for a timing precision of 1 ms. Model parameters for the multiplicative aSRM are as in Figure 4.
Note that for the grey and light-grey bars refer to the left, parameters are optimized for each σ value
individually.

For adaptation to relate to contrast, loosely deﬁned as the ratio of (local) standard deviation σ and
local average signal ¯u, σ/ ¯u (and thus detection threshold), it should respond accordingly to changes
in not just variance but also in changes to mean (rectiﬁed) signal magnitude. Ozuysal & Baccus [14]
show that this property holds for their kinetic model of gain modulation, which also closely matches
experimental data. In the kinetic model, effective gain scales linearly with standard deviation when
all other signal statistics are held constant, and similarly with 1/ ¯u; in simulations, where effective
gain in computed as 1/ϑ(t), we ﬁnd that the multiplicative aSRM shares this property (Figure 5g).

3.2 H1 encoding/decoding

With multiplicative effective adaptation responding to contrast changes, we can examine the effec-
tiveness of the corresponding neural coding model. For this, we use the original blowﬂy data from
Brenner et al [4], consisting of velocity stimulus proﬁles presented to the blowﬂy, where the ve-
locity stimulus is scaled with factors of σ1 = 18◦ s−1 , σ2 = 2σ1 = 36◦ s−1 , σ3 = 90◦ s−1 and
σ4 = 180◦ s−1 . We examine how well multiplicative adaptive neural coding approximates the recti-
ﬁed ﬁltered signal, as compared to such neural coding with the additive aSRM.
We ﬁlter each version of this velocity stimulus with the ﬁlter obtained using GLM optimization on
the velocity stimulus with variance σ1 and optimize the parameters in both aSRM models for condi-
tion σ1 , using deterministic thresholds. Adaptation was highly robust for the parameters, provided
we chose an exponential response kernel with time-constant 10ms to match the correlation time of
the ﬁltered signal. We further tuned the resting threshold ϑ0 and magnitude of the power-law adap-
tation kernel γ so that the average ﬁring rate matched the experimental data at least for the σ1 signal.
An example of stimulus encoding with multiplicative adaptive neural coding is shown in ﬁgure 6a.
We compare coding efﬁciency for the multiplicative aSRM and for the additive aSRM for a spike
precision of 1ms [28], applying the model optimized for condition σ1 to all four stimulus conditions
σ1 , σ2 , σ3 , σ4 , and, for the multiplicative aSRM additionally for the conditions 50 × σ1 , 100 ×
σ1 , 500 × σ1 . Relative coding efﬁciencies are plotted in ﬁgure 6b, black and white bars. We see that
the multiplicative aSRM maintains a high coding efﬁciency over the entire dynamic range, even for
the 500 × σ1 stimulus condition. The dynamic range of the additive aSRM however is insufﬁcient
to encode the wide dynamic range of the original data. Similar to the experiment in [4], we ﬁnd

7

50060070080090010001100120013001400150000.511.522.533.544.55time (ms)signal spikessignal u(t)estimated signal u(t) 01020304050607080 coding efficiency (%)multipl adaptationadd. adaptationscaled sum adaptationscaled fixed(a)(b)that the ﬁring rate for the multiplicative aSRM signal encoding remains approximately stable for all
stimulus conditions, with a ﬁring rate of 55 ± 5 spikes/s, without changing any parameters. The
ﬁring rate for the additive aSRM increases from a (matched) ﬁring rate of 55 spikes/s for the σ1
stimulus, to over 180 spikes/s for the σ4 stimulus.
We also compare against the additive aSRM and neural coding with a non-adaptive, ﬁxed response
kernel SRM, with the magnitude of the response-kernel (equivalent to ϑ0 ) optimized for the local
variance such that for each stimulus, the ﬁring rate for these models matches that of the multiplicative
aSRM. This is shown in the light grey (scaled additive aSRM) and dark grey (scaled non-adaptive
SRM) bars in ﬁgure 6b. The coding efﬁciency for multiplicative aSRM is close to that of locally
rescaled additive aSRM’s, and exceeds locally rescaled non-adaptive coding.

4 Discussion

We showed how a multiplicative model of neural adaptation in the Spike Response Model can ac-
count quantitatively for key experimental adaptation data. When interpreting the fast adaptation
component as the manifestation of a greedy signal encoding scheme, we further showed that multi-
plicative adaptation allows the Spike Response Model to achieve high coding efﬁciency for signals
with dynamic ranges that change over several orders of magnitude, without changing parameters.
Just as the H1 blowﬂy neuron, the multiplicative aSRM uses a near-constant ﬁring rate for the widely
varying dynamic range in the different stimulus conditions.
The ubiquity of adaptation in neural systems and notions of synaptic facilitation and depression
suggest that gain modulation could possibly be decoded in a receiving neuron by adaptively scaling
the size of the post-synaptic response. Although Series [29] argues that a number of visual percepts
are consistent with decoding neurons being “unaware” of presynaptic adaptation, the presence or
absence of such coupled adaptation can be considered as a form of spectral ﬁltering [30]. As we
have shown, a key advantage of accounting for gain modulation in spike-based neural coding is
that it greatly extends the neuron’s dynamic range, and may allow for instance implicit spike-based
probabilistic computation as in [31] to scale to multiple layers.
From a biological perspective, it may seem implausible to let threshold dynamics and spike-triggered
adaptation currents scale with vast changes in dynamic range. However, as noted in [17], there is a
theoretical link between spike-triggered plasticity like spike-timing dependent plasticity and spike-
triggered adaptation [32]. That is, scaling of synaptic weights could complement adaptation to
large changes in dynamic range. The multiplicative adaptive Spike Response Model also captures
only part of the ﬁrst-order dynamics in the LNK model in [14], and does not account for variance-
dependent changes in temporal ﬁltering (e.g. [9]). Thus, spike-based adaptation of the response
kernel could likely further improve the coding efﬁciency.
The multiplicative adaptive Spike Response Model provides a spike-based account for gain mod-
ulation, which can easily be reconstructed by post-synaptic neurons as a function of the received
spike-train. It thus provides an effective neuron model for dynamical spiking neural networks, re-
solving for instance stability problems in spiking reservoir computing approaches.
Acknowledgement. The author thanks Hao Wang for assistance with the simulations, and Jaldert
Rombouts, Kausik Lakshminarasimhan and Hao Wang for helpful suggestions.

References
[1] S B Laughlin. The role of sensory adaptation in the retina. The Journal of experimental biology, 146:39–
62, September 1989.
[2] S.M. Smirnakis, M.J. Berry, D.K. Warland, W. Bialek, and M. Meister. Adaptation of retinal processing
to image contrast and spatial scale. Nature, 386(6620):69–73, 1997.
[3] M.J. Wainwright. Visual adaptation as optimal information transmission. Vision Research, 39(23):3960–
3974, 1999.
[4] N. Brenner, W. Bialek, and R. de Ruyter van Steveninck. Adaptive rescaling maximizes information
transmission. Neuron, 26(3):695–702, 2000.
[5] A.L. Fairhall, G.D. Lewen, W. Bialek, and R.R. de Ruyter van Steveninck. Efﬁciency and ambiguity in
an adaptive neural code. Nature, 412(6849):787–792, 2001.

8

[6] O Schwartz and E P Simoncelli. Natural signal statistics and sensory gain control. Nature Neuroscience,
4(8):819–25, 2001.
[7] T. Hosoya, S.A. Baccus, and M. Meister. Dynamic predictive coding by the retina. Nature, 436(7047):71–
77, 2005.
[8] J.W. Pillow, L. Paninski, V.J. Uzzell, E.P. Simoncelli, and E.J. Chichilnisky. Prediction and decod-
Journal of Neuroscience,
ing of retinal ganglion cell responses with a probabilistic spiking model.
25(47):11003–13, 2005.
[9] S. Baccus and M. Meister. Fast and slow contrast adaptation in retinal circuitry. Neuron, 36(5):909–19,
2002.
[10] S. Hong, B.N. Lundstrom, and A.L. Fairhall. Intrinsic gain modulation and adaptive neural coding. PLoS
Computational Biology, 4(7), 2008.
[11] H P Snippe and J H van Hateren. Recovery from contrast adaptation matches ideal-observer predictions.
Journal of the Optical Society of America. A, Optics, image science, and vision, 20(7):1321–1330, 2003.
[12] H P Snippe, L Poot, and J H Van Hateren. Asymmetric dynamics of adaptation after onset and offset of
ﬂicker. Journal of Vision, pages 1–12, 2004.
[13] M. DeWeese and A. Zador. Asymmetric dynamics in optimal variance adaptation. Neural Comp,
10(5):1179–1202, 1998.
[14] Y. Ozuysal and S.A. Baccus. Linking the Computational Structure of Variance Adaptation to Biophysical
Mechanisms. Neuron, 73(5):1002–1015, March 2012.
[15] R Harris, D C O’Carroll, and S B Laughlin. Contrast gain reduction in ﬂy motion adaptation. Neuron,
28(2):595–606, 2000.
[16] R. Jolivet, A. Rauch, H.R. L ¨uscher, and W. Gerstner. Predicting spike timing of neocortical pyramidal
neurons by simple threshold models. Journal of computational neuroscience, 21(1):35–49, 2006.
[17] R Naud. The Dynamics of Adapting Neurons. PhD thesis, EPFL Lausanne, 2011.
[18] P.J. Drew and LF Abbott. Models and properties of power-law adaptation in neural systems. Journal of
neurophysiology, 96(2):826, 2006.
[19] Z. Xu, JR Payne, and ME Nelson. Logarithmic time course of sensory adaptation in electrosensory
afferent nerve ﬁbers in a weakly electric ﬁsh. Journal of neurophysiology, 76(3):2020, 1996.
[20] B.N. Lundstrom, M.H. Higgs, W.J. Spain, and A.L. Fairhall. Fractional differentiation by neocortical
pyramidal neurons. Nature neuroscience, 11(11):1335–1342, 2008.
[21] B. Wark, A. Fairhall, and F. Rieke. Timescales of inference in visual adaptation. Neuron, 61(5):750–761,
2009.
[22] R. Brette. Spiking models for level-invariant encoding. Front. in Comp. Neurosc., 5, 2011.
[23] W. Gerstner and W. Kistler. Spiking Neuron Models: Single Neurons, Populations, Plasticity. Cambridge
University Press, 2002.
[24] M. Buiatti and C. van Vreeswijk. Variance normalisation: a key mechanism for temporal adaptation in
natural vision? Vision Research, 43(17):1895–1906, August 2003.
[25] S. Deneve. Bayesian spiking neurons I: inference. Neural computation, 20(1):91–117, 2008.
[26] P. Lichtsteiner, C. Posch, and T. Delbruck. A 128× 128 120 db 15 µs latency asynchronous temporal
contrast vision sensor. Solid-State Circuits, IEEE Journal of, 43(2):566–576, 2008.
[27] C Pozzorini, R Naud, S Mensi, and W Gerstner. Multiple timescales of adaptation in single neuron
models. In Front. Comput. Neurosci. Conference Abstract: BCCN, 2010.
[28] F. Rieke, D. Warland, and W. Bialek. Spikes: exploring the neural code. The MIT Press, 1999.
[29] P. Seri `es, A.A. Stocker, and E.P. Simoncelli. Is the Homunculus “Aware” of Sensory Adaptation? Neural
Computation, 21:3271–3304, 2009.
[30] S.M. Bohte and J.O. Rombouts. Fractionally Predictive Spiking Neurons. In Advances in Neural Infor-
mation Processing Systems (NIPS) 23, pages 253–261. The MIT Press, 2010.
[31] W.J. Ma, J.M. Beck, P.E. Latham, and A. Pouget. Bayesian inference with probabilistic population codes.
Nature neuroscience, 9(11):1432–1438, November 2006.
[32] G. Hennequin, W. Gerstner, and J.P. Pﬁster. Stdp in adaptive neurons gives close-to-optimal information
transmission. Front. in Comp. Neurosc., 4, 2010.

9

