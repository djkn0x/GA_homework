Phishing Detection Using Neural Network

Ningxia Zhang, Yongqing Yuan
Department of Computer Science, Department of Statistics, Stanford University

Abstract

The goal of this project is to apply multilayer feedforward neural networks to phishing email detection and evaluate the effectiveness of
this approach. We design the feature set, process the phishing dataset, and implement the neural network (NN) systems. We then use
cross validation to evaluate the performance of NNs with different numbers of hidden units and activation functions. We also compare
the performance of NNs with other major machine learning algorithms. From the statistical analysis, we conclude that NNs with an
appropriate number of hidden units can achieve satisfactory accuracy even when the training examples are scarce. Moreover, our feature
selection is effective in capturing the characteristics of phishing emails, as most machine learning algorithms can yield reasonable results
with it.
Introduction

incorporating some basic features pertaining to the email
structure and external links.

1

Recently, a phishing email has been circulating in the
Stanford community, aiming to collect SUnetIDs and pass-
words. As the majority of phishing emails are formatted
to appear from a legitimate source, a large percentage
of email users are unable to recognize phishing attacks.
Moreover, traditional spam email ﬁlters are inclined to fail
to identify phishing emails since most phishing attacks use
more sophisticated techniques and tend to be directed to a
more targeted audience. With the increasing severity of this
issue, many efforts have been devoted to apply machine
learning methods to phishing detection.

One of the most common machine learning techniques
for phishing classiﬁcation is to use a list of key features
to represent an email and apply a learning algorithm to
classify an email to phishing or ham based on the selected
features. Chandrasekaran et al.
[4] proposed a novel
technique to classify phishing emails based on distinct
structural characteristics, such as the structure of the email
subject line and some functional words. They used SVM to
test their features on 400 emails and obtained a 95% accu-
racy rate. However, they did not perform different splits
between training and test data due to the small sample size.
Fette et al. [6] used ten different features speciﬁc to the
deceptive methods for phishing classiﬁcation and obtained
an F1 -measure of more than 90% using a support vector ma-
chine classiﬁer. However they used signiﬁcantly more ham
emails (7000) than phishing emails (860) in their simulation.

In this project, we use approximately 8762 emails out
of which 4560 are phishing emails and the rest are ham.
We notice that few studies have been done on applica-
tions of neural networks (NNs) to phishing email ﬁltering.
Although NNs normally require considerable time for pa-
rameter training, they usually yield more accurate results
than other classiﬁers [5]. In our project, we try to detect
phishing attacks through a feedforward neural network by

1

2 Methods

2.1 Features

After referring to available literature, we have selected and
deﬁned a set of features that capture the characteristics of
phishing emails [1, 3, 6].

2.1.1 Structural Features

1. Total number of body parts
According to MIME standard, "Content-Type" attribute of
one email could be multipart, meaning that this email has
multiple body parts. Phishers are likely to utilize this fact to
construct phishing emails with sophisticated structures. By
counting the number of boundary variables, we obtain the
number of body parts in a multipart email. If the "Content-
Type" of the email is not multipart, this feature is set to
0, for the purpose of differentiating from multipart emails
with only one body part. If one part can be further divided
into multiple parts, the number of sub-parts is added to
the number of parts of the entire email. For example, if an
email has 2 body parts, one of which has 2 sub-parts, the
number of body parts is set to 4. However, only 3 parts of
the content are scanned in the feature extraction process.
2. Total number of alternative parts
The multipart/alternative subtype indicates that each part
is an "alternative" version of the same or similar content,
each in a different format denoted by its "Content-Type"
header [7]. As it is not strictly enforced that each part
of the message is the same or similar, phishers often take
advantage of this fact to create fraudulent emails.

2.1.2 Link Features

1. Total number of links
Phishing emails usually contain multiple links to fake web-
sites for readers to sign in.
2. Number of IP-based links
A legitimate website usually has a domain name for identi-
ﬁcation while phishers typically use multiple zombie sys-
tems to host phishing sites. Besides, the use of IP address
makes it difﬁcult for readers to know exactly which site
they are being directed to when they click on the link.
Therefore, the presence of IP-based links can be a good
indicator of phishing emails.
3. Number of deceptive links
Deceptive links are the ones with visible URLs different
from the URLs to which they are pointing. Some phishers
use this technique to fool email readers into clicking on the
links.
4. Number of links behind an image
In order to make the emails look authentic, phishers often
place in the emails images or banners linking to a legitimate
website. Thus, if URL-based images appear in an email, it
is likely to be an phishing email.
5. Maximum number of dots in a link
Using sub-domains is another technique phishers often
exploit to make links appear legitimate, resulting in a inor-
dinately large number of dots in the URL [3].
6. A Boolean indicator of whether there is a link that contains
one of the following words: click, here, login, update
To realize the goal of acquiring usernames, passwords, or
credit card information from the readers, phishing emails
often invite readers to login to the fake websites for reasons
such as updating personal information. Therefore, those
words appearing in the link text would be a good indicator.

2.1.3 Element Features

1. A Boolean indicator of whether it is in HTML format
Phishing emails are mostly in HTML format as plain text
does not provide the opportunity to play the tricks of phish-
ing.
2. A Boolean indicator of whether it contains JavaScript
JavaScript enables phishers to perform many actions behind
the scene, such as creating popup windows and changing
the status bar of a web browser [6]. If the email contains
strings, "javascript" or "onclick", this feature is set to one.
3. A Boolean indicator of whether it contains <Form> tag
HTML forms are one of the techniques used to gather
information from readers [3].

2.1.4 Word List Features

appear as phishers fabricate stories luring readers to enter
their personal information.

2.2 Neural Networks
An artiﬁcial neural network, or neural network, is a mathe-
matical model inspired by biological neural networks. In
most cases it is an adaptive system that changes its struc-
ture during learning [10]. There are many different types
of NNs. For the purpose of phishing detection, which is
basically a classiﬁcation problem, we choose multilayer
feedforward NN. In a feedforward NN, the connections
between neurons do not form a directed cycle. Contrasted
with recurrent NNs, which are often used for pattern recog-
nition, feedforward NNs are better at modeling relation-
ships between inputs and outputs. In our experiments, we
use the most common structure of multilayer feedforward
NN, which consists of one input layer, one hidden layer
and one output layer. The number of computational units
in the input and output layers corresponds to the number
of inputs and outputs. Different numbers of units in the
hidden layer are attempted in the following experiments.
To ﬁt our dataset, hyperbolic tangent and sigmoid are used
as activation functions. A comparison of the two is also
conducted. With regard to the training method, we choose
resilient propagation training (RPROP), as it is usually the
most efﬁcient training algorithm for supervised feedfor-
ward NNs [9].

2.3 Other Machine Learning Techniques
To further evaluate the performance of NNs in phishing
detection, we compare its performance against that of other
major machine learning classiﬁers – decision tree (DT),
K-nearest neighbors, naive Bayes (NB), support vector ma-
chine (SVM) and unsupervised K-means clustering. The
same dataset and feature set are used in the comparison.

2.4 Cross Validation
Given a training dataset and a proposed classifer, we as-
sess the performance of the classiﬁer by using hold-out
cross validation, also known as simple cross validation [8].
The dataset is randomly divided into Str ain and Scv . The
proposed classiﬁer is trained on Str ain to get parameter esti-
mates and tested on Scv . We then obtain the output which
indicates whether each email in Scv is ham or phishing.
This procedure is repeated 20 times for different sizes of
Str ain and Scv . The proportions of the dataset used as Str ain
are as follows: 0.1%, 1%, 10%, 20%, 30%, 40%, 50%, 60%,
70%, 80% and 90%.

1. Boolean indicators of whether the words or stems listed below
appear in the email body: account, update, conﬁrm, verify, secur,
notif, log, click, inconvenien
In typical phishing email examples, these words frequently

2.5 Evaluation Metrics
By comparing the classiﬁcation predictions with the actual
categories of the emails, we are able to compute the num-

2

bers of true negatives (TN, correctly classiﬁed ham email),
false negatives (FN, phishing email mistakenly classiﬁed as
ham), true positives (TP, correctly classiﬁed phishing email)
and false positives (FP, ham email mistakenly classiﬁed
as phishing). To evaluate the classiﬁer performance, we
compute the accuracy(Accu) and the weighted accuracy
(Wacc ) by the following formula:

(1)

(2)

Accu =

Wacc (λ) =

T N+T P
T N+FP+T P+FN
λ·T N+T P
λ·(T N+FP)+FN+T P
In phishing email ﬁltering, errors are not of equal impor-
tance. A false positive is much more costly than a false
negative in the real world [1]. It is thus desirable to have
a classﬁer with a low false positive rate. The "weighted
accuracy" measure is proposed by Androutsopoulos et al.
[2] to address this issue. Different values of λ can be ap-
plied to the formula (1). Notice that when λ is one, the FP
and FN are weighed equally. In our simulations, we pick
λ = 9 so that FP are penalized nine times more than FN.
In addition, we compute the precision, recall and F1 -score
of each classifer as follows:

T P+FP Recal l = T P
Precision = T P
T P+FN
F1 = 2· precision·recal l
precision+recal l

(3)

(4)

3 Dataset

The dataset comprises of a large number of real world ex-
amples of ham and phishing emails, all in standard MIME
format. There are a total number of 4202 ham emails and
4560 phishing emails, separated in 7 folders, 3 of which
hold ham emails and 4 hold phishing emails. Each text ﬁle
contains a single MIME email.

4

Implementation and Experiments

4.1 Preprocessing

4.1.1 Feature Extraction

We write a Perl script to extract features from one email
example. It reads in the email ﬁle, does structural analysis
with the help of MIME::Entity and MIME::Parser modules.
It summarises link features using HTML::SimpleLinkExtor
and HTML::LinkExtractor modules. Other features are
obtained by taking advantage of the powerful regular ex-
pression manipulation of Perl. Ultimately, it outputs a
feature vector together with the ideal value (1 for phishing
email and 0 for ham). To process the entire dataset, another
Perl script is written to call the feature extracting script and
write the obtained feature vectors line by line into one text
ﬁle.

3

4.1.2 Normalization

In order to ensure that each feature has an equal impact in
the classiﬁcation process, the vectors should be normalized
before applying machine learning algorithms. For each
feature, we ﬁnd the maximum and minimum values, and
for each value of this feature, we compute:
normal ized_value = (current_value−minimum)
(max imum−minimum)

After normalization, the values of all features fall into the
range of 0 to 1 and each feature contributes the same in de-
termining the classiﬁcation output. The normalized vectors
of the whole dataset are stored in another text ﬁle.

4.1.3 Training and Test Sets Preparation

To conduct the cross validations described above, we di-
vide the dataset into training and test sets with different
proportions. For each proportion, we generate 20 different
training and test sets. This is done by Matlab.

4.2 Machine Learning Implementation

The multilayer feedforward NN is implemented in Java
with the Encog Java Core package, which provides a power-
ful framework to conveniently construct NNs and perform
training and testing. When implementing other machine
learning algorithms, we exploit the corresponding off-the-
shelf Matlab packages.

4.3 Data Analysis

Once we obtain the classiﬁcation predictions, we compute
TN, FN, TP, FP, Accu, Waccu , Precision, Recall and F1 -score
as described in the method section. We compare different
neural networks by varying the units in the hidden layer
as well as the activation function. We also compare the
performance of neural networks with that of other machine
learning techniques.

5 Results

As mentioned in the previous section, to evaluate each
neural network classiﬁer, we calculate the average Accu
and Waccu (λ = 9) in 20 cross validation procedures for
each training size. As shown in Figure 1 and Figure 2,
when the training size is small, more hidden units tend to
overﬁt the data while fewer hidden units tend to underﬁt.
However, when the training set is large enough, the num-
ber of hidden units does not greatly affect performance.

Figure 1: Each curve shows the average Accu for an NN classiﬁer
with a speciﬁc hidden layer size.

Figure 4: Waccu for NN with 0.1% training size
We compare the NN performance using two activa-
tion functions: hyperbolic tangent (HT) function and sig-
moid function. The results are shown in Figure 5 and
Figure 6. It is noticeable that the sigmoid function per-
forms slightly better than the hyperbolic tangent function.

Figure 2: Each curve shows the average Waccu for an NN classi-
ﬁer with a speciﬁc hidden layer size.

Figure 5: Accu of two NN (8 hidden units) activation functions

To further demonstrate the overﬁtting of the dataset
with a small training size, we examine the Accu and
Waccu for the 0.1% training set in Figure 3 and Fig-
ure 4. We observe that the two curves both peak
at 8 hidden units and start to decline as more hid-
den units are used.
It is also worth noting that the
Waccu generally drops after penalizing FP more than FN.

Figure 6: Waccu of two NN (8 hidden units) activation functions
We also compare the NN performance with other ma-
chine learning techniques. The results are shown in Figure
7 and Figure 8. Decision tree has the best overall perfor-
mance, while it falls short on small training sets compared
to NN and K-nearest. Generally, most algorithms can reach
an accuracy of 95%, which suggests that the selected feature
set has captured the essential characteristics of phishing
emails. When we perform unsupervised 2-means clustering
on the entire dataset, we are able to achieve 87% accuracy,
which further supports the validity of our feature set.

Figure 3: Accu for NN with 0.1% training size

4

the highest recall while still mainitaining a >95% precision,
suggesting that NNs are excellent at detecting phishing
emails while misclassifying only a small portion of ham
emails.

References

[1] Saeed Abu-Nimeh, Dario Nappa, Xinlei Wang, and
Suku Nair. A comparison of machine learning tech-
In Proceedings of the
niques for phishing detection.
Anti-Phishing Working Group eCrime Researchers Sum-
mit, pages 649–656, 2007.

[2] Ion Androutsopoulos, John Koutsias, Konstantinos V.
Chandrinos, George Paliouras, and Constantine D.
Spyropoulos. An evaluation of naive bayesian anti-
spam ﬁltering. In Proceedings of the Workshop on Ma-
chine Learning in the New Information Age, 11th Eu-
ropean Conference on Machine Learning, Barcelona,
Spain, 2002.

[3] Ram Basnet, Srinivas Mukkamala, and Andrew H.
Sung. Detection of phishing attacks: A machine learn-
ing approach. Studies in Fuzziness and Soft Computing,
226:373–383, 2008.

Krishnan
[4] Madhusudhanan
Chandrasekaran,
Narayanan, and Shambhu Upadhyaya.
Phish-
ing e-mail detection based on structural properties. In
Proceedings of the NYS Cyber Security Conference, 2006.

[5] James Clark, Irena Koprinsk, and Josiah Poon. A neu-
ral network based approach to automated e-mail clas-
siﬁcation. In Proc. IEEE/WIC International Conference on
Web Intelligence (WI), pages 702–705, 2003.

[6] Ian Fette, Norman Sadeh, and Anthony Tomasic.
In Proceedings
Learning to detect phishing emails.
of the International World Wide Web Conference(WWW),
2007.

[7] Network Working Group. Multipurpose internet
mail extensions (MIME) part two:media types. http:
//tools.ietf.org/html/rfc2046#section-5.1.4,
1996.

[8] Andrew Ng. CS229 lecture notes. http://cs229.
stanford.edu/notes/cs229-notes5.pdf, 2012.

[9] Martin Riedmiller and Heinrich Braun. A direct adap-
tive method for fast backpropagation learning: The
In Proceedings of the IEEE Interna-
rprop algorithm.
tional Conference on Neural Networks, volume 5, pages
586–591, 1993.

[10] Wikipedia. Artiﬁcial neural network — wikipedia, the
free encyclopedia.

Figure 7: Accu of NN (8 hidden units) and other machine learn-
ing techniques

Figure 8: Waccu of of NN (8 hidden units) and other machine
learning techniques

Table 1: Evaluations of NNs with two activation functions
F1
Activation Accu Waccu
Precision Recall
0.9571
0.9618
0.9525
0.9494
0.9551
HT
sigmoid
0.9516
0.9417
0.9450
0.9630
0.9539

Table 2: Evaluations of NNs and other machine learning tech-
niques
F1
Accu Waccu
Precision Recall
Method
0.9668
0.9561
0.9778
0.9742
0.9658
DT
0.9275
0.9555
0.9022
0.8929
0.9218
SVM1
0.9591
0.9491
0.9693
0.9654
0.9579
SVM2
0.9367
0.9460
0.9173
0.9278
0.9370
NB
0.9579
0.9583
0.9585
0.9536
0.9558
K-nearest
NN
0.9571
0.9525
0.9618
0.9551
0.9494
Table 1 summarizes performance measures for NNs
with two activation functions in detail. As seen in the table,
HT function performs slightly better in terms of all mea-
sures except recall. Notice that the largest difference out
of all the measures comes from Waccu , which suggests that
the HT function is better at avoiding misclassifying ham
emails to phishing emails.
Table 2 summarizes the performace measures for NNs
and other machine learning techniques. As shown in the
table, DT gives the best overall performance. NNs give

5

