Probabilistic n-Choose-k Models for Classiﬁcation
and Ranking

Kevin Swersky
Daniel Tarlow
Dept. of Computer Science
University of Toronto
[kswersky,dtarlow]@cs.toronto.edu

Ryan P. Adams
School of Eng. and Appl. Sciences
Harvard University
rpa@seas.harvard.edu

Richard S. Zemel
Dept. of Computer Science
University of Toronto
zemel@cs.toronto.edu

Brendan J. Frey
Prob. and Stat. Inf. Group
University of Toronto
frey@psi.toronto.edu

Abstract

In categorical data there is often structure in the number of variables that take on
each label. For example, the total number of objects in an image and the number of
highly relevant documents per query in web search both tend to follow a structured
distribution. In this paper, we study a probabilistic model that explicitly includes
a prior distribution over such counts, along with a count-conditional likelihood
that deﬁnes probabilities over all subsets of a given size. When labels are binary
and the prior over counts is a Poisson-Binomial distribution, a standard logistic
regression model is recovered, but for other count distributions, such priors induce
global dependencies and combinatorics that appear to complicate learning and
inference. However, we demonstrate that simple, efﬁcient learning procedures
can be derived for more general forms of this model. We illustrate the utility of
the formulation by exploring applications to multi-object classiﬁcation, learning
to rank, and top-K classiﬁcation.

Introduction
1
When models contain multiple output variables, an important potential source of structure is the
number of variables that take on a particular value. For example, if we have binary variables indi-
cating the presence or absence of a particular object class in an image, then the number of “present”
objects may be highly structured, such as the number of digits in a zip code. In ordinal regression
problems there may be some prior knowledge about the proportion of outputs within each level. For
instance, when modeling scores assigned to papers submitted to a conference, this structure can be
due to instructions that reviewers assign scores such that the distribution is roughly uniform.
One popular model for multiple output classiﬁcation problems is logistic regression (LR), in which
the class probabilities are modeled as being conditionally independent, given the features; another
popular approach utilizes a softmax over the class outputs. Both models can be seen as possessing
a prior on the label counts: in the case of the softmax model this prior is explicit that exactly one
is active. For LR, there is an implicit factorization in which there is a speciﬁc prior on counts; this
prior is the source of computational tractability, but also imparts an inductive bias to the model. The
starting observation for our work is that we do not lose much efﬁciency by replacing the LR counts
prior with a general prior, which permits the speciﬁcation of a variety of inductive biases.
In this paper we present a probabilistic model of multiple output classiﬁcation, the n-choose-
k model, which incorporates a distribution over the label counts, and show that computations needed

1

for learning and inference in this model are efﬁcient. We develop applications of this model to di-
verse problems. A maximum-likelihood version of the model can be used for problems such as
multi-class recognition, in which the label counts are known at training time but only a prior dis-
tribution is known at test time. The model easily extends to ordinal regression problems, such as
ranking or collaborative ﬁltering, in which each item is assigned to one of a small number of rel-
evance levels. We establish a connection between n-choose-k models and ranking objectives, and
prove that optimal decision theoretic predictions under the model for “monotonic” gain functions
(to be deﬁned later), which include standard objectives used in ranking, can be achieved by a simple
sorting operation. Other problems can be modeled via direct maximization of expected gain. An
important aim in classiﬁcation and information retrieval is to optimize expected precision@K. We
show that we can efﬁciently optimize this objective under the model and that it yields promising
results.
Overall, the result is a class of models along with a well-developed probabilistic framework for
learning and inference that makes use of algorithms and modeling components that are not often
used in machine learning. We demonstrate that it is a simple, yet expressive probabilistic approach
that has many desirable computational properties.
2 Binary n-Choose-k Model
We begin by deﬁning the basic model under the assumption of binary output variables.
In the
following section, we will generalize to the case of ordinal variables. The model inputs are x,
and θ is deﬁned as θ = Wx, where W are the parameters. The model output is a vector of D
binary variables y ∈ Y = {0, 1}D . We will use subsets c ⊆ {1, . . . , D} of variable indices and will
represent the value assigned to a subset of variables as y c . We will also make use of the notation ¯c
to mean the complement {1, . . . , D}\c. The generative procedure is then deﬁned as follows:
• Draw k from a prior distribution p(k) over counts k .
(cid:40) exp{(cid:80)
• Draw k variables to take on label 1, where the probability of choosing subset c is given by
d∈c θd }
if |c| = k
p(y c = 1, y ¯c = 0 | k) =
Zk (θ)
otherwise
being off or on, and Zk (θ) = (cid:80)
d yd=k exp{(cid:80)
0
y | (cid:80)
where θ = (θ1 , . . . , θD ) are parameters that determine individual variable biases towards
d θd yd}. Under this deﬁnition Z0 = 1,
and p(0 | 0) = 1. This has been referred to as a conditional Bernoulli distribution [1].
Logistic regression can be viewed as an instantiation of this model, with a “prior” distribution over
count values that depends on parameters θ . This is a forced interpretation, but it is useful in under-
where Z (θ) = (cid:80)
standing the implicit prior over counts that is imposed when using LR. Speciﬁcally, if p(k) is deﬁned
the following sense. Suppose we have a joint assignment of variables y and (cid:80)
as be a particular function of θ (known as a Poisson-Binomial distribution [2]): p(k ; θ) = Zk (θ)
Z (θ) ,
k Zk (θ), then the joint probability p(y , k ; θ) becomes equivalent to a LR model in
exp{(cid:80)
d yd = k , and p(k ; θ)
(cid:89)
is Poisson-Binomial, then
d∈c θd }
exp{θd yd}
p(y , k ; θ) = p(k ; θ)p(y | k ; θ) =
Zk (θ)
1 + exp{θd} .
Z (θ)
Zk (θ)
d
Note that the last equality factorizes Z (θ) to create independence across variables, but it requires
that the “prior” be deﬁned in terms of parameters θ . Our interest in this paper is in the more ﬂexible
family of models that arise after breaking the dependence of the “prior” on θ . First, we explore
treating p(k) as a prior in the Bayesian sense, using it to express prior knowledge about label counts;
later we will explore learning p(k) using separate parameters from θ . A consequence of these
decisions is that the distribution does not factorize. At this point, we have not made it clear that
these models can be learned efﬁciently, but we will show in the next section that this is indeed the
case.

(2)

=

,

(1)

2.1 Maximum Likelihood Learning
Our goal in learning is to select parameters so as to maximize the probability assigned to observed
data by the model. For notational simplicity in this section, we compute partial derivatives with

2

(3)

yd ; θ) + κ

respect to θ , then it should be clear that these can be back-propagated to a model of θ(x; W). We
note that if this relationship is linear, and the objective is convex in terms of θ , then it will also be
D(cid:88)
p(k)p(y | k ; θ) = log p(y | (cid:88)
convex in terms of W. The log-likelihood is as follows:
(cid:88)
log p(y ; θ) = log
θd yd − log Z(cid:80)
k=0
d
=
d yd (θ) + κ,
n=1 , we maximize the sum of log probabilities (cid:80)
d
where κ is a constant that is independent of θ . As is standard, if we are given multiple sets of
binary variables, {yn}N
derivatives take a standard log-sum-exp form, requiring expectations Ep(yd |k=(cid:80)
n log p(yn ; θ). The partial
A naive computation of this expectation would require summing over (cid:0) D
(cid:1) conﬁgurations.
d(cid:48) yd(cid:48) ) [yd ].
k=(cid:80)
d yd
However, there are more efﬁcient alternatives: the dynamic programming algorithms developed
in the context of Poisson-Binomial distributions are applicable, e.g., the algorithm from [3] runs
in O(Dk) time. The basic idea is to compute partial sums along a chain that lays out vari-
ables yd in sequence. An alternative formulation of the dynamic program [4] can be made to
yield an O(D log2 D) algorithm by using a divide-and-conquer algorithm that employs Fast Fourier
Transforms (FFTs). These algorithms are quite general and can also be used to compute Zk values,
incorporate prior distributions over count values, and draw a sample of y values conditional upon
some k for the same computational cost [5]. We use the FFT tree algorithm from [5] throughout,
because it is most ﬂexible and has best worst-case complexity.

(4)

2.2 Test-time Inference
Having learned a model, we would like to make test-time predictions. In Section 4.2, we will show
that optimal decision-theoretic predictions (i.e., that maximize expected gain) can be made in several
settings by a simple sorting procedure, and this will be our primary way of using the learned model.
However, here, we consider the task of producing a distribution over labels y , given θ(x). To draw
a joint sample of y values, we can begin by drawing k from p(k), then conditional on that k , use the
dynamic programming algorithm to draw a sample conditional on k .
To compute marginals, a simple strategy is to loop over each value of k and run dynamic program-
ming conditioned on k , and then average the results weighted by the respective prior. For priors that
only give support to a small number of k values, this is quite efﬁcient. An alternative approach is
to draw several samples of k from p(k), then for each sampled value, run dynamic programming to
compute marginals. Averaging these marginals can then be seen as a Rao-Blackwellized estimate.
Finally, it is possible to compute exact marginals for arbitrary p(k) in a single run of an O(D log2 D)
dynamic programming algorithm, but the simpler strategies were sufﬁcient for our needs here, so
we do not pursue that direction further.

3 Ordinal n-Choose-k Model
An extension of the binary n-choose-k model can be developed in the case of ordinal data, where we
assume that labels y can take on one of R categorical labels, and where there is an inherent ordering
to labels R > R − 1 > . . . > 1; each label represents a relevance label in a learning-to-rank setting.
Let kr represent the number of variables y that take on label r and deﬁne k = (kR , . . . , k1 ). The idea
in the ordinal case is to deﬁne a joint model over count variables k, then to reduce the conditional
distribution of p(y | k) to be a series of binary models. The generative model is deﬁned as follows:
• Initialize all variables y to be unlabeled.
• Sample kR , . . . , k1 jointly from p(k).
• Repeat for r = R to 1:
(cid:40) exp{(cid:80)
– Choose a set cr of kr unlabeled variables y≤r and assign them relevance label r .
Choose subsets with probability equal to the following:
θd }
d∈cr
p(y≤r,cr = 1, y≤r,¯cr = 0 | kr ) =
Zr,k (θ ,y≤r )
0

if |cr | = kr
otherwise

(5)

,

3

log

p(k)p(y | k; θ) =

where we use the notation y≤r to represent all variables that are given a relevance
Zr,kr (θ , y≤r ) = (cid:80)
label less than or equal to r . Zr,k is similar to the normalization constant Zk that
y≤r |((cid:80)
appears in the binary model, but it is restricted to sum over y≤r instead of the full y :
exp {θd · 1 {yd = r}}.
d 1{yd=r})=kr
Note that if R = D and p(k) speciﬁes that kr = 1 for all r , then this process deﬁnes a Plackett-Luce
(PL) [6, 7, 8] ranking model. One interpretation of this model is as a “group” PL model, where
instead of drawing individual elements in the generative process, groups of elements are drawn si-
multaneously. In this work, we focus on ranking with weak labels (R < D) which is more restrictive
than modeling distributions over permutations [9], where learning would require marginalizing over
all possible permutations consistent with the given labels. In this setting, inference in the ordinal
n-choose-k model is both exact and efﬁcient.
Let kr = (cid:80)
3.1 Maximum Likelihood Learning
 (cid:88)
 + κ.
d 1 {yd = r}. The log likelihood of parameters θ can be written as follows:
(cid:88)
R(cid:88)
θd − log Zr,kr (θ , y≤r )
k∈K
r=1
d:yd=r
Here, we see that learning decomposes into the sum of R objectives that are of the same form as
arise in the binary n-choose-k model. As before, the only non-trivial part of the gradient compu-
tation comes from the log-sum-exp term, but the required expectations that arise can be efﬁciently
computed using dynamic programming. In this case, R − 1 calls are required.
3.2 Test-time Inference
The test-time inference procedure in the ordinal model is similar to the binary case. Brute force enu-
meration over k becomes exponentially more expensive as R grows, but for some priors where p(k)
has sparse support, this may be feasible. To draw samples of y , the main requirement is the abil-
distribution over k takes the form p(k) = 1 {(cid:80)
r kr = D} · (cid:81)
ity to draw a joint sample of k from p(k). In the case that p(k) is a simple distribution such as
a multinomial, this can be done easily. It is also possible to efﬁciently draw a joint sample if the
r p(kr ). That is, there is an arbitrary
but independent prior over each kr value, along with a single constraint that the chosen kr values
sum to exactly D . Given a sample of k, it is straightforward to sample y using R calls to dynamic
programming. To do so, begin by using the binary algorithm to sample kR variables to take on
value R. Then remove the chosen variables from the set of possible variables, and sample kR−1
variables to take on value R − 1. Repeat until all variables have been assigned a value.
An alternative to producing marginal probabilities at test time is trying to optimize performance un-
der a task-speciﬁc evaluation measure. The main motivation for the ordinal model is the learning to
rank problem [10], so our main interest is in methods that do well under such task-speciﬁc evalua-
tion measures that arise in the ranking task. In Section 4.2, we show that we can make exact optimal
decision theoretic test-time predictions under the learning-to-rank gain functions without the need
for sampling.

(6)

4
Incorporating Gain
4.1 Training to Maximize Expected Top-K Classiﬁcation Gain
One of the motivating applications for this model is the top-K classiﬁcation (TKC) task. We formu-
late this task using a gain function, parameterized by a value K and a “scoring vector” t, which is
assumed to be of the same dimension as y . The gain function stipulates that K elements of y are
(cid:26) (cid:80)
chosen, (assigning a score of zero if some other number is chosen), and assigns reward for choosing
if (cid:80)
each element of y based on t. Speciﬁcally the gain function is deﬁned as follows:
d yd = K
d yd td
otherwise .
0
The same gain can be used for Precision@K, in which case the number of nonzero values in t is
unrestricted. Here, we focus on the case where t is binary with a single nonzero entry at index d∗ .

GK (y , t) =

(7)

4

An interesting issue is what gain function should be used to train a model when the test-time evalu-
ation metric is TKC, or Precision@K. Maximum likelihood training of TKC in this case of a single
target class could correspond to a version of our n-choose-k model in which p(k) is a spike at k = 1;
note that in this case the n-choose-k model is equivalent to a softmax over the output classes. An
alternative is to train using the same gain function used at test-time.
Here, we consider incorporating the TKC gain at training time for binary t with one nonzero entry,
(cid:40)(cid:88)
(cid:41) (cid:88)
(cid:88)
(cid:88)
(cid:88)
training the model to maximize expected gain. Speciﬁcally, the objective is the following:
y
y
d
k
d

p(K )p(y | K )yd∗

Ep [GK (y , t)] =

p(k)p(y | k)1

yd = K

yd td =

(8)

It becomes clear that this objective is equivalent to the marginal probability of yd∗ under a prior
distribution that places all its mass on k = K . In Section 5.3, we empirically investigate training
under expected gain versus training under maximum likelihood

4.2 Optimal Decision-theoretic Predictions for Monotonic Gain Functions
We now turn attention to gain functions deﬁned on rankings of items. Letting π be a permutation,
we deﬁne a “monotonic” gain function as follows:
• It can be expressed as (cid:80)D
Deﬁnition 1. A gain function G(π , r) is a monotonic ranking gain if:
d=1 αd f (rπd ), where αd is a weighting (or discount) term, and
πd is the index of the item ranked in position d,
• αd ≥ αd+1 ≥ 0 for all d, and
• f (r) ≥ f (r − 1) ≥ 0 for all r ≥ r (cid:48) .
N DCG(π , r) ∝ (cid:80)
It
learning-to-rank scoring functions like normal-
is straightforward to see that popular
ized discounted cumulative gain (NDCG) and Precision@K are monotonic ranking gains.
log2 (1+d) , so set αd = κ ·
log2 (1+d) and f (r) = 2r − 1. We deﬁne Preci-
2rπd −1
P @K (π , r) = (cid:80)
1
d
sion@K gain to be the fraction of documents in the top K produced ranks that have label R:
d 1 {d ≤ K } 1 {rπd = R}, so set αd = 1 {d ≤ K } and f (r) = 1 {r = R}.
D(cid:88)
(cid:88)
R(cid:88)
D(cid:88)
D(cid:88)
The expected gain under a monotonic ranking gain and ordinal n-choose-k model is
αd f (y (cid:48)
p(y (cid:48) )
Ep [G(π)] =
πd
where we have deﬁned gd = (cid:80)R
y (cid:48)∈Y
y (cid:48)
=1
d=1
d=1
d=1
πd
r=1 f (r)p(yd = r).
We now state four propositions and a lemma. The proofs of the propositions mostly result from
algebraic manipulation, so we leave their proof to the supplementary materials. The main theorem
will be proved afterwards.
Proposition 1. If θi ≥ θj , then p(yi = R) ≥ p(yj = R).
Proposition 2. If θi ≥ θj and p(yi ≥ r) ≥ p(yj ≥ r), then p(yi ≥ r − 1) ≥ p(yj ≥ r − 1).
Lemma 1. If θi ≥ θj , then for all r , p(yi ≥ r) ≥ p(yj ≥ r).

)p(yπd = y (cid:48)
πd

f (y (cid:48)
πd

αd gπd ,

) =

) =

αd

(9)

Proof. By induction. Proposition 1 is the base case, and Proposition 2 is the inductive step.
Proposition 3. If θi ≥ θj and f is deﬁned as in Deﬁnition 1, then gi ≥ gj .
Proposition 4. Consider two pairs of non-negative real numbers ai , aj and bi , bj where ai ≥ aj
and bi ≥ bj . It follows that ai bi + aj bj ≥ ai bj + aj bi .
Theorem 1. Under an ordinal n-choose-k model, the optimal decision theoretic predictions for a
monotonic ranking gain are made by sorting θ values.

5

Figure 1: Four example images from the embedded MNIST dataset test set, along with the Poisson-
Binomial distribution produced by logistic regression for each image. The area marked in red has
zero probability under the data distribution, but the logistic regression model is not ﬂexible enough
to model it.

Proof. Without loss of generality, assume that we are given a vector α corresponding to placing the
α’s in descending order and a vector gπ where π is some arbitrary ordering of the g ’s. The goal now
is to ﬁnd the ordering π∗ that maximizes the objective given in (9) which is equivalently expressed
as the inner product αT gπ .
Assume that we are given an ordering ˆπ where for at least one pair i, j where i > j , we have
that θ ˆπi < θ ˆπj . Furthermore, assume that this ordering is optimal. That is, ˆπ = π∗ . By Proposi-
tion 3 we have that g ˆπi < g ˆπj . The contributions of these elements to the overall objective is given
by αi g ˆπi + αj g ˆπj . By Proposition 4 we improve the objective by swapping θ ˆπi and θ ˆπj contradict-
ing the assumption that ˆπ is a local optimum.
If we have multiple elements that are not in sorted order, then we can repeat this argument by
considering pairs of elements until the whole vector is sorted.

5 Experiments
5.1 Modeling Varying Numbers of Objects
Our ﬁrst experiment explores an issue that arises frequently in computer vision, where there are
an unknown number of objects in an image, but the number is highly structured. We developed a
multiple image dataset that simulates this scenario.1 To generate an image, we uniformly sampled
a count between 1 and 4, and then take that number of digit instances (with at most one instance
per digit class) from the MNIST dataset and embed them in a 60 × 60 image. The x, y locations
are chosen from a 4 × 4 uniformly spaced grid and and then a small amount of jitter is added. We
generated 10,000 images each for the training, test, and validation sets. The goal is to predict the set
of digits that appear in a given image. Examples can be seen in Figure 1.
We train a binary n-choose-k model on this dataset. The inputs to the model are features learned
from the images by a standard Restricted Boltzmann Machine with 1000 hidden units. As a base-
line, we trained a logistic regression classiﬁer on the features and achieved a test-set negative log-
likelihood (NLL) of 2.84. Ideally, this model should learn that there are never more than four digits
in any image. In Figure 1, we show four test images, and the Poisson-Binomial distribution over
counts that arises from the logistic regression model. Marked in red are regions where there is zero
probability of the count value in the data distribution. Here it is clear that the implicit count prior
in LR is not powerful enough to model this data. As a comparison, we trained a binary n-choose-
k model where we explicitly parameterize and learn an input-dependent prior. The model learns the
correct distribution over counts and achieves a test-set NLL of 1.95. We show a visualization of the
learned likelihood and prior parameters in the supplementary material.

5.2 Ranking
A second set of experiments considers learning-to-rank applications of the n-choose-k model. We
report on comparisons to other ranking approaches, using seven datasets associated with the LETOR
3.0 benchmark [10]. Following the standard LETOR procedures, we trained over ﬁve folds, each
with distinct training, validation, and testing splits.
For each dataset, we train an ordinal n-choose-k model to maximize the likelihood of the data, where
each training example consists of a number of items, each assigned a particular relevance level; the
number of levels ranges from 2-4 across the datasets. At test time, we produce a ranking, which as

1http://www.cs.toronto.edu/˜kswersky/data/

6

(b) NP 2004
(a) TD 2003
Figure 2: Ranking results on two datasets from LETOR 3.0. Results for the other 5 datasets, along
with Precision@K results, appear in the supplementary material.

shown in Section 4.2 is the optimal decision theoretic prediction under a ranking gain function, by
simply sorting the items for each test query based on their θ score values. Note that this is a very
simple ranking model, in that the score assigned to each test item by the model is a linear function
of the input features, and the only hyperparameter to tune is an (cid:96)2 regularization strength.
Results for two of the data sets are shown in Figure 2 (ﬁrst is our best relative performance, second is
typical); the full set of results are in the supplementary material. Several publicly available baselines
are shown for comparison. As can be seen in the graphs, our approach is competitive with the state-
of-the-art on all data sets, and substantially outperforms all baselines on the TD 2003 dataset. Note
that the performance of the baseline methods is quite variable and it appears that overﬁtting is an is-
sue on these datasets, even for linear models. We hypothesize that proper probabilistic incorporation
of weak labels helps to mitigate this effect to some degree.

5.3 Top-K Classiﬁcation
Our third and ﬁnal set of experiments concern top-K classiﬁcation, an important task that has gained
considerable attention recently in the ImageNet Challenge.2 Here we consider a task analogous to
that in the ImageNet Challenge, in which each image contains a single object label, but a model
is allowed to return up to K class predictions per image. A classiﬁcation is deemed correct if the
appropriate class is one of the K returned classes.
We train binary n-choose-k models, experimenting with different training protocols that directly
maximize expected gain under the model, as described in Section 4.1. That is, we train on the ex-
pected top-K gain for different values of K . Note that top-1 is equivalent to softmax regression. For
each model/evaluation criterion combination, we ﬁnd the (cid:96)2 penalty that gives the highest validation
accuracy; the corresponding test-set results are shown in Table 1. For comparison, we also include
logistic regression, where each output is conditionally independent. We experimented on the em-
bedded MNIST dataset where all but one label from each example was randomly removed, and on
the Caltech-101 Silhouettes dataset [11], which consists of images of binarized silhouettes from 101
different categories. In both datasets we trained the models using the pixels as inputs. We noticed
that the optimal (cid:96)2 strength chosen by each method was quite high, suggesting that overﬁtting is an
issue in these datasets. When the (cid:96)2 strength is low, the difference between the objectives becomes
more apparent. On Caltech it is clear that training for the expected gain improves the corresponding
test accuracy in this regime. On the embedded MNIST dataset, when the (cid:96)2 strength is low there is
a surprising result that the top-3 and top-5 criteria outperform top-1, even when top-1 is used as the
evaluation measure. Since there are several digits actually present in the ground truth, there is no
real signal in the data that differentiates the digit labeled as the target from the other equally valid
“distractor” digits. In order to satisfy the top-1 objective for the given target, the learning algorithm
is forced to ﬁnd some arbitrary criterion by which to cause the given target to be preferred over the
distractors, which is harmful for generalization purposes. This scenario does occur in datasets like
ImageNet, where multiple objects can be present in a single image. It would be interesting to repeat
these experiments on more challenging, large scale datasets, but we leave this for future work.
2http://www.image-net.org/challenges/LSVRC/2011/

7

Ordinal nCkAdaRank!NDCGFRankListNetRankBoostRankSVMRegression!RegSmoothRank123456789100.20.250.30.350.4NDCG Truncation Level (K)NDCG@K123456789100.40.50.60.70.80.9NDCG Truncation Level (K)NDCG@KTop 1 / Top 3 / Top 5
0.606 / 0.785 / 0.812
LR
0.621 / 0.796 / 0.831
Top 1
0.614 / 0.792 / 0.834
Top 3
Top 5
0.602 / 0.787 / 0.834
(a) Caltech Sil. strong (cid:96)2

Top 1 / Top 3 / Top 5
0.545 / 0.716 / 0.766
0.574 / 0.755 / 0.804
0.558 / 0.771 / 0.813
0.523 / 0.767 / 0.823
(b) Caltech Sil. weak (cid:96)2

Top 1 / Top 3 / Top 5
0.346 / 0.647 / 0.815
0.353 / 0.659 / 0.820
0.353 / 0.671 / 0.834
0.330 / 0.659 / 0.824
(c) EMNIST strong (cid:96)2

Top 1 / Top 3 / Top 5
0.263 / 0.557 / 0.742
0.268 / 0.569 / 0.757
0.318 / 0.637 / 0.815
0.313 / 0.642 / 0.822
(d) EMNIST weak (cid:96)2

Table 1: Top-K classiﬁcation results when various models are trained using an expected top-K gain
and then tested using some possibly different top-K criterion. The rows correspond to training
criteria, and the columns correspond to test criteria.
(a) and (c) show the test accuracy when a
strong (cid:96)2 regularizer is used, while (b) and (d) use a relatively weaker regularizer. Logistic regression
is included for comparison.

6 Related Work

Our work here is related to many different areas; we cannot hope to survey all related work in multi-
label classiﬁcation and ranking. Instead, we focus on work related to the main novelty in this paper,
the explicit modeling of structure on label counts. That is, given that we have prior knowledge of
label count structure, or are modeling a domain that exhibits such structure, the question is how can
the structure be leveraged to improve a model.
The ﬁrst and most direct approach is the one that we take here: explicitly model the count structure
within the model. There are other alternative approaches that are similar in this respect. The work
of [12] considers MAP inference in the context of cardinality-based models and develops applica-
tions to named entity recognition tasks. Similarly, [13] develops an example application where a
cardinality-based term constrains the number of pixels that take on the label “foreground” in a fore-
ground/background image segmentation task. [14] develops models that include a penalty in the
energy function for using more labels, which can be seen as a restricted form of structure over label
cardinalities.
An alternative way of incorporating structure over counts into a model is via the gain function. The
work of Joachims [15] can be seen in this light – the training objective is formulated so as to optimize
performance on evaluation measures that include Precision@K. A different approach to including
count information in the gain function comes from [16], which trains an image segmentation model
so as match count statistics present in the ground truth data. Finally, there are other approaches that
do not neatly fall into either category, such as the posterior regularization framework of [17] and
related works such as [18]. There, structure, including structure that encodes prior knowledge about
counts, such as there being at least one verb in most sentences, is added as a regularization term that
is used both during learning and during inference.
Overall, the main difference between our work and these others is that we work in a proper proba-
bilistic framework, either maximizing likelihood, maximizing expected gain, and/or making proper
decision-theoretic predictions at test time. Importantly, there is no signiﬁcant penalty for assuming
the proper probabilistic approach: learning is exact, and test-time prediction is efﬁcient.

7 Discussion

We have presented a ﬂexible probabilistic model for multiple output variables that explicitly models
structure in the number of variables taking on speciﬁc values. The model is simple, efﬁcient, easy to
learn due to its convex objective, and widely applicable. Our theoretical contribution provides a link
between this type of ordinal model and ranking problems, bridging the gap between the two tasks,
and allowing the same model to be effective for several quite different problems. Finally, there are
many extensions. More powerful models of θ can be put into the formulation, and gradients can
easily be back-propagated. Also, while we chose to take a maximum likelihood approach in this
paper, the model is well suited to fully Bayesian inference using e.g., slice sampling. The unimodal
posterior distribution should lead to good behavior of the sampler. Beyond these extensions, we
believe the framework here to be a valuable modeling building block that has broad application to
problems in machine learning.

8

References
[1] S. X. Chen and J. S. Liu. Statistical applications of the Poisson-Binomial and conditional
Bernoulli distributions. Statistica Sinica, 7(4), 1997.
[2] X. H. Chen, A. P. Dempster, and J. S. Liu. Weighted ﬁnite population sampling to maximize
entropy. Biometrika, 81(3):457–469, 1994.
[3] M. H. Gail, J. H. Lubin, and L. V. Rubinstein. Likelihood calculations for matched case-control
studies and survival studies with tied death times. Biometrika, 68:703–707, 1981.
[4] L. Belfore. An O(n) log2(n) algorithm for computing the reliability of k-out-of-n:G and k-to-
l-out-of-n:G systems. IEEE Transactions on Reliability, 44(1), 1995.
[5] D. Tarlow, K. Swersky, R. Zemel, R.P. Adams, and B. Frey. Fast exact inference for recursive
cardinality models. In Uncertainty in Artiﬁcial Intelligence, 2012.
[6] R. Plackett. The analysis of permutations. Applied Statistics, pages 193–202, 1975.
[7] R.D. Luce. Individual Choice Behavior a Theoretical Analysis. Wiley, 1959.
[8] J. Guiver and E. Snelson. Bayesian inference for plackett-luce ranking models. In International
Conference on Machine Learning, 2009.
[9] J. Huang, C. Guestrin, and L. Guibas. Efﬁcient inference for distributions on permutations. In
Advances in Neural Information Processing Systems, 2007.
[10] T. Qin, T.Y. Liu, J. Xu, and H. Li. LETOR: A benchmark collection for research on learning
to rank for information retrieval. Information Retrieval Journal, 2010.
[11] B. Marlin, K. Swersky, B. Chen, and N. de Freitas. Inductive principles for restricted Boltz-
mann machine learning. In Artiﬁcial Intelligence and Statistics, 2010.
[12] R. Gupta, A. Diwan, and S. Sarawagi. Efﬁcient inference with cardinality-based clique poten-
tials. In International Conference on Machine Learning, 2007.
[13] D. Tarlow, I. Givoni, and R. Zemel. HOP-MAP: Efﬁcient message passing for high order
potentials. In Artiﬁcial Intelligence and Statistics, 2010.
[14] A. Delong, A. Osokin, H.N. Isack, and Y. Boykov. Fast approximate energy minimization with
label costs. International Journal of Computer Vision, 96(1):127, 2012.
[15] T. Joachims. A support vector method for multivariate performance measures. In International
Conference on Machine Learning, 2005.
[16] P. Pletscher and P. Kohli. Learning low-order models for enforcing high-order statistics. In
Artiﬁcial Intelligence and Statistics, 2012.
[17] K. Ganchev, J. Grac¸ a, J. Gillenwater, and B. Taskar. Posterior regularization for structured
latent variable models. Journal of Machine Learning Research, 11:2001–2049, 2010.
[18] G. Mann and A McCallum. Generalized expectation criteria with application to semi-
supervised classiﬁcation and sequence modeling. Journal of Machine Learning Research,
11:955–984, 2010.

9

