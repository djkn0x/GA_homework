Visual Recognition using Embedded Feature
Selection for Curvature Self-Similarity

Angela Eigenstetter
HCI & IWR, University of Heidelberg
aeigenst@iwr.uni-heidelberg.de

Bj ¨orn Ommer
HCI & IWR, University of Heidelberg
ommer@uni-heidelberg.de

Abstract

Category-level object detection has a crucial need for informative object represen-
tations. This demand has led to feature descriptors of ever increasing dimension-
ality like co-occurrence statistics and self-similarity. In this paper we propose a
new object representation based on curvature self-similarity that goes beyond the
currently popular approximation of objects using straight lines. However, like all
descriptors using second order statistics, ours also exhibits a high dimensionality.
Although improving discriminability, the high dimensionality becomes a critical
issue due to lack of generalization ability and curse of dimensionality. Given
only a limited amount of training data, even sophisticated learning algorithms
such as the popular kernel methods are not able to suppress noisy or superﬂu-
ous dimensions of such high-dimensional data. Consequently, there is a natural
need for feature selection when using present-day informative features and, par-
ticularly, curvature self-similarity. We therefore suggest an embedded feature se-
lection method for SVMs that reduces complexity and improves generalization
capability of object models. By successfully integrating the proposed curvature
self-similarity representation together with the embedded feature selection in a
widely used state-of-the-art object detection framework we show the general per-
tinence of the approach.

1

Introduction

One of the key challenges of computer vision is the robust representation of complex objects and
so over the years, increasingly rich features have been proposed. Starting with brightness values
of image pixels and simple edge histograms [10] descriptors evolved and more sophisticated fea-
tures like shape context [1] and wavelets [23] were suggested. The probably most widely used and
best performing image descriptors today are SIFT [18] and HOG [4] which model objects based
on edge orientation histograms. Recently, there has been a trend to utilize more complicated image
statistics like co-occurrence and self-similarity [25, 5, 15, 29, 31] to build more robust descriptors.
This development shows, that the dimensionality of descriptors is getting larger and larger. Fur-
thermore it is noticeable that all descriptors that model the object boundary rely on image statistics
that are primarily based on edge orientation. Thus, they approximate objects with straight lines.
However, it was shown in different studies within the perception community that besides orienta-
tion also curvature is an important cue when performing visual search tasks. In our earlier work
[21] we extended the modeling of object boundary contours beyond the widely used edge orien-
tation histograms by utilizing curvature information to overcome the drawbacks of straight line
approximations. However, curvature can provide even more information about the object bound-
ary. By computing co-occurrences between discriminatively curved boundaries we build a curvature
self-similarity descriptor that provides a more detailed and accurate object description.While it was
shown that self-similarity and co-occurrence lead to very robust and highly discriminative object
representations, these second order image statistics are also pushing feature spaces to extremely

1

high dimensions. Since the amount of training data stays more or less the same, the dimensionality
of the object representation has to be reduced to prevent systems to suffer from curse of dimension-
ality and overﬁtting. Nevertheless, well designed features still increase performance. Deselaers et
al. [5], for instance, suggested an approach that results in a 160000 dimensional descriptor which
was evaluated on the ETHZ shape dataset which contains on average 30 positive object instances
per category. To exploit the full capabilities of high-dimensional representations applied in object
detection we developed a new embedded feature selection method for SVM which reliable discards
superﬂuous dimensions and therefore improves object detection performance.
The paper is organized as follows: First we will give a short overview on embedded feature selection
methods for SVMs (Section 2.1) and describe a novel method to capture the important dimensions
from high-dimensional representations (Section 2.2). After that we describe our new self-similarity
descriptor based on curvature to go beyond the straight line approximation of objects to a more
accurate description (Section 3). Moreover, Section 3 discusses previous work on self-similarity. In
the experimental section at the end of the paper we evaluate the suggested curvature self-similarity
descriptor along with our feature selection method.

2 Feature Selection for Support Vector Machines

2.1 Embedded Feature Selection Approaches

Guyon et al. [12] categorize feature selection methods into ﬁlters, wrappers and embedded methods.
Contrary to ﬁlters and wrappers embedded feature selection methods incorporate feature selection
as a part of the learning process (for a review see [17]). The focus of this paper is on embedded
feature selection methods for SVMs, since most state-of-the-art detection systems use SVM as a
classiﬁer. To directly integrate feature selection into the learning process of SVMs sparsity can be
enforced on the model parameter w. Several researchers e.g [2] have considered replacing the L2
2 with an L1 regularization term (cid:107)w(cid:107)1 . Since L1 norm penalty for SVM has
regularization term (cid:107)w(cid:107)2
some serious limitations, Wang et al. [30] suggested the doubly regularized SVM (DrSVM) which
is not replacing the L2 regularization but adding an additional L1 regularization to automatically
select dimensions during the learning process.
Contrary to linear SVM enforcing sparsity on the model parameter w does reduce dimensionality
for non-linear kernel functions in the higher dimensional kernel space rather than in the number
of input features. To reduce the dimensionality for non-linear SVMs in the feature space one can
introduce an additional selection vector θ ∈ [0, 1]n , where larger values of θi indicate more useful
features. The objective is then to ﬁnd the best kernel of the form Kθ (x, z) = K (θ ∗ x, θ ∗ z), where
x, z ∈ Rn are the feature vectors and ∗ is element-wise multiplication. These hyper-parameters
θ can be obtained via gradient descent on a generalization bound or a validation error. Another
possibility is to consider the scaling factors θ as parameters of the learning algorithm [11], where
the problem was solved using a reduced conjugate gradient technique.
In this paper we integrate the scaling factors into the learning algorithm, but instead of using L2
norm constraint like in [11] on the scaling parameter θ we apply an L1 norm sparsity which is
explicitly discarding dimensions of the input feature vector. For the linear case our optimization
problem becomes similar to DrSVM [30] where a gradient descent method is applied to ﬁnd the
optimal solution w∗ . To ﬁnd a starting point a computational costly initialization is applied, while
our selection step can start at the canonical θ = 1, because w is modeled in a separate variable.

2.2

Iterative Dimensionality Reduction for SVM

A SVM classiﬁer is learning a hyperplane deﬁned by w and b which best separates the training data
{(xi , yi )}1≤i≤N with labels yi ∈ {−1, +1}. We are following the concept of embedded feature
selection and therefore include the feature selection parameter θ directly in the SVM classiﬁer. The
N(cid:88)
corresponding optimization problem can be expressed in the following way:
(cid:107)w(cid:107)2
2 + C
ξi
i=1
yi (wT ψ(θ ∗ xi ) + b) ≥ 1 − ξi ∧ ξi ≥ 0 ∧ (cid:107)θ(cid:107)1 ≤ θ0

subject to :

(1)

min
θ

min
w,b,ξ

1
2

2

Algorithm 1: Iterative Dimensionality Reduc-
tion for SVM

1: converged := FALSE, θ := 1
2: while converged==FALSE do
l , α , b] = trainSVM( X (cid:48) , Y (cid:48) , θ , C)
[x(cid:48)
3:
θ* = applyBundleMethod(X (cid:48)(cid:48) ,Y (cid:48)(cid:48) ,x(cid:48)
l ,α,b,C)
4:
if θ* == θ then
5:
converged=TRUE;
6:
end if
7:
θ = θ*
8:
9: end while

Figure 1: Visualization of curvature compu-
tation. Dik is on the left-hand side of the
vector (pi+l − pi ) and therefore has a posi-
tive sign, while D (cid:48)
ik is on the right-hand side
i+l − p(cid:48)
of the vector (p(cid:48)
i ) and therefore gets a
negative sign

λ(cid:107)θ(cid:107)1 +

(cid:107)w(cid:107)2
2 + C

max(0, 1 − yi fθ (xi ))

where K (x, z) := ψ(x) · ψ(z) is the SVM kernel function. The function ψ(x) is typically unknown
and represents the mapping of the feature vector x into a higher dimensional space. We enforce
sparsity of the feature selection parameter θ by the last constraint of Eq. 1, which restricts the
L1-norm of θ by a constant θ0 . Since SVM uses L2 normalization it does not explicitly enforce
single dimensions to be exactly zero. However, this is necessary to explicitly discard unnecessary
N(cid:88)
dimensions. We rewrite the problem in Eq. 1 without additional constraints in the following way:
1
min
min
2
w,b
θ
i=1
where the decision function fθ is given by fθ (x) = wT ψ(θ ∗ x) + b. Note, that the last constraint,
where the L1-norm is restricted by a constant θ0 is rewritten as an L1-regularization term, multiplied
with the sparsity parameter λ.
Due to the complexity of problem 2 we propose to solve two simpler problems iteratively. We
ﬁrst split the training data into three sets, training {(x(cid:48)
i )}1≤i≤N (cid:48) , validation {(x(cid:48)(cid:48)
i )}1≤i≤N (cid:48)(cid:48)
i , y (cid:48)
i , y (cid:48)(cid:48)
and a hold out testset. Now we optimize the problem according to w and b for a ﬁxed selection
parameter θ using a standard SVM algorithm on the training set. Parameter θ is optimized in a
second optimization step on the validation data using an extended version of the bundle method
suggested in [6]. We are performing the second step of our algorithm on a separate validation set
to prevent overﬁtting. In the ﬁrst step of our algorithm, the parameter θ is ﬁxed and the remaining
N (cid:48)(cid:88)
N (cid:48)(cid:88)
problem is converted into the dual problem
j K (θ ∗ x(cid:48)
i , θ ∗ x(cid:48)
αi− 1
i y (cid:48)
αiαj y (cid:48)
j )
max
N (cid:48)(cid:88)
2
α
i,j=1
i=1
subject to : 0 ≤ αi ≤ C,
αi y (cid:48)
where the decision function fθ is given by fθ (x) = (cid:80)m
i = 0
i=1
l=1 αl ylK (θ ∗ x, θ ∗ x(cid:48)
l ) + b, where m
is the number of support vectors. Eq. 3 is solved using a standard SVM algorithm [3, 19]. The
optimization of the selection parameter θ starts at the canonical solution where all dimensions are
set to one. This is corresponding to the solution that is usually taken as a ﬁnal model in other
approaches. In our approach we apply a second optimization step to explicitly eliminate dimensions
which are not necessary to classify data from the validation set. Fixing the values of the Lagrange
multipliers α, the support vectors x(cid:48)
N(cid:88)
l and the offset b obtained by solving Eq. 3, leads to
i=1
which is an instance of the regularized risk minimization problem min
λΩ(θ) + R(θ) , where Ω(θ)
θ
is a regularization term and R(θ) is an upper bound on the empirical risk. To solve such non-
differentiable risk minimization problems bundle methods have recently gained increasing interest
in the machine learning community. For the case that the risk function R is non-negative and convex

max(0, 1 − yi fθ (x(cid:48)(cid:48)
i )).

min
θ

λ(cid:107)θ(cid:107)1 +

(cid:107)w(cid:107)2
2 + C

1
2

(2)

(3)

(4)

3

pppii+lkp'ip'kp'i+lDikD'ikit is always lower bounded by its cutting plane at a certain point θ i :
R(θ) ≥ < ai , θ > +bi for all i
(5)
where ai := ∂θR(θ i ) and bi := R(θ i )− < ai , θ i >. Bundle methods build an iteratively increasing
piecewise lower bound of the objective function by utilizing its cutting planes. Starting with an
initial solution it solves the problem where R is approximated by one initial cutting plane using
standard solver. A second cutting plane is build at the solution of the approximated problem. The
new approximated lower bound of R is now the maximum over all cutting planes. The more cutting
planes are added the more accurate gets the lower bound of the risk function.
For the general case of non-linear kernel functions the problem in Eq. 4 is a non-convex and there-
fore especially hard to optimize. In the special case of a linear kernel the problem is convex and
the applied bundle method converges towards the global optimum. Some efforts have been made
to adjust bundle methods to handle non-convex problems [16, 6]. We adapted the method of [6] to
apply L1 regularization instead of L2 regularization and employ it to solve the optimization problem
in Eq. 4. Although the convergence rate of O(1/e) to a solution of accuracy e [6] does no longer
apply for our L1 regularized version, we observed that the algorithm converges withing the order of
10 iterations which is in the same range as for the algorithm in [6]. An overview of the suggested
iterative dimensionality reduction algorithm is given in Algorithm 1.

3 Representing Curvature Self-Similarity

Although several methods have been suggested for the robust estimation of curvature, it has been
mainly represented indirectly in a contour based manner [1, 32] and to locate interest points at
boundary points with high curvature value. To design a more exact object representation that rep-
resents object curvedness in a natural way we revisit the idea of [21] and design a novel curvature
self-similarity descriptor. The idea of self-similarity was ﬁrst suggested by Shechtman et al. [25]
who proposed a descriptor based on local self-similarity (LSS). Instead of measuring image fea-
tures directly it measures the correlation of an image patch with a larger surrounding image region.
The general idea of self-similarity was used in several methods and applications [5, 15, 29, 31]. In
[15] self-similarity is used to improve the Local Binary Pattern (LBP) descriptor for face identiﬁca-
tion. Deselaers et al. [5] explored global self-similarity (GSS) and showed its advantages over local
self-similarity (LSS) for object detection. Furthermore, Walk et al. [29] showed that using color
histograms directly is decreasing performance while using color self-similarity (CSS) as a feature
is more appropriate. Besides object classiﬁcation and detection, self-similarity was also used for
action recognition [15] and turned out to be very robust to viewpoint variations.
We propose a new holistic self-similarity representation based on curvature. To make use of the
aforementioned advantages of global self-similarity we compute all pairwise curvature similarities
across the whole image. This results in a very high dimensional object representation. As mentioned
before such high dimensional representations have a natural need for dimensionality reduction which
we fulﬁll by applying our embedded feature selection algorithm outlined in the previous section.
To describe complex objects it is not sufﬁcient to build a self-similarity descriptor solely based on
curvature information, since self-similarity of curvature leaves open many ambiguities. To resolve
these ambiguities we add 360 degree orientation information to get a more accurate descriptor. We
are using 360 degree orientation, since curved lines cannot be fully described by their 180 degree
orientation. This is different to straight lines, where 180 degree orientation gives us the full informa-
tion about the line. Consider a half circle, with an arbitrary tangent line on it. The tangent line has
an orientation between 0 and 180 degrees. However, it does not provide information on which side
of the tangent the half circle is actually located, in contrast to a 360 degree orientation. Therefore,
using a 180 degree orientation yields to high similarities between a left curved line segment and a
right curved line segment.
As a ﬁrst step we extract the curvature information and the corresponding 360 degree orientation
of all edge pixels in the image. To estimate the curvature we follow our approach presented in
[21] and use the distance accumulation method of Han et al. [13], which accurately approximates
the curvedness along given 2D line segments. Let B be a set of N consecutive boundary points,
B := {p0 , p1 , p2 , ..., pN −1} representing one line segment. A ﬁxed integer value l deﬁnes a line Li
between pairs of points pi to pi+l , where i + l is taken modulo N . The perpendicular distance Dik

4

Figure 2: Our visualization shows the original images along with their curvature self-similarity
matrices displaying the similarity between all pairs of curvature histogram cells. While curvature
self-similarity descriptor is similar for the same object category it looks quite different to other object
categories
point pk and a chord length l is the sum hl (k) = (cid:80)k
is computed from Li to the point pk , using the euclidean distance. The distance accumulation for
i=k−l Dik . The distance is positive if pk is on
the left-hand side of the vector (pi+l − pi ), and negative otherwise (see Figure 1 and Figure 3). To
get the 360 degree orientation information we compute the gradient of the probabilistic boundary
edge image [20] and extend the resulting 180 degree gradient orientation to a 360 degree orientation
using the sign of the curvature.
Contrary to the original curvature feature proposed in [21] where histograms of curvature are com-
puted using differently sized image regions we build our basic curvature feature using equally
sized cells to make it more suitable for computing self-similarities. We divide the image into non-
overlapping 8 × 8 pixel cells and build histograms over the curvature values in each cell. Next
we do the same for the 360 degree orientation and concatenate the two histograms. This results in
histograms of 28 bins, 10 bins representing the curvature and 18 bins representing the 360 degree
orientation. There are many ways to deﬁne similarities between histograms. We follow the scheme
that was applied to compute self similarities between color histograms [29] and use histogram inter-
section as a comparison measure to compute the similarities between different curvature histograms
in the same bounding box. Furthermore, we apply an L2-normalization to the ﬁnal self-similarity
vector. The computation of self-similarities between all curvature-orientation histograms results in
an extremely high-dimensional representation. Let D be the number of cells in an image, then com-
puting all pairwise similarities results in a D2 large curvature self-similarity matrix. Some examples
are shown in Figure 2. Since, the similarity matrix is symmetric we use only the upper triangle
which results in a (D · (D − 1)/2)-dimensional vector. This representation gives a very detailed
description of the object.
The higher dimensional a descriptor gets, the more likely it contains noisy and correlated dimen-
sions. Furthermore, it is also intuitive that not all similarities extracted from a bounding box are
helpful to describe the object. To discard such superﬂuous dimensions we apply our embedded
feature selection method to the proposed curvature self-similarity representation.

4 Experiments

We evaluate our curvature self-similarity descriptor in combination with the suggested embedded
dimensionality reduction algorithm for the object detection task on the PASCAL dataset [7]. To
show the individual strengths of these two contributions we need to perform a number of evaluations.
Since this is not supported by the PASCAL VOC 2011 evaluation server we follow the best practice
guidelines and use the VOC 2007 dataset. Our experiments show, that curvature self-similarity
is providing complementary information to straight lines, while our feature selection algorithm is
further improving performance by fulﬁlling its natural need for dimensionality reduction.
The common basic concept shared by many current detection systems are high-dimensional, holis-
tic representations learned with a discriminative classiﬁer, mostly an SVM [28]. In particular the
combination of HOG [4] and SVM constitutes the basis of many powerful recognition systems and
it has laid the foundation for numerous extensions like, part based models [8, 22, 24, 33], variations
of the SVM classiﬁer [8, 27] and approaches utilizing context information [14, 26]. These systems
rely on high-dimensional holistic image statistics primarily utilizing straight line approximations. In
this paper we explore a orthogonal direction to these extensions and focus on how one can improve
on the basic system by extending the straight line representation of HOG to a more discriminative
description using curvature self-similarity. At the same time our aim is to reduce the dimensionality

5

Table 1: Average precision of our iterative feature reduction algorithm for linear and non-linear
kernel function using our ﬁnal feature vector consisting of HOG+Curv+CurvSS. For linear kernel
function we compare our feature selection (linSVM+FS) to L2 normalized linear SVM (linSVM)
and to the doubly regularized SVM (DrSVM) [30]. For non-linear kernel function we compare the
fast intersection kernel SVM (FIKSVM) [19] with our feature selection (FIKSVM+FS)

linSVM
DrSVM
linSVM + FS
FIKSVM
FIKSVM + FS

linSVM
DrSVM
linSVM + FS
FIKSVM
FIKSVM + FS

aero
66.1
59.1
69.7
80.1
80.4

table
71.4
59.9
72.0
64.1
67.6

bike
80.0
77.6
80.3
74.8
74.9

dog
57.2
53.9
57.8
61.7
64.6

bird
53.0
53.5
55.5
57.1
57.5

boat
53.1
49.9
56.2
59.3
62.1

bottle
70.7
64.4
71.8
63.3
66.7

horse mbike pers
72.9
83.0
76.5
72.3
76.5
70.9
77.2
83.3
73.0
79.4
70.9
74.6
79.7
74.2
79.6

bus
73.8
71.6
74.0
73.9
73.9

plant
47.7
47.7
49.7
47.5
53.0

car
75.3
75.8
75.9
77.3
78.0

sheep
55.1
66.3
56.7
62.0
64.2

cat
61.2
50.8
63.2
77.3
80.1

sofa
61.1
69.0
62.4
59.8
64.6

chair
63.8
56.1
64.8
69.1
70.6

train
70.4
67.7
70.7
76.9
77.1

cow
70.7
64.5
71.0
66.4
69.9

tv
73.1
79.7
73.8
69.3
69.8

mean
66.8
64.3
68.0
68.1
70.4

of such high-dimensional representations to decrease the complexity of the learning procedure and
to improve generalization performance.
In the ﬁrst part of our experiments we adjust the selection parameter λ of our iterative dimensionality
reduction technique via cross-validation. Furthermore, we compare the performance of our feature
selection algorithm to L2 regularized SVM [3, 19] and DrSVM [30]. In the second part we evaluate
the suggested curvature self-similarity feature after applying our feature selection method to it.

4.1 Evaluation of Feature Selection

All experiments in this section are performed using our ﬁnal feature vector consisting of HOG,
curvature (Curv) and curvature self-similarity (CurvSS). We apply our iterative dimensionality re-
duction algorithm in combination with linear L2 regularized SVM classiﬁer (linSVM) [3] and non-
linear fast intersection kernel SVM (FIKSVM) by Maji et al. [19]. The FIKSVM is widely used
and evaluation is relatively fast compared to other non-linear kernels. Nevertheless, computational
complexity is still an issue on the PASCAL dataset. This is why on this database linear kernels are
typically used [8, 26].
Because of the high computational complexity of DrSVM and FIKSVM, we compare to these meth-
ods on a smaller train and test subset obtained from the PASCAL training and validation data in the
following way. All training and validation data from the PASCAL VOC 2007 dataset are used to
train an SVM using our ﬁnal object representation on all positive samples and randomly chosen
negative samples. The resulting model is used to collect hard negative samples. The set of collected
samples is split up into three sets: training, validation and test. Out of the collected set of samples
every tenth sample is assigned to the hold out test set which is used to compare the performance of
our feature selection method. The remaining samples are randomly split into training and validation
set of equal size which are used to perform the feature selection. The reduction algorithm is applied
on 5 different training/validation splits which results in ﬁve different sets of selected features. For
each set we train an L2 norm SVM on all samples from the training and validation set using only
the remaining dimensions of the feature vector. Then we choose the feature set with the best per-
formance on the hold out test set. To ﬁnd the best performing selection parameter λ, we repeat this
procedure for different values of λ.
The performance of our dimensionality reduction algorithm is compared to the performance of
linSVM and DrSVM [30] for the case of a linear kernel. Since DrSVM is solving a similar op-
timization problem as our suggested feature selection algorithm for a linear kernel this comparison
is of particular interest. We are not comparing performance to DrSVM in the non-linear case since

6

Figure 3: Based on meaningful
edge images one can extract accu-
rate curvature information which is
used to build our curvature self-
similarity object representation

Figure 4: A signiﬁcant number of images from PASCAL
VOC feature contour artifacts i.e, due to their size, low
resolution, or compression artifacts. The edge maps are
obtained from the state-of-the-art probabilistic boundary
detector [20]. It is evident that objects like the sheep are
not deﬁned by their boundary shape and are thus beyond the
scope of approaches base on contour shape

it is performing feature selection in the higher dimensional kernel space rather than in the original
feature space. Instead we compare our feature selection method to that of FIKSVM for the non-
linear case. Our feature selection method reduces the dimensionality of the feature by up to 55% for
the linear case and by up to 40% in the non-linear case, while the performance in average precision
is constant or increases beyond the performance of linSVM and FIKSVM. On average our feature
selection increases performance about 1.2% for linSVM and 2.3% for FIKSVM on the hold-out
testset. The DrSVM is actually decreasing the performance of linSVM by 2.5% while discarding a
similar amount of features. All in all our approach improves the DrSVM by 3.7% (see Table 1). Our
results conﬁrm that our feature selection method reduces the amount of noisy dimensions of high-
dimensional representations and therefore increases the average precision compared to an linear and
non-linear SVM classiﬁer without applying any feature selection. For the linear kernel we showed
furthermore that the proposed feature selection algorithm achieves gain over the DrSVM.

4.2 Object Detection using Curvature Self-Similarity

In this section we provide a structured evaluation of the parts of our ﬁnal object detection system.
We use the HOG of Felzenszwalb et al. [8, 9] as baseline system, since it is the basis for many
powerful object detection systems. All detection results are measured in terms of average precision
performing object detection on the PASCAL VOC 2007 dataset.
To the best of our knowledge neither curvature nor self-similarity was used to perform object detec-
tion on a dataset of similar complexity as the PASCAL dataset so far. Deselaers et al. [5] evaluated
their global self-similarity descriptor (GSS) on the simpler classiﬁcation challenge on the PASCAL
VOC 2007 dataset, while the object detection evaluation was performed on the ETHZ shape dataset.
However, we showed in [21], that including curvature already solves the detection task almost per-
fectly on the ETHZ dataset. Furthermore, [21] outperforms the GSS descriptor on three categories
and reached comparable performance on the other two. Thus we evaluate on the more challenging
PASCAL dataset. Since the proposed approach models the shape of curved object contours and
reduces the dimensionality of the representation, we expect it to be of particular value for objects
that are characterized by their shape and where their contours can be extracted using state-of-the-art
methods. However, a signiﬁcant number of images form PASCAL VOC are corrupted due to noise
or compression artifacts (see Fig. 4). Therefore state-of-the-art edge extraction fails to provide any
basis for contour based approaches on these images and one can therefore only expect a signiﬁcant
gain on categories where proper edge information can be computed for a majority of the images.
Our training procedure makes use of all objects that are not marked as difﬁcult from the training
and validation set. We evaluate the performance of our system on the full testset consisting of
4952 images containing objects from 20 categories using a linear SVM classiﬁer [3]. Due to the
large amount of data in the PASCAL database the usage of intersection kernel for object detection
becomes comparable intractable. Results of our ﬁnal system consisting of HOG, curvature (Curv),
curvature self-similarity (CurvSS) and our embedded feature selection method (FS) are reported in
terms of average precision in Table 2. We compare our results to that of HOG [9] without applying
the part based model. Additionally we show results of our own HOG baseline system which is using
standard linear SVM [3] instead of the latent SVM used in [9]. Furthermore we show results with

7

curvature values Table 2: Detection performance in terms of average precision of the HOG baseline system, HOG and
curvature (Curv) before and after discarding noisy dimensions using our feature selection method
(FS) and our ﬁnal detection system consisting of HOG, curvature (Curv), the suggested curvature
self-similarity (CurvSS) with and without feature selection (FS) on the PASCAL VOC 2007 dataset.
Note, that we use all data points to compute the average precision as it is speciﬁed by the default ex-
perimental protocol since VOC 2010 development kit. This yields lower but more accurate average
precision measurements

HOG of [9]
HOG
HOG+Curv
HOG+Curv+FS
HOG+Curv+CurvSS
HOG+Curv+
CurvSS+FS

HOG of [9]
HOG
HOG+Curv
HOG+Curv+FS
HOG+Curv+CurvSS
HOG+Curv+
CurvSS+FS

aero
19.0
20.8
23.0
25.4
28.6

28.9

table
10.5
9.8
13.0
15.6
16.3

16.7

bike
44.5
43.0
42.6
42.9
39.1

43.1

dog
2.0
2.2
3.7
3.7
6.2

6.4

bird
2.9
2.1
3.7
3.7
2.3

3.5

boat
4.2
5.0
6.7
6.8
6.8

7.0

bottle bus
37.7
13.5
13.7
37.8
38.6
12.4
13.5
38.8
40.3
12.9

13.6

40.6

car
39.0
38.7
39.9
40.0
38.8

40.4

cat
8.3
6.7
7.5
8.1
9.3

9.6

horse mbike pers
24.0
29.7
43.5
24.3
29.5
42.4
25.5
30.5
46.0
30.8
46.4
25.7
27.2
27.5
48.0

plant
3.0
3.8
4.0
4.0
4.2

sheep sofa
11.6
17.7
17.6
11.5
18.7
8.7
11.3
19.1
20.5
9.3

48.5

30.6

27.3

4.8

11.6

20.7

chair
11.4
12.1
10.0
12.0
11.1

12.5

train
28.3
29.0
32.3
32.3
35.9

36.0

cow
15.8
16.3
16.9
17.1
13.9

17.3

tv
32.4
33.4
33.6
33.6
34.8

34.8

mean
20.0
20.0
20.9
21.5
21.7

22.7

and without feature selection to show the individual gain of the curvature self-similarity descriptor
and our embedded feature selection algorithm.
The results show that the suggested self-similarity representation in combination with feature selec-
tion improves performance on most of the categories. All in all this results in an increase of 2.7% in
average precision compared to the HOG descriptor. One can observe that curvature information in
combination with our feature selection algorithm is already improving performance over the HOG
baseline and that adding curvature self-similarity additionally increases performance by 1.2%. The
gain obtained by applying our feature selection (FS) depends obviously on the dimensionality of the
feature vector; the higher the dimensionality the more can be gained by removing noisy dimensions.
For HOG+Curv applying our feature selection is improving performance by 0.6% while the gain for
the higher dimensional HOG+Curv+CurvSS is 1%. The results underline that curvature informa-
tion provides complementary information to straight lines and that feature selection is needed when
dealing with high dimensional features like self-similarity.

5 Conclusion

We have observed that high-dimensional representations cannot be sufﬁciently handled by linear and
non-linear SVM classiﬁers. An embedded feature selection method for SVMs has therefore been
proposed in this paper, which has been demonstrated to successfully deal with high-dimensional
descriptions and it increases the performance of linear and intersection kernel SVM. Moreover, the
proposed curvature self-similarity representation has been shown to add complementary information
to widely used orientation histograms.1

References
[1] S. Belongie, J. Malik, and J. Puzicha. Matching shapes. ICCV, 2001.

1This work was supported by the Excellence Initiative of the German Federal Government and the Frontier
fund, DFG project number ZUK 49/1.

8

[2] P. S. Bradley and O. L. Magasarian. Feature selection via concave minimization and support vector
machines. ICML, 1998.
[3] C.-C Chang and C.-J. Lin. LIBSVM: A library for support vector machines. ACM Transactions on
Intelligent Systems and Technology, 2:27:1–27:27, 2011.
[4] N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. CVPR, 2005.
[5] T. Deselaers and V. Ferrari. Global and efﬁcient self-similarity for object classiﬁcation and detection.
CVPR, 2010.
[6] T.-M.-T. Do and T. Arti ´eres. Large margin training for hidden markov models with partially observed
states. ICML, 2009.
and A. Zisserman.
[7] M. Everingham, L. Van Gool, C. K.
The
J. Winn,
I. Williams,
PASCAL Visual Object Classes Challenge 2007 (VOC2007) Results.
http://www.pascal-
network.org/challenges/VOC/voc2007/workshop/index.html.
[8] P. Felzenszwalb, R. Girshick, D. McAllester, and D. Ramanan. Object detection with discriminatively
trained part based models. PAMI, 2010.
[9] P. F. Felzenszwalb, R. B. Girshick, and D. McAllester. Discriminatively trained deformable part models,
release 4. http://www.cs.brown.edu/ pff/latent-release4/.
[10] W. T. Freeman and M. Roth. Orientation histograms for hand gesture recognition. Intl. Workshop on
Automatic Face and Gesture- Recognition, 1995.
[11] Y. Grandvalet and S. Canu. Adaptive scaling for feature selection in SVMs. NIPS, 2003.
[12] I. Guyon and A. Elisseeff. An introduction to variable and feature selection. JMLR, 3:11571182, 2003.
[13] J. H. Han and T. Poston. Chord-to-point distance acccumulation and planar curvature: a new approach to
discrete curvature. Pattern Recognition Letters, 22(10):1133 – 1144, 2001.
[14] G. Heitz and D. Koller. Learning spatial context: Using stuff to ﬁnd things. ECCV, 2008.
[15] I. N. Junejo, E. Dexter, I. Laptec, and P. Per ´ez. Cross-view action recognition from temporal self-
similarities. ECCV, 2008.
[16] N. Karmitsa, M. Tanaka Filho, and J. Herskovits. Globally convergent cutting plane method for nonconvex
nonsmooth minimization. Journal of Optimization Theory and Applications, 148(3):528 – 549, 2011.
[17] T. N. Lal, O. Chapelle, J. Weston, and A. Elisseeff. Studies in Fuzziness and Soft Computing. I. Guyon
and S. Gunn and N. Nikravesh and L. A. Zadeh, 2006.
[18] D.G. Lowe. Object recognition from local scale-invariant features. ICCV, 1999.
[19] S. Maji, A. C. Berg, and J. Malik. Classiﬁcation using intersection kernel support vector machines is
efﬁcient. CVPR, 2008.
[20] D. Martin, C. Fowlkes, and J. Malik. Learning to detect natural image boundaries using local brightness,
color, and texture cues. PAMI, 26(5):530 – 549, 2004.
[21] A. Monroy, A. Eigenstetter, and B. Ommer. Beyond straight lines - object detection using curvature.
ICIP, 2011.
[22] A. Monroy and B. Ommer. Beyond bounding-boxes: Learning object shape by model-driven grouping.
ECCV, 2012.
[23] C. P. Papageorgiou, M. Oren, and T. Poggio. A general framwork for object detection. ICCV, 1998.
[24] P. Schnitzspan, M. Fritz, S. Roth, and B. Schiele. Discriminative structure learning of hierarchical repre-
sentations for object detection. CVPR, 2009.
[25] E. Shechtman and M. Irani. Matching local self-similarities across images and videos. CVPR, 2007.
[26] Z. Song, Q. Chen, Z. Huang, Y. Hua, and S. Yan. Contextualizing object detection and classiﬁcation.
CVPR, 2011.
[27] I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun. Support vector learning for interdependent and
structured output spaces. ICML, 2004.
[28] V. N. Vapnik. The Nature of Statistical Learning Theory. Springer Verlag, 1995.
[29] S. Walk, N. Majer, K. Schindler, and B. Schiele. New features and insights for pedestiran detection.
CVPR, 2010.
[30] L. Wang, J. Zhu, and H. Zou. The doubly regularized support vector machine. Statistica Sinica, 16, 2006.
[31] L. Wolf, T. Hassner, and Y. Taigman. Descriptor based methods in the wild. ECCV, 2008.
[32] P. Yarlagadda and B. Ommer. From meaningful contours to discriminative object shape. ECCV, 2012.
[33] L. Zhu, Y. Chen, A. Yuille, and W. Freeman. Latent hierarchical structural learning for object detection.
CVPR, pages 1062 –1069, 2010.

9

