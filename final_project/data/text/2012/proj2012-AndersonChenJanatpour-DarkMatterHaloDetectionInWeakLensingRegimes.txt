Dark Matter Halo Detection in Weak Lensing Regimes

Matt Anderson
Stanford University
andersme@stanford.edu

Phil Chen
Stanford University
pcchen@stanford.edu

Dustin Janatpour
Stanford University
dustinj@stanford.edu

INTRODUCTION
The Observing Dark Worlds Competition found on Kaggle,
a website aggregating machine learning competitions, posed
the following challenge: Given an image of some fraction of
a sky with information about the location and observed ellip-
ticities of hundreds of galaxies, can we predict the location
of dark matter halos in that sky?

DATA AND EVALUATION
We are given both training data and test data. The data con-
sists of several hundred skies (three hundred for the training
set, one hundred and twenty for the test set), each comprised
of three hundred to seven hundred and twenty galaxy obser-
vations. Additionally, the training data contains the locations
of true halos.

Although current methods exist to predict the location of
these centers given comprehensive amounts of data such as
three-dimensional position, mass, etc., there are not many
approaches to ﬁnding the centers given two-dimensional im-
ages of a sky. However, for many regions of space, the only
data collected are two-dimensional images, and thus the dark
matter structures in those regions of space are as of yet un-
known.

Each of the galaxies is speciﬁed by its (x,y)-position and its
ellipticities e1 and e2 . e1 corresponds to elongation along
the x and y axes. Positive e1 corresponds to a horizontally
elongated galaxy, and negative e1 corresponds to a vertically
elongated galaxy. e2 corresponds to elongation along the
axes 45 degrees from the x-axis. Positive e2 corresponds
to elongation along the 45 degree axis. Negative e2 corre-
sponds to elongation along the negative 45 degree axis.

From only two-dimensional images, dark matter centers can
be detected by the ellipticity distortion they cause on each
galaxy. However, the incomplete and inherently noisy na-
ture of the data complicates the problem. This distortion
cannot be observed directly, especially under weak lensing
assumptions, as a galaxy’s natural ellipticity is drawn from
a complex, unknown random distribution. In addition, these
background ellipticities tend to be large relative to the dark
matter signal, especially for galaxies far from the dark mat-
ter. Only by considering every galaxy and enforcing the as-
sumption that average natural ellipticity is close to zero can
we begin to look for signs of dark matter halos.

After ruling out many of the methods discussed in the course,
we adopted several distinct approaches to the problem. The
most successful was a variation on the k-means algorithm
that used a modiﬁed clustering update rule and scoring mech-
anism for clusters that selected the best candidates. An alter-
native we considered was applying a batch gradient descent
to an objective function formulated directly from the physi-
cal model. However, the complexity of this model prevented
this method from producing global minima, leading to poor
results.

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CHI 2009, April 4 - 9, 2009, Boston, Massachusetts, USA.
Copyright 2009 ACM 978-1-60558-246-7/09/04...$5.00.

1

The quality of a set of predictions is measured by a combi-
nation of distance error, the average radial distance between
the predicted halo to the true halo, and positional bias, the
average angle between a prediction and the line generated
by a reference point and the true halo.

Benchmarks
The competition provides four benchmarks with publicly avail-
able algorithms, described brieﬂy below.
• Lenstool Maximum Likelihood - Uses Lenstool software
to estimate maximum likelihood for the halo positions.
• Gridded Signal Benchmark - Divides the sky into a grid.
For each grid tile, this algorithm calculates the average
signal (sum of tangential ellipticities) for that tile relative
to the tile center, then outputs grid tiles with the highest
signal.
• Randomly Placing Halos - Randomly places halos in the
sky.
• Single Halo Maximum Likelihood - Divides the sky into
a grid. For each grid tile, calculates the maximum like-
lihood that a halo will be at the center of the grid tile.
Outputs the single most likely halo.

ALGORITHMS
Variations of K-Means Clustering
In attempting to tackle this problem, we considered many
algorithms. We believed that the problem lent itself to the K-
means clustering algorithm in the sense that cluster centers

Figure 1. An example sky with the halos being shown
(cid:113)
We calculate r as the euclidean distance.
(gy − hy )2 + (gx − hx )2
r =
• Centroid updating rule: In place of the usual centroid cal-
culation, we modiﬁed the centroid update rule in an at-
tempt to maximize local tangential ellipticity. After we
calculated the centroid for a particular cluster, we per-
turbed it by using neighboring points to generate an up-
date vector.

We know that the effect of a dark matter halo on sur-
rounding galaxies is inversely related to the distance to
the galaxy. Speciﬁcally, dark matter halos cause elonga-
tion of galaxies along the tangential axis. Thus, for each
neighboring point, we construct a vector from the galaxy,
g, to the halo, h.
−→v = h − g
We calculate the length of this vector (distance from galaxy
to halo). We take the vector normal, −→n , to the galaxy’s
major axis (based on its ellipse). We then project −→v onto
−→n as follows:
−→v · −→n−→n · −→n
−→n
−→p =
We then calculate the update vector:
−→u = −→v − −→p
We average the update vectors for all of the neighboring
points. Then, we apply this ﬁnal update vector to the cen-
troid to perturb it. We do not consider convergence until
either the cluster center has stopped changing or no new
assignments have been calculated.
• Scoring function: To deal with the convergence to local
minima, we initialize the algorithm with a k parameter
that is greater than the number of halos. Once the clusters
have converged, we score each cluster and return the top

might somehow be correlated to halos. Since halos typically
affect the set of nearby nodes, we examined how we might
vary the K-means clustering to achieve such a correlation.
To begin, we analyzed the k-means clustering to determine
what difﬁculties we might have.

Difﬁculties
• Susceptible to local minima: Since calculating optimal
clusters is an NP-hard problem, the algorithms typically
used for k-means are heuristic and converge to local op-
tima. Therefore, we would not be able to calculate global
optima
• ”Clusters”: The galaxy and dark matter halo positions are
uncorrelated (rather, the ellipticities and the dark matter
halo positions are). Thus, the idea of clusters (as tradi-
tionally deﬁned) does not perfectly apply to the data.
• Centroids: Using the positional centroid of the points as-
signed to a particular cluster does not provide any infor-
mation regarding the existence of a halo.
• Number of Clusters: For predicting a single halo, the algo-
rithm would converge after only one iteration under tradi-
tional k-means, as all points would be assigned to a single
cluster.

Approach
To deal with these difﬁculties, we attempted to modify the
k-means algorithm as follows.
• Assignment rule: We attempted to use a modiﬁed distance
metric for calculating assignments based on the tangential
ellipticity. This distance metric was
dpdm (h, g) = (e1 cos(2φ) + e2 sin(2φ))(r)
(cid:19)
(cid:18) gy − hy
where the angle from the galaxy center, φ, was deﬁned as
follows:
gx − hx

φ = arctan

2

clusters. After running this algorithm several times, we
take the average of the clusters.
We used two types of scoring functions, one based on
signal (tangential ellipticity) and one based on maximum
likelihood. The signal-based scoring function was simply
the sum of all tangential ellipticities of its neighbors. The
maximum likelihood approach was based on single maxi-
mum likelihood. That is,

f =

1
r
f1 = − cos 2φ · f
f2 = − sin 2φ · f
c = (f1 − e1 )2 + (f2 − e2 )2
s = e− c
2

(1)

g (i) =

Batch Gradient Descent
Introduction and Formulation
We wish to formulate the halo-center ﬁnding problem as a
minimization problem in order to apply the batch gradient
descent algorithm to an objective function and hopefully ob-
tain a good set of halos. Given a sky with m galaxies and n
 , h(j ) =
 x(i)
 y (j )

halos, we write
y (i)
x(j )
e(i)
θ(j )
1
e(i)
2
for i = 1, ..., m, j = 1, ..., n. For each galaxy and halo,
x and y represent its x and y coordinates. e(i)
1 and e(i)
2 are
the real and imaginary ellipticities of the i’th galaxy, respec-
tively, and θ(j ) is the Einstein radius of the j th halo. The
positional angle of the vector from the j th halo center to the
(cid:19)
(cid:18) y (i) − y (j )
ith galaxy is
x(i) − x(j )
and the observed (complex) ellipticity of each galaxy is e(i)
c =
1 + ie(i)
e(i)
(cid:88)
2 . In the weak lensing limit, the observed ellipticity
for galaxy i is
j

φ(ij ) = arctan

c = e(i)
e(i)
s +

γ (ij )

where e(i)
is the natural ellipticity of the ith galaxy, γ (ij ) =
s
exp[2φ(ij ) i] θ(j )2
, where θ(ij )
is the angle between the galaxy
r
θ(ij )2
r
and the halo with respect to the observer. Since the ob-
server is very far away, this approximates to θ(ij )
r = r(ij ) =
[(x(i) −x(j ) )2 + (y (i) −y (j ) )2 ]1/2 , the distance between them
(cid:88)
in the image. Thus, we may write
c = e(i)
e(i)
s +
j

θ(j )2
[(x(i) − x(j ) )2 + (y (i) − y (j ) )2 ]

exp[2φ(ij ) i]

.

exp

Now, the assumption given is that the magnitude of the av-
erage ellipticity should be close to zero, so for the objective
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)2
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:88)
function, we wish to minimize
e(i)
s
i
2iφ(ij ) (cid:105)
(cid:104)
c −(cid:88)
From the above equations, we can write
θ(j )2
e(i)
s = e(i)
[(x(i) − x(j ) )2 + (y (i) − y (j ) )2 ]
j
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)2
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:88)
Then, we have
J (h) =
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)2
i
2iφ(ij ) (cid:105)
(cid:104)
c − (cid:88)
θ(j )2
e(i)
[(x(i) − x(j ) )2 + (y (i) − y (j ) )2 ]
j
We then wish to minimize this value with respect to θ(j ) , x(j ) , y (j )
for j = 1, ..., n. Since we wish to perform a batch gradi-
ent descent with constraints (in this case, 0 ≤ x(j ) , y (j ) ≤
4200, θ(j ) ≥ 0), we could add a log-barrier function to pe-
nalize values that are too close to the barriers. However,
for the sake of simplicity, we broke the function into two
parts. Since the log-barriers are added linearly to the objec-
tive function, we ﬁrst apply the gradient descent rule under
the assumption of no log barriers, then add the barriers at the
end.

(cid:88)
i

e(i)
s

exp

=

b =

a =

is complex, we

θ(j )2
[(x(i) − x(j ) )2 + (y (i) − y (j ) )2 ]

Using Euler’s identity and the fact that e(i)
c
(cid:104)
2φ(ij ) (cid:105)
1 −(cid:88)
(cid:88)
rewrite the above as J (h) = a2 + b2 , with
e(i)
cos
2φ(ij ) (cid:105)
(cid:104)
2 −(cid:88)
(cid:88)
i
j
θ(j )2
e(i)
[(x(i) − x(j ) )2 + (y (i) − y (j ) )2 ]
sin
i
j
(cid:104)
(cid:105)
1 − (cid:88)
(cid:88)
Noting the similarities in the equations above, we write
f (ij )
e(i)
0
(cid:105)
(cid:104)
2 − (cid:88)
(cid:88)
j
i
f (ij )
f (ij )
e(i)
sin
1
0
(cid:18) y (i) − y (j )
(cid:19)
j
i
x(i) − x(j )

f (ij )
0 = 2 arctan

where

f (ij )
1

a =

b =

cos

f (ij )
1 =

θ(j )2
[(x(i) − x(j ) )2 + (y (i) − y (j ) )2 ]

3

Update Rule
With learning rate α, we give the batch gradient descent rule
for our objective:
θ(j ) := θ(j ) − α

J (h)

∂
∂ θ(j )

x(j ) := x(j ) − α

y (j ) := y (j ) − α

∂
∂x(j )

∂
∂ y (j )

J (h)

J (h)

Where

and

∂ a
∂x(j )

∂ b
∂x(j )

∂ a
∂ y (j )

∂ b
∂ y (j )

with

∂
∂ θ(j )

∂
∂x(j )

∂
∂ y (j )

∂ a
∂ θ(j )

J (h) = 2a

J (h) = 2a

J (h) = 2a
= − (cid:88)
= − (cid:88)
i
i

∂ a
∂ θ(j )

∂ a
∂x(j )

∂ a
∂ y (j )

+ 2b

+ 2b

+ 2b

∂ b
∂ θ(j )

∂ b
∂x(j )

∂ b
∂ y (j )

cos(f (ij )
0

∂ f (ij )
1
∂ θ(j )

)

sin(f (ij )
0

∂ f (ij )
1
∂ θ(j )

)

∂ b
(cid:34)
∂ θ(j )
= − (cid:88)
cos(f (ij )
(cid:34)
0
= − (cid:88)
i
sin(f (ij )
(cid:34)
0
= − (cid:88)
i
cos(f (ij )
(cid:34)
0
= − (cid:88)
i
sin(f (ij )
0
i

∂ f (ij )
1
∂x(j )

)

− sin(f (ij )
0

)

∂ f (ij )
0
∂x(j )

f (ij )
1

∂ f (ij )
1
∂x(j )

+ cos(f (ij )
0

)

∂ f (ij )
0
∂x(j )

f (ij )
1

)

with

∂ f (ij )
1
∂ y (j )

)

− sin(f (ij )
0

)

∂ f (ij )
0
∂ y (j )

f (ij )
1

∂ f (ij )
1
∂ y (j )

+ cos(f (ij )
0

)

∂ f (ij )
0
∂ y (j )

f (ij )
1

)

2

(cid:20)

= −

∂ f (ij )
0
∂ y (j )

(cid:21)2(cid:33)

(cid:32)
r(ij )
1 +
x
(cid:16)
(cid:17)2
2r(ij )
y
r(ij )2
+ r(ij )2
y
x
x = x(i) − x(j ) , r(ij )
y = y (i) − y (j ) .
and r(ij )

∂ f (ij )
1
∂x(j )

r(ij )
y
r(ij )
x

θ(j )2

=

Adding a log-barrier
To penalize values that approach the boundaries, we add a
− (cid:88)
function B (h) to the objective function, where B (h) is
log([4200 − x(j ) ]2 ) +
log([0 − x(j ) ]2 )+
j

1
2

1
2

[

log([0− θ(j ) ]2 )

log([0−y (j ) ]2 )+

log([4200−y (j ) ]2 )+

1
1
1
2
2
2
We can see that as any of the parameters approaches a bound-
ary, B goes to inﬁnity. To keep B from dominating the ob-
jective function far away from the barrier, we add a scaling
parameter µ, so that our new objective function is J (cid:48) (h) =
a2 + b2 + µB (h). The new gradient updates are
θ(j ) := θ(j ) − α
J (cid:48) (h)

∂
∂ θ(j )

x(j ) := x(j ) − α

y (j ) := y (j ) − α
− (cid:88)
− (cid:88)
i
i

1
θ(j )

1
θ(j )

=

∂ a
∂ θ(j )

∂
∂x(j )

J (cid:48) (h)

∂
∂ y (j )

J (cid:48) (h)

cos(f (ij )
0

∂ f (ij )
1
∂ θ(j )

)

sin(f (ij )
0

∂ f (ij )
1
∂ θ(j )

)

=

∂ b
∂ θ(j )
(cid:34)
AX = − (cid:88)
cos(f (ij )
(cid:34)
0
BX = − (cid:88)
i
(cid:34)
AY = − (cid:88)
i
cos(f (ij )
(cid:34)
0
BY = − (cid:88)
i
sin(f (ij )
0
i

sin(f (ij )
0

(cid:35)
(cid:35)
(cid:35)
(cid:35)

∂ f (ij )
1
∂x(j )

)

− sin(f (ij )
0

)

∂ f (ij )
0
∂x(j )

f (ij )
1

∂ f (ij )
1
∂x(j )

+ cos(f (ij )
0

)

∂ f (ij )
0
∂x(j )

f (ij )
1

)

∂ f (ij )
1
∂ y (j )

)

− sin(f (ij )
0

)

∂ f (ij )
0
∂ y (j )

f (ij )
1

∂ f (ij )
1
∂ y (j )

+ cos(f (ij )
0

)

∂ f (ij )
0
∂ y (j )

f (ij )
1

)

(cid:35)
(cid:35)
(cid:35)
(cid:35)

4

∂ f (ij )
0
∂x(j )

=

∂ f (ij )
1
=
∂ θ(j )
(cid:32)
1 +
(cid:16)

=

∂ f (ij )
1
∂x(j )

2θ(j )
+ r(ij )2
r(ij )2
y
x
(cid:21)2(cid:33)
(cid:20)
2r(ij )
y

r(ij )
y
r(ij )
x

2r(ij )
x θ(j )2
+ r(ij )2
r(ij )2
y
x

r(ij )2
x
(cid:17)2

In addition, the signal this objective function reﬂects is very
weak. It is quite reasonable that, even in the absence of dark
matter, the average over the galaxy’s ellipticities will be non-
zero.

Finally, though we are in the weak lensing regime, the as-
sumption that we are operating in the weak lensing limit may
have been inaccurate. However, the full formalism for weak-
lensing regime-observed ellipticity is

e(i)
c =

e(i)
s + γ
1−κ
1−κ e(i)
1 + γ
s
where κ is convergence, which we are not given. Using this
to develop the objective, however, yields a function that is
even less conducive to gradient descent.

While initial progress was promising, neither our modiﬁed
clustering approach nor our batch gradient descent rule yielded
robust results. We believe that, despite our best efforts, the
former model was too coarse to adequately respond to the
highly nuanced lensing perturbations caused by the pres-
ence of halos, and the latter was subject to the limitations
of non-convexity on the objective function. Though we had
hoped to test alternate approaches, for instance binary classi-
ﬁcation indicating the approximate presence of halos in sky
localities or factor analytical models that acknowledge vari-
ation in mass, density, and position of halos as unobserved
variables, we struggled to adequately featurize and linearly
separate the data. We also found it difﬁcult to formulate
linear approximations for nonlinearity intrinsic to the prob-
lem. Given more time, however, we believe progress could
be made through the development of techniques for solving
nonlinear factor analytical models.

REFERENCES
1. Narayan, R., & Bartelmann, M. (1996). Lectures on
gravitational lensing. arXiv preprint astro-ph/9606001.

2. Bernstein, G. M., & Jarvis, M. (2007). Shapes and
shears, stars and smears: Optimal measurements for
weak lensing. The Astronomical Journal, 123(2), 583.

3. Bartelmann, M., & Schneider, P. (2001). Weak
gravitational lensing. Physics Reports, 340(4), 291-472.

4. Padmanabhan, N., Seljak, U., & Pen, U. L. (2003).
Mining weak lensing surveys. New Astronomy, 8(6),
581-603.

5. Munshi, D., Valageas, P., Van Waerbeke, L., & Heavens,
A. (2008). Cosmology with weak lensing surveys.
Physics Reports, 462(3), 67-121.

∂ a
∂x(j )

∂ b
∂x(j )

∂ a
∂ y (j )

=

=

=

1
x(j )

1
x(j )

1
y (j )

−

−

−

1
4200 − x(j )
1
4200 − x(j )
1
4200 − y (j )

+ AX

+ BX

+ AY

∂ b
1
1
4200 − y (j )
∂ y (j )
y (j )
The rest of the algorithm proceeds as without the barrier.

+ BY

=

−

RESULTS AND DISCUSSION
Modiﬁed K-Means
We tested the variations of the K-means algorithm with all
possible combinations of traditional and different factors.

Using a combination of the traditional assignment and mod-
iﬁed update rule with the maximum likelihood scoring func-
tion produced results that were better than the random bench-
mark and the single maximum likelihood benchmark. The
reason for the improvement was its ability to distinguish
multiple clusters more effectively than the single maximum
likelihood. However, it performed worse than the gridded
signal benchmark.

Ultimately, the performance of the k-means algorithm was
slow computationally and poor relative to the benchmarks.
The computational complexity was high due to the numbers
of iterations, clusters, and averaging. The main issue was the
susceptibility to local optima, which is an intrinsic weakness
of the algorithm. For example, on a typical run, eight out of
the ten runs would be relatively accurate, but the other two
had high enough variation to introduce signiﬁcant error. One
possible cause is the fact that the clusters could be surround-
ing the halos, but the individual centers of the clusters would
not be close to true halo.

One potentially interesting approach would be to construct a
mixture of Gaussians model that attempted to learn the den-
sity of dark matter halos with regard to galaxies. We would
then use the model to generate potential dark matter halo lo-
cations.

Batch Gradient Descent
We tested batch gradient descent on each training sky by dis-
cretizing and choosing many sets of initialization points and
returning the set of parameters that converged to the best
objective. Unfortunately, application of this algorithm per-
formed worse than the random benchmark. This is likely
due to a number of factors which we outline below.

First and foremost, our objective function is non-convex.
Thus, even in instances in which the gradient converged (which
was not always the case), we could at best hope for locally
optimal results. The objective function is also highly sen-
sitive to the behavior of galaxies that are very close to the
halos, and thus gradient descent behaves poorly.

5

