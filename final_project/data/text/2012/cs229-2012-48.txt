Time series analysis: the eﬀect of adding an unsupervised
layer to NN time series prediction

David Seetapun

December 14, 2012

Introduction and Synthetic Data
Let {Yt } be an observed time series where the interval between observations is ﬁxed. We consider models
which take a window of length d of the time series so that Ys+d is the response to (cid:104)Ys , Ys+1 , . . . , Ys+d−1 (cid:105). We
will train the models to predict the next observation in the time series. In order to predict an observation
q(cid:88)
p(cid:88)
some number of periods f in the future we will predict the next observation and iterate the predictor. The
method of stochastic sampling may be also used [1] but we will not consider it here.
θi εt−i + εt . Following [2] we start the inves-
φiYt−i +
An ARM A(p, q) process is given by Yt =
tigation with synthetic data as we will then have solutions for the distributions of the the Yt and we can
t(cid:88)
then compare E (Yt ) to the model predictions. In what follows Yt is a sample of 500,000 ARMA(2,2) with

φ = .35, .45 and θ = .15, .25. Also we add .01 to each element so that Zt =
mean.

Yi will have a non constant

ARMA(2,2), Gaussian process models and FFNN

We use a set of 50000 observations, split by random selection into 75% training set, 25% validation
set for the NN. The test set consists of the ﬁrst 500 observations. We ﬁt a Gaussian process model with
exponential kernel (by optimizing the hyperparameters), a FFNN with hidden layer size 5 and window size
5 and an ARMA(2,2) model. The optimal predictions were obtained from the ﬁtted ARMA(2,2) model.
The results are shown in ﬁgure 1 below.
The FFNN produces the optimal predictions. The GP is unable to model the non zero mean (as ex-
pected for most kernels). Since GP with standard kernels cannot model non stationary processes, we will
not consider them further.
t(cid:88)
We consider the times series Zt =
Yi which is non stationary. We train the FFNN directly without
diﬀerencing to the stationary Yt . The results are in ﬁgure 2 for diﬀerent size windows.
There is much more variability in the ﬁnal model arising from with starting with random weights. From
a qualitative standpoint, we will interpret this as the increased diﬃculty of modelling the joint distributions
of the integrated time series.

ARIMA(2,1,2) and FFNN

Autoencoders
We know from the above that there is a representation of the time series Zt , namely Zt − Zt−1 that is
easily modelled by a small FFNN. So we can now ask if we can arrive at such representations with unsu-
pervised learning and in particular if the method of training the layers of a multiple layer AE recursively
results a good ﬁnal ﬁt for our synthetic data set.

1

We train two AE with one and two hidden layers each and then use the encoded data for the supervised
training of a FFNN with hidden layer size 5. No further ﬁne tuning is done. NN indicates where we train
the overall network corresponding to one AE stack as a single network. The results are below in ﬁgure 3.
We see that the method of training each layer separately, does not produce a better result than training
the network as a single entity. Further, if ﬁne tuning the AE networks starting from the parameters obtained
by training each layer separately are in the same basin of attraction as the parameters obtained by training
the network as a whole, we will obtain results as shown on the plot.
We also plot the decoded representation of the time series along with the original times series in ﬁgure
4. We see that the eﬀect of the AE is largely to smooth the time series. This will not remove the predictive
diﬃculties associated with the nonstationarity. This concludes our experiments with synthetic data which
we used to evaluate the diﬃculty of training NN with and without AE on data from a well understood time
series. We will use our understanding of the tools and techniques employed above to investigate observed
data.

Global Energy Forecasting Competition - Wind Forecasting on kaggle.
Initial experiments and observations

The data set and predictive challenge is described at www.kaggle.com/c/GEF2012-wind-forecasting. The
problem is to predict the power output of seven wind farms in given 48 hour windows from 48 hour wind
forecasts. Training data is provided in which 48 hour wind forecasts are given every 12 hours, the test data
only has forecasts that would be available when the test prediction period starts. The wind forecasts are
given as x and y (planar) components of the wind, and the polar (r, θ) representation is also included in
the data set (or in the notation of the datasets provided u,v,ws,wd).
As a ﬁrst experiment, we assume that the observed wind is normally distributed around the prediction
with the variance increasing with the lead time, justifying the use of the latest prediction as the best
estimator of the wind speed at any time a power prediction was required. The feature vector is then the
x, y , r, θ of the latest forecast. We also add windows of previous power observations to each of the seven
predictors. The results are given as Window-SP.

Window-SP
0
6
12
24
36

RMSE Window-TP
0
0.17887
5
0.18132
0.18064
12
0.18396
0.18739

RMSE Window-TF
5
0.16618
0.16878
12
0.17181

RMSE
0.16878
0.17181

INT-α
α = 1.0
α = .775
α = .75
α = .6
α = .5

RMSE
0.16301
0.16368
0.16132
0.16287
0.16217

From this it is clear that using the windowing technique with power observations to capture autoregressive
properties of the time series of power generation does not increase the accuracy of the predictor.
Now we predict the power output of each of the seven wind farms simultaneously using the seven most
recent predictions in an attempt to capture any correlations that may be present. This predictive method
yielded RMSE of 0.16618 or 25/134 on the leaderboard (the top score was 0.14567) indicating that we
are beneﬁtting from the covariance structure of the seven farms. Windows consisting of previous power
observations and forecast observations are added. The results are Window-TP and Window-TF.
To reﬁne our predictive model we have to address the issue related to the lead in the wind forecast for
a required forecast date. Because of the way the forecast data is supplied, any date in the training set will
have a forecast that is at most 12 hours old but dates in the test set can have most recent forecasts that
are 48 hours old. As a next experiment we will construct a test set where the lead in the forecast time is a
feature of the training examples. This only results in a small improvement to 0.16558.
We will use another approach to reﬁne our model. Until now we have supposed that the observed wind
is normally distributed around the latest prediction. The way that the wind forecasts are presented means

2

there are times T where the prediction for T has a long lead but T is very close to a date S for which there
is a prediction with lead of one hour (giving a very good indication of the wind at time S ). Using a simple
linear interpolation to modify the forecasts does not improve the model, which obtains 0.24955. Thus we
introduce a decay term so that the inﬂuence of the S forecast is more local. Thus if FT is a recent forecast
for time T and FT −j is an old forecast for T − j we use K e−αj FT + (1 − K e−αj )FT −j for the forecast at
T − j . With such a term α the results are in the table above under INT−α We also add the time of day
and day of year to capture seasonal eﬀects. With α = .75 we obtain an improvement to 0.16044. In what
follows we will include these seasonal features.

Random Forests and Boosted Decision Trees

RF α
0.75
0.6
0.5
0.4

RMSE GBM-5CV RMSE
0.16485
1000
0.15529
0.16196
5000
0.15563
0.15420
10000
0.16283
0.15560

Having settled on feature vectors which give good performance, we will experiment with the underlying
regression technique. Using a two layer NN has no eﬀect on performance nor does predicting each farm
individually from the whole feature vector. Using the same α parameterized interpolation above with a
Random Forest of 250 trees we obtain the results in the table. With gradient boosting we show the results
in the table with 5 fold cross validation.

Autoencoders

In an eﬀort to further improve performance, we will address the issue of the lead in the forecast. We
will use an autoencoder on the time series of the most recent forecasts. We will do this for each component
separately and then recalculate the polar representation. The motivation here is to obtain a representation
of the forecasts in the test sets consistent with the forecasts in the training set and also interpolate the
data as above. This results in 0.26672 which is comparable with linear interpolation with no decay factor.
In what follows we use the α interpolation scheme above as we require the smoothing to be local for good
performance.

WINDOW-α-TP
2
4
8

RMSE WINDOW-α-AE1
0.16049
8
16
0.16445
0.16454
32

RMSE WINDOW-α-AE2
0.23306
8
16
0.23621
0.23858
32

RMSE
0.22929
0.23870
0.24208

If we use as a feature vector the planar forecast of each wind farm, we can again use the windowing tech-
nique to provide a temporal context. However the length of the feature vector will be 14 times the length of
the window (here we omit the polar representation). For small window lengths the results are in the table
above. For larger window lengths, we use an autoencoder on the features for dimensionality reduction and
non supervised feature selection. The autoencoder is trained with L-BFGS and we optimise over the whole
training set and not smaller batches as the number of examples is small. For one and two hidden layers,
the results are under WINDOW-α-AE1,WINDOW-α-AE2 respectively.

Conclusions
The best result is achieved with a random forest and α interpolation giving RMSE 0.15420. This result
places in the top 10%. From the experiments for both the wind data and the synthetic data above, we failed
to achieve any performance gains with multilayer NN with the use of windowing to provide temporal context.

3

It may be that the method is more suited to time series where there are more directly observable predictive
variables rather than time series where there are few predictive variables such as he ones considered here.

References

[1] Volker Tresp, Reimar Hofmann, Graphical Models: Foundation of Neural Computing. Eds, M Jordan
and T. Sejnowski MIT Press, Massachusetts, 2001.

[2] Jerome T. Conner, R. Douglas Martin, L. E. Atlas, Recurrent Neural Networks and Robust Time Series
Prediction. IEEE Transactions on Neural Networks, Vol. 5 No. 2 March 1994.

ARMA(2,2)
Optimal Prediction
FFNN w=5,h=5
GP

0.2

0.1

0

−0.1

10

8

6

4
420

420

440

460

480

500

520

540

560

580

Figure 1: FFNN and GP

ARIMA(2,2)
Optimal
w=5,h=5
w=10,h=5
w=15,h=5

440

460

480

500

520

540

560

580

Figure 2: FFNN and ARIMA

4

ARIMA(2,2)
Optimal
1 stack
2 stacks
NN

440

460

480

500

520

540

560

580

Figure 3: AE predictions

ARIMA(2,2)
AE decoded

8

7

6

5

4
420

0.5

0
−0.5
−1

0

10

20

30

40

50

60

70

80

90

100

110

120

Figure 4: Result of AE

5

