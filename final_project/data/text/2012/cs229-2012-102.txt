C
CS229 
Final 
Proje
ect 
oft Kinect
he Microso
on using th
assificatio
on and Cla
Recognitio
Gesture R
t 
 
Chun-wei Le
C
ee 
f Electrical En
Dept. of 
gineering 
Sta
anford Univer
rsity 
nweil@stanfor
chun
rd.edu 
 

Junji M
Ma 
l Engineering
t. of Electrica
Dept
 
Stanford Un
niversity 
j
junjima@stan
nford.edu 

Just
tin Huang 
ctrical Engine
Dept. of Elec
eering 
rd University 
Stanfor
jjhuang0
0@stanford.ed
du 

bstract—In  thi
Ab
machine  lear
detail  a  few 
is  report  we 
rning 
ognize  and  cla
n  learn  to  reco
hods  in  which 
meth
  a  system  can
assify 
n  Hidden  Ma
primarily  on
Our  focus  is 
hum
man  gestures. 
arkov 
od. 
dels, and we dis
Mod
scuss the advan
ntages of using
g such a metho

I. INTRO
ODUCTION 
(HCI)  has  in
uter  interface 
The  field  of  h
human-compu
T
n  the 
in  making  hu
of  a 
uman  control 
made  strides 
past 
few  decades 
comp
more  conven
re  intuitive.  F
mputer  system 
nient  and  mo
From 
ing  with  a  ke
sed  onto  grap
field  progress
eyboard,  the  f
start
phical 
wing  the  comp
mouse,  to  allow
GUI),  to  the  m
interfaces  (G
user 
puter 
to  un
a  of  allowing  a
ech. The  idea 
nderstand  spee
a  computer  sy
ystem 
been 
to  u
understand  hu
uman  gesture
es,  however, 
has  always 
on  in  techno
diffi
cult  to  reach
h,  due  to  the
e  sophisticati
ology 
requ
and  good  ca
as  fast  proces
uired—such  a
ssing  power 
amera 
unched  the  K
Corporation  lau
,  Microsoft  C
ems.  In  2010,
syste
Kinect 
syste
em  for  the Xb
box  360, whic
ch  combines  b
both  a  stereosc
copic 
came
era,  infrared  s
sensor  and  m
more  into  a  co
ompact  device
e,  but 
ffordable pric
e at an easily a
was available
e importantly 
more
ce.  
 

 

icrosoft Kinec
Figure 1:  Mi
F
t 
The  Kinect  se
T
erved  as  an  in
nterpreter  that
t  translated  hu
uman 
nds.  Although
ame  comman
ures  into  ga
gestu
h  Microsoft 
later 
ranting  develo
early  2011,  gr
ect  SDK  in  e
ased  the  Kine
relea
opers 
gesture  recogn
  sensors,  its  g
f  the Kinect’s
ess  to many  of
acce
nition 
algo
rithms  remain
ned  proprietar
ry  and  hidden
n  from  the  pu
ublic. 
This
a  real  time  ge
o  implement  a
us  an  effort  to
s  project  is  thu
esture 
class
sification  syst
tem  using  the
e  Kinect  for 
data  sensing
g  and 
colle
ection.  

II. PROJE
ECT GOALS 
ning  technique
e various  learn
ms  to explore
Our project aim
O
es  for 
goal of being
h  the ultimate 
gestures, with
deling human g
mod
g  able 
lassifier  shoul
to  tr
rain  a  real  tim
me  action  clas
ssifier.  The  cl
ld  be 
able 
to distinguish
h between a ge
esture and not
thing at all, as
s well 
as th
of gestures. 
ifferent types 
ing between di
he distinguishi
ures 
A. B
Baseline Gestu
the  followin
gestures  are 
ng:  punch,  sw
O
Our  baseline 
wing, 
mable  by  a  s
actions  perfor
These  are  all  a
e  and  slap.  T
wave
single 
hand
d (in our case, 
we focused o
on the right han
nd).  

B. C
Coding Enviro
onment 
in  the  MAT
arily  coded 
ms  are  prima
Our  algorithm
O
TLAB 
trigger  the K
hough  code  to 
envi
ironment,  alth
Kinect  and  inte
erface 
is written in C
it wi
ith MATLAB
C#.  
III. DA
DATASET 
Kinect Sensor 
Capability 
A. K
track 
image  proce
T
The  Kinect’s 
essing  power 
allows  it  to 
front  of  it,  bu
ut we will  focu
to  3  users  in 
eleton’  for  up 
‘ske
us  on 
in the 
ws us to obtai
eing tracked. T
first person be
the f
The SDK allo
joint 
XYZ  coordi
ble  precision
doub
inates  of  the 
twenty  key 
poin
nts that make u
up the skeleton
n.  

 
inect Skeleton
Figure 2: Ki
n 
Data Collectio
on 
B. D
our  sets  of  dat
we  collected  fo
oordinates,  w
Using  these  c
U
ta  for 
our  team  mem
ine  gestures,  w
h  of  our  basel
each
with  each  of 
mbers 
ples each, resu
perf
forming 100 tr
raining examp
lting in a total
l of at 
least
t  300  exampl
es  per  gesture
e.  Each  traini
ng  window  la
asts  a 
worth of data  a
s 30  frames w
e Kinect  takes
ond, where  the
seco
and  in 
h  the  action  i
gin  and  finish
dual  must  beg
ch  an  individ
whic
in  its 
entir
rety.  In  additi
ion,  we  record
ded  an  additio
onal  set  of  da
ata  to 
repr
resent  random
m noise,  involv
ving  lack  of  a
action  or  a  ran
ndom 
uating  our  mo
use  in  evalu
intended  for 
ry  of  action, 
flurr
odels’ 
uracies later on
accu
n in validation
n. 

 of Baseline G
e 3: Examples 
Figure
Gestures 

 

movement  o
concern  the 
stures  mainly 
Since  our  ges
S
f  the 
s of the head, s
YZ coordinates
right
t arm, we took
k only the XY
spine, 
right
t  hip,  right  elb
bow,  right wri
ist  and  right  h
hand,  for  a  tot
tal  of 
x540. 
ple vector is 1
training examp
an individual t
values. Thus, a
18 v
Feature Extrac
C. F
ction 
ermined  that  m
tures,  we  dete
ating  our  feat
W
When  delibera
much 
ng  our  design
when  performin
  not  move  w
he  body  does 
of  th
nated 
Thus,  we  dec
ht  hand  does. 
r  only  the  righ
ons  and  rather
actio
cided 
he  relative pos
ependent on  th
ures merely  de
make our  featu
to m
sition 
of ou
ur hand to our
r spine coordin
nates. To com
mpensate for bo
odies 
y  the 
of di
ifferent  stature
es, we  normal
lize  (divide)  th
hese  values by
points,  using
nd  the  spine 
  the  head  an
ance  between 
dista
g  the 
mption that m
ly consistent h
most of our use
assu
ers have a fairl
head-
y-arm  ratio.  T
body
Thus  our  base
eline  features 
are  calculate
ed  as 
such
h: 
Fig(cid:1850)(cid:3045)(cid:3036)(cid:3034)(cid:3035)(cid:4593)(cid:1851)(cid:3045)(cid:3036)(cid:3034)(cid:3035)(cid:3047)
(cid:3047)(cid:3035)(cid:3028)(cid:3041)(cid:3031) (cid:3404) (cid:3025)(cid:3293)(cid:3284)(cid:3627)(cid:3025)
(cid:3284)(cid:3282)(cid:3283)(cid:3295)(cid:3283)(cid:3276)(cid:3289)(cid:3279)(cid:2879)(cid:3025)(cid:3294)(cid:3291)(cid:3284)
 
(cid:3284)(cid:3289)(cid:3280)(cid:3627)
(cid:3025)(cid:3283)(cid:3280)(cid:3276)(cid:3279)(cid:2879)(cid:3025)(cid:3294)(cid:3291)(cid:3284)(cid:3289)(cid:3280)
(cid:3047)(cid:3035)(cid:3028)(cid:3041)(cid:3031) (cid:3404) (cid:3026)(cid:3293)(cid:3284)(cid:3282)(cid:3627)(cid:3026)
ed Feature Po
gure 4: Selecte
oints 
(cid:3282)(cid:3283)(cid:3295)(cid:3283)(cid:3276)(cid:3289)(cid:3279)(cid:2879)(cid:3026)(cid:3294)(cid:3291)(cid:3284)(cid:3289)
(cid:4593)(cid:1852)(cid:3045)(cid:3036)(cid:3034)(cid:3035)(cid:3047)
(cid:3289)(cid:3280)  
(cid:3047)(cid:3035)(cid:3028)(cid:3041)(cid:3031) (cid:3404) (cid:3027)(cid:3293)(cid:3284)(cid:3282)(cid:3627)(cid:3027)
(cid:3026)(cid:3283)(cid:3280)(cid:3276)(cid:3279)(cid:2879)(cid:3026)(cid:3294)(cid:3291)(cid:3284)(cid:3289)(cid:3280) (cid:3627)
      
(cid:3282)(cid:3283)(cid:3295)(cid:3283)(cid:3276)(cid:3289)(cid:3279)(cid:2879)(cid:3027)(cid:3294)(cid:3291)(cid:3284)
(cid:4593)
(cid:3289)(cid:3280)(cid:3627)
(cid:3027)(cid:3283)(cid:3280)(cid:3276)(cid:3279)(cid:2879)(cid:3027)(cid:3294)(cid:3291)(cid:3284)(cid:3289)(cid:3280)
   
 
s, such as the a
other features
dered several 
We also consid
W
angle 
l as  the veloci
inates, as well
d elbow coord
ween hand and
betw
ity of 
the h
hand coordina
ate, though the
e latter is theor
retically accou
unted 
n our time fram
for in
ames. 
IV. E
OF MODEL OP
EXPLORATION 
PTIONS 
ve  consideratio
menting  our  sy
B
Before  implem
ystem, we  gav
on  to 
a  few
w  different  ty
ypes  of  learnin
ng  techniques 
for  distinguis
shing 
 
ing examples. 
d on our traini
 another based
ures from one 
gestu
r Machine (SV
upport Vector
A. Su
VM) 
urned  to,  given
st  tools  we  tu
S
SVMs  were  o
one  of  the  firs
n  the 
Our 
h  as  libsvm. 
libraries  such
lability  of  ‘o
avail
off-the-shelf’ 
first calculate 
atures for all o
the above fea
cedure was to f
proc
of our 
re  we 
ors  are  then  sh
a.  These  vecto
uences  of  data
sequ
huffled,  befor
each 
divid
de it up such t
that we have 3
300 training ex
xamples from 
train 
set, r
reserving the r
remaining as t
the validation
n set. We then 
ver  the  test m
matrix 
rix  and  fit  it o
r training matr
odel  from  our 
a mo
to de
etermine the re
ecognition rat
e for each of o
our actions. 

(1) 

(2) 

(3) 

E I.  SVM GEST
TABLE
TURE RECOGNITIO
ON RATES 

Tr
rue 
Lab
bels 
 
Pun
nch 

Slap
p 

Swi
ing 

Wa
ave 
 

Punc
ch 
100%
% 

0% 

7.1%
% 

0% 

ected Actions 
Dete
Swin
Sla
ap 
ng 
0%
% 
0%
% 

100
0% 

0%
% 

8.7
7% 

0%
% 

85.7
7% 

0%
% 

Wave
0% 

0% 

7.1%

91.3%

accuracy was  a
overall SVM  a
out  that  the ov
It would  turn 
I
about 
92.3
3%,  which  is  p
pretty  good  fo
for  a  first  attem
mpt;  although
h  it  is 
clea
ar some action
s are harder fo
or the system 
to detect. How
wever, 
false 
changes  wh
ossibility  of 
oduce  the  po
hen  we  intro
this 
posi
itives. 

ABLE II.  SVM
TA
(W/ FALSE POSITI
OGNITION RATES (
M GESTURE RECO
IVES) 
Tr
rue 
La
abels 
 
Pun
nch 

tected Actions 
Dete
Swing 
0% 

Wave 
87.5% 

Punch
12.5%

Slap 
0% 

e 
Fals
0%
 

Sla
ap 

Sw

ing 

Wa
ave 

Fal
lse 

0% 

7.1%

82.6%

2.56%

100% 

33.3% 

0% 

0% 

0% 

35.7% 

13% 

7.69% 

0% 

7.1% 

0% 

2
25.6% 

0%

 

16.7%
% 

4.35%
% 

64.1%
% 

ropped to a 40
s latter case dr
ccuracy in this
The overall ac
T
0.97%. 
Ord
inarily,  one  m
might  improve
e  the  feature 
selection  to  b
boost 
our 
Ms were not w
mined  that SVM
ver, we determ
score. Howev
worth 
time 
ly  model  the 
y  to  efficient
their  inability
suing,  due  to 
purs
The  SVM  m
models  our  tra
e  nature  of  o
slice
ur  problem. 
aining 
vect
tors  as  is  from
m  start  to  end, 
but  realistical
lly  the  same  a
action 
earlier  frame.
ater  frame  and
y  start  in  a  la
may
d  end  in  an 
.  The 
a poor 
counting for th
exibility in acc
M’s lack of fle
SVM
his makes it a
good 
es.  In  addition
didate  for mod
cand
deling  gesture
n,  the SVM  is 
very 
for 
multi-class  c
classification. 
However,  ‘n
no  action’  is 
possibly  enca
broa
ad  and  cannot 
apsulate  all po
ossibilities  and
d  still 
we  require  i
model.  What 
d  consistent  m
n  a  good  and
train
is  the 
a  certain  likeli
o  default  to  ‘n
del’s  ability  to
mod
no  action’  if  a
ihood 
  action  was 
shold  for  the
thre
not  reached, 
rather  than  b
being 
one of k classe
forc
ed to choose o
es.  
K-Means Clust
B. K
tering 
stigating  whet
ored  was  inves
tion  we  explor
One  other  opt
O
ther  a 
patte
ern  existed  in
n  the  sequenc
ces  of  the  ge
estures  such  t
that  a 
clus
tering algorith
hm such as K-
-Means could 
mark division
ns for 
s  of  our  tra
h  dimensions
to  the  high
h  class.  Due
each
aining 
e  classification
selection),  the
after  feature  s
exam
mples  (1x90, 
n  was 
poor
r  and  resulted
in  every  sing
gle  example be
eing  classified
d  as  a 
‘pun
nch.’  Intuitive
ely,  it  is  under
erstandable  tha
at  K-Means  w
would 
slice 
y  single  time 
oking  at  every
  due  to  it  loo
form  horribly,
perf
ther inflexible
, making it rat
gether at once
altog
e.  
V. H
HIDDEN MARK
KOV MODEL (H
HMM) 
ntroduction to
A. In
o HMMs 

 
a Hidden Mar
rkov Model 
 Example of a
Figure 5:
n Markov Mo
tilizing  Hidde
y  settled  on  ut
We  ultimately
W
odels, 
a  gr
raph-based  mo
odel  which  co
onsiders  a  seq
quence  of  sym
mbols 
emit
tted  by  true  hi
idden  states  in
n  time. Critica
al  to  the HMM
M  are 
state 
how  likely  a 
h  determine  h
ilities,  which 
sitive  probab
tran
tran
sitions  to  ano
other  state  (or
r  to  itself),  as
s  well  as  emi
ission 

rvation  occurs
ikely  an  obser
dictate  how  li
prob
babilities  that 
s  at  a 
le  running  the
ain  state. Whi
certa
e model,  the  t
rue  state  is  hi
idden 
s,  and  only  ob
to  us
bservations  as
  a  result  of  th
he  state  are  sh
hown. 
log-
calculates  the 
our  system  c
observations, 
ed  on  these  o
Base
and  the  follo
y  true  state  a
e  most  likely
likel
lihood  of  the
owing 
e  the  skeleton
case,  our  obs
uence.  In  our 
sequ
servations  are
n  key 
nts  available  t
poin
to  us.  The  h
hidden  states 
are  the  pose
es  or 
equence  of  s
,  and  the  se
human  user,
postu
ures  of  the 
states 
stitutes an acti
cons
on.   

 
Figure 6:
: Hidden Mark
kov Model of 
a Gesture 
need 
respondingly n
ctions, we corr
ur baseline ac
As we have fo
A
our test gestur
we can match o
Ms in which w
ain four HMM
to tra
re 
st 
sequ
uences against
t and determin
ne the likeliho
od that our tes
given models
occurs in the 
data 
s. 
B. T
lch Algorithm 
The Baum-Wel
ssess  observa
n  in  the  form
ations/emissio
W
While  we  po
m  of 
train
ning  data,  it  is
s  rather  difficu
ult  as  humans
s  to  predict  wh
what  a 
bability matri
r emission pro
nsition and/or
esponding  tran
corre
ix  for 
the  Baum-W
Fortunately, 
of  action  is. 
a  ce
ertain  type  o
Welch 
us  to  estima
rameters  given
ate  these  par
rithm  allows 
algo
en  an 
obse
ervation  sequ
uence  and  r
random 
initia
alized  probab
bility 
e  of  local  max
o  the  presence
unately,  due  to
rices.  Unfortun
matr
xima, 
does  influence
nitialization  d
of  random  in
methodology 
the  m
e  the 
during this proj
hly explored d
result, but was
end r
s not thorough
oject. 
F
Following  the
e  calculation 
of  the  pro
obability  matr
rices, 
deter
rmining  the  l
likelihood  of 
a  sequence  w
would  be  a  si
imple 
e  of 
the  sequenc
he  steps  of 
m  tracing  th
ward  algorithm
forw
states [1] [2] 
[3].  
he most likely 
ervations and d
obse
determining th
C. C
Codebook of Sy
ymbols 
our  features  n
need  to  be  fu
with  HMMs, 
To  continue  w
T
urther 
observations o
emit discrete o
mple HMMs e
cessed. Our sim
proc
out of 
r  current  fea
However,  our
ossibilities.  H
et  list  of  po
a  se
atures 
origi
inate  from  a  th
theoretically  in
nfinite  set  of  3
3D  points, ma
aking 
mission  probab
n  an HMM  em
e  to  capture  in
ther  infeasible
it  rat
bility 
of  a 
duce  the  idea 
ue,  we  introd
with  this  issu
matr
rix.  To  cope 
y,  we  segment
MM  codeboo
abulary,  or  HM
voca
ok.  Essentially
nt  our 
instead  grou
3D 
space  into  d
discrete  block
ks  (symbols), 
uping 
poin
nts  together.  A
And  the  3D  sp
pace  is  calcula
ated  relatively
y  and 
This 
the  person  in
he  height  of 
malized  by  th
norm
n  the  scene.
from 
to estimate the
ws the HMM t
allow
e probability t
that a symbol 
a set
t vocabulary w
was observed. 
 
 

Figu
ure 7: Segmen

 
tation of 3D S
Space 

itrary  matter  b
ne  in  an  arbi
ation  was  don
The  segment
but  a 
pref
ference  to  giv
ve  greater  reso
olution  to  the
e  XY  plane,  r
rather 
wide 
than
n  to  depth,  sin
nce  most  of  th
he  baseline  ac
ctions  span  a 
vel.  If  setting
ame  depth  lev
mately  the  sam
a  at  approxim
area
g  the 
each 
ke  7  divisions 
we would mak
ols  to  be  98, w
mber  of  symbo
num
alon
ng the X and Y
Y axis, but only
ly 2 divisions a
along the Z ax
xis. 
D. M
Model Classifi
cation Thresh
hold 
our  five  dat
a,  we  trained 
ared  our  data
Having  prepa
H
tasets 
-Welch  to  pro
)  using  Baum
isy  action  set)
luding  the  noi
(incl
oduce 
five 
HMMs. As m
mentioned  bef
fore, we  prepa
are  our  testing
g  data 
in a 
similar mann
er, and then m
match the data
a to each of the
e five 
mod
hest  log-likelih
flects  the  high
he  one  that  ref
dels  to  find  th
hood. 
he ‘best’ mode
simply pick th
t adequate to s
wever, it is not
How
el as a 
orce  the  syste
this  would  fo
lculation,  as  t
ult  of  that  cal
resu
em  to 
mak
ke a choice eve
en if none of t
the actions we
ere good candi
idates. 
that  the  likeli
reshold  value 
,  we  set  a  thr
deal  with  this
To  d
ihood 
e  program  eve
res  must  surpa
scor
ass  before  the
en  considers  it
t  as  a 
best
t match candid
date [4].  

 

tem Flow Cha
Figure 8: Syst
F
art 
VI. SIM
MULATION RE
ESULTS AND A
NALYSIS 
We  ran  our  v
W
verification  se
et  on  the  train
ned  models,  w
while 
er  of  hidden  s
ing  the  numb
ects  of  adjusti
loring  the  effe
expl
states 
well as the num
as w
mber of symbo
ols, in search o
of an optimal v
value. 
x  104
0

d
o
o
h
i
l
e
k
i
l
g
o
L

-0.5

-1

-1.5

-2

-2.5

-3

-3.5

-4

-4.5

Swing 
Wave 
Slap 
Punch 

-5

 

8
80

70
60
50
40
30
20
10
0
Cyc le
ning Likelihoo
9: HMM Train
Figure 9
od Curves 
parameters,
the 
r  reasonable
that  under
We  observed
W
d 
, 
e  flattened  ou
ut  by 
generally  app
ning  curves  g
learn
peared  to  hav
und  the 20th cy
arou
ycle of  trainin
ng, but would 
not  truly conv
verge 
s.  In  the  int
unti
l  approximat
ely  70  cycles
erest  of  time
e,  we 
Such 
n  100  cycles. 
terations  upon
op  training  ite
ced  caps  to  st
plac
local 
he algorithm to
a failure for th
ations imply a
situa
o converge at
still 
prisingly,  oft
ma,  but  sur
opti
ften  the  resu
ulting  model 
capt
tures the desig
gnated action v
very well. 
lts. For num  s
ery  good  resu
ten  yielded ve
Simulation oft
S
states 
  same  parame
ols  =  72  (the 
0,  num  symbo
=  30
eter  values  fo
or  the 
curv
ves in Figure 8
8), we achieve
ed the followin
ng: 

 

pear  to  increas
time  does  app
the  training  ti
As  expected, 
A
se  for 
re states within
mor
n the system. 
For very sma
all number of s
states, 
such
h  as  in  the  r
ange  of  1  to
o  5,  however,
,  the  differen
nce  is 
omplete  in  rou
mputation  is co
h  that  the com
ligible enough
negl
ughly 
the s
same amounts
s of time.  
 

gnition by Eac
Gesture Recog
Figure 10: G
ch Classifier

 

BLE III.  GEST
TA
ES=30, SYMBOLS
ON RATES (STATE
TURE RECOGNITIO
S=72) 
Tr
rue 
Lab
bels 
 
Pun
nch 

Dete
ected Actions 
Swing 
0% 

Punch 
92.86% 
 

Slap 
3.57% 

Wave 
0% 

0% 

0% 

False
e 
3.57%
% 

8.33%
% 

2.54%
% 

5.37%
% 

97.46% 

0% 

9
4.63% 

91.67% 

0% 

0% 

0% 

0% 

0% 

0% 

Slap
p 

Swi
ing 

Wa
ave 

Fals
se 

10.46% 
 

30.54% 

1.26% 

1
3.39% 

44.35%
% 

that  the design
one can see  t
se  two charts, 
Based on  thes
B
nated 
the  correspon
ery  well  by  t
recognized  ve
on  is  being  r
actio
nding 
ry  single  case
gnition  in  ever
ast 90%  recog
M, with  at  lea
HMM
e. For 
the 
‘negative’  exa
ample,  we  se
ee  that  the  rec
cognition  is  m
much 
more
with  none  ha
the  actions,  w
between  all 
e  distributed 
aving 
ecognition, wh
e than 50% re
more
hich is good. 
A. Ef
Effect of Numb
ber of States 
I
It  would  be  in
nteresting  to  o
observe  the  ef
ffect  of  numb
ber  of 
orize  that  the  m
ne  might  theo
del  results.  On
es  on  our  mod
state
more 
ain  to  be  bette
del  should  tra
re  are,  the  mod
den  states  ther
hidd
er,  up 
es  might  bec
o  many  state
re  having  too
to  a
a  point  wher
come 
redu
undant  if  the 
action  set  is 
too  basic.  O
On  the  other  h
hand, 
trai
may  slow  do
the 
ny  states  m
too  man
havi
ng 
own 
ining 
signi
n  needed  for
a  computatio
e  to  the  extra
ificantly,  due
r  the 
too  few  state
es  should  ma
sely,  having 
rices.  Convers
matr
ake  it 
f  our 
diffi
cult  for  the 
system  to  d
distinguish  be
etween  all  of
diffe
first 
erent  actions, 
leading  to  m
mixed  up  acc
curacies.  We 
ore the effect 
has on the train
this number h
expl
ning runtime.
 

(Symbols=128
um. of States (
ain Time vs Nu
Figure 11: Tra
F
8) 

 

 

tes (Symbols=
s Num. of Stat
gnition Rate vs
ure 12: Recog
Figu
128) 
of  states  is per
y  the number o
n accuracy by 
The effect on
rhaps 
mor
re surprising. A
As expected,  t
the  improvem
ment  in accura
acy as 
num
mber  of  states 
increases  stag
gnates. Howev
ver,  it  appears
s  that 
our recognition
 very small, o
is reduced to 
en the number
whe
n rate 
ave’  action  w
t  for  the  ‘wa
gh,  all  except
ains  very  hig
rem
which 
drop
mbers,  event
er  state  num
lowe
ps  significan
ntly 
in 
tually 
beco
oming confuse
ed for another
r action (not sh
hown in figur
res). 
ve  result  ca
ounter  intuiti
that  this  co
We  believe 
an  be 
ially explaine
we have, say,
that although 
d by the fact t
part
, only 
a  sin
We  believe  tha
of  symbols.  W
e  have  a  lot  o
ngle  state,  we
at  our 
four
r  actions  are  d
different  enou
ugh  that  they 
do  not  have  m
many 
ls.  Thus,  dur
ring  the  likeli
hared  symbol
rlapping  or  sh
over
ihood 
bility  is  alwa
nsition  probab
ough  the  tran
ulation,  altho
calc
ays  1 
on probabilitie
f),  the emissio
oning  to  itself
(one
e state  transiti
es for 
each
h  symbol  can 
still  be  differ
rent.  This  allo
ows  for  the  tra
ained 
mod
dels  to  classi
ify  our  valid
dation  data  b
ased  on  emi
ission 
hen  dropped,  l
e’  accuracy  th
ne.  The  ‘wave
babilities  alon
prob
likely 
with another ac
on  symbols w
a  few commo
ause  it  shared 
beca
ction, 
er.  In 
more frequent
e recognized m
ugh for it to b
enou
tly as the othe
real-
prac
ctice,  when  th
his  one-state  m
model  was  ap
pplied  to  our 
was  consist
only  the  ‘pu
e  program,  o
time
unch’  action 
tently 
ected.  
dete
determined 
Based  on  ou
that  the  opti
ur  data,  we 
imum 
cular  set of  act
num
mber of  states 
tions  is  aroun
nd 30. 
for our partic
e  recognized  f
our  actions  are
where  all of o
s  is  the point w
This
fairly 
dels are able  t
l, and our mod
well
to distinguish 
the noise bett
ter as 
more false pos
l, preventing m
well
sitives. 
B. E
Effect of Numb
ber of Symbols
s 
er  of 
eep  on  numb
formed  a  swe
we  also  perfo
In  addition,  w
I
entation =  2,  a
ping Z-segme
8  to  126),  keep
mbols  (from  18
sym
and X 
*Y*Z  =  numb
,  such  that X*
ions  the  same,
Y-segmentati
and 
ber  of 
sym
mbols.  We  pe
erformed  a  r
runtime  analy
ysis  as  well,
,  but 
d  to have negli
mbols  seemed
number of  sym
prisingly,  the n
surp
igible 
imp
act on the run
time, and thus
s the chart is n
not included. 

C. A
Additional Ges
stures 
ibrary, we  incl
our gesture  li
T
To  include mo
ore variety  in 
luded 
’ and a  ‘circle
two 
more actions
, a  ‘fist pump
e’ drawn  in m
midair. 
is  an  action
‘fist  pump’
The 
ly  only  span
on  that  mainl
ns  Y-
coor
rdinates, wher
reas the circle 
spans both X 
and Y at leng
gth.   

BLE IV.  GEST
TAB
ES=30, SYMBOLS
ON RATES (STATE
TURE RECOGNITIO
S=256) 
Tr
rue 
Lab
bels 
 

Detected Actions
D
 
ng  Wave 
Swin
Fist 
0
0 
0 
0.81 

Pun
nch 

Sla
ap 

Sw

ing 

Wa
ave 

Fis
t 

Cir
rcle 

Punch 
93.55 

Slap 
0 

Circle 
0 

False 
5.65 

0 

0 

0 

1.0 

0 

99.14 

0 

0 

0 

0 

0 

99.3
30 

0 

0 

12.7
75 

0 

0 

94.44 

0 

0 

0 

0 

0 

7
71.0 

0 

0 

0 

0 

0.86 

0.70 

5.56 

28.0 

0 

58.82 

28.43 

3.41 
17.61 
0 
21.02 
4
4.55 
1.14 
52.27 
Fal
lse 
ecognition  rem
mains 
ew data  that  re
n  from  this ne
It  can be  seen
ess  so  for  our
estures,  but  le
y  good  for  th
very
e  baseline  ge
r  new 
addi
itions.  This  m
may  be  due  to 
there  being  le
ess  variance  i
in  the 
they 
n  data  for  the
train
ning/validation
e  fist  pump  a
and  circle,  as 
hereas  the bas
seline 
individual (wh
by  the same  i
e both  trained
were
ast). Secondly
re  team,  at  lea
rts of  the  entir
olved  the  effor
invo
y,  it  is 
some 
did  involve 
e  ‘negative’  d
sible  that  the
poss
data,  which 
ently  containe
rand
dom  moveme
nts,  inadverte
ed  fist  pump
p  and 
e  baseline  ges
d  avoiding  the
this  data  tried
le  actions,  as 
circl
stures 
was  collected
wo  new  inclus
made  the  tw
d  before  we 
but 
sions. 
Othe
siphoned  som
hat  ‘swing’  s
akes  sense  th
erwise,  it  ma
me  of 
‘circ
cle’s  recogniti
ion,  as  swing 
g  shares  rough
hly  half  of  cir
rcle’s 
gest
ture. 

VIII. CON
NCLUSION 
hat  HMMs  ar
y  conclude  th
From  this  pro
oject,  we  may
F
re  an 
and 
effe
ctive  and  ef
fficient  meth
hod  of  both 
recognizing 
prove  this  con
ncept, 
o  further  imp
n  gestures.  To
sifying  human
clas
we m
ture set beside
phisticated feat
ild a more sop
may try to bui
es the 
right  hand  tha
dinates  of  the 
d  XYZ  coord
ple  normalize
simp
at  we 
curr
rently  use.  Th
his  may  allow 
w  greater  diffe
erentiation  bet
tween 
sting  to  add  m
ould  be  intere
ddition,  it  wo
h  action.  In  ad
each
many 
gnize 
ssifier  to  reco
allow  our  clas
a  points  and  a
re  Kinect  data
mor
tire  body. We
volving  the  ent
d  gestures  invo
re  complicated
mor
e may 
also
  extend  our  r
recording  time
e  beyond  a  se
econd.  This,  a
again, 
allow
ws for more c
omplex recog
gnitions, but al
lso complicate
es the 
ecognize  actio
s  ability  to  re
g  the  system’s
cess  by  testing
proc
ons  of 
erent duration
diffe
. 
a  lot  by  recru
e  our  results  a
sibly  improve
W
We  may  poss
uiting 
man
ny  more  peop
le  to  perform
m  actions  for 
us,  merely  ad
dding 
trained  models
t,  preventing  t
to  our  dataset,
re  variance  int
mor
s  that 
too constraine
are t
d. 
optimize  the  H
e  to  further  o
y  be  desirable
Finally,  it  ma
F
HMM 
train
ning  and  expe
ectation-maxim
mization  algor
rithms  to  allow
w  the 
o wait 
d  of  having  to
dback,  instead
ear  instant  feed
em  to  give  ne
syst
a de
truly 
elay of approx
ximately one s
second. This w
would make  it 
application. 
ble for an HCI 
viab
ACKNOWL
LEDGMENT 
e  to  thank  Pro
W
We would  lik
ofessor Andre
ew Ng  for  teac
ching 
TAs  for helpin
well  as  all  the T
29  class,  as w
h  a  large CS22
such
ng us 
out t
throughout the
e quarter. 

 

mbols (States=
vs Num. of Sym
gnition Rate v
gure 13: Recog
Fig
=30) 
Since  a  low
wer  number  o
of  symbols 
equates  to  l
ower 
ould cause  fe
ature 
mented,  this w
ms of our segm
lution  in  term
reso
ar  to  get  clust
tered 
be  very  simil
nts  that  may  n
poin
not  originally 
.  Indeed,  Figu
ure  12  does  s
ng  the  model
ther,  confusin
toge
show 
that 
as  the  numbe
er  of  symbols
s  decrease,  th
he  recognition
n  rate 
for  w
s  well.  Curio
ficantly  fall  a
wing  do  signif
wave  and  sw
ously, 
possibly  due  to
ecognizable,  p
emain  very  re
ch  and  slap  re
punc
o  the 
that  change  i
two  actions  t
that  these  ar
fact 
re  the  only  t
in  Z-
coor
rdinates,  whic
ch  we  did  not 
alter  in  terms
s  of  segmenta
ation. 
Conv
versely,  it  se
eems  that  the
e  more  symb
ols  there  are
e,  the 
ate  can  becom
me.    Perhaps  i
recognition  r
er  the  overall 
bette
if we 
s  and  more  c
more  feature
uired,  the  run
clustering  requ
had 
ntime 
wou
icular case it i
ut in our parti
ramatically, bu
uld increase dr
is not 
evid
dent.  Thus,  fo
or  our  case,  th
he  optimal  nu
umber  of  sym
mbols 
on  keeping  al
more,  based  o
und  98  and  m
ms  to  be  arou
seem
ll  the 
gnition rates a
reco
above 90%. 
I. REAL TIME I
IMPLEMENTAT
VII
TION 
A. Im
mplementation
n Details 
we  interfaced
d  the 
r  MATLAB 
F
Following  our
simulations, 
MATLAB  v
pre-
models  were 
via  C#.  The 
Kine
ect  API  with 
nvolved  in  ca
train
ned,  with  the 
code  only  in
apturing  the  s
single 
TLAB  modul
it  to  the  MAT
data,  sending 
ond  worth  of  d
seco
le  for 
turned label. 
btaining the re
ulation and ob
calcu
state only whe
valid starting s
egins picks a v
Our system be
O
en the 
difference2  <  0
hand
d  has  been  sta
able  for  a  wh
hile  (with  a  d
0.01) 
betw
ween frames. I
If the frame re
emains stable a
after this poin
nt, we 
ce  is  beyond
the  differen
cording  until 
not  begin  rec
do  n
d  the 
cond, we will 
s beyond a sec
movement last
shold. If the m
thres
only 
ocessing, assum
take 
the most rece
ent 30 frames f
for feature pro
ming 
the  u
user  wants  to
o  finalize  thei
ir  gesture  and
d  that  the  cli
ipped 
ch  a  mechanis
eason  for  suc
noise.  The  re
ion  is  simply 
porti
sm  is 
our  actions  us
ocity  or with  s
with  zero  velo
sually  begin w
that 
slight 
jitter
ing  falsely.  T
et  off  recordi
potentially  se
r  that  could 
These 
eria  allow  us
crite
s  to  have  m
more  accurat
e  and  contr
rolled 
reco
rdings [5].  
B. O
Observations 
  symbols  is  f
states  and  98
Our  system  tr
O
rained  on  30 
fairly 
nizing  the corr
accu
urate  in  recogn
rect gesture an
nd seldom con
nfuse 
cur  are  due  to
rs  that  do  occ
The  few  error
for  another.  T
one 
o  the 
syste
nt  as 
ze  a  movemen
le  to  recogniz
s  being  unabl
em  sometimes
m  is  a  lot  of  t
n.  This  problem
ained  to  learn
it  has  been  tra
one 
times 
due 
to  the  user  n
not  performin
ng  the  action 
within  a  sec
cond, 
r needs to be r
times, the user
wing.’ Other t
icularly for ‘sw
parti
rather 
e  body  they  p
relative  to  the
ise  in  where  r
prec
perform  the  ac
ction, 
due t
to the way in w
which we defi
fined our featu
ures.  

REFERENCES 
[1]  L.  R.  Rabiner,  “A  Tutorial  on  Hidden  Markov  Models  and 
Selected  Applications  in  Speech  Recognition,”  Proceedings  of 
the IEEE, vol. 77, no. 2, February 1989. 
[2]  Z.  Ghahramani.  “EM  for  Hidden  Markov  Models  for  Discrete-
Valued 
Observations” 
[Online]. 
Available: 
http://mlg.eng.cam.ac.uk/zoubin/software.html 
[3]  J.  C.  Hall.  (2011,  Dec  22).  “How  to  Do  Gesture  Recognition 
With Kinect Using Hidden Markov Models  (HMMs)”  [Online]. 

Available: 
http://www.creativedistraction.com/demos/gesture-
recognition-kinect-with-hidden-markov-models-hmms/ 
[4]  H.  Lee  and  J.  Kim,  “An  HMM-Based  Threshold  Model 
Approach  for  Gesture  Recognition,”  IEEE  Transactions  on 
Pattern  Analysis  and  Machine  Intelligence,  vol.  21,  no.  10, 
October 1999. 
[5]  Y.  Wang,  C.  Yang,  X.  Wu,  S.  Xu  and  H.  Li,  “Kinect  Based 
Dynamic  Hand  Gesture  Recognition  Algorithm  Research,”  4th 
International  Conference  on 
Intelligent  Human-Machine 
Systems and Cybernetics, 2012. 

 

