High-Order Multi-Task Feature Learning to Identify
Longitudinal Phenotypic Markers for Alzheimer’s
Disease Progression Prediction

Hua Wang, Feiping Nie, Heng Huang,
Department of Computer Science and Engineering,
University of Texas at Arlington, Arlington, TX 76019
{huawangcs, feipingnie}@gmail.com, heng@uta.edu

Jingwen Yan, Sungeun Kim, Shannon L. Risacher, Andrew J. Saykin, Li Shen, for the ADNI∗
Department of Radiology and Imaging Sciences,
Indiana University School of Medicine, Indianapolis, IN 46202
{jingyan, sk31, srisache, asaykin, shenli}@iupui.edu

Abstract

Alzheimer’s disease (AD) is a neurodegenerative disorder characterized by pro-
gressive impairment of memory and other cognitive functions. Regression analy-
sis has been studied to relate neuroimaging measures to cognitive status. However,
whether these measures have further predictive power to infer a trajectory of cog-
nitive performance over time is still an under-explored but important topic in AD
research. We propose a novel high-order multi-task learning model to address this
issue. The proposed model explores the temporal correlations existing in imag-
ing and cognitive data by structured sparsity-inducing norms. The sparsity of the
model enables the selection of a small number of imaging measures while main-
taining high prediction accuracy. The empirical studies, using the longitudinal
imaging and cognitive data of the ADNI cohort, have yielded promising results.

1 Introduction

Neuroimaging is a powerful tool for characterizing neurodegenerative process in the progression
of Alzheimer’s disease (AD). Neuroimaging measures have been widely studied to predict disease
status and/or cognitive performance [1, 2, 3, 4, 5, 6, 7]. However, whether these measures have
further predictive power to infer a trajectory of cognitive performance over time is still an under-
explored yet important topic in AD research. A simple strategy typically used in longitudinal studies
(e.g., [8]) is to analyze a single summarized value such as average change, rate of change, or slope.
This approach may be inadequate to distinguish the complete dynamics of cognitive trajectories
and thus become unable to identify underlying neurodegenerative mechanism. Figure 1 shows a
schematic example. Let us look at the plot of Cognitive Score 2. The red and blue groups can be
easily separated by their complete trajectories. However, given very similar score values at the time
points of t0 and t3, any of the aforementioned summarized values may not be sufﬁcient to identify the
group difference. Therefore, if longitudinal cognitive outcomes are available, it would be bene ﬁcial
to use the complete information for the identiﬁcation of rel evant imaging markers [9, 10].

∗Data used in preparation of this article were obtained from the Alzheimer’s Disease Neuroimaging Ini-
tiative (ADNI) database (adni.loni.ucla.edu). As such, the investigators within the ADNI contributed to
the design and implementation of ADNI and/or provided data but did not participate in analysis or writ-
ing of this report. A complete listing of ADNI investigators can be found at: http://adni.loni.ucla.edu/wp-
content/uploads/how to apply/ADNI Acknowledgement List.pdf.

1

Figure 1: Longitudinal multi-task regression of cognitive trajectories on MRI measures.

However, how to identify the temporal imaging features that predict longitudinal outcomes is a chal-
lenging machine learning problem. First, the input data and response measures often are high-order
tensors, not regular data/label matrix. For example, both input neuroimaging measures (samples ×
features × time) and output cognitive scores (samples × scores × time) are 3D tensors. Thus, it is
not trivial to build the longitudinal learning model for tensor data. Second, the associations between
features and a speciﬁc task ( e.g. cognitive score) at two consecutive time points are often correlated.
How to efﬁciently include such correlations of association s cross time is unclear. Third, some longi-
tudinal learning tasks are often interrelated to each other. For example, it is well known that [3, 4] in
RAVLT assessment, the total number of words remembered by the participants in the ﬁrst 5 learning
trials heavily impacts the total number of words which can be recalled in the 6th learning trial, and
the results of these two measures both partially determines the ﬁnal recognition rate after 30 minutes
delay. How to integrate such tasks correlations into longitudinal learning model is under-explored.

In this paper, we focus on the problem of predicting longitudinal cognitive trajectories using neu-
roimaging measures. We propose a novel high-order multi-task feature learning approach to iden-
tify longitudinal neuroimaging markers that can accurately predict cognitive scores over all the time
points. The sparsity-inducing norms are introduced to integrate the correlations existing in both
features and tasks. As a result, the selected imaging markers can fully differentiate the entire lon-
gitudinal trajectory of relevant scores and better capture the associations between imaging markers
and cognitive changes over time. Because the structured sparsity-inducing norms enforce the cor-
relations along two directions of the learned coefﬁcient te nsor, the parameters in different sparsity
norms are tangled together by distinct structures and lead to a difﬁcult optimization problem. We
derive an efﬁcient algorithm to solve the proposed high-ord er multi-task feature learning objective
with closed form solution in each iteration. We further prove the global convergence of our algo-
rithm. We apply the proposed longitudinal multi-task regression method to the ADNI cohort. In
our experiments, the proposed method not only achieves competitive prediction accuracy but also
identiﬁes a small number of imaging markers that are consist ent with prior knowledge.

2 High-Order Multi-Task Feature Learning Using Sparsity-Inducing Norms

For AD progression prediction using longitudinal phenotypic markers, the input imaging features
are a set of matrices X = {X1 , X2 , . . . , XT } ∈ Rd×n×T corresponding to the measurements at
T consecutive time points, where Xt is the phenotypic measurements for a certain type of imaging
markers, such as voxel-based morphometry (VBM) markers (see details in Section 3) used in this
study, at time t (1 ≤ t ≤ T ). Obviously, X is a tensor data with d imaging features, n subject
samples and T time points. The output cognitive assessments for the same set of subjects are a set of
matrices Y = {Y1 , Y2 , . . . , YT } ∈ Rn×c×T for a certain type of the cognitive measurements, such
as RAVLT memory scores (see details in Section 3), at the same T consecutive time points. Again,
Y is a tensor data with n samples, c scores, and T time points. Our goal is to learn from {X , Y } a
model that can reveal the longitudinal associations between the imaging and cognitive trajectories,
by which we expect to better understand how the variations of different regions of human brains
affect the AD progression, such that we can improve the diagnosis and treatment to the disease.

Prior regression analyses typically study the associations between imaging features and cognitive
measures at each time point separately, which is equivalent to assume that the learning tasks, i.e.,
cognitive measures, at different time points are independent. Although this assumption can sim-
plify the problem and make the solution easier to obtain, it overlooks the temporal correlations of
imaging and cognitive measures. To address this, we propose to jointly learn a single longitudinal
regression model for the all time points to identify imaging markers which are associated to cog-

2

T i m e

T

BT
BT

…

s
e
r
u
t
a
e
F

d

B1

Tasks
c
B = fB1 ; : : : ; BT g

d

B1

B2

… …

BT

c

TB
1

TB
2

… …

B

T

T

c x T
B(1) = unfold(1) (B) = [B1 ; : : : ; BT ]

d x T
B(2) = unfold(2) (B) = #BT
T $
1 ; : : : ; B T

Figure 2: Left: visualization of the coefﬁcient tensor B learned for the association study on longi-
tudinal data. Middle: the matrix unfolded from B along the ﬁrst mode (feature dimension). Right:
the matrix unfolded from B along the second mode (task dimension).

nitive patterns. As a result, we aim to learn a coefﬁcient ten sor (a stack of coefﬁcient matrices)
B = {B1 , · · · , Bn} ∈ Rd×c×T , as illustrated in the left panel of Figure 2, to reveal the temporal
changes of the coefﬁcient matrices. Given the additional ti me dimension, our problem becomes a
difﬁcult high-order data analysis problem, which we call as high-order multi-task learning.

2.1 Longitudinal Multi-Task Feature Learning

min
B

2

F

t ||2
||bk
2 .

(1)

+ α kBk2
2

=

t Bt − Yt ||2
||X T
F + α

In order to associate the imaging markers and the cognitive measures, the multivariate regression
model was used in traditional association studies, which minimizes the following objective:
d
T
T
B ⊗1 X T − Y (cid:13)(cid:13)(cid:13)
J0 = (cid:13)(cid:13)(cid:13)
Xk=1
Xt=1
Xt=1
where bk
t denotes the k -th row of coefﬁcient matrix Bt at time t. Apparently, the objective J0 in
Eq. (1) can be decoupled for each individual time point. Therefore it does not take into account the
longitudinal correlations between imaging features and cognitive measures. Because our goal in the
association study is to select the imaging markers which are connected to the temporal changes of
all the cognitive measures, the T groups of regression tasks at different time points should not be
decoupled and have to be performed simultaneously. To achieve this, we select imaging markers
correlated to all the cognitive measures at all time points by introducing the sparse regularization
[11, 12, 13] into the longitudinal data regression and feature selection model as follows:
vuut
d
T
T
T
Xk=1
Xt=1
Xt=1
Xt=1
t Bt − Yt ||2
||X T
F + α (cid:13)(cid:13)B(1)(cid:13)(cid:13)2,1
where we denote unfoldk (B ) = B(k) ∈ RIk×(I1 ...Ik−1 Ik+1 ...In ) as the unfolding operation to a gen-
eral n-mode tensor B along the k -th mode, and B(1) = unfold1 (B ) = [B1 , . . . , BT ] as illustrated
in the middle panel of Figure 2. By solving the objective J1 , the imaging features with common
in ﬂuences across all the time points for all the cognitive me asures will be selected due to the second
term in Eq. (2), which is a tensor extension of the widely used ℓ2,1 -norm for matrix.

t Bt − Yt ||2
||X T
F + α

t ||2
||bk
2 =

min
B

J1 =

,

(2)

2.2 High-Order Multi-Task Correlations

The objective J1 in Eq. (2) couples all the learning tasks together, which, though, still does not ad-
dress the correlations among different learning tasks at different time points. As discussed earlier,
during the AD progression, many cognitive measures are interrelated together and their effects dur-
ing the process could overlap, thus it is necessary to further develop the objective J1 in Eq. (2) to
leverage the useful information conveyed by the correlations among different cognitive measures.
In order to capture the longitudinal patterns of the AD data, we consider two types of tasks corre-
lations. First, for an individual cognitive measure, although its association to the imaging features
at different stages of the disease could be different, its associations patterns at two consecutive time
points tend to be similar [9]. Second, we know that [4, 14] during the AD progression, different
cognitive measures are interrelated to each other. Mathematically speaking, the above two types of
correlations can both be described by the low ranks of the coefﬁcient matrices unfolded from the

3

J2 =

min
B

coefﬁcient tensor along different modes. Thus we further de velop our learning model in Eq. (2) to
impose additional low rank regularizations to exploit these task correlations.
Let B(2) = unfold2 (B ) = (cid:2)B T
T (cid:3) as illustrated in the right panel of Figure 2, we minimize
1 , . . . , B T
the ranks of B(1) and B(2) to capture the two types of task correlations, one for each type, as follows:
T
Xt=1
t Bt − Yt ||2
||X T
+ (cid:13)(cid:13)B(2)(cid:13)(cid:13)∗ (cid:1) ,
+ β (cid:0)(cid:13)(cid:13)B(1)(cid:13)(cid:13)∗
F + α (cid:13)(cid:13)B(1)(cid:13)(cid:13)2,1
where k·k∗ denote the trace norm of a matrix. Given a matrix M ∈ Rn×m and its singular
values σi (1 ≤ i ≤ min (n, m)), the trace norm of M is de ﬁned as kM k∗ = Pmin (n,m)
σi =
i=1
1
Tr (cid:0)M M T (cid:1)
2 . It has been shown that [15, 16, 17] the trace-norm is the best convex approximation
of the rank-norm. Therefore, the third and fourth terms of J2 in Eq. (3) indeed minimize the rank of
the unfolded learning model B , such that the two types of correlations among the learning tasks at
different time points can be utilized. Due to its capabilities for both imaging marker selection and
task correlation integration on longitudinal data, we call J2 de ﬁned in Eq. (3) as the proposed High-
Order Multi-Task Feature Learning model, by which we will study the problem of longitudinal data
analysis to predict cognitive trajectories and identify relevant imaging markers.

(3)

2.3 New Optimization Algorithm and Its Global Convergence

Despite its nice properties, our new objective J2 in Eq. (3) is a non-smooth convex problem. Some
existing methods can solve it, but not efﬁciently. Thus, in t his subsection we will derive a new
efﬁcient algorithm to solve this optimization problem with global convergence proof, where we
employ an iteratively reweighted method [18] to deal with the non-smooth regularization terms.
Taking the derivative of the objective J2 in Eq. (3) with respect to Bt and set it as 0, we obtain1 :
ˆD(cid:17) = 0 ,
t Bt − 2Xt Yt + 2αDBt + 2β (cid:16) ¯DBt + Bt
2XtX T
(1) (cid:17)−1/2
2 (cid:16)B(1)B T
, ¯D = 1
1
where D is a diagonal matrix with D (i, i) =
2qPT
t k2
t=1kbk
2
(2) (cid:17)−1/2
2 (cid:16)B(2)B T
1
. We can re-write Eq. (4) as following:
(cid:16)XtX T
t + αD + β ¯D(cid:17) Bt + βBt
which is a Sylvester equation and can be solved in closed form. When the time t changes from 1 to
T , we can calculate Bt (1 ≤ t ≤ T ) by solving Eq. (5). Because D , ¯D and ˆD are dependent on B
and can be seen as latent variables, we propose an iterative algorithm to obtain the global optimum
solutions of Bt (1 ≤ t ≤ T ), which is summarized in Algorithm 1.
Convergence analysis of the new algorithm. We ﬁrst prove the following two useful lemmas, by
which we will prove the convergence of Algorithm 1.

ˆD = XtYt ,

and ˆD =

(4)

(5)

Lemma 1 Given a constant α > 0, for function f (x) = x − x2
2α , we have f (x) ≤ f (α) for any
x ∈ R. The equality holds if and only if x = α.

The proof of Lemma 1 is obvious and skipped due to space limit.

2

Lemma 2 Given two semi-positive de ﬁnite matrices A and ˜A, the following inequality holds:
1
1
1
1
tr (cid:16) ˜AA− 1
tr (cid:16)AA− 1
tr (cid:16) ˜A
2 (cid:17) −
2 (cid:17) ≤ tr (cid:16)A
2 (cid:17) −
2 (cid:17) .
2
The equality holds if and only if A = ˜A.
1 kM k2,1 is a non-smooth function of M and not differentiable when one of its row mi = 0. Following
[18], we introduce a small perturbation ζ > 0 to replace kM k2,1 by Pi qkmi k2
+ ζ , which is smooth and
2
differentiable with respect to M . Apparently, Pi qkmi k2
+ ζ is reduced to kM k2,1 when ζ → 0. In the
2
sequel of this paper, we implicitly apply this replacement for all k·k2,1 . Following the same idea, we also
1
introduce a small perturbation ξ > 0 to replace kM k∗ by tr (cid:0)M M T + ξ I (cid:1)
2 for the same reason.
4

(6)

Algorithm 1: A new algorithm to solve the optimization problem in Eq. (3).
Data: X = [X1 , X2 , . . . , XT ] ∈ Rd×n×T , Y = [Y1 , Y2 , . . . , YT ] ∈ Rn×c×T .
1. Set g = 1. Initialize B (1)
t ∈ Rd×c (1 ≤ t ≤ T ) using the linear regression results at each individual time point.
repeat
2. Calculate the diagonal matrix D(g) , where the i-th diagonal element is computed as D(g) (i, i) =
(2) (cid:17)T (cid:19)− 1
(1) (cid:17)T (cid:19)− 1
2 (cid:18)B (g)
2 (cid:18)B (g)
2 ; calculate ˆD(g) = 1
2 .
(2) (cid:16)B (g)
(1) (cid:16)B (g)
calculate ¯D(g) = 1
(1 ≤ t ≤ T ) by solving the Sylvester equation in Eq. (5).

1
2sPT
t=1 (cid:13)(cid:13)(cid:13)(cid:13)

b

(g),k
t

;

2
(cid:13)(cid:13)(cid:13)(cid:13)
2

3. Update B (g+1)
t
4. g = g + 1.
until Converges
Result: B = [B1 , B2 , . . . , BT ] ∈ Rd×c×T .

Proof : Because A and ˜A are two semi-positive de ﬁnite matrices and we know that
tr (cid:16) ˜AA(cid:17), we can derive:
1
2 + ˜AA− 1
1
2 (cid:17) = tr (cid:16)A− 1
1
tr (cid:16)A
4 (cid:16)A + ˜A − A
2 − 2 ˜A
2 ˜A
4 (cid:19) = (cid:13)(cid:13)(cid:13)
tr (cid:18)A− 1
2 (cid:17)2
2 (cid:17)(cid:13)(cid:13)(cid:13)
1
1
A− 1
1
A− 1
4 (cid:16)A
4 (cid:16)A
2 − ˜A
F
by which we have the following inequality tr (cid:16) ˜A
2 tr (cid:16) ˜AA− 1
2 tr (cid:16)A
2 (cid:17) ≤ 1
2 (cid:17) − 1
1
alent to Eq. (6) and completes the proof of Lemma 2.

1
2 − ˜A

1
2 − ˜A

1
2 (cid:17) A− 1
4 (cid:17) =

≥ 0 ,

1
2 A

2

tr (cid:16)A ˜A(cid:17) =

(7)

2 (cid:17), which is equiv-
1
(cid:3)

Now we prove the convergence of Algorithm 1, which is summarized by the following theorem.

Theorem 1 Algorithm 1 monotonically decreases the objective of the problem in Eq. (3) in each
iteration, and converges to the globally optimal solution.

L(g+1) + α

Proof : In Algorithm 1, we denote the updated Bt in each iteration as ˜Bt . We also denote the
t B (g)
least square loss in the g -th iteration as L(g) = PT
F . According to Step 3 of
t=1 ||X T
t − Yt ||2
Algorithm 1 we know that the following inequality holds:
T
T
T
t (cid:17) ≤
¯D ˜Bt(cid:17) + β
tr (cid:16) ˜Bt
tr (cid:16) ˜B T
t D ˜Bt (cid:17) + β
tr (cid:16) ˜B T
Xt=1
Xt=1
Xt=1
ˆD ˜B T
t
T
T
T
t (cid:17) .
tr (cid:16)Bt
¯DBt(cid:17) + β
tr (cid:16)B T
t DBt (cid:17) + β
tr (cid:16)B T
Xt=1
Xt=1
Xt=1
ˆDB T
t
Denote the updated B(1) as ˜B(1) , and the updated B(2) as ˜B(1) , from Eq. (8) we can derive:
ˆD(cid:17) ≤
¯D(cid:17) + β tr (cid:16) ˜B(2)
L(g+1) + α tr (cid:16) ˜B T
(1)D ˜B(1) (cid:17) + β tr (cid:16) ˜B(1)
˜B T
˜B T
(2)
(1)
T
T
T
tr (cid:16)B(2)B T
¯D(cid:17) + β
tr (cid:16)B(1)B T
tr (cid:16)B T
(1)DB(1) (cid:17) + β
Xt=1
Xt=1
Xt=1
L(g) + α
(1)
(2)
According to the de ﬁnitions of D , ¯D and ˆD , we have:

ˆD(cid:17) .

L(g) + α

(9)

(8)

+

+

||2
2

||2
2

||2
2

β
2

β
2

α
2

α
2

L(g) +

d
Xk=1

L(g+1) +

tr (cid:18) ˜B(1)

(1) (cid:17)− 1
2 (cid:19) +
(1) (cid:16)B(1)B T
˜B T
(1) (cid:17)− 1
tr (cid:18)B(1)B T
2 (cid:19) +
(1) (cid:16)B(1)B T

d
t=1 ||b(g+1),k
PT
Xk=1
t
qPT
t=1 ||b(g),k
t
(g),k
PT
||2
t=1 ||b
2
t
qPT
t=1 ||b(g),k
t
Then according to Lemma 1 and Lemma 2, the following three inequalities hold:
vuut
≤ vuut
t=1 ||b(g),k
t=1 ||b(g+1),k
2 − PT
2 − PT
||2
||2
2
2
t
t
||2
||2
2qPT
2qPT
t=1 ||b(g),k
t=1 ||b(g),k
t
t
5

(g+1),k
||b
t

T
Xt=1

T
Xt=1

(g),k
||b
t

β
2

||2
2

β
2

tr (cid:18) ˜B(2)

(2)(cid:17)− 1
2 (cid:19) ≤
(2) (cid:16)B(2)B T
˜B T
(2) (cid:17)− 1
tr (cid:18)B(1)B T
2 (cid:19) .
(1) (cid:16)B(2)B T
(10)

.

(11)

||2
2

˜B(1)

˜B(2)

tr (cid:16) ˜B(1)

tr (cid:16) ˜B(2)

(1) (cid:17) − tr (cid:18) 1
˜B T
2
(2) (cid:17) − tr (cid:18) 1
˜B T
2

(1)(cid:17)− 1
2 (cid:19) ,
(1) (cid:16)B(1)B T
B(1)B T
(12)
(2)(cid:17)− 1
2 (cid:19) .
(2) (cid:16)B(2)B T
B(2)B T
(13)

(1)(cid:17)− 1
2 (cid:19) ≤ tr (cid:16)B(1)B T
(1) (cid:17) − tr (cid:18) 1
(1) (cid:16)B(1)B T
˜B T
2
(2)(cid:17)− 1
(2) (cid:17) − tr (cid:18) 1
2 (cid:19) ≤ tr (cid:16)B(2)B T
(2) (cid:16)B(2)B T
˜B T
2
Adding the both sides of of Eqs. (10 –13) together, we can obta in:
vuut
vuut
Thus, our algorithm decreases the objective value of Eq. (3) in each iteration. When the objective
value keeps unchange, Eq. (4) is satisﬁed,
i.e., the K.K.T. condition of the objective is satisﬁed.
Thus, our algorithm reaches one of the optimal solutions. Because the objective in Eq. (3) is a
convex problem, Algorithm 1 will converge to one of the globally optimal solution.
(cid:3)

(1) (cid:17) + β tr (cid:16)B(2)B T
2 + β tr (cid:16)B(1)B T
(2)(cid:17)
||2

2 + β tr (cid:16) ˜B(1)
||2

(1) (cid:17) + β tr (cid:16) ˜B(2)
˜B T

(2)(cid:17) ≤
˜B T

d
X
k=1

d
X
k=1

T
X
t=1

T
X
t=1

L(g+1) + α

||b(g),k
t

L(g+1) + α

||b(g+1),k
t

(14)

3 Experiments

We evaluate the proposed method by applying it to the Alzheimer’s Disease Neuroimaging Initiative
(ADNI) cohort to examine the association between a wide range of imaging measures and two types
of cognitive measures over a certain period of time. Our goal is to discover a compact set of imaging
markers that are closely related to cognitive trajectories.
Imaging markers and cognitive measures. Data used in this work were obtained from the ADNI
database (adni.loni.ucla.edu). One goal of ADNI has been to test whether serial MRI, PET,
other biological markers, and clinical and neuropsychological assessment can be combined to mea-
sure the progression of Mild Cognitive Impairment (MCI) and early AD. For up-to-date information,
see www.adni-info.org. We downloaded 1.5 T MRI scans and demographic information for
821 ADNI-1 participants. We performed voxel-based morphometry (VBM) on the MRI data by
following [8], and extracted mean modulated gray matter (GM) measures for 90 target regions of
interest (ROIs) (see Figure 3 for the ROI list and detailed de ﬁnitions of these ROIs in [3]). These
measures were adjusted for the baseline intracranial volume (ICV) using the regression weights de-
rived from the healthy control (HC) participants at the baseline. We also downloaded the longitudinal
scores of the participants in two independent cognitive assessments including Fluency Test and Rey’s
Auditory Verbal Learning Test (RAVLT). The details of these cognitive assessments can be found
in the ADNI procedure manuals2 . The time points examined in this study for both imaging markers
and cognitive assessments included baseline (BL), Month 6 (M6), Month 12 (M12) and Month 24
(M24). All the participants with no missing BL/M6/M12/M24 MRI measurements and cognitive
measures were included in this study. A total of 417 subjects were involved in our study, including
84 AD, and 191 MCI and 142 HC participants. We examined 3 RAVLT scores RAVLT TOTAL,
RAVLT TOT6 and RAVLT RECOG, and 2 Fluency scores FLU ANIM and FLU VEG.

3.1 Improved Cognitive Score Prediction from Longitudinal Imaging Markers

We ﬁrst evaluate the proposed method by applying it to the ADN I cohort for predicting the two types
of cognitive scores using the VBM markers, tracked over four different time points. Our goal in this
experiment is to improve the prediction performance.
Experimental setting. We compare the proposed method against its two close counterparts includ-
ing multivariate linear regression (LR) and ridge regression (RR). LR is the simplest and widely
used regression model in statistical learning and brain image analysis. RR is a regularized version
of LR to avoid over- ﬁtting. Due to their mathematical nature , these two methods are performed for

2http://www.adni-info.org/Scientists/ProceduresManuals.aspx

6

Table 1: Performance comparison for memory score prediction measured by RMSE.
Ours (ℓ2,1 -norm only) Ours (trace norm only)
TGL
RR
LR
0.301
0.306
0.318
0.341
0.380
0.171
0.165
0.155
0.144
0.147

RAVLT
Fluency

Ours
0.283
0.135

each cognitive measure at each time point separately, and thus they cannot make use of the temporal
correlation. We also compare our method to a recent longitudinal method, called as Temporal Group
Lasso Multi-Task Regression (TGL) [9]. TGL takes into account the longitudinal property of the
data, which, however, is designed to analyze only one single memory score at a time. In contrast,
besides imposing structured sparsity via tensor ℓ2,1 -norm regularization for imaging marker selec-
tion, our new method also imposes two trace norm regularizations to capture the interrelationships
among different cognitive measures over the temporal dimension. Thus, the proposed method is
able to perform association study for all the relevant scores of a cognitive test at the same time, e.g.,
our method can simultaneously deal with the three RAVLT scores, or the two Fluency scores.

To evaluate the usefulness of each component of the proposed method, we implement three versions
of our method as follows. First, we only impose the ℓ2,1 -norm regularization on the unfolded co-
efﬁcient tensor B along the feature mode, denoted as “ ℓ2,1 -norm only ”. Second, we only impose
the trace norm regularizations on the two coefﬁcient matric es unfolded from the coefﬁcient tensor B
along the feature and task modes respectively, denoted as “t race norm only ”. Finally, we implement
the full version of our new method that solves the proposed objective in Eq. (3). Note that, if no
regularization is imposed, our method is degenerated to the traditional LR method.

To measure prediction performance, we use standard 5-fold cross-validation strategy by computing
the root mean square error (RMSE) between the predicted and actual values of the cognitive scores
on the testing data only. Speciﬁcally, the whole set of subje cts are equally and randomly partitioned
into ﬁve subsets, and each time the subjects within one subse t are selected as the testing samples
and all other subjects in the remaining four subsets are used for training the regression models. This
process is repeated for ﬁve times and average results are rep orted in Table 1. To treat all regression
tasks equally, data for each response variable is normalized to have zero mean and unit variance.
Experimental results. From Table 1 we can see that the proposed method is consistently better than
the three competing methods, which can be attributed to the following reasons. First, because LR
and RR methods by nature can only deal with one individual cognitive measure at one single time
point at a time, they cannot bene ﬁt from the correlations acr oss different cognitive measures over the
entire time course. Second, although TGL method improves the previous two methods in that it does
take into account longitudinal data patterns, it still assumes all the test scores (i.e., learning tasks)
from one cognitive assessment to be independent, which, though, is not true in reality. For example,
it is well known that [3, 4] in RAVLT assessment, the total number of words remembered by the
participants in the ﬁrst 5 learning trials (RAVLT TOTAL) heavily impacts the total number of words
which can be recalled in the 6th learning trial (RAVLT TOT6), and the results of these two measures
both partially determines the ﬁnal recognition rate after 3 0 minutes delay (RAVLT RECOG). In
contrast, our new method considers all c learning tasks (c = 3 for RAVLT assessment and c =
2 for Fluency assessment) as an integral learning object as formulated in Eq. (3), such that their
correlations can be incorporated by the two imposed low-rank regularization terms.

Besides, we also observe that the two degenerated versions of the proposed method do not perform as
well as their full version counterpart, which provides a concrete evidence to support the necessities of
the component terms of our learning objective in Eq. (3) and justiﬁes our motivation to impose ℓ2,1 -
norm regularization for feature selection and trace norm regularization to capture task correlations.

3.2 Identiﬁcation of Longitudinal Imaging Markers

Because one of the primary goals of our regression analysis is to identify a subset of imaging markers
which are highly correlated to the AD progression re ﬂected b y the cognitive changes over time.
Therefore, we examine the imaging markers identiﬁed by the p roposed methods with respect to the
longitudinal changes encoded by the cognitive scores recorded at the four consecutive time points.

7

BL

M6

M12

M24

0.006

0.005

0.004

0.003

0.002

0.001

a
l
a
d
g
y
m
A
L

a
l
a
d
g
y
m
A
R

r
a
l
u
g
n
A
L

r
a
l
u
g
n
A
R

e
n
i
r
a
c
l
a
C
L

e
n
i
r
a
c
l
a
C
R

e
t
a
d
u
a
C
L

e
t
a
d
u
a
C
R

e
t
a
l
u
g
n
i
C
t
n
A
L

e
t
a
l
u
g
n
i
C
t
n
A
R

e
t
a
l
u
g
n
i
C
d
i
M
L

e
t
a
l
u
g
n
i
C
d
i
M
R

e
t
a
l
u
g
n
i
C
t
s
o
P
L

e
t
a
l
u
g
n
i
C
t
s
o
P
R

s
u
e
n
u
C
L

s
u
e
n
u
C
R

l
a
t
n
o
r
F
b
r
O
f
n
I
L

l
a
t
n
o
r
F
b
r
O
f
n
I
R

r
e
p
O
_
l
a
t
n
o
r
F
f
n
I
L

r
e
p
O
_
l
a
t
n
o
r
F
f
n
I
R

g
n
a
i
r
T
_
l
a
t
n
o
r
F
f
n
I
L

g
n
a
i
r
T
_
l
a
t
n
o
r
F
f
n
I
R

l
a
t
n
o
r
F
b
r
O
d
e
M
L

l
a
t
n
o
r
F
b
r
O
d
e
M
R

l
a
t
n
o
r
F
d
i
M
L

l
a
t
n
o
r
F
d
i
M
R

l
a
t
n
o
r
F
p
u
S
L

l
a
t
n
o
r
F
p
u
S
R

l
a
t
n
o
r
F
b
r
O
d
i
M
L

l
a
t
n
o
r
F
b
r
O
d
i
M
R

l
a
t
n
o
r
F
p
u
S
d
e
M
L

l
a
t
n
o
r
F
p
u
S
d
e
M
R

l
a
t
n
o
r
F
b
r
O
p
u
S
L

l
a
t
n
o
r
F
b
r
O
p
u
S
R

m
r
o
f
i
s
u
F
L

m
r
o
f
i
s
u
F
R

l
h
c
s
e
H
L

l
h
c
s
e
H
R

s
u
p
m
a
c
o
p
p
i
H
L

s
u
p
m
a
c
o
p
p
i
H
R

a
l
u
s
n
I
L

a
l
u
s
n
I
R

l
a
u
g
n
i
L
L

l
a
u
g
n
i
L
R

l
a
t
i
p
i
c
c
O
f
n
I
L

l
a
t
i
p
i
c
c
O
f
n
I
R

l
a
t
i
p
i
c
c
O
d
i
M
L

l
a
t
i
p
i
c
c
O
d
i
M
R

l
a
t
i
p
i
c
c
O
p
u
S
L

l
a
t
i
p
i
c
c
O
p
u
S
R

y
r
o
t
c
a
f
l
O
L

y
r
o
t
c
a
f
l
O
R

m
u
d
i
l
l
a
P
L

m
u
d
i
l
l
a
P
R

p
p
i
h
a
r
a
P
L

p
p
i
h
a
r
a
P
R

l
a
r
t
n
e
c
a
r
a
P
L

l
a
r
t
n
e
c
a
r
a
P
R

l
a
t
e
i
r
a
P
f
n
I
L

l
a
t
e
i
r
a
P
f
n
I
R

l
a
t
e
i
r
a
P
p
u
S
L

l
a
t
e
i
r
a
P
p
u
S
R

l
a
r
t
n
e
c
t
s
o
P
L

l
a
r
t
n
e
c
t
s
o
P
R

l
a
r
t
n
e
c
e
r
P
L

l
a
r
t
n
e
c
e
r
P
R

s
u
e
n
u
c
e
r
P
L

s
u
e
n
u
c
e
r
P
R

n
e
m
a
t
u
P
L

n
e
m
a
t
u
P
R

s
u
t
c
e
R
L

s
u
t
c
e
R
R

r
e
p
O
_
c
i
d
n
a
l
o
R
L

r
e
p
O
_
c
i
d
n
a
l
o
R
R

a
e
r
A
r
o
t
o
M
p
p
u
S
L

a
e
r
A
r
o
t
o
M
p
p
u
S
R

g
r
a
m
a
r
p
u
S
L

g
r
a
m
a
r
p
u
S
R

l
a
r
o
p
m
e
T
f
n
I
L

l
a
r
o
p
m
e
T
f
n
I
R

l
a
r
o
p
m
e
T
d
i
M
L

l
a
r
o
p
m
e
T
d
i
M
R

e
l
o
P
p
m
e
T
d
i
M
L

e
l
o
P
p
m
e
T
d
i
M
R

e
l
o
P
p
m
e
T
p
u
S
L

e
l
o
P
p
m
e
T
p
u
S
R

l
a
r
o
p
m
e
T
p
u
S
L

l
a
r
o
p
m
e
T
p
u
S
R

s
u
m
a
l
a
h
T
L

s
u
m
a
l
a
h
T
R

Figure 3: Top panel: Average regression weights of imaging markers for predicting three RAVLT
memory scores. Bottom panel: Top 10 average weights mapped onto the brain.

Shown in Figure 3 are (1) the heat map of the learned weights (magnitudes of the average regression
weights for all three RAVLT scores at each time point) of the VBM measures at different time points
calculated by our method; and (2) the top 10 weights mapped onto the brain anatomy. A ﬁrst glance
at the heat map in Figure 3 indicates that the selected imaging markers have clear patterns that span
across all the four studied time points, which demonstrates that these markers are longitudinally
stable and thereby can potentially serve as screening targets over the course of AD progression.

Moreover, we observe that the bilateral hippocampi and parahippocampal gyri are among the top
selected features. These ﬁndings are in accordance with the known knowledge that in the patho-
logical pathway of AD, medial temporal lobe is ﬁrstly affect ed, followed by progressive neocortical
damage [19, 20]. Evidence of a signiﬁcant atrophy of middle t emporal region in AD patients has
also been observed in previous studies [21, 22, 23].

In summary, the identiﬁed longitudinally stable imaging ma rkers are highly suggestive and strongly
agree with the existing research ﬁndings, which warrants th e correctness of the discovered imaging-
cognition associations to reveal the complex relationships between MRI measures and cognitive
scores. This is important for both theoretical research and clinical practices for a better understand-
ing of AD mechanism.

4 Conclusion

To reveal the relationship between longitudinal cognitive measures and neuroimaging markers, we
have proposed a novel high-order multi-task feature learning model, which selects the longitudinal
imaging markers that can accurately predict cognitive measures at all the time points. As a result,
these imaging markers could fully differentiate the entire longitudinal trajectory of relevant cognitive
measures and better capture the associations between imaging markers and cognitive changes over
time. To solve our new objective, which uses the non-smooth structured sparsity-inducing norms,
we have derived an iterative algorithm with a closed form solution in each iteration. We have further
proved our algorithm converges to the global optimal solution. The validations using ADNI imaging
and cognitive data have demonstrated the promise of our method.
Acknowledgement. This work was supported by NSF CCF-0830780, CCF-0917274, DMS-
0915228, and IIS-1117965 at UTA; and by NSF IIS-1117335, NIH R01 LM011360, UL1
RR025761, U01 AG024904, RC2 AG036535, R01 AG19771, and P30 AG10133-18S1 at IU. Data
used in the work were obtained from the ADNI database. ADNI funding information is available at
http://adni.loni.ucla.edu/wp-content/uploads/how to apply/ADNI DSP Policy.pdf.

8

References
[1] C Hinrichs, V Singh, G Xu, SC Johnson, and ADNI. Predictive markers for ad in a multi-modality
framework: an analysis of mci progression in the adni population. Neuroimage, 55(2):574–89, 2011.
[2] CM Stonnington, C Chu, S Kloppel, and et al. Predicting clinical scores from magnetic resonance scans
in alzheimer’s disease. Neuroimage, 51(4):1405–13, 2010.
[3] L. Shen, S. Kim, and et al. Whole genome association study of brain-wide imaging phenotypes for
identifying quantitative trait loci in MCI and AD: A study of the ADNI cohort. Neuroimage, 2010.
[4] H. Wang, F. Nie, H. Huang, S. Risacher, C. Ding, A.J. Saykin, L. Shen, et al. Sparse multi-task regression
and feature selection to identify brain imaging predictors for memory performance. In ICCV, 2011.
[5] D. Zhang and D. Shen. Multi-modal multi-task learning for joint prediction of multiple regression and
classi ﬁcation variables in alzheimer’s disease. Neuroimage, 2011.
[6] H. Wang, F. Nie, H. Huang, S. Kim, Nho K., S. Risacher, A. Saykin, and L. Shen. Identifying Quantitative
Trait Loci via Group-Sparse Multi-Task Regression and Feature Selection: An Imaging Genetics Study
of the ADNI Cohort. Bioinformatics, 28(2):229–237, 2012.
[7] H. Wang, F. Nie, H. Huang, S. Risacher, A. Saykin, and L. Shen.
Identifying Disease Sensitive and
Quantitative Trait Relevant Biomarkers from Multi-Dimensional Heterogeneous Imaging Genetics Data
via Sparse Multi-Modal Multi-Task Learning. Bioinformatics, 28(18):i127–i136, 2012.
[8] S. L. Risacher, L. Shen, J. D. West, S. Kim, B. C. McDonald, L. A. Beckett, D. J. Harvey, Jr. Jack, C. R.,
M. W. Weiner, A. J. Saykin, and ADNI. Longitudinal MRI atrophy biomarkers: relationship to conversion
in the ADNI cohort. Neurobiol Aging, 31(8):1401–18, 2010.
[9] J. Zhou, L. Yuan, J. Liu, and J. Ye. A multi-task learning formulation for predicting disease progression.
In SIGKDD, 2011.
[10] H. Wang, F. Nie, H. Huang, J. Yan, S. Kim, Nho K., S. Risacher, A. Saykin, and L. Shen. From Phenotype
to Genotype: An Association Study of Candidate Phenotypic Markers to Alzheimer’s Disease Relevant
SNPs. Bioinformatics, 28(12):i619–i625, 2012.
[11] A. Argyriou, T. Evgeniou, and M. Pontil. Multi-task feature learning. NIPS, pages 41–48, 2007.
[12] G. Obozinski, B. Taskar, and M. Jordan. Multi-task feature selection. Technical report, Department of
Statistics, University of California, Berkeley, 2006.
[13] M. Yuan and Y. Lin. Model selection and estimation in regression with grouped variables. Journal of The
Royal Statistical Society Series B, 68(1):49C –67, 2006.
[14] H. Wang, F. Nie, H. Huang, S. Risacher, A. Saykin, and L. Shen. Identifying ad-sensitive and cognition-
relevant imaging biomarkers via joint classi ﬁcation and re gression. Medical Image Computing and
Computer-Assisted Intervention (MICCAI 2011), pages 115–123, 2011.
[15] B. Recht, M. Fazel, and P.A. Parrilo. Guaranteed minimum-rank solutions of linear matrix equations via
nuclear norm minimization. Arxiv preprint arxiv:0706.4138, 2007.
[16] E.J. Cand `es and B. Recht. Exact matrix completion via c onvex optimization. Foundations of Computa-
tional Mathematics, 9(6):717–772, 2009.
[17] E.J. Candes and T. Tao. The power of convex relaxation: Near-optimal matrix completion. Information
Theory, IEEE Transactions on, 56(5):2053–2080, 2010.
[18] I.F. Gorodnitsky and B.D. Rao. Sparse signal reconstruction from limited data using focuss: A re-
weighted minimum norm algorithm. Signal Processing, IEEE Transactions on, 45(3):600–616, 1997.
[19] H. Braak and E. Braak. Neuropathological stageing of alzheimer-related changes. Acta neuropathologica,
82(4):239–259, 1991.
[20] A. Delacourte, JP David, N. Sergeant, L. Buee, A. Wattez, P. Vermersch, F. Ghozali, C. Fallet-Bianco,
F. Pasquier, F. Lebert, et al. The biochemical pathway of neuroﬁbrillary degeneration in aging and
alzheimers disease. Neurology, 52(6):1158–1158, 1999.
[21] L.G. Apostolova, P.H. Lu, S. Rogers, R.A. Dutton, K.M. Hayashi, A.W. Toga, J.L. Cummings, and
P.M. Thompson. 3d mapping of mini-mental state examination performance in clinical and preclinical
alzheimer disease. Alzheimer Disease & Associated Disorders, 20(4):224, 2006.
[22] A. Convit, J. De Asis, MJ De Leon, CY Tarshish, S. De Santi, and H. Rusinek. Atrophy of the medial oc-
cipitotemporal, inferior, and middle temporal gyri in non-demented elderly predict decline to Alzheimer’s
disease. Neurobiol of aging, 21(1):19–26, 2000.
[23] V. Julkunen, E. Niskanen, S. Muehlboeck, M. Pihlajam ¨aki, M. K ¨on ¨onen, M. Hallikainen, M. Kivipelto,
S. Tervo, R. Vanninen, A. Evans, et al. Cortical thickness analysis to detect progressive mild cognitive
impairment: a reference to alzheimer’s disease. Dementia and geriatric cognitive disorders, 28(5):404–
412, 2009.

9

