Automated hand recognition as a human -computer interface 

Sergi i  She lpuk 
 SoftServe , Inc.  
sergi i .shelpuk@gmai l.com  

The   key  factor  of   success  in HCI  is making  the  
experience   of   software   product  as  close   as 
possible   to  the   experience   of   the   real   world 
interaction.  Considering  the   examples above , 
visual  interface  and mouse  are  much more  al ike  
to  the   real   world  than  the  console . However, 
interacting  wi th  the   software   using  our  own 
f ingers  is  even  be tter  since   almost  every 
interaction  of   a  human  be ing  wi th  the   real  
world is of  tacti le  ( kinesthe tic)  nature . 

This concept can be  extended to the  other types 
of  interfaces as we l l .  

Today, webcam is an  integral  part of  almost any 
computing 
device . 
Laptops, 
table ts, 
smartphones,  TV   theaters,  great number of   IP 
phones,  te lepresence   devices,  ATM and even 
some   cars have   integrated webcam often wi th 
the   purpose   of   capturing  and  transmi tting 
someone ’s 
face   during  the   conversation. 
However,  from  the   HCI  point  of   view,  the i r 
potential  seems to be  greatly underestimated.  

This project is devoted to the  deve lopment of  a 
new type  of  HCI al lowing the  presenter to make  
notes and draw on  the  presentation using just 
his/he r  f ingers  wi th  no  addi tional   device   by 
hand recogni tion wi th a webcam.   

2.  Data Set  

Two  separate   datase ts  were   created  f or  the  
purpose  of  this project: hand image  datase t and 
f inger f igure  datase t.   

Hand  image  datase t was obtained by capturing 
the   picture   from  the   came ra  and  breaking  i t 
down into 100x100  pixe l  squares. After that, the  
pictures  wi th  the   hand  were   separated 
manual ly,  f i l tered  and  reduced  to  the   50x50 
pixe ls size .  

Finger f igure  datase t was obtained by breaking 
down  100x100  pictures  wi th  the   hand  into 

 

Abstract  

This  paper 
investigates  applying  Machine  
Learning  to  the   problem  of   turning  a  regular 
webcam  into  the   input  device   and  human -
computer  interface   by  the   hand  recogni tion.  
The   purpose   of   the   project  is  to  create   an 
appl ication  for  drawing  and  making  notes  on 
the  presentation by moving the  hand in front of  
the  laptop came ra.  For the  purpose  of  this task, 
there   were   created  two   separate   datase ts, 
appl ied  color  f i l tering  and  trained  two neural  
ne twork  based  classi f iers.  For  the   purpose  of  
accuracy 
improvement,  also 
there   was 
introduced an algori thmic threshold based f i ler 
for the  drawing.  

1.  Introduction 

Human-computer interaction  (HCI)  focus is one  
of   the   most  popu lar  and  promising  ideas  in 
software   and  hardware   design  of   the   last 
decade .  Computer evolution and success stories 
(as  we l l   as  reasons  of   fai lure )   of   nume rous 
products were  based on new type s of  interface  
and  user  experience   that  make   the   product 
convenient  and  easy  to  use   for  as  many 
potential   custome rs  as  possible .  In  the   early 
days  of   personal   computers,  window s  based 
interface   and  mouse   made   a  revolution  in PC 
world  through  making  interaction  wi th  the  
programs  more   intui tive   than  the   console . 
Today, we  are  wi tnessing another HCI-enabled 
revolution: smartphones and table ts. Removal  
of   the   mouse   and  keyboard    and  abi l i ty  to 
access  the   software   di rectly  wi th  the   f ingers 
make  these  devices such user friendly that even 
chi ldren  who  do  not  have   the   access  to  the  
education  who  and  have   never  seen  any 
compute r be fore   can use   table ts  to  learn how 
to  read  and  wri te   by  themse lves1 .  The  
importance  of  this cannot be  overestimated.  

                                                                 
1  MI T Technol ogy  Revi ew:  Gi ven Ta bl ets  but No 
Tea chers , Ethi opi a n Chi l dren Tea ch Thems el ves  

-  1  -  

40x40  squares.  After  that,  the   pictures  wi th 
f inger f igures were  separated manual ly.  

2.1  Hand  image dataset  

This  datase t  consists  of   9404  images  of   50x50 
pixe l   size .  The   pictures  are   divided  into   two 
types:  2724  pictures wi th human hand (posi tive 
examples)   and  6680  pictures  wi thout  human 
hand (negative  example s) .  

Filtering 

Regular  RGB color  image  contains  information 
about  pixe l   colors  that  is  redundant  for  the  
purpose   of   this  project  –  higher  number  of  
features  requi res  more   data  to  train  the  
accurate   classi f ier.  Converting  the   image   into 
grayscale   does  not  ful ly address  the  problem: 
grey intensi ty of  every pixel varies wi th the  l ight 
condi tion. Addi tional ly, the  grayscale image sti l l  
contains  the   background  that  also  affects  the  
classi f ier performance .  

To  address  this  problem  the   training  se t 
pictures were  processed wi th the  skin de tection 
f i l tering.  

The  goal   is  to  transform an RGB color image  in 
the   form  that  contains  only  evidences  of   the  
hand  but  not  the   background  or  any  other 
redundant information.  The  transformation also 
should provide  this resul t independent of  l ight 
condi tion  and  whi te   balance   of   the   original  
picture .  

The   f i l ter  uses  the   fact  that  in  standard 
grayscale   image   the   pixe l   wi th  intensi ty  “0” 
corresponds  to  the   black color,  the  pixe l  wi th 
intensi ty  “255” corresponds  to  the  whi te  color 
and al l  the  values be tween them corresponds to 
the   shades.  For  the   f i l tering, RGB value  of   the  
f ingertips  is  used  as  a  re ference   color.  Each 
pixe l  of   the   image   is  transformed according to 
the  formula2 : 

 

                                                                 
2  According to the c lass res trictions, the fi ltering was wri tten from 
s cra tch 

-  2  -  

  is  a  vector  of   RGB  values  of   the  

original  pixe l .  

is  a  vector  of   re ference   color  (the  
color  of   the   f ingertips  in  the   current  l ight 
condi tion) . 

  is  a  grayscale   value   of   the   pixe l  

after transformation . 

 is a variance  constant.  

Intui tion behind  this  f i l tering  is  the  fol lowing: 
after  the   transformation, grayscale  picture  has 
only  the   f igures  that are   simi lar  in color to the  
f ingertips. Everything e lse  is whi te .  

 

(a)  

 

(b)  

 

(c)  

 
Figure  1: Original  image  (a) , greyscale image  (b)  
wi thout f i l tering (stil l contain a lot of  redundant 
information)   and  f i l tered  image   (c)   – posi tive  
example  from the  hand image  datase t 
 

 

(a)  

 

(b)  

 

(c)  

 
Figure  2: Original  image  (a) , greyscale image  (b)  
wi thout  f i l tering  and  f i l tered  image   (c)   – 
negative  example from the  hand image  datase t 
 

This al lows to use  the  product wi th the  di fferent 
l ight condi tions by changing value  of  the
. 

2.2  Finger figure dataset  

This  datase t  consists  of   7547  images  of   40x40 
pixe l   size .  The   pictures  are   divided  into  two 
types:  2273  pictures wi th f inger f igure (posi tive  
examples)   and  5247  pictures  wi thout  f inger 
f igure  (negative  example ) .  

21255refpixelTrefpixelCCCCfilteredeC3RCpixel3RCrefRCfilteredR2refCNo  f i l tering  was  appl ied  for  this  data  se t 
because   grayscale  
image   gives  the   easi ly 
recognized pattern.  

 

 

(b)  
(a)  
 
 
Figure  2: Posi tive  (a)  and negative (b)  examples 
from the  f inger f igure  datase t  

3.  System Design 

The  system overal l  consists of  two archi tectural  
components  Octave   scripts  and  Python 
program.  

Octave  scripts functional i ty : 

1. 

importing  pictures and  transform ing  them 
into  training  se t,  cross  val idation  se t  and 
test se t 
2.  training classi f iers  
3.  exporting we ights in CSV  format 

Python program functional i ty : 

1. 
loading we ights from CSV  f i les  
2.  capturing video from came ra 
3.  performing skin de tection f i l tering  
4.  de tecting hand on the  screen  
5.  de tecting f inger f igure  
6.  transforming  coordinates  of   the   f inger 
f igure   to  the   screen  coordinates  for  the  
mouse  posi tion  
7.  performing threshold  based f i l tering 
8.  drawing a  f igure  based on  the  coordinates 
of  the  f inger f igure  

OpenCV  2.1 l ibrary was used for the  purpose  of  
video capturing, resizing and transforming into 
grayscale 3 .  Numpy  1.6.1  l ibrary  was  used  for 
l inear algebra calculations in Python.  

performance ,  performs  f i l tering  and  breaks  i t 
into  50x50  squares  and  tests  using  two 
classi f iers. Fi rst one  is looking for a hand on the  
picture  (hand image  classi f ier) .  

If   i t  re turns  “true”  (the   image   contains  hand)  
then the  program transforms the  coordinates of  
the   posi tive   square   to  the   coordinates  of   the  
original   640x480  image ,  takes  100x100  square  
wi th  the   hand,  transforms  i t  to  the   greyscale  
and breaks into 40x40 squares.  

Each  of   the   40x40  square   is  tested  wi th  the  
second classi f ier. If  i t re turns “true” (the  image  
contains  f inger  f igure )   then  the   program 
transforms  the  coordinate  of  the  square  to the  
original   coordinates  and  considers  them  as  a 
drawing point.  

For  the   purpose   of   this  appl ication,  both 
classi f iers  should  perform on  two classes  that 
are   non- l inearly  separable .  Two  possible  
algori thms  performing  we l l   on  non - l inear 
classi f ication were  considered for the  purpose  
of  this project: SVM wi th polynomial kernel  and 
Neural  Ne tworks (NN) .  

The   table   be low  represents  best  achieved 
performance  of  two algori thms on the  datase ts: 

 

SVM 
NN 

Hand image  
datase t 
88,01% 
95,12% 

Finger f igure  
datase t 
92,4% 
97,15% 

So,  NN  classi f iers  were   se lected  for  the  
appl ication.   Backpropagation  was  used  as  a 
training me thod.  

Also, 
to  avoid 
regularization  was  used 
overf i tting.   Regularization  parame ter  was 
se lected  based  on  the   cross -val idation  se t 
performance .  

3.1  Classifiers 

3.2  Hand  image classifier  

The   system  needs  to  f ind  the   f in ger  f igure  on 
the   image   taken  from  the   webcam.  For  this 
purpose ,   Python  program  captures  the   image  
from  the   webcam,  reduces  i ts  size   from 
640x480 
to  320x240 
for 
the  
reason  of  
                                                                 
3  According to the  c la s s  re s trict ion s , both neura l  ne twork (NN) 
c la s s i fie rs   we re   wri tten  from  s cra tch,  OpenCV   inte rna l   NN 
funct iona l i ty wa s  not  us ed for the  purpos e  of thi s  proje ct  
 

Archi tecture   of   the   hand  image   classi f ier   and 
regularization parame ter was se lected based on 
the   classi f ier  performance  on  the  hand  image  
datase t. 

The  table  be low represents the  accuracy of  the  
three  layer NN archi tecture  given regularization 

parame ter
.  NN  archi tecture   is  represented 
as  fol lowing:  Input  layer  size/hidden  layer 

-  3  -  

size/output  layer  size .  Some   combinations  of  
archi tecture/regularization parame ter was not 
tested  because   they  are   clearly  supposed  to 
give  the  performance  lower than al read y found 
max imum. 

For the  f inger f igure  classi fier, the  same  analysis 
was performed to de f ine the  be tter archi tecture 
and  the   be tter  regularization  parame ter.   The  
resul ts of  the  analysis are  presented in the  table  
be low.  

 

2500/ 
30/ 
2 

2500/ 
2500/ 
100/ 
 5/ 
2 
2 
0,902 
-  
0  0,814 
-  
0,84 
-  
0,01 
-  
0,850 
-  
0,05 
-  
0,1  0,829  0,861 
-  
0,871 
-  
1 
-  
2  0,817 
-  
0,888  0,939 
0,84 
5 
10  0,850  0,890  0,946 
15  0,850 
-  
-  
20  0,829  0,871  0,913 
0,891 
0,84 
30  0,829 
-  
0,813 
-  
40 

2500/ 
2500/ 
200/ 
300/ 
2 
2 
0,94 
0,93 
-  
-  
-  
-  
-  
-  
0,9512  0,950 
-  
-  
0,949 
-  
0,949 
-  
-  
-  
0,942 
0,946 
-  
-  
0,936 
0,94 

2500/ 
30/ 
2 

0,89 
0,883 
-  
-  
0,83 
-  

 

0 
0,5 
1 
2 
5 
7 

2500/ 
100/ 
2 
0,927 
-  
0,932 
-  
-  
0,912 

2500/ 
200/ 
2 
0,968 
0,9715 
0.97 
-  
0,961 
-  

2500/ 
300/ 
2 
0.962 
0.962 
0.964 
0.965 
0.962 
0.98 

So three  layer neural  ne twork wi th archi tecture  
2500/200/2  and 
regularization  parame ter 

  was  chosen  for  the   f inger  f igure  
image  classi f ier.  

The  performance  of  the  classi f ier is speci fied in 
the  table  be low: 

Four  layer  NN   archi tectures  were   also  tested 
but 
they  did  not  show  any  signi f icant 
improvement  of   the   performance .  So  three  
layer  neural   ne twork  wi th  archi tecture  
2500/200/2  and 
regularization  parame ter 
  was  chosen  for  the   hand  image  
classi f ier.  

The  performance  of  the  classi f ier is speci fied in 
the  table  be low: 

Test se t size  
Accuracy  
True  posi tive 
False  posi tive 
True  negative  
False  negative  
Precision 
Recal l  
F1  score  

1509 
0.9715 
421 
12 
1045 
31 
0.9722 
0.9314 
0.951 

Test se t size  
Accuracy 
True  posi tive 
False  posi tive 
True  negative  
False  negative  
Precision 
Recal l  
F1  score  

1800 
0.951 
536 
31 
1252 
61 
0.945 
0.897 
0.91 

For  the   purpose   of   this project we   real ly care  
about  precision  since   false   posi tives  affects 
performance   of   the   system  overal l . From  this 
point of  view, the  performance  of  the  classi f ier 
is acceptable .  

3.3  Finger  figure classifier  

As we l l  as for hand image  classi f ier, precision is 
a key performance  indicator so this classi f ier is 
acceptable  as we l l .  

3.4  Threshold  based  filtering  

The  main problem wi th the  appl ication is false  
posi tives:  every 
false   posi tive   not  only 
consumes  CPU  resources  to  evaluate   the  
picture   in de tai ls  looking  for  f inger  f igure , but 
also in case  of  false  posi tive  of  the  f inger f igure  
classi f ier,  i t  produces  a  false   drawing  point. 
Despi te   pre tty  high  leve l   of   accuracy,  this 
happens  and 
sti l l   makes 
the   me thod 
inappl icable .  

To  address  this 
issue ,  addi tional   f i l tering 
me thod was  introduced. Each drawing point is 
represented  by  two  coordinates  X  and  Y.  We  

-  4  -  

15.0  Using  the   fact  that  i f   a  100x100  square  
contains a hand, then the  shi fted for =/ -  10 
pixe ls square  should also contain the  hand, 
the   addi tional   classi f ication  can  be  
introduces  to  improve   the   accuracy  of  
classi f ication 
  Currently,  the   appl ication  uses  straight 
l ines  to  connect  drawing  points.  This 
resul ts  in qui te  ugly  l ines. Drawing points 
can  be   divided  into  groups  of   three   and 
each  group  can  be   approx imated  by  the  
second  order  polynomial .  This  wi l l   make  
the  drawing smooth.  
  Addi tional   algori thm could be   introduced 
to  predict  where   the   f inger  f igure   most 
l ike ly wi l l  be   in  the  next  time frame  (next 
screen  capture )   based  on  the   previous 
movements. This can reduce  the  CPU work 
and the  amount of  pictures to classi fy thus 
reducing the  false  posi tive  chance .  

References 

Robert L. Harvey, Paul  N. DiCaprio, and Karl  G. 
He inemann   A Neural  Ne twork Archi tecture  for 
General  
Image   Recogni tion .  The   Lincoln 
Laboratory  Journal   Volume   4. Number 2. 1991 
(189-207)  

C.-C.  Yang,  S.O.  Prasher,  J.-A.  Landry,  H.S. 
Ramaswamy  and A. Di tommaso. Appl ication of  
arti f icial  neural  ne tworks  in image  recogni tion 
and classi f ication of  crop and weeds . Canadian 
Agricul tural   Engineering  Vol .  42,  No.  3         
July/August/September 2000 (147-152)  

Christopher  M.  Bishop.  Neural   Ne tworks  for 
Pattern  Recogni tion  Ox ford  Universi ty  Press, 
Nov. 23 1995 

make  assumption that since  the  user moves the  
hand  smoothly,  so  two  sequential   drawing 
points  cannot  be   far  away  from each other.  If  
the   distance   of   the   next  drawing point  found 
and  previous  drawing  point  exceeds  some  

threshold 
then  the   new  drawing  point  is 
l ike ly  to  be   a  false   posi tive   and  should  be  
excluded  from  the   drawing  point  l ists   for  the  
current l ine . 

After  the   f i l tering,  the   drawing  point 
is 
connected wi th  the  previous drawing point by 
emulating  mouse   movement  wi th  the   le ft 
button pressed.  

The   f igure   be low  represents  the   example   of  
using the  appl ication to make  some  note  on the  
PowerPoint presentation.  

Figure  3. Drawing on the  presentation wi th the 
deve loped appl ication 

 

4.  Conclusion and future work 

Clearly,  the   qual i ty  of   the   drawing  on  the  
current  stage  
is  not  enough  to  cal l   the  
appl ication  a  comple ted  product .  However,  i t 
shows  that  Machine   Learning can  turn  regular 
webcam  into  interface   for  human  computer 
interaction.  

The   project  has  a  lot  of   opportuni ties  for 
improvement and future  work:  

  Deep  learning  techniques  and  Dropout 
me thod  can  be   appl ied  to  improve   the  
performance  of  the  classi f iers.  

-  5  -  

trd