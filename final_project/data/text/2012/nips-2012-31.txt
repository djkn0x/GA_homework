Fast Resampling Weighted v -Statistics

Chunxiao Zhou
Mark O. Hatﬁeld Clinical Research Center
National Institutes of Health
Bethesda, MD 20892
chunxiao.zhou@nih.gov

Jiseong Park
Dept of Math
George Mason Univ
Fairfax, VA 22030
jiseongp@gmail.com

Yun Fu
Dept of ECE
Northeastern Univ
Boston, MA 02115
yunfu@ece.neu.edu

Abstract

In this paper, a novel and computationally fast algorithm for computing weighted
v -statistics in resampling both univariate and multivariate data is proposed. To
avoid any real resampling, we have linked this problem with ﬁnite group action
and converted it into a problem of orbit enumeration. For further computational
cost reduction, an efﬁcient method is developed to list all orbits by their sym-
metry orders and calculate all index function orbit sums and data function orbit
sums recursively. The computational complexity analysis shows reduction in the
computational cost from n! or nn level to low-order polynomial level.

1

Introduction

Resampling methods (e.g., bootstrap, cross-validation, and permutation) [3,5] are becoming increas-
ingly popular in statistical analysis due to their high ﬂexibility and accuracy. They have been suc-
cessfully integrated into most research topics in machine learning, such as feature selection, di-
mension reduction, supervised learning, unsupervised learning, reinforcement learning, and active
learning [2, 3, 4, 7, 9, 11, 12, 13, 20].
The key idea of resampling is to generate the empirical distribution of a test statistic by resampling
with or without replacement from the original observations. Then further statistical inference can
be conducted based on the empirical distribution, i.e., resampling distribution. One of the most
important problems in resampling is calculating resampling statistics, i.e., the expected values of
test statistics under the resampling distribution, because resampling statistics are compact represen-
tatives of the resampling distribution. In addition, a resampling distribution may be approximated
by a parametric model with some resampling statistics, for example, the ﬁrst several moments of
a resampling distribution [5, 16]. In this paper, we focus on computing resampling weighted v -
statistics [18] (see Section 2 for the formal deﬁnition). Suppose our data includes n observations,
a weighted v -statistic is a summation of products of data function terms and index function terms,
i.e., weights, over all possible k observations chosen from n observations, where k is the order of
the weighted v -statistic. If we treat our data as points in a multi-dimensional space, a weighted
v -statistic can be considered as an average of all possible weighted k-points distances. The higher k ,
the more complicated interactions among observations can be modeled in the weighted v -statistic.
Machine learning researchers have already used weighted v -statistics in hypothesis testing, density
estimation, dependence measurement, data pre-processing, and classiﬁcation [6, 14, 19, 21] .
Traditionally, estimation of resampling statistics is solved by random sampling since exhaustive ex-
amination of the resampling space is usually ill advised [5,16]. There is a tradeoff between accuracy
and computational cost with random sampling. To date, there is no systematic and efﬁcient solution
to the issue of exact calculation of resampling statistics. Recently, Zhou et.al. [21] proposed a recur-
sive method to derive moments of permutation distributions (i.e., empirical distribution generated by
resampling without replacement). The key strategy is to divide the whole index set (i.e., indices of
all possible k observations ) into several permutation equivalent index subsets such that the summa-

1

tion of the data/index function term over all permutations is invariant within each subset and can be
calculated without conducting any permutation. Therefore, moments are obtained by summing up
several subtotals. However, methods for listing all permutation equivalent index subsets and calcu-
lating of the respective cardinalities were not emphasized in the previous publication [21]. There is
also no systematic way to obtain coefﬁcients in the recursive relationship. Even only for calculating
the ﬁrst four moments of a second order resampling weighted v statistic, hundreds of index subsets
and thousands of coefﬁcients have to be derived manually. The manual derivation is very tedious and
error-prone. In addition, Zhou’s work is limited to permutation (resampling without replacement)
and is not applicable to bootstrapping (resampling with replacement) statistics.
In this paper, we propose a novel and computationally fast algorithm for computing weighted v -
statistics in resampling both univariate and multivariate data. In the proposed algorithm, the calcu-
lation of weighted v -statistics is considered as a summation of products of data function terms and
index function terms over a high-dimensional index set and all possible resamplings with or without
replacement. To avoid any resampling, we link this problem with ﬁnite group actions and convert
it into a problem of orbit enumeration [10]. For further computational cost reduction, an efﬁcient
method has been developed to list all orbits by their symmetry order and to calculate all index func-
tion orbit sums and data function orbit sums recursively. With computational complexity analysis,
we have reduced the computational cost from n! or nn level to low-order polynomial level. Detailed
proofs have been included in the supplementary material.
In comparison with previous work [21], this study gives a theoretical justiﬁcation of the permutation
equivalence partition idea and extends it to other types of resamplings. We have built up a solid
theoretical framework that explains the symmetry of resampling statistics using a product of sev-
eral symmetric groups. In addition, by associating this problem with ﬁnite group action, we have
developed an algorithm to enumerate all orbits by their symmetry order and generated a recursive
relationship for orbits sum calculation systematically. This is a critical improvement which makes
the whole method fully programmable and frees ourselves from onerous derivations in [21].

2 Basic idea

In general, people prefer choosing statistics which have some symmetric properties. All resampling
This study is focused on computing resampling weighted v -statistics, i.e., T (x) = (cid:80)n
strategies, such as permutation and bootstrap, are also more or less symmetric. These facts motivated
us to reduce the computational cost by using abstract algebra.
(cid:80)n
i1=1 · · ·
id=1 w(i1 , · · · , id )h(xi1 , · · · xid ), where x = (x1 , x2 , · · · , xn )T is a collection of n observa-
tions (univariate/multivariate), w is an index function of d indices, and h is a data function of d
observations. Both w and h are symmetric, i.e., invariant under permutations of the order of vari-
ables. Weighted v -statistics cover a large amount of popular statistics. For example, in the case of
multiple comparisons, observations are collected from g groups: ﬁrst group (x1 , · · · , xn1 ), second
group (xn1+1 , · · · , xn1+n2 ), and last group (xn−ng +1 , · · · , xn ), where n1 , n2 , · · · , ng are numbers
modiﬁed F test statistic T (x) = ((cid:80)n1
i=1 xi )2/n1+((cid:80)n1+n2
i=n1+1 xi )2/n2+· · ·+((cid:80)n
of observations in each group. In order to test the difference among groups, it is common to use the
(cid:80)n
weighted v -statistic, i.e., T (x) = (cid:80)n
i=n−ng +1 xi )2/ng ,
where n = n1 + n2 + · · · + ng . We can rewrite the modiﬁed F statistic [3] as a second order
i2=1 w(i1 , i2 )h(xi1 , xi2 ), here h(xi1 , xi2 ) = xi1 xi2 and
i1=1
w(i1 , i2 ) = 1/nk if both xi1 and xi2 belong to the k-th group, and w(i1 , i2 ) = 0 otherwise.
(cid:17)r
(cid:17)
(cid:16)
(cid:16) (cid:88)
The r-th moment of a resampling weighted v -statistic is:
w(i1 , · · · , id )h(xσ ·i1 , · · · , xσ ·id )
(cid:26) (cid:88)
T r (x)
= Eσ
(cid:110)(cid:16) r(cid:89)
(cid:17)(cid:16) r(cid:89)
i1 ,··· ,id
1 , · · · , ik
w(ik
(cid:26) (cid:88)
h(xσ ·ik
d )
(cid:17)(cid:16) r(cid:89)
(cid:110)(cid:16) r(cid:89)
(cid:88)
1
1 ,··· ,ir
d ,··· ,ir
1 ,··· ,i1
i1
k=1
k=1
d
1 , · · · , ik
w(ik
d )
σ∈R
1 ,··· ,ir
d ,··· ,ir
1 ,··· ,i1
i1
k=1
k=1
d

(cid:17)(cid:111)(cid:27)
)

, · · · , xσ ·ik
d

, · · · , xσ ·ik
d

)

(cid:17)(cid:111)(cid:27)

h(xσ ·ik
1

,

(1)

Eσ

= Eσ

=

1
|R|

2

Eσ

=

,

(2)

h(xσ ·ik
1

where Eσ

where σ is a resampling which is uniformly distributed in the whole resampling space R. |R|, the
number of all possible resamplings, is equal to n! or nn for resampling without or with replacement.
Thus the r-th moment of a resampling weighted v -statistic can be considered as a summation of
products of data function terms and index function terms over a high-dimensional index set U r
d =
{1, · · · , n}dr and all possible resamplings in R. Since both index space and resampling space are
huge, it is computationally expensive for calculating resampling statistics directly.
d )} is called an index paragraph, which
1 , · · · , i1
For terminology convenience, {(i1
d ), · · · , (ir
1 , · · · , ir
1 , · · · , ik
d ), k = 1, · · · , r , and each index sentence has d index words
includes r index sentences (ik
j , j = 1, · · · , d. Note that there are three different types of symmetry in computing resampling
ik
weighted v -statistics. The ﬁrst symmetry is that permutation of the order of index words will not
affect the result since the data function is assumed to be symmetric. The second symmetry is the
permutation of the order of index sentences since multiplication is commutative. The third symmetry
is that each possible resampling is equally likely to be chosen.
(cid:17)(cid:111)
(cid:17)
(cid:16)
(cid:110)(cid:16) r(cid:89)
(cid:17)
(cid:16) r(cid:89)
(cid:88)
In order to reduce the computational cost, ﬁrst, the summation order is exchanged,
, · · · , xσ ·ik
1 , · · · , ik
w(ik
T r (x)
)
d )
Eσ
(cid:17)
(cid:16)(cid:81)r
(cid:16)(cid:81)r
(cid:17)
(cid:80)
d
1 ,··· ,i1
d ,··· ,ir
1 ,··· ,ir
i1
k=1
k=1
d
(cid:110){(i1
, · · · , xσ ·ik
, · · · , xσ ·ik
= 1|R|
k=1 h(xσ ·ik
k=1 h(xσ ·ik
)
)
.
σ∈R
1
1
d
d
(cid:111)
1 , · · · , i1
= {1, · · · , n}dr =
d ), · · · , (ir
1 , · · · , ir
d )}|ik
m ∈
The whole index set U r
(cid:16)(cid:81)r
(cid:17)
d
{1, · · · , n}; m = 1, · · · , d; k = 1, · · · , r
in
index subsets,
is then divided into disjoint
, · · · , xσ ·ik
(cid:16)(cid:81)r
(cid:17)
which Eσ
is invariant. The above index set partition simpliﬁes
k=1 h(xσ ·ik
)
1
d
the computing of resampling statistics in the following sense:
(a) we only need to calculate
(cid:16)(cid:81)r
(cid:17)
, · · · , xσ ·ik
once per each index subset, (b) due to the symmetry of resam-
k=1 h(xσ ·ik
Eσ
)
1
d
, · · · , xσ ·ik
pling, the calculation of Eσ
is equivalent to calculating the average of
k=1 h(xσ ·ik
)
1
d
all data function terms within the corresponding index subset, then we can completely replace all
resamplings with simple summations, and (c) for further computational cost reduction, we can sort
all index subsets in their symmetry order and calculate all index subset summations recursively. We
will discuss the details in the following sections for both resampling without or with replacement.
The abstract algebra terms used in this paper are listed as follows.
Terminology. A group is a non-empty set G with a binary operation satisfying the following axioms:
closure, associativity, identity, and invertibility. The symmetric group on a set, denoted as Sn , is the
group consisting of all bijections or permutations of the set. A semigroup has an associative binary
operation deﬁned and is closed with respect to this operation, but not all its elements need to be
invertible. A monoid is a semigroup with an identity element. A set of generators is a subset of
group elements such that all the elements in the group can be generated by repeated composition of
the generators. Let X be a set and G be a group. A group action is a mapping G × X → X which
satisﬁes the following two axioms: (a) e · x (cid:55)→ x for all x ∈ X , and (b) for all a, b ∈ G and x ∈ X ,
a · (b · x) = (ab) · x. Here the (cid:48) ·(cid:48) denotes the action. It is well known that a group action deﬁnes an
equivalence relationship on the set X , and thus provides a disjoint set partition on it. Each part of
the set partition is called an orbit that denotes the trajectory moved by all elements within the group.
We use symbol [ ] to represent an orbit. Two elements, x and y ∈ X fall into the same orbit if there
exists a g ∈ G such that x = g · y . The set of orbits is denoted by G (cid:13) X . A transversal of orbits is
a set of representatives containing exactly one element from each orbit. In this paper, we limit our
discussion to only ﬁnite groups [10,17].

3 Permutation

For permutation statistics, observations are permuted in all possible ways, i.e., R = Sn . Based on
the three types of symmetry, we link the permutation statistics calculation with a group action.
Deﬁnition 1. The action of G := Sn × Sr × Sd
r on the index set U r
d is deﬁned as

3

, where m ∈ {1, · · · , d}, and k ∈ {1, · · · , r}.

m := σ · iτ −1 ·k
(σ, τ , π1 , · · · , πr ) · ik
−1
k ·m
π
Here, πk denotes the permutation of the order of index words within the k-th index sentence, τ
denotes the permutation of the order of r index sentences, and σ denotes the permutation of the value
1 = 1 → 2, 2 → 1,
of an index word from 1 to n. For example, let n = 4, d = 2, r = 2, π1 = π−1
2 = 1 → 1, 2 → 2, τ = τ −1 = 1 → 2, 2 → 1, and σ = 1 → 2, 2 → 4, 3 →
π2 = π−1
3, 4 → 1, then (σ, τ , π1 , π2 ) · {(1, 4)(3, 4)} = {(3, 1)(1, 2)} by {(1, 4)(3, 4)} → {(4, 1)(3, 4)} →
{(3, 4)(4, 1)} → {(3, 1)(1, 2)}. Note that the reason to deﬁne the action in this way is to guarantee
G × U r
d → U r
d is a group action.
(cid:17)
(cid:16)(cid:81)r
In most applications, both r and d are much less than the sample size n, we assume throughout this
paper that n (cid:29) dr .
, · · · , xσ ·ik
(cid:17)
(cid:16)(cid:81)r
Proposition 1. The data function sum Eσ
is invariant within each
k=1 h(xσ ·ik
)
index orbit of group action G := Sn × Sr × Sd
1
d
r acting on the index set U r
d as deﬁned in deﬁnition
(cid:81)r
, · · · , xσ ·ik
(cid:88)
1, and Eσ
k=1 h(xσ ·ik
)
=
(cid:17) ,
(cid:16)
1
d
, · · · , xj k
k=1 h(xj k
)
1
d
(cid:16)
(cid:17)
1 , · · · , ir
d ), · · · , (ir
1 , · · · , i1
[{(i1
d )}]
1 ,··· ,j 1
{(j 1
d ),··· ,(j r
1 ,··· ,j r
1 ,··· ,i1
d )}∈[{(i1
1 ,··· ,ir
d ),··· ,(ir
d )}]
card
[{(i1
1 , · · · , i1
d ), · · · , (ir
1 , · · · , ir
d )}]
is the cardinality of the index orbit, i.e., the number
where card
(cid:16)(cid:81)r
(cid:17)
d )}].
d ), · · · , (ir
1 , · · · , i1
1 , · · · , ir
of indices within the index orbit [{(i1
, · · · , xσ ·ik
Due to the invariance property of Eσ
, the calculation of permutation
k=1 h(xσ ·ik
)
1
d
statistics can be simpliﬁed by summing up all index function product terms in each index orbit.
Proposition 2. The r-th moment of permutation statistics can be obtained by summing up the
(cid:17)
(cid:16)
(cid:88)
product of the data function orbit sum hλ and the index function orbit sum wλ over all index orbits,
wλhλ
T r (x)
card([λ])
λ∈L
d )} is a representative index paragraph, [λ] is the index
1 , · · · , ir
where λ = {(i1
d ), · · · , (ir
1 , · · · , i1
(cid:88)
r(cid:89)
orbit including λ, and L is a transversal of all index orbits . The data function orbit sum is
, · · · , xj k
h(xj k
1
d
1 ,··· ,j 1
{(j 1
d ),··· ,(j r
1 ,··· ,j r
d )}∈[λ]
k=1
r(cid:89)
(cid:88)
and the index function orbit sum is
1 ,··· ,j r
d ),··· ,(j r
1 ,··· ,j 1
{(j 1
d )}∈[λ]
k=1

1 , · · · , j k
w(j k
d ).

Eσ

=

wλ =

hλ =

(3)

(4)

(5)

(6)

,

),

Proposition 2 shows that the calculation of resampling weighted v -statistics can be solved by com-
puting data function orbit sums, index function orbit sums, and cardinalities of all orbits deﬁned in
deﬁnition 1. We don’t need to conduct any real permutation at all.
Now we demonstrate how to calculate orbit cardinalities, hλ and wλ .
The following
of G (cid:13) U r
index paragraphs and cardinality of each orbit
shows a naive algorithm to enumerate all
d , which are needed to calculate hλ and wλ . We construct a Cayley Action
Graph with a vertex set of all possible index paragraphs in U r
d . We connect a directed
edge from {(i1
1 , · · · , i1
d ), · · · , (ir
1 , · · · , ir
d )} to {(j 1
1 , · · · , j 1
d ), · · · , (j r
1 , · · · , j r
d )} if {(j 1
1 , · · · , j 1
d ),
· · · , (j r
1 , · · · , j r
d )} = gk {(i1
1 , · · · , i1
d ), · · · , (ir
1 , · · · , ir
d )}, where gk is a generator ∈ {g1 , · · · , gp}.
{g1 , · · · , gp} is the set of generators of group G, i.e., G = (cid:104)g1 , · · · , gp (cid:105). It is sufﬁcient and efﬁcient
to use the set of generators of group to construct the Cayley Action Graph, instead of using the set of
all group elements. For example, we can choose {g1 , · · · , gp} = {σ1 , σ2 } × {τ1 , τ2 } × {π1 , π2}r ,
where σ1 = (12 · · · n), σ2 = (12), τ1 = (12 · · · r), τ2 = (12), π1 = (12 · · · d), and π2 = (12).
Here σ1 = (12 · · · n) denotes the permutation 1 → 2, 2 → 3, · · · , n → 1, and σ2 = (12) denotes

4

1 → 2, 2 → 1, 3 → 3, · · · , n → n. Note that listing the index paragraphs of each orbit is equivalent
to ﬁnding all connected components in the Cayley Action Graph, which can be performed by using
Graph of G (cid:13) U 1
existing depth-ﬁrst or breadth-ﬁrst search methods [15]. Figure 1 demonstrates the Cayley Action
2 , where d = 2, r = 1, and n = 3. Since the main effort here is to construct the
Cayley Action Graph, the computational cost of the naive algorithm is O(ndr p) = O(ndr 22+r ).
Moreover, the memory cost is O(ndr ). Unfortunately, this algorithm is not an ofﬂine one since we
usually do not know the data size n before we have the data at hand, even d and r can be preset.
In other words, we can not list all index orbits before we know the data size n. Moreover, since
ndr 22+r is still computationally expensive, the naive algorithm is ill advised even if n is preset.

∗

Figure 1: Cayley action graph for G (cid:13) U 1
.
Figure 2: Finding the transversal.
2
In table 1, we propose an improved ofﬂine algorithm in which we assume that d and r are preset.
For computing hλ and wλ , we ﬁnd that we do not need to know all the index paragraphs within
G (cid:13) U r
each index orbit. Since each orbit is well structured, it is enough to only list a transversal of orbits
d and corresponding cardinalities. For example, there are two orbits, [{(1, 1)}] and [{(1, 2)}],
(cid:110){(1, 1)}, {(1, 2)}(cid:111)
when d = 2 and r = 1. [{(1, 1)}], with cardinality n, includes all index paragraphs with i1
2 .
1 = i1
[{(1, 2)}], with cardinality n(n − 1), includes all index paragraphs with i1
1 (cid:54)= i1
2 . Actually, the
transversal L =
carries all the above information. This ﬁnding reduces the
(cid:110){(i1
computation cost dramatically.
(cid:111)
d )}|ik
1 , · · · , ir
d ), · · · , (ir
1 , · · · , i1
∗ = {1, · · · , dr}dr =
Deﬁnition 2. We deﬁne an index set U r
m
d
and a group G∗ := Sdr × Sr × Sd
∈ {1, · · · , dr}; m = 1, · · · , d; k = 1, · · · , r
r .
Since we assumed n (cid:29) dr , U r
∗ is a subset of the index set U r
d . The group G∗ can be considered a
∗ and G∗
d
subgroup of G since the group Sdr can be naturally embedded into the group Sn . Both U r
d
are unrelated to the sample size n.
Proposition 3. The transversal of G∗ (cid:13) U r
∗ is also a transversal of G (cid:13) U r
d .
By proposition 3, we notice that the listing of the transversal of G (cid:13) U r
d
the transversal of G∗ (cid:13) U r
d is equivalent to the listing of
∗ (see Figure 2). The latter is computationally much easier than the former
d when n (cid:29) dr .
∗ are much smaller than those of G and U r
Furthermore, ﬁnding the transversal of G∗ (cid:13) U r
since the cardinalities of G∗ and U r
d
∗ can be done without knowning sample size n. Due
to the structure of each orbit of G (cid:13) U r
d , we can calculate the cardinality of each orbit of G (cid:13) U r
d
with the transversal of G∗ (cid:13) U r
∗ , although G (cid:13) U r
d and G∗ (cid:13) U r
d
∗ have different caridnalities for
d
d
d
corresponding orbits.
Table 1: Ofﬂine double sided searching algorithm for listing the transversal
Input: d and r ,
1. Starting from an orbit representative {(1, · · · , d), · · · , ((r − 1)d + 1, · · · , rd)}
2. Construct the transversal of Sdr (cid:13) U r
∗ by merging
3. Construct the transversal of of G∗ (cid:13) U r
∗ by graph isomorphism testing
d
4. Ending to an orbit representative {(1, · · · , 1), · · · , (1, · · · , 1)}
Output: a transversal L of G (cid:13) U r
d
d , #(λ), #(λ → ν ), and merging order(symmetry order) of orbits
sal of G (cid:13) U r
Comparing with the Cayley Action Graph naive algorithm, our improved algorithm lists the transver-
d and calculates the cardinalities of all orbits more efﬁciently. In addition, the improved
algorithm also assigns a symmetry order to all orbits, which helps further reduce the computational

5

Cayley action graphSet of orbits13213211i12i)}],[{()}],[{(211112  Utransversal   rdUG\\**\\rdUGcost of the data function orbit sum hλ and the index function orbit sum wλ . The base of our im-
one hand, it is challenging to directly list the transversal of G∗ (cid:13) U r
proved algorithm is on the fact that a subgroup acting on the same set causes a ﬁner partition. On
∗ . On the other hand, it is much
∗ . These two group
actions help us ﬁnd the transversal of G∗ (cid:13) U r
d
easier to ﬁnd two related group actions, causing ﬁner and coarser partitions of U r
∗ efﬁciently with a double sided searching method.
d
d
∗ is deﬁned as σ · ik
m , where σ ∈
Each orbit of Sdr (cid:13) U r
Deﬁnition 3. The action of Sdr on the index set U r
Sdr , m ∈ {1, · · · , d}, and k ∈ {1, · · · , r}.
∗ is denoted by
d
1 , · · · , i1
d ), · · · , (ir
1 , · · · , ir
d )}]s .
[{(i1
d
Note the group action deﬁned in deﬁnition 3 only allows permutation of index values, it does not
∗ is a ﬁner partition of G∗ (cid:13) U r
embedded in G∗ , the set of orbits Sdr (cid:13) U r
allow shufﬂing of index words within each index sentence or of index sentences. Since Sdr is
∗ . For example, both
[{(1, 2)(1, 2)}]s and [{(1, 2)(2, 1)}]s are ﬁner partitions of [{(1, 2)(1, 2)}]. In addition, it is easy to
construct a transversal of Sdr (cid:13) U r
d
d
∗ by merging distinct index elements.
d
Deﬁnition 4. Given a representative I , which includes at least two distinct index values, for example
i (cid:54)= j , an operation called merging replaces all index values of i or j with min(i, j ).
For example, [{(1, 2)(2, 3)}] becomes [{(1, 1)(1, 3)}] after merging the index values of 1 and 2.
∗ is deﬁned as σ ·iθ−1 ·(k,m)s
Deﬁnition 5. The action of Sdr ×Sdr on the index set U r
, where θ ∈ Sdr
θ−1 ·(k,m)w
d
denotes a permutation of all dr index words without any restriction, i.e. θ−1 · (k , m)s denotes the
index sentence location after permutation θ , and θ−1 · (k , m)w denotes the index word location after
permutation θ . The orbit of Sdr × Sdr (cid:13) U r
1 , · · · , ir
d ), · · · , (ir
1 , · · · , i1
∗ is denoted by [{(i1
d )}]l .
d
words, the order does not matter for Sdr × Sdr (cid:13) U r
Since the group action deﬁned in deﬁnition 5 allows free shufﬂing of the order of all dr index
∗ and shufﬂing can across different sentences.
∗ is a coarser partition of G∗ (cid:13) U r
For example, [{(1, 2)(1, 2)}]l = [{(1, 1)(2, 2)}]l . Sdr × Sdr (cid:13) U r
∗ .
d
Proposition 4. A transversal of Sdr (cid:13) U r
d
d
∗ can be generated by all possible mergings of
[{(1, · · · , d), · · · , (d(r − 1) + 1, · · · , dr)}]s .
d
Proposition 5. Enumerating a transversal of Sdr × Sdr (cid:13) U r
∗ is equivalent to the integer partition
d
of dr .
We start the transversal graph construction from an initial orbit [{(1, · · · , d), · · · , (d(r − 1) +
1, · · · , dr)}]s , i.e, all index elements have distinct values. Then we generate new orbits of Sdr (cid:13) U r
∗
by merging distinct index values in existing orbits until we meet [{(1, · · · , 1), · · · , (1, · · · , 1)}]s ,
d
i.e., all index elements have equal values. We also add an edge from an existing orbit to a new orbit
generated by merging the existing one. The procedure for d = 2, r = 2 case is shown in Figure 3.
∗ from that of Sdr (cid:13) U r
Now we generate the transversal of G∗ (cid:13) U r
∗ . This can be done by checking
whether two orbits in Sdr (cid:13) U r
∗ are equivalent in G∗ (cid:13) U r
∗ . Actually, orbit equivalence checking
d
d
d
d
is equivalent to the classical graph isomorphism problem since we can consider each index word as
(cid:16)
(cid:17)
a vertex and connect two index words if they belong to the same index sentence.
, where v is the number of vertices. Figure 4 shows a transversal of G∗ (cid:13) U 2
The graph isomorphism testing can be done by Luks’s famous algorithm [1,15] with computational
√
∗
cost exp
(Figure 3). By proposition 3, it is also a transversal of G (cid:13) U 2
generated from that of S4 (cid:13) U 2
O(
v logv)
2
∗
Since G∗ (cid:13) U r
∗ is a ﬁner partition of Sdr × Sdr (cid:13) U r
2 .
∗ , orbit equivalence testing is only necessary
when two orbits of Sdr (cid:13) U r
2
∗ correspond to the same integer partition. This is why we named this
d
d
d
algorithm double sided searching.

Figure 3: Transversal graph for S4 (cid:13) U 2
2

∗

.

graph for G (cid:13) U 2
Transversal
4:
Figure
2 .

6

 [{(1,2)(3,1)}]s [{(1,2)(3,3)}]s [{(1,2)(1,1)}]s [{(1,2)(1,2)}]s [{(1,2)(2,1)}]s [{(1,2)(2,2)}]s [{(1,1)(1,1)}]s [{(1,1)(3,4)}]s [{(1,2)(1,4)}]s [{(1,2)(2,4)}]s [{(1,2)(3,2)}]s [{(1,1)(3,3)}]s [{(1,1)(3,1)}]s [{(1,1)(1,4)}]s [{(1,2)(3,4)}]s   [(1,2) (3,4)] [(1,1)(3,4)] [(1,2)(1,4)] [(1,2)(3,1)] [(1,2)(2,4)] [(1,2)(3,2)] [(1,2)(3,3)] [(1,1)(3,1)] [(1,1)(3,3)] [(1,2)(1,1)] [(1,2)(1,2)] [(1,2)(2,1)] [(1,2)(2,2)] [(1,1)(1,4)] [(1,1) (1,1)]s  [{(1,2)(3,4)}][{(1,1)(1,1)}][{(1,1)(2,3)}][{(1,2)(1,3)}][{(1,1)(2,2)}][{(1,2)(1,2)}][{(1,1)(1,2)}]Deﬁnition 6. For any two index orbit representatives λ ∈ L and ν ∈ L, we say that ν has a lower
merging or symmetry order than that of λ, i.e., ν ≺ λ, if [ν ] can be obtained from [λ] by several
mergings. Or there is a path from [λ] to [ν ] in the transversal graph. Here L denotes a transversal set
of all orbits.
Deﬁnition 7. We deﬁne #(λ) as the number of Sdr (cid:13) U r
∗ orbits in [λ]. We also deﬁne #(λ → ν )
d
as the number of different [ν ]s s which can be reached from a [λ]s .
d from that of Sdr (cid:13) U r
It is easy to get #(λ) when we generate a transversal graph of G (cid:13) U r
∗ .
The #(λ → ν ) can also be obtained from the transversal graph of G (cid:13) U r
d
d by counting the num-
ber of different [ν ]s s which can be reached from a [λ]s . For example, there are edges connecting
[{(1, 1)(3, 4)}]s to [{(1, 1)(1, 4)}]s and [{(1, 1)(3, 1)}]s . Since [{(1, 1)(1, 4)}] = [{(1, 1)(3, 1)}] =
[{(1, 1)(1, 2)}], #(λ = {(1, 1)(2, 3)} → ν = {(1, 1)(1, 2)}) = 2. Note that this number can also
be obtained from [{(1, 2)(3, 3)}]s to [{(1, 2)(1, 1)}]s and [{(1, 2)(2, 2)}]s .
The difﬁculty for computing data function orbit sum and index function orbit sum comes from two
constraints: equal constraint and unequal constraint. For example, in the orbit [{(1, 1), (2, 2)}], the
equal constraint is that the ﬁrst and the second index values are equal and the third and fourth index
values are also equal. On the other hand, the unequal constraint requires that the ﬁrst two index
values are different from the last two. Due to the difﬁculties mentioned, we solve this problem
by ﬁrst relaxing the unequal constraint and then applying the principle of inclusion and exclusion.
(cid:16)(cid:80)
(cid:17)2
λ=[{(1,1),(2,2)}] = (cid:80)
Thus, the calculation of an orbit sum can be separated into two parts: the relaxed orbit sum without
unequal constraint and lower order orbit sums. For example, the relaxed index function orbit sum is
w∗
.
i,j w(i, i)w(j, j ) =
i w(i, i)
(cid:80)
Proposition 6. The index function orbit sum wλ can be calculated by subtracting all lower or-
λ −
der orbit sums from the corresponding relaxed index function orbit sum w∗
λ , i.e., wλ = w∗
#(ν ) #(λ → ν ). The cardinality of [λ] is #(λ)n(n − 1) · · · (n − q + 1), where q is the
#(λ)
ν≺λ wν
number of distinct values in λ. The calculation of the data index function orbit sum hλ is similar.
So the computational cost mainly depends on the calculation of relaxed orbit sum and the lowest
order orbit sum. The computational cost of the lowest order term is O(n). The calculation of
relaxed orbit can be done by Zhou’s greedy graph search algorithm [21].
Proposition 7. For d ≥ 2, let m(m − 1)/2 ≤ rd(d − 1)/2 < (m + 1)m/2, where r is the order
of moment and m is an integer. For a d-th order weighted v -statistic, the computational cost of the
orbit sum for the r-th moment is bounded by O(nm ). When d = 1, the computational complexity
of the orbit sum is O(n).

4 Bootstrap

Since Bootstrap is resamping with replacement, we need to change Sn to the set of all possible
endofunctions Endn in our computing scheme. In mathematics, an endofunction is a mapping of a
set to its subset. With this change, H := Endn × Sr × S r
d acting on U r
d becomes a monoid action
instead of a group action since endofunction is not invertible. The monoid action also divides the U r
2 = [(1, 2)] (cid:83)[(1, 1)] by monoid action H × U r
d
into several subsets. However, these subsets are not necessarily disjoint after mapping. For example,
2 into two subsets, i.e., [(1, 1)] and [(1, 2)].
when d = 2 and r = 1, we can still divide the index set U 1
d → U r
d , although
However, [(1, 2)] is mapped to U 1
[(1, 1)] is still mapped to itself. Fortunately, the computation of Bootstrap weighted v -statistics
only needs index function orbit sums and relaxed data function orbit sums in the corresponding
permutation computation. Therefore, the Bootstrap weighted v -statistics calculation is just a sub-
problem of permutation weighted v -statistics calculation.
Proposition 8. We can obtain the r-th moment of bootstrapping weighted v -statistics by summing
up the product of the index function orbit sum wλ and the relaxed data function orbit sum h∗
λ over
(cid:88)
all index orbits, i.e.,
wλh∗
Eσ (T r (x)) =
λ
card([λ∗ ])
λ∈L
where σ ∈ Endn , card([λ∗ ]) = #(λ)nq , and q is the number of distinct values in λ.

(7)

,

7

Linear

Permutation

Table 2: Comparison of accuracy and complexity for calculation of resampling statistics.
4th
3rd
2nd moment
Methods
Time
1.1153e3
1.0495
-0.8273
0.7172
Exact
0.0057
1.0495
-0.8273
0.7172
Our
Random
0.7014
-0.8326
1.0555
0.5605
1.718e3
2.1560e6
-4.6020e4
1.0611e3
Exact
0.006
2.1560e6
-4.6020e4
1.0611e3
Our
2.1825e6
-4.5783e4
1.0569e3
Random
2.405
204.4381
35.4241
8.9737
3.5166
Exact
Our
3.5166
8.9737
35.4241
0.0053
0.3294
3.4769
Random
34.6393
8.8390
445.536
2.6998e8
-6.0322e6
2.4739e5
Exact
0.005
2.6998e8
-6.0322e6
2.4739e5
Our
Random
2.4576e5
-5.9825e6
2.6589e8
1.987

Quadratic

Bootstrap

Linear

Quadratic

The computational cost of bootstrapping weighted v -statistics is the same level as that of permutation
statistics.

5 Numerical results
mutation and bootstrapping for both linear test statistic (cid:80)n
(cid:80)n
(cid:80)n
To evaluate the accuracy and efﬁciency of our mothds, we generate simulated data and conduct per-
i=1 w(i)h(xi ) and quadratic test statistic
i2=1 w(i1 , i2 )h(xi1 , xi2 ) . To demonstrate the universal applicability of our method and
i1=1
prevent a chance result, we generate w(i), h(xi ), w(i1 , i2 ), h(xi1 , xi2 ) randomly. We compare the
accuracy and complexity among exact permutation/bootstrap, random permutaton/bootrap (10,000
times), and our methods. Table 2 shows comparisons for computing the second, third, and fourth
moments of permutation statistics with 11 observations (the running time is in seconds) and of boot-
strap statistics with 8 observations.
In all cases, our method achieves the same moments as those of exact permutation/bootstrap, and re-
duces computational cost dramatically comparing with both random sampling and exact sampling.
For demonstration purpose, we choose a small sample size here, i.e., sample size is 11 for per-
mutation and 8 for bootstrap. Our method is expected to gain more computational efﬁciency as n
increases.

6 Conclusion

In this paper, we propose a novel and computationally fast algorithm for computing weighted v -
statistics in resampling both univariate and multivariate data. Our theoretical framework reveals that
the three types of symmetry in resampling weighted v -statistics can be represented by a product of
symmetric groups. As an exciting result, we demonstrate the calculation of resampling weighted
v -statistics can be converted into the problem of orbit enumeration. A novel efﬁcient orbit enumer-
ation algorithm has been developed by using a small group acting on a small index set. For further
computational cost reduction, we sort all orbits by their symmetry order and calculate all index func-
tion orbit sums and data function orbit sums recursively. With computational complexity analysis,
we have reduced the computational cost from n! or nn level to low-order polynomial level.

7 Acknowledgement

This research was supported by the Intramural Research Program of the NIH, Clinical Research
Center and through an Inter-Agency Agreement with the Social Security Administration, the NSF
CNS 1135660, Ofﬁce of Naval Research award N00014-12-1-0125, Air Force Ofﬁce of Scien-
ticﬁc Research award FA9550-12-1-0201, and IC Postdoctoral Research Fellowship award 2011-
11071400006.

8

References

[01] Babai, L., Kantor, W.M. , and Luks, E.M. (1983), Computational complexity and the classiﬁcation of ﬁnite
simple groups, Proc. 24th FOCS, pp. 162-171.
[02] Minaei-Bidgoli, B., Topchy, A., and Punch, W. (2004), A comparison of resampling methods for clustering
ensembles, In Proc. International Conference on Artiﬁcial Intelligence, Vol. 2, pp. 939-945.
[03] Estabrooks, A., Jo, T., and Japkowicz, N. (2004), A Multiple Resampling Method for Learning from
Imbalanced Data Sets, Comp. Intel. 20 (1) pp. 18-36.
[04] Francois, D., Rossib, F., Wertza, V., and Verleysen, M. (2007), Resampling methods for parameter-free
and robust feature selection with mutual information, Neurocomputing 70(7-9):1276-1288.
[05] Good, P. (2005), Permutation, Parametric and Bootstrap Tests of Hypotheses, Springer, New York.
[06] Gretton, A., Borgwardt, K., Rasch, M., Scholkopf, B., and Smola, A. (2007), A kernel method for the
two-sample- problem, In Advances in Neural Information Processing Systems (NIPS).
[07] Guo, S. (2011), Bayesian Recommender Systems: Models and Algorithms, Ph.D. thesis.
[08] Hopcroft, J., and Tarjan, R. (1973), Efﬁcient algorithms for graph manipulation, Communications of the
ACM 16: 372-378.
[09] Huang, J., Guestrin, C., and Guibas, L. (2007), Efﬁcient Inference for Distributions on Permutations, In
Advances in Neural Information Processing Systems (NIPS).
[10] Kerber, A. (1999), Applied Finite Group Actions, Springer-Verlag, Berlin.
[11] Kondor, R., Howard, A., and Jebara, T. (2007), Multi-Object Tracking with Representations of the Sym-
metric Group, Artiﬁcial Intelligence and Statistics (AISTATS).
[12] Kuwadekar, A. and Neville, J. (2011), Relational Active Learning for Joint Collective Classiﬁcation Mod-
els, In International Conference on Machine Learning (ICML), P. 385-392.
[13] Liu, H., Palatucci, M., and Zhang, J.(2009), Blockwise coordinate descent procedures for the multi-task
lasso, with applications to neural semantic basis discovery, In International Conference on Machine Learning
(ICML).
[14] Matthew Higgs and John Shawe-Taylor. (2010), A PAC-Bayes bound for tailored density estimation, In
Proceedings of the International Conference on Algorithmic Learning Theory (ALT).
[15] McKay, B. D. (1981), Practical graph isomorphism, Congressus Numerantium 30: 45-87, 10th. Manitoba
Conf. on Numerical Math. and Computing.
[16] Mielke, P. W., and K. J. Berry (2007), Permutation Methods: A Distance Function Approach, Springer,
New York.
[17] Nicholson, W. K. (2006), Introduction to Abstract Algebra, 3rd ed., Wiley, New York.
[18] Serﬂing, R. J. (1980), Approximation Theorems of Mathematical Statistics, Wiley, New York.
[19] Song, L. (2008), Learning via Hilbert Space Embedding of Distributions, Ph.D. thesis.
[20] Sutton, R. and Barto, A. (1998), Reinforcement Learning, MIT Press.
[21] Zhou, C., Wang, H., and Wang, Y. M. (2009), Efﬁcient moments-based permutation tests, In Advances in
Neural Information Processing Systems (NIPS), p. 2277-2285.

9

